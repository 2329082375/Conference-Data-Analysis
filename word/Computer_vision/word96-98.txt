most of the research on face recognition address the match problem and it assumes a closed universe where there is no need for a reject false positive option the surveillance problem is addressed indirectly if at all through the match problem where the size of the gallery rather than that of the probe set is very large this paper address the proper surveillance problem where the size of the probe unknown image set v gallery known image set is v frontal image we developed robust face id verification classification and retrieval scheme based on hybrid classifier and showed their feasibility using the feret face database the hybrid classifier architecture consists of an ensemble of connectionist network radial basis function rbf and inductive decision tree dt experimental result prove the feasibility of our approach and yield accuracy using the probe and gallery set specified above 
this work considers the problem of discovering areasof convergence of line like shape in an image themotivating application is to use the convergence of theblood vessel network to automatically locate the opticnerve in an ocular fundus image a fuzzy segmentmodel is proposed based on a conjecture that line likeshapes only contribute to a perception of convergencein their near neighborhood using this model a votingtypemethod is described to compute a convergence image which can be 
this paper describes a representation for people and animal called a body plan which is adapted to segmentation and to recognition in complex environment the representation is an organized collection of grouping hint obtained from a combination of constraint on color and texture and constraint on geometric property such a the structure of individual part and the relationship between part body plan can be learned from image data using established statistical learning technique the approach is illustrated with two example of program that successfully use body plan for recognition one example involves determining whether a picture contains a scantily clad human using a body plan built by hand the other involves determining whether a picture contains a horse using a body plan learned from image data in both case the system demonstrates excellent performance on large uncontrolled test set and very large and diverse control set 
a new region based approach to nonrigid motion tracking is described shape is defined in term of a deformable triangular mesh that capture object shape plus a color texture map that capture object appearance photometric variation are also modeled nonrigid shape registration and motion tracking are achieved by posing the problem a an energy based robust minimization procedure the approach provides robustness to occlusion wrinkle shadow and specular highlight the formulation is tailored to rake advantage of texture mapping hardware available in many workstation pc and game console this enables nonrigid tracking at speed approaching video rate 
the efficiency of pattern recognition is particularly crucial in two scenario whenever there are a large number of class to discriminate and whenever recognition must be performed a large number of time we propose a single technique namely pattern rejection that greatly enhances efficiency in both case a rejector is a generalization of a classifier that quickly eliminates a large fraction of the candidate class or input this allows a recognition algorithm to dedicate it effort to a much smaller number of possibility importantly a collection of rejectors may be combined to form a composite rejector which is shown to be far more effective than any of it individual component a simple algorithm is proposed for the construction of each of the component rejectors it generality is established through close relationship with the karhunen lo ve expansion and fisher s discriminant analysis composite rejectors were constructed for two representative application namely appearance matching based object recognition and local feature detection the result demonstrate substantial efficiency improvement over existing approach most notably fisher s discriminant analysis 
this paper describes an interactive sensor planning system that can be used to select viewpoint subject to camera visibility field of view and task constraint application area for this method include surveillance planning safety monitoring architectural site design planning and automated site modeling given a description of the sensor s characteristic the object in the d scene and the target to be viewed our algorithm compute the set of admissible view point that satisfy the constraint the system first build topologically correct solid model of the scene from a variety of data source viewing target are then selected and visibility volume and field of view cone are computed and intersected to create viewing volume where camera can be placed the user can interactively manipulate the scene and select multiple target feature to be viewed by a camera the user can also select candidate viewpoint within this volume to synthesize view and verify the correctness of the planning system we present experimental result for the planning system on an actual complex city model 
the vast majority of corner and edge detector measure image intensity gradient in order to estimate the position and strength of feature however many of the most popular intensity gradient estimator are inherently and significantly anisotropic in spite of this few algorithm take the anisotropy into account and so the set of feature uncovered is typically sensitive to rotation of the image compromising recognition matching e g stereo and tracking we introduce an effective technique for removing unwanted anisotropy from analytical gradient estimate by measuring local intensity gradient in four direction rather than the more traditional two in experiment using real image data our algorithm reduces the gradient anisotropy associated with conventional analytical gradient estimate by up to yeilding more consistent feature topology 
many classical image processing task can be realized a evaluation of a boolean function over subset of an image for instance the simplicity test used in d thinning requires examining the neighbor of each voxel and computing a single boolean function of these input in this article we show how binary decision diagram can be used to produce automatically very efficient and compact code for such function the total number of operation performed by a generated function is at most one test and one branching for each input value e g in the case of d thinning test and branching at each stage the function is guaranteed to examine only the pertinent input data i e the value which affect the result a an example we consider the d simplicity test in digital topology and thinning process we produce function much faster than our previously optimized implementation and than any other implementation we know of in the case of d simplicity test on average at each voxel only neighboring voxel value are examined 
this paper present a new technique for modelling object class such a face and matching the model to novel image from the object class the technique can be used for a variety of image analysis application including face recognition object verification and facial expression analysis the model called a hierarchical morphable model is learned from example image partioned into component and their correspondence this is an extension to the work on morphable model described in previous paper hierarchical morphable model are shown to find good match to novel face image and are also robust to partial occlusion 
conventional video camera have limited field of view that make them restrictive in a variety of vision application there are several way to enhance the field of view of an imaging system however the entire imaging system must have a single effective viewpoint to enable the generation of pure perspective image from a sensed image a new camera with a hemispherical field of view is presented two such camera can be placed back to back without violating the single viewpoint constraint to arrive at a truly omnidirectional sensor result are presented on the software generation of pure perspective image from an omnidirectional image given any user selected viewing direction and magnification the paper concludes with a discussion on the spatial resolution of the proposed camera 
this paper focus on the estimation of the intrinsiccamera parameter and the trajectory of the camerafrom an image sequence intrinsic camera calibrationand pose estimation are the prerequisite formany application involving navigation task scenereconstruction and merging of virtual and real environment proposed and evaluated is a technical solutionto decrease the sensitivity of self calibration byplacing easily identifiable target of known shape in theenvironment the relative 
existing method for grouping edge on the basis of localsmoothness measure fail to compute complete contour in natural image it appears that a stronger global constraint is required motivatedby growing evidence that the human visual system exploit contour closurefor the purpose of perceptual grouping we presentan algorithm for computing highly closed bounding contour from image unlike previous algorithm no restriction are placedon the 
remote reality is an approach to providing an immersive environment via omni directional imaging the system can use a live video feed from a remote location or can use recorded data and be remote in both space and time while le interactive than traditional vr remote reality ha an important advantage there is little to no need for model building in addition the object the texture and the motion are not just realistic they are remote view of reality 
when a symmetric object in d is projected to an image the symmetry property are lost except for specific relative viewpoint for sufficiently complex object however it is still possible to infer symmetry in d from a single image of an uncalibrated camera in this paper we give a general computational procedure for computing d structure and finding image symmetry constraint from single view projection of symmetric d object for uncalibrated camera these constraint take the form of polynomial in bracket determinant and by using projectively invariant shape constraint relating d and image structure the symmetry constraint can be derived easily by considering the effect of the corresponding symmetry transformation group in d the constraint can also be given a useful geometric interpretation in term of projective incidence using the grassmann cayley algebra formalism we demonstrate that in specific situation geometric intuition and the use of gc algebra is a very simple and effective tool for finding image symmetry constraint 
search is not inherent in the correspondence problem we propose a representation of image called intrinsic curve that combine the idea of associative storage of image with connectedness of the representation intrinsic curve are the path that a set of local image descriptor trace a an image scanline is traversed from left to right curve become surface when full image are considered instead of scanlines because only the path in the space of descriptor is used for matching intrinsic curve lose track of space and are invariant with respect to disparity under ideal circumstance establishing stereo correspondence then becomes a trivial lookup problem we also show how to use intrinsic curve to match real image in the presence of noise brightness bias contrast fluctuation and moderate geometric distortion and we show how intrinsic curve can be used to deal with image ambiguity and occlusion we carry out experiment on single scanline matching to prove the feasibility of the approach and illustrate it main feature 
in this paper we propose the use of mirror and a single camera for computational stereo when compared to conventional stereo system that use two camera our method ha a number of significant advantage such a wide field of view single viewpoint projection identical camera parameter and ease of calibration we propose four stereo system that use a single camera pointed towards planar ellipsoidal hyperboloidal and paraboloidal mirror in each case we present a derivation of the epipolar constraint next we attempt to understand what can be seen by each system and formalize the notion of field of view we conclude with two experiment to obtain d structure in the first we use a pair of planar mirror and in the second a pair of paraboloidal mirror the result of our experiment demonstrate the viability of stereo using mirror 
we propose an algorithm to automatically construct feature detector for arbitrary parametric feature to obtain a high level of robustness we advocate the use of realistic multi parameter feature model and incorporate optical and sensing effect each feature is represented a a densely sampled parametric manifold in a low dimensional subspace of a hilbert space during detection the brightness distribution around each image pixel is projected into the subspace if the projection lie sufficiently close to the feature manifold the feature is detected and the location of the closest manifold point yield the feature parameter the concept of parameter reduction by normalization dimension reduction pattern rejection and heuristic search are all employed to achieve the required efficiency by applying the algorithm to appropriate parametric feature model detector have been constructed for five feature namely step edge roof edge line corner and circular disc detailed experiment are reported on the robustness of detection and the accuracy of parameter estimation 
this paper is concerned with acquiring panoramic focused image using a small field of view video camera when scene point are distributed over a range of distance from the sensor obtaining a focused composite image involves focus computation and mechanically changing some sensor parameter translation of sensor plane panning of camera etc which can be time intensive in this paper we present method to optimize the image acquisition strategy in order to reduce redundancy we show that panning a camera about a point f focal length in front of the camera eliminates redundancy the non frontal imaging camera nicam with tilted sensor plane ha been previously introduced a a sensor that can acquire focused panoramic image in this paper we also describe strategy for optimal selection of panning angle increment and sensor plane tilt for nicam experimental result are presented for panoramic image acquisition using a regular camera a well a using nicam 
an approach to normalization is presented for both the affine and the projective case the approach is based on group factorization a well a on optimizing parameter invariant integral in order to overcome the difficult problem of parameterization related work ha been carried out by and by for affine transformation and by for projective transformation to avoid some drawback inherent to projective transformation it is suitable to integrate point information or explore thick curve 
this paper present a new operater for corner detection this operator us a variant of the morphological closing operator which we have called asymmetrical closing it consists of the successive application of different morphological transformation using different structuring element each of these structuring element used to probe the image under study is tuned to affect corner of different orientation and brightness we found that this kind of approach based on brightness comparison lead to better quality result than others and is achieved at a lower computational cost 
we describe a flexible model for representing image of object of a certain class known a priori such a face and introduce a new algorithm for matching it to a novel image and thereby performing image analysis we call this model a multidimensional morphable model or just a morphable model the morphable model is learned from example image calledprototypes of object of a class in this paper we introduce an effective stochastic gradient descent algorithm that automatically match a model to a novel image by finding the parameter that minimize the error between the image generated by the model and the novelimage two example demonstrate the robustness and the broad range of applicability of the matching algorithm and the underlying morphable model our approach can provide novel solution to several vision task including the computation of image correspondence object verification image synthesis and image compression 
we present a new function that operates on fundamental matrix across a sequence of view the operation we call threading connects two consecutive fundamental matrix using the trifocal tensor a the connecting thread the threading operation guarantee that consecutive camera matrix are consistent with a unique d model without ever recovering a d model application include recovery of camera ego motion from a sequence of view image stabilization plane stabilization across a sequence and multiview imagebased rendering 
matching image based on a hausdorff measure ha become popular for computer vision application however no probabilistic model ha been used in these application this limit the formal treatment of several issue such a feature uncertainty and prior knowledge in this paper we develop a probabilistic formulation of image matching in term of maximum likelihood estimation that generalizes a version of hausdorff matching this formulation yield several benefit with respect to previous hausdorff matching formulation in addition we show that the optimal model position in a discretized pose space can be located efficiently in this formation and we apply these technique to a mobile robot self localization problem 
in face recognition literature holistic template matching system and geometrical local feature based system have been pursued in the holistic approach pca principal component analysis and lda linear discriminant analysis are popular one more recently the combination of pca and lda ha been proposed a a superior alternative over pure pca and lda in this paper we illustrate the rationale behind these method and the pro and con of applying them to pattern classification task a theoretical performance analysis of lda suggests applying lda over the principal component from the original signal space or the subspace the improved performance of this combined approach is demonstrated through experiment conducted on both simulated data and real data 
the silhouette of a smooth d object observed by a moving camera change over time past work ha shown how surface geometry can be recovered using the deformation of the silhouette when the camera motion is known this paper address the problem of estimating both the full euclidean surface structure and the camera motion from a dense set of silhouette captured under orthographic or scaled orthographic projection the approach relies on a viewpoint invariant representation of curve swept by viewpoint dependent feature such a bitangents inflection and contour point with parallel tangent feature point which form stereo frontier point between non consecutive image are matched using this representation the camera s angular velocity is computed from constraint derived from this correspondence along with the image velocity of these feature from the angular velocity the epipolar geometry is ascertained and infinitesimal motion frontier point can be detected in turn the motion of these frontier point constrains the translation component of camera motion finally the surface is reconstructed using established technique once the camera motion ha been estimated 
traditionally corner are found along step edge in this paper we present an alternative approach corner along ridge trough and local minimum point these feature seem to be more reliable for tracking a new approach for sub pixel localization of these corner is suggested using a local approximation of the image surface 
we have designed and implemented a real time binocular tracking system which us two independent cue commonly found in the primary function of biological visual system to robustly track moving target in complex environment without a priori knowledge of the target shape or texture a fast optical flow segmentation algorithm quickly locates independently moving object for target acquisition and provides a reliable velocity estimate for smooth tracking in parallel target position is generated from the output of a zero disparity filter where a phase based disparity estimation technique allows dynamic control of the camera vergence to adapt the horopter geometry to the target location the system take advantage of the optical property of our custom designed foveated wide angle lens which exhibit a wide field of view along with a high resolution fovea method to cope with the distortion introduced by the space variant resolution and a robust real time implementation on a high performance active vision head are presented 
the basic limitation of the current appearance based matching method using eigenimages are non robust estimation of coefficient and inability to cope with problem related to occlusion and segmentation in this paper we present a new approach which successfully solves these problem the major novelty of our approach lie in the way how the coefficient of the eigenimages are determined instead of computing the coefficient by a projection of the data onto the eigenimages we extract them by a hypothesize and test paradigm using subset of image point competing hypothesis are then subject to a selection procedure based on the minimum description length principle the approach enables u not only to reject outlier and to deal with occlusion but also to simultaneously use multiple class of eigenimages 
abstract one of the main problem to obtain a euclidean d reconstructionfrom multiple view is the calibration of the camera explicitcalibration is not always practical and ha to be repeated regularly sometimesit is even impossible i e for picture taken by an unknown cameraof an unknown scene the second possibility is to do auto calibration 
in this paper we study the statistical theory of shape for ordered finite point congurations or otherwise stated the uncertainty of geometric invariant such study have been made for affine invariant in e g where in the former case a bound on error are used instead of error described by density function and in the latter case a first order approximation give an ellipsis a uncertainty region here a general approach for defining shape and finding it density expressed 
we present virtualized reality a technique to create virtual world out of dynamic event using densely distributed stereo view the intensity image and depth map for each camera view at each time instant are combined to form a visible surface model immersive interaction with the virtualized event is possible using a dense collection of such model additionally acomplete surface model of each instant can be built by merging the depth map from different camera into a common volumetric space the corresponding model is compatible with traditional virtual model and can be interacted with immersively using standard tool because both vsms and csms are fully three dimensional virtualized model can also be combined and modi ed to build larger more complex environment an important capability for many non trivial application we present result from d dome our facility to create virtualized model 
a novel feature detector the constrained phase congruency transform cpct is introduced it simultaneously detects interest point a well a their scale in various orientation the cpct is especially important in registration application the local transformation between interest point can be determined based on their orientational scale the cpct detects the feature in mach band and in sinusoidal wave this cannot be done simply by looking for local maximum in intensity gradient nor by looking for local energy maximum i conjecture that constraining the general phase congruency is sufficient for feature detection the correct detection of feature location and of their scale is demonstrated the robustness of the cpct is achieved by constraining the local phase only four easy to detect phase are used in the computation they correspond to symmetry and anti symmetry in their neighborhood the scale at any location and orientation is determined by the scale of the channel that conforms to the constraint and maximizes energy 
we propose a new machine learning paradigm called graph transformer network that extends the applicability of gradient based learning algorithm to system composed of module that take graph a input and produce graph a output training is performed by computing gradient of a global objective function with respect to all the parameter in the system using a kind of back propagation procedure a complete check reading system based on these concept is described the system us convolutional neural network character recognizers combined with global training technique to provide record accuracy on business and personal check it is presently deployed commercially and read million of check per month 
this paper investigates the problem of computing the fundamental matrix for a class of active stereo vision system namely with common elevation platform the fundamental matrix is derived for such a system and a number of method are proposed to simplify it computation experimental result validate the feasibility of the different method these method are then used in a real application to validate the correctness of the fundamental matrix form for an active stereo system we demonstrate that typical variation in camera intrinsic parameter do not much affect the epipolar geometry in the image this motivates u to calibrate the camera intrinsic parameter approximately and then to use the calibration result to compute the epipolar geometry directly in real time 
we derive and discus a set of parametric equation which when given a convex d feature domain k will generate affine invariant with the property that the invariant value are uniformly distributed in the region once the shape of the feature domain k is determined and fixed it is straightforward to compute the value of the parameter and thus the proposed scheme can be tuned to a specific feature domain the feature of all recognizable object model are assumed to be three dimensional point and uniformly distributed over k the scheme lead to improved discrimination power improved computational load and storage load balancing and can also be used to determine and identify bias in the database of recognizable model over represented construct of object point obvious enhancement produce rigid transformation and similarity transformation invariant with the same good distribution property making this approach generally applicable 
this paper present an approach to the recognition of articulated d object in monocular video image a hierarchical object representation model object a a composition of rigid component which are explicitly connected by specific kinematic constraint e g rotational and or translational joint the recognition task follows this tree like structure by first estimating the d pose of the static component root and afterwards determining the relative d pose of the remaining component recursively this method limit the search space for the actual correspondence between image and model feature and cope with the problem of self occlusion experiment in the context of autonomous mobile robot show the practicability of this approach 
this paper present a new approach for the classification and retrieval of three dimensional image and model from database a set of retrieval algorithm is introduced these algorithm are content based meaning that the input is not made out of keywords but of three dimensional model tensor of inertia distribution of normal and distribution of cord are used to describe each model the database can be searched by scale shape or color or any combination of these parameter a user friendly interface make the retrieval operation simple and intuitive and allows to edit reference model according to the specification of the user experimental result using a database of more than range image and vrml model are presented 
we describe an estimation technique which given a measurement of the depth of a target from a wide field of view wfov stereo camera pair produce a minimax risk fixed size confidence interval estimate for the target depth this work constitutes the first application to the computer vision domain of optimal fixed size confidence interval decision theory the approach is evaluated in term of theoretical capture probability and empirical capture frequency during actual experiment with a target on an optical bench the method is compared to several other procedure including the kalman filter the minimax approach is found to dominate all the other method in performance in particular for the minimax approach a very close agreement is achieved between theoretical capture probability and empirical capture frequency this allows performance to be accurately predicted greatly facilitating the system design and delineating the task that may be performed with a given system 
we present a new algorithm for computing the heading from multiple frame which improves on previous approach it exploit our discovery and analysis of a new structure from motion ambiguity allowing for this ambiguity also make two frame reconstruction more robust we show experimentally that the error landscape for planar scene ha few significant local minimum 
the distribution of object color can be effectively utilized for recognition and indexing difficulty arise in the recognition of object color distribution when there are variation in illumination color change in object pose with respect to illumination direction and specular reflection however most of the recent approach to color based recognition focus mainly on illumination color invariance we propose an approach that identifies object color distribution influenced by illumination pose illumination color and specularity we suggest the use of chromaticity distribution to achieve illumination pose invariance to characterize change in chromaticity distribution due to illumination color a set of chromaticity histogram of each object is generated for a range of lighting color based on linear model of illumination and reflectance and the histogram are represented using a small number of eigen basis vector constructed from principal component analysis since specular reflection may alter the chromaticity distribution of test object a model based specularity detection rejection algorithm called chromaticity differencing is developed to reduce these effect 
abstract the appearance of an object depends on both the viewpoint from which it is observed and the lightsources by which it is illuminated if the appearance of two object is never identical for any pose or lightingconditions then in theory the object can always be distinguished or recognized the question arises whatis the set of image of an object under all lighting condition and pose in this paper we consider only the set ofimages of an object under variable illumination 
we present a novel geometric approach for solving the stereo problem for an arbitrary number of image greater than or equal to it is based upon the definition of a variational principle that must be satisfied by the surface of the object in the scene and their image the euler lagrange equation which are deduced from the variational principle provide a set of pde s which are used to deform an initial set of surface which then move towards the object to be detected the level set 
for many practical application it is important to relax the self calibration condition to allow for changing internal camera parameter e g zooming focusing classical technique failed for such condition we present the available constraint that allow u to right a projective calibration to a euclidean one meanwhile we found that the estimation of the internal parameter were rather inaccurate we discus theoretically this difficulty and above all the resulting effect on the d reconstruction in fact we show that the uncertainty on the focal length estimation lead to a euclidean calibration up to a quasi anisotropic homothety whereas the error on the principal point can often be interpreted a a translation hopefully the calibration we come up with is quite acceptable for reconstruction of model 
the extraction of curvilinear structure is an important low level operation in computer vision most existing operator use a simple model for the line that is to be extracted i e they do not take into account the surroundings of a line therefore they will estimate a wrong line position whenever a line with different lateral contrast is extracted in contrast the algorithm proposed in this paper us an explicit model for line and their surroundings by analyzing the scale space behavior of a model line profile it is shown how the bias that is induced by asymmetrical line can be removed thus the algorithm is able to extract an unbiased line position and width both with sub pixel accuracy 
this contribution describes an automatic d surface modeling system that extract dense metric d surface from an uncalibrated video sequence a static d scene is observed from multiple viewpoint by freely moving a video camera around the object no restriction on camera movement and internal camera parameter like zoom are imposed a the camera pose and intrinsic parameter are calibrated from the sequence dense surface reconstruction are obtained by first treating consecutive image of the sequence a stereoscopic pair and computing dense disparity map for all image pair all viewpoint are then linked by controlled correspondence linking for each image pixel the correspondence linking algorithm allows for accurate depth estimation a well a image texture fusion from all viewpoint simultaneously by keeping track of surface visibility and measurement uncertainty it can cope with occlusion and measurement outlier the correspondence linking is applied to increase the robustness and geometrical resolution of surface depth a well a to remove highlight and specular reflection and to create super resolution texture map for increased realism the major impact of this work is the ability to automatically generate geometrically correct and visually pleasing d surface model from image sequence alone which allows the economic model generation for a wide range of application the resulting textured d surface model are highly realistic vrml representation of the scene 
in stereo algorithm with more than two camera the improvement of accuracy is often reported since they are robust against noise however another important aspect of the polynocular stereo that is the ability of occlusion detection ha been paid le attention we intensively analyzed the occlusion in the camera matrix stereo sea and developed a simple but effective method to detect the presence of occlusion and to eliminate it effect in the correspondence search by considering several statistic on the occlusion and the accuracy in the sea we derived a few base mask which represent occlusion pattern and are effective for the detection of occlusion several experiment using typical indoor scene showed quite good performance to obtain dense and accurate depth map even at the occluding boundary of object 
in this paper we propose fully d active surface model for image segmentation our model are capable of fitting a diverse range of region shape they have low sensitivity to initial shape and position we design self inflation deflation force which cooperate naturally with gradient force they permit the active surface to travel a long distance without the aid of any external force they are easily controlled in both their direction and magnitude the model produce accurate segmentation when tested with synthetic and real image they manifest robustness to image noise and imperfect image data importantly they are capable of converging to the correct boundary even if the initial estimate is not close 
we present a technique for camera calibration and euclidean reconstruction from multiple image of the same scene unlike standard tsai s camera calibration from a known scene we exploited controlled known motion of the camera to obtain it calibration and euclidean reconstruction without any knowledge about the scene we consider three linearly independent translation of an uncalibrated camera mounted on a robot arm that provides u with four view of the scene the translation of the robot arm are measured in a robot coordinate system this special but still realistic arrangement allowed u to find a linear algorithm for recovering all intrinsic camera calibration parameter the rotation of the camera with respect to the robot coordinate system and proper scaling factor for all point allowing their euclidean reconstruction the experiment showed that an efficient and robust algorithm wa obtained by exploiting total least square in combination with careful normalization of image coordinate 
automated scene recognition in dynamic environment involvesnot only object classification or recognition but also a furtherstep consisting in finding what is going on in this environment that isto say what the object are doing and what their purpose are 
a novel method for representing d object that unifies viewer and model centered object representation is presented a unified d frequency domain representation called volumetric iconic spectral signature v i encapsulates both the spatial structure of the object and a continuum of it view in the same data structure the frequency domain image of an object viewed from any direction can be directly extracted employing an extension of the projection slice theorem where each fourier transformed view is a planar slice of the volumetric frequency representation the v i representation can be employed for pose invariant recognition of complex object such a face the recognition and pose estimation is based on an efficient matching algorithm in a four dimensional fourier space experimental example of pose estimation and recognition of face are also presented 
stereo reconstruction algorithm often fail to properly deal with complex surface because there is not enough image information to overcome this problem we propose to guide the reconstruction process using a priori information about the differential geometry of the object surface we use both linear structure such a crest line or scalar field such a curvature value to generate a reconstruction of the surface which is consistent with the differential property this method improves the accuracy of the reconstruction around the discontinuity and increase the compactness of the surface representation 
the kalman filter is a very efficient optimal filter however it ha the precondition that the noise of the process and of the measurement are gaussian the author introduce the general distribution filter which is an optimal filter that can be used even where the distribution are not gaussian an efficient practical implementation of the filter is possible where the distribution are discrete and compact or can be approximated a such 
a number of vision based biometric technique have beenproposed in the past for personal identification we present a novel onebased on visual capturing of signature this paper describes a systembased on correlation and recursive prediction method that can trackthe tip of the pen in real time with sufficient spatio temporal resolutionand accuracy to enable signature verification several example and theperformance of the system are shown introduction and motivationa number of 
present a new approach to segment vessel from d angiography of the brain the author approach is based on a vessel model and us a multiscale analysis in order to extract the vessel network surrounding an aneurysm the author model allows them to choose a criterion based on the eigenvalue of the hessian matrix for selecting a subset of interesting point near the vessel center it also allows them to choose a good parameter for a normalization of the single scale response the response at one scale is obtained by integrating along a circle the first derivative of the intensity in the radial direction once the multiscale response is obtained the author create a smoothed skeleton of the vessel combined with a mip or a volume rendering to enhance their visualization the method ha been tested on a large variety of d image of the brain with excellent result vessel of various size and contrast are detected with a remarkable robustness and most junction are preserved 
this paper present an approach to measuring fluid flow from image sequence the approach center around a motion recovery algorithm that is based on principle from fluid mechanic the algorithm is constrained so that recovered flow observe conservation of mass a well a physically motivated boundary condition empirical result are presented from application of the algorithm to fluid flow captured via transmittance imagery i e radiograph in these experiment fluid seeded with tracer were driven through simple physical system the significance of this work is twofold first from a theoretical point of view it is shown how information derived from the physical behavior of fluid can be used to motivate a flow recovery algorithm second from an application point of view the developed algorithm can be used to augment the tool that are available for the measurement of fluid dynamic other imaged flow that observe compatible constraint might benefit in a similar fashion 
digital video is rapidly becoming important for education entertainment and a host of multimedia application with the size of the video collection growing to thousand of hour technology is needed to effectively browse seg ments in a short time without losing the content of the video we propose a method to extract the significant audio and video information and create a skim video which represents a very short synopsis of the original the goal of this work is to show the utility of integrating lan guage and image understanding technique for video skimming by extraction of significant information such a specific object audio keywords and relevant video struc ture the resulting skim video is much shorter where com paction is a high a and yet retains the essential content of the original segment 
this paper present a system for automatic extraction and tracking of d contour of the tongue surface from digital ultrasound image sequence the input to the system is provided by a head and transducer support system hat which is developed for use in ultrasound imaging of the tongue movement we developed a novel active contour snake model that us several temporally adjacent image during the extraction of the tongue surface contour for an image frame the user supply an initial contour model for a single image frame in the whole sequence using optical flow and multi resolution method this initial contour is then used to find the candidate contour point in the temporally immediate adjacent image subsequently the new snake mechanism is applied to estimate optimal contour for each image frame using these candidate point in turn the extracted contour are used a model for the extraction process of new adjacent frame finally the system us a novel postprocessing technique to refine the position of the contour we tested the system on different speech sequence each containing about image visual inspection of the detected contour by the speech expert show that the result are very promising and this system can be effectively employed in speech and swallowing research 
most of the research on face recognition address the match problem and it assumes a closed universe where there is no need for a reject false positive option the surveillance problem is addressed indirectly if at all through the match problem where the size of the gallery rather than that of the probe set is very large this paper address the proper surveillance problem where the size of the probe unknown image set v gallery known image set is v frontal image we developed robust face id verification classification and retrieval scheme based on hybrid classifier and showed their feasibility using the feret face database the hybrid classifier architecture consists of an ensemble of connectionist network radial basis function rbf and inductive decision tree dt experimental result prove the feasibility of our approach and yield accuracy using the probe and gallery set specified above 
this work considers the problem of discovering areasof convergence of line like shape in an image themotivating application is to use the convergence of theblood vessel network to automatically locate the opticnerve in an ocular fundus image a fuzzy segmentmodel is proposed based on a conjecture that line likeshapes only contribute to a perception of convergencein their near neighborhood using this model a votingtypemethod is described to compute a convergence image which can be 
this paper describes a representation for people and animal called a body plan which is adapted to segmentation and to recognition in complex environment the representation is an organized collection of grouping hint obtained from a combination of constraint on color and texture and constraint on geometric property such a the structure of individual part and the relationship between part body plan can be learned from image data using established statistical learning technique the approach is illustrated with two example of program that successfully use body plan for recognition one example involves determining whether a picture contains a scantily clad human using a body plan built by hand the other involves determining whether a picture contains a horse using a body plan learned from image data in both case the system demonstrates excellent performance on large uncontrolled test set and very large and diverse control set 
a new region based approach to nonrigid motion tracking is described shape is defined in term of a deformable triangular mesh that capture object shape plus a color texture map that capture object appearance photometric variation are also modeled nonrigid shape registration and motion tracking are achieved by posing the problem a an energy based robust minimization procedure the approach provides robustness to occlusion wrinkle shadow and specular highlight the formulation is tailored to rake advantage of texture mapping hardware available in many workstation pc and game console this enables nonrigid tracking at speed approaching video rate 
the efficiency of pattern recognition is particularly crucial in two scenario whenever there are a large number of class to discriminate and whenever recognition must be performed a large number of time we propose a single technique namely pattern rejection that greatly enhances efficiency in both case a rejector is a generalization of a classifier that quickly eliminates a large fraction of the candidate class or input this allows a recognition algorithm to dedicate it effort to a much smaller number of possibility importantly a collection of rejectors may be combined to form a composite rejector which is shown to be far more effective than any of it individual component a simple algorithm is proposed for the construction of each of the component rejectors it generality is established through close relationship with the karhunen lo ve expansion and fisher s discriminant analysis composite rejectors were constructed for two representative application namely appearance matching based object recognition and local feature detection the result demonstrate substantial efficiency improvement over existing approach most notably fisher s discriminant analysis 
this paper describes an interactive sensor planning system that can be used to select viewpoint subject to camera visibility field of view and task constraint application area for this method include surveillance planning safety monitoring architectural site design planning and automated site modeling given a description of the sensor s characteristic the object in the d scene and the target to be viewed our algorithm compute the set of admissible view point that satisfy the constraint the system first build topologically correct solid model of the scene from a variety of data source viewing target are then selected and visibility volume and field of view cone are computed and intersected to create viewing volume where camera can be placed the user can interactively manipulate the scene and select multiple target feature to be viewed by a camera the user can also select candidate viewpoint within this volume to synthesize view and verify the correctness of the planning system we present experimental result for the planning system on an actual complex city model 
the vast majority of corner and edge detector measure image intensity gradient in order to estimate the position and strength of feature however many of the most popular intensity gradient estimator are inherently and significantly anisotropic in spite of this few algorithm take the anisotropy into account and so the set of feature uncovered is typically sensitive to rotation of the image compromising recognition matching e g stereo and tracking we introduce an effective technique for removing unwanted anisotropy from analytical gradient estimate by measuring local intensity gradient in four direction rather than the more traditional two in experiment using real image data our algorithm reduces the gradient anisotropy associated with conventional analytical gradient estimate by up to yeilding more consistent feature topology 
many classical image processing task can be realized a evaluation of a boolean function over subset of an image for instance the simplicity test used in d thinning requires examining the neighbor of each voxel and computing a single boolean function of these input in this article we show how binary decision diagram can be used to produce automatically very efficient and compact code for such function the total number of operation performed by a generated function is at most one test and one branching for each input value e g in the case of d thinning test and branching at each stage the function is guaranteed to examine only the pertinent input data i e the value which affect the result a an example we consider the d simplicity test in digital topology and thinning process we produce function much faster than our previously optimized implementation and than any other implementation we know of in the case of d simplicity test on average at each voxel only neighboring voxel value are examined 
this paper present a new technique for modelling object class such a face and matching the model to novel image from the object class the technique can be used for a variety of image analysis application including face recognition object verification and facial expression analysis the model called a hierarchical morphable model is learned from example image partioned into component and their correspondence this is an extension to the work on morphable model described in previous paper hierarchical morphable model are shown to find good match to novel face image and are also robust to partial occlusion 
conventional video camera have limited field of view that make them restrictive in a variety of vision application there are several way to enhance the field of view of an imaging system however the entire imaging system must have a single effective viewpoint to enable the generation of pure perspective image from a sensed image a new camera with a hemispherical field of view is presented two such camera can be placed back to back without violating the single viewpoint constraint to arrive at a truly omnidirectional sensor result are presented on the software generation of pure perspective image from an omnidirectional image given any user selected viewing direction and magnification the paper concludes with a discussion on the spatial resolution of the proposed camera 
this paper focus on the estimation of the intrinsiccamera parameter and the trajectory of the camerafrom an image sequence intrinsic camera calibrationand pose estimation are the prerequisite formany application involving navigation task scenereconstruction and merging of virtual and real environment proposed and evaluated is a technical solutionto decrease the sensitivity of self calibration byplacing easily identifiable target of known shape in theenvironment the relative 
existing method for grouping edge on the basis of localsmoothness measure fail to compute complete contour in natural image it appears that a stronger global constraint is required motivatedby growing evidence that the human visual system exploit contour closurefor the purpose of perceptual grouping we presentan algorithm for computing highly closed bounding contour from image unlike previous algorithm no restriction are placedon the 
remote reality is an approach to providing an immersive environment via omni directional imaging the system can use a live video feed from a remote location or can use recorded data and be remote in both space and time while le interactive than traditional vr remote reality ha an important advantage there is little to no need for model building in addition the object the texture and the motion are not just realistic they are remote view of reality 
when a symmetric object in d is projected to an image the symmetry property are lost except for specific relative viewpoint for sufficiently complex object however it is still possible to infer symmetry in d from a single image of an uncalibrated camera in this paper we give a general computational procedure for computing d structure and finding image symmetry constraint from single view projection of symmetric d object for uncalibrated camera these constraint take the form of polynomial in bracket determinant and by using projectively invariant shape constraint relating d and image structure the symmetry constraint can be derived easily by considering the effect of the corresponding symmetry transformation group in d the constraint can also be given a useful geometric interpretation in term of projective incidence using the grassmann cayley algebra formalism we demonstrate that in specific situation geometric intuition and the use of gc algebra is a very simple and effective tool for finding image symmetry constraint 
search is not inherent in the correspondence problem we propose a representation of image called intrinsic curve that combine the idea of associative storage of image with connectedness of the representation intrinsic curve are the path that a set of local image descriptor trace a an image scanline is traversed from left to right curve become surface when full image are considered instead of scanlines because only the path in the space of descriptor is used for matching intrinsic curve lose track of space and are invariant with respect to disparity under ideal circumstance establishing stereo correspondence then becomes a trivial lookup problem we also show how to use intrinsic curve to match real image in the presence of noise brightness bias contrast fluctuation and moderate geometric distortion and we show how intrinsic curve can be used to deal with image ambiguity and occlusion we carry out experiment on single scanline matching to prove the feasibility of the approach and illustrate it main feature 
in this paper we propose the use of mirror and a single camera for computational stereo when compared to conventional stereo system that use two camera our method ha a number of significant advantage such a wide field of view single viewpoint projection identical camera parameter and ease of calibration we propose four stereo system that use a single camera pointed towards planar ellipsoidal hyperboloidal and paraboloidal mirror in each case we present a derivation of the epipolar constraint next we attempt to understand what can be seen by each system and formalize the notion of field of view we conclude with two experiment to obtain d structure in the first we use a pair of planar mirror and in the second a pair of paraboloidal mirror the result of our experiment demonstrate the viability of stereo using mirror 
we propose an algorithm to automatically construct feature detector for arbitrary parametric feature to obtain a high level of robustness we advocate the use of realistic multi parameter feature model and incorporate optical and sensing effect each feature is represented a a densely sampled parametric manifold in a low dimensional subspace of a hilbert space during detection the brightness distribution around each image pixel is projected into the subspace if the projection lie sufficiently close to the feature manifold the feature is detected and the location of the closest manifold point yield the feature parameter the concept of parameter reduction by normalization dimension reduction pattern rejection and heuristic search are all employed to achieve the required efficiency by applying the algorithm to appropriate parametric feature model detector have been constructed for five feature namely step edge roof edge line corner and circular disc detailed experiment are reported on the robustness of detection and the accuracy of parameter estimation 
this paper is concerned with acquiring panoramic focused image using a small field of view video camera when scene point are distributed over a range of distance from the sensor obtaining a focused composite image involves focus computation and mechanically changing some sensor parameter translation of sensor plane panning of camera etc which can be time intensive in this paper we present method to optimize the image acquisition strategy in order to reduce redundancy we show that panning a camera about a point f focal length in front of the camera eliminates redundancy the non frontal imaging camera nicam with tilted sensor plane ha been previously introduced a a sensor that can acquire focused panoramic image in this paper we also describe strategy for optimal selection of panning angle increment and sensor plane tilt for nicam experimental result are presented for panoramic image acquisition using a regular camera a well a using nicam 
an approach to normalization is presented for both the affine and the projective case the approach is based on group factorization a well a on optimizing parameter invariant integral in order to overcome the difficult problem of parameterization related work ha been carried out by and by for affine transformation and by for projective transformation to avoid some drawback inherent to projective transformation it is suitable to integrate point information or explore thick curve 
this paper present a new operater for corner detection this operator us a variant of the morphological closing operator which we have called asymmetrical closing it consists of the successive application of different morphological transformation using different structuring element each of these structuring element used to probe the image under study is tuned to affect corner of different orientation and brightness we found that this kind of approach based on brightness comparison lead to better quality result than others and is achieved at a lower computational cost 
we describe a flexible model for representing image of object of a certain class known a priori such a face and introduce a new algorithm for matching it to a novel image and thereby performing image analysis we call this model a multidimensional morphable model or just a morphable model the morphable model is learned from example image calledprototypes of object of a class in this paper we introduce an effective stochastic gradient descent algorithm that automatically match a model to a novel image by finding the parameter that minimize the error between the image generated by the model and the novelimage two example demonstrate the robustness and the broad range of applicability of the matching algorithm and the underlying morphable model our approach can provide novel solution to several vision task including the computation of image correspondence object verification image synthesis and image compression 
we present a new function that operates on fundamental matrix across a sequence of view the operation we call threading connects two consecutive fundamental matrix using the trifocal tensor a the connecting thread the threading operation guarantee that consecutive camera matrix are consistent with a unique d model without ever recovering a d model application include recovery of camera ego motion from a sequence of view image stabilization plane stabilization across a sequence and multiview imagebased rendering 
matching image based on a hausdorff measure ha become popular for computer vision application however no probabilistic model ha been used in these application this limit the formal treatment of several issue such a feature uncertainty and prior knowledge in this paper we develop a probabilistic formulation of image matching in term of maximum likelihood estimation that generalizes a version of hausdorff matching this formulation yield several benefit with respect to previous hausdorff matching formulation in addition we show that the optimal model position in a discretized pose space can be located efficiently in this formation and we apply these technique to a mobile robot self localization problem 
in face recognition literature holistic template matching system and geometrical local feature based system have been pursued in the holistic approach pca principal component analysis and lda linear discriminant analysis are popular one more recently the combination of pca and lda ha been proposed a a superior alternative over pure pca and lda in this paper we illustrate the rationale behind these method and the pro and con of applying them to pattern classification task a theoretical performance analysis of lda suggests applying lda over the principal component from the original signal space or the subspace the improved performance of this combined approach is demonstrated through experiment conducted on both simulated data and real data 
the silhouette of a smooth d object observed by a moving camera change over time past work ha shown how surface geometry can be recovered using the deformation of the silhouette when the camera motion is known this paper address the problem of estimating both the full euclidean surface structure and the camera motion from a dense set of silhouette captured under orthographic or scaled orthographic projection the approach relies on a viewpoint invariant representation of curve swept by viewpoint dependent feature such a bitangents inflection and contour point with parallel tangent feature point which form stereo frontier point between non consecutive image are matched using this representation the camera s angular velocity is computed from constraint derived from this correspondence along with the image velocity of these feature from the angular velocity the epipolar geometry is ascertained and infinitesimal motion frontier point can be detected in turn the motion of these frontier point constrains the translation component of camera motion finally the surface is reconstructed using established technique once the camera motion ha been estimated 
traditionally corner are found along step edge in this paper we present an alternative approach corner along ridge trough and local minimum point these feature seem to be more reliable for tracking a new approach for sub pixel localization of these corner is suggested using a local approximation of the image surface 
we have designed and implemented a real time binocular tracking system which us two independent cue commonly found in the primary function of biological visual system to robustly track moving target in complex environment without a priori knowledge of the target shape or texture a fast optical flow segmentation algorithm quickly locates independently moving object for target acquisition and provides a reliable velocity estimate for smooth tracking in parallel target position is generated from the output of a zero disparity filter where a phase based disparity estimation technique allows dynamic control of the camera vergence to adapt the horopter geometry to the target location the system take advantage of the optical property of our custom designed foveated wide angle lens which exhibit a wide field of view along with a high resolution fovea method to cope with the distortion introduced by the space variant resolution and a robust real time implementation on a high performance active vision head are presented 
the basic limitation of the current appearance based matching method using eigenimages are non robust estimation of coefficient and inability to cope with problem related to occlusion and segmentation in this paper we present a new approach which successfully solves these problem the major novelty of our approach lie in the way how the coefficient of the eigenimages are determined instead of computing the coefficient by a projection of the data onto the eigenimages we extract them by a hypothesize and test paradigm using subset of image point competing hypothesis are then subject to a selection procedure based on the minimum description length principle the approach enables u not only to reject outlier and to deal with occlusion but also to simultaneously use multiple class of eigenimages 
abstract one of the main problem to obtain a euclidean d reconstructionfrom multiple view is the calibration of the camera explicitcalibration is not always practical and ha to be repeated regularly sometimesit is even impossible i e for picture taken by an unknown cameraof an unknown scene the second possibility is to do auto calibration 
in this paper we study the statistical theory of shape for ordered finite point congurations or otherwise stated the uncertainty of geometric invariant such study have been made for affine invariant in e g where in the former case a bound on error are used instead of error described by density function and in the latter case a first order approximation give an ellipsis a uncertainty region here a general approach for defining shape and finding it density expressed 
we present virtualized reality a technique to create virtual world out of dynamic event using densely distributed stereo view the intensity image and depth map for each camera view at each time instant are combined to form a visible surface model immersive interaction with the virtualized event is possible using a dense collection of such model additionally acomplete surface model of each instant can be built by merging the depth map from different camera into a common volumetric space the corresponding model is compatible with traditional virtual model and can be interacted with immersively using standard tool because both vsms and csms are fully three dimensional virtualized model can also be combined and modi ed to build larger more complex environment an important capability for many non trivial application we present result from d dome our facility to create virtualized model 
a novel feature detector the constrained phase congruency transform cpct is introduced it simultaneously detects interest point a well a their scale in various orientation the cpct is especially important in registration application the local transformation between interest point can be determined based on their orientational scale the cpct detects the feature in mach band and in sinusoidal wave this cannot be done simply by looking for local maximum in intensity gradient nor by looking for local energy maximum i conjecture that constraining the general phase congruency is sufficient for feature detection the correct detection of feature location and of their scale is demonstrated the robustness of the cpct is achieved by constraining the local phase only four easy to detect phase are used in the computation they correspond to symmetry and anti symmetry in their neighborhood the scale at any location and orientation is determined by the scale of the channel that conforms to the constraint and maximizes energy 
we propose a new machine learning paradigm called graph transformer network that extends the applicability of gradient based learning algorithm to system composed of module that take graph a input and produce graph a output training is performed by computing gradient of a global objective function with respect to all the parameter in the system using a kind of back propagation procedure a complete check reading system based on these concept is described the system us convolutional neural network character recognizers combined with global training technique to provide record accuracy on business and personal check it is presently deployed commercially and read million of check per month 
this paper investigates the problem of computing the fundamental matrix for a class of active stereo vision system namely with common elevation platform the fundamental matrix is derived for such a system and a number of method are proposed to simplify it computation experimental result validate the feasibility of the different method these method are then used in a real application to validate the correctness of the fundamental matrix form for an active stereo system we demonstrate that typical variation in camera intrinsic parameter do not much affect the epipolar geometry in the image this motivates u to calibrate the camera intrinsic parameter approximately and then to use the calibration result to compute the epipolar geometry directly in real time 
we derive and discus a set of parametric equation which when given a convex d feature domain k will generate affine invariant with the property that the invariant value are uniformly distributed in the region once the shape of the feature domain k is determined and fixed it is straightforward to compute the value of the parameter and thus the proposed scheme can be tuned to a specific feature domain the feature of all recognizable object model are assumed to be three dimensional point and uniformly distributed over k the scheme lead to improved discrimination power improved computational load and storage load balancing and can also be used to determine and identify bias in the database of recognizable model over represented construct of object point obvious enhancement produce rigid transformation and similarity transformation invariant with the same good distribution property making this approach generally applicable 
this paper present an approach to the recognition of articulated d object in monocular video image a hierarchical object representation model object a a composition of rigid component which are explicitly connected by specific kinematic constraint e g rotational and or translational joint the recognition task follows this tree like structure by first estimating the d pose of the static component root and afterwards determining the relative d pose of the remaining component recursively this method limit the search space for the actual correspondence between image and model feature and cope with the problem of self occlusion experiment in the context of autonomous mobile robot show the practicability of this approach 
this paper present a new approach for the classification and retrieval of three dimensional image and model from database a set of retrieval algorithm is introduced these algorithm are content based meaning that the input is not made out of keywords but of three dimensional model tensor of inertia distribution of normal and distribution of cord are used to describe each model the database can be searched by scale shape or color or any combination of these parameter a user friendly interface make the retrieval operation simple and intuitive and allows to edit reference model according to the specification of the user experimental result using a database of more than range image and vrml model are presented 
we describe an estimation technique which given a measurement of the depth of a target from a wide field of view wfov stereo camera pair produce a minimax risk fixed size confidence interval estimate for the target depth this work constitutes the first application to the computer vision domain of optimal fixed size confidence interval decision theory the approach is evaluated in term of theoretical capture probability and empirical capture frequency during actual experiment with a target on an optical bench the method is compared to several other procedure including the kalman filter the minimax approach is found to dominate all the other method in performance in particular for the minimax approach a very close agreement is achieved between theoretical capture probability and empirical capture frequency this allows performance to be accurately predicted greatly facilitating the system design and delineating the task that may be performed with a given system 
we present a new algorithm for computing the heading from multiple frame which improves on previous approach it exploit our discovery and analysis of a new structure from motion ambiguity allowing for this ambiguity also make two frame reconstruction more robust we show experimentally that the error landscape for planar scene ha few significant local minimum 
the distribution of object color can be effectively utilized for recognition and indexing difficulty arise in the recognition of object color distribution when there are variation in illumination color change in object pose with respect to illumination direction and specular reflection however most of the recent approach to color based recognition focus mainly on illumination color invariance we propose an approach that identifies object color distribution influenced by illumination pose illumination color and specularity we suggest the use of chromaticity distribution to achieve illumination pose invariance to characterize change in chromaticity distribution due to illumination color a set of chromaticity histogram of each object is generated for a range of lighting color based on linear model of illumination and reflectance and the histogram are represented using a small number of eigen basis vector constructed from principal component analysis since specular reflection may alter the chromaticity distribution of test object a model based specularity detection rejection algorithm called chromaticity differencing is developed to reduce these effect 
abstract the appearance of an object depends on both the viewpoint from which it is observed and the lightsources by which it is illuminated if the appearance of two object is never identical for any pose or lightingconditions then in theory the object can always be distinguished or recognized the question arises whatis the set of image of an object under all lighting condition and pose in this paper we consider only the set ofimages of an object under variable illumination 
we present a novel geometric approach for solving the stereo problem for an arbitrary number of image greater than or equal to it is based upon the definition of a variational principle that must be satisfied by the surface of the object in the scene and their image the euler lagrange equation which are deduced from the variational principle provide a set of pde s which are used to deform an initial set of surface which then move towards the object to be detected the level set 
for many practical application it is important to relax the self calibration condition to allow for changing internal camera parameter e g zooming focusing classical technique failed for such condition we present the available constraint that allow u to right a projective calibration to a euclidean one meanwhile we found that the estimation of the internal parameter were rather inaccurate we discus theoretically this difficulty and above all the resulting effect on the d reconstruction in fact we show that the uncertainty on the focal length estimation lead to a euclidean calibration up to a quasi anisotropic homothety whereas the error on the principal point can often be interpreted a a translation hopefully the calibration we come up with is quite acceptable for reconstruction of model 
the extraction of curvilinear structure is an important low level operation in computer vision most existing operator use a simple model for the line that is to be extracted i e they do not take into account the surroundings of a line therefore they will estimate a wrong line position whenever a line with different lateral contrast is extracted in contrast the algorithm proposed in this paper us an explicit model for line and their surroundings by analyzing the scale space behavior of a model line profile it is shown how the bias that is induced by asymmetrical line can be removed thus the algorithm is able to extract an unbiased line position and width both with sub pixel accuracy 
this contribution describes an automatic d surface modeling system that extract dense metric d surface from an uncalibrated video sequence a static d scene is observed from multiple viewpoint by freely moving a video camera around the object no restriction on camera movement and internal camera parameter like zoom are imposed a the camera pose and intrinsic parameter are calibrated from the sequence dense surface reconstruction are obtained by first treating consecutive image of the sequence a stereoscopic pair and computing dense disparity map for all image pair all viewpoint are then linked by controlled correspondence linking for each image pixel the correspondence linking algorithm allows for accurate depth estimation a well a image texture fusion from all viewpoint simultaneously by keeping track of surface visibility and measurement uncertainty it can cope with occlusion and measurement outlier the correspondence linking is applied to increase the robustness and geometrical resolution of surface depth a well a to remove highlight and specular reflection and to create super resolution texture map for increased realism the major impact of this work is the ability to automatically generate geometrically correct and visually pleasing d surface model from image sequence alone which allows the economic model generation for a wide range of application the resulting textured d surface model are highly realistic vrml representation of the scene 
in stereo algorithm with more than two camera the improvement of accuracy is often reported since they are robust against noise however another important aspect of the polynocular stereo that is the ability of occlusion detection ha been paid le attention we intensively analyzed the occlusion in the camera matrix stereo sea and developed a simple but effective method to detect the presence of occlusion and to eliminate it effect in the correspondence search by considering several statistic on the occlusion and the accuracy in the sea we derived a few base mask which represent occlusion pattern and are effective for the detection of occlusion several experiment using typical indoor scene showed quite good performance to obtain dense and accurate depth map even at the occluding boundary of object 
in this paper we propose fully d active surface model for image segmentation our model are capable of fitting a diverse range of region shape they have low sensitivity to initial shape and position we design self inflation deflation force which cooperate naturally with gradient force they permit the active surface to travel a long distance without the aid of any external force they are easily controlled in both their direction and magnitude the model produce accurate segmentation when tested with synthetic and real image they manifest robustness to image noise and imperfect image data importantly they are capable of converging to the correct boundary even if the initial estimate is not close 
we present a technique for camera calibration and euclidean reconstruction from multiple image of the same scene unlike standard tsai s camera calibration from a known scene we exploited controlled known motion of the camera to obtain it calibration and euclidean reconstruction without any knowledge about the scene we consider three linearly independent translation of an uncalibrated camera mounted on a robot arm that provides u with four view of the scene the translation of the robot arm are measured in a robot coordinate system this special but still realistic arrangement allowed u to find a linear algorithm for recovering all intrinsic camera calibration parameter the rotation of the camera with respect to the robot coordinate system and proper scaling factor for all point allowing their euclidean reconstruction the experiment showed that an efficient and robust algorithm wa obtained by exploiting total least square in combination with careful normalization of image coordinate 
automated scene recognition in dynamic environment involvesnot only object classification or recognition but also a furtherstep consisting in finding what is going on in this environment that isto say what the object are doing and what their purpose are 
a novel method for representing d object that unifies viewer and model centered object representation is presented a unified d frequency domain representation called volumetric iconic spectral signature v i encapsulates both the spatial structure of the object and a continuum of it view in the same data structure the frequency domain image of an object viewed from any direction can be directly extracted employing an extension of the projection slice theorem where each fourier transformed view is a planar slice of the volumetric frequency representation the v i representation can be employed for pose invariant recognition of complex object such a face the recognition and pose estimation is based on an efficient matching algorithm in a four dimensional fourier space experimental example of pose estimation and recognition of face are also presented 
stereo reconstruction algorithm often fail to properly deal with complex surface because there is not enough image information to overcome this problem we propose to guide the reconstruction process using a priori information about the differential geometry of the object surface we use both linear structure such a crest line or scalar field such a curvature value to generate a reconstruction of the surface which is consistent with the differential property this method improves the accuracy of the reconstruction around the discontinuity and increase the compactness of the surface representation 
the kalman filter is a very efficient optimal filter however it ha the precondition that the noise of the process and of the measurement are gaussian the author introduce the general distribution filter which is an optimal filter that can be used even where the distribution are not gaussian an efficient practical implementation of the filter is possible where the distribution are discrete and compact or can be approximated a such 
a number of vision based biometric technique have beenproposed in the past for personal identification we present a novel onebased on visual capturing of signature this paper describes a systembased on correlation and recursive prediction method that can trackthe tip of the pen in real time with sufficient spatio temporal resolutionand accuracy to enable signature verification several example and theperformance of the system are shown introduction and motivationa number of 
present a new approach to segment vessel from d angiography of the brain the author approach is based on a vessel model and us a multiscale analysis in order to extract the vessel network surrounding an aneurysm the author model allows them to choose a criterion based on the eigenvalue of the hessian matrix for selecting a subset of interesting point near the vessel center it also allows them to choose a good parameter for a normalization of the single scale response the response at one scale is obtained by integrating along a circle the first derivative of the intensity in the radial direction once the multiscale response is obtained the author create a smoothed skeleton of the vessel combined with a mip or a volume rendering to enhance their visualization the method ha been tested on a large variety of d image of the brain with excellent result vessel of various size and contrast are detected with a remarkable robustness and most junction are preserved 
this paper present an approach to measuring fluid flow from image sequence the approach center around a motion recovery algorithm that is based on principle from fluid mechanic the algorithm is constrained so that recovered flow observe conservation of mass a well a physically motivated boundary condition empirical result are presented from application of the algorithm to fluid flow captured via transmittance imagery i e radiograph in these experiment fluid seeded with tracer were driven through simple physical system the significance of this work is twofold first from a theoretical point of view it is shown how information derived from the physical behavior of fluid can be used to motivate a flow recovery algorithm second from an application point of view the developed algorithm can be used to augment the tool that are available for the measurement of fluid dynamic other imaged flow that observe compatible constraint might benefit in a similar fashion 
digital video is rapidly becoming important for education entertainment and a host of multimedia application with the size of the video collection growing to thousand of hour technology is needed to effectively browse seg ments in a short time without losing the content of the video we propose a method to extract the significant audio and video information and create a skim video which represents a very short synopsis of the original the goal of this work is to show the utility of integrating lan guage and image understanding technique for video skimming by extraction of significant information such a specific object audio keywords and relevant video struc ture the resulting skim video is much shorter where com paction is a high a and yet retains the essential content of the original segment 
this paper present a system for automatic extraction and tracking of d contour of the tongue surface from digital ultrasound image sequence the input to the system is provided by a head and transducer support system hat which is developed for use in ultrasound imaging of the tongue movement we developed a novel active contour snake model that us several temporally adjacent image during the extraction of the tongue surface contour for an image frame the user supply an initial contour model for a single image frame in the whole sequence using optical flow and multi resolution method this initial contour is then used to find the candidate contour point in the temporally immediate adjacent image subsequently the new snake mechanism is applied to estimate optimal contour for each image frame using these candidate point in turn the extracted contour are used a model for the extraction process of new adjacent frame finally the system us a novel postprocessing technique to refine the position of the contour we tested the system on different speech sequence each containing about image visual inspection of the detected contour by the speech expert show that the result are very promising and this system can be effectively employed in speech and swallowing research 
a novel local scale controlled piecewise linear diffusion for selective smoothing and edge detection is presented the diffusion stop at the place and time determined by the minimum reliable local scale and a spatial variant anisotropic local noise estimate it show anisotropic nonlinear diffusion equation using diffusion coefficient tensor that continuously depend on the gradient is not necessary to achieve sharp distorted stable edge detection across many scale the new diffusion is anisotropic and asymmetric only at place it need to be i e at significant edge it not only doe not diffuse across significant edge but also enhances edge it advance geometry driven diffusion because it is a piecewise linear model rather than a full nonlinear model thus it is simple to implement and analyze and avoids the difficulty and problem associated with nonlinear diffusion it advance local scale control by introducing spatial variant anisotropic local noise estimation and local stopping of diffusion the original local scale control wa based on the unrealistic assumption of uniformly distributed noise independent of the image signal the local noise estimate significantly improves local scale control 
this paper demonstrates the existence of a new approximate intrinsic ambiguity in euclidean structure from motion sfm which occurs a generically a the ba relief ambiguity but unlike it strengthens for scene with more depth variation the ambiguity doe not occur in projective sfm but the reason for this make projective reconstruction more likely to have large error our analysis give a semiquantitative characterization of the least square error surface over a domain complementary to that analyzed by jepson heeger and maybank a part of our analysis we show that the least square error for infinitesimal motion the optical flow error give a good approximation to the least square error for moderate finite motion we propose that many high error local minimum occur for epipoles in or near the image we also establish the existence of a new local minimum in minimizing over the rotation given the translation direction 
the same scene viewed under two different illuminant inducestwo different colour image if the two illuminant are the samecolour but are placed at different position then corresponding rgb pixelsare related by simple scale factor in contrast if the lighting geometryis held fixed but the colour of the light change then it is the individualcolour channel e g all the red pixel value or all the green pixel thatare a scaling apart it is well known that the image dependency 
we describe a hierarchical appearance based method for learning recognizing and predicting arbitrary spatiotemporal sequence of image the method which implement a robust hierarchical form of the kalman filter derived from the minimum description length mdl principle includes a a special case several well known object encoding technique including eigenspace method for static recognition successive level of the hierarchical filter implement dynamic model operating over successively larger spatial and temporal scale each hierarchical level predicts the recognition state at a lower level and modifies it own recognition state using the residual error between the prediction and the actual lower level state simultaneously on a longer time scale the filter learns an internal model of input dynamic by adapting it generative and state transition matrix at each level to minimize prediction error the resulting prediction learning scheme thereby implement an on line form of the well known expectation maximization em algorithm from statistic we present experimental result demonstrating the method s efficacy in mediating robust spatiotemporal recognition in a variety of scenario containing varying degree of occlusion and clutter 
previous research ha shown that aggregated predictor improve the performance of non parametric function approximation technique this paper present the result of applying aggregated predictor to a computer vision problem and show that the method of bagging significantly improves performance in fact the result are better than those previously reported on other domain this paper explains this performance in term of the variance and bias 
this paper summarizes a novel logic based approach to grouping and perceptual organization presented more thoroughly in cite feldman ci and present novel efficient method for computing interpretation in this framework grouping interpretation are first defined a logical structure built out of atomic premise regularity that are derived from consideration of non accidentalness these interpretation can then be partially ordered by their degree of regularity or constraint measured numerically by their it codimension the genericity constraint the principle that interpretation should minimize coincidence in the observed configuration dictate that the preferred interpretation will be the minimum in this partial order i e the interpretation with it maximum codimension the preferred interpretation called the it qualitative parse corresponds neatly to the interpretation intuitively preferred by human observer a a side effect the most salient or most structured part of the scene can be identified a the highest codimension subtree of the qualitative parse an efficient o n method for computing the maximum codimension interpretation is presented along with example 
two new scheme are presented for finding human face in a photograph the first scheme approximates the unknown distribution of the face and the face like manifold using higher order statistic ho an ho based data clustering algorithm is also proposed in the second scheme the face to non face and non face to face transition are learnt using a hidden markov model hmm the hmm parameter are estimated corresponding to a given photograph and the face are located by examining the optimal state sequence of the hmm experimental result are presented on the performance of both the scheme 
we study an application of image registration in the medical domain based on a d hierarchical deformable registration algorithm we have developed a prototype system which automatically aligns a standard atlas to a subject s data to create a customized atlas combined with domain knowledge the registration algorithm can also detect asymmetry and abnormal variation in the subject s data that indicate the existence and location of pathology we have conducted test on mri scan of normal brain mri and i ct scan of brain with pathology with result qualitatively comparable to manual segmentation 
this paper describes a theory and a practical algorithm for the autocalibration of a moving projective camera from view of a planar scene the unknown camera calibration and up to scale the unknown scene geometry and camera motion are recovered from the hypothesis that the camera s internal parameter remain constant during the motion this work extends the various existing method for non planar autocalibration to a practically common situation in which it is not possible to bootstrap the calibration from an intermediate projective reconstruction it also extends hartley s method for the internal calibration of a rotating camera to allow camera translation and to provide d a well a calibration information the basic constraint is that the projection of orthogonal direction vector point at infinity in the plane must be orthogonal in the calibrated camera frame of each image abstractly since the two circular point of the d plane representing it euclidean structure lie on the d absolute conic their projection into each image must lie on the absolute conic s image representing the camera calibration the resulting numerical algorithm optimizes this constraint over all circular point and projective calibration parameter using the inter image homographies a a projective scene representation 
motion of an observer relative to object in a scene provides information about the structure of the scene changing pattern of shading due to motion relative to the light source provide information about surface structure albedo and light source one can stratify this photometric information into affine unitary and metric structure much like the stratification of structure from motion for lambertian surface if either motion or photometry give u more than affine structure the two cue can be combined to yield full metric information edge constraint plus unitary photometry also give u full metric photometry affine structure alone contains much of the quantitative structure information allowing u to judge such thing a the ordinal relationship between the albedo 
it is widely accepted that textureless surface cannot be recovered using passive sensing technique the problem is approached by viewing image formation a a fully three dimensional mapping it is shown that the lens encodes structural information of the scene within a compact three dimensional space behind it after analyzing the information content of this space and by using it property we derive necessary and sufficient condition for the recovery of textureless scene based on these condition a simple procedure for recovering textureless scene is described we experimentally demonstrate the recovery of three textureless surface namely a line a plane and a paraboloid since textureless surface represent the worst case recovery scenario all the result and the recovery procedure are naturally applicable to scene with texture 
we study the d shape similarity between closed surface we represent a curved or polyhedral d object of genus zero using a mesh representation that ha nearly uniform distribution with known connectivity among mesh node we define a shape similarity metric based on the l distance between the local curvature distribution over the mesh representation of the two object for both convex and concave object the shape metric can be computed in time o n where n is the number of tessellation of sphere or the number of mesh which approximate the surface experiment show that our method produce good shape similarity measurement 
we present a new algorithm for efficient matching of d polygonal arc the algorithm is based on the decomposition of the arc into set of corresponding line segment with equal length we derive a closed form solution for the transformation that give the best match between two set of corresponding line segment best in the sense of an l sub norm distance measure which enables the development of efficient arc matching algorithm we apply this algorithm to the problem of finding a match between a short are and a piece of a long arc in real and synthetic image and compare the result with alternative technique in the literature 
we describe a vision system that monitor activity in a site over extended period of time the system us a distributed set of sensor to cover the site and an adaptive tracker detects multiple moving object in the sensor our hypothesis is that motion tracking is sufficient to support a range of computation about site activity we demonstrate using the tracked motion data to calibrate the distributed sensor to construct rough site model to classify detected object to learn common pattern of activity for different object class and to detect unusual activity 
we study the problem of how to detect quot interesting object quot appeared in a given image i our approach is to treat it a a function approximation problem based on an over redundant basis since the basis a library of image template is over redundant there are infinitely many way to decompose i to select the quot best quot decomposition we first propose a global optimization procedure that considers a concave cost function derived from a quot weighted l p norm quot with p this concave cost 
following the theory of statistical estimation the problem of recognizing object imaged in complex real world scene is examined from a parametric perspective a scalar measure of an object s complexity which is invariant under affine transformation and change in image noise level is extracted from the object s fisher information the volume of fisher information is shown to provide an overall statistical measure of the object s recognizability in a particular image while the complexity provides an intrinsically physical measure that characterizes the object in any image an information conserving method is then developed for recognizing an object imaged in a complex scene here the term information conserving mean that the method us al the measured data pertinent to the object s recognizability attains the theoretical lower bound on estimation error for any unbiased estimate and therefore is statistically optimal this method is then successfully applied to finding object imaged in thousand of complex real world scene 
we have been developing a theory of generic d shape based on a reaction diffusion model from mathematical physic the description of a shape is derived from the singularity of a curve evolution process driven by the reaction hyperbolic term the diffusion parabolic term is related to smoothing and shape simplification however the unification of the two is problematic because the slightest amount of diffusion dominates and prevents the formation of generic first order shock the technical issue is whether it is possible to smooth a shape in any sense without destroying the shock we now report a constructive solution to this problem by embedding the smoothing term in a global metric against which a purely hyperbolic evolution is performed from the initial curve this is a new flow for shape that extends the advantage of the original one specific metric are developed which lead to a natural hierarchy of shape feature analogous to the simplification one might perceive when viewing an object from increasing distance we illustrate our new flow with a variety of example 
denote a point in the plane by z z y and a polynomial of nth degree in z by f z spl sigma sub i j spl ge o sub i j spl le n a sub ij x sup i y sup j denote by z f the set of point for which f z z f is the d curve represented by f z in this paper we present a new approach to fitting d curve to data in the plane or d surface to range data which ha significant advantage over presently known method it requires considerably le computation and the resulting curve can be forced to lie close to the data set at prescribed point provided that there is an nth degree polynomial that can reasonably approximate the data linear programming is used to do the fitting the approach can incorporate a variety of distance measure and global geometric constraint 
this paper proposes a new efficient figure from ground method at every stage the data feature are classified to either background or unknown yet class thus emphasizing the background detection task and implying the name of the method the sequential application of such classification stage creates a bootstrap mechanism which improves performance in very cluttered scene this method can be applied to many perceptual grouping cue and an application to smoothness based classification of edge point is given a fast implementation using a kd tree allows to work on large realistic image 
in this paper we propose a new distance measure for an identification problem and describe experiment on fingerprint preselection using eigenfeatures of ridge direction pattern the distance is defined by likelihood ratio of error distribution of feature vector to the whole distribution of feature vector difference in addition we introduce quality index of feature vector and make the distance adaptive to the quality index experiment on fingerprint preselection for ten print card revealed that our proposed distance is much more effective than the mahalanobis distance by combining the eigenfeatures and traditional classification feature false acceptance rate at false rejection rate and one million card sec preselection speed on a standard workstation have been achieved this make it possible to construct high performance fingerprint identification system 
we introduce a novel view based object representation called the saliency map graph smg which capture the salient region of an object view at multiple scale using a wavelet transform this compact representation is highly invariant to translation rotation image and depth and scaling and offer the locality of representation required for occluded object recognition to compare two saliency map graph we introduce two graph similarity algorithm the first computes the topological similarity between two smg s providing a coarse level matching of two graph the second computes the geometrical similarity betweentwo smg s providing a fine level matching of two graph we test and compare these two algorithm on a large database of model object view 
a framework for object segmentation in vector valued image is presented in this paper the first scheme proposed is based on geometric active contour moving towards the object to be detected in the vector valued image object boundary are obtained a geodesic or minimal weighted distance curve in a riemannian space the metric in this space is given by a definition of edge in vector valued image the curve flow corresponding to the proposed active contour hold formal existence uniqueness stability and correctness result the technique is applicable for example to color and texture image the scheme automatically handle change in the deforming curve topology we conclude the paper presenting an extension of the color active contour which lead to a possible image flow for vector valued image segmentation the algorithm is based on moving each one of the image level set according to the proposed color active contour this extension also show the relation of the color geodesic active contour with a number of partial differential equation based image processing algorithm a anisotropic diffusion and shock filter 
a framework for learning parameterized model of optical flow from image sequence is presented a class of motion is represented by a set of orthogonal basis flow field that are computed from a training set using principal component analysis many complex image motion can be represented by a linear combination of a small number of these basis flow the learned motion model may be used for optical flow estimation and for model based recognition for optical flow estimation we describe a robust multi resolution scheme for directly computing the parameter of the learned flow model from image derivative a example we consider learning motion discontinuity non rigid motion of human mouth and articulated human motion 
the objective of this work is to enlarge the class of camera motion for which epipolar geometry and image correspondence can be computed automatically this facilitates matching between quite disparate view wide baseline stereo two extension are made to the current small baseline algorithm first and most importantly a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhood over image pair second algorithm are given for generating putative corner match between image pair using local homographies two novel infrastructure development are also described the automatic generation of local homographies and the combination of possibly conflicting set of match prior to ransac estimation the wide baseline matching algorithm is demonstrated on a number of image pair with varying relative motion and for different scene type all processing is automatic 
in a practical situation the rigid transformation relating different view is recovered with error in such a case the recovered depth of the scene contains error and consequently a distorted version of visual space is computed what then are meaningful shape representation that can be computed from the image the result presented in this paper state that if the rigid transformation between different view is estimated in a way that give rise to a minimum number of negative depth value then at the center of the image affine shape can be correctly computed this result is obtained by exploiting property of the distortion function developed in the distortion model turn out to be a very powerful tool in the analysis and design of d motion and shape estimation algorithm and a a byproduct of our analysis we present a computational explanation of psychophysical result demonstrating human visual space distortion from motion information 
we propose a variant of shape from shading which we call shape from image warping the idea is that the three dimensional shape of an object is estimated by determining how much the image of the object is warped with respect to the image of a known prototype shape we demonstrate that for a class of reflectance function there is a direct relationship between these image warp and geometric warp of the underlying three dimensional shape therefore detecting the image warp relative to a prototype of known shape allows u to reconstruct the shape of the imaged object we derive property of these shape warp and illustrate the result by recovering the shape of face this relationship between image and shape warp help u understand the relationship between image based model of object recognition and approach based on three dimensional object model 
image differencing is used for many application involving change detection although it is usually followed by a thresholding operation to isolate region of change there are few method available in the literature specific to and appropriate for change detection we describe four different method for selecting threshold that work on very different principle either the noise or the signal is modelled and the model cover either the spatial or intensity distribution characteristic the method are a normal model is used for the noise intensity distribution signal intensity are tested by making local intensity distribution comparison in the two image frame i e the difference map is not used the spatial property of the noise are modelled by a poisson distribution and the spatial property of the signal are modelled a a stable number of region or stable euler number 
image based virtual reality is emerging a a major alternative to the more traditional d based vr the main advantage of the image based vr are it photo quality realism and d illusion without any d information unfortunately creating content for image based vr is usually a very tedious process this paper proposes to use a non perspective fisheye lens to capture the spherical panorama with very few image unlike most of camera calibration in computer vision self calibration of the fisheye lens pose new question regarding the parameterization of the distortion and wrap around effect because of it unique projection model and large field of view near degree most of the ambiguity problem in self calibrating a traditional lens can be solved trivially we demonstrate that with four fisheye lens image we can seamlessly register them to create the spherical panorama while self calibrating it distortion and field of view 
a system to retrieve image using a description of the image intensity surface is presented gaussian derivative filter at several scale are applied to the image and low order d differential invariant are computed the resulting multi scale representation is indexed for rapid retrieval query are designed by the user from an example image by selecting appropriate region the invariant vector corresponding to these region are matched with the database counter part both in feature and coordinate space this yield a match score per image image are sorted by the match score and displayed experiment conducted with over image of object embedded in arbitrary background are described it is observed that image similar in appearance and whose viewpoint is within small view variation of the query can be retrieved with an average precision of 
we present a new type of snake in which the dimensionality of the shape is scaled appropriately for the resolution of the image in which the shape are embedded we define shape a an ordered list of control point and compute the principal component of the shape in a prior training set our energy function is based upon the mahalanobis distance of a given shape from the mean shape and on the mahalanobis distance of the image attribute from image attribute value extracted from the training set we show that the derivative of this energy function with respect to the modal weight is reduced a the image resolution is reduced and that the derivative of the energy scale with the variance associated with each mode we exploit this property to determine the subset of the mode which are relevant at a particular level of image resolution thereby reducing the dimensionality of the shape we implement a coarse to fine search procedure in the image and shape domain simultaneously and demonstrate this procedure on the identification of anatomic structure in computed tomography image 
the literature on recursive estimation of structure and motion from monocular image sequence comprises a large number of different model and estimation technique we propose a framework that allows u to derive and compare all model by following the idea of dynamical system reduction the natural dynamic model derived by the rigidity constraint and the perspective projection is first reduced by explicitly decoupling structure depth from motion then implicit decoupling technique are explored which consist of imposing that some function of the unknown parameter is held constant by appropriately choosing such a function not only can we account for all model seen so far in the literature but we can also derive novel one casting all the different model in a common framework allows u to compare their geometric property on common experimental ground 
we consider how tracking in stereo may be enhanced by coupling pair of active contour in different view via affine epipolar geometry and various subset of planar affine transformation a well a by implementing temporal constraint imposed by curve rigidity d curve tracking is achieved using a submanifold model where it is shown how the coupling mechanism can be decomposed to cater for fired and variable epipolar geometry in the case of tracking planar curve the canonical frame model is developed such that the various geometrical constraint needed in different situation may be efficiently selected the result show that coupled active contour add consistency and robustness to tracking in stereo 
we propose a method for segmenting gray value image by segmentation we mean a map from the set of pixel to a small set of level such that each connected component of the set of pixel with the same level form a relatively large and meaningful region the method find a set of level with associated gray value by first finding junction in the image and then seeking a minimum set of threshold value that preserve the junction then it find a segmentation map that map each pixel to the level with the closest gray value to the pixel data within a smoothness constraint for a convex smoothing penalty we show the global optimal solution for an energy function that fit the data can be obtained in a polynomial time by a novel use of the maximum flow algorithm our approach is in contrast to a view in computer vision where segmentation is driven by intensity gradient usually not yielding closed boundary 
in this paper we propose a new approach to recovering epipolar geometry from a pair of uncalibrated image we first detect the feature point by minimizing a proposed cost function we match the feature point discard the outlier and recover the epipolar geometry in one step experiment on real image show that this approach is effective and fast 
in this paper we address the problem of recognizing an object from a novel viewpoint given a single model view of that object a is common in model based recognition object and image are represented a set of feature point we present an efficient algorithm for determining whether two set of image point in the plane could be projection of a common object a three dimensional point set the method relies on the fact that two set of point in the plane are orthographic projection of the same three dimensional point set exactly when they have a common projection onto a line this is a form of the well known epipolar constraint used in stereopsis our algorithm can be used to recognize an object by comparing a stored two dimensional view of the object against an unknown view without requiring the correspondence between point in the view to be known a priori we provide some example illustrating the approach 
we present a method to infer segmented and full volumetric description of object from intensity image we use three weakly calibrated image from closely spaced viewpoint a input deriving full volumetric description requires the development of robust inference rule the inference rule are based on local property of generalized cylinder gc we first detect group in each image based on proximity parallelism and symmetry the group in the three image are matched and their contour are labelled a true and limb edge we use the information about group and the label associated with their contour to recover visible surface and their surface ax to extract the complete volume in term of a gc we need to infer the gc axis it cross section and the scaling function the property of straight and curved axis generalized cylinder are used locally on the visible surface to obtain the gc axis the cross section is recovered if seen in the image else it is inferred using the visible surface and gc property we consider group with true edge limb edge or a combination of both the final description are volumetric and in term of part sometimes when not enough information is present to make volumetric inference the description remain at the surface level we demonstrate result on real image of moderately complex object with texture and shadow 
abstract we describe a face modeling system which estimate complete facial structure and texture from a real time video stream the system begin with a face tracking algorithm which detects and stabilizes live facial im age into a canonical d pose the resulting canonical texture is then processed by a statistical model to l ter imperfection and estimate unknown component such a missing pixel and underlying d structure this statistical model is a soft mixture of eigenfea ture selector which span the d deformation and texture change across a training set of laser scanned face an iterative algorithm is introduced for deter mining the dimensional partitioning of the eigenfea tures to maximize their generalization capability over a cross validation set of data the model s ability to lter and estimate absent facial component are then demonstrated over incomplete d data this ulti mately allows the model to span known and regress un known facial information from stabilized natural video sequence generated by a face tracking algorithm the resulting continuous and dynamic estimation of the model s parameter over a video sequence generates a compact temporal description of the d deformation and texture change of the face 
use of uncalibrated image ha found many application such a image synthesis however it is not easy to specify the desired position of the new image in projective or affine space this paper proposes to recover euclidean structure from uncalibrated image using domain knowledge such a distance and angle the knowledge we have is usually about an object category but not very precise for the particular object being considered the variation fuzziness is modeled a a gaussian variable six type of common knowledge are formulated once we have an euclidean description the task to specify the desired position in euclidean space becomes trivial the proposed technique is then applied to synthesis of new facial image a number of difficulty existing in image synthesis are identified and solved for example we propose to use edge point to deal with occlusion 
most of behavior recognition method proposed so far share the limitation of bottom up analysis and single object assumption the bottom up analysis can be confused by erroneous and missing image feature and the single object assumption prevents u from analyzing image sequence including multiple moving object this paper present a robust behavior recognition method free from these limitation our method is best characterized by top down image feature extraction by selective attention mechanism object discrimination by colored token propagation and integration of multi viewpoint image extensive experiment of human behavior recognition in real world environment demonstrate the soundness and robustness of our method 
abstract an improved technique for d head tracking under varying illumination condition is proposed the head is modeled a a texture mapped cylinder tracking is formulated a an image registration problem in the cylinder s texture map image to solve the registration problem in the presence of lighting variation and head motion the residual error of registration is modeled a a linear combination of texture warping template and orthogonal illumination template fast and stable on line tracking is then achieved via regularized weighted least square minimization of the registration error the regularization term tends to limit potential ambiguity that arise in the warping and illumination template it enables stable tracking over extended sequence tracking doe not require a precise initial fit of the model the system is initialized automatically using a simple d face detector the only assumption is that the target is facing the camera in the first frame of the sequence the warping template are computed at the first frame of the sequence illumination template are precomputed off line over a training set of face image collected under varying lighting condition experiment in tracking are reported 
we propose a framework for extracting structure from stereo which represents the scene a a collection of approximately planar layer each layer consists of an explicit d plane equation a colored image with per pixel opacity a sprite and a per pixel depth offset relative to the plane initial estimate of the layer are recovered using technique taken from parametric motion estimation these initial estimate are then refined using a re synthesis algorithm which take into account both occlusion and mixed pixel reasoning about such effect allows the recovery of depth and color information with high accuracy even in partially occluded region another important benefit of our framework is that the output consists of a collection of approximately planar region a representation which is far more appropriate than a dense depth map for many application such a rendering and video parsing 
in this paper we present a method for d reconstruction of human body with application in cad system for garment design the reconstruction scheme us image information from several arbitrary view and deformable superquadrics a the model of the body part two visual cue are used occluding contour and stereo possibly aided by projected pattern our preliminary experiment show that the reconstruction is more complete than in purely stereo or structured light based method and more precise than the reconstruction from occluding contour only from the reconstructed human body the body measurement can be taken automatically and used in garment design we give an example of draping of virtual garment over the photo realistic d model of the imaged human one can easily envision the use of the described algorithm in the development of custom fit garment retail software over the internet which would include the possibility of trying the garment on in virtual reality 
communication involves more than simply spoken information typical interaction use gesture to accurately and efficiently convey idea that are more easily expressed with action than word a more intuitive interface with machine should involve not only speech recognition but gesture recognition a well one of the most frequently used and expressively powerful gesture is pointing it is far easier and more accurate to point to an object than give a verbal description of it location to produce a more efficient accurate and natural human machine interface we use the perseus architecture to interpret the pointing gesture perseus us a variety of technique to reliably solve this complex visual problem in non engineered world knowledge about the task and environment is used at all stage of processing to best interpret the scene for the current situation once the visual operator are chosen contextual knowledge is used to tune them for maximal performance redundant interpretation of the scene provides robustness to error in interpretation fusion of independent type of information result in increased tolerance when assumption about the environment fail window of attention are used to improve speed and remove distraction from the scene furthermore reuse is a major issue in the design of perseus information about the environment and task is explicitly represented so it can easily be re used in task other than pointing a clean interface to perseus is provided for symbolic higher level system like the rap reactive execution system in this paper we describe perseus in detail and show how it is used to locate object pointed to by people 
almost all work on texture in the computer visionand graphic community ha modeled the texture astangential i e lying in the tangent plane to the surface this is equivalent to thinking of the texture asa pattern painted on the surface three dimensionaltextures where the element may point out of the surface have largely been ignored we study a specialclass of d texture perpendicular texture where wecan model the element a being normal to the surface the perspective 
we introduce in this paper two probabilistic reasoning model ppm and prm which combine the principal component analysis pca technique and the bayes classifier and show their feasibility on the face recognition problem the conditional probability density function for each class is modeled using the within class scatter and the maximum a posteriori map classification rule is implemented in the reduced pca subspace experiment carried out using facial image corresponding to subject with subject having duplicate image from the feret database show that the prm approach compare favorably against the two well known method for face recognition the eigenfaces and fisherfaces 
we propose a computational scheme for uncalibrated reconstruction of scene structureup to a relief transformation from binocular disparity this scheme which wecall regional disparity correction rdc is motivated both by computational considerationsand by psychophysical observation regarding human stereoscopic depth perception we describe an implementation of rdc and demonstrate it performanceexperimentally a an example of application of rdc we show how it can be used toalign 
we firstly present a variational approach such that during image restoration edge detected in the original image are being preserved and then we compare in a second part the mathematical foundation of this method with respect to some of the well known method recently proposed in the literature within the class of pde based algorithm anisotropic diffusion mean curvature motion min max flow technique the performance of our approach is carefully examined and compared to the classical method experimental result on synthetic and real image will illustrate the capability of all the studied approach 
we address the problem of egomotion estimation of a monocular observer moving with arbitrary translation and rotation in an unknown environment using log polar image the method we propose is uniquely based on the spatio temporal image derivative or the normal flow thus we avoid computing the complete optical flow field which is an ill posed problem due to the aperture problem we use a search paradigm based on geometric property of the normal flow field and consider a family of search subspace to estimate the egomotion parameter these algorithm are particularly well suited for the log polar image geometry a we use a selection of special normal flow vector with simple representation in logpolar coordinate this approach highlight the close coupling between algorithmic aspect and the sensor geometry retina physiology often found in nature finally we present and discus a set of experiment for various kind of camera motion which show encouraging result 
in this paper we present a shape recovery technique in d and d with specific application in visualizing and measuring anatomical shape from medical image this algorithm model extremely corrugated structure like the brain is topologically adaptable is robust and run in o n logn time where n is the total number of point in the domain our two stage technique is based on the level set shape recovery scheme introduced in and the fast march ing method in for computing solution to static hamilton jacobi equation 
we present a theory and practical computation for automatically matching a police artist sketch to a set of true photograph we locate facial feature in both the sketch a well a the set of photograph image then the sketch is photometrically standardized to facilitate comparison with a photo and then both the sketch and the photo are geometrically standardized finally for matching eigenanalysis is employed result using real police sketch and arrest photo are presented 
to create a more realistic soccer game derived from tv image we developed an image synthesis system that generates an image sequence from the viewpoint of a player on the field this system is based on the camera calibration theory the system first determines the camera parameter of a tv image by using the intersection point of the white line drawn on the soccer field it then extract player from each image and estimate their position in the world coordinate system finally it applies a running motion to the player in their respective position and generates computer graphic animation from the viewpoint of any player selected by a user the system wa tested over seven sequence of tv image and demonstrated satisfactory result 
system that attempt to recover the spoken word from image sequence usually require complicated model of the mouth and it motion here we describe a new approach based on a fast mathematical morphology transform called the sieve we form statistic of scale measurement in one and two dimension and these are used a a feature vector for standard hidden markov model hmms 
we describe mosaicing for a sequence of image acquired by a camera rotating about it centre the novel contribution are in two area first in the automation and estimation of image registration image are registered under a full degree of freedom homography the registration is automatic and robust and a maximum likelihood estimator is used in panicular the registration is consistent so that there are no accumulated error over a sequence this mean that it is not a problem if the sequence loop back on itself the second novel area is in enhanced resolution a region of the mosaic can be viewed at a resolution higher than any of the original frame it is shown that the degree of resolution enhancement is determined by a measure based on a matrix norm a maximum likelihood solution is given which also take account of the error in the estimated homographies an improved map estimator is also developed result of both mle and map estimation are included for sequence acquired by a camcorder and a ccd camera 
our main contribution in this paper is to describe a new class of the adaptive mesh the mesh us both split and merge operation to adapt itself to the structure of volumetric data point the adaptive behavior is controlled by the variance of the data point position about maximum likelihood quadric patch we show that the density of control point on the mesh is regulated by the curvature of the underlying surface finally we illustrate the effectiveness of the method on both real world and simulated data set 
an ever increasing number of registered trademark ha created greater demand for an automatic trademark retrieval system we present a method for such a system based on the image content using shape feature zernike or pseudo zernike moment of the image are employed a a feature set to retrieve similar shape we take into account visually salient feature that dominantly affect the global shape of the trademark and ignore their minor detail experimental result on a database of trademark image demonstrate that the proposed method retrieves visually similar trademark which agree well with human perception 
most view based vision algorithm are based on strong assumption about the disposition of the object in the image to safely apply those algorithm in real world image sequence we propose that a vision system should be divided into two component the first component contains an approximate world model of the scene a low accuracy coarse description of the object and action in the world approximate world model are constructed and updated by simple vision routine and by the use of action information provided by an external source the second component employ view based algorithm to perform required perceptual task the selection and control of the view based method are determined by the information provided by the approximate world model we demonstrate the approximate world model approach in a project to control camera in a tv studio where the external context is provided by a script 
in this paper we present a car tracking system which provides quantitative and qualitative motion estimate of the tracked car simultaneously from a moving observer first we construct three motion model constant velocity constant acceleration and turning to describe the qualitative motion of a moving car then the model are incorporated into the extended kalman filter to perform quantitative tracking finally we develop an extended interacting multiple model eimm algorithm to manage the switching between model and to output both qualitative and quantitative motion estimate of the tracked car accurate motion modeling and efficient model management result in a high performance tracking system the experimental result on simulated and real data demonstrate that our tracking system is reliable and robust and run in real time the multiple motion representation make the system useful in various autonomous driving task 
providing a machine with the ability to learn and use model of natural interaction is a challenging and largely unaddressed problem a framework is developed enabling both the acquisition of interaction behaviour from the observation of human and the use of the acquired behaviour model to simulate a plausible partner during interaction statistically based interaction behaviour model are acquired automatically from the observation of interacting human interaction with a virtual human is achieved using the model together with a stochastic tracking algorithm experimental result demonstrate the generation and use of the model for a simple human interaction 
in this work we investigate the visual appearance of real world surface and the dependence of appearance on imaging condition we present a brdf bidirectional reflectance distribution function database with reflectance measurement for over different sample each observed with over different combination of viewing and source direction we fit the brdf measurement to two recent model to obtain a brdf parameter database these brdf parameter can be directly used for both image analysis and image synthesis finally we present a btf bidirectional texture function database with image texture from over different sample each observed with over different combination of viewing and source direction each of these unique database ha important implication for a variety of vision algorithm and each is made publicly available 
we present a surface texture and microstructure extraction system to provide added realism in visualization and virtual reality application the system us multiple image d model and camera information in addition to knowledge about man made structure to cope with problem such a perspective distortion data deficiency and corruption caused by shadow and occlusion combined with the ascender site modeling system cite collins iuw and scene rendering algorithm the system is typically useful for urban site model refinement and visualization 
we demonstrate real time face tracking and pose estimation in an unconstrained office environment with an active foveated camera using vision routine previously implemented for an interactive environment we determine the spatial location of a user s head and guide an active camera to obtain foveated image of the face face are analyzed using a set of eigenspaces indexed over both pose and world location closed loop feedback from the estimated facial location is used to guide the camera when a face is present in the foveated view our system can detect the head pose of an unconstrained user in real time a he or she move about an open room 
minimum description length mdl estimation ha proven itself of major importance in a large number of application many of which are in the field of computer vision and pattern recognition a problem is encountered in applying the associated formula however especially those associated with model cost this is because most of these are asymptotic form appropriate only for large sample size j rissanen ha recently derived sharper code length formula valid for much smaller sample size because of the importance of these result it is our intent here to present a tutorial description of them in keeping with this goal we have chosen a simple application whose relative tractability allows it to be explored more deeply than most problem the segmentation of binary string based on a piecewise bernoulli assumption by that we mean that the string are assumed to be divided into substring the bit of which are assumed to have been generated by a single within a substring bernoulli source 
this paper present an interactive modeling system that construct d model from a collection of panoramic image mosaic a panoramic mosaic consists of a set of image taken around the same viewpoint and a transformation matrix associated with each input image our system first recovers the camera pose for each mosaic from known line direction and point and then construct the d model using all available geometrical constraint we partition constraint into soft and hard linear constraint so that the modeling process can be formulated a a linearly constrained least square problem which can be solved efficiently using qr factorization the result of extracting wire frame and texture mapped d model from single and multiple panorama are presented 
this paper investigates the structure of projective translation rigid translation expressed a homographies in projective space a seven parameter representation is proposed which explicitly represents the geometric entity constraining and defining the translation a practical algebraic method for estimating these parameter is developed it provides affine calibration of a stereo rig determines the translation axis and allows projective translation to be composed the practical effectiveness of the calibration is evaluated on synthetic and real image data 
detection of the set of center of maximal disk is a key step toward generation of accurate skeleton on the basis of distance map algorithm using approximate distance metric are abundant and their theory ha been well established however the resulting skeleton may be inaccurate and sensitive to rotation in this paper we study method for detecting maximal disk from distance map based on the exact euclidean metric we first show that no previous algorithm identifies the exact set of discrete maximal disk under euclidean distance metric we then propose new algorithm and show that they produce the exact set of maximal disk the effectiveness of our algorithm is demonstrated with numerous example 
we have addressed the problem of tracking the nonrigid motion of the heart using a sequence of velocity field and a sequence of contour the information from both the contour and the dense velocity field is integrated into a deforming mesh that is placed over the myocardium at one time frame and then tracked over the entire cardiac cycle the deformation is guided by a smoothing filter that provides a compromise between i believing the dense field velocity and the contour data when it is crisp and coherent in a local spatial and temporal sense and ii employing a temporally smooth cyclic model of cardiac motion when contour and velocity data are not trustworthy the method ha been carefully evaluated with simulated data and phantom data experiment with in vivo data have also been conducted 
a novel boundary detection scheme based on edgejow is proposed in this paper this scheme utilizes a predictive coding model to identify the direction of change in color and texture at each image location at a given scale and construct an edge flow vector by iteratively propagating the edge flow the boundary can be detected at image location which encounter two opposite direction offrow in the stable state a user defined image scale is the only significant control parameter that is needed by the algorithm the scheme facilitates integration of color and texture into a single framework for boundary detection 
an approach for learning and estimating temporal flow model from image sequence is proposed the temporal flow model are represented a a set of orthogonal temporal flow base that are learned using principal component analysis of instantaneous flow measurement spatial constraint on the temporal flow are also developed for modeling the motion of region in rigid and coordinated motion the performance of these model is demonstrated on several long image sequence of rigid and articulated body in motion 
we propose a novel method of extracting a moving object region from each frame in a series of image regardless of complex changing background using statistical knowledge about the target in vision system for real world like a human motion tracker a priori knowledge about the target and environment is often limited e g only the approximate size of the target is known and is insufficient for extracting the target motion directly in our approach information about both target object and environment is extracted with a small amount of given knowledge about the target object pixel value color intensity etc distribution for both the target object and background region are adaptively estimated from the input image sequence based on the knowledge then the probability of each pixel being associated with the target object is calculated the target motion can be extracted from the calculated stochastic image we confirmed the stability of this approach through experiment 
the performance of active contour in tracking is highly dependent on the availability of an appropriate model of shape and motion to use a a predictor model can be hand built but it is far more effective and le time consuming to learn them from a training set technique to do this exist both for shape and for shape and motion jointly this paper extends the range of shape and motion model in two significant way the first is to model jointly the random variation in shape arising 
this paper address the general d rigid motion problem where the point correspondence and the motion parameter between two set of d point are to be recovered the existence of missing point in the two set is the most difficult problem we first show a mathematical symmetry in the solution of rotation parameter and point correspondence a closed form solution based on the correlation matrix eigenstructure decomposition is proposed for correspondence recovery with no missing point using a heuristic measure of point pair affinity derived from the eigenstructure a weighted bipartite matching algorithm is developed to determine the correspondence in general case where missing point occur the use of the affinity heuristic also lead to a fast outlier removal algorithm which can be run iteratively to refine the correspondence recovery simulation result and experiment on real image are shown in both ideal and general case 
generalized cylinder gc are a popular representational tool in computer vision in medical imaging the curved axis gc is particularly applicable to a number of elongated physical structure such a vasculature bone and bronchus in many of these instance it is necessary to recover curved axis gc with arbitrary cross section it is also vital that these structure once recovered can be analyzed and visualized with off the shelf algorithm and software package such tool are usually designed to operate on the domain of polynomial or rational surface unfortunately most extant suitably versatile gc representation do not admit rational parameterizations we develop an entirely rational b spline representation for generalized cylinder with curved ax and arbitrary cross section function we demonstrate how our representation can be used a a deformable model by extracting a rational gc from pre segmented spinal data using a discrete dynamic surface fit 
this paper considers a specific problem of visual perception of motion namely the problem of visual detection of independent d motion most of the existing technique for solving this problem rely on restrictive assumption about the environment the observer s motion or both moreover they are based on the computation of a dense optical flow field which amount to solving the ill posed correspondence problem in this work independent motion detection is formulated a a problem of robust parameter estimation applied to the visual input acquired by a rigidly moving observer the proposed method automatically selects a planar surface in the scene and the residual planar parallax normal flow field with respect to the motion of this surface is computed at two successive time instant the two resulting normal flow field are then combined in a linear model the parameter of this model are related to the parameter of self motion ego motion and their robust estimation lead to a segmentation of the scene based on d motion the method avoids a complete solution to the correspondence problem by selectively matching subset of image point and by employing normal flow field experimental result demonstratethe effectiveness of the proposed method in detecting independent motion in scene with large depth variation and unrestrited observer motion 
although powerful image representation have been proposed for content based image retrieval most of the current system are rigid i e they retrieve a fixed set of image a response to a given query and an image feature in this paper our goal is to introduce tool for making image retrieval system more flexible more precisely we use multiple image feature and present in detail a new relevance feedback technique that integrates the positive and negative example provided by the user experimental result on various large database show that the proposed technique is more performant than the standard relevance feedback approach 
a new object tracking algorithm based on affine structure ha been developed and it is shown that it performance is better than that of a kalman filter based correlation tracker the algorithm is fast reliable viewpoint invariant and insensitive to occlusion and or individual corner disappearance or reappearance detailed experimental analysis on a long real image sequence is also presented 
this paper describes a fast and flexible method for extracting text region from a document page containing text graphic and picture such region can be given a an input to an ocr system the user fix two parameter the minimum width w of the text to be detected and the precision needed both expressed a a percentage of the image width according to the implementation need the method work by subdividing the page into overlapping column whose width and inter shift depend on w and and by performing text line extraction on each column separately successively a statistical analysis of the text line element found in each column is performed and they are connected to form complete text line finally related piece of text are merged into block so that a sensible reading order is provided for the ocr system the algorithm is very fast is able to work on low resolution document page and is robust against skew the algorithm a also very flexible no assumption are made on the layout of the document the shape of the text region and the font size and style the main assumption is that the background is uniform and the text approximately horizontal despite the statistical nature of the method a single line of text of a certain font size is generally sufficient to warrant detection experimental result are shown which demonstrate the effectiveness of the method on several different kind of document 
this paper present a general trainable framework for object detection in static image of cluttered scene the detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instance by learning an object class in term of a subset of an overcomplete dictionary of wavelet basis function we derive a compact representation of an object class which is used a an input to a support vector machine classifier this representation overcomes both the problem of in class variability and provides a low false detection rate in unconstrained environment we demonstr ate the capability of the technique in two domain whose inherent information content differs significantly the first system is face detection and the second is the domain of people which in contrast to face vary greatly in color texture and pattern unlike previous approach this system learns from example and doe not rely on any a priori hand crafted model or motion based segmentation the paper also present a motion based extension to enhance the performance of the detection algorithm over video sequence the result presented here suggest that this architecture may well be quite general 
image denoising and segmentation are fundamental problem in the field of image processing and computer vision with numerous application we propose a partial differential equation pde based smoothing and segmentation framework wherein the image data are smoothed via an evolution equation that is controlled by a vector field describing a viscous fluid flow image segmentation in this framework is defined by location in the image where the fluid velocity is a local maximum the nonlinear image smoothing is selectively achieved to preserve edge in the image the novelty of this approach lie in the fact that the selective term is derived from a nonlinearly regularized image gradient field unlike most earlier technique which either used a constant with respect to time selective term or a time varying nonlinearly smoothed scalar valued term implementation result on synthetic and real image are presented to depict the performance of the technique in comparison to method recently reported in literature 
an autonomous vehicle ha been developed for precision application of treatment onoutdoor crop this document detail a new vision algorithm to aid navigation and crop weeddiscrimination being developed for this machine the algorithm track a model of the crop plantingpattern through an image sequence using an extended kalman filter a parallel update schemeis used to provide not only navigation information for the vehicle controller but also estimate ofplant position for the 
in this paper the special case of reconstruction from image sequence taken by camera with skew equal to and aspect ratio equal to ha been treated these type of camera here called camera with euclidean image plane represent rigid projection where neither the principal point nor the focal length is known it will be shown that it is possible to reconstruct an unknown object from image taken by a camera with euclidean image plane up to similarity transformation i e euclidean transformation plus change in the global scale an algorithm using bundle adjustment technique ha been implemented the performance of the algorithm is shown on simulated data 
a multiple instruction multiple data mimd parallel computing platform built upon a network of tm c s c c for real time image processing of a hierarchical foveal machine vision hfmv system is described in this paper the architecture of the system the parallel algorithm development environment and strategy to map task into the computing platform are described the platform support both static and dynamic computing resource allocation the performance of the computing platform is illustrated by example 
the organization of image database can rely upon different aspect of image similarity here we extract silhouette from image of three dimensional object and rely upon curve similarity for image classification our scheme avoids the embedding of image in a vector space instead we propose a curve dissimilarity measure which relies upon a novel curve matching syntactic algorithm and use it to represent the database a a complete graph with node representing the image and dissimilarity value assigning weight to the edge a robust clustering algorithm which is based on a physical ferromagnet model is used to find the hierarchical structure underlying the collection of image we tested our scheme with a database of real image of object some of them very different others rather similar we get a perfect hierarchical classification of these image into class of object belonging to different family 
we use colour mixture model for real time colour based object localisation tracking and segmentation in dynamic scene within such a framework we address the issue of model order selection modelling scene background and model adaptation in time experimental result are given to demonstrate our approach in different scale and lighting condition 
this paper describes an effcient method to calculate from an image of an object configuration of a two fingered robot gripp er that form a cage to contain that object closing the finger on the object from these configuration is guaranteed to reach a given desired grasp this build on the visual grasping theory of blake taylor and cox which describes how to find optimal grasp it extends the result of rimon and blake which show how to construct such cage in two way first a more effcient algorithm for computing the cage is described second a further development deal with occlusion by solving thecaging problem within a restricted image window the new method greatly reduce the complexity of the visual caging problem making it feasible in a real time computer vision system 
we present completely new very powerful solution to two fundamental problem central to computer vision given data set representing c object to be stored in a database and given a new data set for an object determine the object in the database that is most like the object measured we solve this problem through use of pims polynomial interpolated measure which is a new representation integrating implicit polynomial curve and surface explicit polynomial and discrete data set which may be sparse the method provides high accuracy at low computational cost given noisy d data along a curve or d data along a surface decompose the data into patch such that new data taken along affine transformation or euclidean transformation of the curve or surface can be decomposed into correponding patch then recognition of complex or partially occluded object can be done in term of invariantly determined patch we briefly outline a low computational cost image database indexing system based on this representation for object having complex shape geometry 
we describe a local parallel method for computing the stochastic completion field introduced in an earlier paper cite williams the stochastic completion field represents the likelihood that a completion joining two contour fragment pass through any given position and orientation in the image plane it is based upon the assumption that the prior probability distribution of completion shape can be modeled a a random walk in a lattice of discrete position and orientation the local parallel method can be interpreted a a stable finite difference scheme for solving the underlying fokker planck equation identified by mumford cite mumford the resulting algorithm is significantly faster than the previously employed method which relied on convolution with large kernel filter computed by monte carlo simulation the complexity of the new method is o n m while that of the previous algorithm wa o n m for an n x n image with m discrete orientation perhaps most significantly the use of a local method allows u to model the probability distribution of completion shape using stochastic process which are neither homogenous nor isotropic for example it is possible to modulate particle decay rate by a directional function of local image brightness i e anisotropic decay the effect is that illusory contour can be made to respect the local image brightness structure finally we note that the new method is more plausible a a neural model since unlike the previous method it can be computed in a sparse locally connected network and the network dynamic are consistent with psychophysical measurement of the time course of illusory contour formation 
the three best known criterion in two view motion analysis are based respectively on the distance between point and their corresponding epipolar line on the gradient weighted epipolar error and on the distance between point and the reprojections of their reconstructed point the last one ha a better statistical interpretation but is however much slower than the first two in this paper we show that the last two criterion are equivalent when the epipoles are at infinity and differ from each other only a little even when the epipoles are in the image the first two criterion are equivalent only when the epipoles are at infinity and when the observed object ha the same scale in the two image this suggests that the second criterion is sufficient in practice because of it computational efficiency the resultis valid for both calibrated and uncalibrated image 
we describe an approach to detecting locating and normalizing road sign the approach will apply provided i the sign have stereotypical boundary shape i e rectangular or hexagonal of course we allow for these shape to be distorted by projection to unknown viewpoint ii the writingon the sign ha one uniform color and the rest of the sign ha a second uniform color we allow for the color of the illuminant to be unknown we show that the approach work even under significant illuminant color change viewpoint direction shadowing and occlusion this work is part of a project intended to help people who are blind or whose sight is impaired 
we investigate the application of support vector machine svms in computer vision svm is a learning technique developed by v vapnik and his team at t bell lab that can be seen a a new method for training polynomial neural network or radial basis function classifier the decision surface are found by solving a linearly constrained quadratic programming problem this optimization problem is challenging because the quadratic form is completely dense and the memory requirement grow with the square of the number of data point we present a decomposition algorithm that guarantee global optimality and can be used to train svm s over very large data set the main idea behind the decomposition is the iterative solution of sub problem and the evaluation of optimality condition which are used both to generate improved iterative value and also establish the stopping criterion for the algorithm we present experimental result of our implementation of svm and demonstrate the feasibility of our approach on a face detection problem that involves a data set of data point 
abstract cartography and other application of remote sensing have led to an increasedinterest in the semi automatic interpretation of structure in aerial image of urbanand suburban area building delineation and d reconstruction is a good case inpoint although urban and suburban area are particularly challenging because oftheir complexity the degree of regularity in such man made structure also helpsto tackle the problem the paper present the iterated application of the hough 
we study occluding contour artifact in area based stereo matching they are false response of the matching operator to the occlusion boundary and cause the object extend beyond their true boundary in disparity map most of the matching method suffer from these artifact the effect is so strong that it cannot be ignored we show what give rise to the artifact and design a matching criterion that accommodates the presence of occlusion a opposed to method that identify and remove the artifact this approach lead to the problem of measurement contamination studied in statistic we show that such a problem is hard given finite computational resource unless more independent measurement directly related to occluding contour is available what can be achieved is a substantial reduction of the artifact especially for large matching template reduced artifact allow for easier hierarchical matching and for easy fusion of reconstruction from different viewpoint into a coherent whole 
we evaluated six algorithm for computing egomotion from image velocity we established benchmark for quantifying bias and sensitivity to noise and for quantifying the convergence property of those algorithm that require numerical search our simulation result reveal some interesting and surprising result first it is often written in the literature that the egomotion problem is difficult because translation e g along the x axis and rotation e g about the y axis produce similar image velocity we found to the contrary that the bias and sensitivity of our six algorithm are totally invariant with respect to the axis of rotation second it is also believed by some that fixating help to make the egomotion problem easier we found to the contrary that fixating doe not help when the noise is independent of the image velocity fixation doe help if the noise is proportional to speed but this is only for the trivial reason that the speed are slower under fixation third it is widely believed that increasing the field of view will yield better performance we found to the contrary that this is not necessarily true 
this paper demonstrates a new visual motion estimation technique that is able to recover high degree of freedom articulated human body configuration in complex video sequence we introduce the use of a novel mathematical technique the product of exponential map and twist motion and it integration into a differential motion estimation this result in solving simple linear system and enables u to recover robustly the kinematic degree of freedom in noise and complex self occluded configuration we demonstrate this on several image sequence of people doing articulated full body movement and visualize the result in re animating an artificial d human model we are also able to recover and re animate the famous movement of eadweard muybridge s motion study from the last century to the best of our knowledge this is the first computer vision based system that is able to process such challenging footage and recover complex motion with such high accuracy 
the use of visual representation in which retinal neuron receptive field are not constant over the visual field is universal in the visual system of higher vertebrate and is coming to play an important role in active vision application the breaking of translation symmetry that is unavoidably associated with non uniform sampling present a major algorithmic complication for image processing in this paper we use a lie group approach to derive a kernel which provides a quasi shift i e approximate shift invariant template matching capability under normal convolution in the distorted range coordinate of the non uniform mapping we work out the special case of the logpolar mapping which is of great interest in vision in this case we call the associated linear integral transform the exponential chirp transform ect the method is however general for other form of mapping or warp function 
the correspondence problem in computer vision is basically a matching task between two or more set of feature in this paper we introduce a vectorized image representation which is a feature based representation where correspondence ha been established with respect to a reference image the representation consists of two image measurement made at the feature point shape and texture feature geometry or shape is represented using the x y location of feature relative to the some standard reference shape image grey level or texture are represented by mapping image grey level onto the standard reference shape computing this representation is essentially a correspondence task and in this paper we explore an automatic technique for vectorizing face image our face vectorizer alternate back and forth between computation step for shape and texture and a key idea is to structure the two computation so that each one us the output of the other in addition to describing the vectorizer an application to the problem of facial feature detection will be presented 
in this contribution we are concerned with the detection andrefined localization of d point landmark we propose multi step differentialprocedures for subvoxel localization of d point landmark moreover we address the problem of choosing an optimal size for a region ofinterest roi around point landmark that is to reliably localize thelandmark position on the one hand a much a possible image informationabout the landmark should be incorporated on the other hand the 
in recent year curve evolution ha developed into an important tool in computer vision and ha been applied to a wide variety of problem such a smoothing of shape shape analysis and shape recovery the underlying principle is the evolution of a simple closed curve whose point move in the direction of the normal with prescribed velocity a fundamental limitation of the method a it stand is that it cannot deal with important image feature such a triple point the method also requires a choice of an edge strength function defined over the image domain indicating the likelihood of an object boundary being present at any point in the image domain this implies a separate preprocessing step in essence precomputing approximate boundary in the presence of noise one also ha to choose the initial curve it is shown here that the different version of curve evolution used in computer vision together with the preprocessing step can be integrated in the form of a new segmentation functional which overcomes these limitation and extends curve evolution model moreover the numerical solution obtained retain sharp discontinuity or shock thus providing sharp demarcation of object boundary 
scene classification is a major open challenge in machine vision most solution proposed so far such a those based on color histogram and local texture statistic cannot capture a scene s global configuration which is critical in perceptual judgment of scene similarity we present a novel approach configural recognition for encoding scene class structure the approach s main feature is it use of qualitative spatial and photometric relationship within and across region in low resolution image the emphasis on qualitative measure lead to enhanced generalization ability and the use of low resolution image render the scheme computationally efficient we present result on a large database of natural scene we also describe how qualitative scene concept may be learned from example 
we develop an approach to image segmentation for naturalscenes containing image texture one general methodology which showspromise for solving this problem is to characterize textured region viatheir response to a set of filter however this approach brings with itmany open question including how to combine texture and intensityinformation into a common descriptor and how to deal with the factthat filter response inside textured region are generally spatially 
this paper present a formal model of an active recognition system that can be programmed by learning at each time step the system decides between producing an action to generate new data and stopping to issue the name of the object observed the action can be directed either towards the external environment or towards the internal perceptual system of the agent the decision strategy is based on a quantitative evaluation of the system learning experience the problem studied is the recognition of chess piece using a moving camera and a multiscale feature detector the recognition is difficult because the object are complex neither polyhedral nor smooth and rather similar between class especially in certain view configuration the system us the information obtained by observing internal state transition when the camera is moved or when the feature detector scale is changed a simulation of the agent and the environment is used for experimental measure of the model performance 
current indexing based approach build the hash table using either a large number of reference view or d model in this paper we propose building the hash table using algebraic function of view during preprocessing we consider group of model point and we represent all the view i e image that they can produce in a hash table these view are computed using algebraic function of a small number of reference view which contain the group fundamental to this procedure is a methodology based on singular value decomposition and interval arithmetic for estimating the range of value that the parameter of algebraic function can assume during recognition scene group are used to retrieve from the hash table the model group that might have produced them using algebraic function of view for indexing based recognition offer a number of advantage first of all the hash table can be built easier without requiring d model or a large number of reference view second recognition doe not rely on the similarity between new and reference view third verification becomes simpler finally the approach is more general and extendible 
object recognition start from a set of image measurement including location of point line surface color and shading which provides access into a database where representation of object are stored we describe a complexity theory of indexing a meta analysis which identifies the best set of measurement up to algebraic transformation such that the representation of object are linear subspace and thus easy to learn direct indexing is efficient since the linear subspace are of minimal rank the index complexity is determined via a simple process equivalent to computing the rank of a matrix we readily re derive the index complexity of the few previously analyzed case we then compute the best index for new case point in one perspective image and direction in one para perspective image the most efficient representation of a color is a plane in d space for future application with any vision problem where the relation between shape and image measurement can be written down in an algebraic form we give an automatic process to construct the most efficient database that can be directly obtained by learning from example 
multiple image of a scene are related through d d view transformation and linear and non linear camera transformation in all the traditional technique to compute these transformation especially the one relying on direct intensity gradient one image and it coordinate system have been assumed to be ideal and distortion free in this paper we present a formulation and an algorithm for true multi image alignment that doe not rely on the measurement of a reference image being distortion free for instance in the presence of lens distortion none of the image can be assumed to be ideal in our formulation all the image are modeled a intensity measurement represented in their respective coordinate system each of which is related to an ideal coordinate system through an interior camera transformation and an exterior view transformation the goal of the accompanying algorithm is to compute an image in the ideal coordinate system while solving for the transformcations that relate the ideal system with each of the data image key advantage of the technique presented in this paper are i no reliance on one distortion free image ii ability to register image and compute coordinate transformation even when the multiple image are of an extended scene with no overlap between the first and last frame of the sequence and iii ability to handle linear and non linear transformation within the same framework the new algorithm is evaluated in the context of two application i correction of lens distortion and ii creation of video mosaic 
this paper present a novel approach to the detection andrecognition of qualitative part like geons from real d intensity image previous work relied on semi local property of either line drawing orgood region segmentation here in the framework of model based optimisation whole geons or substantial sub part are recognised by fittingparametric deformable contour model to the edge image by mean ofa maximum a posteriori estimation performed by adaptive simulated 
we present five performance measure to evaluate grouping module in the context of constrained search and indexing based object recognition using these measure we demonstrate a sound experimental framework based on statistical anova test to compare and contrast three edge based organization module namely those of etemadi et al jacob and sarkar boyer in the domain of aerial object using image with adapted parameter the jacob module is overall the best choice for constraint based recognition for fixed parameter the sarkar boyer module is the best in term of recognition accuracy and indexing speedup etemadi et al s module performs equally well with fixed and adapted parameter while the jacob module is most sensitive to fixed and adapted parameter choice the overall performance ranking of the module is jacob sarkar boyer and etemadi et al 
deformable model are related to other data representation method it wa recently proposed a class of model based on a fuzzy energy function which includes many well known algorithm snake elastic net fuzzy and hard c mean and kohonen map this paper describes a probabilistic extension of these algorithm in a bayesian framework using gibbs boltzman distribution it is shown that the new class of model minimizes an energy function with an additional term the log partition function the role of the log partition function in probabilistic version of snake c mean and elastic net is studied and analytic expression are derived in the case of probabilistic snake the log partition function produce an additional force field which improves the performance of these algorithm in some application 
this paper present a novel time based visual motion cue called the hybrid visual threat cue hvtc that provides some measure for a change in relative range a well a absolute clearance between a d surface and a moving observer it is shown that the hvtc is a linear combination of time to contact ttc visual looming and the visual threat cue vtc the visual field associated with the hvtc can be used to demarcate the region around a moving observer into safe and danger zone of varying degree which may be suitable for autonomous navigation task the hvtc is independent of the d environment and need almost no a priori information about it it is rotation independent and is measured in time sup unit several approach to extract the hvtc are suggested also a practical method to extract it from a sequence of image of a d textured surface obtained by a visually fixating fixed focus monocular camera in motion is presented this approach of extracting the hvtc is independent of the type of d surface texture and need no optical flow information d reconstruction segmentation feature tracking 
this paper examines the fundamental ambiguity and uncertainty inherent in recovering structure from motion by examining the eigenvectors associated with null or small eigenvalue of the hessian matrix we can quantify the exact nature of these ambiguity and predict how they affect the accuracy of the reconstructed shape our result for orthographic camera show that the ba relief ambiguity is significant even with many image unless a large amount of rotation is present similar result for perspective camera suggest that three or more frame and a large amount of rotation are required for metrically accurate reconstruction 
this paper will review the design of a working system that visually recognizes hand gesture for the control of a window based user interface after an overview of the system it will explore one aspect of gestural interaction in depth hand tracking and what is needed for the user to be able to interact comfortably with on screen object we describe how the location of the hand is mapped to a location on the screen and how it is both necessary and possible to smooth the camera input using a non linear physical model of the cursor the performance of the system is examined especially with respect to object selection we show how a standard hci model of object selection fitts law can be extended to model the selection performance of free hand pointing 
efficient access to information contained in video database implies that a structured representation of the content of the video is built beforehand this paper describes an approach in this direction targeted at video indexing and browsing exploiting a d motion model estimator we partition the video into shot characterize camera motion extract and track mobile object these step rely on robust motion estimation statistical test and contextual statistical labeling the content of each shot can then be viewed on a synoptic frame composed of a mosaic image of the background scene on which trajectory of mobile object are superimposed the proposed method also provides instantaneous and long term qualitative and quantitative object motion cue for content based indexing it different step and the system they form are designed to keep computational cost low while being able to cope with general video content wa aimed at we provide experimental result on real world sequence the structured output open important possible extension for instance in the direction of higher level interpretation 
ritz vector approximate eigenvectors that are a common choice for primary image in content based indexing they can be computed efficiently even when the image are accessed through slow communication such a the internet we develop an algorithm that computes ritz vector in one pas through the image when iterated the algorithm can recover the exact eigenvectors in application to image indexing and learning it may be necessary to compute primary image for indexing many sub category of the image set the proposed algorithm can compute these additional primary image offline without the image data much more costly even when access to the image is inexpensive 
we analyze the use of kinematic constraint for articulated object tracking condition for the occurrence of singularity in d model are presented and their effect on tracking are characterized we describe a novel d scaled prismatic model spm for figure registration in contrast to d kinematic model the spm ha fewer singularity problem and doe not require detailed knowledge of the d kinematics we fully characterize the singularity in the spm and illustrate tracking through singularity using synthetic and real example with d and d model our result demonstrate the significant benefit of the spm in tracking with a single source of video 
antonio j colmenarez and thomas s huang in this paper we present a visual learning technique that maximizes the discrimination between positive and negative example in a training set we demonstrate our technique in the context of face detection with complex background without color or motion information which ha proven to be a challenging problem we use a family of discrete markov process to model the face and background pattern and estimate the probability model using the data statistic then we convert the learning process into an optimization selecting the markov process that optimizes the information based discrimination between the two class the detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure we show that because of the discrete nature of these model the detection process is by almost two order of magnitude le computationally expensive than neural network approach however no improvement in term of correct answer false alarm tradeoff is achieved 
we describe an appearance based object recognition system using a keyed multi level context representation reminiscent of certain aspect of cubist art specifically we utilize distinctive intermediate level feature in this case automatically extracted d boundary fragment a key which are then verified within a local context and assembled within a loose global context to evoke an overall percept this system demonstrates extraordinarly good recognition of a variety of d shape ranging from sport car and fighter plane to snake and lizard with full orthographic invariance we report the result of large scale test involving over separate test image that evaluate performance with increasing number of item in the database in the presence of clutter background change and occlusion and also the result of some generic classification experiment where the system is tested on object never previously seen or modelled to our knowledge the result we report are the best in the literature for full sphere test of general shape with occlusion and clutter resistance 
we present a computational group theoretic approach to steerable function the approach is group theoretic in that the treatment involves continuous transformation group for which elementary lie group theory may be applied the approach is computational in that the theory is constructive and lead directly to a procedural implementation for function that are steerable with n finite number of basis function under a k parameter group the procedure is efficient and is guaranteed to return the minimum number of basis function if the function is not steerable a numerical implementation of the procedure could also be used to compute basis function that approximately steer the function over a range of transformation parameter example of both application are demonstrated 
we propose a new method to recognize d free form object from their apparent contour it is the extension of our established method to recognize object with fixed edge object model are compared with d boundary which are extracted by segment based stereo vision based on the local shape of the boundary candidate transformation are generated the candidate are verified and adjusted based on the whole shape of the boundary themodels are built from all around range data of the object experimental result show the effectiveness of the method 
snake or active contour are used extensively in computer vision and image processing application particularly to locate object boundary problem associated with initialization and poor convergence to concave boundary however have limited their utility this paper develops a new external force for active contour largely solving both problem this external force which we call gradient vector flow gvf is computed a a diffusion of the gradient vector of a gray level or binary edge map derived from the image the resultant field ha a large capture range and force active contour into concave region example on simulated image and one real image are presented 
we describe progress in completely automatically recovering d scene structure together with d camera position from a sequence ofimages acquired by an unknown camera undergoing unknown movement the main departure from previous structure from motion strategy isthat processing is not sequential instead a hierarchical approach is employedbuilding from image triplet and associated trifocal tensor thisis advantageous both in obtaining correspondence and also in optimally 
this paper describes a new method for estimating optical flow that strike a balance between the flexibility of local dense computation and the robustness and accuracy of global parameterized flow model an affine model of image motion is used within local image patch while a spatial smoothness constraint on the affine flow parameter of neighboring patch enforces continuity of the motion we refer to this a a skin and bone model in which the affine patch can be thought of a rigid bone connected by a flexible skin since local image patch may contain multiple motion we use a layered representation for the affine bone to regularize this layered motion representation we develop a new framework for regularization with transparency 
in this paper we develop a method to find correspondence between a cranio caudal cc and a medio lateral oblique mlo x ray image of the same breast matching between such pair of image is considered essential by radiologist for more reliable diagnosis of early breast cancer the two image are taken while the breast is compressed between the cassette and plate of the x ray machine but almost always to a different extent in each direction the deformation of the breast caused by the different compression in the different direction cause corresponding point to appear far from the straight epipolar line familiar from binocular stereo vision the method developed in this paper calculates the line in a mlo image corresponding to a point in the cc image through simulation of the deformation and the projection of a d line curve corresponding to the point experiment using actual image show that the method give good prediction which can be used to find exact correspondence between point in the two image 
this paper describes a boundary estimation scheme based on a new adaptive approach to b spline curve fitting the number of control point of the spline their location and the observation parameter are all considered unknown the optimal number of control point is estimated via a new minimum description length mdl type criterion the result is an adaptive parametrically deformable contour which also estimate the observation model parameter experiment on synthetic and real medical image confirm the adequacy and good performance of the approach 
we propose anew rectification method for aligning epipolar line of a pair of stereo image taken under any camera geometry it effectively remaps both image onto the surface of a cylinder instead of a plane which is used in common rectification method for a large set of camera motion remapping to a plane ha the drawback of creating rectified image that are potentially infinitely large and present a loss of pixel information along epipolar line in contrast cylindrical rectification guarantee that the rectified image are bounded for all possible camera motion and minimizes the loss of pixel information along epipolar line the process e g stereo matching etc subsequently applied to the rectified image are thus more accurate and general since they can accommodate any camera geometry 
recognizing a target in synthetic aperture radar sar image is an important yet challenging application of the model based vision technique this paper describes a model based sar recognition system based on invariant histogram and deformable template matching technique an invariant histogram is a histogram of invariant value defined by geometric feature such a point and line in sar image although a few invariant are sufficient to recognize a target we use a histogram of all invariant value given by all possible target feature pair this redundant histogram enables robust recognition under severe occlusion typical in sar recognition scenario multi step deformable template matching examines the existence of an object by superimposing template over potential energy field generated from image or primitive feature it determines the template configuration which ha the minimum deformation and the best alignment of the template with feature the deformability of the template absorbs the instability of sar feature we have implemented the system and evaluated the system performance using hybrid sar image generated from synthesized model signature and real sar background signature 
the paper discus objection against performance characterization of vision algorithm and explains theirmotivation short and long term argument are given which overcome these objection the methodologyfor performance characterization is sketched to demonstrate the feasibility of empirical testing staffof visionalgorithms motivationfor at least year computer vision ha been confronted with paper and discussion on the scientificvalue of it result and the difficulty in 
this paper present a new framework for segmentation of textured visual imagery the proposed method consists of a bayesian formulation for labeling similar region similarity is defined via texture feature obtained by gabor wavelet multivariate gaussian distribution are employed to model the feature class conditional density while the markov process is used to characterize the distribution of the region labeling due to each feature a coarse nearest neighbor clustering is performed over the feature space to estimate the initial labelings an iterative solution to the maximum a posteriori map estimation is developed where the parameter of the prior distribution of region label are estimated using the expectation maximization em algorithm finally for man made object segmentation a region growing procedure is used to analyze the classified texture region by incorporating measure of local shape characteristic to obtain smooth boundary and region homogeneity result of the developed algorithm on real scene image are presented 
this paper is concerned with the analysis of d fluid motion from numerical image the interpretation of such deformable flow field can be derived from the characterization of linear motion model provided that first order approximation are considered in an adequate neighborhood of so called singular point where the velocity becomes null however locating such point delimiting this neighborhood and estimating the associated d affine motion model are intricate difficult problem we explicitly address these three joint problem according to a statistical adaptive approach in the fluid mechanic image we are dealing with the motion model can be directly inferred from a single image since the visualized form account for the underlying motion we have developed an original method which relies on an orthogonality constraint between the spatial image gradient field and the motion model velocity field while explicitly formalizing and handling both model and measurement noise this method ha been validated on several real fluid flow image 
a method for recognition of street name phrase collected from mail piece is presented in this paper some of the challenge posed by the problem are i patron error ii non standardized way of abbreviating name and iii variable number of word in a street name image a neural network ha been designed to segment word in a phrase a street name in this case using distance between component and style of writing the network learns the type of spacing including size that one should expect between different pair of character in handwritten test experiment show perfect word segmentation performance at about of case unlike conventional method where lexicon entry are expanded to take care of all variation of prefix and size substring matching is attempted only between the main body of a lexicon entry and the word segment of an image effort to reduce computational complexity are successfully made by the sharing of character segmentation result between the segmentation and recognition phase phrase recognition accuracy is achieved on a test set 
texture ha long been regarded a spatial distribution of gray level variation and texture analysis ha generally been confined to the d image domain introducing the concept of d world texture this paper considers texture a a function of d structure and proposes a set of d textural feature the proposed d feature appear to have a great potential in terrain classification experiment have been carried out to compare the d feature with a popular traditional d feature set the result show that the d feature significantly outperform the d feature in term of classification accuracy 
automatic indexing or registration is an essential task for image database it allows to archive organise and retrieve a large amount of image by using inner property in this paper we propose an indexing technique which allows to solve indexing problem due to geometric or photometric transformation inferred by the different image acquisition this approach is based on an invariant partition of the image thanks to the use of interest point or keypoints and a characterisation with ifs parameter or barycentric moment the research process is based on a similarity measure taking in account a numerical distance and a localisation criterion this work is based on a local characterisation of the image we use the interest point to build a triangular partition or a set of triangle we associate to each polygon a vector containing it photometric property in other approach the keypoints are directly characterised by local invariant the use of the ifs parameter to index the image ha been studied in early publication the improvement robustness against rotation and scaling come from the use of the invariant partition and the barycentric coordinate the research process is particularly important it us traditional spatial relation and integrate them with a numerical distance to calculate a score associated to each image 
a complete analysis of the statistical issue related to the estimation of a bilinear form one of the fundamental problem in computer vision is presented it is shown why already at moderate noise level most available technique fail to provide a satisfactory solution a new estimation procedure is proposed in which the nonlinear nature of the error are taken into account and the implementation us the generalized singular value decomposition for superior numerical behavior a an example the ellipse fitting problem is discussed and the performance of the new algorithm is compared with thecurrent state of the art 
a motion estimation algorithm using wavelet approximation a an optical flow model ha been developed to estimate accurate dense optical flow from an image sequence this wavelet motion model is particularly useful in estimating optical flow with large displacement traditional pyramid method which use the coarse to fine image pyramid by image burring in estimating optical flow often produce incorrect result when the coarse level estimate contain large error that cannot be corrected at the subsequent finer level this happens when region of low texture become flat or certain pattern result in spatial aliasing due to imageblurring our method in contrast us large to small full resolution region without blurring image and simultaneously optimizes the coarser and finer part of optical flow so that the large and small motion can be estimated correctly we compare result obtained by using our method with those obtained by using one of the leading optical flow method the szeliski pyramid spline based method the experiment include case of small displacement le than pixel under image size or equivalent displacement under other image size and those of large displacement pixel while both method produce comparableresults when the displacement are small our method out performs pyramid spline based method when the displacement are large 
this paper tackle the problem of selfcalibration of multiple camera which are very far apart given a set of feature correspondence one can determine the camera geometry the key problem we address is finding such correspondence since the camera geometry location and orientation and photometric characteristic vary considerably between image one cannot use brightness and or proximity constraint instead we propose a three step approach first we use moving object in the scene to determine a rough planar alignment next we use static feature to improve the alignment finally we use off plane feature to determine the epipolar geometry and the horizon line we do not assume synchronized camera and we show that enforcing the geometric constraint enables u to align the tracking data in time we present result on challenging outdoor scene using real time tracking data 
we describe a technique for using the joint occurrence of local feature at multiple resolution to measure the similarity between texture image though superficially similar to a number of gabor style technique which recognize texture through the extraction of multi scale feature vector our approach is derived from an accurate generative model of texture which is explicitly multi scale and non parametric the resulting recognition procedure is similarly non parametric and can model complex non homogeneous texture we report result on publicly available texture database in addition experiment indicate that this approach may have sufficient discrimination power to perform target detection in synthetic aperture radar image sar 
in this paper the feasibility of self calibration in the presence of varying internal camera parameter is under investigation a self calibration method is presented which efficiently deal with all kind of constraint on the internal camera parameter within this framework a practical method is proposed which can retrieve metric reconstruction from image sequence obtained with uncalibrated zooming focusing camera the feasibility of the approach is illustrated on real and synthetic example 
this paper describes a system which us multiple visual process to detect and track face for video compression and transmission the system is based on an architecture in which a supervisor selects and activates visual process in cyclic manner control of visual process is made possible by a confidence factor which accompanies each observation fusion of result into a unified estimation for tracking is made possible by estimating a covariance matrix with each observation visual process for face tracking are described using blink detection normalized color histogram matching and cross correlation ssd and ncc ensemble of visual process are organized into processing state so a to provide robust tracking transition between state is determined by event detected by process the result of face detection is fed into recursive estimator kalman filter the output from the estimator drive a pd controller for a pan tilt zoom camera the resulting system provides robust and precise tracking which operates continuously at approximately image per second on a megahertz computer work station 
we present a technique to extract complex suburban roofsfrom set of aerial image because we combine d edge information photometric and chromatic attribute and d information we can dealwith complex house neither do we assume the roof to be flat or rectilinearnor do we require parameterized building model from only oneimage d edge and their corresponding attribute and relation areextracted using a segment stereo matching based on all available image the d 
motion segmentation involves identifying region of the image that correspond to independently moving object the number of independently moving object and type of motion model for each of the object is unknown a priori in order to perform motion segmentation the problem of model selection robust estimation and clustering must all be addressed simultaneously here we place the three problem into a common bayesian framework investigating the use of model averaging representing a motion by a combination of model a a principled way for motion segmentation of image the final result is a fully automatic algorithm for clustering that work in the presence of noise and outlier 
the extraction of figure symmetry from image contour face a number of fundamental difficulty object symmetry are distorted due to i gap in the bounding contour of a shape due to figure ground blending weak contrast edge highlight noise etc ii an introduction of part and occluders and iii spurious edge element due to surface marking texture etc a framework for extracting such symmetry from real image is proposed based on the propagation of contour orientation information and the detection of four type of singularity shock arising from the collision of propagating element in this paper we show that an additional labeling of shock based on whether the colliding wavefront carry true orientation information regular v rarefaction wave allows a division of shock into three set regular shock are the partial shock of partial contour a they remain invariant to the completion of the contour semi degenerate and degenerate shock depict potential part and gap finally shock altered due to spurious edge occlusion and gap are recovered via a simulation of inter penetrating wave generated at select shock group which with the aid of the above shock label lead to second and further generation of shock 
gaussian curvature is an invariant local descriptor of smooth surface we present an object signature which is a condensed representation of the distribution of gaussian curvature information at visible object point an invariant related to gaussian curvature at a point is derived from the covariance matrix of the photometric value in a neighborhood about that point in addition we introduce an albedo normalization method that is capable of cancelling albedo on lambertian surface we use three illumination condition two of which are unknown the three tuple of intensity value at a point is related via a one to one mapping to the surface normal at that point the determinant of the covariance matrix of the local three tuples is invariant to albedo rotation and translation the collection of determinant over mutually illuminated object point is combined into a signature distribution which is albedo rotation translation and scale invariant an object recognition methodology using these signature is proposed 
this paper describes a color region based approach to motion estimation in color image sequence the system is intended for robotic and vehicle guidance application where the task is to detect and track moving object in the scene it belongs to the class of feature based matching technique and us color region resulting from a prior color segmentation a the matching primitive in contrast to other regionbased approach it take into account the unavoidable variation in the segmentation by the extension of the matching model to multi match in order to provide extended trajectory color region that could not be matched on the feature level are matched on the pixel level by the integration of a correlation based mechanism the usage of color information and the combination of feature based and correlation based matching lead to robust and ecient algorithm the system wa applied to a motion segmentation task in vehicle guidance experiment on more than natural color outdoor image taken from a moving car show promising result 
a technique is introduced for extracting and reconstructing a wide class of building type from a registered range image and optical image an attentional focus stage followed by model indexing allows top down robust surface fittting to reconstruct the d nature of the building in the data because of the effectiveness of model selection top down processing of noisy range data still succeeds and the algorithm is capable of detecting and reconstructing several different building roof class including fiat single level fiat multi leveled peaked and curued rooftop the algorithm is applicable to range data that may have been collected from several different range sensor type we demonstrate reconstruction of different building class in the presence of large amount of noise our result underline the usefuless of range data when processed in the context of a focus of attention area derived from the monocular optical image 
in this paper the problem of generating a d octree like structure with the help of epipolar geometry within a projective framework is addressed after a brief introduction on the basic of octrees and epipolar geometry the new concept called projective octree is introduced together with an algorithm for building this projective structure finally some result of the implementation are presented in the last section together with the conclusion and future work 
the problem of finding the closest point in high dimensional space is common in computational vision unfortunately the complexity of most existing search algorithm such a k d tree and r tree grows exponentially with dimension making them impractical for dimensionality above in nearly all application the closest point is of interest only if it lie within a user specified distance epsilon we present a simple and practical algorithm to efficiently search for the nearest neighbor within euclidean distance epsilon our algorithm us a projection search technique along with a novel data structure to dramatically improve performance in high dimension a complexity analysis is presented which can help determine epsilon in structured problem benchmark clearly show the superiority of the proposed algorithm for high dimensional search problem frequently encountered in machine vision such a real time object recognition 
we discus optimal rotation estimation from two set of dpoints in the presence of anisotropic and inhomogeneous noise we firstpresent a theoretical accuracy bound and then give a method that attainsthat bound which can be viewed a describing the reliability of thesolution we also show that an efficient computational scheme can beobtained by using quaternion and applying renormalization using realstereo image for d reconstruction we demonstrate that our methodis superior to 
existing object tracking algorithm generally use some form of local optimisation assuming that an object s position and shape change smoothly over time in some situation this assumption is not valid the trackable shape of an object may change discontinuously for example if it is the d silhouette of a d object in this paper we propose a novel method for modelling temporal shape discontinuity explicitly allowable shape are represented a a union of learned bounded region within a shape space discontinuous shape change are described in term of transition between these region transition probability are learned from training sequence and stored in a markov model in this way we can create wormhole in shape space tracking with such model is via an adaptation of the condensation algorithm 
we describ e an implemented technique for generating event model automatically based on qualitative reasoning and a statistical analysis of video input using an existing tracking program which generates labelled contour for object in every frame the view from a fixed camera is partitioned into semantically relevant region based on the path followed by movingobjects the path are indexed with temporal information so object moving along the same path at different speed can be distinguished using a notion of proximity based on the speed of the moving object and qualitative spatial reasoning technique event model describing the behaviour of pair of object can be built again using statistical method the system ha been tested on a traffic domain and learns various event model expressed in the qualitative calculus which represent human observable event the system can then be used to recognise subsequent selected event occurrence or unusual behaviour 
we present a d shape based object recognition system for simultaneous recognition of multiple object in scene containing clutter and occlusion recognition is based on matching surface by matching point using the spin image representation the spin image is a data level shape descriptor that is used to match surface represented a surface mesh we present a compression scheme for spin image that result in efficient multiple object recognition which we verify with result showing the simultaneous recognition of multiple object from a library of model furthermore we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trial on scene 
the one dimensional image analysis method know a the sieve is extended to any finite dimensional image it preserve all the usual scale space property but ha some additional feature that we believe make it more attractive than the diffusion based method we present some simple example of how it might be used 
this study combine two useful method in recognition consensus or voting based approach and moment based representation match between image patch are generated using a gaussian weighted moment encoding of the patch and a feature indexing process each match implies an object d position and orientation pose and generates a vote for this pose recognition is accomplished by detecting significant cluster of vote in pose space this combined method is an improvement over voting and moment method in isolation using image brightness moment the idea is successfully demonstrated on example of human face undergoing full d pose change a well a change in feature such a talking and blinking the idea is then extended to moment of local texture orientation and successfully demonstrated under large variation in lighting nature and geometry 
we derive real time global optimization algorithm for several clustering optimization method used in unsupervised texture segmentation speed is achieved by exploiting the topological relation of feature to design a multiscale optimization technique while accuracy and global optimization property are provided by a deterministic annealing method coarse grained cost function are derived for both central and sparse pairwise clustering where the problem of coarsening sparse random graph is solved by the concept of structured randomization annealing schedule and coarse to fine optimization are tightly coupled by a statistical convergence criterion derived from computational learning theory the algorithm are benchmarked on brodatz like micro texture mondrian result are presented for an autonomous robotics application 
inspired by the property of the humam visual system a new active vision system called escher etl stereo compact head for robot vision ha been recently implemented with foveated wide angle lens the lens exhibit a wide field of view along with a space varying resolution for facilitating both detection and close observation however to handle such optical property and achieve basic eye movement function new calibration method are needed therefore two novel and online technique are presented that in one case perform a global identification of the optical process through artificial neural technique and in the other case compute the physical parameter by using environmental feature tracking and controlled rotation of the camera self alignment of the camera is also achieved using a similar technique 
the paper contributes to the viewpoint invariant recognition of planar pattern especially label and sign under affine deformation by their nature the information of such eye catcher is not contained in the outline or frame they often are affinely equivalent like parallelogram and ellipsis but in the intensity content within moment invariant are well suited for their recognition they need a closed bounding contour but this is comparatively easy to provide for the simple shape considered on the other hand they characterize the intensity pattern without the need for error prone feature extraction this paper us moment a the basic feature but extends the literature in two respect deliberate mix of different type of moment to keep the order of the moment and hence also the sensitivity to noise low and yet have a sufficiently large number to safeguard discriminant power and invariance with respect to photometric change is incorporated in order to find the simplest moment invariant that can cope with changing lighting condition which can hardly be avoided when changing viewpoint the paper give complete classification of such affine photometric moment invariant experiment are described that illustrate the use of some of them 
the recognition of general three dimensional object in cluttered scene is a challenging problem in particular the design of a good representation suitable to model large number of generic object that is also robust to occlusion ha been an stumbling block in achieving success in this paper we propose a representation using appearance based part and relation to overcome these problem appearance based part and relation are defined in term of closed region and the union of these region respectively the region are segmented using the mdl principle and their appearance is obtained from collection of image and compactly represented by parametric manifold in the two eigenspaces spanned by the part and the relation 
we present a novel application of the expectation maximization algorithm to the global analysis of articulated motion the approach utilizes a kinematic model to constrain the motion estimate producing a segmentation of the flow field into part with different articulated motion experiment with synthetic and real image are described 
this paper describes an efficient algorithm for the segmentation of echo cluster within a dynamic d sonar image the sensor centered image is an echo management framework grouping sonar return into spherical cell and allowing real time organisation of d range data using inexpensive equipment each cell act a a spatial key to the feature related to this location the spherical representation is effectively exploited for segmentation using an approach motivated from connected component analysis in binary video image a fast algorithm linear in time complexity based on cell connectivity between sonar beam is presented including method for coping with sparse data 
new representation are developed for d ip implicit polynomial curve of arbitrary degree these representation permit shape recognition and pose estimation with essentially single rather than iterative computation and extract and use all the information in the polynomial coefficient this is accomplished by decomposing polynomial coefficient space into a union of orthogonal subspace for which rotation within two dimensional subspace or identity transformation within one dimensional subspace result from rotation in x y measured data space these rotation in the two dimensional coefficient subspace are related in simple way to each other and to rotation in the x y data space by recasting this approach in term of complex polynomial i e z x iy and complex coefficient further simplification occurs for rotation and some simplification occurs for translation 
in this paper we describe an algorithm for object recognition that explicitly model and estimate the posterior probability function p object image we have chosen a functional form of the posterior probability function that capture the joint statistic of local appearance and position on the object a well a the statistic of local appearance in the visual world at large we lise a discrete representation of local appearance consisting of approximately pattern we compute an estimate of p object image in closed form by counting the frequency of occurrence of these pattern over various set of training image we have used this method for detecting human face from frontal and profile view the algorithm for frontal view ha shown a detection rate of with false alarm on a set of image containing face combining the mit test set of sung and poggio with the cmu test set of rowley baluja and kanade the algorithm for detection of profile view ha also demonstrated promising result 
representing shape is a significant problem for vision system that must recognize or classify object we derive a representation for a given shape by investigating it self similarity and constructing it shape axis sa and shape axis tree sa tree we start with a shape it boundary contour and two different parameterizations for the contour to measure it self similarity we consider matching pair of point and their tangent along the boundary contour i e matching the two parameterizations the matching of self similarity criterion may vary e g co circularity parallelism distance region homogeneity the locus of middle point of the pairing contour point are the shape axis and they can be grouped into a unique tree graph the sa tree the shape axis for the co circularity criterion is compared to the symmetry axis an interpretation in term of object part is also presented 
this paper introduces a unified approach to the problem of verifying alignment hypothesis in the presence of substantial amount of uncertainty in the predicted location of projected model feature our approach is independent of whether the uncertainty is distributed or bounded and moreover incorporates information about the domain in a formally correct manner information which can be incorporated includes the error model the distribution of background feature and the position of the data feature near each predicted model feature experiment are described that demonstrate the improvement over previously used method furthermore our method is efficient in that the number of operation is on the order of the number of image feature that lie nearby the predicted model feature 
a new method for the representation recognition and interpretation of parameterized gesture is presented by parameterized gesture we mean gesture that exhibit a meaniful variation one example is a point gesture where the important parameter is the dimnesional direction our approach is to extend the standard hidden markov model method of gesture recognition by including a global parametric variation in the output probability of the state of the hmm using a linear model to derive the theory we formulate an expectation maximization em method for training the parametric hmm during testing the parametric hmm simultaneously recognizes the gesture and estimate the quantifying parameter using visually derived and directly measured dimensional hand position measurement a input we present result on two different movement a size gesture and a point gesture and show robustness with respect to noise in the input feature 
in this paper we study the limitation of current verification strategy in object recognition and suggest how they may be enhanced on the whole object topologyis exploited little during verification in practice understanding the connectivity relationship between feature in the image or on the object can l ead to significantly more accurate evaluation of recognition hypothesis we study how topology reasoning allows u to hypothesize the presence of occlusion in the image analysis of these hypothesis provides information which turn out to be crucial to the quality of our overall verification result 
a general geometrical framework for image processing is presented we consider intensity image a surface in the x i space the image is thereby a two dimensional surface in three dimensional space for gray level image the new formulation unifies many classical scheme algorithm and measure via choice of parameter in master geometrical measure more important it is a simple and efficient tool for the design of natural scheme for image enhancement segmentation and scale space here we give the basic motivation and apply the scheme to enhance image we present the concept of an image a a surface in dimension higher than the three dimensional intuitive space this will help u handle movie color and volumetric medical image 
we present a new method for extracting and classifying motion pattern to recognize hand gesture first motion segmentatzon of the image sequence is generated based on a muttiscale transform and attributed graph matching of region across frame this produce region correspondence and their affine transformation second color information of motion region is used to determine skin region third human head and palm region are identified based on the shape and size of skin area in motion finally affine transformation defining a region s motion between successive frame are concatenated to construct the region s motion trajectory gestural motion trajectory are then classified by a time delay neural network trained with backpropagation learning algorithm our experimental result show that hand gesture can be recognized well using motion pattern 
the use of hand gesture provides an attractive mean of interacting naturally with a computer generated display using one or more video camera the hand movement can potentially be interpreted a meaningful gesture one key problem in building such an interface without a restricted setup is the ability to localize and track the human arm robustly in image sequence this paper proposes a multiple cue based localization scheme combined with a tracking framework to reliably track the human ann dynamic in unconstrained environment the localization scheme integrates the multiple cue of motion shape and color for locating a set of key image feature using constraint fusion these feature are tracked by a modified extended kalman filter that exploit the articulated structure of the arm we also propose an interaction scheme between tracking and localization for improving the estimation process while reducing the computational requirement the performance of the framework is validated with the help of extensive experiment and simulation 
this paper describes a robust segmentation algorithm for the detection and localization of woven fabric defect the essence of the presented segmentation algorithm is the localization of those event i e defect in the input image that disrupt the global homogeneity of the background texture to this end preprocessing module based on the wavelet transform and edge fusion are employed with the objective of attenuating the background texture and accentuating the defect then texture feature are utilized to measure the global homogeneity of the output image if these image are deemed to be globally nonhomogenous i e defect are present a local roughness measure is used to localize the defect the utility of this algorithm can be extended beyond the specific application in our work that is defect segmentation in woven fabric indeed in a general sense this algorithm can be used to detect and to localize anomaly that reside in image characterized by ordered texture the efficacy of this algorithm ha been tested thoroughly under realistic condition and a a part of an on line fabric inspection system using over image offabrics containing different type of defect the overall detection rate of our approach wa with a localization accuracy of le than inch and a false alarm rate of 
dept of comput inf sci pennsylvania univ philadelphia pa usa abstract we present a new method for the d model based tracking of human body part to mitigate the difficulty arising due to occlusion among body part we employ multiple calibrated camera in a mutually orthogonal configuration in addition we develop criterion for a time varying active selection of a set of camera to track the motion of a particular human part in particular at every frame each camera track a number of part depending on the visibility of these part and the observability of their predicted motion from the specific camera to relate point on the occluding contour of the part to point on their model we apply concept from projective geometry then within the physic based framework we compute the generalized force applied from the part occluding contour to model point of the body part these force update the translational and rotational degree of freedom of the model such a to minimize the discrepancy between the sensory data and the estimated model state we present initial tracking result from a series of experiment involving the recovery of complex d motion in the presence of significant occlusion 
abstract a constrained optimization method called the lagrange hopfield lh method is presented for solving markov random field mrf based bayesian image estimation problem for restoration and segmentation the method combine the augmented lagrangian multiplier technique with the hopfield network to solve a constrained optimization problem into which the original bayesian estimation problem is reformulated the lh method effectively overcomes instability that are inherent in the penalty method e g hopfield network or the lagrange multiplier method in constrained optimization an additional advantage of the lh method is it suitability for neural like analog implementation experimental result are presented which show that lh yield good quality solution at reasonable computational cost 
this paper present a task oriented evaluation methodology for edge detector performance is measured based on the task of structure from motion eighteen real image sequence from different scene varying in the complexity and scenery type are used the task level ground truth for each image sequence is manually specified in term of the d motion and structure an automated tool computes the accuracy of the motion and structure achieved using the set of edge map parameter sensitivity and execution speed are also analyzed four edge detector are compared all implementation and data set are publicly available 
this work focus on creating a framework for objectively evaluating the performance of range image segmentation algorithm the algorithm are evaluated in term of correct segmentation overand undersegmentation missed and noise region a set of image with ground truth wa created for this work the image were captured using a structured light scanner image used in the evaluation contain planar spherical cylindrical toroidal andconical surface patch the different surface patch in each image were manually identified to establish ground truth for performance evaluation two segmentation algorithm from the literature are compared 
we develop a vision system for highly mobile autonomous agent that is capable of dynamic obstacle avoidance we demonstrate the robust performance of the system in artificial animal with directable foveated eye situated in physic based virtual world through active perception each agent control it eye and body by continuously analyzing photorealistic binocular retinal image stream the vision system computes stereo disparity and segment looming target in the low resolution visual periphery while controlling eye movement to track an object fixated in the high resolution fovea it match segmented target against mental model of colored object of interest in order to decide whether the segmented object are harmless or represent dangerous obstacle the latter are localized enabling the artificial animal to exercise the sensorimotor control necessary to avoid collision 
bilateral filtering smooth image while preserving edge by mean of a nonlinear combination of nearby image value the method is noniterative local and simple it combine gray level or color based on both their geometric closeness and their photometric similarity and prefers near value to distant value in both domain and range in contrast with filter that operate on the three band of a color image separately a bilateral filter can enforce the perceptual metric underlying the cie lab color space and smooth color and preserve edge in a way that is tuned to human perception also in contrast with standard filtering bilateral filtering produce no phantom color along edge in color image and reduces phantom color where they appear in the original image 
we report the result of an experimental study in which human subject are asked to demarcatethe contour of a sample of natural image by analysing the statistic of these contour wederive a set of empirical probability distribution for three contour grouping cue proximity goodcontinuation curvature and brightness similarity we show that of these three cue proximityis by far the most powerful followed by good continuation and finally brightness similarity usinga 
we present a framework for recognizing isolated and continuous american sign language asl sentence from three dimensional data the data are obtained by using physic based three dimensional tracking method and then presented a input to hidden markov model hmms for recognition to improve recognition performance we model context dependent hmms and present a novel method of coupling three dimensional computer vision method and hmms by temporally segmenting the data stream with vision method we then use the geometric property of the segment to constrain the hmm framework for recognition we show in experiment with a sign vocabulary that three dimensional feature outperform two dimensional feature in recognition performance furthermore we demonstrate that context dependent modeling and the coupling of vision method and hmms improve the accuracy of continuous asl recognition 
using result from robust kalman filtering we present a new kalman filter based snake model for tracking of nonrigid object in combined spatio velocity space the proposed model is the stochastic version of the velocity snake which is an active contour model for combined tracking of position and velocity of nonrigid boundary the proposed model us image gradient and optical flow measurement along the contour a system measurement an optical flow based measurement error is used to detect and reject image measurement which correspond to image clutter or to other object the method wa applied to object tracking ofboth rigid and nonrigid object resulting in good tracking result and robustness to image clutter occlusion and numerical noise 
in this paper we present an evaluation of a robust visual image tracker on echocardiographic image sequence we show how the tracking framework can be customised to define an appropriate shape space that describes heart shape deformation that can be learnt from a training data set we also investigate an energy based temporal boundary enhancement method to improve image feature measurement preliminary result are presented demonstrating tracking on real normal heart motion data sequence and synthesised and real abnormal heart motion data sequence we conclude by discussing some of our current research effort 
fixation is defined a the ability of an active visual system to keep the projection of an environmental point stationary in the image we show in this paper that fixation enables the decoupling of the d motion parameter by projecting appropriately the spherical motion field in two latitudinal direction with respect to two different pole of the image sphere both computational step are based on one dimensional search along meridian of the image sphere we do not use the efference copy of the fixational rotation of the camera performance of the algorithm is tested on real world sequence with fixation accomplished either off line or during the recording using an active camera 
a system of coupled differential equation is formulated which learns prior for modelling preattentive texture it is derived from an energy functional consisting of a linear combination of a large number of term corresponding to the feature that the system is capable of learning the system learns the parameter associated with each feature by applying gradient ascent to the log likelihood function update of each parameter is thus governed by the residual with respect to the corresponding feature a feature residual is computed from it observed value and value generated by the system the latter is calculated from a synthesized sample image which is generated by mean of a reaction diffusion equation obtained by applying gradient descent to the energy functional 
in this paper we develop a representation for the temporal structure inherent in human action and demonstrate an effective method for using that representation to detect the occurrence of action the temporal structure of the action sub action event and sensor information is described using a constraint network based on allen s interval algebra we map these network onto a simpler valued domain past now fut network a pnf network to allow fast detection of action and sub action the occurrence of an action is computed by considering the minimal domazn of it pnf network under constraint imposed by the current state of the sensor and the previous state of the network we illustrate the approach with example showing that a major advantage of pnf propagation is the detection and removal of inconsistent situation 
due to illumination variability the same object can appear dramatically different even when viewed in fixed pose to handle this variability an object recognition system must employ a representation that is either invariant to or model this variability this paper present an appearance based method for modeling the variability due to illumination in the image of object the method differs from past appearance based method however in that a small set of training image is used to generate a representation the illumination cone which model the complete set of image of an object with lambertian reflectance map under an arbitrary combination of point light source at infinity this method is both an implementation and extension an extension in that it model cast shadow of the illumination cone representation proposed in the method is tested on a database of image of face and the result exceed those of popular existing method 
we present a novel method of velocity field estimation for point on moving contour in an image sequence the method determines the corresponding point in the next image frame by considering curvature change at each point on a contour in previous method there are error in estimation for the point which have low curvature variation since those method compute the solution by approximatingthe normal component of optical flow the proposed method computes optical flow vector of contour point by minimizing the curvature change a a first step snake are used to locate smooth curve in d imagery then the extracted curve are tracked continuously we excluded the rearranging process in snake and allowed the snaxel distance to vary each point on a contour ha a unique corresponding point in thenext frame experimental result showed that the proposed method computes accurate optical flow vector for various moving contour 
we present a formal methodology for the integration of optical flow and deformable model the optical flow constraint equation provides a non holonomic constraint on the motion of the deformable model in this augmented system force computed from edge and optical flow are used simultaneously when this dynamic system is solved a model based least square solution for the optical flow is obtained and improved estimation result are achieved the use of a d model reduces or eliminates problem associated with optical flow computation this approach instantiates a general methodology for treating visual cue a constraint on deformable model we apply this framework to human face shape and motion estimation our d deformable face model us a small number of parameter to describe a rich variety of face shape and facial expression we present experiment in extracting the shape and motion of a face from image sequence 
the paper present an agent based surveillance system for use in monitoring scene involving both pedestrian and vehicle the surveillance system supply textual description for the dynamic activity occurring in the d world these are derived by mean of dynamic andprobabilistic inference based on geometric information provided by a vision system that track vehicle and pedestrian the symbolic scene annotation is given at two major level of description the object level and the interobject level at object level each tracked object pedestrian or vehicle is assigned a behaviour agent which us a bayesian network to infer the fundamental feature of the object trajectory and continuously update it textual description the inter object interaction level is interpreted by a situation agent which is created dynamically when two object are in close proximity 
we propose a novel appr oach to programa robot by demonstrating the task multiple number of time in front of a vision system here we integrate human dexterity with sensory data using computer vision technique in a single platform a simultaneous feature detection and tracking framework is used to track various feature finger tip and the wrist joint a kalman filter doe the tracking by predicting the tentative feature location and a ho based data clustering algorithm extract the feature color information of the feature are used for establishing correspondence a fast efficient and robust algorithm for the vision system thus developed process a binocular video sequence to obtain the trajectory and the orientation information of the end effector the concept of a trajectory bundle is introduced to avoid singularity and to obtain an optimal path 
this paper present an algorithm for detecting localizingand grouping instance of repeated scene element the grouping is representedby a graph where node correspond to individual element andarcs join spatially neighboring element associated with each arc is anaffine map that best transforms the image patch at one location to theother the approach we propose consists of step detecting quot interesting quot element in the image matching element with their neighbor 
we present a class of pde based algorithm suitable for a wide range of image processing application the technique are applicable to both saltand pepper grey scale noise and full image continuous noise present in black and white image grey scale image texture image and color image at the core the technique rely on a level set formulation of evolving curve and surface and the viscosity in profile evolution essentially the method consists of moving the isointensity contour in a image under curvature dependent speed law to achieve enhancement compared to existing technique our approach ha several distinct advantage first it contains only one enhancement parameter which in most case is automatically chosen second the scheme automatically stop smoothing at some optimal point continued application of the scheme produce no further change third the method is one of the fastest possible scheme based on a curvature controlled approach 
in this paper we propose a method for locating d position of a soccer ball from monocular image sequence of soccer game toward this goal we adopted ground model to image transformation together with physic based approach that a ball follows the parabolic trajectory in the air by using the transformation the height of a ball can be easily calculated using simple triangular geometric relation given the start and the end position of the ball on the ground here the height of a ball are determined in term of a player s height even if the end position of a ball is not given on the ground due to kicking or heading of a falling ball before it touch the ground the most probable trajectory can be determined by searching based on the physical fact that the ball follows a parabolic trajectory in the air we have tested and experimented with a real image sequence the result of which seem promising 
we consider the problem of feature based face recognition in the setting where only a single example of each face is available for training the mixture distance technique we introduce achieves a recognition rate of on a database of people in which each face is represented by measured distance this is currently the best recorded recognition rate for a feature based system applied to a database of this size by comparison nearest neighbor search using euclidean distance yield in our work a novel distance function is constructed based on local second order statistic a estimated by modeling the training data a a mixture of normal density we report on the result from mixture of several size we demonstrate that a flat mixture of mixture performs a well a the best model and therefore represents an effective solution to the model selection problem a mixture perspective is also taken for individual gaussians to choose between first order variance and second order covariance model here an approximation to flat combination is proposed and seen to perform well in practice our result demonstrate that even in the absence of multiple training example for each class it is sometimes possible to infer from a statistical model of training data a significantly improved distance function for use in pattern recognition 
this paper present a novel technique for the estimation of global nonrigid motion without using point correspondence the completedescription of the nonrigid motion of an object involves specifying a displacement vector at each point of the object such a description provides a large amount of information which need to be processed further in order to study the global characteristic of the deformation nonrigid motion can be studied hierarchically in term of a global nonrigid motion and point by point local nonrigid motion the technique presented in this paper give a method for estimating a global a fine or polynomial transformation between two object the novelty of the technique lie in the fact that it doe not use any point correspondence our method us hyper quadric model to model the data and estimate the global deformation we show that affine or polynomial transformation between two data set can be recovered from the hyper quadric parameter the usefulness of the technique is two fold first it pave the way for viewing nonrigid motion hierarchically in term of global and local motion second it can be used a a front end to other motion analysis technique that assume small motion for instance most nonrigid motion analysis algorithm make some assumption on the type of nonrigid motion conformal motion small motion etc that are not always satisfied in practice when the motion between two data set is large our algorithm can be used to estimate the affine transformation which includes scale and shear or a polynomial transformation between the two data set which can then be used to warp the first data set closer to the second so a to satisfy the small motion assumption we present experiment result with real and synthetic and data 
image sequence analysis for real time application requires high quality and highly efficient algorithm for tracking a there is no time to do the costly object recognition each time a new image is captured tracking with projection histogram revealed amazing result compared with standard correlation method tracker based on projection histogram performed up to better than the reference method on a common test set the new template based method relying on projection histogram rph is described and compared with two commonly known template based method namely the normalized cross correlation ncc and displaced frame distance dfd method the input to the system consists of live or recorded video data where filterbased preprocessing can be applied before tracking in order to enhance feature such a edge texture etc a region of interest roi is taken a a template for tracking in subsequent image tracking exploit a kalman filtered local search in order to renew correspondence between the object template and the new object location comparative test were performed with real live image sequence taken in underground station tracking with projection histogram outperformed tracking by ncc and dfd on grey level image sequence a well a on edge enhanced image sequence even the worst chosen parameter set for tracking by the new rph method resulted in better tracking a with the best one for both ncc and dfd 
a face recognition system is described which employ a fuzzy information fusion technique to increase the over all recognition rate the face image are searched for locating head area and face boundary the eye and mouth are detected using rigid and deformable template assuming a d head model the face rotation are estimated which allows for compensating rotated facial feature back to a front upright view each facial feature form a source of information for classification based on a correlation technique using eye forehead mouth and nose window three classifier are established the output of each classifier is taken a a partial evidence in classification the importance of each source is measured using a fuzzy density measure and the final classification is achieved using a fuzzy evidence aggregation method the performance of the system is evaluated using a combined match score 
we devise a statistical framework for edge detection by performing a statistical analysis of zero crossing of the second derivative of an image this analysis enables u to estimate at each pixel of an image the probability that an edge pass through the pixel we present a statistical analysis of the lindeberg operator that we use to compute image derivative we also introduce a confidence probability that tell u how reliable the edge probability is given the image s noise level and the operator s scale combining the edge and confidence probability lead to a probabilistic scale selection algorithm we present the result of experiment on natural image 
the compact description of a video sequence through a single image map and a dominant motion ha application in several domain including video browsing and retrieval compression mosaicing and visual summarization building such a representation requires the capability to register all the frame with respect to the dominant object in the scene a task which ha been in the past addressed through temporally localized motion estimate in this paper we show how the lack of temporal consistency associated with such estimate can undermine the validity of the dominant motion assumption leading to oscillation between different scene interpretation and poor registration to avoid this oscillation we augment the motion model with a generic temporal constraint which increase the robustness against competing interpretation leading to more meaningful content summarization 
the spectral property of outdoor illumination function can vary significantly due to atmospheric condition and scene geometry we show using a statistical analysis of a comprehensive physical model that the variation in outdoor illumination function over both the visible range m m and the visible near infrared range m m can be represented accurately by use of seven dimensional linear model the physical model includes solar and scattered radiation a well a the effect of atmospheric gas and aerosol the modtran code wa employed for computing radiative transfer aspect of the model we show that the new model ha strong agreement over the visible wavelength with the empirical study of judd et al we also demonstrate the accuracy of the model over the m m spectral range using measured outdoor illumination function 
in the literature we find two class of algorithm which on the basis of two view of a scene recover the rigid transformation between the view and subsequently the structure of the scene the first class contains technique which require knowledge of the correspondence or the motion field between the image and are based on the epipolar constraint the second class contains so called direct algorithm which require knowledge about the value of the flow in one direction only and are based on the positive depth constraint algorithm in the first class achieve the solution by minimizing a function representing deviation from the epipolar constraint while direct algorithm find the d motion that when used to estimate depth produce a minimum number of negative depth value this paper present a stability analysis of both class of algorithm the formulation is such that it allows comparison of the robustness of algorithm in the two class a well a within each class specifically a general statistical model is employed to express the function which measure the deviation from the epipolar constraint and the number of negative depth value and these function are studied with regard to their topographic structure specifically a regard the error in the d motion parameter at the place representing the minimum of the function the analysis show that for algorithm in both class which estimate all motion parameter simultaneously the obtained solution ha an error such that the projection of the translational and rotational error on the image plane are perpendicular to each other furthermore the estimated projection of the translation on the image lie on a line through the origin and the projection of the real translation 
a new boundary detection approach for shape modeling is presented itdetects the global minimum of an active contour model s energybetween two end point initialization is made easier and the curveis not trapped at a local minimum by spurious edge we modify the snake energy by including the internal regularization term in theexternal potential term our method is based on finding a path ofminimal length in a riemannian metric we then make use of a newefficient numerical method to find this shortest path it is shown that the proposed energy though based only on apotential integrated along the curve imposes a regularization effectlike snake we explore the relation between the maximum curvaturealong the resulting contour and the potential generated from the image the method is capable to close contour given only one point on theobjects boundary by using a topology based saddle search routine we show example of our method applied to real aerial andmedical image 
an unsupervised algorithm for arranging an image database a a binary tree is described tree node are associated with image subset maintaining the property that the similarity among the image associated with the child of a node is higher than the similarity among the image associated with the parent node experiment with datasets of hundred and thousand of image show that shallow tree can produce clustering into meaningful class visual content search tree can be used to automate image retrieval by content orhelp a human to interactively search for image 
because of the size of the world wide web and it inherentlack of structure finding what one is looking for can bea challenge in fact some of the most highly visited website are search engine however while web page typicallycontain both text and image most currently availablesearch engine only index text this paper describeswebseer a system for locating image on the web webseeruses image content in addition to associated text toindex image the image analysis is designed 
this paper proposes a method for detecting obstacle on a runway by controlling their expected disparity by approximating the runway by a planar surface the initial model flow field mff corresponding to an obstacle free runway is described by the data from on board sensor ob the error variance of the initial mff is computed and used to estimate the mff obstacle are detected by comparing the expected residual flow disparity with the residual flow field rff estimated after warping or stabilizing an image using the mff expected temporal and spatial disparity are obtained from the use of the ob this allows u to control the residual disparity by increasing the temporal baseline and or by utilizing the spatial baseline if distant object cannot be detected for a given temporal baseline experimental result for two real flight image sequence are presented 
affine invariant medial ax and symmetry set of planar shape are intr oduced and studied in this paper two different approach are presented the first one is based on affine invariant distance and defines the symmetry set a set containing the medial axis a the closure of the locus of point on at least two affine normal and affine equidistant from the corresponding point on the curve the second approach is based on a affine bitangent conic in this case the symmetry set is defined a the closure of the locus of center of conic with at least three point contact with two or more distinct point on the curve this is equivalent to conic and curve having at those point the same affine tangent or the same euclidean tangent and curvature although the two analogous definition for the classical euclidean symmetry set medial axis are equivalent this is not the case for the affine group we then show how to use the symmetry set to detect affine skew symmetry proving that the contact based symmetry set is a straight line if and only if the given shape is the affine transformation of a symmetric object 
this paper report novel algorithm for the efficient localization and recognition of vehicle in traffic scene which eliminate the need for explicit symbolic feature extraction and matching the algorithm make use of two a priori source of knowledge about the scene and the object i the ground plane constraint and ii the fact that road vehicle are strongly rectilinear the algorithm are demonstrated and tested using routine outdoor traffic image success with a variety of vehicle demonstrates the efficiency and robustness of context based computer vision in road traffic scene the limitation of the algorithm are also addressed in the paper 
this paper present sitecity a semi automated building extraction system integrating photogrammetry geometric constraint and image understanding algorithm existing automated building extraction system produce mixed result and it is clear that human intervention is required to correct mistake from fully automated system sitecity give human operator the ability to construct and manipulate three dimensional building object using multiple image image understanding algorithm are integrated into sitecity to assist user the automated process in sitecity use user delineated roof boundary a cue and attempt to locate the floor of a building and match the building object in other image in addition photogrammetric cue are used to assist automated process these automated process are described and their performance is evaluated illustrating that automated process in sitecity produce comparable performance to that of human subject 
we present a new approach for resolving occlusion in augmented reality the main interest is that it doe not require d reconstruction of the considered scene our idea is to use a contour based approach and to label each contour point a being behind or in front of depending on whether it is in front of or behind the virtual object this labeling step only requires that the contour can be tracked from frame to frame a proximity graph is then built in order to group the contour that belong to the same occluding object finally we use some kind of active contour to accurately recover the mask of the occluding object 
we present a shape based method of indexing to model aspect from a single intensity image object are assumed to be rigid a model aspect is represented by a d edgemap and the part of the object silhouette part decomposition is derived from a codon representation of the object silhouette invariant feature extracted from each part are then used to index into a hash table to generate model aspect hypothesis knowledge about part is incorporated in voting scheme to order hypothesis for efficient verification of candidate model verification of model aspect hypothesis is carried out by an alignment algorithm that is robust to partial occlusion result of test using model aspect from object demonstrate that accurate recognition can be achieved with very few verification attempt 
tracking the d contour of a moving object ha widely been used in the past year so called active contour model have been proven to be a promising approach to real time tracking of deformable object also tracking d contour which are projection of rigid d object is reduced to tracking deformable d contour there the deformation of the contour are caused by the movement in d and the changing perspective to the camera in this paper a combination of d and d shape description is presented which can be applied to the prediction of change in d contour which are caused by movement in d only coarse d knowledge is provided which is automatically acquired in a training step then the reconstructed d model of the object is used to predict the shape of the d contour thus limitation of the contour point search in the image is possible which reduces the error in the contour extraction caused by heterogenous background the experimental part show that the proposed combination of d and d shape description is efficient and accurate with respect to real time contour extraction and tracking 
in this paper we focus on using local d structure for segmentation a tensor descriptor is estimated for each neighbourhood i e for each voxel in the data set the tensor are created from a combination of the output form a set of d quadrature filter the shape of the tensor describe locally the structure of the neighborhood in term of how much it is like a plane a line and a sphere we apply this to segmentation of bone from computer tomography data ct traditional method are based purely on gray level value discrimination and have difficulty in recovering thin bone structure due to so called partial voluming a problem which is present in all such sampled data we illuminate the partial voluming problem by showing that thresholding creates complicated artifact even if the signal is densely enough sampled and can be perfectly reconstructed the unwanted effect of thresholding can be reduced by a change of the signal basis we show that by using additional local structure information can significantly reduce the degree of sampling artifact evaluation of the method on a clinical case is presented the segmentation of a human skull from a ct volume the method show that many of the thin bone structure which disappear in a pure thresholding can be recovered 
a least square method simultaneously solves for the model to sensor suite pose and sensor to sensor registration the development is for a sensor suite containing separate range and optical sensor to address outlier and more generally match finding a statistical method median filtering and a search method local search are developed sensitivity to gaussian noise and the choice of initial pose estimate is investigated on synthetic data both of the matching method are demonstrated on real data 
common object such a people and car comprisemany visual part and attribute yet image based trackingalgorithms are often keyed to only one of a target sidentifying characteristic in this paper we presenta framework for combining and sharing informationamong several state estimation process operating onthe same underlying visual object well known techniquesfor joint probabilistic data association areadapted to yield increased robustness when multipletrackers attuned to 
we address the problem of locating a gray level pattern in a gray level image the pattern can have been transformed by an affine transformation and may have undergone some additional change we define a difference function based on comparing each pixel of the pattern with a window in the image and search efficiently for transformation that minimize the difference function the search is guaranteed it will always find the transformation minimizing the difference function and not get fooled by a local minimum it is also efficient in that it doe not need to examine every transformation in order to achieve this guarantee this technique can be applied to object location motion tracking optical flow or block based motion compensation in video image sequence compression e g mpeg 
we previously presented a framework for segmentation of complex scene using multiple physical hypothesis for simple image region a consequence of that framework wa a proposal for a new approach to the segmentation of complex scene into region corresponding to coherent surface rather than merely region of similar color herein we present an implementation of this new approach and show example segmentation for scene containing multi colored piece wise uniform object using our approach we are able to intelligently segment scene with object of greater complexity than previous physic based segmentation algorithm the result show that by using general physical model we obtain segmentation that correspond more closely to coherent surface in the scene than segmentation found using only color 
different instance of a handwritten word consist of the same basic feature hump cusp crossing etc arranged in a deformable spatial pattern thus keywords in cursive text can be detected by looking for the appropriate feature in the correct spatial configuration a keyword can be modeled hierarchically a a set of word fragment each of which consists of lower level feature to allow flexibility the spatial configuration of keypoints within a fragment is modeled using a dryden mardia dm probability density over the shape of the configuration in a writer dependent test on a transcription of the declaration of independence word character the method detected all eleven instance of the keyword government with only four false positive 
volume intersection algorithm are used to reconstruct incomplete object from their silhouette an imagined light source is moved about the data and the cumulative amount of light seen at each point in space is interpreted a indicating the likelihood that the point is inside the object the object data need not be uniformly distributed nor exclusively surface data explicit distinction between noise surface and interior data is avoided the novel concept of a localised viewing region is introduced to overcome the inherent inability of volume intersection algorithm to reconstruct concave surface algorithm for d pixel and d voxel data are described and applied to d ultra sound data 
the problem of non parametric probability density function pdf estimation using radial basis function rbf neural network is addressed here we investigate two criterion based on a modified kullback leibler distance that lead to an appropriate choice of the network architecture complexity in the first criterion the modification consists in the addition of a term that penalizes complex architecture mpl criterion the second strategy involves the regularization of the network through the imposition of lower bound on the standard deviation derived from condition of existence of rejection test lbsd criterion experimental result indicate that the mpl criterion outperforms the lbsd method 
a new algorithm and systematic evaluation is presented for searching a database via relevance feedback it represents a new image display strategy for the pichunter system the algorithm take feedback in the form of relative judgment item a is more relevant than item b a opposed to the stronger assumption of categorical relevance judgment item a is relevant but item b is not it also exploit a learned probabilistic model of human behavior to make better use of the feedback it obtains the algorithm can be viewed a an extension of indexing scheme like the k d tree to a stochastic setting hence the name stochastic comparison search in simulation the amount of feedback required for the new algorithm scale like log d where d is the size of the database while a simple query by example approach scale like d a where a 
this paper describes a probabilistic decomposition of human dynamic at multiple abstraction and show how to propagate hypothesis across space time and abstraction level recognition in this framework is the succession of very general low level grouping mechanism to increased specific and learned model based grouping technique at higher level hard decision threshold are delayed and resolved by higher level statistical model and temporal context low level primitive are area of coherent motion found by em clustering mid level category are simple movement represented by dynamical system and high level complex gesture are represented by hidden markov model a successive phase of simple movement we show how such a representation can be learned from training data and apply it to the example of human gait recognition 
this paper is concerned with surface shape estimation by a method in which an empirically determined associative model relating appearance to surface shape is used significantly the estimated model is more accurate than the algorithm that generates the example the method presented here is a generalization of shape from shading method that doe not rely upon idealized model of the image formation process a a relative of shape from shading this method more accurately recovers small surface detail than is possible with method such a stereo and motion the present approach is a continuous analogue of pattern recognition and is closely related to method of joint space learning used in robotics experiment on real scene are used to illustrate the concept involved 
a new framework and method based on image motion trajectory in spatiotemporal space x y t space are proposed to estimate image velocity from an image sequence we focus on the surface of the trajectory in the x y t space formed by the edge and contour of moving object and obtain image velocity from the orientation of the intersection line formed by tangent plane on the trajectory the proposed method includes two hough transforms to detect the most dominant orientation in all possible intersection line and reliably produce the dominant translational image velocity semi locally also the confidence measure of estimate is defined to decide the optimal size of patch that suppresses the aperture problem experimental result from several synthetic and real image sequence are presented to verify the effectiveness of the method and to confirm it robustness against noise and occlusion 
this paper describes an application of the hierarchical mixture of expert algorithm to the registration of multiple cartographic model to noisy radar data according to the hme algorithm each model is represented by a set of maximum likelihood registration parameter together with a set of matching probability this architecture can be viewed a providing simultaneous registration and hypothesis verification the map in the cartographic data base compete to account for radar data through the imposed probability normalization the resulting matching algorithm can be regarded a a generic tool for model retrieval from a data base our evaluation on radar image illustrates some of the characteristic of the algorithm our main conclusion are that the method is both robust to added image noise and poor initialization 
to make a euclidean reconstruction of the world seen through a stereo rig we can either use a calibration grid and the result will rely on the precision of the grid and the extracted point of interest or use self calibration past work on self calibration is focussed on the use of only one camera and give sometimes very unstable result in this paper we use a stereo rig which is supposed to be weakly calibrated using a method such a the one described in deriche et al then by matching two set of point of the same scene reconstructed from different point of view we try to find both the homography that map the projective reconstruction to the euclidean space and the displacement from the first set of point to the second set of point we present result of the euclidean reconstruction of a whole object from uncalibrated camera using the method proposed here 
a factorization method is proposed for recovering camera motion and object shape from point correspondence observed in multiple image with perspective projection for any factorization based approach for perspective image scaling parameter called projective depth must be estimated in order to obtain a measurement matrix that could be decomposed into motion and shape one possible approach proposed by sturm and triggs is to compute projective depth from fundamental matrix and epipoles the estimation process of the fundamental matrix however might be unstable if the measurement noise is large or the camera and the object point are nearly in critical configuration in this paper the author propose an algorithm by which the projective depth are iteratively estimated so that the measurement matrix is made to be a close a possible to rank this estimation process requires no fundamental matrix computation and is therefore robust against measurement noise camera motion and shape in d projective space are then recovered by factoring the measurement matrix computed from the obtained projective depth the author also derive metric constraint for a perspective camera model in the case where the intrinsic camera parameter are available and show that these constraint can be linearly solved for a projective transformation which relates projective and euclidean description of the scene structure using this transformation the projective motion and shape obtained in the previous factorization step is upgraded to metric description that is represented with respect to the euclidean coordinate frame the validity of the proposed method is confirmed by experiment with real image 
we address the problem of automatically reconstructing m manifold of unknown topology from unorganized point in metric p space obtained from a noisy measurement process the point set is first approximated by a collection of oriented primitive fuzzy set over a range of resolution hierarchical multiresolution representation is then computed based on the relation of relative containment defined on the collection finally manifold structure is recovered by establishing connectivity between these primitive based on proximity compatibility of position and orientation and local topological constraint the method ha been successfully applied to the problem of surface reconstruction from polynocular stereo data with many outlier 
flexible model of object class based on linear combination of prototypical image are capable of matching novel image of the same class and have been shown to be a powerful tool to solve several fundamental vision task such a recognition synthesis and correspondence the key problem in creating a specific flexible model is the computation of pixelwise correspondence between the prototype a task done until now in a semiautomatic way in this paper we describe an algorithm that automatically bootstrap the correspondence between the prototype the algorithm which can be used for d image a well a for d model is shown to synthesize successfully a flexible model of frontal face image and a flexible model of handwritten digit 
a fast stereo algorithm based on aliasing effect of simple disparity estimator within a coherence detection scheme is presented the algorithm calculates dense disparity map with subpixel precision by performing local spatial filter operation and simple arithmetic transformation performance similar to classical area based approach is achieved but without the complicated hierarchical search structure typical for these approach the algorithm is completely parallel the disparity value are calculated independently for each pixel in addition local validation count for the disparity estimate and a fused cyclopean view of the scene are available within the proposed network structure for coherence based stereo 
a new algorithm for graph matching which us graduated assignment is presented along with experimental result demonstrating large improvement in speed and accuracy over previous technique the softassign a novel constraint satisfaction technique is applied to a new graph matching energy function that us a robust sparse distance measure between the link of the two graph the softassign which ha emerged out of the neural network statistical physic framework enforces two way assignment constraint without the use of penalty term the algorithm s low order computational complexity lm where l and m are the number of link in the two graph compare favorably with most competing approach the method not restricted to any special class of graph is applied to subgraph isomorphism weighted graph matching and attributed relational graph matching experiment on graph generated from image and on randomly generated graph including benchmark against a relation labeling algorithm and an algorithm employing potts glass dynamic are reported over twenty five thousand experiment were conducted no comparable result have been reported by any other graph matching algorithm before in the research literature 
recovering three dimensional d information of a scene from it image is a fundamental problem in computer vision there exists two major multi ocular cue for it namely the motion cue and the stereo cue this paper present a new approach of integrating the two cue when two camera that move through the scene while taking picture repeatedly are available the approach is based on the singular value decomposition svd technique with which the d structure of the scene the image projection parameter the motion parameter and the stereo geometry are all separated the approach offer the advantage of both cue simple correspondence a well a accurate reconstruction it can also work with relatively short image sequence 
region based image segmentation technique make use ofsimilarity in intensity color and texture to determine the partitioning ofan image the powerful cue of contour continuity is not exploited at all in this paper we provide a way of incorporating curvilinear grouping intoregion based image segmentation soft contour information is obtainedthrough orientation energy weak contrast gap and subjective contoursare completed by contour propagation the normalized cut approach 
this paper introduces a new real time method to estimate the posture of a human from thermal image acquired by an infrared camera regardless of the background and lighting condition distance transformation is performed for the human body area extracted from the thresholded thermal image for the calculation of the center of gravity after the orientation of the upper half of the body is obtained by calculating the moment of inertia significant point such a the top of the head the tip of the hand and foot are heuristically located in addition the elbow and knee position are estimated from the detected significant point using a genetic algorithm based learning procedure the experimental result demonstrate the robustness of the proposed algorithm and real time faster than frame per second performance 
in this paper we introduce a novel geometric shape modeling scheme which allows for representation of global and local shape characteristic of an object geometric model are traditionally well suited for representing global shape but not the local detail however in this paper we propose a powerful geometric shape modeling scheme which allows for the representation of global shap e with local detail and permit model shaping a well a topological change via physic based control the proposed modeling scheme consists of representing shape by pedal curve and surface pedal curve surface are the locus of the foot of perpendicular to the tangent of a fixed curve surface from a fixed point called the pedal point by varying the location of the pedal point one can synthesize a large class of shape which exhibit both local and glob al deformation we introduce physic based control for shaping these geometric model by letting the pedal point vary and use a dynamic spline to represent the position of this varying pedal point the model dubbed a a snake pedal allows for interactive manipulation via force applied to the snake we demonstrate the applicability of this modeling scheme via example of shape synthesis and shape estimation from real image data 
we present a new efficient stereo algorithm addressing robust disparity estimation in the presence of occlusion the algorithm is an adaptive multi window scheme using left right consistency to compute disparity and it associated uncertainty we demonstrate and discus performance with both synthetic and real stereo pair and show how our result improve on those of closely related technique for both robustness and efficiency 
a general technique for the recovery of significant image feature is presented the technique is based on the mean shift algorithm a simple nonparametric procedure for estimating density gradient drawback of the current method including robust clustering are avoided feature space of any nature can be processed and a an example color image segmentation is discussed the segmentation is completely autonomous only it class is chosen by the user thus the same program can produce a high quality edge image or provide by extracting all the significant color a preprocessor for content based query system a spl time color image is analyzed in le than second on a standard workstation gray level image are handled a color image having only the lightness coordinate 
recent research in image sensor ha produced camera with very large field of view an area of computer vision research which will benefit from this technology is the computation of camera motion ego motion from a sequence of image traditional camera suffer from the problem that the direction of translation may lie outside of the field of view making the computation of camera motion sensitive to noise in this paper we present a method for the recovery of ego motion using omnidirectional camera noting the relationship between spherical projection and wide angle imaging device we propose mapping the image velocity vector to a sphere using the jacobian of the transformation between the projection model of the camera and spherical projection once the velocity vector are mapped to a sphere we show how existing ego motion algorithm can be applied and present some experimental result these result demonstrate the ability to compute ego motion with omnidirectional camera 
this paper we develop geometric relationship between the residual planar parallax displacementsof pair of point these geometric relationship address the problem of d scene analysiseven in difficult condition i e when the epipole estimation is ill conditioned when there is a smallnumber of parallax vector and in the presence of moving object we show how these relationshipscan be applied to each of the three problem outlined at the beginning of this section moreover the 
planar pose measurement from image is an important problem for automated assembly and inspection in addition to accuracy and robustness ease of use is very important for real world application recently murase and nayar have presented the parametric eigenspace for object recognition and pose measurement based on training image although their system is easy to use it ha potential problem with background clutter and partial occlusion we present an algorithm that is robust in these term it us several small feature on the object rather than a monolithic template these eigenfeatures are matched using a median statistic giving the system robustness in the face of background clutter and partial occlusion we demonstrate our algorithm s pose measurement accuracy with a controlled test and we demonstrate it detection robustness on cluttered image with the object of interest partially occluded 
we present a new clustering algorithm that address two major issue associated with conventional partitional clustering the difficulty in determining the number of cluster and the sensitivity to noise and outlier the proposed algorithm determines the number of cluster by a process of competitive agglomeration noise immunity is achieved by integrating concept from robust statistic into the algorithm the proposed approach can incorporate different distance measure in the objective function to find an unknown number of cluster of various type including line plane and surface 
this paper considers a specific problem of visual perception of motion namely the problem of visual detection of independent d motion most of the existing technique for solving this problem rely on restrictive assumption about the environment the observer s motion or both moreover they are based on the computation of optical flow which amount to solving the ill posed correspondence problem in this work independent motion detection is formulated a robust parameter estimation applied to the visual input acquired by a binocular rigidly moving observer depth and motion measurement are combined in a linear model the parameter of this model are related to the parameter of self motion egomotion and the parameter of the stereoscopic configuration of the observer the robust estimation of this model lead to a segmentation of the scene based on d motion the method avoids the correspondence problem by employing only normal flow field experimental result demonstrate the effectiveness of this method in detecting independent motion in scene with large depth variation without any constraint imposed on observer motion 
the problem of model selection is relevant to many area of computer vision model selection criterion have been used in the vision literature and many more have been proposed in statistic but the relative strength of these criterion have not been analyzed in vision more importantly suitable extension to these criterion must be made to solve problem unique to computer vision using the problem of surface reconstruction a our context we analyze existing criterion using simulation and sensor data introduce new criterion from statistic develop novel criterion capable of handling unknown error distribution and outlier and extendmodel selection criterion to apply to the surface merging problem the new surface merging rule improve upon previous result and work well even at small step height h and crease discontinuity our result show that a bayesian criterion and it bootstrapped variant perform the best although for time sensitive application a variant of the akaike criterion may be a better choice unfortunately none of the criterion work reliably for small region size implying that model selection and surface merging should be avoided unless the region size is sufficiently large 
this paper describes a methodology to interpret the information from telephone company dsx assignment table drawing horizontal line are found using an efficient algorithm that work over the run length encoded representation of the image for vertical line the image is transposed using an efficient method we developed and the algorithm for horizontal line is applied again using the information about the line the tabular structure are extracted by finding biconnected component on the graph formed by the line and their intersection a methodology ha also been developed for the representation of end access to the entry inside the table 
this paper describes a new approach for tracking rigid and articulated object using a view based representation the approach build on and extends work on eigenspace representation robust estimation technique and parameterized optical flow estimation first we note that the least square image reconstruction of standard eigenspace technique ha a number of problem and we reformulate the reconstruction problem a one of robust estimation second we define a subspace constancy assumption that allows u to exploit technique for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image to account for large affine transformation between the eigenspace and the image we define an eigenpyramid representation and a coarse to fine matching strategy finally we use these technique to track object over long image sequence in which the object simultaneously undergo both affine image motion and change of view in particular we use this eigentracking technique to track and recognize the gesture of a moving hand view based object representation have found a number of expression in the computer vision literature in particular in the work on eigenspace representation eigenspace representation provide a compact approximate encoding of a large set of training image in term of a small number of orthogonal basis image these basis image span a subspace of the training set called the eigenspace and a linear combination of these image can be used to approximately reconstruct any of the training image previous work on eigenspace representation ha focused on the problem of object recognition and ha only peripherally addressed the problem of tracking object over time additionally these eigenspace reconstruction method are not invariant to image transformation such a translation scaling and rotation previous approach have typically assumed that the object of interest can be located in the scene segmented and transformed into a canonical form for matching with the eigenspace in this paper we will present a robust statistical framework for reconstruction using the eigenspace that will generalize and extend the previous work in the area to ameliorate some of these problem the work combine line of research from object recognition using eigenspaces parameterized optical 
in this paper we undertake a systematic investigation of affine invariant object detection edge detection is first presented from the point of view of the affine invariant scale space obtained by curvature based motion of the image level set in this case affine invariant edge are obtained a a weighted difference of image at different scale we then introduce the affine gradient a the simplest possible affine invariant differential function which ha the same qualitative behavior a the euclidean gradient magnitude these edge detector are the basis both to extend the affine invariant scale space to a complete affine flow for image denoising and simplification and to define affine invariant active contour for object detection and edge integration the active contour are obtained a a gradient flow in a conformally euclidean space defined by the image on which the object is to be detected that is we show that object can be segmented in an affine invariant manner by computing a path of minimal weighted affine distance the weight being given by function of the affine edge detector the geodesic path is computed via an algorithm which allows to simultaneously detect any number of object independently of the initial curve topology 
in this paper the computation of medial axis is posed a a statistical inference problem not a a mathematical transform this method provides answer to two essential problem in computing the medial axis representation i prior knowledge are adopted for ax and junction so that the ax around junction become well defined ii a stochastic jump diffusion process is proposed for estimating medial axis in a markov random field we argue that the stochastic algorithm for computing medial axis is compatible with existing algorithm for image segmentation such a snake and region competition thus it provides a new direction for computing medial axis from real textured image experiment are demonstrated on both synthetic and real shape 
this paper concern the influence of edge direction on the estimation of edge contrast and orientation we show that the gradient estimated using radial filter is not affected by edge orientation for non radial filter the gradient can be affected by edge orientation for instance we find that the estimated edge orientation using a non radial filter may be biased even if the signal is noise free however there are non radial filter for which gradient is unaffected by edge orientation a in the case of radial filter the property of these function are given in this paper the result are illustrated by the study of the canny deriche and shen castan detector we take into account discretization error these result give a clear indication of the effect of the rotation invariance property of an edge detector on it response thus providing a more precise meaning for this property in edge detection 
a method for detection and description of rectangular building from two or more registered aerial intensity image is proposed the output is a d description of the building with an associated confidence measure for each building hierarchical perceptual grouping and matching across view is employed to increase the robustness of the system verification of selected building hypothesis is done using shadow and wall evidence of the building the system is largely feature based grouping and matching are performed in a hierarchical manner utilizing primitive of increasing complexity starting with line segment and junction and proceeding to higher level feature binocular and trinocular epipolar constraint are used to reduce the search space for matching feature 
we present a new graph theoretic approach to the problem of image segmentation our method us local criterion and yet produce result that reflect global property of the image we develop a framework that provides specific definition of what it mean for an image to be underor over segmented we then present an efficient algorithm for computing a segmentation that is neither undernor over segmented according to these definition our segmentation criterion is based on intensity difference between neighboring pixel an important characteristic of the approach is that it is able to preserve detail in low variability region while ignoring detail in high variability region which we illustrate with several example on both real and sythetic image 
in this paper we introduce a method for distinguishing between informative and uninformativeviewpoints a they pertain to an active observer seeking to identify anobject in a known environment the method is based on a generalized inverse theoryusing a probabilistic framework where assertion are represented by conditionalprobability density function consequently the method also permit the assessmentof the belief associated with a set of assertion based on data acquired from a 
rigid motion imposes constraint on the motion of image point between the two image the matched point must conform to one of several possible constraint such a that given by the fundamental matrix or image image homography and it is essential to know which model to fit to the data before recovery of structure matching or segmentation can be performed successfully this paper compare several model selection method with a particular emphasis on providing a method that will work fully automatically on real imagery 
in this paper a minimax entropy principle is studied based on which a novel theory called frame filter random field and minimax entropy is proposed for texture modeling frame combine attractive aspect of two important theme in texture modeling multi channel filtering and markov random field mrf modeling it incorporates the response of a set of well selected filter into the distribution over a random field and hence ha a much stronger descriptive ability than the traditional mrf model furthermore it interprets and clarifies many previous concept and method for texture analysis and synthesis from a unified point of view algorithm are proposed for probability inference stochastic simulation and filter selection experiment on a variety of texture are described to illustrate our theory and to show the performance of our algorithm these experiment demonstrate that many texture previously considered a different category can be modeled and synthesized in a common framework 
wavelet transforms are attracting increasing interest in computer vision because they provide a mathematical tool for multiscale image analysis in this paper we show that i the subsampled wavelet multiresolution representation is translationally variant and ii a wavelet transform of a signal generally confounds the phase component of the analysing wavelet associated with that scale and orientation the importance of this observation is that commonly used feature in texture analysis also depend on this phase component this not only cause unnecessary spatial variation of feature at each scale but also make it more difficult to match feature across scale 
we address the problem of d object recognition from a single d image using a model database we develop a new method calledenhanced geometric hashing this approach allows u to solve for the indexingand the matching problem in one pas with linear complexity useof quasi invariant allows u to index image in a new type of geometrichashing table they include topological information of the observedobjects inducing a high numerical stability we also introduce a more robust 
we present a new approach to the tracking of very non rigid pattern of motion such a water flowing down a stream the algorithm is based on a disturbance map which is obtained by linearly subtracting the temporal average of the previous frame from the new frame every local motion creates a disturbance having the form of a wave with a head at the present position of the motion and a historical tail that indicates the previous location of that motion these disturbance serve a locus of attraction for tracking particle that are scattered throughout the image the algorithm is very fast and can be performed in real time we provide excellent tracking result on various complex sequence using both stabilized and moving camera showing a busy ant column waterfall rapid and flowing stream shopper in a mall and car in a traffic intersection 
this paper proposes an approach for automatic road extraction in aerial imagery which exploit the scale space behavior of road in combination with geometric constrained snake based edge extraction the approach not only ha few parameter to be adjusted but for the rst time allows for a bridging of shadow and partially occluded area using the heavily disturbed evidence in the image the road network is constructed after extracting crossing of various shape and topology reasonable result are obtained which are evaluated based on ground truth 
we define a new image feature called the color correlogram and use it for image indexing and comparison this feature distills the spatial correlation of color and is both effective and inexpensive for content based image retrieval the correlogram robustly tolerates large change in appearance and shape caused by change in viewing position camera zoom etc experimental evidence suggests that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement method for image indexing retrieval 
in this paper sequence of camera motion that lead to inherent ambiguity in uncalibrated euclidean reconstruction or self calibration are studied our main contribution is a complete detailed classification of these critical motion sequence cm the practically important class are identified and their degree of ambiguity are derived we also discus some practical issue especially concerning the reduction of the ambiguity of a reconstruction 
this paper proposes a method which estimate the relationship between learner s behavior and other agent one in the environment through interaction observation and action using the method of system identification in order to identify the model of each agent akaike s information criterion is applied to the result of canonical variate analysis for the relationship between the observed data in term of action and future observation next reinforcement learning based on the estimated state vector is performed to obtain the optimal behavior the proposed method is applied to a soccer playing situation where a rolling ball and other moving agent are well modeled and the learner s behavior are successfully acquired by the method computer simulation and real experiment are shown and a discussion is given 
this paper address the problem of characterizing the space formed by all image of a rigid set of n point observed by a weak perspective or paraperspective camera by taking explicitly into account the euclidean constraint associated with calibrated camera we showthat this space is a six dimensional variety embedded in ir n and parameterize it using the image position of three reference point this parameterization is constructed vialinear least square from point correspondence established across a sequence of image and it is used to synthesize new picture without any explicit three dimensional model degenerate scene and camera configuration are analyzed and experiment with real image sequence are presented 
this paper describes a novel framework for performing relational graph matching using genetic search the fitness measure is the recently reported global consistency measure of wilson and hancock the basic measure of relational distance underpinning the technique is hamming distance our standpoint is that genetic search provides a more attractive mean of performing stochastic discrete optimisation on the global consistency measure than alternative such a simulated annealing moreover the action of the optimisation process is easily understood in term of it action in the hamming distance domain we provide some experimental evaluation of the method in the matching of aerial stereograms 
we present an algorithm which us information from both surface reflectance and illumination variation to solve for colour constancy most colour constancy algorithm assume that the illumination across a scene is constant but this is very often not valid for real image the method presented in this work identifies and remove the illumination variation and in addition us the variation to constrain the solution the constraint is applied conjunctively to constraint found from surface reflectance thus the algorithm can provide good colour constancy when there is sufficient variation in surface reflectance or sufficient illumination variation or a combination of both we present the result of running the algorithm on several real scene and the result are very encouraging 
most of the recent color recognition indexing approach concentr ate on establishing invariance to illumination color to improve the utility of color recognition however other effect caused by illumination pose and specularity on three dimensional object surface have not received notable attention we present a chromaticity recognition method that discount the effect of illumination pose illumination color and specularity it utilizes a chromaticity space based on log ratio of sensor response for illumination pose and color invariance a model based specularity detection rejection algorithm can be used to improve the chromaticity recognition and illumination estimation for object including specular reflection 
image texture can arise not only from surface albedo variation ed texture but also from surface height variation d texture since the appearance of d texture depends on the illumination and viewing direction in a complicated manner such image texture can be called a bidirectional texture function a fundamental representation of image texture is the histogram of pixel intensity since the histogram of d texture also depends on the illumination and viewing direction in a complex fashion we refer to it a a bidirectional histogram in this work we present a concise analytical model for the bidirectional histogram of lambertian isotropic randomly rough surface which are common in real world scene we demonstrate the accuracy of the histogram model by fitting to several sample from the columbia utrecht texture database the parameter obtained from the model fit are roughness measure which can be used in texture recognition scheme in addition the model ha potential application in estimating illumination direction in scene where surface of known tilt and roughness are visible we demonstrate the usefulness of our model by employing it in a novel d texture synthesis procedure 
we explore the application of facial tracking to automated re animation to this end it is necessary to recover both head pose and facial expression from the facial movement of a performer however both effect are coupled this is a serious problem which previous study haven t fully considered the solution to this interaction problem proposed here is to solve explicitly at each timestep for pose and expression variable in principle this is a nonlinear inverse problem however appropriate parameterisation of pose in term of affine transformation with parallax and of expression in term of key frame reduces the problem to a bilinear one this can then be solved directly by singular value decomposition thus actor driven animation ha b een implemented in real time at video field rate using two indy desktop workstation 
an approach for perceptual segmentation of colour image texture is described a multiscale representation of the texture image generated by a multiband smoothing algorithm based on human psychophysical measurement of colour appearance is used a the input initial segmentation is achieved by applying a clustering algorithm to the image at the coarsest level of smoothing using these isolated em core cluster d colour histogram are formed and used for probabilistic assignment of all other pixel to the core cluster to form larger cluster and categorise the rest of the image the process of setting up colour histogram and probabilistic reassignment of the pixel is then propagated through finer level of smoothing until a full segmentation is achieved at the highest level of resolution 
we present in this paper a novel calibration method that us cross ratio to compute world point falling onto any given light stripe plane of a structured light system we show that by using known non coplanar set of collinear world point the direct x image to world transformation matrix for each light stripe plane can also be recovered from plane to plane homography preliminary experiment conducted with a calibration target and a mannequin suggest that this novel calibration method is robust and is applicable to many shape measurement task 
a new method is presented for robustly estimating multiple view relation from image point correspondence there are three new contribution the first is a general purpose method of parametrizing these relation using point correspondence the second contribution is the formulation of a common maximum likelihood estimate mle for each of the multiple view relation the parametrization facilitates a constrained optimization to obtain the mle the third contribution is a new robust algorithm mlesac for obtaining the point correspondence the method is general and it use is illustrated for the estimation of fundamental matrix image to image homographics and quadratic transformation result are given for both synthetic and real image it is demonstrated that the method give result equal or superior to previous approach 
we present an approach to recognition of complex object in cluttered d scene that doe not require feature extraction or segmentation our object representation comprises descriptive image associated with each oriented point on the surface of an object using a single point basis constructed from an oriented point the position of other point on the surface of the object can be described by two parameter the accumulation of these parameter for many point on the surface of the object result in an image at each oriented point these image localized description of the global shape of the object are invariant to rigid transformation through correlation of image point correspondence between a model and scene data are established and then grouped using geometric consistency the effectiveness of our algorithm is demonstrated with result showing recognition of complex object in cluttered scene with occlusion 
automatic d model acquisition and d tracking of simple object under motion using a single camera is often difficult due to the sparsity of information from which to establish the model we have developed an automatic scheme that first computes a simple pointalistic euclidean model of the object and then enriches this model using hyper patch these hyper patch contain information on both the orientation and intensity pattern variation of roughly planar patch on an object this information allows both the spatial and intensity distortion of the projected patch to be modelled accurately under d object motion we show that hyper patch not only can be computed automatically during model acquisition from a monocular image sequence but that they are also extremely appropriate for the task of visual tracking 
video convey information through several plane of communication encompassing what is represented in the image how the image are linked together and how the subject is imaged this feature is stressed in commercial where color editing effect rhythm and object motion are exploited to influence human purchasing habit in this paper based on research in the marketing field a link is formalized between low level feature of a commercial video and feeling that the video would inspire in the observer this link is used to define high level index capturing the main semantics of the video these index are embedded in a video retrieval system to support access to a database of video based on their semantics 
this paper deal with the problem of characterizing and parametrizing the manifold of trifocal tensor that describe the geometry of three view like the fundamental matrix characterizes the geometry of two the paper contains two new result first a new simpler set of algebraic constrai nt that characterizes the set of trifocal tensor is presented second we give a ne w parametrization of the trifocal tensor based upon those constraint which is also simpler than previously known parametrizations some preliminary experimental result of the use of these constraint and parametrization to estimate th e trifocal tensor from image correspondence are presented 
we present an incremental focus of attention ifa architecture for adding robustnessto software based real time motion tracker the framework provides a structurewhich when given the entire camera image to search efficiently focus the attentionof the system into a narrow set of configuration that includes the target configuration ifa offer a mean for automatic tracking initialization and reinitialization whenenvironmental condition momentarily deteriorate and cause the system 
in this paper we present a unified factorization algorithm for recovering structure and motion from image sequence by using point feature line segment and plane this new formulation is based on directional uncertainty model for feature point and line segment are both described by the same probabilistic model and so can be recovered in the same way prior information on the coplanarity of feature is shown to fit naturally into the new factorization formulation and provides additional constraint for the shape recovery this formulation lead to a weighted least square motion and shape recovery problem which is solved by an efficient quasi linear algorithm the statistical uncertainty model also enables u to recover uncertainty estimate for the reconstructed three dimensional feature location 
diffuse interreflection cause effect that make current theory of shape from shading unsatisfactory we show that distant radiating surface produce radiosity effect at low spatial frequency this mean that if a shading pattern ha a small region of support unseen surface in the environment can only produce effect that vary slowly over the support region it is therefore relatively easy to construct matching process for such pattern that are robustto interreflection we call region with these pattern shading primitive fold and groove on surface provide two example of shading primitive the shading pattern is relatively independent of surface shape at a fold or a groove and the pattern is localised we show that the pattern of shading can be predicted accurately by a simple model and derive a matching process from this model both groove and fold matcher are shown to work well on image of real scene 
we develop a method for recognizing color texture independent of rotation scale and illumination color texture is modeled using spatial correlation function defined within and between sensor band using a linear model for surface spectral reflectance with the same number of parameter a the number of sensor class we show that illumination and geometry change in the scene correspond to a linear transformation of the correlation function and a linear transformation of their coordinate a several step algorithm which includes scale estimation and correlation moment computation is used to achieve the invariance the key to the method is the new result that illumination and geometry change in the scene correspond to a specific transformation of correlation function zernike moment matrix these matrix can be estimated from a color image this relationship is used to derive an efficient algorithm for recognition the algorithm is substantiated using classification result on over image of color texture obtained under various illumination condition and geometric configuration 
in order to take advantage of the top speed of manipulator vision can not be tightly integrated into the motion control loop past visual servo control system have performed satisfactorily with this constraint however it can be shown that the task execution time can be reduced if the vision system is de coupled from the low level motor control system for reaching there is a trade off between the accuracy of a motion and the time requir ed to execute a motion in study of human motor contr ol this trade off is quantified by fitts law a relationship between the motion time the target distance and the target width these study suggest that vision is not used tightly within the control loop i e a a sensor that is servo ed on but rather vision is used to determine where the reaching target is and whether target ha been reached successfully through a simple robotic example we demonstrate that a similar trade off exists between motion accuracy and the motion execution time for visual guided robot reaching motion 
in this paper we propose and examine non parametric statistical test to define similarity and homogeneity measure for texture the statistical test are applied to the coefficient of image filtered by a multi scale gabor filter bank we will demonstrate that these similarity measure are useful for both texture based image retrieval and for unsupervised texture segmentation and hence offer an unified approach to these closely related task we present result on brodatz like micro texture and a collection of real word image 
a general active contour formulation is considered and a convexity analysis of it energy function is presented condition under which this formulation ha a unique solution are derived these condition involve both the active contour energy potential and the regularization parameter this analysis is then applied to four particular active contour formulation revealing important characteristic of their convexity and suggesting that external potential involving center of mass computation may be better behaved than the ususal potential based on image gradient most importantly our analysis provides an explanation for the poor convergence behavior at concave boundary and suggests an alternate algorithm for approaching these type of boundary 
image taken with wide angle camera tend to have severe distortion which pull point towards the optical center this paper proposes a new method for recovering the distortion parameter without using any calibration object the distortion cause straight line in the scene to appear a curve in the image our algorithm seek to find the distortion parameter that would map the image curve to straight line the user selects a small set of point along the image curve recovery of the parameter is formulated a the minimization of an objective function which is designed to explicitly account for noise in the selected image point experimental result are provided for synthetic data with different noise level a well a for real image the computed distortion parameter are used to undistort a video stream in real time using a look up table 
multiscale approach are an invaluable tool for image segmentation a vast amount of research ha been devoted to the construction of different multiscale representation of an image in this paper we use the hyperstack a multiscale linking model for image segmentation for an in depth comparison of four different scale space generator with respect to segmentation result we consider the linear gaussian scale space both in the spatial and the fourier domain the variable conductance diffusion according to the perona malik equation and the euclidean shortening flow we have done experiment on mr image of the brain for which a gold standard is available the hyperstack proof to be rather insensitive to the underlying scale space generator 
the surface growing framework presented by besl and jain ha served a the basis for many range segmentation technique it ha been augmented with alternative fitting technique model selection criterion and solid modelling component all of these approach however require global threshold and large isolated seed region range scene typically do not satisfy the global threshold assumption since it requires data noise characteristic to be constant throughout the scene furthermore a scene complexity increase the number of surface discontinuity and outlier increase hindering the identification of large seed region we present statistical criterion based on multivariate regression to replace the traditional decision criterion used in surface growing we use local estimate and their uncertainty to construct criterion which capture the uncertainty in extrapolating estimated fit we restrict surface expansion to very localized extrapolation increasing the sensitivity to discontinuity and allowing region to refine their estimate and uncertainty our approach us a small number of parameter which are either statistical threshold or cardinality measure i e we do not use threshold defined by specific range distance or orientation angle 
a testbed for automatic face recognition show an eigenface coding of shape free texture with manually coded landmark wa more effective than correctly shaped face being dependent upon high quality representation of the facial variation by a shape free ensemble configuration also allowed recognition these measure combine to improve performance and allowed automatic measurement of the face shape caricaturing further increased performance correlation of contour of shapefree image also increased recognition suggesting extra information wa available a natural model considers face a in a manifold linearly approximated by the two factor with a separate system for local feature 
in this paper we present new algorithm for target detection segmentation in second generation forward looking infra red flir image an initial detection algorithm that model the background using weibull function is used to identify candidate target location in the image a two stage focused analysis of each candidate target location is then performed to get an accurate representation of the target boundary a region growing procedure is used to get an initial estimate of the target region which is then combined with salient edge information in the image to arrive at a more accurate representation of the target boundary the region and edge integration is done using a novel method that us a bayes minimum risk classification approach finally to reduce the false alarm rate a higher level interpretation module is used to classify the detected area a man made or natural object using geometric and flir intensity based feature extracted from the target 
several vision problem can be reduced to the problem of fitting a linear surface of low dimension to data including the problem of structure from affine motion and of characterizing the intensity image of a lambertian scene by constructing the em intensity manifold for these problem one must deal with a data matrix with some missing element in structure from motion missing element will occur if some point feature are not visible in some frame to construct the intensity manifold missing matrix element will arise when the surface normal of some scene point do not face the light source in some image we propose a novel method for fitting a low rank matrix to a matrix with missing element we show experimentally that our method produce good result in the presence of noise these result can be either used directly or can serve a an excellent starting point for an iterative method 
we present a model of contour extraction in which the perceptual salience of contour arises from long range interaction between orientation selective filter it ha been previously shown that salient contour may be extracted from noisy image by using a number heuristic feature our algorithm is based on cortical mechanism and simulation show close agreement with result from recent anatomical physiological and psychophysical study including recent result of d j field et al i kovacs et al and m k kapadia et al the performance of the algorithm is demonstrated on a range of psychophysical stimulus and real image 
the foreground group in a scene may be discovered andcomputed a a factorized approximation to the pairwise affinity of theelements in the scene a pointwise approximation of the pairwise affinityinformation may in fact be interpreted a a saliency index and theforeground of the scene may be obtained by thresholding it an algorithmcalled affinity factorization is thus obtained which may be used forgrouping 
focus of attention mechanism for robot vision are discussed a new method for neglecting low level filter response from already modelled structure is presented the method is based on a filtering technique termed normalized convolution in one experiment the robot is continuously moving it arm in the scene while tracking other object it is shown how the arm can be made invisible so that only the moving object of interest is detected this make tracking of object much simpler in another experiment the attention of the system is shifted between object by simply cancelling the mask of the object to be attended to with this strategy the low level process do not need to know the difference between a new object entering the scene and a mask being cancelled and thus a complex communication structure between high and low level is avoided 
we describe a system that is being used to segment gray matter and create connected cortical representation from mri the method exploit knowledge of the anatomy of the cortex and incorporates structural constraint into the segmentation first the white matterand csf region in the mr volume are segmented using some novel technique of posterior anisotropic diffusion then the user selects the cortical white matter component of interest and it structure is verified by checking for cavity and handle after this a connected representation of the gray matter is created by a constrained growing out from the white matter boundary because the connectivity is computed the segmentation can be used a input to several method of visualizing the spatial pattern of cortical activity within gray matter in our case the connected representation of gray matter is used to create a representation of theflattened cortex then fmri measurement are over laid on the flattened representation yielding a representation of the volumetric data within a single image 
in this paper we present an integrated approach that solves the structure and motion problem for affine camera given image of corresponding point line and conic in any number of view a reconstruction of the scene structure and the camera motion is calculated up to an affine transformation starting with three view two novel concept are introduced the first one is a quasi tensor consisting of component and the second one is another quasitensor consisting of component these tensor describe the viewing geometry for three view taken by an affine camera it is shown how correspondence of point line and conic can be used to constrain the tensor component a set of affine camera matrix compatible with the quasi tensor can easily be calculated from the tensor component the resulting camera matrix serve a an initial guess in a factorisation method using point line and conic concurrently generalizing the well known factorisation method by tomasi kanade finally example are given that illustrate the developed method on both simulated and real data 
the author describes a new method for camera autocalibration and scaled euclidean structure and motion from three or more view taken by a moving camera with fixed but unknown intrinsic parameter the motion constancy of these is used to rectify an initial projective reconstruction euclidean scene structure is formulated in term of the absolute quadric the singular dual d quadric spl time rank matrix giving the euclidean dot product between plane normal this is equivalent to the traditional absolute conic but simpler to use it encodes both affine and euclidean structure and project very simply to the dual absolute image conic which encodes camera calibration requiring the projection to be constant give a bilinear constraint between the absolute quadric and image conic from which both can be recovered nonlinearly from m spl ge image or quasi linearly from m spl ge calibration and euclidean structure follow easily the nonlinear method is stabler faster more accurate and more general than the quasi linear one it is based on a general constrained optimization technique sequential quadratic programming that may well be useful in other vision problem 
this paper present a new similarity measure for object recognition from large library of line pattern the measure draw it inspiration from both the hausdorff distance and a recently reported bayesian consistency measure that ha been sucessfully used for graphbased correspondence matching the measure us robust error kernel to gauge the similarity of pairwise attribute relation defined on the edge of nearest neighbour graph we use the similarity measure in a recognition experiment which involves a library of over line pattern a sensitivity study reveals that the method is capable of delivering a recognition accuracy of a comparative study reveals that the method is most effective when a gaussian kernel or huber s robust kernel is used to weight the attribute relation moreover the method consistently outperforms rucklidge s median hausdorff distance 
this paper present a methodology for localization of manmade object in complex scene by learning multiple feature model in image the methodology is based on a modular structure consisting of multiple classifier each of which solves the problem independently based on it input observation each classifier module is trained to detect manmade object region and a higher order decision integrator collect evidence from each of the module to delineate a final region of interest the proposed framework is applied to the problem of automatic manmade object localization detection result obtained on the detection of vehicle in color visual and infrared imagery are presented in this paper 
the paper present a new method for matching individual line segment between image the method us both grey level information and the multiple view geometric relation between the image for image pair epipolar geometry facilitates the computation of a cross correlation based matching score for putative line correspondence for image triplet cross correlation matching score are used in conjunction with line transfer based on the trifocal geometry algorithm are developed for both short and long range motion in the case of long range motion the algorithm involves evaluating a one parameter family of plane induced homographies the algorithm are robust to deficiency in the line segment extraction and partial occlusion experimental result are given for image pair and triplet for varying motion between view and for different scene type the three view algorithm eliminates all mismatch 
we describe a new approach to feature based object recognition using maximum a posteriori map estimation under a markov random field mrf model the main advantage of this approach is that it allows explicit modeling of dependency between individual feature of an object for instance we use the approach to model the fact that mismatched feature due to partial occlusion tend to form spatially coherent group rather than being independent efficient computation of the map estimate in our framework can be accomplished by finding a minimum cut on an appropriately defined graph an even more efficient approximation that doe not use graph cut is also presented this approximation technique which we call spatially coherent matching scm is closely related to generalized hausdorff matching we report some monte carlo experiment showing that the scm technique improves substantially on the tradeoff between correct detection and false alarm compared with previous feature matching method such a the hausdorff distance 
image mosaic are useful for a variety of task in vision and computer graphic a particularly convenient way to generate mosaic is by stitching together many ordinary photograph existing algorithm focus on capturing static scene this paper present a complete system for creating visually pleasing mosaic in the presence of moving object there are three primary contribution the first component of our system is a registration method that remains unbiased by movement the mellin transform is extended to register image related by a projective transform second an efficient method for finding a globally consistent registration of all image is developed by solving a linear system of equation derived from many pairwise registration matrix we find an optimal global registration lastly a new method of compositing image is presented blurred area due to moving object are avoided by segmenting the mosaic into disjoint region and sampling pixel in each region from a single source image 
model based vehicle tracking in traffic image sequence can be made more robust by matching expected displacementrates of vehicle surface point to optical flow of vector computed from an image sequence the capability to track vehicle uninterruptedly in thismanner over extended image sequence result in the ability to investigate even small error in of estimation it turn out that the of magnitude are systematically underestimated the albeit small bias can be corrected by analyzing the influence of explicitly modeled grey value noise on the precision of of value estimated by mean of the neighborhood sampling method 
understanding observation of interacting object requires one to reason about qualitative scene dynamic for example on observing a hand lifting a can we may infer that an active hand is applying an upwards force by grasping to lift a passive can in previous work we presented a system that infers qualitative scene dynamic from the instantaneous motion of object however since that analysis only considered single frame in isolation there were often multiple interpretation for each frame in this work we show how the dynamic information inferred at each frame can be integrated over time to reduce ambiguity our approach to integrating information is to extend our representation to describe object by a set of property or capability that are assumed to persist over time given this extended representation we find interpretation that require the smallest set s of property over the whole image sequence 
the observed image texture for a rough surface ha a complex dependence on the illumination and viewing angle due to effect such a local shading interreflection and the shadowing and occlusion of surface element we introduce the dimensionality surface a a representation for the visual complexity of a material sample the dimensionality surface defines the number of basis feature that are required to represent the space of observed texture for a surface a a function of range of illumination and viewing angle basis texture are represented using multiband correlation function we study property of the dimensionality surface for real material using the columbia utrecht reflectance and texture curet database the analysis show that the dependence of the dimensionality surface on range of illumination and viewing angle is approximately linear with a slope dependent on the complexity of the sample 
we confront the theoretical and practical difficulty of computing a representation for two dimensional shape based on shock or singularity that arise a the shape s boundary is deformed first we develop subpixel local detector for finding and classifying shock second to show that shock pattern are not arbitrary but obey the rule of a grammar and in addition satisfy specific topological and geometric constraint shock hypothesis that violate the grammar or are topologically or geometrically invalid are pruned to enforce global consistency survivor are organized into a hierarchical graph of shock group computed in the reaction diffusion space where diffusion play a role of regularization to determine the significance of each shock group the shock group can be functionally related to the object s part protrusion and bend and the representation is suited to recognition several example illustrate it stability with rotation scale change occlusion and movement of part even at very low resolution 
condensation recently introduced in the computer visionliterature is a particle filtering algorithm which represents a tracked object s state using an entire probability distribution clutter can cause thedistribution to split temporarily into multiple peak each representinga different hypothesis about the object configuration when measurementsbecome unambiguous again all but one peak corresponding tothe true object position die out while several peak persist estimating 
a new approach to the recognition of temporal behavior and activity is presented the fundamental idea inspired by work in speech recognition is to divide the inference problem into two level the lower level is performed using standard independent probabilistic temporal event detector such a hidden markov model hmms to propose candidate detection of low level temporal feature the output of these detector provide the input stream for a stochastic context free grammar parsing mechanism the grammar and parser provide longer range temporal constraint disambiguate uncertain low level detection and allow the inclusion of a priori knowledge about the structure of temporal event in a given domain to achieve such a system we provide technique for generating a discrete symbol stream from continuous low level detector and for enforcing temporal exclusion constraint during parsing we demonstrate the approach in several experiment using both visual and other sensing data 
the paper present an analysis of the stability of pose estimation the investigated pose estimation technique is based on orientation of three edge segment and provides the rotation part of object pose the specific emphasis of the analysis is on determining how the stability varies with view point relative to an object the stability investigation propagates the uncertainty in edge segment orientation to the resulting effect on the pose parameter it is shown that there is a very strong variation in noise sensitivity over the range of viewpoint and that exactly what viewpoint offer highest robustness towards noise can be determined in advance experiment on real image verify the theoretical result and show that dependent on viewpoint pose parameter variance varies from to degree squared 
this paper derives what we term the euclidean hinge constraint for projective reconstruction of object displaying articulated motion a euclidean hinge is defined here to be an articulation axis with the proviso that any plane perpendicular to the articulation axis in link ha a coincident plane which is perpendicular to the articulation ad in link and that these plane remain coincident under articulated motion this constraint permit the independent projective reconstruction of two adjacent articulated link to be placed in a common frame the constraint may be expressed mathematically by considering what we define a circular parallax additionally the existence of a euclidean hinge permit the permit the projective frame to be brought nearer to a euclidean frame for the reconstructed object a brief reprise of the method of articulation axis estimation is given together with a more extensive series of experimental result 
this paper deal with the problem of motion based segmentation of image sequence such partition are multiple purpose in dynamic scene analysis we first extract a texture based partition using an unsupervised mrf approach the region obtained are then grouped according to a motion based criterion this grouping process relies on two motion estimation technique and exploit contextual information between region in contrast with clustering technique region grouping is formalized a a motion based graph labeling process within a markovian framework result on real world image sequence are shown and validate the proposed method 
this paper present an algorithm for a dense computation of the difference in blur between two image the two image are acquired by varying the intrinsic parameter of the camera the image formation system is assumed to be passive estimation of depth from the blur difference is straigh forward the algorithm is based on a local image decomposition technique using the hermite polynomial basis we show that any coefficient of the hermite polynomial computed using the more blurred image is a function of the partial derivative of the other image and the blur difference hence the blur difference can be computed by resolving a system of equation all computation required are local and carried out in the spatial domain an algorithm is presented for estimation of the blur in d and d case and it behavior is studied for constant image step edge line edge and junction the algorithm is tested using synthetic and real image the result obtained are very encouraging 
the aim of this paper is to provide a comparative evaluation of a number of contrasting approach to relational matching unique to this study is the way in which we show how a diverse family of algorithm relate to one another using a common bayesian framework broadly speaking there are two main aspect to this study firstly we focus on the issue of how relational inexactness may be quantified we illustrate that several popular relational distance measure can be recovered a specific limiting case of the same bayesian consistency measure the second aspect of our comparison concern the way in which structural inexactness is controlled we investigate three different realisation of the matching process which draw on contrasting control model the main conclusion of our study is that the active process of graph editing outperforms the alternative in term of it ability to effectively control a large population of contaminating clutter 
a new framework is presented in this paper for tracking non rigid motion in image sequence this method model non rigid motion a the deformation of connected d membrane patch local smoothness constraint for each patch are the low frequency vibration mode obtained from modal analysis these constraint are incorporated with the template matching algorithm into a local motion estimator to maintain the global topological structure different patch are connected together by hinge which introduce additional constraint in the tracking process the resulted over constrained linear system is solved efficiently using a least square estimator to improve the robustness of the tracker stochastic filtering technique is employed to take advantage of the temporal continuity of the deformation promising result on both natural and synthetic facial motion sequence are demonstrated in this paper 
this paper proposes a method for automatically constructing triangular g spline model of complex three dimensional object from a few registered photograph these model are used for pose estimation from monocular silhouette data and they form the basis for a simple recognition strategy the proposed approach is demonstrated by several experiment 
this paper is concerned with the problem of segmenting an image into region using a local measure of the difference between image pixel we develop a general framework for a broad range of segmentation problem based on pairwise comparison of region in a segmentation this framework provides precise definition of when a segmentation is too coarse or too fine within this framework we define a particular pairwise region comparison function for graph based segmentation problem then we provide an efficient algorithm for computing a segmentation using this comparison function and prove that it produce good segmentation those that are neither too coarse nor too fine by our definition we apply this algorithm to image segmentation an important characteristic of this method is it ability to preserve detail in low variability image region while ignoring detail in high variability region we illustrate the method with several example on both real and sythetic image 
this paper present fundamental theory and design of centralpanoramic camera panoramic camera combine a convex hyperbolic orparabolic mirror with a perspective camera to obtain a large field of view we show how to design a panoramic camera with a tractable geometryand we propose a simple calibration method we derive the image formationfunction for such a camera the main contribution of the paperis the derivation of the epipolar geometry between a pair of panoramiccameras we show 
camera calibration is essential to many computer vision application in practice this often requires cumbersome calibration procedure to be carried out regularly in the last few year a lot of work ha been done on self calibration of camera ranging from weak calibration to metric calibration it ha been shown that a metric calibration of the camera setup up to scale wa possible based on the rigidity of the scene only in this paper a stratified approach is proposed which gradually retrieves the metric calibration of the camera setup starting from an uncalibrated image sequence the projective calibration is retrieved first in projective space the plane at infinity is then identified yielding the affine calibration this is achieved using a constraint which can be formulated between any two arbitrary image of the sequence once the affine calibration is known the upgrade to metric is easily obtained through linear equation 
many computer vision task rely on feature extraction inter est point are such feature this paper show that interest point are geometrically stable under different transformation and have high information content distinctiveness these two property make interest point very successful in the context of image matching to measure these two property quantitatively we introduce two evaluation criterion repeatability rate and information content the quality of the interest point depends on the detector used in this paper several detector are compared according to the criterion specified above we determine which detector give the best result and show that it satisfies the criterion well 
we introduce a method for unsupervised clustering of image of d object our method examines the space of all image and partition the image into set that form smooth and parallel surface in this space it further us sequence of image to obtain more reliable clustering finally since our method relies on a non euclidean similarity measure we introduce algebraic technique for estimating local property of these surface without first embedding the image in a euclidean space we demonstrate our method by applying it to a large database of image 
this paper present a statistical approach for detecting corner from chain encoded digital arc an arc point is declared a a corner if the estimated parameter of the two fitted line of the two arc segment immediately to the right and left of the arc point are statistically significantly different the corner detection algorithm consists of two step corner detection and optimization while corner detection involves statistically identifying the most likely corner point along an arc sequence corner optimization deal with improving the locational error of the detected corner the major contribution of this research include developing a method for analytically estimating the covariance matrix of the fitted line parameter and developing a hypothesis test statistic to statistically test the difference between the parameter of two fitted line this paper discus the theory and performance characterization of the proposed corner detector 
we consider the problem of determining whether two image come from different object or the same object in the same pose but under different illumination condition we show that this problem cannot be solved using hard constraint even using a lambertian reflectance model there is always an object and a pair of lighting condition consistent with any two image nevertheless we show that for point source and object with lambertian reflectance the ratio of two image from the same object is simpler than the ratio of image from different object we also show that the ratio of the two image provides two of the three distinct value in the hessian matrix of the object s surface using these observation we develop a simple measure for matching image under variable illumination comparing it performance to other existing method on a database of image of individual 
this paper give a practical and accurate algorithm for the computation of the quadrifocal tensor and extraction of camera matrix from it previous method for using the quadrifocal tensor in projective scene reconstruction have not emphasized accuracy of the algorithm in condition of noise method given in this paper minimize algebraic error either through a non iterative linear algorithm or two alternative iterative algorithm it is shown by experiment with synthetic data that the iterative method though minimizing algebraic rather than more correctly geometric error measured in the image give almost optimal result 
we present a method for matching curve which accommodates large and small deformation the method preserve geometric similarity in the case of small deformation and loosens these geometric constraint when large deformation occur the approach is based on the computation of a set of geodesic path connecting the curve these two curve are defined a a source area and a destination area which can have an arbitrary number of connected component and different topology the applicative framework of the presented method is the study of the crustal deformation from a set of iso elevation curve an experiment with real curve demonstrates that the approach can be successfully applied to characterize deformation of digital elevation model 
the color associated with an object in machine vision image is not constant under varying illuminating and viewing condition such a in outdoor image the perceived color of an object can vary significantly thus making color based recognition difficult existing method in color based recognition have been applied mostly to indoor and or constrained imagery but not to realistic outdoor data this work analyzes the variation of object color in outdoor image with respect to existing model of day light illumination and surface reflectance two approach for color recognition are then proposed the first develops context based model of daylight illumination and hybrid surface reflectance and predicts the color of object based on scene context the secondmethod show that object color can be nonparametrically learned through classification method such a neural network and multivariate decision tree the method have been successfully tested in domain such a road highway scene off road navigation and military target detection 
markov random field mrf s can be used for a wide variety of vision problem in this paper we focus on mrf s with two valued clique potential which form a generalized potts model we show that the maximum a posteriori estimate of such an mrf can be obtained by solving a multiway minimum cut problem on a graph we develop efficient algorithm for computing good approximation to the minimum multiway cut the visual correspondence problem can be formulated a an mrf in our framework this yield quite promising result on real data with ground truth we also apply our technique to mrf s with linear clique potential 
we present an integrated approach to the derivation of scene description from binocular stereo image by inferring the scene description directly from local measurement of both point and line correspondence we address both the stereo correspondence problem and the surface reconstruction problem simultaneously we introduce a robust computational technique call tensor voting for the inference of scene description in term of surface junction and region boundary the methodology is grounded in two element tensor calculus for representation and non linear voting for data communication by efficiently and effectively collecting and analyzing neighborhood information we are able to handle the task of interpolation discontinuity detection and outlier identification simultaneously the proposed method is non iterative robust to initialization and thresholding in the preprocessing stage and the only criticalfree parameter is the size of the neighborhood we illustrate the approach with result on a variety of image 
this paper describes an active camera real time system for tracking shape description and classification of the human face and mouth using only an sgi indy computer the system is based on use of d blob feature which are spatially compact cluster of pixel that are similar in term of low level image property pattern of behavior e g facial expression and head movement can be classified in real time using hidden markov model hmm method the system ha been tested on hundred of user and ha demonstrated extremely reliable and accurate performance typical classification accuracy are near 
conventional edge linking method perform poorly whenmultiple response to the same edge bifurcation and nearby edge arepresent we propose a scheme for curve inference where divergent bifurcationsare initially suppressed so that the smooth part of the curve canbe computed more reliably recovery of curve singularity and gap isdeferred to a later stage when more contextual information is available introductionthe problem of curve inference from a brightness image is of 
we describe a novel technique for face recognition based on deformable intensity surface which incorporates both the shape and texture component of the d image the intensity surface of the facial image is modeled a a deformable d mesh in z y i x y space using an efficient technique for matching two surface in term of the analytic mode of vibration we obtain a dense correspondence field or d warp between two image the probability distribution of two class of warp are then estimated from training data interpersonal and extrapersonal variation these density are then used in a bayesian framework for image matching and recognition experimental result with facial data from the u army feret database demonstrate an increased recognition rate over the previous best method 
we propose a new image retrieval method based on human perceptual clustering of color image this color clustering produce for each image a small set of representative color which capture the color property of the image and a small set of sizable contiguous region which capture the spatial geometrical property of the image the proposed method outperforms the traditional histogram and it improved method not only with it richer image retrieval capability which cover a wider spectrum of user requirement but also with it powerful indexing scheme which is essential to cater for large scale image database 
this paper develops real time tracking technology for sport broadcast application the specific sport chosen here is the game of tennis the output of the tennis tracking system are spatio temporal trajectory of motion of the player and the ball which can in turn provide a number of statistic about the game for instance the distance travelled by a player the speed and the acceleration at any instant a well a court coverage pattern can be obtained from the trajectory the statistic so obtained can be visualized in compelling way to enhance the appreciation of the athleticism and strategy involved in the sport we present technique for tracking the player and the ball in video obtained from stationary camera the problem is challenging a the tracking need to be performed outdoors player are fast moving non rigid object and the ball is a small object that can move at speed in the range of mile an hour player trajectory are obtained by dynamically clustering track of local feature ball segmentation and tracking is based on shape and color feature of the ball real time tracking result are presented on video recorded live by the author in an international tennis tournament 
this pap er present a comprehensive framework for tracking moving human in an indoor environment from sequence of synchronized monocular grayscale image captured from multiple fixed camera the proposed framework consists of three main module single view tracking svt multiple view transition tracking mvtt and automatic camera switching ac bayesian classification scheme based on motion analysis of human feature are used to track spatially and temporally a subject image of interest between consecutive frame the automatic camera switching module predicts the position of the subject along a spatial temporal domain and then selects the camera which provides the best view and requires the least switching to continue tracking limited degree of occlusion are tolerated within the system tracking is based up on the image of upper human body captured from various viewing angle and non human moving object are excluded using principal component analysis pca experimental result are presented to evaluate the performance of the tracking system 
in this paper a novel recursive method for estimating structure and motion from image sequence is presented the novelty lie in the fact that the output of the algorithm is independent of the chosen coordinate system in the image a well a the ordering of the point it relies on subspace method and is derived from both ordinary coordinate representation and camera matrix and from a so called depth and shape analysis furthermore no initial phase is needed to start up the algorithm it start directly with the first two image and incorporates new image a soon a new corresponding point are obtained the performance of the algorithm is shown on simulated data moreover the two different approach one using camera matrix and the other using the concept of affine shape and depth are unified into a general theory of structure and motion from image sequence 
it is often necessary to handle randomness and geometry in computer vision for instance to match and fuse together noisy geometric feature such a point line or d frame or to estimate a geometric transformation from a set of matched feature however the proper handling of these geometric feature is far more difficult than for point and a number of paradox can arise we analyse in this article three basic problem what is a uniform random distribution of feature how to define a distance between feature and what is the mean feature of a number of feature measurement and we propose generic method to solve them 
we develop a face recognition algorithm which is insensitiveto gross variation in lighting direction and facial expression takinga pattern classification approach we consider each pixel in an imageas a coordinate in a high dimensional space we take advantage of theobservation that the image of a particular face under varying illuminationdirection lie in a d linear subspace of the high dimensional featurespace if the face is a lambertian surface without self shadowing 
this paper present a quantitative approach to grouping a genericgrouping method which may be applied to many domain is given and an analysisof it expected grouping quality is done the grouping method is divided into twoparts constructing a graph representation of the geometric relation in the dataset and then finding the quot best quot partition of the graph into group both stagesare implemented using known statistical tool such a wald s sprt algorithmand the maximum likelihood 
abstract we present a new approach to analyse the deformation of the left ventricle of the heart based on aparametric model that give a compact representation of a set of point in a d image we presenta strategy for tracking surface in a sequence of d cardiac image following tracking we theninfer quantitative parameter which characterize left ventricle motion volume of left ventricle ejection fraction amplitude and twist component of cardiac motion we explain the computationof 
in this paper it is shown how corresponding conic in two image can be used to estimate the epipolar geometry in term of the fundamental essential matrix the corresponding conic can be image of either planar conic or silhouette of quadric it is shown that one conic correspondence give two independent constraint on the fundamental matrix and a method to estimate the fundamental matrix from at least four corresponding conic is presented furthermore a new type of fundamental matrix for describing conic correspondence is introduced finally it is shown that the problem of estimating the fundamental matrix from point correspondence and conic correspondence in general ha different solution a method to calculate these solution is also given together with an experimental validation 
a novel approach to grouping symmetrical planar curve under a projective transform is described symmetric curve are important a a generic model for object recognition where an object class is defined by the set of symmetry that any object in the class obeys in this paper a new algorithm is presented for grouping curve based on their correspondence under a plane projectivity the correspondence between curve is established from an initial correspondence between two pair of distinguished line such a line tangent to inflection point this initial correspondence lead to a reduced dimensional form for the projective mapping between the curve and a natural method for establishing correspondence between all point on the curve a saliency measure is introduced which permit grouping result to be ordered in term of the degree of symmetry supported by each curve pair this saliency measure provides a basis for recognition in the case of approximate symmetry 
we present a new framework for recognizing planar object class which is based on local feature detector and a probabilistic model of the spatial arrangement of the feature the allowed object deformation are represented through shape statistic which are learned from example instance of an object in an image are detected by finding the appropriate feature in the correct spatial configuration the algorithm is robust with respect to partial occlusion detector false alarm and missed feature a success rate wa achieved for the problem of locating quasi frontal view of face in cluttered scene 
this paper present a method for alignment of image acquired by sensor of different modality e g eo and ir the paper ha two main contribution i it identifies an appropriate image representation for multi sensor alignment i e a representation which emphasizes the common information between the two multi sensor image suppresses the non common information and is adequate for coarse to fine processing ii it present a new alignment technique which applies global estimation to any choice of a local similarity measure in particular it is shown that when this registration technique is applied to the chosen image representation with a local normalized correlation similarity measure it providesa new multi sensor alignment algorithm which is robust to outlier and applies to a wide variety of globally complex brightness transformation between the two image our proposed image representation doe not rely on sparse image feature e g edge contour or point feature it is continuous and doe not eliminate the detailed variation within local image region our method naturally extends to coarse to fine processing and applies even in situation when the multi sensor signal are globally characterized by low statistical correlation 
during evaluation of real world traffic scene we often encounterthe situation that the vehicle under scrutiny are temporarilyoccluded by dynamic or stationary scene component vision basedtracking algorithm often fail in tracking vehicle under such condition contextual knowledge about occlusion is expected to facilitate the vehicletracking process we collected a set of potential occlusion situation described by primitive predicate which are modeled by mean of fuzzysets 
we present a principled method of obtaining a weighted similarity metric for d image retrieval firmly rooted in bayes decision theory the basic idea is to determine a set of most discriminative feature by evaluating how well they perform on the task of classifying image according to predefined semantic category we propose this indirect method a a rigorous way to solve the difficult feature selection problem that come up in most content based image retrieval task the method is applied to normal and pathological neuroradiological ct image where we take advantage of the fact that normal human brain present an approximate bilateral symmetry which is often absent in pathological brain the quantitative evaluation of the retrieval system show promising result 
a real time tracking algorithm that us contextual information is described the method is capable of simultaneously tracking multiple non rigid object when erratic movement and object collision are common a closed world assumption is used to adaptively select and weight image feature used for correspondence result of algorithm testing and the limitation of the method are discussed the algorithm ha been used to track child in an interactive narrative playspace 
structure of dynamic scene can only be recovered using a real time range sensor depth from defocus offer an effective solution to fast and dense range estimation however accurate depth estimation requires theoretical and practical solution to a variety of problem including recovery of textureless surface precise blur estimation and magnification variation caused by defocusing both textured and textureless surface are recovered using an illumination pattern that is projected via the same optical path used to acquire image the illumination pattern is optimized to maximize accuracy and spatial resolution in computed depth the relative blurring in two image is computed using a narrow band linear operator that is designed by considering all the optical sensing and computational element of the depth from defocus system defocus invariant magnification is achieved by the use of an additional aperture in the imaging optic a prototype focus range sensor ha been developed that ha a workspace of cubic foot and produce up to depth estimate at hz with an average rms error of several experimental result are included to demonstrate the performance of the sensor 
image editing system are essentially pixel based in this paper we propose a novel method for image editing in which the primitive working unit is not a pixel but an edge the feasibility of this proposal is suggested by recent work showing that a gray scale image can be accurately represented by it edge map if a suitable edge model and scale selection method are employed in particular an efficient algorithm ha been reported to invert such an edge representation to yield a high fidelity reconstruction of the original image we have combined these algorithm together with an efficient method for contour grouping and an intuitive user interface to allow user to perform image editing operation crop paste delete directly in the contour domain experimental result suggest that this novel combination of vision algorithm may increase the efficiency of certain class of image editing operation 
different kind of digital image can be modelled a the sampling of a continuous surface being described and analyzed through the extraction of geometric feature from the underlying surface among them ridge and valley or generically crease have deserved special interest the computer vision community ha been relying on different crease definition some of them equivalent although they are quite valuable in a number of application they usually do not correspond to the real crease of a topographic relief these definition give rise either to algorithm that label pixel a crease point and then focus on the problem of grouping them into curve or to operator whose outcome is a creaseness image we draw our attention to the real crease definition for a landscape due to rudolf rothe which is based on the convergence of slopelines they are computed by numerically solving a system of differential equation afterwards we extract rothe crease which are part of slopelines where others converge avoiding in such a way any pixel grouping step at the same time we compute a creaseness image according to this definition 
this paper is concerned with the retrieval of image from large database based on their shape similarity to a query image our approach is based on two dimensional histogram that encode both the local and global geometric property of the shape the pairwise attribute are the directed segment relative angle and directed relative position the novelty of the proposed approach is to simultaneously use the relational and structural constraint derived from an adjacency graph to gate histogram contribution we investiguate the retrieval cap ability of the method for various query we also investigate the robustness of the method to segmentation error we conclude that a relational histo gram of pairwise segment attributespresents a very efficient way of indexing into large database the optimal configuration is obtained when the local feature are constructed from six neighbouring segment pair moreover a sensitivity analysis reveals that segmentation error do not affect the retrieval performance 
we present in this paper a system which automatically build from real image a scene model containing both d geometric information of the scene structure and it photometric information under various illumination condition the geometric structure is recovered from image taken from distinct viewpoint structure from motion and correlation based stereo technique are used to match pixel between image of different viewpoint and to reconstruct the scene in d space the photometric property is extracted from image taken under different illumination condition orientation position and intensity of the light source this is achieved by computing a low dimensional linear space of the spatio illumination volume and is represented by a set of basis image the model that ha been built can be used to create realistic rendering from different viewpoint and illumination condition application include object recognition virtual reality and product advertisement 
in this paper we present the first step in the development of a statistical shape model specifically a point distribution model pdm of the cortical surface of the brain this will ultimately be used to locate label and describe the cortex for visualisation diagnosis andquantification in order to produce the model it wa necessary to find and label the sulcal fissure on a series of mr image due to the complexity of the surface an automated method wa developed to facilitate development of a full surface model automating the marking process introduced the problem of identifying correspondence between example the knowledge of which is essential to the development of a pdm various method were investigated to solve this problem including simple point matching and more complex curve matching each is outlined and discussed the model obtained so far provide interesting insight into the shape and cortical pattern variation over a group of normal subject 
this paper present an efficient algorithm for generating adaptive triangular mesh from dense range image the proposed technique consists of two stage first a quadrilateral mesh is generated from the given range image the point of this mesh adapt to the surface shape represented in the range image by grouping in area of high curvature and dispersing in low variation region the second stage split each quadrilateral cell obtained before into two triangle between the two possible flip it is chosen the one whose diagonal s direction is closest to the orientation of the discontinuity present in that cell both stage avoid costly iterative optimization technique result with real range image are presented they show low cpu time and accurate triangular approximation of the given image 
in many vision problem we want to infer two or more hidden factor which interact to produce our observation we may want to disentangle illuminant and object color in color constancy rendering condition from surface shape in shape from shading face identity and head pose in face recognition or font and letter class in character recognition we refer to these two factor generically a style and content bilinear model offer a powerful framework for extracting the two factor structure of a set of observation and are familiar in computational vision from several well known line of research this paper show how bilinear model can be used to learn the style content structure of a pattern analysis or synthesis problem which can then be generalized to solve related task using different style and or content we focus on three task extrapolating the style of data to unseen content class classifying data with known content under a novel style and translating data from novel content class and style to a known style or content we show example from color constancy face pose estimation shape from shading typography and speech 
we describe the geometry constraint and algorithmic implementation for metric rectification of plane the rectification allows metric property such a angle and length ratio to be measured on the world plane from a perspective image the novel contribution are first that in a stratified context the various form of providing metric information which include a known angle two equal though unknown angle and a known length ratio can all be represented a circular constraint on the parameter of an affine transformation of the plane this provides a simple and uniform framework for integrating constraint second direct rectification from right angle in the plane third it is shown that metric rectification enables calibration of the internal camera parameter fourth vanishing point are estimated using a maximum likelihood estimator fifth an algorithm for automatic rectification example are given for a number of image and application demonstrated for texture map acquisition and metric measurement 
the estimation and detection of occlusion boundary and moving bar are important and challenging problem in image sequence analysis here we model such motion feature a linear combination of steerable basis flow field these model constrain the interpretation of image motion and are used in the same way a translational or affine motion model we estimate the subspace coefficient of the motion feature model directly from spatiotemporal image derivative using a robust regression method from the subspace coefficient we detect the presence of a motion feature and solve for the orientation of the feature and the relative velocity of the surface our method doe not require the prior computation of optical flow and recovers accurate estimate of orientation and velocity 
manufacturing flaw of all type shape and size can be exhaustively detected a abnormal pixel if process and noise variation can be learned at every pixel in the inspection area this statistical template approach to automated visual inspection is extremely fast effective and flexible while achieving false negative rate critical to this approach are the following novel feature represent both geometry and process information in a model template align d surface with subpixel accuracy compensate for local deformation and texture estimate bimodal distribution robustly this novel paradigm wa applied to the automatic screening of x ray image of turbine blade it ha been validated with over image and shown to out perform regular inspector looking at high pas filtered image 
this paper describes an attentional mechanism based on the interpretation of spectral signature for detecting regular object configuration in area of an image delineated using context information the proposed global operator relies on the spectral analyse s of edge structure and exploit spatial a well a frequency domain constraint derived from known geometrical model of monitored object a decision theoretic method for learning decision region is presented application of this mechanism are demonstrated for several aerial image interpretation task specific example are described for detecting vehicle formation such a convoy qualifying the geometry of detected formation or monitoring the occupancy of region of interest such a parking area road or open area experiment and sensitivity analysis result are reported 
under binocular viewing of a scene there are inevitably region seen only in one eye or camera normally this is a source of trouble for stereopsis algorithm which must deal with these region on non correspondence this paper point out that in fact half occlusion can be a source of valuable information this is done by deriving a formula relating the displacement of an occlusion junction in the two eye image and the depth difference between the scene edge that comprise the occlusion junction this paper represents the first quantitative result on the cue of half occlusion in stereopsis 
we present a method for computing dense visual correspondence based on general assumption about scene geometry our algorithm doe not rely on correlation and us a variable region of support we assume that image consist of a number of connected set of pixel with the same disparity which we call em disparity component at each pixel we compute a small set of plausible disparity each of which is more likely to be the pixel s true disparity than not a pixel is assigned a disparity d based on connected component of pixel where each pixel in a component considers d to be plausible our implementation chooses the largest plausible disparity component however global contextual constraint can also be applied while the algorithm wa originally designed for visual correspondence it can also be used for other early vision problem such a image restoration it run in a few second on traditional benchmark image with standard parameter setting and give quite promising result 
we present ordinal measure for establishing image correspondence linear correspondence measure like correlation and the sum of squared difference are known to be fragile ordinal measure which are based on relative ordering of intensity value in window have demonstrable robustness to depth discontinuity occlusion and noise the relative ordering of intensity value in each window is represented by a rank permutation which is obtained by sorting the corresponding intensity data by using a novel distance metric between the rank permutation we arrive at ordinal correlation coefficient these coefficient are independent of absolute intensity scale i e they are normalized measure further since rank permutation are invariant to monotone transformation of the intensity value the coefficient are unaffected by nonlinear effect like gamma variation between image we have developed a simple algorithm for their efficient implementation experiment suggest the superiority of ordinal measure over existing technique under non ideal condition though we present ordinal measure in the context of stereo they serve a a general tool for image matching that is applicable to other vision problem such a motion estimation and image registration 
a traditional approach to extracting geometric information from alarge scene is to compute multiple d depth map from stereo pairsor direct range finder and then to merge the d data however theresulting merged depth map may be subject to merging error if therelative pose between depth map are not known exactly in addition the d data may also have to be resampled before merging which addsadditional complexity and potential source of error this paper provides a mean of directly extracting d data coveringa very wide field of view thus by passing the need for numerousdepth map merging in our work cylindrical image are firstcomposited from sequence of image taken while the camera is rotated about a vertical axis by taking such image panorama atdifferent camera location we can recover d data of the sceneusing a set of simple technique feature tracking an pointstructure from motion algorithm and multibaseline stereo we alsoinvestigate the effect of median filtering on the recovered d pointdistributions and show the result of our approach applied to bothsynthetic and real scene 
we firstly present a variational approach such that during image restoration edge detected in the original image are being preserved and then we compare in a second part the mathematical foundation of this method with respect to some of the well known method recently proposed in the literature within the class of pde based algorithm anisotropic diffusion mean curvature motion min max flow technique the performance of our approach is carefully examined and compared to the classical method experimental result on synthetic and real image will illustrate the capability of all the studied approach 
we present the concept of non rigid matching based on demon by reference to maxwell s demon we contrast this concept with the more conventional viewpoint of attraction we show that demon and attractive point are clearly distinct for large deformation but also that they become similar for small displacement encompassing technique close to optical flow we describe a general iterative matching method based on demon and derive from it three different non rigid matching algorithm one using all the image intensity one using only contour and one for already segmented image at last we present result with synthesized and real deformation with application to computer vision and medical image processing 
we introduce a novel method for visual homing using this method a robot can be sent to desired position and orientation in d space specified by single image taken from these position our method is based on recovering the epipolar geometry relating the current image taken by the robot and the target image using the epipolar geometry most of the parameter which specify the difference in position and orientation of the camera between the two image are recovered however since not all of the parameter can be recovered from two image we have developed specific method to bypass these missing parameter and resolve the ambiguity that exist we present two homing algorithm for two standard projection model weak and full perspective our method determines the path of the robot on line the starting position of the robot is relatively not constrained and a d model of the environment is not required the method is almost entirely memoryless in the sense that at every step the path to the target position is determined independently of the previous path taken by the robot because of this property the robot may be able while moving toward the target to perform auxiliary task or to avoid obstacle without this impairing it ability to eventually reach the target position we have performed simulation and real experiment which demonstrate the robustness of the method and that the algorithm always converge to the target pose 
there are many historical manuscript written in a single hand which it would be useful to index example include the w b dubois collection at the university of massachusetts and the early presidential library at the library of congress since optical character recognition ocr doe not work well on handwriting an alternative scheme based on matching the image of the word is proposed for indexing such text the current paper deal with the matching aspect of this process two different technique for matching word are discussed the first method match word assuming that the transformation between the word may be modelled by a translation shift the second method match word assuming that the transformation between the word may be modelled by an affine transform experiment are shown demonstrating the feasibility of the approach for indexing handwriting the method should also be applicable to retrieving previously stored material from personal digital assistant pda 
in this paper we present a novel approach to surface recovery from an image sequence of a rotating object in this approach the object is illuminated under a collinear light source where the light source lie on or near the optical axis and rotated on a controlled turntable a wire frame of d curve on the object surface is extracted by using shading and occluding contour in the image sequence then the whole object surface is recovered by interpolating the surface between curve on the wire frame the interpolation can be done by using geometric or photometric method the photometric method us shading information and is more powerful than geometric method the experimental result on real image sequence of matte and specular surface show that the technique is feasible and promising 
this paper present a trainable object detection architecture that is applied to detecting people in static image of cluttered scene this problem pose several challenge people are highly non rigid object with a high degree of variability in size shape color and texture unlike previous approach this system learns from example and doe not rely on any a priori handcrafted model or on motion the detection technique is based on the novel idea of the wavelet template that defines the shape of an object in term of a subset of the wavelet coeficients of the image it is invariant to change in color and texture and can be used to robustly define a rich and complex class of object such a people we show how the invariant property and computational eficiency of the wavelet template make it an effective tool for object detection 
the second order statistic of natural image can be well characterized by a self similar i f power spectrum and the bandpass decomposition in biological vision system is characterized by a self similar wavelet like structuring of the frequency channel it ha thus often been suggested that there might exist a systematic interrelationship between these two property but a complete formal derivation of this relation ha not yet been provided using rate distortion argument and a complexity measure we first show that a self similar bandpass decomposition can achieve a desired level of distortion with a le complex system structure than required for a decomposition in band of equal linear bandwidth a closer analysis reveals that the true optimum decomposition is approximately selfsimilar but show a systematic decrease of the logbandwidths with increasing center frequency of the subbands since this effect ha also been observed in neurophysiological experiment we conclude that the typical property of visual neuron may infact result from an optimized exploitation of the statistical redundancy of the natural environment 
a the field of view of a picture is much smaller than our own visual field of view it is common to paste together several picture to create a panoramic mosaic having a larger field of view image with a wider field of view can be generated by using fish eye lens or panoramic mosaic can be created by special device which rotate around the camera s optical center quicktime vr surround video or by aligning and pasting frame in a video sequence to a single reference frame existing mosaicing method have strong limitation on imaging condition and distortion are common manifold projection enables the creation of panoramic mosaic from video sequence under more general condition and in particular the unrestricted motion of a hand held camera the panoramic mosaic is a projection of the scene into a virtual manifold whose structure depends on the camera s motion this manifold is more general than the customary projection onto a single image plane or onto a cylinder in addition to being more general than traditional mosaic manifold projection is also computationally efficient a the only image deformation used are image plane translation and rotation real time software only implementation on a pentium pc prof the superior quality and speed of this approach 
current method for registering image region perform well for simple transformation or large image region the author present a new method that is better able to handle small image region a they deform with nonlinear transformation he introduces difference decomposition a novel approach to solving the registration problem the method is a generalization of previous method and can better handle nonlinear transforms although the method are general he focus on projective transformation and introduces piecewise projective transformation for modeling the motion of non planar object he concludes with example from a prototype implementation 
in this paper we describe a new recognition method thatuses a subspace representation to approximate the comparison of binaryimages e g intensity edge using the hausdorff fraction the techniqueis robust to outlier and occlusion and thus can be used for recognizingobjects that are partly hidden from view and occur in clutteredbackgrounds we report some simple recognition experiment in whichnovel view of object are classified using both a standard ssd basedeigenspace method 
we derive a sensitivity analysis for moment invariant of multidimensional distribution these invariant have many us in computational system and have recently been used for illumination invariant recognition in color image in this context the sensitivity analysis predicts the response of moment invariant to partial occlusion using the result of the sensitivity analysis we develop a novel surface representation called the invariant profile which capture color distribution and spatial information while remaining invariant to the spectral content of the scene illumination unlike previous representation the recognition of invariant profile doe not require illumination correction we demonstrate the sensitivity analysis and the use of invariant profile for recognition with a set of experiment on color image 
this paper deal with the d structure estimation and exploration of a scene using active vision our method is based on the structure from controlled motion approach which consists in constraining the camera motion in order to obtain a precise and robust estimation of the d structure of a geometrical primitive since this approach involves to gaze on the considered primitive we present a method for connecting up many estimation in order to recover the complete spatial structure of scene composed of cylinder and segment we have developed perceptual strategy able to perform a succession of robust estimation without any assumption on the number and on the localization of the different object furthermore the proposed strategy ensures the completeness of the reconstruction an exploration process centered on current visual feature and on the structure of the previously studied primitive is presented this lead to a gaze planning strategy that mainly us a representation of known and unknown area a a basis for selecting viewpoint finally experiment carried out on a robotic cell have proved the validity of our approach 
the robustness of shape recovery based on deformable model dep end in general on the relative difference of position and topology of the initial model with respect to the data a close initialization with correct topology guaranty a proper recovery of the object furthermore the closeness of the initial model greatly influence the time of computation needed for the recovery in this paper we propose a method for initializing deformable model from range data or volumetric image the prop osed method solves two distinct problem first we use the topological segmentation of volumetric image in order to recover the approximate topology of the object second we use an efficient mesh sampling algorithm to control the number of vertex of the initial model the method take into account missing data and outlier 
this paper give a widely applicable technique for solving many of the parameter estimation problem encountered in geometric computer vision a commonly used approach is to minimize an algebraic error function instead of a possibly preferable geometric error function it is claimed in this paper that minimizing algebraic error will usually give excellent result and in fact the main problem with most algorithm minimizing algebraic distance is that they do not take account of mathematical constraint that should be imposed on the quantity being estimated this paper give an efficient method of minimizing algebraic distance while taking account of the constraint this provides new algorithm for the problem of resectioning a pinhole camera computing the fundamental matrix and computing the tri focal tensor evaluation result are given for the resectioning and tri focal tensor estimation algorithm 
for the problem of tracking vehicle on freeway using machine vision existing system work well in free flowing traffic traffic engineer however are more interested in monitoring freeway when there is congestion and current system break down for congested traffic due to the problem of partial occlusion we have developed a feature based tracking approach for the task of tracking vehicle under congestion instead of tracking entire vehicle vehicle sub feature are tracked to make the system robust to partial occlusion in order to group together sub feature that come from the same vehicle the constraint of common motion is used here we describe the real time implementation of the system using a network of dsp chip 
this paper present a robust technique to detect local deterioration of old cinematographic film this method relies on spatio temporal information and combine two different detector a morphological detector which us spatial property of deterioration and a dynamic detector based on motion estimation technique our deterioration detector ha been validated on several film sequence and turned out to be a powerful tool for digital film restoration 
this paper address a problem arising in the reverse engineering of solid model from depth map we wish to identify and t surfacesofknowntypewherevertheseareagoodt thispaperpresents a set of method for the least square tting of sphere cylinder cone andtoritothree dimensionalpointdata least squaresttingofsurfaces other plane even of simple geometric type ha been little studied our method ha the particular advantage of being robust in the sense that a the principal curvature of the surface beingtted decrease or become more equal the result which are returned naturally become closerand closertothosesurfacesof simplertype i e plane cylinder cone or sphere which best describe the data unlike other method which may diverge a various parameter or their combination become innite 
a robust and accurate polarization phase based technique for material classification is presented the novelty of this technique is three fold in i it theoretical development ii it application and iii it experimental implementation the concept of phase of polarization of a light wave is introduced to computer vision for discrimination between material according to their intrinsic electrical conductivity such a distinguishing conducting metal and poorly conducting dielectric previous work ha used intensity color and polarization component ratio this new method is based on the physical principle that metal retard orthogonal component of light upon reflection while dielectric do not this method ha significant complementary advantage with respect to existing technique is computationally efficient and can be easily implemented with existing imaging technology experiment for real circuit board inspection non conductive and conductive glass and outdoor object recognition have been performed to demonstrate it accuracy and potential capability 
given three partially overlapping view of a scene from which a set of point correspondence have been extracted recover the three trifocal tensor between the three view we give a new way of deriving the trifocal tensor based on grassmann cayley algebra that shed some new light on it structure we show that our derivation lead to a complete characterization of it geometric and algebraic property which is fairly intuitive i e geometric we give a set of algebraic constraint which 
motivated by a need to define an object centered reference system determined by the most salient characteristic of the shape many method have been proposed all of which directly or indirectly involve an axis about which the shape is locally symmetric recently a function v called the edge strength function ha been successfully used to determine efficiently the ax of local symmetry of d shape the level curve of v are interpreted a succesively smoother version of the initial shape boundary the local minimum of the absolute gradient left nabla v right along the level curve of v are shown to be a robust criterion for determining the shape skeleton more generally at an extremal point of left nabla v right along a level curve the level curve is locally symmetric with respect to the gradient vector nabla v that is at such a point the level curve is approximately a conic section whose one of the principal ax coincides with the gradient vector thus the locus ofthe extremal point of left nabla v right along the level curve determines the ax of local symmetry of the shape in this paper we extend this method to shape of arbitrary dimension 
under a weak perspective camera model the imageplane coordinate in different view of a planarobject are related by an affine transformation becauseof this property researcher have attempted touse affine invariant for recognition however thereare two problem with this approach object orobject class with inherent variability cannot be adequatelytreated using invariant and in practicethe calculated affine invariant can be quite sensitiveto error in the image 
smooth surface are approximated by polyhedral surface for a number of computational purpose an inherent problem of these approximation algorithm is that the resulting polyhedral surface appear faceted within a recently introduced signal processing approach to solving this problem surface smoothing corresponds to low pas filtering in this paper we look at the filter design problem in more detail we analyze the stability property of the low pas filter described in and show how to minimize it running time we show that most classical technique used to design finite impulse response fir digital filter can also be used to design significantly faster surface smoothing filter finally we describe an algorithm to estimate the power spectrum of a signal and use it to evaluate the performance of the different filter design technique described in the paper 
we present a method for motion estimation using ordinal measure ordinal measure are based on relative ordering of intensity value in an image region called rank permutation while popular measure like the sum of squared difference ssd and normalized correlation ncc rely on linearity between corresponding intensity value ordinal measure only require them to be monotonically related so that rank permutation between corresponding region are presented this property turn out to be useful for motion estimation in tagged magnetic resonance image we study the imaging equation involved in two method of tagging and observe temporal monotonicity in intensity under certain condition though the tag themselves fade we compare our method to ssd and ncc in a rotating ring phantom image sequence we present an experiment on a real heart image sequence which suggests the suitability of our method 
a novel approach is proposed to obtain a record of the patient s occlusion using computer vision data acquisition is obtained using intra oral video camera the technique utilizes shape from shading to extract d information from d view of the jaw and a novel technique for d data registration using genetic algorithm the resulting d model can be used for diagnosis treatment planning and implant purpose the overall purpose of this research is to develop a model based vision system for orthodontics to replace traditional approach this system will be flexible accurate and will reduce the cost of orthodontic treatment 
image quantization and dithering are fundamental image processing problem in computer vision and graphic both step are generally performed sequentially and in most case independent of each other color quantization with a pixel wise defined distortion measure and the dithering process with it local neighborhood typically optimize different quality criterion or frequently follow a heuristic approach without reference to any quality measure in this paper we propose a new model to simultaneously quantize and dither color image the method is based on a rigorous cost function approach which optimizes a quality criterion derived from a simplified model of human perception optimization are performed by an efficient multiscale procedure which substantially alleviates the computational burden the quality criterion and the optimization algorithm are evaluated on a representative set of artificial and real world image thereby showing a significant image quality improvement over standard color reduction approach 
many relaxation based smoothing method used in surface reconstruction algorithm filter out the effect of noise in image data but result in the elimination of important discontinuity information a well in this paper the inter pixel interaction during relaxation is shown to be equivalent to a multiple measurement fusion problem which can be solved using optimal estimation theory pixel in a given neighbourhood act a noisy information source combining their information to update the state of that neighbourhood by formulating discontinuity a another noise source in the image and by using the so called curvature consistency reconstruction algorithm on range image it is shown that optimal estimation theory offer a method for the automatic and adaptive localization of discontinuity while providing a smooth piece wise continuous surface description 
we show that we can effectively fit arbitrarily complex animation model to noisy image data our approach is based on least square adjustment using of a set of progressively finer control triangulation and take advantage of three complementary source of information stereo data silhouette edge and d feature point 
we present an incremental system that build accurate cad model of object from multiple range image using a hybrid of surface mesh and volumetric representation the system creates a water tight d model at each step of the modeling process allowing reasonable model to be built from a small number of view we also present a method that can be used to plan the next view and reduce the number of scan needed to recover the object result are presented for the creation of d model of a computer game controller a hip joint prosthesis and a mechanical strut 
the determination of the position and the orientation of the camera from the known correspondence of the reference point and the image point is known a the problem of pose estimation in computer vision or space resection in photogrammetry it is well known that using corresponding point ha at most solution le appears to be known about the case of and point in this paper we describe linear solution that always give the unique solution to point and point pose determination for the reference point not lying on the critical configuration the same linear method can also be extended to any n point the robustness and accuracy of the method are experimented both on simulated and real image 
an algorithm for simultaneous detection segmentation and characterization of spatiotemporal periodicity is presented the use of periodicity template is proposed to localize and characterize temporal activity the template not only indicate the presence and location of a periodic event but also give an accurate quantitative periodicity measure hence they can be used a a new mean of periodicity representation the proposed algorithm can also be considered a a periodicity filter a low level model of periodicity perception the algorithm is computationally simple and shown to be more robust than optical flow based technique in the presence of noise a variety of real world example are used to demonstrate the performance of the algorithm 
feature indexing technique are promising for object recognition since they can quickly reduce the set of possible match for a set of image feature this work exploit another property of such technique they have inherently parallel structure and connectionist network formulation are easy to develop once indexing ha been performed a voting scheme such a geometric hashing can be used to generate object hypothesis in parallel we describe a framework for the connectionist implementation of such indexing and recognition technique with sufficient processing element recognition can be performed in a small number of time step the number of processing element necessary to achieve peak performance and the fan in fan out required for the processing element is examined these technique have been simulated on a conventional architecture with good result 
we propose a novel approach for solving the perceptual grouping problem in vision rather than focusing on local feature and their consistency in the image data our approach aim at extracting the global impression of an image we treat image segmentation a a graph partitioning problem and propose a novel global criterion the normalized cut for segmenting the graph the normalized cut criterion measure both the total dissimilarity between the different group a well a the total similarity within the group we show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion we have applied this approach to segmenting static image a well a motion sequence and found the result to be very encouraging 
this paper describes a general purpose method we have developed for automatically segmenting object of an unknown number and unknown location in image our method integrates deformable model and statistic of image cue including intensity gradient color and texture by using a combination of image feature rather than a single feature such a gradient our method is more robust to noise and sparse data to allow for the automated segmentation of an unknown number and location of object we simultaneously segment object initialized at uniformly distributed point in the image a method is developed to automatically merge model corresponding to the same object result of the method are presentedfor several example including greyscale color and noisy image 
we present an analysis of sfm from the point of view of noise this analysis result in an algorithm that is provably convergent and provably optimal with respect to a chosen norm in particular we cast sfm a a nonlinear optimization problem and define a bilinear projection iteration that converges to fixed point of a certain cost function we then show that such fixed point are fundamental i e intrinsic to the problem of sfm and not an artifact introduced by our algorithm we classify and characterize geometrically local extremum and we argue that they correspond to phenomenon observed in visual psychophysics finally we show under what condition it is possible given convergence to a local extremum to jump to the valley containing the optimum this lead u to suggest a representation of the scene which is invariant with respect to such local extremum 
we discus the uniqueness of d shape recovery of a polyhedron from a single shading image first we analytically show that multiple convex and concave shape solution usually exist for a simple polyhedron if interreflection are not considered then we propose a new approach to uniquely determine the concave shape solution using interreflection a a constraint a numerical example in which two convex shape and two concave shape exist for a trihedral corner ha been shown by horn however it is difficult to prove the uniqueness using constraint equation we analytically show that multiple convex and concave shape solution usually exist for a pyramid using a reflectance map if interreflection distribution is not considered however if interreflection distribution is used a a constraint that limit the shape solution for a concave polyhedron the polyhedral shape can be uniquely determined interreflection are used a a constraint to determine the shape solution in our approach 
historically ssd or correlation based visual tracking algorithm have been sensitive to change in illumination and shading across the target region this paper describes method for implementing ssd tracking that is both insensitive to illumination variation and computationally efficient we first describe a vector space formulation of the tracking problem showing how to recover geometric deformation we then show that the same vector space formulation can be used to account for change in illumination we combine geometry and illumination into an algorithm that track large image region on live video sequence using no more computation than would be required to trade with no accommodation for illumination change we present experimental result which compare the performance of ssd tracking with and without illumination compensation 
foveated vision and two mode tracking a inspired by the human oculomotor system are often used in active vision system the purpose of this paper is to provide answer to the following basic question which arise from implementation first is it beneficial to have foveated vision and what is the optimal size of the foveal window second is there a need for two control mechanism smooth pursuit and saccade for improved performance and how can one efficiently switch between them in order to do so a setup is proposed in which these strategy can be evaluated in a systematic manner it is shown that the fovea appears a a compromise between the tightness of the tracking specification and computational constraint introducing a model for the later and postulating some a priori knowledge of the target behavior it is possible to compute the size of the fovea in an optimal way a a by product smooth pursuit can be defined in a natural way and the use of a two mode tracking scheme is justified the second mode i e saccadic control aim at re centering the target on the fovea so that the smooth pursuit controller can continue to operate it is shown that a control strategy can indeed be defined so that this objective can be met under appropriate operating condition 
this paper present a novel approach to the recovery of generic solid part ofobjects from real d image the part vocabulary chosen is the one of geons whichare qualitative volumetric part primitive that are defined by simple but perceptuallyrelevant property which are viewpoint quasi invariant most previous workson detection and recognition of geons from d image relied on quasi perfect linedrawings the use of aspect ha also been proposed for matching fixed template of 
this paper considers the effect of spatial quantization on several moment invariant of particular interest are the affine moment invariant which have emerged in recent year a a useful tool for image reconstruction image registration and recognition of deformed object traditional analysis assumes moment and moment invariant for image that are defined in the continuous domain in practice however the digitization process introduces error that violate the invariance assumption this paper present an analysis of quantization induced error on two dimensional hu moment invariant and affine moment invariant and on invariant derived from one dimensional contour moment error bound are given in several case 
this paper address robust feature tracking we extend the well known shi tomasi kanade tracker by introducing an automatic scheme for rejecting spurious feature we employ a simple and efficient outlier rejection rule called x and prove that it theoretical assumption are satisfied in the feature tracking scenario experiment with real and synthetic image confirm that our algorithm make good feature track better we show a quantitative example of the benefit introduced by the algorithm for the case of fundamental matrix estimation the complete code of the robust tracker is available via ftp 
we study the problem of how to detect interesting object appeared in a given image i our approach is to treat it a a function approximation problem based on an over redundant basis and also account for occlusion where the basis superposition principle is no longer valid since the basis a library of image template is over redundant there are infinitely many way to decompose i we are motivated to select a sparse compact representation of i and to account for occlusion and noise we then study a greedy and iterative weighted lp matching pursuit strategy with 
this paper describes a technique for the reconstruction and segmentation of three dimensional acoustical image using a coupled random field able to actively integrate confidence information associated with acquired data beamforming a method widely applied in acoustic imaging is used to build a three dimensional image associated point by point with another kind of information representing the reliability i e confidence of such an image unfortunately this kind of image is plagued by several problem due to the nature of the signal and to the related sensing system thus heavily affecting data quality specifically speckle noise and the broad directivity characteristic of the sensor lead to very degraded image in the proposed algorithm range and confidence image are modelled a markov random field whose associated probability distribution are specified by a single energy functional a threefold process ha been applied able to reconstruct segment and restore the involved acoustic image exploiting both type of data our approach showed better performance with respect to other mrf based method a well a classical method disregarding reliability information optimal in the maximum a posteriori probability sense estimate of the d and confidence image are obtained by minimizing the energy functional by using simulated annealing 
in geometrical camera calibration the objective is to determine a set of camera parameter that describe the mapping between d reference coordinate and d image coordinate various method for camera calibration can be found from the literature however surprisingly little attention ha been paid to the whole calibration procedure i e control point extraction from image model fitting image correction and error originating in these stage the main interest ha been in model fitting although the other stage are also important in this paper we present a four step calibration procedure that is an extension to the two step method there is an additional step to compensate for distortion caused by circular feature and a step for correcting the distorted image coordinate the image correction is performed with an empirical inverse model that accurately compensates for radial and tangential distortion finally a linear method for solving the parameter of the inverse model is presented 
we present method for the global reconstruction of some class of special surface the contour ending cusp on the apparent contour is tracked under a dynamic monocular perspective observer the class of surface considered are surface of revolution sor canal surface and ruled surface this paper present theoretical method for surface reconstruction and error analysis of reconstruction under noise we find the technique used exhibit stability even under large noise this work ha added to the accumulating body of work that ha arisen in the computer vision community concerning the differential geometric aspect of special surface class 
a family of structure from motion algorithm called the factorization method ha been recently developed from the orthographic projection model to the affine camera model all these algorithm are limited to handling only point feature of the image stream we propose in this paper an algorithm for the recovery of shape and motion from line correspondence by the factorization method with the affine camera instead of one step factorization for point a multi step factorization method is developed for line based on the decomposition of the whole shape and motion into three separate substructure each of these substructure can then be linearly solved by factorizing the appropriate measurement matrix it is also established that affine shape and motion with uncalibrated affine camera can be achieved with at least seven line over three view which extends the previous result of koenderink and van doorn for point to line 
we develop a local image correspondence algorithm which performs well near occluding boundary unlike traditional robust method our method can find correspondence when the only contrast present is the occluding boundary itself and when the sign of contrast along the boundary is possibly reversed we define a new image transform which characterizes local image homogeneity defined a an attribute value in a central region and most generally a function describing the surrounding local similarity structure in this paper we use radial similarity function and color attribute within each window we compute the central color and an image with the cumulative probability color is unchanged along a ray from the center to a given point in the window this representation is insensitive to structure outside an occluding boundary but can model the boundary itself we show comparative result tracking finger mouth and eye feature 
this paper present a novel multiscale representation of one dimensional signal based on complex analysis we show that a signal and it derivative at different scale can be represented by one analytic function defined on the unit disc in the complex plane which is called the schwarz representation of a signal this representation is applied to the matching problem using the theory of analytic function we are able to define the inverse of a signal the matching function between two signal can be defined a the composition of one signal s schwarz representation and another signal s inverse the matching function determined by this method ha a group structure and is close formed 
image appearance may change over time due to a variety of cause such a object or camera motion generic photometric event including variation in illumination e g shadow and specular reflection and iconic change which are specific to the object being viewed and include complex occlusion event and change in the material property ofthe object we propose a general framework for representing and recovering these appearance change in an image sequence a a mixture of different cause the approach generalizes previous work on optical flow to provide a richer description of image event and more reliable estimate of image motion 
this paper present a new algorithm for detecting object in image one of the fundamental task of computer vision the algorithm extends the representational efficiency of eigenimage method to binary feature which are le sensitive to illumination change than gray level value normally used with eigenimages binary feature square subtemplates are automatically chosen on each training image using feature rather than whole template make the algorithm more robust to background clutter and partial occlusion instead of representing the feature with real valued eigenvector principle component we use binary vector quantization to avoid floating point computation the object is detected in the image using a simple geometric hash table and hough transform on a test of image the algorithm work on we present a theoretical analysis of the algorithm in term of the receiver operating characteristic which consists of the probability of detection and false alarm we verify this analysis with the result of our image test and we use the analysis a a principled way to select some of the algorithm s important operating parameter 
traditional subspace method for face recognition compute a measure of similarity between image after projecting them onto a fixed linear subspace that is spanned by some principal component vector a k a eigenfaces of a training set of image by supposing a parametric gaussian distribution over the subspace and a symmetric gaussian noise model for the image given a point in the subspace we can endow this framework with a probabilistic interpretation so that bayes optimal decision can be made however we expect that different image cluster corresponding say to different pose and expression will be best represented by different subspace in this paper we study the recognition performance of a mixture of local linear subspace model that can be fit to training data using the expectation maximization algorithm the mixture model outperforms a nearest neighbor classifier that operates in a pca subspace 
a fundamental problem in depth from defocus is the measurement of relative defocus between image we propose a class of broadband operator that when used together provide invariance to scene texture and produce accurate and dense depth map since the operator are broadband a small number of them are sufficient for depth estimation of scene with complex textural property experiment are conducted on both synthetic and real scene to evaluate the performance of the proposed operator the depth detection gain error is le than irrespective of texture frequency depth accuracy is found to be spl sim of the distance of the object from the imaging optic 
the computational cost of conventional filter method for junction characterization is very high this burden can be attenuated by using steerable filter however in order to achieve a high orientational selectivity to characterize complex junction a large number of basis filter is necessary from this result a yet too high computational effort for steerable filter in this paper we present a new method for characterizing junction which keep the high orientational resolution and is computationally efficient it is based on applying rotated copy of a wedge averaging filter and estimating the derivative with respect to the polar angle the new method is compared with the steerable wedge filter method in experiment with real image we show the superiority of our method a well a it adaptability to scale change and robustness against noise 
we introduce a method for segmenting surface of three dimensional object using two image of the object obtained from the same viewpoint under different illumination condition the method allows surface spectral reflectance to vary from point to point and requires only weak condition on the uncalibrated illumination configuration the algorithm is based on the local recovery of an illumination change matrix that depends on surface geometry but not on the spectral reflectance of the surface we show that for typical sensor noise level this technique can be used for the reliable detection of surface orientation change of a few degree this approach can be generalized using a calibrated setup to recover a dense set of surface orientation estimate from two image we present a set of experiment demonstrating the capability of the algorithm for the segmentation of planar surface in the presence of spatially varying spectral reflectance 
we have recently proposed a scale adaptive algorithm for reliable edge detection and blur estimation the algorithm produce a contour code which consists of estimate of position brightness contrast and blur for each edge point in the image here we address two question can scale adaptation be used to achieve precise localization of blurred edge how much of the perceptual content of an image is carried by the d contour code we report an efficient algorithm for subpixel localization and show that local scale control allows excellent precision even for highly blurred edge we further show how local scale control can quantitatively account for human visual acuity of blurred edge stimulus to address the question of perceptual content we report an algorithm for inverting the contour code to reconstruct an estimate of the original image while reconstruction based on edge brightness and contrast alone introduces significant artifact restitution of the local blur signal is shown to produce perceptually accurate reconstruction 
we present an extension of the usual projective geometric framework for computer vision which can nicely take into account an information that wa previously not used i e the fact that the pixel in an image correspond to point which lie in front of the camera this framework called the oriented projec tive geometry retains all the advantage of the unoriented projective geometry namel y it simplicity for expressing the viewing geometry of a system of camera while extending it adequation to model realistic situation we discus the mathematical and practical issue raised by this new framework for a number of computer vision algorithm we present different experiment where this new tool clearly help 
previous work ha developed an approach for estimating shape and albedo from multiple image assuming lambertian reflectance with single light source the main contribution of this paper are i to show how the approach can be generalized to include ambient background illumination ii to demonstrate the use of the integrability constraint for solving this problem and iii an iterative algorithm which is able to improve the analysis by finding shadow and rejecting them 
we compute the sign of gaussian curvature using a purely geometric definition consider a point p on a smooth surface s and a closed curve g on s which encloses p the image of g on the unit normal gaussian sphere is a new curve b the gaussian curvature at p is defined a the ratio of the area enclosed by g over the area enclosed by b a g contract to p the sign of gaussian curvature at p is determined by the relative orientation of the closed curve g and b we directly compute the relative orientation of two such curve from intensity data we employ three unknown illumination condition to create a photometric scatter plot this plot is in one to one correspondence with the subset of the unit gaussian sphere containing the mutually illuminated surface normal this permit direct computation of the sign of gaussian curvature without the recovery of surface normal our method is albedo invariant we assume diffuse reflectance but the nature of the diffuse reflectance can be general and unknown simulation a well a empirical result demonstrate the accuracy of our technique 
in this paper we describe a method for estimating the internal parameter of the left and right camera associated with a stereo image pair the stereo pair ha known epipolar geometry and therefore d projective reconstruction of pair of matched image point is available the stereo pair is allowed to move and hence there is a collineation relating the two projective reconstruction computed before and after the motion we show that this collineation ha similar but different 
we develop a simple and very fast method for object tracking based exclusively on color information in digitized video image running on a silicon graphic r indy system with an indycam our algorithm is capable of simultaneously tracking object at full frame size time pixel and video frame rate fps robustness with respect to occlusion is achieved via an explicit hypothesis tree model of the occlusion process we demonstrate the efficacy of our technique in the challenging task of tracking people especially tracking human head and hand 
abstract in extended video sequence individual frame are grouped into shot which are defined a a sequence taken by a single camera and related shot are grouped into scene which are defined by a single dramatic event taken by a small number of related camera this hierarchical structure is deliberately constructed dictated by the limitation and preference of the human visual and memory system we present three novel high level segmentation result derived from these consideration some of which are analogous to those involved in the perception of the structure of music first and primarily we derive and demonstrate a method for measuring probable scene boundary by calculating a short term memory based model of shot to shot coherence the detection of local minimum in this continuous measure permit robust and flexible segmentation of the video into scene without the necessity for first aggregating shot into cluster second and independently of the first we then derive and demonstrate a one pas on the fly shot clustering algorithm third we demonstrate partially successful result on the application of these two new method to the next higher theme level of video structure index term digital and video library low level vision color and texture pattern analysis segmentation and grouping vision based computer interface 
robust technique are developed for determining structure from motion in the uncalibrated case the structure recovery is based on previous work in which it wa shown that a camera undergoing unknown motion and having an unknown and possibly varying focal length can be self calibrated via closedform expression in the entry of two matrix derivable from an instantaneous optical flow field critical to the recovery process is the obtaining of accurate numerical estimate up to a scalar factor of these matrix in the presence of noisy optical flow data we present technique for the determination of these matrix via least square method and also a way of enforcing a dependency constraint that is imposed on these matrix a method for eliminating outlying flow vector is also given result of experiment with real image sequence are presented that suggest that the approach hold promise 
automatic target recognition atr application require simultaneously a wide field of view fov for better detection and situation awareness high resolution for target recognition and threat assessment and high frame rate for detecting brief event and disambiguating frame to frame correlation uniformly sampling the entire fov at recognition resolution is simply wasteful in atr scenario with localized region of interest roi foveal data acquisition with space variant sampling and contextsensitive sensor articulation is highly optimized for active atr application we propose a multiscale local zernike filter based front end target detection technique for a commercially feasible foveal sensor topology with piecewise constant resolution profile anisotropic heat diffusion is employed for preprocessing of the foveal data expansion template matching is used to derive a detection filter that optimizes the discriminant signal to noise ratio snr result are presented with simulated foveal imagery derived from real uniform acuity flir data 
following the success of applying deformable model to feature extraction a natural next step is to apply such model to pattern classification recently we have cast a deformable model under a bayesian framework for classification giving promising result however deformable model method are computationally expensive due to the required iterative optimization process the problem is even more severe when there are a large number of model e g for character recognition because each of them ha to deform and match with the input data before a final classification can be derived in this paper we propose to combine the deformable model into a mixture in which the individual model compete with each other to survive the matching process during classification model that do not compete well are eliminated early thus allowing substantial saving in computation this process of competition elimination ha been applied to handwritten digit recognition in which significant speedup can be achieved without sacrificing recognition accuracy 
an iterative predict and match system render cadmodels to refine prediction about detectable feature inboth optical and range sensor data predicted featuresadapt to a scene specific interpretation which includesa time of day lighting model and reasoning about unmodeledoccluding surface during rendering linksbetween the rendered image and the d cad modelare retained to propagate information between objectmodel scene and sensor coordinate reference frame precise geometric 
we present a vision system for the d model based tracking of unconstrained human movement using image sequence acquired simultaneously from multiple view we recover the d body pose at each time instant without the use of marker the pose recovery problem is formulated a a search problem and entail finding the pose parameter of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi view image the model used for this purpose are acquired from the image we use a decomposition approach and a best first technique to search through the high dimensional pose parameter space a robust variant of chamfer matching is used a a fast similarity measure between synthesized and real edge image we present initial tracking result from a large new human in action hia database containing more than frame in each of four orthogonal view they contain subject involved in a variety of activity of various degree of complexity ranging from the more simple one person hand waving to the challenging two person close interaction in the argentine tango 
this paper describes a new method for face recognition under drastic change of the imaging process through which the facial image are acquired unlike the conventional method that use only the face feature the present method exploit the statistical information of the variation between the face image set being compared in addition to the feature of the face themselves to incorporate both of the face and perturbation feature for recognition we develop a technique called weak orihogonalization of the two subspace that transforms the given two overlapped subspace so that the volume of the intersection of the resulting two subspace is minimized matching operation are performed in the transformed face space that ha thus been weakly orihogonalized against perturbation space experimental result on real picture of the frontal face from driver license show that the new algorithm improves the recognition performance over the conventional method we also demonstrate the effectiveness of our method on image set with change in viewing geometry 
a novel geometric approach for d object segmentation and representation is presented the scheme is based on geometric deformable surface moving towards the object to be detected we show that this model is equivalent to the computation of surface of minimal area better known a minimal surface in a riemannian space this space is defined by a metric induced from the d image volumetric data in which the object are to be detected the model show the relation between classical deformable surface obtained via energy minimization and geometric one derived from curvature based flow the new approach is stable robust and automatically handle change in the surface topology during the deformation based on an efficient numerical algorithm for surface evolution we present example of object detection in real and synthetic image 
this contribution attempt to move beyond the status where single moving object in video image sequence are tracked separately in the scene domain based on individually adapted approach and parameter instead we investigate which performance can be achieved by a combination of approach based on edge element orientation and on optical flow applied to a variety of image sequence and vehicle five different image sequence of traffic scene recorded under different condition have been evaluated quantitative statement are provided about the success rate of the approach after evaluating over full video frame i e more than minute of real world video using one single approach and a single parameter set remaining tracking failure are analyzed and classified 
a method for calculating optic flow using robust statistic is developed the method generally out performs all competing method in term of accuracy one of the key feature in the success of this method is that we use least median of square which is known to be robust to outlier the computational cost is kept very low by using an approximate solution to the least median of square only in a first stage that detects outlier the essential ingredient of our method should be applicable in a wide range of other computer vision problem 
a robust iterative approach is introduced for finding the dominant plane in a scene using binocular vision neither camera calibration nor stereo correspondence is required recently cohen formalized a framework guaranteeing local convergence of iterative two step method in this paper the framework is adopted with a global step using tentative match to estimate the planar projectivity and a local step attempting to solve the stereo correspondence a detected point in the first image is matched to an auxiliary point in the second image on the line joining the transformed first image point and it closest detected second image point convergence is assured while achieving robustness to both mismatching and non coplanar point 
a method of localising object in image is proposed possible configuration are evaluated using the contour discriminant a likelihood ratio which is derived from a probabilistic model of the feature detection process we treat each step in this process probabilistically including the occurrence of clutter feature and derive the observation density for both correct target configuration and incorrect clutter configuration the contour discriminant distinguishes target object from the background even in heavy clutter making only the most general assumption about the form that clutter might take the method generates sample stochastically to avoid the cost of processing an entire image and promise to be particularly suited to the task of initialising contour tracker based on sampling method 
this paper describes a method to upgrade projective reconstruction to affine and to metric reconstruction using rigid gener almotions of a stereo rig we make clear the algebraic relationship between projective reconstruction the plane at infinity affine reconstruction camera calibration and metric reconstruction we show that all the computation can be carried out using standard linear resolution method and that these method compare favorably with nonlinear optimization method in the presence of gaussian noise we carry out a theoretical error analysis which quantify the relative importance of the accuracy of projective to affine conversion and affine to euclidean conversion experiment with real data are consistent with the theoretical error analysis and with a sensitivity analysis performed with simulated data 
in a new object representation using appearance based part and relation to recognize d object from d image in the presence of occlusion and background clutter wa introduced appearance based part and relation are defined in term of closed region and the union of these region respectively the region are segmented using the mdl principle and their appearance is obtained from collection of image and compactly represented by parametric manifold in the eigenspaces spanned by the part and the relation in this paper we introduce the discriminatory power of the proposed feature and describe how to use it to organize large database of object 
we are interested in description of d data set a obtained from stereo or a d digitizer we therefore consider a input a sparse set of point possibly associated with orientation information in this paper we address the problem of inferring integrated high level description such a surface curve and junction from a sparse point set while the method described previously provides excellent result for smooth structure it only detects discontinuity but doe not localize them for precise localization we propose a non iterative cooperative algorithm in which surface curve and junction work together initial estimate are computed based on previous result where each point in the given sparse and possibly noisy point set is convolved with a predefined vector mask to produce dense saliency map these map serve a input to our novel maximal surface and curve marching algorithm for initial surface and curve extraction refinement of initial estimate is achieved by hybrid voting using excitatory and inhibitory field for inferring reliable and natural extension so that surface curve and curve junction discontinuity are preserved result on several synthetic a well a real data set are presented 
over recent year symmetry research ha shifted from the detection of affinely to perspectively skewed mirror symmetry also link between invariance research and symmetry specific geometric constraint have been established the paper aim to contribute to both strand several set of symmetry specific invariant are derived that can be used in different situation depending on the a priori assumption made it is also argued that all the result directly apply to the case of perspectively skewed point symmetry 
in this paper we present an automatic system for analyzing and annotating video sequence of technical talk our method us a robust motion estimation technique to detect key frame and segment the video sequence into subsequence containing a single overhead slide the subsequence are stabilized to remove motion that occurs when the speaker adjusts their slide any change remaining between frame in the stabilized sequence may be due to speaker gesture such a pointing or writing and we use active contour to automatically track these potential gesture given the constrained domain we define a simple vocabulary of action which can easily be recognized based on the active contour shape and motion the recognized action provide a rich annotation of the sequence that can be used to access a condensed version of the talk from a web page 
this paper is concerned with the problem of tracking cloud structure like vortex in meteorological image for this purpose we characterize the deformation between two successive occurrence by matching their two boundary curve our approach is based on the computation of the set of path connecting the two curve to be matched it minimizes a cost function which measure the local similarity of the two curve these matching path are obtained a geodesic curve on this cost surface moreover our method allows to consider complex curve of arbitrary topologysince these curve are represented through an implicit function rather than through a parameterization experimental result are given to illustrate the property of themethod in processing synthetic and then meteorologic remotely sensed data 
in this paper we propose an algorithm for doing reconstruction of general sd curve from a number of d image taken by uncalibrated camera no point correspondence between the image are assumed the curve and the view point are uniquely reconstructed module common projective transformation and the point correspondence problem is solved furthermore the algorithm is independent of the choice of coordinate a it is based on orthogonal projection and aligning subspace the algorithm is based on an extension of afine shape of finite point configuration to more general object 
selecting the appropriate spatial scale for local edge analysis is a challenge for natural image where blur scale and contrast may vary over a broad range while previous method for scale adaptation have required the global solution of a non convex optimization problem it is shown that knowledge of sensor property and operator norm can be exploited to define a unique locally computable minimum reliable scale for local estimation the resulting method for local scale control allows edge spanning a broad range of blur scale and contrast to be reliably localized by a single system with no input parameter other than the second moment of the sensor noise local scale control further permit the reliable estimation of local blur scale in complex image where the condition demanded by fourier method for blur estimation break down 
using a combination of technique from visual representation view synthesis and visual motor model estimation we present a method for animating movement of an articulated agent e g human or robot arm without the use of any prior model or explicit d information the information needed to generate simulated image can be acquired either on or off line by watching the agent doing an arbitrary possibly unrelated task we present experimental result synthesizing image sequence of the simulated movement of a human arm and a puma robot arm control is in either image camera motor joint or cartesian world coordinate we have created a user interface where a user can input a movement program and then upon execution view movie of the simulated agent executing the program along with the instantaneous value of the dynamic variable 
we have developed a video rate stereo machine that ha the capability of generating a dense depth map at the video rate the performance bench mark of the cmu video rate stereo machine are multi image input of up to camera throughput of million point disparity measurement per second frame rate of frame sec a dense depth map of up to x pixel disparity search range of up to pixel high precision of depth output up to bi t with interpolation the capability of passively producing such a dense depth map d representation of a scene at the video rate can open up a new class of application of d vision merging real and virtual world in real time 
the problem of tracking curve in dense visual clutter is a challenging one tracker based on kalman filter are of limited use because they are based on gaussian density which are unimodal they cannot represent simultaneous alternative hypothesis extension to the kalman filter to handle multiple data association work satisfactorily in the simple case of point target but do not extend naturally to continuous curve a new stochastic algorithm is proposed here the condensation algorithm conditional density propagation over time it us factored sampling a method previously applied to interpretation of static image in which the distribution of possible interpretation is represented by a randomly generated set of representative the condensation algorithm combine factored sampling with learned dynamical model to propagate an entire probability distribution for object position and shape over time the result is highly robust tracking of agile motion in clutter markedly superior to what ha previously been attainable from kalman filtering notwithstanding the use of stochastic method the algorithm run in near real time 
the euclidean skeleton is essential for general shape representation this paper provides an efficient method to extract a well connected euclidean skeleton by a neighbor bisector decision ned rule on a vector distance map the shortest vector which generates a pixel s distance is stored when calculating the distance map a skeletal pixel is extracted by checking the vector of the pixel and it neighbor this method succeeds in generating a well connected euclidean skeleton without any linking algorithm a theoretical analysis and many experiment with image of different size also show the ned rule work excellent the average complexity of the method with the ned rule algorithm and the vector distance transform algorithm is linear in the number of the pixel 
this paper present a novel approach to part based object recognition in the presence of occlusion we focus on the problem of determining the pose of a d object from a single d image when convex part of the object have been matched to corresponding region in the image we consider three type of occlusion self occlusion occlusion whose locus is identified in the image and completely arbitrary occlusion we derive efficient algorithm for the first two case and characterize their performance for the last case we prove that the problem of finding valid pose is computationally hard but provide an efficient approximate algorithm this work generalizes our previous work on region based object recognition which focused on the case of planar model 
this paper present a theoretical framework for the combination of soft decision generated by expert employing mixed some shared and some distinct object representation by taking the confidence of the individual expert into account weighted benevolent fusion strategy are derived this provides a basis for combining classifier and illustrates that a substantial gain in performance can be achieved by fusing the opinion of multiple expert these strategy are experimentally tested and their effectiveness is considered 
we propose an automated approach to modeling drainage channel and more generally linear feature that lie on the terrain from multiple image which result not only in high resolution accurate and consistent model of the feature but also of the surrounding terrain in our specific case we have chosen to exploit the fact that river flow downhill and lie at the bottom of local depression in the terrain valley floor tend to be u shaped and the drainage pattern appears a a network of linear feature that can be visually detected in single gray level image different approach have explored individual facet of this problem ours unifies these element in a common framework we accurately model terrain and feature a dimensional object from several information source that may be in error and inconsistent with one another this approach allows u to generate model that are faithful to sensor data internally consistent and consistent with physical constraint 
tracking research ha diverged into two camp low level approach which are typically fast and robust but provide little fine scale information and high level approach which track complex deformation in high dimensional space but must trade off speed against robustness real time high level system perform poorly in clutter and initialisation for most high level system is either performed manually or by a separate module this paper present a new technique to combine lowand 
two novel variant of dynamic link architecture that are based on mathematical morphology and incorporate coefficient which weigh the contribution of each node in elastic graph matching according to it discriminatory power are developed they are the so called morphological dynamic link architecture and the morphological signal decomposition dynamic link architecture the proposed variant are tested for face authentication in a cooperative scenario where the candidate claim an identity to be checked their performance is evaluated in term of their receiver operating characteristic and the equal error rate achieved in m vt database an equal error rate in the range is reported 
a multi image focus of attention mechanism ha been developed that can quickly distinguish raised object like building from structured background clutter typical to many aerial image scenario the underlying approach is the space sweep stereo method in which feature from multiple image are backprojected onto a virtual horizontal plane that is methodically swept through the scene backprojected gradient orientation from multiple image are highly correlated when they come from scene location containing structural edge that are roughly horizontal like building roof and terrain otherwise they tend to be uniformly distributed these observation are used to define a structural salience measure that can determine whether a given volume of space contains a statistically signijicant number of structural edge without first pe otrning precise reconstruction of those edge the utility of structural salience for computing focus of attention region is illustrated on sample data from ft hood texas 
a novel deformable template is presented which detects the boundary of an open hand in a grayscale image a dynamic programming algorithm enhanced by pruning technique find the hand contour in the image in a little a second without initialization by the user the template is translationand rotation invariant and accomodates shape deformation significant occlusion and background clutter and the presence of multiple hand 
this paper address the problem of recognizing object in large image database the method is based on local characteristic which are invariant to similarity transformation in the image these characteristic are computed at automatically detected keypoints using the greyvalue signal the method therefore work on image such a painting for which geometry based recognition fails due to the locality of the method image can be recognized being given part of an image and in the presence of occlusion applying a voting algorithm and semi local constraint make the method robust to noise scene clutter and small perspective deformation experiment show an efficient recognition for different type of image the approach ha been validated on an image database containing image some of them being very similar by structure texture or shape 
in this paper we propose an algorithm for estimating dense shape and motion of dynamic piecewise planar scene from region correspondence using factorization region correspondence are used since they are easier to establish and more reliable than either line or point correspondence the image measurement required are the centroid and area for each region singular value decomposition is employed to find the basis of range space of the motion shape and surface normal matrix by imposing model constraint motion shape and surface normal can be recovered only from region correspondence 
if d rigid motion is estimated with some error a distorted version of the scene structure will in turn be computed of computational interest are these region in space where the distortion are such that the depth become negative because in order to be visible the scene ha to lie in front of the image the stability analysis for the structure from motion problem presented in this paper investigates the optimal relationship between the error in the estimated translational and rotational parameter of a rigid motion that result in the estimation of a minimum number of negative depth value the input used is the value of the flow along some direction which is more general than optic flow or correspondence for a planar retina it is shown that the optimal configuration is achieved when the projection of the translational and rotational error on the image plane are perpendicular furthermore the projection of the actual and the estimated translation lie on a line passing through the image center for a spherical retina given a rotational error the optimal translation is the correct one while given a translational error the optimal rotational error is normal to the translational one at an equal distance from the real and estimated translation the proof besides illuminating the confounding of translation and rotation in structure from motion have an important application to ecological optic explaining difference of planar and spherical eye or camera design in motion and shape estimation 
in this paper we consider the problem of finding corresponding point from multiple perspective projection image the correspondence problem and estimating the d point from which these point have arisen the triangulation problem we pose the triangulation problem a that of finding the bayesian maximum a posteriori estimate of the d point given it projection in n image assuming a gaussian error model for the image point co ordinate and the camera parameter we solve this by an iterative steepest descent method we then consider the correspondence problem a a statistical hypothesis verification problem given a set of d point under the hypothesis that the point are in correspondence the map estimate of the d point is computed based on the map estimate we derive a statistical test for verifying this hypothesis to find set of corresponding point when multiple point in each of n image are given we propose a method that doe the bayesian triangulation and hypothesis verification on each n tuple of point selecting those that pas the hypothesis test we characterize the performance of the bayesian triangulation in term of the average distance of the triangulated d point from the true d point and of the point correspondence method in term of it misdetection and false alarm rate 
the problem of segmenting a volumetric layer of finite thickness is encountered in several important area within medical image analysis key example include the extraction of the cortical gray matter of the brain and the left ventricle myocardium of the heart the coupling between the two bounding surface of such a layer provides important information that help to solve the segmentation problem here we propose a new approach of coupled surface propagation via level set method which take into account coupling a an important constraint by evolving two embedded surface simultaneously each driven by it own image derived information while maintaining the coupling we capture a representation of the two bounding surface and achieve automatic segmentation on the layer characteristic gray level value instead of image gradient information alone are incorporated in deriving the useful image information to drive the surface propagation which enables our approach to capture the homogeneity inside the layer the level set implementation offer the advantage of easy initialization computational efficiency and the ability to capture deep fold of the sulcus a a test example we apply our approach to unedited d magnetic resonance mr brain image our algorithm automatically isolates the brain from non brain structure and recovers the cortical gray matter 
recently we have proposed a new approach to estimation of the coefficient of eigenimages which is robust against occlusion varying background and other type of non gaussian noise in this paper we show that our method for estimating the coefficient can be applied to convolved and subsampled image yielding the same value of the coefficient this enables an efficient multiresolution approach where the value of the coefficient can directly be propagated through the scale this property is used to extend our robust method to the problem of scaled image we performed extensive experimental evaluation to confirm our theoretical result 
current system for content filtering browsing and retrieval rely on low level image descriptor which are un intuitive for most user in this paper we propose an alternative framework that exploit the structured nature of most content source to achieve semantic content characterization and lead to much more meaningful user interaction computationally this framework is based on the principle of bayesian inference and can be implemented efficiently with bayesian network a an illustration of it potential we apply it to the domain of movie database 
in this research we propose a new iterative shape from texture sft algorithm which extract accurate surface depth information of a curved object covered with fairly homogeneous texture directly the shape information can be inferred from the rate of texture distortion depicted in an image and therefore the modeling of the projection and surface geometry a well a the estimation of local texture variation are crucial in obtaining accurate surface shape of an object by introducing semi perspective projection camera model and a parametric surface model we establish a new sft problem formulation called the textural irradiance equation which relates the local texture density called textural intensity to finite surface parameter moreover by adopting an adaptive multiscale filtering scheme for local texture density estimation in which the scale or frequency band of a local edge filter is chosen adaptively according to the local shape information we greatly enhance the accuracy of the estimation of the projected local texture density and the final reconstructed shape we demonstrate the performance of the proposed algorithm by the test with several synthetic and real texture image 
this paper considers a model based approach to identifying and locating known d object from d image the method is based on geometric feature matching of the model and image data where both are represented in term of local geometric feature this paper extends and refines previous work on feature matching using transformation constraint method by detailing the case of full d object represented a point feature and developing geometric algorithm based on conservative approximation to the previously presented general algorithm which are much more computationally feasible 
temporal segmentation of video is a necessary first step to indexing digital video for browsing and retrieval a number of different video temporal segmentation algorithm have been published in the literature there ha been little effort to evaluate and characterize their performance so a to deliver a single or set of algorithm that may be used by other researcher for indexing video database we present result of evaluating a number of these algorithm and characterizing their performance specifically with respect to robustness to encoder and bitrate change the lesson learnt have relevance to algorithm development and evaluation in general 
this paper address the problem of computing three dimensionalstructure and motion from an unknown rigid conguration ofpoints and line viewed by an ane projection model an algebraic structure analogous to the trilinear tensor for three perspective camera isdened for congurations of three centered ane camera this centeredane trifocal tensor contains non zero coecients and involves linearrelations between point correspondence and trilinear relation betweenline 
video mosaicing is commonly used to increase the visual field of view by pasting together many video frame existing mosaicing method are effective only in very limited case where the image motion is almost a uniform translation or the camera performs a pure pan forward camera motion or camera zoom are very problematic for traditional mosaicing a mosaicing methodology to allow image mosaicing in the most general case is presented where frame in the video sequence are transformed such that the optical flow becomes parallel this transformation is an oblique projection of the image into a viewing pipe whose central axis is the trajectory of the camera the pipe projection enables to define high quality mosaicing even for the most challenging case of forward motion and of zoom in addition view interpolation generating dense intermediate view is used to overcome parallax effect 
we propose a new feature distance which is derived from an optimal relational graph matchingcriterion instead of defining an arbitrary similarity measure for grouping we will use the criterionof reducing instability in the relational graph to induce a similarity measure this similarity measurenot only improves the stability of the matching but more importantly also capture the relativeimportance of relational similarity in the feature space for the purpose of grouping we will call 
we describe a novel computer vision application vision based human sensing for a smart kiosk interface a smart kiosk is a free standing information dispensing computer appliance capable of engaging in public interaction with multiple people vision sensing is a critical component of the kiosk interface where it is used to determine the context for the interaction we present a taxonomy of vision problem for a kiosk interface and describe a prototype kiosk which us color stereo tracking and graphical output to interact with several user 
two approach for d curved object reconstruction using active sensor and illumination control are proposed and compared to each other in both case the highlight information is fully utilized rather than discarded and knowledge of the object surface is not required the first approach requires camera control only and recovers shape depth from highlight and occluding contour the second approach requires both camera and illumination control and recovers d depth from highlight only 
we propose a model for view based adaptive affine tracking of moving object we avoid the need for feature based matching in establishing correspondence through learning landmark we use an effective bootstrapping process based on colour segmentation and selective attention we recover affine parameter with dynamic update to the eigenspace using most recent history and perform prediction in parameter space experimental result are given to illustrate our approach 
many application require detecting structural change in a scene over a period of time comparing intensity value of successive image is not effective a such change don t necessarily reflect actual change at a site but might be caused by change in the view point illumination and season we take the approach of comparing a d model of the site prepared from previous image with new image to infer significant change this task is difficult a the image and the model have very different level of abstract representation our approach consists of several step registering a site model to a new image model validation to confirm the presence of model object in the image structural change detection seek to resolve matching problem and indicate possibly changed structure and finally updating model to reflect the change our system is able to detect missing or mi modeled building change in model dimension and new building under some condition 
a common factor in all illusory contour figure is the perception of a surface occluding part of a background in our previous work we have shown that by detecting junction and assigning a proper set of hypothesis at each junction we could diffuse this information and obtain surface reconstruction where the surface boundary represented illusory contour amodal completion emerge at the overlapping surface we here address the problem of selecting the best image organization set of hypothesis we propose two optimization criterion one based on a coherence measure between pair of junction correlation between the diffusion of each pair and another one based on an entropy measure sharpness of the reconstruction we show their similarity and a statistical physic approach to select the best organization the experiment suggest that despite the large number of possible organization our approach may take a few step to select the best organization starting from random organization 
we investigate the relationship between the kinematics infinitesimal motion model of a calibrated stereo rig and point and line image feature measurement seen at two time instance of the rig s motion four image in all in particular we are interested in the byproduct of this analysis providing a direct connection between the spatio temporal derivative of the image at two time instance and kinematics of the d motion of the rig we establish a fundamental result showing that quadruple of point line line line match i e point in the reference image and line coincident with the corresponding point in the remaining three image are sufficient for a unique linear solution for the kinematics of the rig in other word the projected instantaneous motion of one and a half d line is sufficient for recovering the kinematics of the moving rig in particular spatio temporal derivative across point are sufficient for a direct estimation of the rig s motion consequently we describe a new direct estimation method for motion estimation and d reconstruction from stereo image sequence obtained by a stereo rig moving through a rigid world correspondence optic flow are not required a spatio temporal derivative are used instead one can then use the image from both pair combined to compute a dense depth map finally since the basic equation are linear we combine the contribution coming from all pixel in the image using a least square approach 
the demo present a virtual mirror interface which reacts to the viewer using robust real time face tracking the display directly combine a user s face with various graphical distortion performed only on the face region in the image the face detection and tracking is done in real time so the graphical effect stay with the user and continues to adapt al they move within the viewing space increasing in intensity a the user approach the display the tracking system performs well in crowded environment with open and moving background this robust performance is achieved using multi modal integration combining stereo color and grey scale pattern matching module into single realtime system stereo processing is used to isolate the figure of a user from other object and people in the background skinhue classification identifies and track likely body part within the foreground region face pattern detection discriminates and localizes the face within the tracked body part a second set of display located to the side of the main viewing area show intermediate result of each processing module of the system 
in this paper it is shown how to use the generalisedepipolar constraint on apparent contour or silhouette one such constraint is obtained for each frontier pointin each image pair in a sequence of image to estimatethe camera motion introduction n got h r in it wa shown how the viewer motion can becalculated from the contraints on the camera motionand the frontier point however only a pair of imageswas considered at the same time in this situationthe problem is 
this paper present a technique for visual recognition inwhich physical object are represented by family of surface in a localappearance space an orthogonal family of local appearance descriptorsis obtained by applying principal component analysis to image neighborhood the principal component with the largest variance are usedto define a space for describing local appearance the projection of theset of all neighborhood from an image give a discrete sampling of asurface in 
the paper describes visual routine based on model of color and shape a well a crucial issue involving the sche duling of such routine the visual routine are developed in a unique platform the view from a car driving in a simulated world is fed into a datacube pipeline video processor the use of this simulation provides a flexible environment from which to set crucial image processing parameter of the individual routine in addition to the simulation are also tested in similar image generated by driving in the real world to assure the generalizability of the simulation 
a common factor in all illusory contour figure is the perception of a surface occluding part of a background these surface are not constrained to be at constant depth and they can cross other surface we address the problem of how the image organization that yield illusory contour arise our approach is to iteratively find the most salient surface by i detecting occlusion ii assigning salient surface state a set of hypothesis of the local salient surface configuration iii applying a bayesian model to diffuse these salient surface state and iv efficiently selecting the best image organization set of hypothesis based on the resulting diffused surface 
traditional light source modelling is concerned with specific type of light source the two most common of which are point source and daylight little attempt ha been made however to relate different type of source to each other for example how may the lighting from an overcast sky be compared to that from a lamp having a theoretical framework to compare different type of light source is important for computer vision in particular for understanding shading and shadow cue a vision system need to take account of the light source in order to interpret these cue in this paper we present a framework for comparing type of light source which is based on a dimensional analysis of the set of light ray in a free space specifically we introduce a d light source hypercube in which the different type of source may be embedded and compared we also present a novel definition for light source which generalizes the standard definition of a source a an emitter 
several color object recognition method that are based on image retrieval algorithm attempt to discount change of illumination in order to increase performance when test image illumination condition differ from those that obtained when the image database wa created here we extend the seminal method of swain and ballard to discount changing illumination the new method is based on the first stage of the simplest color indexing method which us angular invariant between color image and edge image channel that method first normalizes image channel and then effectively discard much of the remaining information here we adopt the color normalization stage a an adequate color constancy step further we replace d color histogram by d chromaticity histogram treating these a image we implement the method in a compressed histogram image domain using a combination of wavelet compression and discrete cosine transform dct to fully exploit the technique of low pas filtering for efficiency result are very encouraging with substantially better performance than other method tested the method is also fast in that the indexing process is entirely carried out in the compressed domain and us a feature vector of only or value 
one of the key problem in appearance based vision is understanding how to use a set of labeled image to classify new image classification system that can model human performance or that use robust image matching method often make use of similarity judgment that are non metric but when the triangle inequality is not obeyed most existing pattern recognition technique are not applicable we note that exemplar based or nearest neighbor method can be applied naturally when using a wide class of non metric similarity function the key issue however is to find method for choosing good representative of a class that accurately characterize it we show that existing condensing technique for finding class representative are ill suited to deal with non metric dataspaces we then focus on developing technique for solving this problem emphasizing two point first we show that the distance between two image is not a good measure of how well one image can represent another in non metric space instead we use the vector correlation between the distance from each image to other previously seen image second we show that in non metric space boundary point are le significant for capturing the structure of a class than they are in euclidean space we suggest that atypical point may be more important in describing class we demonstrate the importance of these idea to learning thatgeneralizes from experience by improving performance using both synthetic and real image 
a unique imaging modality based on equal thickness contour etc ha introduced a new opportunity for d shape reconstruction from multiple view we present a computational framework for representing each view of an object in term of it object thickness and then integrating these representation into a d surface by algebraic reconstruction the object thickness is inferred by grouping curve segment that correspond to point of second derivative maximum at each step of the process we use some form of regularization to ensure closeness to the original feature a well a neighborhood continuity we apply our approach to image of a sub micron crystal structure obtained through a holographic process 
in this paper we describe a real time computer visionand machine learning system for modeling andrecognizing human behavior in a visual surveillancetask the system is particularly concerned with detectingwhen interaction between people occur andclassifying the type of interaction example of interestinginteraction behavior include following anotherperson altering one s path to meet another and soforth our system combine top down with bottom up informationin a closed feedback 
we describe a method for determining affine and metric calibrationof a camera with unchanging internal parameter undergoingplanar motion it is shown that affine calibration is recovered uniquely and metric calibration up to a two fold ambiguity the novel aspect of this work are first relating the distinguished objectsof d euclidean geometry to fixed entity in the image second showingthat these fixed entity can be computed uniquely via the trifocal tensorbetween image 
all illusory surface figure yield a perception of a surface occluding another one or the background occluded surface yield completion a phenomenon known a amodal completion it is intriguing that for some image illusory surface are perceived but not for other image see figure also illusory surface may have portion occluded we aim to understand these phenomenon our approach detects intensity edge and junction from the junction we seek to find an optimal image organization i e multiple ordered surface with the ordering accounting for salience the most salient being the figure while the other surface are classified a background a decision of which surface is the top one is made locally at each pixel allowing the salient surface figure to have portion occluded i e with amodal completion we account for a variety of imagery not explained before 
many presume that parsing the shadow out of an image is a high level task because of the global nature of the shadow formation process but shape from shading algorithm are low level in the sense that they seek solution surface normal or depth value directly from image intensity a dilemma arises since shape from shading involves an illumination term shadow must first be identified we show that a structure intermediate between intensity and surface the shading flow field provides a solution to this dilemma our analysis is based on the observation that the geometric information that can be derived from image support different inference than the photometric information and our specific goal will be to articulate this geometric structure and to show how shading flow field can be reliably computed 
the problem addressed in this paper is related to displayinga real d scene from any viewpoint to display a scene a relativelysparse set of d reference view is stored the image that are inbetweenthe reference view are obtained by interpolation of coordinatesand brightness colour this approach is able to generate the scene representationand render image automatically and efficiently even for complexscenes of d object this is possible since the processing time doesnot 
we describe a new multi phase color based image retrieval system focus fast object color based query system with an online user interface which is capable of identifying multi colored query object in an image in the presence of significant interfering background the query object may occur in arbitrary size orientation and location in the database image the color feature used to describe an image have been developed based on the need for speed in matching and ease of computation on complex image while maintaining the scale and rotation invariance property the first phase match the color content of an image computed a the peak in the color histogram of the image with the query object color using an efficient indexing mechanism the second phase match the spatial relationship between color region in the image with the query using a spatial proximity graph spg structure designed for the purpose the method is fast and ha low storage overhead test result with multi colored query object from artificial and natural domain show that focus is quite effective in handling interfering background and large variation in scale the experimental result on a database of diverse image highlight the capability of the system 
a method is presented for efficient and reliable object recognition within noisy cluttered and occluded range image the method is based on a strategy which hypothesizes the intersection of the object with some selected image point and search for additional surface data at location relative to that point at each increment the image is queried for the existence of surface data at a specific spatial location and the set of possible object pose is further restricted eventually either the object is identified and localized or the initial hypothesis is refuted the strategy is implemented in the discrete domain a a binary decision tree classifier the tree leaf node represent individual voxel template of the model the internal tree node represent the union of the template of their descendant leaf node the union of all leaf node template is the complete template set of the model over it discrete pose space each internal node also reference a single voxel which is the most common element of it child node template traversing the tree is equivalent to efficiently matching the large set of template at a selected image seed location the process is approximately order of magnitude more efficient than brute force template matching experimental result are presented in which object are reliably recognized and localized in dimension in le than second within noisy and significantly occluded range image 
in this paper we propose a new solution to the stereo correspondence problem by including feature an intensity based matching the feature we use are intensity gradient in both the x and y direction of the left and the deformed right image although a uniform smoothness constraint is still used it is nevertheless applied only to non feature region to avoid local minimum in function minimization we propose to parameterize the disparity function by hierarchical gaussians a simple stochastic gradient method is used to estimate the gaussian weight experiment with various real stereo image show robust performance 
this paper describes an efficient approach to pose invariant object recognition employing pictorial recognition of image patch a complete affine invariance is achieved by a representation which is based on a new sampling configuration in the frequency domain employing singular value decomposition svd the affine transform is decomposed into slant tilt swing scale and d translation from this decomposition we derive an affine invariant representation that allows to recognize image patch that correspond to object surface which are roughly planar invariant to their pose in space the representation is in the form of spectral signature that are derived from a set of cartesian logarithmic logarithmic log log sampling configuration in the frequency domain unlike previous log polar representation which are not invariant to slant i e foreshortening only in one direction our new configuration yield complete affine invariance the proposed log log configuration can be employed both globally or locally by a gabor or fourier transforms local representation enables to recognize separately several object in the same image the actual signature recognition is performed by multi dimensional indexing in a pictorial dataset represented in the frequency domain the recognition also provides d pose information 
the process of grouping and subsequently recognising object in cluttered image is one laden with difficulty however result can be greatly enhanced if the inherent uncertainty of image feature is taken into account this paper show that starting with the individual edgel s uncertainty it is possible to calculate covariance information for all derived quantity this information can be used to choose between competing algorithm selecting the one that produce the more reliable result but also a an aid during the recognition process the consequent application of error propagation lead to a new formulation for the calculation of the cross ratio which is both robust and efficient in dealing with measured line and doe notrequire knowledge about the vanishing point extensive monte carlo simulation a well a the application to image of cluttered street scene demonstrate the robustness and suitability of the approach 
the study of visual navigation problem requires the integration of visual process with motor control most essential in approaching this integration is the study of appropriate spatio temporal representation which the system computes from the imagery and which serve a interface to all motor activity since representation resulting from exact quantitative reconstruction have turned out to be very hard to obtain we argue here for the necessity of representation which can be computed easily reliably and in real time and which recover only the information about the d world which is really needed in order to solve the navigational problem at hand in this paper we introduce a number of such representation capturing aspect of d motion and scene structure which are used for the solution of navigational problem implemented in visual servo system in particular the following three problem are addressed a to change the robot s direction of motion towards a fixed direction b to pursue a moving target while keeping a certain distance from the target and c to follow a wall like perimeter the importance of the introduced representation lie in the following they can be extracted using minimal visual information in particular the sign of flow measurement or the the first order spatiotemporal derivative of the image intensity function in that sense they are direct representation needing no intermediate level of computation such a correspondence they are global in the sense that they represent how three dimensional information is globally encoded in them thus they are robust representation since local error do not affect them usually from sequence of image three dimensional quantity such a motion and shape are computed and used a input to control process the representation discussed here are given directly a input to the control procedure thus resulting in a real time solution 
the dimensionality of visual motion analysis can be reduced by analyzing projection offlow vector field in contrast to motion vector field these projection exhibit simplegeometric property which are invariant to the scene structure and depend only on thecamera motion using these property structure and motion can be either completely orpartially decoupled we estimate motion parameter from projection of flow field by usingrobust technique implemented in a recursive observer 
this paper present a self calibration and pose estimation method that us two camera which only differ by focal length the estimation of the rotation and focal length is independent of the translation recovery unlike most method we do not initialize our recovery with the projective camera instead we estimate the ego motion and calibration from homographies these homographies can be easily obtained from a fundamental matrix or a trifocal tensor 
query by content image database will be based on similarity rather than on matching where similarity is a measure that is defined and meaningful for every pair of image in the image space since it is the human user that in the end ha to be satisfied with the result of the query it is natural to base the similarity measure that we will use on the characteristic of human similarity assessment in the first part of this paper we review some of these characteristic and define a similarity measure based on them another problem that similarity based database will have to face is how to combine different query into a single complex query we present a solution based on three operator that are the analogous of the and or and not operator one us in traditional database these operator are powerful enough to express query of unlimited complexity yet have a very intuitive behavior making easy for the user to specify a query tailored to a particular need 
we propose a new method for view synthesis from real image using stereo vision the method doe not explicitly model scene geometry and enables fast and exact generation of synthetic view we also re evaluate the requirement on stereo algorithm for the application of view synthesis and discus way of dealing with partially occluded region of unknown depth and with completely occluded region of unknown texture our experiment demonstrate that it is possible to efficiently synthesize realistic new view even from inaccurate and incomplete depth information 
we propose an em approach combined with the modified separation matrix scheme to perform d motion segmentation of the image sequence which contains multiple moving object we observe that given the detected feature and their d optical flow in most case the object or their flow are separated very well from each other in space the separation matrix method modified by using normalized cut achieves expected grouping result for these case however when the object are overlapped spatially but undergoing independent motion such a ullman s co axial transparent cylinder demonstration there will be no proper affinity to perform segmentation by that way pure underlying d motion becomes the only cite to segment the scene we exploit the em algorithm to deal with such difficult case the scheme is tested on vast number of synthetic image sequence result with real image sequence are also given 
because of the difficulty of obtaining ground truth for real image the traditional technique forcomparing low level vision algorithm is to present image result side by side and to let thereader subjectively judge the quality this is not a scientifically satisfactory strategy however human rating experiment can be done in a more rigorous manner to provide useful quantitativeconclusions we present a paradigm based on experimental psychology and statistic inwhich human rate 
the exact positioning of patient during radiotherapy is essentialfor high precision treatment the registration of portal image sequence can help to control the patient position the particular problem of such megavoltage x ray imagery is it extremely low contrast rendering accurate feature extraction a difficult task to circumvent the step offeature extraction the algorithm presented in this paper relies on anarea bused matching of the image signal using deformable template this strategy contrast with most state of the art registration algorithm for portal imagery the paper includes the mathematical formalism of the least square template matching method a well a the framework for automated quality control together yielding a fast robust and very accurate image matching procedure test on i portal image series with more than image in total have shown very satisfying result artificially rotated and shifted image demonstrate the performance of the method with respect to a ground truth 
we develop a theory for the temporal integration of visual motion motivated by psychophysical experiment the theory proposes that input data are temporally grouped and used to predict and estimate motion flow in the image sequence our theory is expressed in term of the bayesian generalization of standard kalman filtering which allows u to solve temporal grouping in conjunction with prediction and estimation a demonstrated for tracking isolated contour the bayesian formulation is superior to approach which use data association a a first stage followed by conventional kalman filtering our computer simulation demonstrate that our theory qualitatively account for several psychophysical experiment on motion occlusion and motion outlier 
in mr brain image segmentation using intensity value is severely limited owing to field inhomogeneity susceptibility artifact and partial volume effect edge based segmentation method suffer from spurious edge and gap in boundary a method is presented which combine the advantage of edge based and region based segmentation first a multiscale image representation is constructed which favor intra tissue diffusion over inter tissue diffusion by exploiting local contrast subsequently a multiscale linking model the hyperstack is used to group voxels into a number of segment this facilitates segmentation of grey matter white matter and cerebrospinal fluid with minimal user interaction using a supervised segmentation technique and mr simulation of a brain phantom a validation it is shown that the error are in the order of or smaller than reported in literature 
this paper address two important issue related to texture pattern retrieval feature extraction and similarity search a gabor feature representation for textured image is proposed and it performance in pattern retrieval is evaluated on a large texture image database these feature compare favorably with other existing texture representation a simple hybrid neural network algorithm is used to learn the similarity by simple clustering in the texture feature space with learning similarity the performance of similar pattern retrieval improves significantly an important aspect of this work is it application to real image data texture feature extraction with similarity learning is used to search through large aerial photograph feature clustering enables efficient search of the database a our experimental result indicate 
this article develops an analogy between object recognition and the transmission of information through a channel based on the statistical representation of the appearance of d object this analogy provides a mean to quantitatively evaluate the contribution of individual receptive field vector and to predict the performance of the object recognition process transinformation also provides a quantitative measure of the discrimination provided by each viewpoint thus permitting the determination of the most discriminant viewpoint a an application the article develops an active object recognition algorithm which is able to resolve ambiguity inherent in a single view recognition algorithm 
we describe a linear algorithm to recover d affine shape motion from line correspondence over three view with uncalibrated affine camera the key idea is the introduction of a one dimensional projective camera this convert the d affine reconstruction of line into d projective reconstruction of point using the full tensorial representation of three uncalibrated d view we prove that the d affine reconstruction of line from minimal data is unique up to a re ordering of the view d affine line reconstruction can be performed by properly rescaling image coordinate instead of using projection matrix the algorithm is validated on both simulated and real image sequence 
this paper proposes a novel approach to extract meaningful content information from video by collaborative integration of image understanding and natural language processing a an actual example we developed a system that associate face and name in video called name it which is given news video a a knowledge source then automatically extract face and name association a content information the system can infer the name of a given unknown face image or guess face which are likely to have the name given to the system this paper explains the method with several successful matching result which reveal effectiveness in integrating heterogeneous technique a well a the importance of real content information extraction from video especially face name association 
a method is described for the determination of the viewing parameter of randomly acquired projection of asymmetric object it extends upon the common line algorithm by determining the relative orientation of projection from the location of line of intersection among the fourier transforms of the projection in three dimensional fourier space a new technique for finding the line of intersection in the presence of translational displacement and for subsequently finding the translational displacement is presented a new technique for dealing with noise is also presented the complete algorithm is described and it efficacy is demonstrated using real data this technique may be applied to the three dimensional reconstruction of virus molecule and cell from in vivo image it also ha many other application including the reconstruction of underwater scene radioastronomy geoseismic analysis and portable radiography for medical diagnosis and industrial inspection 
a complete and practical system for object recognition with occlusion ha been developed which is very robust with respect to noise and local deformation of shape a well a scale change and rigid motion of the object the system ha been tested on a wide variety of d object with different shape and surface property no restrictive assumption have been made about the shape of admissible object an industrial application with a controlled environment is envisaged the curvature scale space technique is used to obtain a novel multi scale segmentation of the image contour and the model contour using curvature zero crossing point multi scale segmentation render the system substantially more robust with respect to noise and local shape difference object indexing is used to narrow down the search space and avoid an exhaustive investigation of all model segment a local matching algorithm applies candidate generation selection merging extension and grouping to select the best matching model 
we introduce the problem of view interpolation fordynamic scene our solution to this problem extendsthe concept of view morphing and retains thepractical advantage of that method we are specificallyconcerned with interpolating between two referenceviews captured at different time so that there isa missing interval of time between when the view weretaken the synthetic interpolation produced by our algorithmportray one possible physically valid versionof what transpired in 
we consider the problem of reconstructing thelocation of a moving d point seen from amonocular moving camera since the point ismoving while the camera is moving then even ifthe camera motion is known it is impossible toreconstruct the d location of the point undergeneral circumstance however we show thatif the point is moving along a straight line thenthe parameter of the line and hence the dposition of the point at each time instance canbe uniquely recovered and by 
in this paper we present a neural network based face detection system unlike similar system which are limited to detecting upright frontal face this system detects face at any degree of rotation in the image plane the system employ multiple network a router network first process each input window to determine it orientation and then us this information to prepare the window for one or more detector network we present the training method for both type of network we also perform sensitivity analysis on the network and present empirical result on a large test set finally we present preliminary result for detecting face rotated out of the image plane such a profile and semi profile 
in this paper a correlational approach for distinguishing occluding contour from object marking for d object modeling is presented the proposed method is valid under weak perspective projection doe not require to search for correspondence between frame can handle scaling between consecutive image thus can estimate the full euclidean surface structure and doe not require camera calibration or camera motion measurement extensive experimental result show that the method is robust to the occlusion of feature point and image noise unlike previous affine based approach qualitative and quantitative result for the relation between the required minimum viewing angle change for the detection and the surface curvature are also presented 
in this paper two new feature tracking algorithm are proposed in the first algorithm a perspective camera model is used making use of the projective invariant of barrett and assuming the image feature point corresponding to general point in space are tracked by a conventional method in the image sequence the other feature point in the sequence can be tracked using a hough technique correspondence between two reference image a required by the original barrett s invariant is not necessary in the second algorithm an affine camera model is assumed and the image feature point corresponding to non coplanar point in space are assumed tracked in the image sequence using a conventional method these image point form the basis of affine coordinate in each image after the correspondence of a fifth point is established between the first two image the affine coordinate of all image point in the first image can be computed a far a we know this is the only algorithm which can transfer a point knowing only a single image experiment showed that both algorithm gave highly accurate tracking result 
this paper describes the derivation of probability of correctness from score assigned by most recognizers motivation for this research is three fold i probability value can be used to rerank the output of any recognizer by using a new set of training data if the training data is sufficiently large and representative of the test data the recognition rate are seen to improve significantly ii derivation of probability value put the output of different recognizers on the same scale this make comparison across recognizers trivial and iii word recognition can be readily extended to phrase and sentence recognition because the integration of language model becomes straightforward we have conducted an extensive set of experiment the result show a reranking of recognition choice based on the derived probability value leading to an enhancement in performance 
this paper discus the problem of selecting appropriate scale for region detection prior to feature localization we argue that an approach in morphological opening closing scale space is better than one in gaussian scale space the proposed operator is based on a new shape decomposition method called morphological band pas filter that decomposes an image into structure of different size and different curvature polarity local appropriate scale is then defined a the scale that maximizes the response of the band pas filter at each point this operator give constant scale value in a region of constant width and it zero crossing coincide with local maximum of the gradient magnitude it usefulness is demonstrated by some example 
this paper present a new scale position and orientation invariant approach to object detection the proposed method first chooses attention region in an image based on the region detection result on the image within the attention region the method then detects target using a novel object detection algorithm that combine template matching method with feature based method via hierarchical mrf and map estimation hierarchical mrf and map estimation provide a flexible framework to incorporate various visual clue the combination of template matching and feature detection help to achieve robustness against complex background and partial occlusion in object detection experimental result are given in the paper 
we introduce a new solid shape model formulation that includes built in offset from a base global component e g an ellipsoid which are function of the global component s parameter the offset provide two feature first they help to form an expected model shape which facilitates appropriate model data correspondence second they scale with the base global model to maintain the expected shape even in the presence of large global deformation we apply this model formulation to the recovery of d cardiac motion from a volunteer dataset of tagged mr image the model instance is a variation of the hybrid volumetric ventriculoid hvv a deformable thick walled ellipsoid model resembling the left ventricle lv of the heart a unique aspect of our implementation is the employment of constant volume constraint when recovering the cardiac motion in addition we present a novel geodesic like prismoidal tessellation of the model which provides for more stable fit 
in this contribution we present an algorithm for tracking non rigid moving object in a sequence of colored image which were recorded by a non stationary camera the application background is vision based driving assistance in the inner city in an initial step object part are determined by a divisive clustering algorithm which is applied to all pixel in the first image of the sequence the feature space is defined by the color and position of a pixel for each new image the cluster of the previous image are adapted iteratively by a parallel k mean clustering algorithm instead of tracking single point edge or area over a sequence of image only the centroid of the cluster are tracked the proposed method remarkably simplifies the correspondence problem and also ensures a robust tracking behaviour 
the appearance of a particular object depends on both the viewpoint from which it is observed and the light source by which it is illuminated if the appearance of two object is never identical for any pose or lighting condition then in theory the object can always be distinguished or recognized the question arises what is the set of image of an object under all lighting condition and pose in this paper we consider only the set of image of an object under variable illumination including multiple extended light source and attached shadow we prove that the set of n pixel image of a convex object with a lambertian reflectance function illuminated by an arbitrary number of point light source at infinity form a convex polyhedral cone in ir sup n and that the dimension of this illumination cone equal the number of distinct surface normal furthermore we show that the cone for a particular object can be constructed from three properly chosen image finally we prove that the set of n pixel image of an object of any shape and with an arbitrary reflectance function seen under all possible illumination condition still form a convex cone in ir sup n these result immediately suggest certain approach to object recognition throughout this paper we offer result demonstrating the empirical validity of the illumination cone representation 
image motion induced by camera or object motion can be approximated locally by an affine coordinate transformation we extract d information directly from the affine parameter without camera calibration the derivation relies on the following assumption the object is rigid locally planar and it local d motion is translation these assumption enable complete recovery of d structure whereas it is impossible to compute the direction and magnitude of the motion still it is possible to distinguish between object moving differently explicit expression for the structure and the motion indicator are given in term of the affine parameter computed for each image patch result of experiment on data with known ground truth are described 
undeformed superquadrics are volumetric modeling primitive with an extensive shape vocabulary that are described by only parameter fitting these model viewpoint invariantly to range data enables classification based on the superquadric parameter however current recovery routine show several limitation especially when the algorithm are applied to range image instead of true d image in this paper problem with the common superquadric recovery procedure are identified and solution are presented 
in this paper we consider one aspect of the problem of automatically constructing geometric model of articulated object from multiple range image automatic model construction ha been investigated for rigid object but the technique used do not extend easily to the articulated case the problem arises because of the need to register surface measurement taken from different viewpoint into a common reference frame registration algorithm generally assume that an object doe not change shape from one viewto the next but when automatically building a model of an articulated object it is necessary for the mode of articulation to be present in the example data to avoid this problem we propose that raw surface data of articulated object is first segmented into rigid subset corresponding to rigid subcomponents of the object this allows a model of each subcomponent to be constructed using the conventional approach and a final articulated model to be constructed by assembling each of the subcomponent model we describe an algorithm developed to segment range data into rigid subset based on surface patch correspondence and present some result for the planar patch case 
in the depth from defocus dfd method two defocused image of a scene are obtained by capturing the scene with different set of camera parameter an arbitrary selection of the camera setting can result in observed image whose relative blurring is insufficient to yield a good estimate of the depth in this paper we study the effect of the degree of relative blurring on the accuracy of the estimate of the depth by addressing the dfd problem in a maximum likelihood based framework we propose a criterion for optimal selection of camera parameter to obtain an improved estimate of the depth the optimality criterion is based on the cramer rao bound of the variance of the error in the estimate of blur simulation a well a experimental result on real image are presented for validation 
in this paper we will introduce a common framework for the definition and operation on the different multiple view tensor the novelty of the proposed formulation is to not fix any parameter of the camera matrix but instead letting a group act on them and look at the different orbit in this setting the multiple view geometry can be viewed a a four dimensional linear manifold in ir m where m denotes the number of image the grassman coordinate of this manifold are the epipoles the component of the fundamental matrix the component of the trifocal tensor and the component of the quadfocal tensor all relation between these grassman coordinate can be expressed using the so called quadratic p relation which are quadratic polynomial in the grassman coordinate using this formulation it is evident that the multiple view geometry is described by four different kind of projective invariant the epipoles the fundamental matrix the trifocal tensor and the quadfocal tensor a an application of this formalism it will be shown how the multiple view geometry can be calculated from the fundamental matrix for two view from the trifocal tensor for three view and from the quadfocal tensor for four view a a byproduct we show how to calculate the fundamental matrix from a trifocal tensor a well a how to calculate the trifocal tensor from a quadfocal tensor it is furthermore shown that in general n n n n linearly independent constraint on the quadfocal tensor and that corresponding point can be used to estimate the tensor component linearly finally it is shown that the rank of the trifocal tensor is and that the rank of the quadfocal tensor is 
this paper describes a family of factorization based algorithm that recover d projective structure and motion from multiple uncalibrated perspective image of d point and line they can be viewed a generalization of the tomasi kanade algorithm from affine to fully perspective camera and from point to line they make no restrictive assumption about scene or camera geometry and unlike most existing reconstruction method they do not rely on privileged point or image all of the available image data is used and each feature in each image is treated uniformly the key to projective factorization is the recovery of a consistent set of projective depth scale factor for the image point this is done using fundamental matrix and epipoles estimated from the image data we compare the performance of the new technique with several existing one and also describe an approximate factorization method that give similar result to svd based factorization but run much more quickly for large problem 
we address the detection and tracking of moving object in a video stream obtained from a moving airborne platform the approach is based on the compensation of the image flow induced by the motion of observation platform and the detection and tracking of moving region the use of such an approach lead u to deal with stabilization inaccuracy false alarm and non detection of moving object and tracking difficulty due to partial occlusion or stop and go motion our approach use a hierarchical feature based stabilization scheme and normal component of the residual flow for detecting moving object these object are tracked using a dynamic template for each object and extract trajectory a the result of a graph searching algorithm the proposed framework show that an integration of well known tool and an efficient description of the moving object can give very accurate detection and tracking of moving object 
in previous work we modify the hidden markov model hmm framework to incorporate a global parametric variation in the output probability of the state of the hmm development of the parametric hidden markov model phmm wa motivated by the task of simultaneously recognizing and interpreting gesture that exhibit meaningful variation with standard hmms such global variation confounds the recognition process the original phmm approach assumes a linear dependence of output density mean on the global parameter in this paper we extend the phmm to handle arbitrary smooth nonlinear dependency we show a generalized expectation maximization gem algorithm for training the phmm and a gem algorithm to simultaneously recognize the gesture and estimate the value of the parameter we present result on a pointing gesture where the nonlinear approach permit the natural azimuth elevation parameterization of pointing direction 
different application in the field of vision based navigation of autonomous mobile robot depend on the degree of knowledge of the environment indoor environment application often use landmark or map for navigation others have only knowledge of known and expected object in such application part of the scene are classified in these object e g road junction door wall furniture and a possible path will be estimated in case of a lack of a priori knowledge of the environment we propose an approach for vision based navigation considering any reconstructed d point of the scene a line segment stereo algorithm and a reconstruction procedure lead to uncertain d point of the scene in front of the mobile system all these d point are regarded a obstacle and a following trace estimation will be applied on this d data in order to increase the reliability of reconstructed d point a validation step excludes impossible d point exploiting the stereo geometry of the vision system after validation a two step analysis is applied which contains the minimum distance method and point distribution analysis method this analysis lead to a possible trace for the mobile robot resulting in value for steering angle and velocity given to the mobile system the method ha been implemented on the experimental system movilar mobile vision and laser based robot which is based on a multi processor network it achieves actually process cycle of approximately s and a velocity of about cm s i e a slow walking speed experimental result of the above mentioned method are presented 
in this paper we present a robust method for creating a triangulated surface mesh from multiple range image our method merges a set of range image into a volumeteric implicit surface representation which is converted to a surface mesh using a variant of the marching cube algorithm unlike previous technique based on implicit surface representation our method estimate the signed distance to the object surface by finding a consensus of locally coherent observation of the surface we call this method the consensus surface algorithm this algorithm effectively eliminates many of the troublesome effect of noise and extraneous surface observation without sacrificing the accuracy of the resulting surface we utilize octrees to represent volumetric implicit surface effectively reducing the computation and memory requirement of the volumetric representation without sacrificing accuracy of the resulting surface we present result which demonstrate that our consensus surface algorithm can construct accurate geometric model from rather noisy input range date 
we introduce the concept of self calibration of a d projectivecamera from point correspondence and describe a method foruniquely determining the two internal parameter of a d camera basedon the trifocal tensor of three d image the method requires the estimationof the trifocal tensor which can be achieved linearly with noapproximation unlike the trifocal tensor of d image and solving forthe root of a cubic polynomial in one variable interestingly enough weprove that a d 
we offer a novel strategy to adapt the perceptual organization process to an object and it context in a scene given a set of training image of an object in context a learning process decides on the relative importance of the basic gestalt relationship such a proximity parallelness similarity symmetry closure and common region towards segregating the object from the background this learning is accomplished using a team of stochastic automaton in a n player cooperative game framework the grouping process which is based on graph partitioning is able to form large group from relationship defined over a small set of primitive and is fast we demonstrate the robust performance of the grouping system on a variety of real image among the interesting conclusion is the significant role of photometric attribute in grouping and the ability to perform figure ground segmentation from a set of local relation each defined over a small number of primitive 
this paper present a novel method for determining the location of the instantaneous epipole in a sequence of image acquired by an uncalibrated camera and containing a single rigid motion e g the camera move in a static environment the method us the full perspective camera model and requires the estimation of the optical flow at a minimum of six image location the key observation is that the optical flow equation can be written in term of the epipole in a strikingly simple form if the translation and rotational flow component are not separated a done usually the epipole location can then be obtained a the minimum of a least square residual function asdsociated to the computed optical flow we report and discus initial experiment on both synthetic and real data and illustrate possible development of this method towards the use of uncalibrated optical flow for d motion and structure reconstruction 
ray based representation of shape have received little attention in computer vision in this paper we show that the problem of recovering shape from silhouette becomes considerably simplified if it is formulated a a reconstruction problem in the space of oriented ray that intersect the object the method can be used with both calibrated and uncalibrated camera doe not rely on point correspondence to compute shape and doe not impose restriction on object topology or smoothness 
existing polarization based image understanding technique use information only from reflected light apart from incandescent body thermally emitted light radiation from element of a scene in the visible spectrum is insignificant however at longer wavelength such a in the infrared thermal emission is typically quite prevalent from a number of scene element of interest flir imagery of both indoor and outdoor scene reveals that many object thermally emit a significant amount of radiation polarization from thermally emitting object ha been observed a long a year ago from incandescent object but since then there have only been a limited number of empirical investigation into this phenomenon this paper present a comprehensive model for explaining polarization of thermal emission from both rough and smooth surface in agreement with empirical data that can significantly enhance the image understanding of flir imagery in particular it is possible to discern metal from dielectric material under certain condition and from an accurate model for thermally emitted polarization it is possible to predictively model polarization signature from cad model of importance to automatic target recognition 
this paper address the question of how to integrate local and global information the goal being a stable mechanism to partition parametric data into meaningful class without injecting a priori information about the data to do this we introduce a novel framework to represent both local and global information and their interaction where both type of information are represented together in parameter space and together define a self organisation or warping of the data an unsupervised clustering analysis is then performed to extract from the parametric data class that are stable and meaningful a an example of this paradigm we consider the problem of shape decomposition here we describe how image discontinuity i e curve edge or local curvature can be integrated with global parametric model that represent the image the resulting class cluster are then equivalent to the inferred part decomposition an example of how this process can be used is demonstrated by applying it to the specific problem of determining the part of d object result on real laser rangefinder image of complex object are presented 
abstract if instead of the full motion field we consider only the direction of the motion field due toa rigid motion what can we say about the three dimensional motion information containedin it this paper provides a geometric analysis of this question based solely on the constraintthat the depth of the surface in view is positive 
we introduce a unified framework for developing matching constraint of multiple affine view and rederive view affine epipolar geometry and view affine image transfer constraint within this framwork we then describe a new linear method for euclidean motion and structure from calibrated affine image based on insight into the particular structure of these multiple view constraint compared with the existing linear method of huang and lee the new method us different and more appropriate constraint it ha no failure mode of the euclidean factorisation method of tomasi and kanade we demonstrate the method on real image sequence 
correlation based real time stereo system have been proven to be effective in application such a robot navigation elevation map building etc this paper provides an in depth analysis of the major error source for such a real time stereo system in the context of cross country navigation of an autonomous vehicle three major type of error foreshortening error misalignment error and systematic error are identified the combined disparity error can easily exceed three tenth of a pixel which translates to significant range error upon understanding these error source we demonstrate different approach to either correct them or model their magnitude without excessive additional computation by correcting those error we show that the precision of the stereo algorithm can be improved by 
grouping based on common motion or common fate provides a powerful cue for segmenting image sequence recently a number of algorithm have been developed that successfully perform motion segmentation by assuming that the motion of each group can be described by a low dimensional parametric model e g affine typically the assumption is that motion segment correspond to planar patch in d undergoing rigid motion here we develop an alternative approach where the motion of each group is described by a smooth dense flow field and the stability of the estimation is ensured by mean of a prior distribution on the class of flow field we present a variant of the em algorithm that can segment image sequence by fitting multiple smooth flow field to the spatiotemporal data using the method of green s function we show how the estimation of a single smooth flow field can be performed in closed form thus making the multiple model estimation computationally feasible furthermore the number of model is estimated automatically using similar method to those used in the parametric approach we illustrate the algorithm s performance on synthetic and real image sequence 
a simple and inexpenssive approach for extracting the three dimentional shape of object is presented it is based on weak structured lighting it differs from other conventional structured lighting approach in that it requires very little hardware besides the camera a desk lamp a pencil and a checkerboard the camera face the object which is illuminated by the desk lamp the user move a pencil in front of the light source casting a moving shadow on the object the d shape of the object is extracted from the spatial and temporal location of the observed shadow experimental result are presented on three different scene demonstrating that the error in reconstructing the surface is le than 
we recently demonstrated a new approach to multiframe structure from motion from point feature which in the appropriate domain provably reconstructs structure and motion correctly the algorithm work for general motion and large perspective effect in this paper we describe how to adapt our approach to translational motion lying along a line or in a plane with arbitrary rotation an analysis of the ba relief effect for multiple motion sequence is also presented 
binocular stereo is the process of obtaining depth information from a pair of left and right view of a scene we present a new approach to compute the disparity map by solving a global optimization problem that model occlusion discontinuity and epipolar line interaction in the model geometric constraint require every disparity discontinuity along the epipolar line in one eye toalways correspond to an occluded region in the other eye while at the same time encouraging smoothness across epipolar line smoothing coefficient are adjusted according to the edge and junction information for some well defined set of optimization function we can map the optimization problem to a maximum flow problem on a directed graph in a novel way which enables u to obtain a global solution in a polynomial time experiment confirm the validity of this approach 
the structure from motion algorithm from two view fails if the object is a planar surface or the camera motion is a pure rotation this paper present a new scheme for automatically detecting these anomaly without using any knowledge about the noise in the image this judgment doe not involve any empirically adjustable threshold either the basic principle of our scheme is to choose a model that ha higher predicting capability measured by the geometric information criterion geometric aic 
this paper proposes a new method for model based tracking of a human body in d motion from multiple view the tracking is performed by estimating the pose increment of the body part from multiple image sequence after establishing of fitting an articulated model to the human body at the initial frame the pose increment can be obtained from solving a system of linear equation this calculation doe not depend on the number of view point experiment verify that the proposed method can avoid occusion and visual degenerate from a particular view point and track a human body in complicated motion 
two key performance characterization of biometric algorithm face recognition in particular are verification performance and and performance a a function of database size and composition this characterization is required for developing robust face recognition algorithm and for successfully transitioning algorithm from the laboratory to real world in this paper we present a general verification protocol and apply it to the result from the sep feret test and discus and present result on the effect of database size and variability on identification and verification performance 
to attain smooth human interaction we propose a system which simultaneously utilizes the stereo disparity and optical flow information of real time stereo gray multiresolution image to recognize object and gesture for real time calculation of the disparity and optical flow information of a stereo image the system first creates pyramid image by utilizing a gaussian filter the system then determines the disparity and optical flow of a low density image and extract region in front of a certain depth the three foremost region are recognized by higher order local auto correlation feature and a linear discriminant analysis with this process the system recognizes the face and hand sign of user which are displayed foremost and roughly recognizes novements within the region in real time with this framework the system can discriminate the face of a user can monitor the basic movement of the user can smoothly learn a presented object by user and can communicate with user from hand sign learned in advance 
a segmentation and velocity estimation technique is presented which treat each object either moving or stationary a a distinct intensity wave profile the fourier component of wave profile and equally of object which move with constant velocity exhibit a regular frequency dependent phase change using a hough transform which embodies the relationship between velocity and phase change moving object are isolated by identifying the subset of the fourier component of the total image intensity wave profile which exhibit this phase relationship velocity is measured by locating local maximum in the hough space and segmentation is effected by re constituting the moving wave profile the object from the fourier component which satisfy the velocity phase change relationship for the detected velocity 
this paper present a novel theory for learning generic prior model from a set of observed natural image based on a minimax entropy theory that the author studied in texture modeling we start by studying the statistic of natural image including the scale invariant property then generic prior model were learnt to duplicate the observed statistic the learned gibbs distribution confirm and improve the form of existing prior model and more interestingly inverted potential are found to be necessary and such potential produce pattern and enhance preferred image feature the learned model is compared with existing prior model in experiment of image restoration 
we present a set of algorithm and a search strategy for the robust contentbased retrieval of multispectral satellite image since the property of interest in these image is usually the physical characteristic of ground cover we use representation and method that are invariant to illumination and atmospheric condition the representation and algorithm are derived for this application from a physical model for the formation of multispectral satellite image the use of several representation and algorithm is necessary to interpret the diversity of physical and geometric structure in these image algorithm are used that exploit multispectral distribution multispectral spatial structure and labeled class the performance of the system is demonstrated on a large set of multispectral satellite image taken over different area of the united state under different illumination and atmospheric condition 
an algorithm to detect depth discontinuity from a stereo pair ofimages is presented the algorithm match individual pixel incorresponding scanline pair while allowing occluded pixel toremain unmatched then propagates the information betweenscanlines by mean of a fast postprocessor the algorithm handleslarge untextured region us a measure of pixel dissimilaritythat is insensitive to image sampling and prune bad search nodesto increase the speed of dynamic programming the computation isrelatively fast taking about nanosecond per pixel perdisparity on a personal computer approximate disparity map andprecise depth discontinuity along both horizontal and verticalboundaries are shown for several stereo image pair containingtextured untextured fronto parallel and slanted object inindoor and outdoor scene 
a method of registering image at subpixel accuracy ha been proposed which doe not resort to interpolation the method is based on the phase correlation method and is remarkably robust to correlated noise and uniform variation of luminance we have shown that the cross power spectrum of two image containing subpixel shift is a polyphase decomposition of a dirac delta function by estimating the sum of polyphase component one can then determine subpixel shift along each axis 
this paper present technique for constructing full view panoramic mosaic form sequence of image our representation associate a rotation matrix and optionally a focal length with each input image rather than explicitly projecting all of the image onto a common surface e g a cylinder in order to reduce accumulated registration error we apply global alignment block adjustment to whole sequence of image which result in an optimal image mosaic in the least square sense to compensate for small amount of motion parallax introduced by translation of the camera and other unmodeled distortion we develop a local alignment deghosting technique which warp each image based on the result of pairwise local image registration by combining both global and local alignment we significantly improve the quality of our image mosaic thereby enabling the creation of full view panoramic mosaic with hand held camera 
the main problem for building a mosaic is the computation of the warping function homographies in fact two case are to be distinguished the first is when the homography is mainly a translation i e the rotation around the optical axis and the zooming factor are small the second is the general case when the rotation around the optical axis and zooming are arbitrary some efficient method have been developed to solve the first case but the second case is more difficult in particular when the rotation around the optical axis is very large degree or more often in this case human interaction is needed to provide a first approximation of the transformation that will bring u back to the first case in this article we present a method to solve this problem without human interaction for any rotation around the optical axis and fairly large zooming factor 
we describe the generation of a large pose mosaic dataset a collection of several thousand digital image grouped by spatial position into spherical mosaic each annotated with estimate of the acquiring camera s dof pose dof position and dof orientation in an absolute coordinate system the pose mosaic dataset wa generated by acquiring image grouped by spatial position into node essentially spherical mosaic a prototype mechanical pan tilt head wa manually deployed to acquire the data manual surveying provided initial position estimate for each node a back projecting scheme provided initial rotational estimate relative rotation within each node along with internal camera parameter were refined automatically by an optimization correlation scheme relative translation and rotation among node were refined according to point correspondence generated automatically and by a human operator the resulting pose imagery is self consistent under a variety of evaluation metric pose mosaic are useful first class data object for example in automatic reconstruction of textured d cad model which represent urban exterior 
in this paper we consider a multi camera vision system mounted on a moving object in a static three dimensional environment by using the motion flow field seen by all of the camera an algorithm which doe not need to solve the point correspondence problem among the camera is proposed to estimate the d ego motion parameter of the moving object our experiment have shown that using multiple optical flow field obtained from different camera can be very helpful for ego motion estimation 
this paper present a prediction and verification segmentation scheme wing attention image from multiple fixation a major advantage of this scheme is that it can handle a large number of different deformable object presented in complex background the scheme is also relatively efficient since the segmentation is guided by the past knowledge through a prediction and verification scheme the system ha been tested to segment hand in the sequence of intensity image where each sequence represents a hand sign the experimental result showed a correct segmentation rate with a false rejection rate 
computer vision system such a seeing robot aimed at functioning robustly in a natural environment rich on information benefit from relying on multiple cue then the problem of integrating these become central existing approach to cue integration have typically been based on physical and mathematical model for each cue and used estimation and optimization method to fuse the parameterizations of these model in this paper we consider an approach for fusion that doe not rely on the underlying model for each cue it is based on a simple binary voting scheme a particular feature of such a scheme is that also incommensurable cue such a intensity and surface orientation can be fused in a direct way other feature are that uncertainty and the normalization of them is avoided instead consensus of several cue is considered a non accidental and used a support for hypothesis of whatever structure is sought for it is shown that only a small set of cue need to agree to obtain a reliable output we apply the proposed technique to finding instance of planar surface in binocular image without resorting to scene reconstruction or segmentation the result are of course not comparable to the best result that can be obtained by complete scene reconstruction however they provide the most obvious instance of plane also with rather crude assumption and coarse algorithm even though the precise extent of the planar patch is not derived good overall hypothesis are obtained our work applies voting scheme beyond earlier attempt and also approach the cue integration problem in a novel manner although further research is needed to establish the full applicability of our technique our result so far seem quite useful 
the retrieval of image from a large database of image is an important and emerging area of research here a technique to retrieve image based on appearance that work effectively across large change of scale is proposed the database is initially filtered with derivative of a gaussian at several scale a user defined template is then created from an image of an object similar to those being sought the template is also filtered using gaussian derivative the template is then matched with the filter output of the database image and the match ranked according to the match score experiment demonstrate the technique on a number of image in a database no prior segmentation of the image is required and the technique work with viewpoint change up to degree and illumination change 
one of the central problem in stereo matching and other image registration task is the selection of optimal window size for comparing image region this paper address this problem with some novel algorithm based on iteratively diffusing support at different disparity hypothesis and locally controlling the amount of diffusion based on the current quality of the disparity estimate it also develops a novel bayesian estimation technique which significantly outperforms technique based on area based matching ssd and regular diffusion we provide experimental result on both synthetic and real stereo image pair 
we introduced an unsupervised texture segmentation method the selectionist relaxation relying on a markov random field mrf texture description and a genetic algorithm based relaxationscheme it ha been shown elsewhere that this method is convenientfor achieving a parallel and reliable estimation of mrf parameter andconsequently a correct image segmentation nevertheless these resultshave been obtained with an order model on artificial texture the purposeof the present work is 
the need to generate new view of a d object from a single real image arises in several field including graphic and object recognition while the traditional approach relies on the use of d model we exploit d image transformation that are specific to the relevant object class and learnable from example view of other prototypical object of the same class 
tracking with deformable contour in a filtering frame work requir esa dynamical model for prediction for any given application tracking is improved by having an accurate model learned from training data we develop a method for learning dynamical model from training sequence explicitly taking account of the fact that training data are noisy measurement and not true state by introducing an augmented state smoothing filter we show how the technique of expectation maximisation can be applied to this problem and show that the resulting algorithm produce more robust and accurate tracking 
describing a video sequence in term of a small number of coherently moving segment is useful for task ranging from video compression to event perception promising approach is to view the motion segmentation problem in a mixture estimation framework however existing formulation generally use only the motion data and thus fail to make use of static cue when segmenting the sequence furthermore the number of model is either specified in advance or estimated outside the mixture model framework in this work we address both of these issue we show how to add spatial constraint to the mixture formulation and present a variant of the em algorithm that make use of both the form and the motion constraint moreover this algorithm estimate the number of segment given knowledge about the level of model failure expected in the sequence the algorithm s performance is illustrated on synthetic and real image sequence 
stereo sequence promise to be a powerful method for segmenting image for application such a tracking human figure we present a method of statistical background modeling for stereo sequence that improves the reliability and sensitivity of segmentation in the presence of object clutter the dynamic version of the method called gated background adaptation can reliably learn background statistic in the presence of corrupting foreground motion the method ha been used with a simple head discriminator to detect and track people using a stereo head mounted on a pan tilt platform it run at video rate using standard pc hardware 
the problem of determining feature correspondence across multiple view is considered the term true multi image matching is introduced to describe technique that make full and efficient use of the geometric relationship between multiple image and the scene a true multi image technique must generalize to any number of image be of linear algorithmic complexity in the number of image and use all the image in an equal manner a new space sweep approach to true multi image matching is presented that simultaneously determines d feature correspondence and the d position of feature point in the scene the method is illustrated on a seven image matching example from the aerial image domain 
this paper describes a new method for lens distortion calibration using only point correspondence in multiple view without the need to know either the d location of the point or the camera location the standard lens distortion model is a model of the deviation of a real camera from the ideal pinhole or projective camera model given multiple view of a set of corresponding point taken by ideal pinhole camera there exist epipolar and trilinear constraint among pair and triplet of these view in practice due to noise in the feature detection and due to lens distortion these constraint do not hold exactly and we get some error the calibration is a search for the lens distortion parameter that minimize this error using simulation and experimental result with real image we explore the property of this method we describe the use of this method with the standard lens distortion model radial and decentering but it could also be used with any other parametric distortion model finally we demonstrate that lens distortion calibration improves the accuracy of d reconstruction 
we describe a novel approach for image matchingbased on deformable intensity surface in thisapproach the intensity surface of the imageis modeled a a deformable d mesh in the x y i x y space each surface point ha degree of freedom thus capturing fine surfacechanges a set of representative deformationswithin a class of object e g face are statisticallylearned through a principal componentsanalysis thus providing a priori knowledgeabout object specific 
the success of an intelligent robotic system depends on the performance of it vision system which in turn depends to a great extend upon the quality of it calibration during the execution of a task the vision system is subject to external influence such a vibration thermal expansion etc which affect and possibly render invalid the initial calibration moreover it is possible that the parameter of the vision system like e g the zoom or the focus are altered intentionally in order to perform specific vision task this paper describes a technique for automatically maintaining calibration of stereovision system over time without using again any particular calibration apparatus it us all available information i e both spatial and temporal data uncertainty is systematically manipulated and maintained synthetical and real data are used to validate the proposed technique and the result compare very favourably with those given by classical calibration method 
this paper proposes a new algorithm for matching point feature across pair of image despite the well known combinatorial complexity of the problem this work show that an acceptably good solution can be obtained directly by singular value decomposition of an appropriate correspondence strength matrix the approach draw from the method proposed previously but besides suggesting it usefulness for stereo matching in this work a correlation weighted proximity function is used a correspondence strength to specifically cater for real image 
crease are a type of ridge valley structure that can be characterized by local condition therefore creaseness refers to local ridgeness and valleyness the curvature of the level curve and the mean curvature m of the level surface are good measure of creaseness for d and d image respectively however the way they are computed give rise to discontinuity reducing their usefulness in many application we propose a new creaseness measure based on these curvature that avoids the discontinuity we demonstrate it usefulness in the registration of ct and mr brain volume from the same patient by searching the maximum in the correlation of their creaseness response ridgeness from the ct and valleyness from the mr due to the high dimensionality of the space of transforms the search is performed by a hierarchical approach combined with an optimization method at each level of the hierarchy 
the purpose of this study is not only to recognize some kind of facial expression which is associated with human emotion but also to estimate it degree our method is based on the idea that facial expression recognition can be achieved by extracting a variation from expressionless face with considering face area a a whole pattern for the purpose of extracting subtle change in the face such a the degree of expression it is necessary to eliminate the individuality appearing in the facial image using a elastic net model a variation of facial expression is represented a motion vector of the deformed net from a facial edge image then applying k l expansion the change of facial expression represented a the motion vector of node is mapped into low dimensional eigen space and estimation is achieved by projecting input image on to the emotion space in this paper we have constructed three kind of expression model happiness anger surprise and experimental result are evaluated 
despite many successful application of robust statistic they have yet to be completely adapted to many computer vision problem range reconstruction particularly in unstructured environment requires a robust estimator that not only tolerates a large outlier percentage but also tolerates several discontinuity extracting multiple surface in an image region observing that random outlier and or point from across discontinuity increase a hypothesized fit s scale estimate standard deviation of the noise our new operator called muse minimum unbiased scale estimator evaluates a hypothesized fit over potential inlier set via an objective function of unbiased scale estimate muse extract the single best fit from the data by minimizing it objective function over a set of hypothesized fit and can sequentially extract multiple surface from an image region we show muse to be effective on synthetic data modelling small scale discontinuity and in preliminary experiment on complicated range data 
we present a variational approach to dense stereo reconstruction which combine powerful tool such a regularization and multi scale processing to e stimate directly depth from a number of stereo image while preserving depth discontinuity the problem is set a a regularization and minimization of a nonquadratic functional the tikhonov quadratic regularization term usually used to recover smooth solution is replaced by a function of the gradient depth specifically derived to allow depth discontinuity formation in the solution condition to be fulfilled by this specific regularizing term to preserve discontinuitiesare also presented to solve this problem in the discrete case a pde based expli cit scheme for moving iteratively towards the solution ha been developed this approach present the additional advantage of not introducing any intermediate representation such a disparity or rectified image depth is computed directly from the grey level image and we can also deal with any number greater than two of camera promising experimental result illustrate the capabili tie of this approach 
we present a fast electronic image stabilization system that compensates for d rotation the extended kalman filter framework is employed to estimate the rotation between frame which is represented using unit quaternion a small set of automatically selected and tracked feature point are used a measurement the effectiveness of this technique is also demonstrated by constructing mosaic image from the motion estimate and comparing them to mosaic built from d stabilization algorithm two different stabilization scheme are presented the first implemented in a real time platform based on a datacube mv board estimate the motion between two consecutive frame and is able to process gray level image of resolution x at hz the second scheme estimate the motion between the current frame and an inverse mosaic this allows better estimation without the need for indexing the new image frame experimental result for both scheme using real and synthetic image sequence are presented 
a divide and conquer strategy in shape from shading problem under fully perspective condition is proposed for the information recovery of book surface the whole recovery process is composed of three sequential step preprocessing apparent shape recovery and ortho image generation pure shade image are extracted at preprocessing step by introducing phenomenological model of interreflection and by removing pigment part from observed image using existing invariance equation of slope and that of ortho image being explicit are derived from equation of shading and that of observation being implicit recurrence relation is derived from definition of mean slope in discrete image theoretically it become possible to recover unique shape without iteration using derived equation in case of lambertian cylinder however a feed back shape recovery process is implemented a practical algorithm in order to overcome self shadow result of simulation and real experiment show the properness and acceptability of the proposed strategy and implemented algorithm 
one of the most promising application of d ultrasound lie in the visualisation and volume estimation of internal d structure unfortunately artifact and speckle make automatic analysis of the data difficult in this paper we investigate the use of d spatial compounding to improve data quality and find that accurate registration is the key a correlation based registration technique is applied to d ultrasound data acquired from in vivo examination of a human gall bladder we find that the registration technique performs well and visualisation and segmentation of the compounded data are clearly improved 
we introduce a new distance between two distribution that we call the earth mover s distance emd which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving distribution mass around this is a special case of the transportation problem from linear optimization for which efficient algorithm are available the emd also allows for partial matching when used to compare distribution thathave the same overall mass the emd is a true metric and ha easy to compute lower bound in this paper we focus on application to image database especially color and texture we use the emd to exhibit the structure of color distribution and texture space by mean of multi dimensional scaling display we also propose a novel approach to the problem of navigating through a collection of color image which lead to a new paradigm for image database search 
we show that the self calibration of a stereo head from corresponding point in an image pair is in certain circumstance prone to considerable error a novel error analysis reveals that the automated determination of relative orientation and focal length is adversely affected when the camera verge inwards a similar amount and when the principal point location have a horizontal error this analysis is facilitated by the adoption of closed form solution for self calibration from previous work of the author it is also shown that estimation of the fundamental matrix associated with a stereo head image pair is improved when a domain specific parameterization and associated computational technique are adopted experiment conducted with such image pair suggest that given cognisance of sensitive configuration and adoption of the revised method of fundamental matrix estimation robust reconstruction are attainable this is demonstrated on the problem of metrically reconstructing a scene from two pair of image obtained by an uncalibrated stereo head undergoing unknown ground plane motion 
dependence on landmark point or high order derivativeswhen establishing correspondence between geometrical image curve undervarious subclass of projective transformation remains a shortcomingof present method in the proposed framework geometric transformationsare treated a smooth function involving the parameter of thecurves on which the transformation basis point lie by allowing the basispoints to vary along the curve hypothesised correspondence are freedfrom the 
this work recovers d graphic model of object with specular surface an object is routed and continuous image of it are taken circular light that generate cone of ray are used to illuminate the rotating object when the light are properly set each point on the object can be highlighted during the rotation the shape for each rotational plane is measured independently using it corresponding epipolar palne image a d graphic model is subsequently reconstructed by combining shape at different rotational plane computing a shape is simple and requires only the motion of the highlight on each rotation plane result not obtained before are given in the d shape recovery experiment on real object 
until now all super resolution algorithm have presumed that the image were taken under the same illumination condition this paper introduces a new approach to super resolution based on edge model and a local blur estimate which circumvents these difficulty the paper present the theory and the experimental result using the new approach 
this paper describes technique to perform fast and accuratecurve detection using a variant of the hough transform we show thatthe hough transform can be decomposed into small subproblems thatexamine only a subset of the parameter space each subproblem considersonly those curve that pas through some small subset of the data point this property allows the efficient implementation of the hough transformwith respect to both time and space and allows the careful propagationof the 
human being seem to recognize object based on a kind of model matching i e a virtual manipulation on mental image this paper present a d object pose estimation method simulating the human recognition scheme computer synthesizes not only an edge image but also a shading image from an object model then it match the two kind of synthesized image with the inputted image individually by using a non linear least square method and estimate the pose parameter value finally it chooses the better of the individually estimated pose thus the fusion of the shading and the edge information is achieved since the two piece of information complement each other this method ha the advantage of much higher robustness and accuracy of pose estimation than ordinary model matching technique which rely only on geometrical feature such a vertex or edge 
we present a new algorithm for the automatic recovery of tag grid line intersection in tagged mr image of the left ventricle of the heart our method us an active spring mesh to capture local property of the motion and a global motion model to capture the global coherence of the motion we recover the global component of the motion using robust estimation different motion model have been developed for short and long axis view of the heart the algorithm ha been tested on healthy and pathological data 
in computer vision two complementary approach have been widely used to perform object reconstruction and registration the deformable model framework locally applies internal and external force to fit d data the non rigid registration framework iteratively computes the best global transformation in order to minimize the distance between a template and the data in this paper we first show that applying a global transformation on a surface model is equivalent to applying an external force on a deformable model without any regularizing force second we propose a hybrid framework which combine the registration framework and the deformable model scheme our hybrid deformation approach allows to control the scale at which the model is deformed this is clearly beneficial for performing both reconstruction and registration task we show many example of this approach on active contour and deformable surface furthermore a global transformation based on axial symmetry is introduced 
in this study ultrasound image sequence of fetus head are examined for the bi parietal diameter measurement there are five part of the fetus head that have to be seen clearly before such a measurement can be made our approach is based on model based multi objective analysis for each part an objective function encoding both data and anatomic constraint is formulated the resulting multi objective problem is then transformed into a problem of coupled differential equation and is then solved using numerical integration throughout the process continuity principle is used between the frame so that the result of analysis on one frame can be used on the next frame whenever possible 
we propose an approach for boundary finding where the correspondence of a subset of boundary point to a model is simultaneously determined global shape parameter derived from the statistical variation of object boundary point in a training set are used to model the object a bayesian formulation based on this prior knowledge and the edge information of the input image is employed to find the object boundary with it subset point in correspondence with boundary in the training set or the mean boundary we compared the use of a generic smoothness prior and a uniform independent prior with the training set prior in order to demonstrate the power of this statistical information a number of experiment were performed on both synthetic and real medical image of the brain and heart to evaluate the approach including the validation of the dependence of the method on image quality different initialization and prior information 
a new view based approach to the representation and recognition of action is presented the basis of the representation is a temporal template a static vector image where the vector value at each point is a function of the motion property at the corresponding spatial location in an image sequence using aerobics exercise a a test domain we explore the representational power of a simple two component version of the template the first value is a binary value indicating the presence of motion and the second value is a function of the recency of motion in a sequence we then develop a recognition method which match these temporal template against stored instance of view of known action the method automatically performs temporal segmentation is invariant to linear change in speed and run in real time on a standard platform we recently incorporated this technique into the kidsroom an interactive narrative play space for child 
efficient edge detection algorithm such a canny s fail near curve singularity moreover the standard linking algorithm used on top of these detector often fail because of instability in the tracking process due to multiple response to the same edge and interference of nearby edge we propose a hierarchical approach to edge detection based on a graph stabilization method that allows bifurcation resolution in stage curve singularity are recovered at the last stage by using top down feedback to select the best curve connection 
the problem considered in this paper is that of estimating the projective transformation between two image in situation where the image motion is large and featurematching is not aided by a proximity heuristic the overall algorithm designed is based on a multiresolution multihypothesis scheme and similarity between tracking and matching through multiple resolution level are exploited two major tool are developed in this paper i a bayesian framework for incorporating similarity measure of feature correspondence in regression to specify the different level of confidence in the correspondence and ii a bayesian version of ransac which is able to utilise prior estimate and matching probability the algorithm is tested on a number of real image with large image motion and promising result were obtained 
it is typical in edge detection application to examine a single scale or to consider some space of scale in the image without knowing which scale is appropriate for each location in the image however many image contain a wide variation in the distance to the scene point and thus object of the same size can appear at greatly differing scale in the image we present a method where the scale of the smoothing and edge detection is varied locally according to the distance to the scene point which we estimate through stereoscopy the edge that are detected are thus at the same scale in the world rather than at the same scale in the image this method ha been implemented efficiently by smoothing the image at a discrete set of scale and performing interpolation to estimate the response at the correct scale for each pixel the application of this technique to an ordnance recognition problem ha resulted in a considerable improvement in performance 
this paper present a multibaseline stereo technique specially suited to detecting obstacle a method is described for weakly calibrating a set of multibaseline stereo camera with high accuracy this method is then used to tailor the stereo search space to the special case where the world in front of the camera consists mainly of nearly horizontal planar surface the ground where we are interested in deviation from those planar surface obstacle the resulting disparity map are presented and compared to the output of a traditional stereo algorithm 
we present algorithm for coupling and training hidden markov model hmms to model interacting process and demonstrate their superiority to conventional hmms in a vision task classifying two handed action hmms are perhaps the most successful framework in perceptual computing for modeling and classifying dynamic behavior popular because they offer dynamic time warping a training algorithm and a clear bayesian semantics however the markovian framework make strong restrictive assumption about the system generating the signal that it is a single process having a small number of state and an extremely limited state memory the single process model is often inappropriate for vision and speech application resulting in low ceiling on model performance coupled hmms provide an efficient way to resolve many of these problem and offer superior training speed model likelihood and robustness to initial condition 
this paper pr esents a framework for detecting and tracking moving object in a sequence of image using a statistical approach where the inter frame difference is modeled by a mixture of two laplacian or gaussian distribution and an energy minimization based approach we reformulate the motion detection and tracking problem a a front propagation problem the euler lagrange equation of the designed energy functional is first derived and the flow minimizing the energy is then obtained following the work by caselles et al cks and malladi et al msv msv the contour to be detected and tracked are modeled a geodesic active contour evolving toward the minimum of the designed energy under the influence of internal and external image dependent force using the level set formulation scheme of osher and sethian o complex curve can be detected and tracked and topological change for the evolving curve are naturally managed to reduce the computational cost required by a direct implementation of the formulation scheme of osher and sethian o a new approach exploiting aspect from the classical narrow band a and fast marching set method is proposed and favorably compared to them in order to further reduce the cpu time a multi scale approach ha also been considered very promising experimental result are provided using real video sequence 
a new dynamic subdivision surface model is proposed for shape recovery from d data set the model inherits the attractive property of the catmull clark subdivision scheme and is set in a physic based modeling paradigm unlike other existing method our model doe not require a parameterized input mesh to recover shape of arbitrary topology allows direct manipulation of the limit surface via application of force and provides a fast robust and hierarchical approach to recover complex shape from d data with very few degree of freedom contr ol vertic e we provide an analytic formulation and introduce the physical quantity required to develop the dynamic subdivision surface model which can be deformed by applying force synthesized from the data our experiment demonstrate that this new dynamic model ha a promising future in shape recovery from volume and range data set 
we have developed a computer vision system including both facial feature extraction and recognition that automatically discriminates among subtly different facial expression expression classification is based on facial action coding system facs action unit au and discrimination is performed using hidden markov model hmms three method are developed to extract facial expression information for automatic recognition the first method is facial feature point tracking using a coarse to fine pyramid method this method is sensitive to subtle feature motion and is capable of handling large displacement with sub pixel accuracy the second method is dense flow tracking together with principal component analysis pca where the entire facial motion information per frame is compressed to a low dimensional weight vector the third method is high gradient component i e furrow analysis in the spatiotemporal domain which exploit the transient variation associated with the facial expression upon extraction of the facial information non rigid facial expression is separated from the rigid head motion component and the face image are automatically aligned and normalized using an affine transformation this system also provides expression intensity estimation which ha significant effect on the actual meaning of the expression 
a model registration system capable of tracking an object the model of which is known in an image sequence is presented it integrates tracking pose determination and updating of the visible feature the which handle various feature point line and free form curve in a very robust way and is able to give a correct estimate of the pose even when tracking errorsoccur the reliability of the system is shown on an augmented reality project 
a novel method for d head tracking in the presence of large head rotation and facial expression change is described tracking is formulated in term of color image registration in the texture map of a d surface model model appearance is recursively updated via image mosaicking in the texture map a the head orientation varies the resulting dynamic texture map provides a stabilized view of the face that can be used a input to many existing d technique for face recognition facial expression analysis lip reading and eye tracking parameter are estimated via a robust minimization procedure this provides robustness to occlusion wrinkle shadow and specular highlight the system wa tested on a variety of sequence taken with low quality uncalibrated video camera experimental result are reported 
this paper introduces an object based approach for temporal video partitioning and content based indexing where the basic indexing unit is lifespan of a video object rather than a camera shot or story unit we propose a system to extract content based feature of video object vos based on a compact d triangular mesh representation of them an adaptive mesh based video object tracking scheme is then employed to compute the motion trajectori of all node point a set of key snapshot which constitute a visual summary of the lifespan of the object are automatically selected using motion and shape information the system provides direct access to the vos and give the functionality such a object based search manipulation animation and tracking 
perspective camera calibration ha been in the last decade a research subject for a large group of researcher and a a result several camera calibration methodology can be foundin the literature however only a small number of those method base their approach on the use of monoplane calibration point to realize an explicit d camera calibration to avoid the singularity obtained with the calibration equation when monoplane calibration point are used this method computes the calibration parameter in a multi step procedure and requires a first guess solution for the intrinsic parameter these parameter are updated and their accuracy increased through an iterative procedure a stability analysis a a function of the pose of the camera is presented camera pose view strategy for accurate camera orientation computation can be extracted from the pose view stability analysis 
we describe an approach to the classification of d object using a multi scale representation this approach start with a smoothing algorithm for representing object at different scale smoothing is applied in curvature space directly thus avoiding the usual shrinkage problem and allowing for efficient implementation a d similarity measure that integrates the representation of the object at multiple scale is introduced given a library of model object that are similar based on this multi scale measure are grouped together into class the object that are in the same class are combined into a single prototype object finally the prototype are used for hierarchical recognition by first comparing the scene representation to the prototype and then matching it only to the object in the most likely class rather than to the entire library of model beyond it application to object recognition this approach provides an attractive implementation of the intuitive notion of scale and approximate similarity for d shape 
conventional video camera have limited field of view which make them restrictive for certain application in computational vision a catadioptric sensor us a combination of lens and mirror placed in a carefully arranged configuration to capture a much wider field of view when designing a catadioptric sensor the shape of the mirror s should ideally be selected to ensure that the complete catadioptric system ha a single effective viewpoint in this paper we derive the complete class of single lens single mirror catadioptric sensor which have a single viewpoint and an expression for the spatial resolution of a catadioptric sensor in term of the resolution of the camera used to construct it we also include a preliminary analysis of thedefocus blur caused by the use of a curved mirror 
human speech is inherently multi modal consisting of both audio and visual component recently researcher have shown that the incorporation of information about the position of the lip into acoustic speech recognisers enables robust recognition of noisy speech in the case of hidden markov model recognition we show that his happens because the visual signal stabilises the alignment of state it is also shown that unadorned lip both the inner and outer contour can be robustly tracked in real time on general purpose workstation to accomplish this efficient algorithm are employed which contain three key component shape model motion model and focused colour feature detector all of which are learnt from example 
previous research on nonlinear shape restoration are based on the assumption that the original shape and distortion of the image have known formulation under certain condition the main contribution of this research is the development of a new restoration algorithm called multi step restoration the algorithm is based on a liner interpolation theory that is able to detect and restore nonlinear shape distortion in any irregular quadrilateral shaped pattern the main idea of the algorithm is the use of two dimensional spline function in bicubic biquadratic and or bilinear model to approximate the three dimensional nonlinear distortion curve the performance of the approach shown by experiment is promising 
recently there have been increasing interest in using nonlinear pdes for application in computer vision and image processing in this paper we propose a general statistical framework for designing a new class of pdes for a given application a markov random field model p i is learned according to the minimax entropy principle studied in so that p i should characterize the ensemble of image in our application p i is a gibbs distribution whose energy term can be divided into two category subsequently the partial differential equation given by gradient descent on the gibbs potential are essentially reaction diffusion equation where the energy term in one category produce anisotropic diffusion while the inverted energy term in the second category produce reaction associated with pattern formation we call this new class of pdes the gibbs reaction and diffusion equation grade and we demonstrate experiment where grade are used for texture pattern formation denoising image enhancement and clutter removal 
a recent trend in motion based segmentation ha been to rely on statistical procedure derived from expectation maximization em principle em based approach have various attractives for segmentation such a proceeding by taking non greedy soft decision with regard to the assignment of pixel to region or allowing the use of sophisticated prior capable of imposing spatial coherence on the segmentation a practical difficulty with such prior is however the determination of appropriate value for their parameter in this work we exploit the fact that the em framework is itself suited for empirical bayesian data analysis to develop an algorithm that find the estimate of the prior parameter which best explain the observed data such an approach maintains the bayesian appeal of incorporating prior belief but requires only a qualitative description of the prior avoiding the requirement of a quantitative specification of it parameter this eliminates the need for trial and error strategy for parameter determination and lead to better segmentation in le iteration 
we have designed and implemented a system for real time detection of d feature on a reconfigurable computer based on field programmable gate array fpga s we envision this device a the front end of a system able to track image feature in real time control application like autonomous vehicle navigation the algorithm employed to select good feature is inspired by tomasi and kanade s method compared to the original method the algorithm that we have devised doe not require any floating point or transcendental operation and can be implemented either in hardware or in software moreover it map efficiently into a highly pipelined architecture well suited to implementation in fpga technology we have implemented the algorithm on a low cost reconfigurable computer and have observed reliable operation on an image stream generated by a standard ntsc video camera at hz 
this paper describes a vectorial representation that can be used to ass the symmetry of object in d image the method exploit a magneto static analogy commencing from the gradient field extracted from filtered grey scale image we construct a vector potential our magneto static analogy is that tangential gradient vector represent the element of a current distribution on the image plane by embedding the image plane in an augmented dimensional space we compute the vector potential by performing volume integration over the current distribution the associated magnetic field is computed by taking the curl of the vector potential the auxiliary spatial dimension provides a natural scale space sampling of the generating current distribution a the height above the image plane is increased so the volume over which averaging is effected also increase we extract edge and symmetry line through a topographic analysis of the vector field at various height above the image plane symmetry ax are line of where the curl of the vector potential vanishes at edge the divergence of the vector potential vanishes 
a method for the temporal classification of natural gesture from video imagery is presented the work is motivated by recent development in the theory of natural gesture which have identified several key temporal aspect of gesture important to communication in particular gesticulation during conversation can be coarsely characterized a period of bi phasic or tri phasic gesture separated by a rest state we first present an automatic procedure for hypothesizing plausible rest state configuration of a speaker second we develop a state based parsing algorithm used to both select among candidate rest state and to parse an incoming video stream into bi phasic and tri phasic gesture finally we demonstrate the use of the bi phasic tri phasic labeling to select semantically significant static image for low bandwidth coding of video of story telling speaker 
gamut mapping colour constancy attempt to determine the set of diagonal matrix taking the gamut of image colour under an unknown illuminantion to the gamut of colour observed under a standard illuminant forsyth developed such an algorithm in rgb sensor space which finlayson later modified to work in a d chromaticity space in this paper we prove that forsyth s d solution gamut is when projected to d identical to the gamut recovered by the d algorithm whilst this implies that there is no inherent disadvantage in working in chromaticity space this algorithm ha a number of problem the d solution set is distorted and contains practically non feasible illuminant these problem have been addressed separately in previous work we address them together in this paper non feasible illuminant are discarded by intersecting the solution gamut with a non convex gamut of common illuminant in d this intersection is relatively simple but to remove the distortion both these set should be represented a d cone of mapping and the intersection is more difficult we present an algorithm which avoids performing this intersection explicitly and which is simple to implement test of this algorithm on both real and synthetic image show that it performs significantly better than the best current algorithm 
we represent local spatial structure in a color image using feature matrix that are computed from an image region feature matrix contain significantly more information about local image structure than previous representation although feature matrix are useful for surface recognition this representation depends on the spectral property of the scene illumination using a finite dimensional linear model for surface spectral reflectance with the same number of parameter a the number of color band we show that illumination change correspond to linear transformation of the feature matrix and that surface rotation correspond to circular shift of the matrix from these relationship we derive an algorithm for illumination and geometry invariant recognition of local surface structure we demonstrate the algorithm with a series of experiment on image of real object 
this paper present a negative result current machine colour constancy algorithm are not good enough for colour based object recognition this result ha surprised u since we have previously used the better of these algorithm successfully to correct the colour balance of image for display colour balancing ha been the typical application of colour constancy rarely ha it been actually put to use in a computer vision system so our goal wa to show how well the various method would do on an obvious machine colour vision task namely object recognition although all the colour constancy method we tested proved insufficient for the task we consider this an important finding in itself in addition we present result showing the correlation between colour constancy performance and object recognition performance and a one might expect the better the colour constancy the better the recognition rate 
in this paper a method to extract curvilinear structure from digital image is presented the approach is based on differential geometric property of the image function for each pixel the second order taylor polynomial is computed by convolving the image with the derivative of a gaussian smoothing kernel line point are required to have a vanishing gradient and a high curvature in the direction perpendicular to the line the use of the taylor polynomial and the gaussian kernel lead to a single response of the filter to each line furthermore the line position can be determined with sub pixel accuracy finally the algorithm scale to line of arbitrary width an analysis about the scale space behaviour of two typical line type parabolic and bar shaped is given from this analysis requirement and useful value for the parameter of the filter can be derived additionally an algorithm to link the individual line point into line and junction that preserve the maximum number of line point is given example on aerial image of different resolution illustrate the versatility of the presented approach 
we propose a motion segmentation algorithm that aim to break a scene into it most prominent moving group instead of identifying point correspondence between the image frame the idea to find what group of pixel are transformed from one image frame to another to do this we treat the image sequence a a three dimensional spatiotemporal data set and construct a weighted graph by taking each pixel a a node and connecting pixel that are in the spatiotemporal neighborhood of each other we define a motion profile vector at each image pixel which capture the probability distribution of the image velocity at that point by defining a distance between motion profile at two pixel we can assign a weight on the graph edge connecting them using normalized cut we find the most salient partition of the spatiotemporal volume formed by the image sequence each partition which is in the form of a spatiotemporal volume corresponds to a group of pixel moving coherently in space and time normalized cut can be computed efficiently by solving a generalized eignevalue problem 
a real time system is described for automatically detecting modeling and tracking face in d a closed loop approach is proposed which utilizes structure from motion to generate a d model of a face and then feed back the estimated structure to constrain feature tracking in the next frame the system initializes by using skin classification symmetry operation d warping and eigenfaces to find a face feature trajectory are then computed by ssd or correlation based tracking the trajectory are simultaneously processed by an extended kalman filter to stably recover d structure camera geometry and facial pose adaptively weighted estimation is used in this filter by modeling the noise characteristic of the d image patch tracking technique in addition the structural estimate is constrained by using parametrized model of facial structure eigen head the kalman filter s estimate of the d state and motion of the face predicts the trajectory of the feature which constrains the search space for the next frame in the video sequence the feature tracking and kalman filtering closed loop system operates at hz 
a real time system is described for automatically detecting modeling and tracking face in d a closed loop approach is proposed which utilizes structure from motion to generate a d model of a face and then feed back the estimated structure to constrain feature track ing in the next frame the system initializes by u ing skin classi cation symmetry operation d warp ing and eigenfaces to nd a face feature trajectory are then computed by ssd or correlation based track ing the trajectory are simultaneously processed by an extended kalman lter to stably recover d struc ture camera geometry and facial pose adaptively weighted estimation is used in this lter by modeling the noise characteristic of the d image patch tracking technique in addition the structural estimate is con strained by using parametrized model of facial struc ture eigen head the kalman lter s estimate of the d state and motion of the face predicts the trajectory of the feature which constrains the search space for the next frame in the video sequence the feature track ing and kalman ltering closed loop system operates at hz 
we present a novel method for the shape and motion estimation of a deformable model using error residual from model based motion analysis the motion of the model is first estimated using a model based least square method using the residual from the least square solution the non rigid structure of the model can be better estimated by computing how change in the shape of the model affect it motion parameterization this method is implemented a a component in a deformable model based framework that us optical flow information and edge this general model based framework is applied to human face shape and motion estimation we present experiment that demonstrate that this framework is a considerable improvement over a framework that us only optical flow information and edge 
the recognition of human gesture and facial expression in imagesequences isan important and challenging problem that enables a hostof human computer interaction application thispaperdescribes a frameworkforincrementalrecognitionofhumanmotionthatextendsthe condensation algorithm proposed by isard and blake eccv human motion are modeled astemporal trajectoriesof some estimated parameter over time the condensationalgorithm us random sampling technique to incrementally match the trajectory model to the multi variate input data the recognition framework is demonstrated withtwoexamples therstexampleinvolvesanaugmentedocewhiteboardwithwhichausercanmakesimplehandgesturestograbregionsof theboard printthem savethem etc thesecondexampleillustratesthe recognition of human facial expression using the estimated parameter of a learned model of mouth motion 
a map mrf based scheme is proposed for recovering the depth and the focused image of a scene from two defocused image the space variant blur parameter and the focused image of the scene are both modeled a mrfs and their map estimate are obtained using simulated annealing the performance of the proposed scheme is tested on both synthetic a well a real data and the estimate of the depth are found to be better than that of the existing window based technique 
in this paper an adaptive split and merge segmentation method is proposed the splitting phase of the algorithm employ the incremental delaunay triangulation competent of forming grid edge of arbitrary orientation and position the tessellation grid defined by the delaunay triangulation is adjusted to the semantics of the image data by combining similarity and difference information among pixel experimental result on synthetic image show that the method is robust to different object edge orientation partially weak object edge and very noisy homogeneous region experiment on a real image indicate that the method yield good segmentation result even when there is a quadratic sloping of intensity particularly suited for segmenting natural scene of man made object 
there is considerable interest in the computer vision community in representing and modelling motion motion model are use d a predictor to increase the robustness and accuracy of visual tracker and a classifier for gesture recognition this paper present a significant development of random sampling method to allow automatic switching between multiple motion model a a natural extension of the tracking process the bayesian mixed state framework is described in it generality and the example of a bouncing ball is used to demonstrate that a mixed state model can significantly improve tracking performance in heavy clutter the relevance of the approach to the problem of gesture recognition is then investigated using a tracker which is able to follow the natural drawing action of a hand holding a pen and switch state according to the hand s motion 
three different statistical model of colour data for use in segmentation or tracking algorithm are proposed result of a performance comparison of a tracking algorithm applied to two separate application using each of the three different type of underlying model of the data are presented from these a comparison of the performance of the statistical colour model themselves is obtained 
let s be a set of six point in space let psi be any hyperboloid of one sheet containing s and let i be a sequence of image of s taken by an uncalibrated camera moving over psi then reconstruction from i is subject to a three way ambiguity which is unbroken a long a the optical centre of the camera remains on psi let p be an image of s taken from a point on psi the image near p define a tangent space which split into a direct sum w p oplus n p oplus f p where wp corresponds to image near p for which the ambiguity is maintained np corresponds to image for which the ambiguity is broken and fp corresponds to image which are physically impossible 
we present a new method for synthesizing novel view of a d scene from few model image in full correspondence the core of this work is the derivation of a tensorial operator that describes the transformation from a given tensor of three view to a novel tensor of a new configuration of three view by repeated application of the operator on a seed tensor with a sequence of desired virtual camera position we obtain a chain of warping function tensor from the set of model image to create the desired virtual view 
in this paper we first introduce the multi focus camera a new image sensor used for depth from defocus dfd range measurement it can capture three image with different focus value simultaneously we then propose two different depth measurement method using the camera the first method an augmented version of the one proposed in employ a noniterative optimization process to compute depth value on edge point the second one incorporates a coded aperture with the camera and applies model based pattern matching to estimate depth value of textured surface here we propose two type of coded aperture and corresponding analysis algorithm d fourier analysis to acquire a depth map and a blur free image from three defocused image taken with a pair of pinhole and d convolution based model matching for the fast and precise depth measurement using a coded aperture with four pinhole experimental result showed that the multi focus camera work well a a practical dfd range sensor and that the coded aperture much improve it range estimation capability for real world scene 
we present a method for the integration of illumination constraint within a deformable model framework these constraint are incorporated a nonlinear holonomic constraint in the lagrange equation of motion governing the deformation of the model for improved numerical performance we employ the baumgarte stabilization method our methodology is general and can be used for a broad range of illumination constraint this approach avoids commonly used approximation in shape from shading such a linearization and the use of partial differential equation which require initial boundary condition furthermore global and local parameterizations of the deformable model allow an improved estimation of shape from shading we demonstrate this improvement over previously used approach through a series of experiment on standardized set of real and synthetic data 
this paper proposes a method that can spot and recognize each facial expression from time sequential image that contain multiple facial expression that could abruptly change from one expression to another expression previously the author have proposed an hmm hidden markov model based method for recognizing a spotted facial expression in this paper to hmm we add state corresponding to the simultaneous motion of two different facial expression i e a muscle relaxation for one expression and a muscle contraction for another expression then the added state are each linked from the hmm apex state of one expression and are linked to that of another expression experimental result showed that for most pair of expression the change in expression can be recognized accurately in addition recognition rate for very fast change of expression improved significantly the proposed method wa applied to regenerate facial expression on a synthesized character to show the method s effectiveness in obtaining facial motion information 
a new cascade basis reduction method of computing the optimal least square set of basis function steering a given function is presented the method combine the lie group theoretic and the singular value decomposition approach in such a way that their respective strength complement each other since the lie group theoretic approach is used the set of basis and steering function computed can be expressed analytically because the singular value decomposition method is used this set of basis and steering function is optimal in the least square sense furthermore the computational complexity in designing basis function for transformation group with large number of parameter is significantly reduced the efficiency of the cascade basis reduction method is demonstrated by designing a set of basis function that steer a gabor function under the four parameter linear transformation group 
we propose a novel solution to the problem of motion compensation of coronary angiographs a the heart is beating it is difficult for the physician to observe closely a particular point e g stenosis on the artery tree we propose to rigidly compensate the sequence so that the area around the point of interest appears stable this is a difficult problem because the artery deform in a nonrigid manner and only their d x ray projection is observed also the lack of feature around the selected point make the matching subject to the aperture problem the algorithm automatically extract a section of the artery of interest model it a a polyline andtracks it the problem is formulated a an energy minimization problem which is solved using a shortest path in a graph algorithm the motion compensated sequence can be obtained by translating every pixel so that the point of interest remains stable we have applied this algorithm to many example in two set of angiography data and have obtained excellent result 
in this paper we propose a general framework to build a task oriented d object recognition system for cad based vision cbv feature from d space curve representing the object s rim provide sufficient information to allow identification and pose estimation of industrial cad model however feature relying on differential surface property tend to be very vulnerable with respect to noise to model the statistical behavior of the data we introduce bayesian netswhich model the relationship between object and observable feature furthermore task oriented selection of the optimal action to reduce the uncertainty of recognition result is incorporated into the bayesian net this enables the integration of intelligent recognition strategy depending on the already acquired evidence into a robust and effcient d cad based recognition system 
computing camera rotation from image sequence can be used for image stabilization and when the camera rotation is known the computation of translation and scene structure are much simplified a well a robust approach for recovering camera rotation is presented which doe not assume any specific scene structure e g no planar surface is required and which avoids prior computation of the epipole given two image taken from two different viewing position the rotation matrix between the image can be computed from any three homgraphy matrix the homographies are computed using the trilinear tensor which describes the relation between the projection of a d point into three image the entire computation is linear for small angle and is therefore fast and stable iterating the linear computation can then be used to recover larger rotation a well 
abstract this article present a statistical theory for texture modeling this theory combine filtering theory and markov random field modeling through the maximum entropy principle and interprets and clarifies many previous concept and method for texture analysis and synthesis from a unified point of view our theory characterizes the ensemble of image i with the same texture appearance by a probability distribution f i on a random field and the objective of texture modeling is to make inference about f i given a set of observed texture example in our theory texture modeling consists of two step a set of filter is selected from a general filter bank to capture feature of the texture these filter are applied to observed texture image and the histogram of the filtered image are extracted these histogram are estimate of the marginal distribution of f i this step is called feature extraction the maximum entropy principle is employed to derive a distribution p i which is restricted to have the same marginal distribution a those in this p i is considered a an estimate of f i this step is called feature fusion a stepwise algorithm is proposed to choose filter from a general filter bank the resulting model called frame filter random field and maximum entropy is a markov random field mrf model but with a much enriched vocabulary and hence much stronger descriptive ability than the previous mrf model used for texture modeling gibbs sampler is adopted to synthesize texture image by drawing typical sample from p i thus the model is verified by seeing whether the synthesized texture image have similar visual appearance to the texture image being modeled experiment on a variety of d and d texture are described to illustrate our theory and to show the performance of our algorithm these experiment demonstrate that many texture which are previously considered a from different category can be modeled and synthesized in a common framework keywords texture modeling texture analysis and synthesis minimax entropy maximum entropy markov 
new set of color model are proposed for object recognition invariant to a change in view point object geometry and illumination further computational method are presented to combine color and shape invariant to produce a high dimensional invariant feature set for discriminatory object recognition experiment on a database of image show that object recognition based on composite color and shape invariant feature provides excellent recognition accuracy furthermore object recognition based on color invariant provides very high recognition accuracy whereas object recognition based entirely on shape invariant yield very poor discriminative power the image database and the performance of the recognition scheme can be experienced within pictoseek on line a part of the zomax system at http www win uva nl research isi zomax 
in this paper we study the infinitesimal time case of the so called multilinear constraint that exist for each subsequence in a sequence of image these constraint link the infinitesimal motion of the image point with the infinitesimal viewer motion the analysis is done both for calibrated and uncalibrated camera two simplification are also presented for the uncalibrated camera case one simplification is made using affine reduction and kinetic depth the second simplification is based upon a projective reduction with respect to the image of a planar patch 
this paper present a general framework for the computation of projective invariant of arbitrary degree of freedom dof trihedral polyhedron we show that high dof figure can be broken down into set of connected four dof polyhedron for which known invariant exist although the more general shape do not posse projective property a a whole when viewed by a single camera each subpart doe yield a projective description which is based on the butterfly invariant furthermore planar projective invariant can be measured which link together the subpart and so we can develop a local global description for general trihedral polyhedron we demonstrate the recovery of polyhedral shape description from image by exploiting the local global nature of the invariant introduction in this article we introduce a general scheme for understand ing the shape property of trihedral polyhedron trihedral polyhedron are solid polyhe dra made up of plane in arbitrary position and a such no special constraint exist b etween the plane the nomenclature trihedral derives from the fact that the vertex of the polyhedron are only ever defined by triple of plane point in space need at least three plane to assert their location but any more would provide excess constraint and hence would not be generic and stably realisable the result in this paper are a summ ary of those given in in all we generalise the result in which showed how a projectively invariant description can be computed for four degree of freedom dof polyhedron from a single view in turn wa a extension of the work of sugihara the latter dealt with scaled orthographic projection and the calibrated perspec tive case whereas the former demonstrated the projective equivalence of all member of the family of four dof polyhedron generating a set of scene measurement using an uncalibrated camera we show in this paper that the approach of can be extended to inclu de all trihedral polyhedron we also build on some recent work for computing the invariant of minimal point configuration in three dimensional space being able to compute measure for small local feature group provides robustness to occlusion more global description can be built up using the local global nature of many shape description we derive a part whole decomposition by drawing the invariant description of and the invariant based on the butterfly configurationof mundy together the butterfly invariant is a geometric description of a special six point configuration our interest in the butterfly invariant wa promoted by the re cent paper of sugimoto this paper discus an invariant very similar to the original butterfly invariant but suggests an algebraic rather than a geometric f ormulation however sugimoto suggested that the invariant in in some way replace the invariant described by in fact these two type of invariant can be taken hand in hand and are exactly complementary this we show partly in this paper and in more detail in the contribution of this paper are three fold in section we discus how the original invariant description of can be decomposed into a set of three independent butterfly invariant then we show in section how to reduce a five dof figure into set of 
in this paper we discus new result on the shape from darkness problem using the motion of cast shadow to recover scene structure our approach is based on collecting a set of image from a fixed viewpoint a a known light source move across the sky previously published solution to this problem have performed the reconstruction only for cross section of the scene in this paper we present a reconstruction algorithm and discus the reconstruction of an entire d scene under various light source trajectory we also consider the constraint on reconstruction we conclude with experimental result that illustrate the convergence property of the solution process and it robustness property 
an image clad surface representation based on regularization theory is introduced in this paper this representation is based on a hybrid model derived from the physical membrane and plate model the representation called the spl lambda spl tau representation ha two dimension one dimension represents smoothness or scale while the other represents the continuity of the image or surface it contains image surface sampled both in scale space and the weighted sobolev space of continuous function thus this new representation can be viewed a an extension of the well known scale space representation we have experimentally shown that the proposed hybrid model result in improved result compared to the two extreme constituent model i e the membrane and the plate model based on this hybrid model a generalized edge detector ged which encompasses most of the well known edge detector under a common framework is developed the existing edge detector can be obtained from the generalized edge detector by simply specifying the valve of two parameter one of which control the shape of the filter spl tau and the other control the scale of the filter spl lambda by sweeping the valve of these two parameter continuously one can generate an edge representation in the spl lambda spl tau space which is very useful for developing a goal directed edge detection scheme for a specific task the proposed representation and the edge detector have been evaluated qualitatively and quantitatively on several different type of image data such a intensity range and stereo image 
this paper proposes a novel pattern classificationapproach called the nearest linear combination nlc approach for eigenface based face recognition assumethat multiple prototypical vector are availableper class each vector being a point in an eigenfacespace a linear combination of prototypical vectorsbelonging to a face class is used to define a measureof distance from the query vector to the class the measure being defined a the euclidean distancefrom the query to the linear 
two important problem in camera control are how to keep a moving camera fixated on a target point and how to precisely aim a camera whose approximate pose is known towards a given d position this paper describes how electronic image alignment technique can be used to solve these problem a well a provide other benefit such a stabilized video hence stabilized fixated imagery is obtained despite large latency in the control loop even for simple control strategy these technique have been tested using an airborne camera and real time affine image alignment 
content based indexing method are of great interest for image and video retrievial in audio visual archive such a in the divan project that we are currently developping detecting and recognizing human face automatically in video data provide user with powerful tool for performing query in this article a new scheme for face recognition using a wavelet packet decomposition is presented each face is described by a subset of band filtered image containing wavelet coefficient these coefficient characterize the face texture and a set of simple statistical measure allows u to form compact and meaningful feature vector then an efficient and reliable probalistic metric derived from the bhattacharrya distance is used in order to classify the face feature vector into person class 
facial expression provides sensitive cue about emotion and play a major role in interpersonal and humancomputer interaction most facial expression recognition system have focused on only six basic emotion and their concomitant prototypic expression posed by a small set of subject in reality human are capable of producing thousand of expression that vary in complexity intensity and meaning to represent the full range of facial expression we developed a computer vision system that automatically recognizes individual action unit au or au combination using hidden markov model and estimate expression intensity three module are used to extract facial expression information facial feature point tracking dense flow tracking with principal component analysis pca and high gradient component detection i e furrow detection the average recognition rate of upper and lower face expression is and respectively using feature point tracking upper face using dense flow tracking with pca and and upper and lower face respectively using high gradient component detection 
this paper present a technique to determine the identity of object in a scene using histogram of the response of a vector of local linear neighborhood operator receptive field this technique can be used to determine the most probable object in a scene independent of the object s position image plane orientation and scale in this paper we describe the mathematical foundation of the technique and present the result of experiment which compare robustness and recognition rate for different local neighborhood operator and histogram similarity measurement 
w s is a real time visual surveillance system for detecting and tracking people and monitoring their activity in an outdoor environment by integrating realtime stereo computation into an intensitybased detection and tracking system unlike many system for tracking people w s make no use of color cue instead w s employ a combination of stereo shape analysis and tracking to locate people and their part head hand foot torso and create model of people s appearance so that they can be tracked through interaction such a occlusion w s is capable of simultaneously tracking multiple people even with occlusion it run at hz for resolution image on a dual pentium pc 
this article raise the problem of error caused by the metrology of a calibration pattern to the accurate estimation of the intrinsic and extrinsic calibration parameter modeling the video system in order to take into account these error a new approach is proposed that enables u to compute in the same time the traditional calibration parameter and the d geometry of the calibration pattern using a multi image calibration algorithm experimental result show that the proposed algorithm lead to reliable calibration result and prof that calibration error no longer depend on the accuracy of calibration point measurement but on the accuracy of calibration point detection in the image plane 
shape indexing is a way of making rapid association between feature detected in an image and object model that could have produced them when model database are large the use of high dimensional feature is critical due to the improved level of discrimination they can provide unfortunately finding the nearest neighbour to a query point rapidly becomes inefficient a the dimensionality of the feature space increase past indexing method have used hash table for hypothesis recovery but only in low dimensional situation in this paper we show that a new variant of the k d tree search algorithm make indexing in higher dimensional space practical this best bin first or bbf search is an approximate algorithm which find the nearest neighbour for a large fraction of the query and a very close neighbour in the remaining case the technique ha been integrated into a fully developed recognition system which is able to detect complex object in real cluttered scene in just a few second 
one approach to recognizing object seen from arbitrary viewpoint isby extracting invariant property of the object from single image such property are found in image of d object only when theobjects are constrained to belong to certain class e g bilaterally symmetric object existing study that follow thisapproach propose how to compute invariant representation for ahandful of class of object a fundamental question regarding theinvariance approach is whether it can be applied to a wide range ofclasses to answer this question it is essential to study the set ofclasses for which invariance exists this paper introduces a newmethod for determining the existence of invariant function forclasses of object together with the set of image from which theseinvariants can be computed we develop algebraic test that determinewhether the object in a given class can be identified from singleimages these test apply to class of object undergoing affineprojection in addition these test allow u to determine the set ofviews of the object which are degenerate we apply these test toseveral class of object and determine which of them is identifiableand which of their view are degenerate 
this article present a theory for multi scale representation of temporaldata assuming that a real time vision system should represent the incomingdata at different time scale an additional causality constraintarises compared to traditional scale space theory we can only use whathas occurred in the past for computing representation at coarser timescales based on a previously developed scale space theory in term of noncreationof local maximum with increasing scale a complete 
in order to reduce false alarm and to improve the target detection performance of an automatic target detection and recognition system operating in a cluttered environment it is important to develop the model not only for man made target but also of natural background clutter because of the high complexity of natural clutter this clutter model can only be reliably built through learning from real example if available contextual information that characterizes each training example can be used to further improve the learned clutter model in this paper we present such a clutter model aided target detection system emphasis are placed on two topic learning the background clutter model from sensory data through a self organizing process reinforcing the learned clutter model using contextual information 
