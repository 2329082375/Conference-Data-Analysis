we present an approach that significantly enhances the capability of traditional image mosaicing the key observation is that a a camera move it sens each scene point multiple time we rigidly attach to the camera an optical filter with spatially varying property so that multiple measurement are obtained for each scene point under different optical setting fusing the data captured in the multiple image yield an image mosaic that includes additional information about the scene this information can come in the form of extended dynamic range high spectral quality or enhancement to other dimension of imaging we refer to this approach a generalized mosaicing the approach wa tested using a filter with spatially varying transmittance and a standard bit black white video camera to achieve image mosaicing with dynamic range comparable to imaging with a bit camera in another experiment we attached a spatially varying spectral filter to the same camera to obtain mosaic that represent the spectral distribution rather than the usual rgb measurement of each scene point we also discus how generalized mosaicing can be used to explore other imaging dimension 
dynamic texture are sequence of image of moving scene that exhibit certain stationarity property in time these include sea wave smoke foliage whirlwind but also talking face traffic scene etc we present a novel characterization of dynamic texture that pose the problem of modelling learning recognizing and synthesizing dynamic texture on a firm analytical footing we borrow tool from system identification to capture the essence of dynamic texture we do so by learning i e identifying model that are optimal in the sense of maximum likelihood or minimum prediction error variance for the special case of second order stationary process we identify the model in closed form once learned a model ha predictive power and can be used for extrapolating synthetic sequence to infinite length with negligible computational cost we present experimental evidence that within our framework even low dimensional model can capture very complex visual phenomenon 
in a number of discipline directional data provides a fundamental source of information a novel framework for isotropic and anisotropic diffusion of direction is presented in this paper the framework can be applied both to regularize directional data and to obtain multi scale representation of it the basic idea is to apply and extend result from the theory of harmonic map in liquid crystal this theory deal with the regularization of vectorial data while satisfying the unit norm constraint of directional data we show the corresponding variational and partial differential equation formulation for isotropic diffusion obtained from an l norm and edge preserving diffusion obtained from an l norm in contrast with previous approach the framework is valid for direction in any dimension support non smooth data and give both isotropic and anisotropic formulation we present a number of theoretical result open question and example for gradient vector optical flow and color image 
the notion of a virtual sensor for optimal d reconstruction is introduced instead of planar perspective image that collect many ray at a fixed viewpoint omnivergent camera collect a small number of ray at many different viewpoint the resulting d manifold of ray are arranged into two multiple perspective image for stereo reconstruction we call such image omnivergent image and the process of reconstructing the scene from such image omnivergent stereo this procedure is shown to produce d scene model with minimal reconstruction error due to the fact that for any point in the d scene two ray with maximum vergence angle can be found in the omnivergent image furthermore omnivergent image are shown to have horizontal epipolar line enabling the application of traditional stereo matching algorithm without modification three type of omnivergent virtual sensor are presented spherical omnivergent camera center strip camera and dual strip camera 
we present a novel approach to measuring similarity between shape and exploit it for object recognition in our framework the measurement of similarity is preceded by solving for correspondence between point on the two shape using the correspondence to estimate an aligning transform in order to solve the correspondence problem we attach a descriptor the shape context to each point the shape context at a reference point capture the distribution of the remaining point relative to it thus offering a globally discriminative characterization corresponding point on two similar shape will have similar shape context enabling u to solve for correspondence a an optimal assignment problem given the point correspondence we estimate the transformation that best aligns the two shape regularized thin plate spline provide a fle xible class of transformation map for this purpose dissimilarity between two shape is computed a a sum of matching error between correspondingpoints together with a term measuring the magnitude of the aligning transform we treat recognition in a nearest neighbor classification framework result are presented for silhouette trademark handwritten digit and the coil dataset 
the mapping between d body pose and d shadow is fundamentally many to many and defeat regression method even with windowed context we show how to learn a function between path in the two system resolving ambiguity by integrating information over the entire length of a sequence the basis of this function is a configurable and dynamical manifold that summarizes the target system s behavior this manifold can be modeled from data with a hidden markov model having special topological property that we obtain via entropy minimization inference is then a matter of solving for the geodesic on the manifold that best explains the evidence in the cue sequence we give a closed form maximum a posteriori solution for geodesic through the learned density space thereby obtaining optimal path over the dynamical manifold these method give a completely general way to perform inference over time series in vision they support analysis recognition classification and synthesis of behavior in linear time we demonstrate with a prototype that infers d from monocular monochromatic sequence e g back subtraction without using any articulatory body model the framework readily accommodates multiple camera and other source of evidence such a optical flow or feature tracking 
the shape of an object may be estimated by observing the shadow on it surface we present a method that is robust with respect to a conservative classification of shadow region assuming that a conservative estimate of the object shape is available we analyze image of the object illuminated with known point light source taken from known camera location we adjust our surface estimate using the shadow region to produce a refinement that is still a conservative estimate a proof of correctness is provided no assumption about the object topology are made although any tangent plane discontinuity over the object s surface are supposed to be detectable an implementation and some experimental result are presented 
we propose a bayesian framework for representing and recognizing local image motion in term of two primitive model translation and motion discontinuity motion discontinuity are represented using a non linear generative model that explicitly encodes the orientation of the boundary the velocity on either side the motion of the occluding edge over time and the appearance disappearance of pixel at the boundary we represent the posterior distribution over the model parameter given the image data using discrete sample this distribution is propagated over time using the condensation algorithm to efficiently represent such a high dimensional space we initialize sample using the response of a low level motion discontinuity detector 
intelligent scissors and intelligent paint are complemen tary interactive image segmentation tool that allow a user to quickly and accurately select object of interest this demonstration provides a mean for participant to experi ence the dynamic nature of these tool introduction 
many visual matching algorithm can be describedin term of the feature and the inter feature distanceor metric the most commonly used metric is thesum of squared difference ssd which is valid froma maximum likelihood perspective when the real noisedistribution is gaussian based on real noise distributionsmeasured from international test set we havefound experimentally that the gaussian noise distributionassumption is often invalid this implies thatother metric which have 
variation in illumination can have a dramatic effect on the appearance of an object in an image in this paper we propose how to deal with illumination variation in eigenspace method we demonstrate that the eigenimages obtained by a training set under a single illumination condition ambient light can be used for recognition of object taken under different illumination condition the major idea is to incorporate a set of gradient based lter bank into the eigenspace recognition framework this can be achieved since the eigenimage coeficients are invariant for linearly ltered image input and eigenimages to achieve further illumination insensitivity we devised a robust procedure for coeficient recovery the proposed approach ha been extensively evaluated on a set of image and the result were compared to other approach 
abstract a framework is developed for the design and analysis of single viewpoint catadioptric camera that use two or more mirror the use of multiple mirror permit folding of the optic which lead to more compact camera design than one that use a single mirror a dictionary of camera design that use two conic mirror is presented we show that any folded system that us conic mirror ha a geo metrically equivalent system that us a single conic mir ror this result make it easy to determine the scene to image mapping of a conic folded system in addition we discus the optical benefit of using folded system a an example we choose a camera design from our dictio nary and optimize it parameter via optical simulation this design is used to construct a compact video camera that provides a hemispherical field of view 
factorization using singular value decomposition svd is often used for recovering d shape and motion from feature correspondence across multiple view svd is powerful at finding the global solution to the associated least square error minimization problem however this is the correct error to minimize only when the x and y positional error in the feature are uncorrelated and identically distributed but this is rarely the case in real data uncertainty in feature position depends on the underlying spatial intensity structure in the image which ha strong directionality to it hence the proper measure to minimize is covariance weighted squared error or the mahalanobis distance in this paper we describe a new approach to covariance weighted factorization which can factor noisy feature correspondence with high degree of directional uncertainty into structure and motion our approach is based on transforming the raw data into a covariance weighted data space where the component of noise in the different direction are uncorrelated and identically distributed applying svd to the transformed data now minimizes a meaningful objective function we empirically show that our new algorithm give good result for varying degree of directional uncertainty in particular we show that unlike other svd based factorization algorithm our method doe not degrade with increase in directionality of uncertainty even in the extreme when only normal flow data is available it thus provides a unified approach for treating corner like point together with point along linear structure in the image 
in this paper we present a novel approach to robust skeleton extraction we use undirected graph to model connectivity of the skeleton point the graph topology remains unchanged throughout the skeleton computation which greatly reduces sensitivity of the skeleton to noise in the shape outline furthermore this representation naturally defines an ordering of the point along the skeleton the process of skeleton extraction can be formulated a energy minimization in this framework we provide an iterative snake like algorithm for the skeleton estimation using distance transform fixed topology skeleton are useful if the global shape of the object is known ahead of time such a for people silhouette hand outline medical structure image of letter and digit small change in the object outline should be either ignored or detected and analyzed but they do not change the general structure of the underlying skeleton example application include tracking object recognition and shape analysis 
we have assembled a standalone movable system that can capture long sequence of omnidirectional image up to image at hz and a resolution of the goal of this system is to reconstruct complex large environment such a an entire floor of a building from the captured image only in this paper we address the important issue of how to calibrate such a system our method us image of the environment to calibrate the camera without the use of any special calibration pattern knowledge of camera motion or knowledge of scene geometry it us the consistency of pairwise tracked point feature across a sequence based on the characteristic of catadioptric imaging we also show how the projection equation for this catadioptric camera can be formulated to be equivalent to that of a typical rectilinear perspective camera with just a simple transformation 
catadioptric system are realization of omnidirectional vision through mirror lens combination design preserving the uniqueness of an effective viewpoint have recently gained attraction we present here a novel approach for estimating the intrinsic parameter of a well known catadioptric system consisting of a paraboloid mirror and an orthographic lens we introduce the geometry of catadioptric line projection and we show that the vanishing point lie on a conic section which encodes the entire calibration information projection of two set of parallel line suffice for intrinsic calibration from one view a well a for metric rectification of a plane our approach overcomes limitation of existing manual calibration method and wa successfully tested on the task of back warping real image image onto virtual plane 
in this work a new approach to fully automatic color image segmentation called jseg is presented first color in the image are quantized to several representing class that can be used to differentiate region in the image then image pixel color are replaced by their corresponding color class label thus forming a class map of the image a criterion for good segmentation using this class map is proposed applying the criterion to local window in the class map result in the j image in which high and low value correspond to possible region boundary and region center respectively a region growing method is then used to segment the image based on the multi scale j image experiment show that jseg provides good segmentation result on a variety of image 
we introduce a finite difference expansion for closely space d camera in projective vision and use it to derive differential analogue of the finite displacement projective matching tensor and constraint the result are simpler more general and easier t o use than astrom heyden s time derivative based continuous time matching constraint we suggest how to use the formalism f or tensor tracking propagation of matching relation agai nst a fixed base image along an image sequence we relate this to non linear tensor estimator and show how unwrapping the optimization loop along the sequence allows simple linear point update estimate to converge rapidly to statistically near optim al nearconsistent tensor estimate a the sequence proceeds we also give guideline a to when difference expansion is likely to be worthwhile a compared to a discrete approach 
we present a method for the recognition of walking people in monocular image sequence based on the extraction of coordinate of specific point location on the body the method work by a comparison of sequence of recorded coordinate with a library of sequence from different individual the comparison is based on the evaluation of view invariant and calibration independent view consistency constraint these constraint are function of corresponding image coordinate in two view and are satisfied whenever the two view are projected from the same three dimensional d object by evaluating the view consistency constraint for each pair of frame in a sequence of a walking person and a stored sequence we obtain a matrix of consistency value that ideally are zero whenever the pair of image depict the same d posture the method is virtually parameter free and computes a consistency residual between a pair of sequence that can be used a a distance for clustering and classification using interactively extracted data we present experimental result that are superior to those of previously published algorithm both in term of performance and generality key word structure from motion calibration object recognition 
a simple algorithm is described that computes the radiometric response function of an imaging system from image of an arbitrary scene taken using different exposure the exposure is varied by changing either the aperture setting or the shutter speed the algorithm doe not require precise estimate of the exposure used rough estimate of the ratio of the exposure e g fnumber setting on an inexpensive lens are sufficient for accurate recovery of the response function a well a the actual exposure ratio the computed response function is used to fuse the multiple image into a single high dynamic range radiance image robustness is tested using a variety of scene and camera a well a noisy synthetic image generated using randomly selected response curve automatic rejection of image area that have large vignetting effect or temporal scene variation make the algorithm applicable to not just photographic but also video camera code for the algorithm and several result are publicly available at http www c columbia edu cave 
extending a dierential total least square method for range flow estimation we present an iterative regularisation approach to compute dense range flow field we demonstrate how this algorithm can be used to detect motion discontinuity this can can be used to segment the data into independently moving region the dierent type of aperture problem encountered are discussed our regularisation scheme then take the various type of flow vector and combine them into a smooth flow field within the previously segmented region a quantitative performance analysis is presented on both synthetic and real data the proposed algorithm is also applied to range data from castor oil plant obtained with the biris laser range sensor to study the d motion of plant leaf 
we describe how d affine measurement may be computed from a single perspective view of a scene given only minimal geometric information determined from the image this minimal information is typically the vanishing line of a reference plane and a vanishing point for a direction not parallel to the plane it is shown that affine scene structure may then be determined from the image without knowledge of the camera s internal calibration e g focal length nor of the explicit relation between camera and world pose in particular we show how to i compute the distance between plane parallel to the reference plane up to a common scale factor semi ii compute area and length ratio on any plane parallel to the reference plane semi iii determine the camera s location simple geometric derivation are given for these result we also develop an algebraic representation which unifies the three type of measurement and amongst other advantage permit a first order error propagation analysis to be performed associating an uncertainty with each measurement we demonstrate the technique for a variety of application including height measurement in forensic image and d graphical modelling from single image 
we develop a pairwise classification framework for face recognition in which a c class face recognition problem is divided into a set of c c two class problem such a problem decomposition not only lead to a set of simpler classification problem to be solved thereby increasing overall classification accuracy but also provides a framework for independent feature selection for each pair of class a simple feature ranking strategy is used to select a small subset of the feature for each pair of class furthermore we evaluate two classification method under the pairwise comparison framework the bayes classifier and the adaboost experiment on a large face database with face image of individual indicate that feature are enough to achieve a relatively high recognition accuracy which demonstrates the effectiveness of the pairwise recognition framework 
we present a simple procedure for synthesising novel view using two or more basis image a input it is possible for the user to interactively adjust the viewpoint and for the corresponding image to be computed and rendered in real time rather than employing a d model our method is based on the linear relation which exist between image taken with an affine camera we show how the combination of view proposed by ullman and basri can be appropriately parameterised when a sequence of five or more image is available this is achieved by fitting polynomial model to the coefficient of the combination where the latter are function of the unknown camera parameter we discus an alternative approach direct image interpolation and argue that our method is preferable when there is a large difference in orientation between the original gaze direction we show the result of applying the parameterisation to a fixating camera using both simulated and real input our observation are relevant to several application including visualisation animation and low bandwidth communication 
the spatial distribution of gray level intensity in an image can be naturally modeled using markov random field mrf model we develop and investigate the performance of face detection algorithm derived from mrf consideration for enhanced detection the mrf model are defined for every permutation of site index in the image we find the optimal permutation that provides maximum discriminatory power to identify face from nonfaces the methodology presented here is a generalization of the face detection algorithm in where a most discriminating markov chain model wa used the mrf model successfully detect face in a number of test image in real time 
this article deal with optical law that must be considered when using underwater camera both theoretical and experimental point of view are described and it is shown that relationship between air and water calibration can be found 
this paper introduces a new probabilistic framework for space carving in this framework each voxel is assigned a probability which is computed by comparing the likelihood for the voxel existing and not existing this new framework avoids many of the difficulty associated with the original space carving algorithm specifically it doe not need a global threshold parameter and it guarantee that no hole will be carved in the model this paper also proposes that a voxel based thick texture is a realistic and efficient representation for scene which contain dominant plane the algorithm is tested using both real and synthetic data and both qualitative and quantitative result are presented 
this paper examines the problem of reconstructing a voxelized representation of d space from a series of image an iterative algorithm is used to find the scene model which jointly explains all the observed image by determining which region of space is responsible for each of the observation the current approach formulates the problem a one of optimization over estimate of these responsibility the process converges to a distribution of responsibility which accurately reflects the constraint provided by the observation the position and shape of both solid and transparent object and the uncertainty which remains reconstruction is robust and gracefully represents regio n of space in which there is little certainty about the exact structure due to limited non existent or contradicting d ata rendered image of voxel space recovered from synthetic and real observation image are shown 
the problem of establishing correspondence between image taken from different viewpoint is fundamental in computer vision we propose an algorithm which is capable of handling larger change in viewpoint than classical correlation based technique optimal performance for the algorithm is achieved for textured object which are locally planar in at least one direction the algorithm work by computing affinely invariant fourier feature from intensity profile in each image the intensity profile are extracted from the image data between randomly selected pair of image interest point using a voting scheme pair of interest point are matched across image by comparing vector of fourier feature outlier among the match are rejected in two stage a fast stage using novel view consistency constraint and a second slower stage using ransac and fundamental matrix computation in order to demonstrate the quality of the result the algorithm is tested on several different image pair 
this paper investigates the multiple view geometry of smooth surface and a plane where the plane provides a planar homography mapping between the view innovation are made in three area first new solution are given for the computation of epipolar and trifocal geometry for this type of scene in particular it is shown that the epipole may be determined from bitangents between the homography registered occluding contour and a new minimal solution is given for computing the trifocal tensor second algorithm are demonstrated for automatically estimating the fundamental matrix and trifocal tensor from image of such scene third a method is developed for estimating camera matrix for a sequence of image of these scene these three area are combined in a freehand scanner application where d texture mapped graphical model of smooth object are acquired directly from a video sequence of the object and plane 
this paper present a new approach to image based guidance of a needle or surgical tool during percutaneous procedure the method is based on visual servoing it requires no prior calibration or registration the technique provides highly precise d alignment of the tool with respect to an anatomic target by taking advantage of projective geometry and projective invariant this can be achieved in a fixed number of iteration in addition the approach estimate the required insertion depth experiment include automatic d alignment and insertion of a needle held by a medical robot into a pig kidney under x ray fluoroscopy 
this paper present an approach to object detection which is based on recent work in statistical model for texture synthesis and recognition heeger and bergen de bonet and viola zhu et al simoncelli and portilla our method follows the texture recognition work of de bonet and viola we use feature vector which capture the joint occurrence of local feature at multiple resolution the distribution of feature vector for a set of training image of an object class is estimated by clustering the data and then forming a mixture of gaussian model the mixture model is further refined by determining which cluster are the most discriminative for the class and retaining only those cluster after the model is learned test image are classified by computing the likelihood of their feature vector with respect to the model we present promising result in applying our technique to face detection and car detection 
we analyze the effect of perturbation on the estimation of depth from defocus dfd implemented by changing the focus setting e g axially moving the sensor the analysis yield the optimal change of focus setting and the spatial frequency for which estimation is most robust for stable estimation at all spatial frequency the change in focus setting should be le than twice the depth of field for the most robust estimation in the highest spatial frequency the axial interval should be equal to the depth of field 
in many case self calibration is not able to yield a unique solution for the d reconstruction of a scene this is due to the occurrence of critical motion sequence if this is the case an ambiguity is left on the reconstruction in this paper it is derived under which condition correct novel view can be generated from ambiguous reconstruction the problem is r st approached from a theoretical point of view it is proven that novel view are correct a long a the inclusion of the new view in the sequence yield the same ambiguity on the reconstruction the problem is therefore much related to the problem of critical motion sequence since the virtual camera can be arbitrarily moved within the smallest critical motion set that contains the recovered camera motion without distortion becoming visible based on these result a practical measure for the expected ambiguity on a novel view based on the recovered structure and motion is derived a an application a viewer wa built that indicates if a specic novel view can be trusted or not by changing the background color 
a bayesian framework for deformable pattern classification wa proposed by k w cheung et al with promising result for isolated handwritten character recognition it performance however degrades significantly when it is applied to detect deformable pattern in complex scene where the amount of outlier due to other neighboring object or the background is usually large also the fact that the associated evidence measure doe not penalize model resting on white space result in a high false alarm rate another bayesian framework for deformable pattern detection is proposed the framework posse the intrinsic property of matching with only part of an image segmentation and it associated evidence measure can penalize white space implicitly however limited data exploration capability is the major trade off by properly combining the two framework a new matching algorithm called bidirectional matching is proposed this combined approach posse the advantage of the two framework and give robust result for non rigid shape extraction to evaluate the performance of the proposed approach we have applied it to shape based handwritten word retrieval using a subset of the bb dataset in the cedar database we can achieve a recall rate of and a precision rate of 
we study the recognition of surface made from different material such a concrete rug marble or leather on the basis of their textural appearance such natural texture arise from spatial variation of two surface attribute reflectance and surface normal in this paper we provide a unified model to address both these aspect of natural texture the main idea is to construct a vocabulary of prototype tiny surface patch with associated local geometric and photometric property we call these d textons example might be ridge groove spot or stripe or combination thereof associated with each texton is an appearance vector which characterizes the local irradiance distribution represented a a set of linear gaussian derivative filter output under different lighting and viewing condition given a large collection of image of different material a clustering approach is used to acquire a small on the order of d texton vocabulary given a few to image of any material it can be characterized using these textons we demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing condition 
point set obtained from computer vision technique are often noisy and non uniform we present a new method of surface reconstruction that can handle such data set using anisotropic basis function our reconstruction algorithm draw upon the work in variational implicit surface for constructing smooth and seamless d surface implicit function are often formulated a a sum of weighted basis function that are radially symmetric using radially symmetric basis function inherently assumes however that the surface to be reconstructed is everywhere locally symmetric such an assumption is true only at planar region and hence reconstruction using isotropic basis is insufficient to recover object that exhibit sharp feature we preserve sharp feature using anisotropic basis that allow the surface to vary locally the reconstructed surface is sharper along edge and at corner point we determine the direction of anisotropy at a point by performing principal component analysis of the data point in a small neighborhood the resulting field of principle direction across the surface is smoothed through tensor filtering we have applied the anisotropic basis function to reconstruct surface from noisy synthetic d data and from real range data obtained from space carving 
in this paper we present a novel approach to estimateand analyze d fluid structure and motion ofclouds from multi spectrum d cloud image sequence accurate cloud top structure and motion are very importantfor a host of meteorological and climate application however due to the extremely complex natureof cloud fluid motion classical nonrigid motion analysismethods will be insufficient to solve this particularproblem in this paper two spectrum of satellite cloudimages are utilized 
this paper present an algorithm that match interest point detected on a pair of grey level image taken from arbitrary point of view first matching hypothesis are generated using a similarity measure of the interest point hypothesis are confirmed using local group of interest paint group match are based on a measure defined on an affine transformation estimate and on a correlation coefficient computed on the intensity of the interest point once a reliable match ha been determined for a given interest point and the corresponding local group new group match are found by propagating the estimated affine transformation the algorithm ha been widely tested under various image transformation it provides dense match and is very robust to outlier i e interest point generated by noise or present in only one image because of occlusion or non overlap 
a family of axially symmetric mirror shape are proposed for panoramic imaging these shapeskeep the resolution in the image invariant to change in elevation in the scene in other word this family of shape achievessolid angle pixel density invariance an analysis of range finding using two coaxial axially symmetric resolution invariant mirror in a coaxial pair is presented the resolution invariance property of these mirror mean that when the image captured is unwarped the resultant image will not suffer from variable image quality this problem is present in unwarped image captured with any mirror shape not designed for resolution invariance the resolution invariance of these mirror is especially important in the case of stereo panoramic mirror where one view of the scene is captured within the other and thus will have lower resolution it is necessary to clearly identify two view of an object to undertake range finding the proposed mirror shape will be useful for mobile robotics and machine vision other application area such a visual sensing for control of traffic light at street intersection could be considered 
a method for upgrading a projective reconstruction to metric is presented the reconstruction is first transformed by considering cheirality so that the convex hull of the set of camera projection centre is the same a in the metric counterpart the method then proceeds iteratively and starting from such a reconstruction is a necessary condition for many iterative calibration algorithm to converge the result show that in practice it is also most often sufficient provided that the minimised objective function is a geometrically meaningful quantity the method ha been found extremely reliable for both large and small reconstruction in a large number of experiment on real data when subjected to the common degeneracy of little or no rotation between the view the method still yield a very reasonable member of the family of possible solution furthermore the method is very fast and therefore suitable for the purpose of viewing reconstruction 
face image are subject to change in view and illumination such change cause data distribution to be highly nonlinear and complex in the image space it is desirable to learn a nonlinear mapping from the image space to a low dimensional space such that the distribution becomes simpler tighter and therefore more predictable for better modeling of face in this paper we present a kernel machine based approach for learning such nonlinear mapping the aim is to provide an effective view based representation for multiview face detection and pose estimation assuming that the view is partitioned into a number of distinct range one nonlinear view subspace is learned for each range of view from a set of example face image of that view range by using kernel principal component analysis kpca projection of the data onto the view subspace are then computed a view based nonlinear feature multi view face detection and pose estimation are performed by classifying a face into one of the facial view or into the nonface class by using a multi class kernel support vector classifier ksvc experimental result show that fusion of evidence from multiviews can produce better result than using the result from a single view and that our approach yield high detection and low false alarm rate in face detection and good accuracy in pose estimation in comparison with the linear counterpart composed of linear principal component analysis pca feature extraction and fisher linear discriminant based classification fldc 
abstract data we o er a simple paradigm for tting mod we o er a simple paradigm for tting parametric el parametric and non parametric to noisy data model which solves these two problem this is which resolve some of the problem associated with done by considering each point on the parametric classic mse algorithm this is done by consider model a a possible source for each data point the ing each point on the model a a possible source for model is also extended to non parametric model each data point and give good result even for curve with strong the paradigm also allows to solve problem which discontinuity are not de ned in the classical mse approach such we show result of the method for line seg a tting a segment a opposed to a line it is ments circle and general curve we also show shown to be non biased and to achieve excellent result using gaussian and uniform noise model result for general curve even in the presence of strong discontinuity previous work result are shown for a number of tting prob lem including line circle segment and gen there are many paper written on using least eral curve contaminated by gaussian and uniform square technique in order to t parameter to a noise noisy model and on using di erent numerical tech niques and linear approximation in order to do the 
for motion picture special effect it is often necessary to take a source image of an actor segment the actor from the unwanted background and then composite over a new background the standard approach requires the unwanted background to be a blue screen while this technique is capable of handling area where the foreground blend into the background the physical requirement present many practical problem this paper present an algorithm that requires minimal human interaction to segment motion picture resolution image and image sequence we show that it can be used not only to segment badly lit or noisy bluescreen image but also to segment actor where the background is more varied 
we treat the problem of edge detection a one of statistical inference local edge cue implemented by lters provide information about the likely position of edge which can be used a input to higher level model dieren t edge cue can be evaluated by the statistical eectiv ene of their corresponding lters evaluated on a dataset of pre segmented image we use information theoretic measure to determine the eectiv ene of a variety of dieren t edge detector working at multiple scale on black and white and colour image our result give quantative measure for the advantage of multi level processing for the use of chromaticity in addition to greyscale and for the relative eectiv ene of dieren t detector proceeding computer vision and pattern recognition cvpr fort collins colorado 
we present an approach that significantly enhances the capability of traditional image mosaicing the key observation is that a a camera move it sens each scene point multiple time we rigidly attach to the camera an optical filter with spatially varying property so that multiple measurement are obtained for each scene point under different optical setting fusing the data captured in the multiple image yield an image mosaic that includes additional information about the scene this information can come in the form of extended dynamic range high spectral quality or enhancement to other dimension of imaging we refer to this approach a generalized mosaicing the approach wa tested using a filter with spatially varying transmittance and a standard bit black white video camera to achieve image mosaicing with dynamic range comparable to imaging with a bit camera in another experiment we attached a spatially varying spectral filter to the same camera to obtain mosaic that represent the spectral distribution rather than the usual rgb measurement of each scene point we also discus how generalized mosaicing can be used to explore other imaging dimension 
dynamic texture are sequence of image of moving scene that exhibit certain stationarity property in time these include sea wave smoke foliage whirlwind but also talking face traffic scene etc we present a novel characterization of dynamic texture that pose the problem of modelling learning recognizing and synthesizing dynamic texture on a firm analytical footing we borrow tool from system identification to capture the essence of dynamic texture we do so by learning i e identifying model that are optimal in the sense of maximum likelihood or minimum prediction error variance for the special case of second order stationary process we identify the model in closed form once learned a model ha predictive power and can be used for extrapolating synthetic sequence to infinite length with negligible computational cost we present experimental evidence that within our framework even low dimensional model can capture very complex visual phenomenon 
in a number of discipline directional data provides a fundamental source of information a novel framework for isotropic and anisotropic diffusion of direction is presented in this paper the framework can be applied both to regularize directional data and to obtain multi scale representation of it the basic idea is to apply and extend result from the theory of harmonic map in liquid crystal this theory deal with the regularization of vectorial data while satisfying the unit norm constraint of directional data we show the corresponding variational and partial differential equation formulation for isotropic diffusion obtained from an l norm and edge preserving diffusion obtained from an l norm in contrast with previous approach the framework is valid for direction in any dimension support non smooth data and give both isotropic and anisotropic formulation we present a number of theoretical result open question and example for gradient vector optical flow and color image 
the notion of a virtual sensor for optimal d reconstruction is introduced instead of planar perspective image that collect many ray at a fixed viewpoint omnivergent camera collect a small number of ray at many different viewpoint the resulting d manifold of ray are arranged into two multiple perspective image for stereo reconstruction we call such image omnivergent image and the process of reconstructing the scene from such image omnivergent stereo this procedure is shown to produce d scene model with minimal reconstruction error due to the fact that for any point in the d scene two ray with maximum vergence angle can be found in the omnivergent image furthermore omnivergent image are shown to have horizontal epipolar line enabling the application of traditional stereo matching algorithm without modification three type of omnivergent virtual sensor are presented spherical omnivergent camera center strip camera and dual strip camera 
we present a novel approach to measuring similarity between shape and exploit it for object recognition in our framework the measurement of similarity is preceded by solving for correspondence between point on the two shape using the correspondence to estimate an aligning transform in order to solve the correspondence problem we attach a descriptor the shape context to each point the shape context at a reference point capture the distribution of the remaining point relative to it thus offering a globally discriminative characterization corresponding point on two similar shape will have similar shape context enabling u to solve for correspondence a an optimal assignment problem given the point correspondence we estimate the transformation that best aligns the two shape regularized thin plate spline provide a fle xible class of transformation map for this purpose dissimilarity between two shape is computed a a sum of matching error between correspondingpoints together with a term measuring the magnitude of the aligning transform we treat recognition in a nearest neighbor classification framework result are presented for silhouette trademark handwritten digit and the coil dataset 
the mapping between d body pose and d shadow is fundamentally many to many and defeat regression method even with windowed context we show how to learn a function between path in the two system resolving ambiguity by integrating information over the entire length of a sequence the basis of this function is a configurable and dynamical manifold that summarizes the target system s behavior this manifold can be modeled from data with a hidden markov model having special topological property that we obtain via entropy minimization inference is then a matter of solving for the geodesic on the manifold that best explains the evidence in the cue sequence we give a closed form maximum a posteriori solution for geodesic through the learned density space thereby obtaining optimal path over the dynamical manifold these method give a completely general way to perform inference over time series in vision they support analysis recognition classification and synthesis of behavior in linear time we demonstrate with a prototype that infers d from monocular monochromatic sequence e g back subtraction without using any articulatory body model the framework readily accommodates multiple camera and other source of evidence such a optical flow or feature tracking 
the shape of an object may be estimated by observing the shadow on it surface we present a method that is robust with respect to a conservative classification of shadow region assuming that a conservative estimate of the object shape is available we analyze image of the object illuminated with known point light source taken from known camera location we adjust our surface estimate using the shadow region to produce a refinement that is still a conservative estimate a proof of correctness is provided no assumption about the object topology are made although any tangent plane discontinuity over the object s surface are supposed to be detectable an implementation and some experimental result are presented 
we propose a bayesian framework for representing and recognizing local image motion in term of two primitive model translation and motion discontinuity motion discontinuity are represented using a non linear generative model that explicitly encodes the orientation of the boundary the velocity on either side the motion of the occluding edge over time and the appearance disappearance of pixel at the boundary we represent the posterior distribution over the model parameter given the image data using discrete sample this distribution is propagated over time using the condensation algorithm to efficiently represent such a high dimensional space we initialize sample using the response of a low level motion discontinuity detector 
intelligent scissors and intelligent paint are complemen tary interactive image segmentation tool that allow a user to quickly and accurately select object of interest this demonstration provides a mean for participant to experi ence the dynamic nature of these tool introduction 
many visual matching algorithm can be describedin term of the feature and the inter feature distanceor metric the most commonly used metric is thesum of squared difference ssd which is valid froma maximum likelihood perspective when the real noisedistribution is gaussian based on real noise distributionsmeasured from international test set we havefound experimentally that the gaussian noise distributionassumption is often invalid this implies thatother metric which have 
variation in illumination can have a dramatic effect on the appearance of an object in an image in this paper we propose how to deal with illumination variation in eigenspace method we demonstrate that the eigenimages obtained by a training set under a single illumination condition ambient light can be used for recognition of object taken under different illumination condition the major idea is to incorporate a set of gradient based lter bank into the eigenspace recognition framework this can be achieved since the eigenimage coeficients are invariant for linearly ltered image input and eigenimages to achieve further illumination insensitivity we devised a robust procedure for coeficient recovery the proposed approach ha been extensively evaluated on a set of image and the result were compared to other approach 
abstract a framework is developed for the design and analysis of single viewpoint catadioptric camera that use two or more mirror the use of multiple mirror permit folding of the optic which lead to more compact camera design than one that use a single mirror a dictionary of camera design that use two conic mirror is presented we show that any folded system that us conic mirror ha a geo metrically equivalent system that us a single conic mir ror this result make it easy to determine the scene to image mapping of a conic folded system in addition we discus the optical benefit of using folded system a an example we choose a camera design from our dictio nary and optimize it parameter via optical simulation this design is used to construct a compact video camera that provides a hemispherical field of view 
factorization using singular value decomposition svd is often used for recovering d shape and motion from feature correspondence across multiple view svd is powerful at finding the global solution to the associated least square error minimization problem however this is the correct error to minimize only when the x and y positional error in the feature are uncorrelated and identically distributed but this is rarely the case in real data uncertainty in feature position depends on the underlying spatial intensity structure in the image which ha strong directionality to it hence the proper measure to minimize is covariance weighted squared error or the mahalanobis distance in this paper we describe a new approach to covariance weighted factorization which can factor noisy feature correspondence with high degree of directional uncertainty into structure and motion our approach is based on transforming the raw data into a covariance weighted data space where the component of noise in the different direction are uncorrelated and identically distributed applying svd to the transformed data now minimizes a meaningful objective function we empirically show that our new algorithm give good result for varying degree of directional uncertainty in particular we show that unlike other svd based factorization algorithm our method doe not degrade with increase in directionality of uncertainty even in the extreme when only normal flow data is available it thus provides a unified approach for treating corner like point together with point along linear structure in the image 
in this paper we present a novel approach to robust skeleton extraction we use undirected graph to model connectivity of the skeleton point the graph topology remains unchanged throughout the skeleton computation which greatly reduces sensitivity of the skeleton to noise in the shape outline furthermore this representation naturally defines an ordering of the point along the skeleton the process of skeleton extraction can be formulated a energy minimization in this framework we provide an iterative snake like algorithm for the skeleton estimation using distance transform fixed topology skeleton are useful if the global shape of the object is known ahead of time such a for people silhouette hand outline medical structure image of letter and digit small change in the object outline should be either ignored or detected and analyzed but they do not change the general structure of the underlying skeleton example application include tracking object recognition and shape analysis 
we have assembled a standalone movable system that can capture long sequence of omnidirectional image up to image at hz and a resolution of the goal of this system is to reconstruct complex large environment such a an entire floor of a building from the captured image only in this paper we address the important issue of how to calibrate such a system our method us image of the environment to calibrate the camera without the use of any special calibration pattern knowledge of camera motion or knowledge of scene geometry it us the consistency of pairwise tracked point feature across a sequence based on the characteristic of catadioptric imaging we also show how the projection equation for this catadioptric camera can be formulated to be equivalent to that of a typical rectilinear perspective camera with just a simple transformation 
catadioptric system are realization of omnidirectional vision through mirror lens combination design preserving the uniqueness of an effective viewpoint have recently gained attraction we present here a novel approach for estimating the intrinsic parameter of a well known catadioptric system consisting of a paraboloid mirror and an orthographic lens we introduce the geometry of catadioptric line projection and we show that the vanishing point lie on a conic section which encodes the entire calibration information projection of two set of parallel line suffice for intrinsic calibration from one view a well a for metric rectification of a plane our approach overcomes limitation of existing manual calibration method and wa successfully tested on the task of back warping real image image onto virtual plane 
in this work a new approach to fully automatic color image segmentation called jseg is presented first color in the image are quantized to several representing class that can be used to differentiate region in the image then image pixel color are replaced by their corresponding color class label thus forming a class map of the image a criterion for good segmentation using this class map is proposed applying the criterion to local window in the class map result in the j image in which high and low value correspond to possible region boundary and region center respectively a region growing method is then used to segment the image based on the multi scale j image experiment show that jseg provides good segmentation result on a variety of image 
we introduce a finite difference expansion for closely space d camera in projective vision and use it to derive differential analogue of the finite displacement projective matching tensor and constraint the result are simpler more general and easier t o use than astrom heyden s time derivative based continuous time matching constraint we suggest how to use the formalism f or tensor tracking propagation of matching relation agai nst a fixed base image along an image sequence we relate this to non linear tensor estimator and show how unwrapping the optimization loop along the sequence allows simple linear point update estimate to converge rapidly to statistically near optim al nearconsistent tensor estimate a the sequence proceeds we also give guideline a to when difference expansion is likely to be worthwhile a compared to a discrete approach 
we present a method for the recognition of walking people in monocular image sequence based on the extraction of coordinate of specific point location on the body the method work by a comparison of sequence of recorded coordinate with a library of sequence from different individual the comparison is based on the evaluation of view invariant and calibration independent view consistency constraint these constraint are function of corresponding image coordinate in two view and are satisfied whenever the two view are projected from the same three dimensional d object by evaluating the view consistency constraint for each pair of frame in a sequence of a walking person and a stored sequence we obtain a matrix of consistency value that ideally are zero whenever the pair of image depict the same d posture the method is virtually parameter free and computes a consistency residual between a pair of sequence that can be used a a distance for clustering and classification using interactively extracted data we present experimental result that are superior to those of previously published algorithm both in term of performance and generality key word structure from motion calibration object recognition 
a simple algorithm is described that computes the radiometric response function of an imaging system from image of an arbitrary scene taken using different exposure the exposure is varied by changing either the aperture setting or the shutter speed the algorithm doe not require precise estimate of the exposure used rough estimate of the ratio of the exposure e g fnumber setting on an inexpensive lens are sufficient for accurate recovery of the response function a well a the actual exposure ratio the computed response function is used to fuse the multiple image into a single high dynamic range radiance image robustness is tested using a variety of scene and camera a well a noisy synthetic image generated using randomly selected response curve automatic rejection of image area that have large vignetting effect or temporal scene variation make the algorithm applicable to not just photographic but also video camera code for the algorithm and several result are publicly available at http www c columbia edu cave 
extending a dierential total least square method for range flow estimation we present an iterative regularisation approach to compute dense range flow field we demonstrate how this algorithm can be used to detect motion discontinuity this can can be used to segment the data into independently moving region the dierent type of aperture problem encountered are discussed our regularisation scheme then take the various type of flow vector and combine them into a smooth flow field within the previously segmented region a quantitative performance analysis is presented on both synthetic and real data the proposed algorithm is also applied to range data from castor oil plant obtained with the biris laser range sensor to study the d motion of plant leaf 
we describe how d affine measurement may be computed from a single perspective view of a scene given only minimal geometric information determined from the image this minimal information is typically the vanishing line of a reference plane and a vanishing point for a direction not parallel to the plane it is shown that affine scene structure may then be determined from the image without knowledge of the camera s internal calibration e g focal length nor of the explicit relation between camera and world pose in particular we show how to i compute the distance between plane parallel to the reference plane up to a common scale factor semi ii compute area and length ratio on any plane parallel to the reference plane semi iii determine the camera s location simple geometric derivation are given for these result we also develop an algebraic representation which unifies the three type of measurement and amongst other advantage permit a first order error propagation analysis to be performed associating an uncertainty with each measurement we demonstrate the technique for a variety of application including height measurement in forensic image and d graphical modelling from single image 
we develop a pairwise classification framework for face recognition in which a c class face recognition problem is divided into a set of c c two class problem such a problem decomposition not only lead to a set of simpler classification problem to be solved thereby increasing overall classification accuracy but also provides a framework for independent feature selection for each pair of class a simple feature ranking strategy is used to select a small subset of the feature for each pair of class furthermore we evaluate two classification method under the pairwise comparison framework the bayes classifier and the adaboost experiment on a large face database with face image of individual indicate that feature are enough to achieve a relatively high recognition accuracy which demonstrates the effectiveness of the pairwise recognition framework 
we present a simple procedure for synthesising novel view using two or more basis image a input it is possible for the user to interactively adjust the viewpoint and for the corresponding image to be computed and rendered in real time rather than employing a d model our method is based on the linear relation which exist between image taken with an affine camera we show how the combination of view proposed by ullman and basri can be appropriately parameterised when a sequence of five or more image is available this is achieved by fitting polynomial model to the coefficient of the combination where the latter are function of the unknown camera parameter we discus an alternative approach direct image interpolation and argue that our method is preferable when there is a large difference in orientation between the original gaze direction we show the result of applying the parameterisation to a fixating camera using both simulated and real input our observation are relevant to several application including visualisation animation and low bandwidth communication 
the spatial distribution of gray level intensity in an image can be naturally modeled using markov random field mrf model we develop and investigate the performance of face detection algorithm derived from mrf consideration for enhanced detection the mrf model are defined for every permutation of site index in the image we find the optimal permutation that provides maximum discriminatory power to identify face from nonfaces the methodology presented here is a generalization of the face detection algorithm in where a most discriminating markov chain model wa used the mrf model successfully detect face in a number of test image in real time 
this article deal with optical law that must be considered when using underwater camera both theoretical and experimental point of view are described and it is shown that relationship between air and water calibration can be found 
this paper introduces a new probabilistic framework for space carving in this framework each voxel is assigned a probability which is computed by comparing the likelihood for the voxel existing and not existing this new framework avoids many of the difficulty associated with the original space carving algorithm specifically it doe not need a global threshold parameter and it guarantee that no hole will be carved in the model this paper also proposes that a voxel based thick texture is a realistic and efficient representation for scene which contain dominant plane the algorithm is tested using both real and synthetic data and both qualitative and quantitative result are presented 
this paper examines the problem of reconstructing a voxelized representation of d space from a series of image an iterative algorithm is used to find the scene model which jointly explains all the observed image by determining which region of space is responsible for each of the observation the current approach formulates the problem a one of optimization over estimate of these responsibility the process converges to a distribution of responsibility which accurately reflects the constraint provided by the observation the position and shape of both solid and transparent object and the uncertainty which remains reconstruction is robust and gracefully represents regio n of space in which there is little certainty about the exact structure due to limited non existent or contradicting d ata rendered image of voxel space recovered from synthetic and real observation image are shown 
the problem of establishing correspondence between image taken from different viewpoint is fundamental in computer vision we propose an algorithm which is capable of handling larger change in viewpoint than classical correlation based technique optimal performance for the algorithm is achieved for textured object which are locally planar in at least one direction the algorithm work by computing affinely invariant fourier feature from intensity profile in each image the intensity profile are extracted from the image data between randomly selected pair of image interest point using a voting scheme pair of interest point are matched across image by comparing vector of fourier feature outlier among the match are rejected in two stage a fast stage using novel view consistency constraint and a second slower stage using ransac and fundamental matrix computation in order to demonstrate the quality of the result the algorithm is tested on several different image pair 
this paper investigates the multiple view geometry of smooth surface and a plane where the plane provides a planar homography mapping between the view innovation are made in three area first new solution are given for the computation of epipolar and trifocal geometry for this type of scene in particular it is shown that the epipole may be determined from bitangents between the homography registered occluding contour and a new minimal solution is given for computing the trifocal tensor second algorithm are demonstrated for automatically estimating the fundamental matrix and trifocal tensor from image of such scene third a method is developed for estimating camera matrix for a sequence of image of these scene these three area are combined in a freehand scanner application where d texture mapped graphical model of smooth object are acquired directly from a video sequence of the object and plane 
this paper present a new approach to image based guidance of a needle or surgical tool during percutaneous procedure the method is based on visual servoing it requires no prior calibration or registration the technique provides highly precise d alignment of the tool with respect to an anatomic target by taking advantage of projective geometry and projective invariant this can be achieved in a fixed number of iteration in addition the approach estimate the required insertion depth experiment include automatic d alignment and insertion of a needle held by a medical robot into a pig kidney under x ray fluoroscopy 
this paper present an approach to object detection which is based on recent work in statistical model for texture synthesis and recognition heeger and bergen de bonet and viola zhu et al simoncelli and portilla our method follows the texture recognition work of de bonet and viola we use feature vector which capture the joint occurrence of local feature at multiple resolution the distribution of feature vector for a set of training image of an object class is estimated by clustering the data and then forming a mixture of gaussian model the mixture model is further refined by determining which cluster are the most discriminative for the class and retaining only those cluster after the model is learned test image are classified by computing the likelihood of their feature vector with respect to the model we present promising result in applying our technique to face detection and car detection 
we analyze the effect of perturbation on the estimation of depth from defocus dfd implemented by changing the focus setting e g axially moving the sensor the analysis yield the optimal change of focus setting and the spatial frequency for which estimation is most robust for stable estimation at all spatial frequency the change in focus setting should be le than twice the depth of field for the most robust estimation in the highest spatial frequency the axial interval should be equal to the depth of field 
in many case self calibration is not able to yield a unique solution for the d reconstruction of a scene this is due to the occurrence of critical motion sequence if this is the case an ambiguity is left on the reconstruction in this paper it is derived under which condition correct novel view can be generated from ambiguous reconstruction the problem is r st approached from a theoretical point of view it is proven that novel view are correct a long a the inclusion of the new view in the sequence yield the same ambiguity on the reconstruction the problem is therefore much related to the problem of critical motion sequence since the virtual camera can be arbitrarily moved within the smallest critical motion set that contains the recovered camera motion without distortion becoming visible based on these result a practical measure for the expected ambiguity on a novel view based on the recovered structure and motion is derived a an application a viewer wa built that indicates if a specic novel view can be trusted or not by changing the background color 
a bayesian framework for deformable pattern classification wa proposed by k w cheung et al with promising result for isolated handwritten character recognition it performance however degrades significantly when it is applied to detect deformable pattern in complex scene where the amount of outlier due to other neighboring object or the background is usually large also the fact that the associated evidence measure doe not penalize model resting on white space result in a high false alarm rate another bayesian framework for deformable pattern detection is proposed the framework posse the intrinsic property of matching with only part of an image segmentation and it associated evidence measure can penalize white space implicitly however limited data exploration capability is the major trade off by properly combining the two framework a new matching algorithm called bidirectional matching is proposed this combined approach posse the advantage of the two framework and give robust result for non rigid shape extraction to evaluate the performance of the proposed approach we have applied it to shape based handwritten word retrieval using a subset of the bb dataset in the cedar database we can achieve a recall rate of and a precision rate of 
we study the recognition of surface made from different material such a concrete rug marble or leather on the basis of their textural appearance such natural texture arise from spatial variation of two surface attribute reflectance and surface normal in this paper we provide a unified model to address both these aspect of natural texture the main idea is to construct a vocabulary of prototype tiny surface patch with associated local geometric and photometric property we call these d textons example might be ridge groove spot or stripe or combination thereof associated with each texton is an appearance vector which characterizes the local irradiance distribution represented a a set of linear gaussian derivative filter output under different lighting and viewing condition given a large collection of image of different material a clustering approach is used to acquire a small on the order of d texton vocabulary given a few to image of any material it can be characterized using these textons we demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing condition 
point set obtained from computer vision technique are often noisy and non uniform we present a new method of surface reconstruction that can handle such data set using anisotropic basis function our reconstruction algorithm draw upon the work in variational implicit surface for constructing smooth and seamless d surface implicit function are often formulated a a sum of weighted basis function that are radially symmetric using radially symmetric basis function inherently assumes however that the surface to be reconstructed is everywhere locally symmetric such an assumption is true only at planar region and hence reconstruction using isotropic basis is insufficient to recover object that exhibit sharp feature we preserve sharp feature using anisotropic basis that allow the surface to vary locally the reconstructed surface is sharper along edge and at corner point we determine the direction of anisotropy at a point by performing principal component analysis of the data point in a small neighborhood the resulting field of principle direction across the surface is smoothed through tensor filtering we have applied the anisotropic basis function to reconstruct surface from noisy synthetic d data and from real range data obtained from space carving 
in this paper we present a novel approach to estimateand analyze d fluid structure and motion ofclouds from multi spectrum d cloud image sequence accurate cloud top structure and motion are very importantfor a host of meteorological and climate application however due to the extremely complex natureof cloud fluid motion classical nonrigid motion analysismethods will be insufficient to solve this particularproblem in this paper two spectrum of satellite cloudimages are utilized 
this paper present an algorithm that match interest point detected on a pair of grey level image taken from arbitrary point of view first matching hypothesis are generated using a similarity measure of the interest point hypothesis are confirmed using local group of interest paint group match are based on a measure defined on an affine transformation estimate and on a correlation coefficient computed on the intensity of the interest point once a reliable match ha been determined for a given interest point and the corresponding local group new group match are found by propagating the estimated affine transformation the algorithm ha been widely tested under various image transformation it provides dense match and is very robust to outlier i e interest point generated by noise or present in only one image because of occlusion or non overlap 
a family of axially symmetric mirror shape are proposed for panoramic imaging these shapeskeep the resolution in the image invariant to change in elevation in the scene in other word this family of shape achievessolid angle pixel density invariance an analysis of range finding using two coaxial axially symmetric resolution invariant mirror in a coaxial pair is presented the resolution invariance property of these mirror mean that when the image captured is unwarped the resultant image will not suffer from variable image quality this problem is present in unwarped image captured with any mirror shape not designed for resolution invariance the resolution invariance of these mirror is especially important in the case of stereo panoramic mirror where one view of the scene is captured within the other and thus will have lower resolution it is necessary to clearly identify two view of an object to undertake range finding the proposed mirror shape will be useful for mobile robotics and machine vision other application area such a visual sensing for control of traffic light at street intersection could be considered 
a method for upgrading a projective reconstruction to metric is presented the reconstruction is first transformed by considering cheirality so that the convex hull of the set of camera projection centre is the same a in the metric counterpart the method then proceeds iteratively and starting from such a reconstruction is a necessary condition for many iterative calibration algorithm to converge the result show that in practice it is also most often sufficient provided that the minimised objective function is a geometrically meaningful quantity the method ha been found extremely reliable for both large and small reconstruction in a large number of experiment on real data when subjected to the common degeneracy of little or no rotation between the view the method still yield a very reasonable member of the family of possible solution furthermore the method is very fast and therefore suitable for the purpose of viewing reconstruction 
face image are subject to change in view and illumination such change cause data distribution to be highly nonlinear and complex in the image space it is desirable to learn a nonlinear mapping from the image space to a low dimensional space such that the distribution becomes simpler tighter and therefore more predictable for better modeling of face in this paper we present a kernel machine based approach for learning such nonlinear mapping the aim is to provide an effective view based representation for multiview face detection and pose estimation assuming that the view is partitioned into a number of distinct range one nonlinear view subspace is learned for each range of view from a set of example face image of that view range by using kernel principal component analysis kpca projection of the data onto the view subspace are then computed a view based nonlinear feature multi view face detection and pose estimation are performed by classifying a face into one of the facial view or into the nonface class by using a multi class kernel support vector classifier ksvc experimental result show that fusion of evidence from multiviews can produce better result than using the result from a single view and that our approach yield high detection and low false alarm rate in face detection and good accuracy in pose estimation in comparison with the linear counterpart composed of linear principal component analysis pca feature extraction and fisher linear discriminant based classification fldc 
abstract data we o er a simple paradigm for tting mod we o er a simple paradigm for tting parametric el parametric and non parametric to noisy data model which solves these two problem this is which resolve some of the problem associated with done by considering each point on the parametric classic mse algorithm this is done by consider model a a possible source for each data point the ing each point on the model a a possible source for model is also extended to non parametric model each data point and give good result even for curve with strong the paradigm also allows to solve problem which discontinuity are not de ned in the classical mse approach such we show result of the method for line seg a tting a segment a opposed to a line it is ments circle and general curve we also show shown to be non biased and to achieve excellent result using gaussian and uniform noise model result for general curve even in the presence of strong discontinuity previous work result are shown for a number of tting prob lem including line circle segment and gen there are many paper written on using least eral curve contaminated by gaussian and uniform square technique in order to t parameter to a noise noisy model and on using di erent numerical tech niques and linear approximation in order to do the 
for motion picture special effect it is often necessary to take a source image of an actor segment the actor from the unwanted background and then composite over a new background the standard approach requires the unwanted background to be a blue screen while this technique is capable of handling area where the foreground blend into the background the physical requirement present many practical problem this paper present an algorithm that requires minimal human interaction to segment motion picture resolution image and image sequence we show that it can be used not only to segment badly lit or noisy bluescreen image but also to segment actor where the background is more varied 
we treat the problem of edge detection a one of statistical inference local edge cue implemented by lters provide information about the likely position of edge which can be used a input to higher level model dieren t edge cue can be evaluated by the statistical eectiv ene of their corresponding lters evaluated on a dataset of pre segmented image we use information theoretic measure to determine the eectiv ene of a variety of dieren t edge detector working at multiple scale on black and white and colour image our result give quantative measure for the advantage of multi level processing for the use of chromaticity in addition to greyscale and for the relative eectiv ene of dieren t detector proceeding computer vision and pattern recognition cvpr fort collins colorado 
we study the low level problem of predicting pixel intensity after subpixel image translation this is a basic subroutine for image warping and super resolution and it ha a critical influence on the accuracy of subpixel matching by image correlation rather than using traditional frequency space filtering theory or ad hoc interpolators such a spline we take an empirical approach finding optimal subpixel interpolation filter by direct numerical optimization over a large set of training example the training set is generated by subsampling larger image at different translation using subsamplers that mimic the spatial response function of real pixel we argue that this give realistic result and design filter of various different parametric form under traditional and robust prediction error metric we systematically study the performance of the resulting filter paying particular attention to the influence of the underlying image sampling regime and the effect of aliasing jaggies we summarize the result and give practical advice for obtaining subpixel accuracy 
conventional vision system and algorithm assume the camera to have a single viewpoint however sensor need not always maintain a single viewpoint for instance an incorrectly aligned system could cause non single viewpoint also system could be designed to specifically deviate from a single viewpoint to trade off image characteristic such a resolution and field of view in these case the locus of viewpoint form what is called a caustic in this paper we present an in depth analysis of caustic of catadioptric camera with conic reflector property of caustic with respect to field of view and resolution are presented finally we present way to calibrate conic catadioptric system and estimate their caustic from known camera motion 
in proc of ieee int l conf on computer vision vancouver canada vision based motion capturing of hand articulation is a challenging task since the hand present a motion of high degree of freedom model based approach could be taken to approach this problem by searching in a high dimensional hand state space and matching projection of a hand model and image observation however it is highly inefficient due to the curse of dimensionality fortunately natural hand articulation is highly constrained which largely reduces the dimensionality of hand state space this paper present a model based method to capture hand articulation by learning hand natural constraint our study show that natural hand articulation lie in a lower dimensional configuration space characterized by a union of linear manifold spanned by a set of basis configuration by integrating hand motion constraint an efficient articulated motion capturing algorithm is proposed based on sequential monte carlo technique our experiment show that this algorithm is robust and accurate for tracking natural hand movement this algorithm is easy to extend to other articulated motion capturing task 
the image point in two image satisfy epipolar constraint however not all set of point satisfying epipolar constra int correspond to any real geometry because there can exist no camera and scene point projecting to given image point such that all image point have positive depth using the cheirality theory due to hartley and previous work on oriented projective geometry we give necessary and sufficient condition for an image point set to correspond to any real geometry for image from conventional camera this condition is simple and given in term of epipolar line and epipoles surprisingly this is not sufficient for central panoramic camera apart from giving the insight to epipolar geometry among the application are reducing the search space and ruling out impossible match in stereo and ruling out impossible solution for a fundamental matrix computed from seven point 
statistic based colour constancy algorithm work well aslong a there are many colour in a scene they fail however when theencountering scene comprise few surface in contrast physic basedalgorithms based on an understanding of physical process such ashighlights and interreflection are theoretically able to solve for colourconstancy even when there are a few a two surface in a scene unfortunately physic based theory rarely work outside the lab in thispaper we 
this paper describes an algorithm for finding face within an image the basis of the algorithm is to run an observation window at all possible position scale and orientation within the image a non linear support vector machine is used to determine whether or not a face is contained within the observation window the non linear support vector machine operates by comparing the input patch to a set of support vector which can be thought of a face and anti face template each support vector is scored by some nonlinear function against the observation window and if the resulting sum is over some threshold a face is indicated because of the huge search space that is considered it is imperative to investigate way to speed up the support vector machine within this paper we suggest a method of speeding up the non linear support vector machine a set of reduced set vector rv s are calculated from the support vector by considering the rv s sequentially and if at any point a face is deemed too unlikely to cease the sequential evaluation obviating the need to evaluate the remaining rv s the idea being that we only need to apply a subset of the rv s to eliminate thing that are obviously not a face thus reducing the computation the key then is to explore the rv s in the right order and a method for this is proposed 
the medial surface of a volumetric object is of signicant interest for shape analysis however it numerical computation can be subtle method based on voronoi technique preserve the object s topology but heuristic pruning measure are introduced to remove unwanted face approach based on euclidean distance function can localize medial surface point accurately but often at the cost of altering the object s topology in this paper we introduce a new algorithm for computing medial surface which address these concern the method is robust and accurate ha low computational complexity and preserve topology the key idea is to measure the net outward flux of a vector eld per unit volume and to detect location where a conservation of energy principle is violated this is done in conjunction with a thinning process applied in a cubic lattice we illustrate the approach with example of medial surface of synthetic object and complex anatomical structure obtained from medical image 
the task of multi camera surveillance is to reconstruct the path taken by all moving object that are temporarily visible from multiple non overlapping camera we present a bayesian formalization of this task where the optimal solution is the set of object path with the highest posterior probability given the observed data we show how to eciently approximate the maximum a posteriori solution by linear programming and present initial experimental result multi camera surveillance 
capturing surface appearance is important for a large number of application appearance of real world surface is difcult to model a it varies with the direction of illumination a well a the direction from which it is viewed consequently measurement of thebrdf bidirectional reectance distribution function have been important in addition many application require measuring how the entire surface reects light i e spatially varying brdf measurement are important a well for compactness we refer to a spatially varying brdf a a btf bidirectional texture function measurement of brdf and or btf typically require signicant resource in time and equipment in this work a device for brdf btf measurement is presented that is compact economical and convenient the device us the approach of curved mirror to remove the need for hemispherical positioning of the camera and illumination source instead simple planar translation of optical component are used to vary the illumination direction and to scan the surface furthermore the measurement process is fast because the device enables simultaneous measurement of multiple viewing direction 
active appearance model aams have been shown to be useful for interpreting image of deformable object here we place the aam matching algorithm in a statistical framework allowing extra constraint to be applied this enables the model to be combined with other method of object location we demonstrate how user interaction can be used to guide the search and give result of experiment showing the effect of constraint on the performance of model matching 
we formulate structure from motion a a bayesian inference problem and use a markov chain monte carlo sampler to sample the posterior on this problem this result in a method that can identify both small and large tracker error and yield reconstruction that are stable in the presence of these error furthermore the method give detailed information on the range of ambiguity in structure given a particular dataset and requires no special geometric formulation to cope with degenerate situation motion segmentation is obtained by a layer of discrete variable associating a point with an object we demonstrate a sampler that successfully sample an approximation to the marginal on this domain producing a relatively unambiguous segmentation 
image rectification is the process of warping a pair of stereo image in order to align the epipolar line with the scan line of the image once a pair of image is rectified stereo matching can be implemented in an efficient manner given the epipolar geometry it is straightforward to define a rectifying transformation however many transformation will lead to unwanted image distortion in this paper we present a novel method for stereo rectification that determines the transformation that minimizes the effect of resampling that can impede stereo matching the effect we seek to minimize are the loss of pixel due to under sampling and the creation of new pixel due to over sampling to minimize these effect we parameterize the family of rectification transformation and solve for the one that minimizes the change in local area integrated over the area of the image 
in the perception of gait timing is everything specifically the relative timing of the individual motion in a gait and when event occur periodically a they do in a gait then relative timing is equivalent to phase the importance of phase in gait appears in the medical psychology and computer vision literature the video phase locked loop vpll is a novel system that perceives gait is sensitive to the phase of the component motion of the gait and is model free vplls provide a mechanism to perform two critical task in gait perception frequency entrainment and phase locking a vpll can lock on oscillation in pixel that arise because of oscillatory motion in doing so the vpll match it internal oscillator to the oscillation in pixel intensity thus performing frequency entrainment phase locking occurs a individual phased locked loop at each pixel site lock simultaneously the abundance of data extracted by the vpll make gait recognition possible in this demonstration we show a vpll operating in realtime the vpll lock to oscillation in the gait of a person walking on a treadmill and also detects translational motion a the vpll system extract phase information in the form of a phasor configuration the configuration is also displayed in real time best provides an excellent introduction to phaselocked loop their application to vplls is found in boyd figure a show a superimposed frame an image sequence of an oscillatory motion a person walking on a treadmill the vpll process the sequence locking on the oscillation figure b show the result a the magnitude of the oscillation a determined by the vpll while we have chosen to display the magnitude signal the vpll also capture frequency and phase information there is ample information derived by a vpll to recognize various oscillatory motion we use procrustes shape analysis to perform recognition related task such a averaging and matching the phase pattern that emerge from the vpll our demonstration includes a real time display of the captured phase pattern the variation in phase that arise from different motion is evident a the phase config a 
abstract this paper oers a novel detection method which work well even in the case of a complicated image collection for instance a frontal face under a large class of linear transformation it wa also successfully applied to detect d object under dierent view call the class of image which should be detected a multi template the detection problem is solved by sequentially applying very simple lters or detector which are designed to yield small result on the multi template hence anti face and large result on random natural image this is achieved by making use of a simple probabilistic assumption on the distribution of natural image which is borne out well in practice and by using a simple implicit representation of the multi template only image which passed the threshold test imposed by the rst detector are examined by the second detector etc the detector have the added bonus that they act independently so that their false alarm are uncorrelated this result in a percentage of false alarm which exponentially decrease in the number of detector this in turn lead to a very fast detection algorithm usually requiring n operation to classify an n pixel image where also the algorithm requires no training loop the suggested algorithm s performance favorably compare to the wellknown eigenface and support vector machine based algorithm and it is substantially faster d vernon ed eccv lncs pp 
this paper introduces a new mult iview reconstruction problem called approximate n view stereo the goal of this problem is to recover a one parameter family of volume that are increasingly tighter supersets of an unknown arbitrarily shaped d scene by studying d shape that reproduce the input photograph up to a special image transformation called a shuffle transformation we prove that these shape can be organized hierarchically into nested supersets of the scene and they can be computed using a simple algorithm called approximate space carving that is provably correct for arbitrary discrete scene i e for unknown arbitrarily shaped lambertian scene that are defined by a finite set of voxels and are viewed from n arbitrarily distributed viewpoint inside or around them the approach is specifically designed to attack practical reconstruction problem including recovering shape from image with inaccurate calibration information and building coarse scene model from multiple view 
abstract this paper ha been prompted by observation of some anomaly in the performance of the standard imaging model pin hole thin lens and gaussian thick lens in the context of composing omnifocus image and estimating depth map from a sequence of image a closer examination of the model revealed that they a sume a position of the aperture that con icts with the design of many available lens we have shown in this paper that the imaging geometry and photometric property of an image are signi cantly in uenced by the position of the aperture this is con rmed by the discrepancy between observed mapping and those pre dicted by the model we have therefore concluded that the current imaging model do not adequately represent practical imaging system we have proposed a new imaging model which overcomes these de ciencies and have given the associated mapping the impact of this model on some common imaging scenario is described along with experimental veri cation of the better perfor mance of the model on three real lens 
in image matching application such a tracking and stereo matching it is common to use the sum of squareddiflerences ssd measure to determine the best match for an image template however this measure is sensitive to outlier and is not robust to template variation we describe a robust measure and eficient search strategy for template matching with a binary or greyscale template using a maximum likelihood formulation in addition to subpixel localization and uncertainty estimation these technique allow optimal feature selection based on minimizing the localization uncertainty we examine the use of these technique for object recognition stereo matching feature selection and tracking 
this paper present the measurement of object reflectance from color image we exploit the gaussian scalespace paradigm to define a framework for the robust measurement of object reflectance from color image illumination and geometrical invariant property are derived from a physical reflectance model based on the kubelka munk theory imaging condition are assumed to be white illumination and matte dull object or general object respective ly summarized by shadow highlight illumination intensity illumination color 
despite the wide application of bilinear problem to problem both in computer vision and in other field their behaviour under the effect of noise is still poorly understood in this paper we show analytically that marginal distribution on the solution component of a bilinear problem can be bimodal even with gaussian measurement error we demonstrate and compare three different method of estimating the covariance of a solution we show that the hessian at the mode substantially underestimate covariance many problem in computer vision can be posed a bilinear problem i e one must find a solution to a set of equation of the form ck ij gijkaibj 
in this paper a robust pattern recognition system using an appearance based representation of colour image is described standard appearance based approach are not robust to outlier occlusion or segmentation error the approach proposed here relies on robust m estimator involving non quadratic and possibly non convex energy function to deal with the minimisation of non convex function in a deterministic framework we introduce an estimation scheme relying on m estimator used in continuation from convex function to hard redescending nonconvex estimator at each step of the robust estimation scheme the non quadratic criterion is minimized using the half quadratic theory this lead to a weighted least square algorithm which is easy to implement the proposed robust estimation scheme doe not require any user interaction because all necessary parameter are previously estimated the method is illustrated on a road sign recognition application experiment show significant improvement with respect to standard estimation scheme 
evidence from neurophysiological and psychological study is coming together to shed light on how we represent and recognize object this review describes evidence supporting two major hypothesis the first is that object are represented in a mosaic like form in which object are encoded by combination of complex reusable feature rather than two dimensional template or three dimensional model the second hypothesis is that transform invariant representation of object are learnt through experience and that this learning is affected by the temporal sequence in which different view of the object are seen a well a by their physical appearance 
a learning account for the problem of object recognitionis developed within the pac probably approximatelycorrect model of learnability the proposedapproach make no assumption on the distribution ofthe observed object but quanties success relative toits past experience most importantly the success oflearning an object representation is naturally tied tothe ability to represent it a a function of some intermediaterepresentations extracted from the image we evaluate this 
in this paper we present our project for realizing virtualized reality in a large scale space such a a soccer stadium concert hall etc we have developed an extended system of cmu d room in an efficient way so that d digitization of a large scale space can practically realized we place progressive scan camera around a large space e g m m with m height the video from those camera are digitized into pc that are connectedvia ethernet a camera calibration technique for a large scale space that is accurate enoughto apply cv based algorithm is developed we also present a method to omit the calibration process with an idea of projective grid space the recent result and future work are presented for demonstrating the significance of the project a a cv based practical application 
we describe a learning based method for low level vision problem estimating scene from image we generate a synthetic world of scene and their corresponding rendered image modeling their relationship with a markov network bayesian belief propagation allows u to efficiently find a local maximum of the posterior probability for the scene given an image we call this approach vista vision by image scene training we apply vista to the super resolution problem estimating high frequency detail from a low resolution image showing good result to illustrate the potential breadth of the technique we also apply it in two other problem domain both simplified we learn to distinguish shading from reflectance variation in a single image under particular lighting condition for the motion estimation problem in a blob world we show figure ground discrimination solution of the aperture problem and filling in arising from application of the same probabilistic machinery 
the image irradiance of a three dimensional object is known to be the function of three component the distribution of light source the shape and reflectance of a real object surface in the past recovering the shape and reflectance of an object surface from the recorded image brightness ha been intensively investigated on the other hand there ha been little progress in recovering illumination from the knowledge of the shape and reflectance of a real object in this paper we propose a new method for estimating the illumination distribution of a real scene from image brightness observed on a real object surface in that scene more specifically we recover the illumination distribution of the scene from a radiance distribution inside shadow cast by an object of known shape onto another object surface of known shape and reflectance by using the occlusion information of incoming light we are able to reliably estimate the illumination distribution of a real scene even in a complex illumination environment 
given a set of d point that we know lie on thesurface of an object we can define many possible surfacesthat pas through all of these point even whenwe consider only surface triangulation there are stillan exponential number of valid triangulation that allfit the data each triangulation will produce a differentfaceted surface connecting the point our goal is to overcome this ambiguity and find theparticular surface that is closest to the true object surface we do not know 
digital watermark have been proposed a a methodfor discouraging illicit copying and distribution ofcopyrighted material and to create secure digital imagelibraries by adding to image copyright and userrightinformation using a robust digital watermark todetect and trace copyright violation ha therefore lotof interest this paper describes an approach to embeddinga digital watermark using the fourier transform the paper also address the difficult problemof oblivious watermark 
a new fully automated shape learning method is presented it is based on clustering a set of trainingshapes in the original shape space defined by the coordinate of the contour point and performinga procrustes analysis on each cluster to obtain cluster prototype average object and statisticalinformation about intra cluster shape variation the main difference from previously reported methodsis that the training set is first automatically clustered and those shape considered to be 
several geometric active contour model have been proposed for segmentation in computer vision and image analysis the essential idea is to evolve a curve in d or a surface in d under constraint from image force so that it cling to feature of interest in an intensity image recent variation on this theme take into account property of enclosed region and allow for multiple curve or surface to be simultaneously represented however it is still unclear how to apply these technique to image of narrow elongated structure such a blood vessel where intensity contrast may be low and reliable region statistic cannot be computed to address this problem we derive the gradient flow which maximize the rate of increase of flux of an appropriate vector field through a curve in d or a surface in d the key idea is to exploit the direction of the vector field along with it magnitude the calculation lead to a simple and elegant interpretation which is essentially parameter free and ha the same form in both dimension we illustrate it advantage with several level set based segmentation of d and d angiography image of blood vessel 
abstract we introduce a fast multiscale algorithm for image segmentation our algorithm us modern numeric technique to nd an approximate solution to normal ized cut measure in time that is linear in the size of the image with only a few dozen operation per pixel in just one pas the algorithm provides a complete hi erarchical decomposition of the image into segment the algorithm detects the segment by applying a pro ce of recursive coarsening in which the same mini mization problem is represented with fewer and fewer variable producing an irregular pyramid during this coarsening process we may compute additional inter nal statistic of the emerging segment and use these statistic to facilitate the segmentation process once the pyramid is completed it is scanned from the top down to associate pixel close to the boundary of seg ments with the appropriate segment the algorithm is inspired by algebraic multigrid amg solver of min imization problem of heat or electric network we demonstrate the algorithm by applying it to real im age 
we show how to use a sampling method to find sparsely clad people in static image people are modeled a an assembly of nine cylindrical segment segment are found using an em algorithm and then assembled into hypothesis incrementally using a learned likelihood model each assembly step pass on a set of sample of it likelihood to the next this yield effective pruning of the space of hypothesis the collection of available nine segment hypothesis is then represented by a set of equivalence class which yield an efficient pruning process the posterior for the number of people is obtained from the class representative people are counted quite accurately in image of real scene using an map estimate we show the method allows top down a well a bottom up reasoning while the method can be overwhelmed by very large number of segment we show that this problem can be avoided by quite simple pruning step 
current vision system are designed to perform in clear weather needle to say in any outdoor application there is no escape from bad weather ultimately computer vision system must include mechanism that enable them to function even if somewhat le reliably in the presence of haze fog rain hail and snow we begin by studying the visual manifestation of different weather condition for this we draw on what is already known about atmospheric optic next we identify effect caused by bad weather that can be turned to our advantage since the atmosphere modulates the information carried from a scene point to the observer it can be viewed a a mechanism of visual information coding based on this observation we develop model and method for recovering pertinent scene property such a threedimensional structure from image taken under poor weather condition 
we consider the interaction between edge and intensity distribution in semi open image neighborhood surrounding them locally this amount to a kind of figure ground problem and we analyze the case of smooth figure occluding arbitrary background technique from differential topology permit a classification into what we call fold the side of an edge from a smooth object and cut the arbitrary background intuitively cut arise when an arbitrary scene is cut from view by an occluder the condition take the form of transversality between an edge tangent map and a shading flow field and example are included 
we describe a new system for estimating road shape ahead of a vehicle for the purpose of driver assistance the method utilises a single on board colour camera together with inertial and velocity information to estimate both the position of the host car with respect to the lane it is following and also the width and curvature of the lane ahead at distance of up to metre the system s image processing extract a variety of different style of lane marking from road imagery and is able to compensate for a range of lighting condition road shape and car position are estimated using a particle filter the system which run at frame per second ha been applied with some success to several hour worth of data captured from highway under varying imaging condition any of the target detected by the radar system present an obstacle to the vehicle s motion and to alert the driver if such condition arise in this paper we present a vision algorithm which is able to estimate the vehicle s position bearing and lateral offset with respect to the centre of it current highway lane together with the pitch of the camera and width of the lane the curvature and rate of change of curvature of the lane up to metre ahead is also estimated to coincide with the field of view of the radar obstacle detection system the system ha been demonstrated on several hour worth of data captured from the test vehicle and is found to perform stably in a range of road and weather condition we review related work below before giving detail of the algorithm and some example of it operation 
when an unknown object with lambertian reflectance is viewedorthographically there is an implicit ambiguity in determining it d structure we show that the object s visible surface f x y is indistinguishable from a generalized ba relief transformation of the object s geometry bar f x y equal f x y x y and a corresponding transformation on the object s albedo for each image of the object illuminated by an arbitrary number of distant light source there exists anidentical image of the transformed object illuminated by similarlytransformed light source this result hold both for theilluminated region of the object a well a those in cast andattached shadow furthermore neither small motion of the object nor of the viewer will resolve the ambiguity in determining theflattening or scaling of the object s surface implication of this ambiguity on structure recovery and shape representation are discussed 
the eikonal equation and variant of it are of significant interest for problem in computer vision and image processing it is the basis for continuous version of mathematical morphology stereo shape from shading and for recent dynamic theory of shape it numerical simulation can be delicate owing to the formation of singularity in the evolving front and is typically based on level set method however there are more classical approach rooted in hamiltonian physic which have received little consideration in computer vision in this paper we first introduce a new algorithm for simulating the eikonal equation which offer a number of computational and conceptual advantage over the earlier method when it come to shock tracking next we introduce a very efficient algorithm for shock detection where the key idea is to measure the net outward flux of a vector field per unit volume and to detect location where a conservation of energy principle is violated we illustrate the approach with several numerical example including skeleton of complex d and d shape 
we are developing a system to extract geodetic texturedcad model from thousand of initially uncontrolled close range ground and aerial image of urbanscenes here we describe one component of the system which operates after the imagery ha been controlledor geo referenced this fully automatic componentdetects significant vertical facade in the scene then extrudes them to meet an inferred triangulatedterrain and procedurally generated roof polygon thealgorithm then estimate for 
by representing image and image prototype by linear subspace spanned by tangent vector derivative of an image with respect to translation rotation etc impressive invariance to known type of uniform distortion can be built into feedforward discriminator we describe a new probability model that can jointly cluster data and learn mixture of nonuniform smooth deformation field our field are based on low frequency wavelet so they use very few parameter to model a wide range of smooth deformation unlike e g factor analysis which us a large number of parameter to model deformation in spirit our idea are most similar to the idea of separating content from style published by tenenbaum and freeman however our model do not need labeled data for training and thus allow for unsupervised separation of appearance from deformation we give result on handwritten digit recognition and face recognition 
the statistic of range image from natural environmentsis a largely unexplored field of research itclosely relates to the statistical modeling of the scenegeometry in natural environment and the modelingof optical natural image we have used a d laserrange finder to collect range image from mixed forestscenes the image are here analyzed with respect todifferent statistic 
a linear method for computing a projective reconstruction from a large number of image is presented and then evaluated the method us planar homographies between view to linearize the resecting of the camera constraint based on the fundamental matrix trifocal tensor or quadrifocal tensor are used to derive relationship between the position vector of all the camera at once the resulting set of equation are solved using a svd the algorithm is computationally efficient a it is linear in the number of matched point used a key feature of the algorithm is that all of the image are processed simultaneously a in the sturmtriggs factorization method but it differs in not requiring that all point be visible in all view an additional advantage is that it work with any mixture of line and point correspondence through the constraint these impose on the multilinear tensor experiment on both synthetic and real data confirm the method s utility 
we study the special form that the general multi image tensor formalism take under the plane parallax decomposition including matching tensor and constraint closure and depth recovery relation and inter tensor consistency constraint plane parallax alignment greatly simplifies the algebra and uncovers the underlying geometric content we relate plane parallax to the geometry of translating calibrated camera and introduce a new par allax factorizing projective reconstruction method based on this initial plane parallax alignment reduces the problem to a single rank one factorization of a matrix of rescaled parallax into a vector of projection centre and a vector o f projective height above the reference plane the method extends to d line represented by viapoints and d plane represented by homographies 
in this paper we present a novel method for automatically and efficiently generating stereoscopic mosaic by seamless registration of optical data collected by a video camera mounted on an airborne platform that undergoes dominant translational motion there are four critical point discussed in this paper using a parallel perspective representation a pair of geometrically registered stereo mosaic can be constructed before we explicitly recover any d information under rather general motion a prism parallel ray interpolation for stereo mosaicing technique is proposed to make stereo mosaic seamless in the presence of motion parallax and for rather arbitrary scene a fast prism algorithm is presented and issue on stitching point selection and occlusion handling are discussed the epipolar geometry of parallel perspective stereo mosaic generated under constrained dof motion is formulated which show optimal baseline easy search for correspondence and constant depth resolution the proposed method for the generation of stereo mosaic and then the reconstruction of a d map are efficient in both computation and storage experimental result on long video sequence are given 
stereoscopic vision ha a fundamental role both for animal and human nonetheless in the computer vision literature there is limited reference to biological model related to stereoscopic vision and in particular to the functional property and the organization of binocular information within the visual cortex in this paper a simple stereo technique based on a space variant mapping of the image data and a multi layered cortical stereoscopic representation mimicking the neural organization of the early stage of the human visual system is proposed radial disparity computed from a stereo pair is used to map the relative depth with respect to the fixation point a set of experiment demonstrating the applicability of the devised technique is also presented 
many communicative behavior in the animal kingdom consist of performing and recognizing specialized pattern of oscillatory motion here we present an approach to the representation and recognition of these oscillatory motion based on the categorical organization of a simple sinusoidal model having very specific and limited parameter value this characterization is used to specify the type and layout of computation for recognizing the pattern result of the method are demonstrated with 
a novel algorithm for motion segmentation is proposed the algorithm us the fact that shape of an object with homogeneous motion is represented a dimensional linear space thus motion segmentation is done a the decomposition of shape space of multiple object into a set of dimensional subspace the decomposition is realized using the discriminant analysis of orthogonal projection matrix of shape space since only discriminant analysis of ddata is needed this analysis is quite simple the algorithm based on the analysis is robust for data with noise and outlier because the analysis can extract useful information for motion segmentation while rejecting useless one the implementation result show that the proposed method is robust and efficient enough to do online task for real scene 
standard presentation system consisting of a laptop connected to a projector suffer from two problem the projected image appears distorted keystoned unless the projector is precisely aligned to the projection screen the speaker is forced to interact with the computer rather than the audience this paper show how the addition of an uncalibrated camera aimed at the screen solves both problem although the location orientation and optical parameter of the camera and projector are unknown the projector camera system calibrates itself by exploiting the homography between the projected slide and the camera image significant improvement are possible over passively calibrating system since the projector actively manipulates the environment by placing feature point into the scene for instance using a low resolution x camera we can achieve an accuracy of pixel in a x presentation slide the camera projector system infers model for the projector to camera and projector to screen mapping in order to provide two major benefit first image sent to the projector are pre warped in such a way that the distortion induced by the arbitrary projector screen geometry are precisely negated this enables projector to be mounted anywhere in the environment for instance at the side of the room where the speaker is le likely to cast shadow on the screen and where the projector doe not occlude the audience s view second the system detects the position of the user s laser pointer dot in the camera image at hz allowing the laser pointer to emulate the pointing action of a mouse this enables the user to activate virtual button in the presentation such a next slide and draw on the projected image the camera assisted presentation system requires no special hardware aside from the cheap camera 
the problem of establishing correspondence and measuring the similarity of a pair of planar curve arises in many application in computer vision and pattern recognition this paper present a new method for comparing planar curve and for performing matching at sub sampling resolution the analysis of the algorithm a well a it structural property are described the performanceof the new technique applied to the problem of signature verification is shown and compared with the performance of the well known dynamic time warping algorithm of different method proposed in the pattern recognition literature that could be applied to this problem some of the method require the extraction of a prototype that summarizes the mean behavior of the example and a measure of the deviation from this prototype that exists in the training set some other method compute the similarity of the curve based on a time distortion function that best aligns the curve a measure of this similarity is later on used for classification 
work in simultaneous localisation and map building slam for mobile robot ha focused on the simplified case in which a robot is considered to move in two dimension on a ground plane while this is often a good approximation a large number of real world application require robot to move around terrain which ha significant slope and undulation and it is desirable that these robot too should be able to estimate their location by building map of natural feature in this paper we describe a real time ekf based slam system permitting unconstrained d localisation and in particular develop model for the motion of a wheeled robot in the presence of unknown slope variation in a fully automatic implementation our robot observes visual point feature using fixating stereo vision and build a sparse map on the fly combining this visual measurement with information from odometry and a roll pitch accelerometer sensor the robot performs accurate repeatable localisation while traversing an undulating course 
the error correcting output coding ecoc approach to classifier design decomposes a multi class problem into a set of complementary two class problem we show how to apply the ecoc concept to automatic face verification which is inherently a two class problem the output of the binary classifier defines the ecoc feature space in which it is easier to separate transformed pattern representing client and impostor we propose two different combining strategy a the matching score for face verification the fir st us the fir st order minkowski metric and requires a threshold to be set the second is a kernel based method and ha no parameter to set the proposed method exhibit better performance on the well known xm vt data set compared with previous reported result 
we describe a novel viewpoint lighting ambiguity which we call the kgbr this ambiguity assumes orthographic projection or an affine camera and us lambertian reflectance function including cast attached shadow and multiple light source a kgbr transform alters the geometry by a three dimensional affine transformation and albedo property of object if two object are related by a kgbr transform then for any viewpoint and lighting of the first object there exists a corresponding viewpoint and lighting of the second object so that the image are identical up to an affine transformation the generalized ba relief gbr ambiguity is obtained a a special case of the kgbr we describe generic viewpoint and lighting assumption and show that either or both resolve this ambiguity by biasing towards object with planar geometry in proceeding international conference on computer vision vancouver british columbia 
sensitivity to variation in illumination is a fundamental and challenging problem in face recognition in this paper we describe a new method based on symmetric shape from shading ssfs to develop a face recognition system that is robust to change in illumination the basic idea of this approach is to use the ssfs algorithm a a tool to obtain a prototype image which is illumination normalized it ha been shown that the ssfs algorithm ha a unique point wise solution but it is still difficult to recover accurate shape information given a single real face image with complex shape and varying albedo in stead we utilize the fact that all face share a similar shape making the direct computation of the prototype image from a given face image feasible finally to demonstrate the efficacy of our method we have applied it to several publicly available face database 
in this paper we propose a novel method called local nonnegative matrix factorization lnmf for learning spatially localized part based subspace representation of visual pattern an objective function is defined to impose localization constraint in addition to the non negativity constraint in the standard nmf this give a set of base which not only allows a non subtractive part based representation of image but also manifest localized feature an algorithm is presented for the learning of such basis component experimental result are presented to compare lnmf with the nmf and pca method for face representation and recognition which demonstrates advantage of lnmf 
a novel algorithm is proposed to learn pattern similarity for texture image retrieval similar pattern in different texture class are grouped into a cluster in the feature space each cluster is isolated from others by an enclosed boundary which is represented by several support vector and their weight obtained from a statistical learning algorithm called support vector machine svm the signed distance of a pattern to the boundary is used to measure it similarity furthermore the pattern of different class within each cluster are separated by several sub boundary which are also learned by the svms the signed distance of the similar pattern to a particular sub boundary associated with the query image are used for ranking these pattern experimental result on the brodatz texture database indicate that the new method performs significantly better than the traditional euclidean distance based approach 
we address the problem of motion flow estimation for a scene with multiple moving object observed from a possibly moving camera we take a input a possibly sparse noisy velocity field a obtained from local matching produce a set of motion boundary and identify pixel with different velocity in overlapping layer for a fixed observer these overlapping layer capture occlusion information for a moving observer further processing is required to segment independent object and infer structure unlike previous approach which generate layer by iteratively fitting data to a set of predefined parameter we instead find boundary first then infer region and address occlusion overlap relationship all computational step use a common framework oftensors to represent velocity information together with saliency confidence and uncertainty communication between site is performed by convolution like tensorvoting the scheme is non iterative and the only free parameter is the scale related to neighborhood size we illustrate the approach with result obtained from synthetic sequence and from real image the quantitative result compare favorably with those of other method especially in the presence of occlusion 
we propose a new stereo method for d navigation in a dynamic environment such a road without depth search and metric camera calibration conventionally there is an effective stereo method based on the constraint that an observer move on the ground plane namely the gp constraint although the gp constraint is often violated in an outdoor environment due to the movement of the observer i e camera vibration and inclination it can be updated using some feature on the ground plane only if the stereo camera are weakly calibrated however the conventional stereo method ha several drawback first it is rather difficult to solve for the general epipolar geometry summarized in the fundamental matrix second although the updated gp constraint often becomes imperfect it lack an effective contrivance for the noise reduction third there is no measure to ass the danger of detected obstacle to solve these problem we develop a domain specific stereo method which utilizes various attribute of road we introduce the pseudo projective camera model that provides a good approximation to the projective camera in road scene and accordingly define the linear epipolar geometry for a pair of pseudo projective camera furthermore we show that extraction of two parallel line lying on the road is effective to update the gp constraint overcome the noise issue and even to estimate the degree of danger through experiment we demonstrate that our method is efficient and applicable to a variety of outdoor scene 
capturing real motion from video sequence is a powerful method for automatic building of facial articulation model in this paper we propose an explanation based facial motion tracking algorithm based on a piecewise bezier volume deformation model pbvd the pbvd is a suitable model both for the synthesis and the analysis of facial image it is linear and independent of the facial mesh structure with this model basic facial movement or action unit are interactively defined by changing the magnitude of these action unit animated facial image are generated the magnitude of these action unit can also be computed from real video sequence using a model based tracking algorithm however in order to customize the articulation model for a particular face the predefined pbvd action unit need to be adaptively modified in this paper we first briefly introduce the pbvd model and it application in facial animation then a multiresolution pbvd based motion tracking algorithm is presented finally we describe an explanation based tracking algorithm that take the predefined action unit a the initial articulation model and adaptively improves them during the tracking process to obtain a more realistic articulation model experimental result on pbvd based animation model based tracking and explanation based tracking are shown in this paper 
this work deal with the recovery of illusory linear clue from perspectively skewed document with the purpose of using them for rectification the computational approach proposed implement the perceptual organization principle implicitly used in textual layout the numerous example provided show that the method is robust and viewpoint and scale invariant in this paper we will be dealing with the problem of finding illusory clue of the type a and c without assumption on the type of document font or camera rotation and orientation other than the presence of some organized text text had been designed long before perception study but with the unspoken principle of perceptual saliency see e g in mind give any organised text even foreign and unintelligible to u and word line and paragraph structure pop out preattentively the approach presented in this paper is strongly based on a computational implementation of these perceptual organization principle and will be shown to be robust fast and general 
in this paper we consider the problem of recovering the d motion and shape of an arbitrarily moving arbitrarilyshaped curve from multiple synchronized video stream acquired from distinct and known point in space by studying the d motion and shape constraint provided by the input video stream we show that shape and motion recovery is equivalent to the problem of recovering the differential property of the spatio temporal curve manifold that describes the curve s trace in space time and a local analytical description of this manifold can be computed directly from the spatio temporalvolumes definedby the input video stream our experimental result suggest that this manifold basedapproachto joint shape and motion estimation yield shape estimate of higher accuracy that those obtained from stereo alone allows accurate recovery of d curve motion and provides significant robustness against image noise and camera calibration error 
in this paper we address the problem of estimating and analyzing the motion in image sequence that involve fluid phenomenon in this context standard motion estimation technique are not well adapted and more dedicated approach have to be designed in this prospect we propose to estimate in a joint and cooperative way a dense motion field and a peculiar parametric representation of the flow the parametric model issue from an extension of rankine vortex model and includes a laminar flow field dense and parametric field are estimated by minimizing a robust global objective function thanks to a specific alternate scheme the method ha been validated on different kind of meteorological image sequence 
this paper present a new method for the simultaneous estimation of lighting direction and shape from shading the method estimate the shape and the lighting direction using a two step iterative process we assume an initial possibly incorrect estimate of the lighting position a stiff deformable model is then fitted to the image assuming this lighting position next a least square estimate of the lighting position is derived from the model using the levenberg marquart method the two step model fitting and lighting position estimation are iterated once the light direction ha converged to a stable solution the deformable model stiffness is lowered and the model fit accurately given the lighting model in addition we show how the method can be used with either orthographic or perspective projection assumption in a variety of experiment on real and synthetic data the method is robust to error both to the initial light position and shape estimate 
abstract a novel approach for real time skin segmentation in video sequence is described the approach enables reliable skin segmentation despite wide variation in illumination during tracking an explicit second order markov model is used to predict evolution of the skin color hsv histogram over time histogram are dynamically updated based on feedback from the current segmentation and based on prediction of the markov model the evolution of the skin color distribution at each frame is parameterized by translation scaling and rotation in color space consequent change in geometric parameterization of the distribution are propagated by warping and re sampling the histogram the parameter of the discrete time dynamic markov model are estimated using maximum likelihood estimation and also evolve over time quantitative evaluation of the method wa conducted on labeled ground truth video sequence taken from popular movie 
in this paper we derive a minimal set of sufficient constraint in order for number to constitute a trifocal tensor it is shown that in general eight nonlinear algebraic constraint are enough this result is in accordance with the theoretically expected number of eight independent constraint and novel since the to date known set of sufficient constraint contain at least condition up to now research and formulation of constraint for the trifocal tensor ha concentrated mainly on the correlation slice and ha produced set of constraint that are neither minimal nor independent we show that by turning attention from correlation to homographic slice simple geometric consideration yield the desired result having the minimal set of constraint is important for constrained estimation of the tensor a well a for deepening the understanding of the multiple view relation that are valid in the projective framework 
we present a method to recover scene deteriorated by superposition of transparent and semi reflected contribution a appear in reflection off window separating the superimposed contribution from the image in which either contribution is in focus is based on mutual blurring and subtraction of the perturbing component this procedure requires the defocus blur kernel to be known the use of uncalibrated kernel had previously led to contaminated result we propose a method for self calibration of the blur kernel from the raw image themselves the kernel are sought to minimize the mutual information of the recovered layer this relaxes the need for prior knowledge on the optical transfer function experimental result are presented 
perspective distortion occlusion and specular reflection are challenging problem in shape from stereo in this paper we review one recently published area based stereo matching algorithm bhat and nayar designed to be robust in these case although the algorithm is an important contribution to stereo matching we show that it coefficient ha a low discriminatory power which lead to a significant number of multiple best match in order to cope with this drawback we introduce a new normalized ordinal correlation coefficient experiment showing the behavior of the proposed coefficient are performed on various datasets including real data with ground truth the new coefficient reduces the occurrence of multiple best match to almost zero per cent it also show a more robust and equally accurate behavior these benefit are achieved at almost no additional computational cost 
a novel method of incorporating shape information into the image segmentation process is presented we introduce a representation for deformable shape and define a probability distribution over the variance of a set of training shape the segmentation process embeds an initial curve a the zero level set of a higher dimensional surface and evolves the surface such that the zero level set converges on the boundary of the object to be segmented at each step of the surface evolution we estimate the maximum a posteriori map position and shape of the object in the image based on the prior shape information and the image information we then evolve the surface globally towards the map estimate and locally based on image gradient and curvature result are demonstrated on synthetic data and medical imagery in d and d 
sparse principal component analysis s pca is a novel framework for learning a linear orthonormal basis representation for structure intrinsic to an ensemble of image s pca is based on the discovery that natural image exhibit structure in a low dimensional subspace in a sparse scale dependent form the s pca basis optimizes an objective function which trade off correlation among output coefficient for sparsity in the description of basis vector element this objective function is minimized by a simple robust and highly scalable adaptation algorithm consisting of successive planar rotation of pair of basis vector the formulation of s pca is novel in that multi scale representation emerge for a variety of ensemble including face image image from outdoor scene and a database of optical flow vector representing a motion class 
a new exemplar based probabilistic paradigm for visual tracking is presented probabilistic mechanism are attractive because they handle fusion of information especially temporal fusion in a principled manner exemplar are selected representative of raw training data used here to represent probabilistic mixture distribution of object configuration their use avoids tedious hand construction of object model and problem with change of topology using exemplar in place of a parameterized model pose several challenge addressed here with what we call the metric mixture m approach the m model ha several valuable property principally it provides alternative to standard learning algorithm by allowing the use of metric that are not embedded in a vector space secondly it us a noise model that is learned from training data lastly it eliminates any need for an assumption of probabilistic pixelwise independence experiment demonstrate the effectiveness of the m model in two domain tracking walking people using chamfer distance on binary edge image and tracking mouth movement by mean of a shuffle distance 
we present an exemplar based object recognition system which is capable of on line learning of representation of scene and object from image sequence local appearance feature are used in a tracking framework to find keyframes of the input sequence during learning the representation of the stored sequence which are used for recognition of novel image consists only of the appearance feature in these key frame and contains no further a priori assumption about the underlying sequence the system is able to create sparse and extendable representation and show good recognition performance in a variety of viewing condition for database of natural and synthetic image sequence 
this paper present a novel modeling algorithm that is capable of simultaneously recovering correct shape geometry a well a it unknown topology from arbitrarily complicated datasets our algorithm start from a simple seed model of genus zero that can be arbitrarily initiated by user within any dataset the deformable behavior of our model is governed by a locally defined objective function associated with each vertex of the model through the numerical computation of function optimization our algorithm can adaptively subdivide the model geometry automatically detect self collision of the model properly modify it topology because of the occurrence of self collision continuously evolve the model towards the object boundary and reduce fitting error and improve fitting quality via global subdivision commonly used mesh optimization technique are employed throughout the geometric deformation and topological variation in order to ensure the model both locally smooth and globally well conditioned we have applied our algorithm to various real synthetic range data a well a volumetric image data in order to empirically verify and validate it usefulness based on our experiment the new modeling algorithm prof to be very powerful and extremely valuable for shape recovery in computer vision reverse engineering in computer graphic and iso surface extraction in visualization 
in this paper we study the problem of recovering the dshape reflectance and non rigid motion of a dynamic dscene because these property are completely unknown our approach us multiple view to build a piecewisecontinuousgeometric and radiometric representation of thescene s trace in space time basic primitive of this representationis the dynamic surfel which encodes the instantaneouslocal shape reflectance and motion of a smallregion in the scene and enables 
we describe two new algorithm for two frame structure from motion from tracked point feature one is the first fast algorithm for computing an exact least square estimate it exploit our observation that the rotationally invariant least square error can be written in a simple form that depends just on the motion the other is essentially a accurate a the least square estimate and is more efficient probably faster and potentially more robust than previous algorithm of comparable accuracy we also analyze theoretically the accuracy of the optical flow approximation to the least square error 
we present a comprehensive treatment of d object tracking by posing it a a nonlinear state estimation problem the measurement are derived using the output of shape encoded filter s the nonlinear state estimation is performed by solving the zakai equation and we use the branching particle propagation method for computing the solution the unnormalized conditional density for the solution to the zakai equation is realized by the weight of the particle we fir st sample a set of particle approximating the initial distribution of the state vector conditioned on the observation where each particle encodes the set of geometric parameter of the object the weight of the particle represents geometric and temporal fit which is computed bottom up from the raw image using a shape encodedfilter the particle branch so that the mean numberof offspring is proportional to the weight time update is handled by employing a second order motion model combined with local stochastic search to minimize the prediction error the prediction adjustmentsuggested by system identification theory is empirically verified to contribute to global stability the amount of diffusion is effectively adjusted using a kalman updating of the covariance matrix we have successfully applied this method to human head tracking where we estimate head motion and compute structure using simple head and facial feature model 
this work take place in the context of hierarchical stochastic model for the resolution of discrete inverse problem from low level vision some of these model lie on the node of a quad tree which lead to non iterative inference procedure nevertheless if they circumvent the algorithmic drawback of grid based model computational load and or great dependence on the initialization they admit modeling shortcoming cumbersome and somehow artificial we investigate a new hierarchical stochastic model which take benefit from both the spatial and the hierarchical prior modeling the independence graph is based on a tree which ha been pollarded with the node at the coarsest resolution exhibiting a grid based interaction structure for this class of model we address the critical problem of parameter estimation to this end we derive an em algorithm on the hybrid structure which mix an exact em algorithm on each subtrees and a low cost gibbsian em algorithm on the coarse spatial grid experiment on a synthetic image and on multi spectral satellite image are reported 
om this paper explores the direct motion estimation problem assuming that video rate depth information is available from either stereo camera or other sensor we use these depth measurement in the traditional linear brightness constraint equation and we introduce a new depth constraint equation a a result estimation of certain type of motion such a translation in depth and rotation out of the image plane becomes more robust we derive linear brightness and depth change constraint equation that govern the velocity field in d for both perspective and orthographic camera projection model these constraint are integrated jointly over image region according to a rigidbody motion model yielding a single linear system to robustly track d object pose result are shown for tracking the pose of face in sequence of synthetic and real image for a color version of this paper and for video result sequence see http www interval com paper 
we present a statistical model for organizing image collection which integrates semantic information provided by associated text and visual information provided by image feature the model is very promising for information retrieval task such a database browsing and searching for image based on text and or image feature furthermore since the model learns relationship between text and image feature it can be used for novel application such a associating word with picture and unsupervised learning for object recognition 
we introduce joint feature distribution a general statistical framework for feature based multi image matching that explicitly model the joint probability distribution of corresponding feature across several image conditioning on feature position in some of the image give well localized distribution for their correspondent in the others and hence tight likelihood region for correspondence search we apply the framework in the simplest case of gaussian like distribution over the direct sum affine image and tensor product projective image of the image coordinate this produce probabilistic correspondence model that generalize the geometric multi image matching constraint roughly speaking by a form of model averaging over them these very simple method predict accurate correspondence likelihood region for any scene geometry including planar and near planar scene without illconditioning or explicit model selection small amount of distortion and non rigidity are also tolerated we develop the theory for any number of affine or projective image explain it relationship to matching tensor and give result for an initial implementation 
this paper present a new methodology for evaluating the quality of motion estimation and stereo correspondence algorithm motivated by application such a novel view generation and motion compensated compression we suggest that the ability to predict new view or frame is a natural metric for evaluating such algorithm our new metric ha several advantage over comparing algorithm output to true motion or depth first of all it doe not require the knowledge of ground truth data which may be difficult or laborious to obtain second it more closely match the ultimate requirement of the application which are typically tolerant of error in uniform color region but very sensitive to isolated pixel error or disocclusion error in the paper we develop a number of error metric based on this paradigm including forward and inverse prediction error residual motion error and local motion compensated prediction error we show result on a number of widely used motion and stereo sequence many of which do not have associated ground truth data 
this paper describes an active character recognitionmethodology henceforth referred to a acr wepresentinthis paper a method that us an active heuristic functionsimilar to the one used by a search algorithm that adaptivelydetermines the length of the feature vector a well asthe feature themselves used to classify an input pattern acr adapts to factor such a the quality of the inputpattern it intrinsic similarity and difference from patternsof other class it is being 
a non metric pan tilt stereo head consists of a weakly calibrated stereo rig mounted on a pan tilt mechanism it is called non metric since neither the kinematics of the mechanism nor camera calibration are required the lie group of projective rotation homographies of projective space corresponding to pure rotation is an original formalism to model the geometry of such a pan tilt system a rodrigues alike formula a well a a minimal parameterization of projective rotation are introduced based on this the practical part devise a numerical optimization technique for accurately estimating projective rotation from point correspondence only this procedure recovers sufficient geometry to operate the system the experiment validate and evaluate the proposed approach on real image data they show the weak calibration image prediction and homing of a non metric pan tilt head 
under normal viewing condition human find it easy to distinguish between object made out of different material such a plastic metal or paper untextured material such a these have different surface reflectance property including lightness and gloss with single isolated image and unknown illumination condition the task of estimating surface reflectance is highly underconstrained because many combination of reflection and illumination are consistent with a given image in order to work out how human estimate surface reflectance property we asked subject to match the appearance of isolated sphere taken out of their original context we found that subject were able to perform the task accurately and reliably without contextual information to specify the illumination the sphere were rendered under a variety of artificial illumination such a a single point light source and a number of photographically captured real world illumination from both indoor and outdoor scene subject performed more accurately for stimulus viewed under real world pattern of illumination than under artificial illumination suggesting that subject use stored assumption about the regularity of real world illumination to solve the ill posed problem 
we improve the promising colour by correlation method for computational colour constancy by modifying it to work in a three dimensional colour space the previous version of the algorithm us only the chromaticity of the input and thus cannot make use of the information inherent in the pixel brightness which previous work suggests is useful we develop the algorithm for the mondrian world matte surface the mondrian world with fluorescent surface and the mondrian world with specularities we test the new algorithm on synthetic data and on a data set of carefully calibrated image we find that on the synthetic data the new algorithm significantly out performs all other colour constancy algorithm in the case of image data the result are also promising the new algorithm doe significantly better than it chromaticity counter part and it performance approach that of the best algorithm since the research into the method is still young we are hopeful that the performance gap between the real and synthetic case can be narrowed 
we present in this article a system which improves a dem the method reconstructs all the facade of the building and then corrects the initial dem by deleting the point of the roof which pas over the boundary defined by the facade we correct the shape of the building with the initial photograph to have sharp contour the proposed approach doe not use any a priori information about the orientation of the facade and the shape of the building we present result with synthetic and real image 
this paper establishes a link between uncalibrated stereo vision and the motion of rigid and articulated body the variation in the projective reconstruction of a dynamic scene over time allows an uncalibrated stereo rig to be used a a faithful motion capturing device we introduce an original theoretical framework projective kinematics which allows rigid and articulated motion to be represented within the transformation group of projective space corresponding projective velocity are defined in the tangent space most importantly these projective motion inherit the lie group structure of the displacement group these theoretical result lead immediately to non metric formulation of visual serving tracking motion capturing and motion synthesis system that no longer require the metric geometry of a stereo camera or of the articulated body to be known we report on such a non metric formulation of a visual serving system and present simulated experimental result 
image alignment is one of the most important task incomputer vision in this paper we explicitly model spatialillumination variation by low order polynomial functionsin an energy minimization framework data constraintsfor the alignment and illumination parameter are derivedfrom the first order taylor approximation of a generalizedbrightness assumption we formulate the parameterestimation problem in a weighted least square frameworkby using the influence function from robust 
we present a method to learn object class model from unlabeled and unsegmented cluttered scene for the purpose of visual object recognition we focus on a particular type of model where object are represented a flexible constellation of rigid part feature the variability within a class is represented by a joint probability density function pdf on the shape of the constellation and the output of part detector in a first stage the method automatically identifies distinctive part in the training set by applying a clustering algorithm to pattern selected by an interest operator it then learns the statistical shape model using expectation maximization the method achieves very good classification result on human face and rear view of car 
dynamic contour or snake provide an effective method for tracking complex moving object for segmentation and recognition task but have difficulty tracking occluding boundary on cluttered background to compensate for this shortcoming dynamic contour often rely on detailed object shape or motion model to distinguish between the boundary of the tracked object and other boundary in the background in this paper we present a complementary approach to detailed object model we impr ove the discriminative power of the local image measurement that drive the tracking process we describe a new robust external energy term for dynamic contour that can track occluding boundary without detailed object model we show how our image model improves tracking in cluttered scene and describe how a fi ne grained image segmentation mask is created directly from the local ima ge measurement used for tracking tracking boundary tracking visual feature in a series of image is an important task both for vision based control and for rotoscoping application dynamic contour ka and related active tracking technique are well suited for both application because they combine simple light weight object model with rapid update dynamic contour track boundary by minimizing the sum of an external force from a local image measure and an internal force from a shape dynamic model a dynamic contour track the indicated boundary by fi nding the shape that minimizes the combined external and inter nal force the external force dri f the dynamic contour according to the current image appearance the internal force increase the spatial and temporal continuity of the tracked boundary dynamic contour usually employ a simple image con 
this paper present a work we have done on the motion detection in the context of an outdoor traffic scene for visual surveillance purpose our motion detection algorithm is based both on background subtraction and three frame difference we propose quite innovative solution for denoising blob filling and shadow detection without exploiting any a priori knowledge actually method presented here have been fully setup only for the former technique target sequence is made of bit grey level still image taken at fps this application work off line at fps on a mhz pentium iii computer 
in this paper we present a procedure for organizing real world scene along semantic ax the approach is based on the output energy of linear discriminant filter that take into account or not spatial information we introduce three semantic ax along which picture are ordered the main semantic axis computes the degree of naturalness of a scene then urban picture are evaluated according to their degree of verticalness and natural scene according to their degree of openness we observe the emergence of typical scene category such a beach mountain skyscraper city center etc along the ax 
optimization method based on iterative scheme can be divided into two class linesearch method and trust region method while linesearch technique are commonly found in various vision application not much attention is paid to trust region method motivated by the fact that linesearch method can be considered a special case of trust region method we propose to apply trust region method to visual tracking problem our approach integrates trust region method with the kullback leibler distance to track a rigid or non rigid object in real time if not limited by the speed of a camera the algorithm can achieve frame rate above fps to justify our method a variety of experiment comparison are carried out for the trust region tracker and a linesearch based mean shift tracker with same initial condition the experimental result support our conjecture that a trust region tracker should perform superiorly to a linesearch one 
this paper present a practical technique for modelbased d hand tracking an anatomically accurate hand model is built from truncated quadric this allows for the generation of d profile of the model using elegant tool from projective geometry and for an efficient method to handle self occlusion the pose of the hand model is estimated with an unscented kalman filter ukf which minimizes the geometric error between the profile and edge extracted from the image the use of the ukf permit higher frame rate than more sophisticated estimation method such a particle filtering whilst providing higher accuracy than the extended kalman filter the system is easily scalable from single to multiple view and from rigid to articulated model first experiment on real data using one and two camera demonstrate the quality of the proposed method for tracking a dof hand model 
curve evolution scheme for segmentation implemented with level set method have become an important approach in computer vision previous work ha modeled evolving contour which are curve in d or surface in d our objective is to explore recent mathematical work enabling the evolution of manifold of higher co dimension we consider d curve in d codimension two for the application of automatically segmenting blood vessel in volumetric magnetic resonance angiography mra image this paper describes the theoretical foundation of our system curve then provides segmentation result compared against segmentation obtained interactively by a neurosurgeon segmentation of bronchus in lung computed tomography ct scan are also presented the new experiment comparison to manual segmentation and sample comparison to the use of a codimension one regularization force are the primary contribution of this report 
in this paper parametric statistical modelling of distribution of colour camera data is discussed a review is provided with some analysis of the property of some common model which a re generally based on an assumption of i ndependence of the c hromaticity and intensity c omponents of colour data result of an empirical comparison of t he performance of various model are also reviewed these result indicate that such model are not appropriate for situation other than highly controlled environment in particular they perform poorly for daylight imagery here a modification to existing statistical colour model is proposed an d the resultant new model are assessed using the same methodology a for the previous result this simple modification which is based on the inclusion of an ambient term in the underlying physical model is s hown to have a major impact on the performance of the model in le constrained daylight environment 
a framework for modeling and recognition of temporal activity is proposed the modeling of set of exemplar activity is achieved by parameterizing their representation in the form of principal component recognition of spatio temporal variant of modeled activity is achieved by parameterizing the search in the space of admissible transformation that the activity can undergo experiment on recognition of articulated and deformable object motion from image motion parameter are presented 
this paper describes a novel view based learning algorithm for d object recognition from d image using a network of linear unit the snow learning architecture is a sparse network of linear function over a pre defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of feature we use pixel based and edge based representation in large scale object recognition experiment in which the performance of snow is compared with that of support vector machine svms and nearest neighbor using the object in the columbia image object database coil experimental result show that the snow based method outperforms the svm based system in term of recognition rate and the computational cost involved in learning most importantly snow s performance degrades more gracefully when the training data contains fewer view the empirical result also provide insight into practical and theoretical consideration on view based method for d object recognition 
we consider the registration of sequence of image where the observed scene is entirely non rigid for example a camera flying over water a panning shot of a field of sunflower in the wind or footage of a crowd applauding at a sport event in these case it is not possible to impose the constraint that world point have similar colour in successive view so existing registration technique cannot be applied indeed the relationship between a point s colour in successive frame is essentially a random process however by treating the sequence of image a a set of sample from a multidimensionalstochastic time series we can learn a stochastic model e g an ar model of the random process which generated the sequence of image with a static camera this stochastic model can be used to extend the sequence arbitrarily in time driving the model with random noise result in an infinitely varying sequence of image which always look like the short input sequence in this way we can create videotextures which can play forever without repetition with a moving camera the image generation process comprisestwo component astochastic componentgenerated by the videotexture and a parametric component due to the camera motion for example a camera rotation induces a relationship between successive image which is modelled by a point perspective transformation or homography human observer can easily separate the camera motion from the stochastic element the key observation for an automatic implementation is that without image registration the time series analysis must work harder to model the combined stochastic and parametric image generation specifically the learned model will require more component or more coefficient to achieve the same expressive power a for the static scene with the correct registration the model will be more compact therefore by searching for the registration parameter which result in the most parsimoniousstochastic model we can register sequence where there is only stochastic rigidity the paper describes an implementation of this scheme and show result on a number of example sequence 
operation and unit of memory in many application this large computational demand may be prohibitive here we suggest an approach to reduce the computational effort relying on the relatively small dimension denoted o f the partial kl basis that is usually needed we propose an algorithm that doe not require to store the entire set of input image before proceeding to the calculation of the kl basis rather it take the image in small block and update the required kl basis sequentially 
support vector machine svms have shown great potential in numerous visual learning and pattern recognition problem the optimal decision surface of a svm is constructed from it support vector which are conventionally determined by solving a quadratic programming qp problem however solving a large optimization problem is challenging since it is computationally intensive and the memory requirement grows with square of the training vector in this paper we propose a geometric method to extract a small superset of support vector which we call guard vector to construct the optimal decision surface specifically the guard vector are found by solving a set of linear programming problem experimental result on synthetic and real data set show that the proposed method is more efficient than conventional method using qps and requires much le memory 
window size and shape selection is a difficult problem in area based stereo we propose an algorithm which chooses an appropriate window shape by optimizing over a large class of compact window we call them compact because their ratio of perimeter to area tends to be small we believe that this is the first window matching algorithm which can explicitly construct non rectangular window efficient optimization over the compact window class is achieved via the minimum ratio cycle algorithm in practice it take time linear in the size of the largest window in our class still the straightforward approach to find the optimal window for each pixel disparity pair is too slow we develop pruning heuristic which give practically the same result while reducing running time from minute to second our experiment show that unlike fixed window algorithm our method avoids blurring disparity boundary a well a construct large window in low textured area the algorithm ha few parameter which are easy to choose and the same parameter work well for different image pair 
we address the problem of integrating shading and multi frame stereo cue within the framework ofoptimization in the innite dimensional space of piecewise smooth surface cue integration then reducesto the determination of region where prior assumption on the reectance of the surface can be enforced and result in a novel re formulation of the correspondence problem a a segmentation quot or grouping quot task in general our formulation combine stereo and shading and therefore allows de 
this paper present a novel approach for multisensory information fusion in the bayesian inference framework specifically under the maximum entropy principle a formula is derived for estimating the joint probability of multisensory signal the formula us appropriate mapping function to reflect the dependency among multisensory signal selection of the mapping is guided by the maximum mutual information criterion in addition an algorithm is proposed for linear mapping of gaussian random variable experiment on simulated gaussian data and video audio signal have been carried out preliminary result demonstrate that the proposed method can significantly improve the recognition accuracy for this type of task 
in this paper we address the problem of segmenting foreground region corresponding to a group of people given model of their appearance that were initialized before occlusion we present a general framework that us maximum likelihood estimation to estimate the best arrangement for people in term of d translation that yield a segmentation for the foreground region given the segmentation result we conduct occlusion reasoning to recover relative depth information and we show how to utilize this depth information in the same segmentation framework we also present a more practical solution for the segmentation problem that is online to avoid searching an exponential space of hypothesis the person model is based on segmenting the body into region in order to spatially localize the color feature corresponding to the way people are dressed modeling these region involves modeling their appearance color distribution a well a their spatial distribution with respect to the body we use a non parametric approach based on kernel density estimation to represent the color distribution of each region and therefore we do not restrict the clothing to be of uniform color instead it can be any mixture of color and or pattern we also present a method to automatically initialize these model and learn them before the occlusion 
we introduce a tensor hijk and it dual hijk which represent the d projective mapping of point across three projection view the tensor hijk is a generalization of the well known d collineation matrix homography matrix and it concatenates two homography matrix to represent the joint mapping across three view the dual tensor hijk concatenates two dual homography matrix mapping of line space and is responsible for representing the mapping associated with moving point along straight line path i e hijk can be recovered from line of sight measurement only 
estimation of rigid body motion parameter in computer vision is normally performed from image correspondence between two coordinate frame a large number of method and algorithm have been proposed based on that such correspondence are known unfortunately the establishment of correspondence is often time consuming and in many case impossible in this paper we propose a novel correspondenceless motion estimation algorithm based on the cross matrix for a comparative study we also implemented a correspondenceless motion estimation algorithm based on the scatter matrix experimental result have demonstrated that our method is more accurate and robust than the scatter matrix based algorithm 
abstract a the identity fraud in our society is reaching unprecedentedproportions and a there is an increasingemphasis on the emerging automatic positive personalidentification application identification basedon biometrics in general and fingerprint in particular is receiving a lot of attention in both researchand industrial community there are two majorshortcomings of the traditional approach to fingerprintrepresentation for a significant fraction ofpopulation the 
we present several method for the estimation of relative pose between plane and camera based on projection of set of coplanar feature in image while such method exist for simple case especially one plane seen in one or several view the aim of this paper is to propose solution for multi plane multi view situation possibly with little overlap we propose a factorization based method for the general case of plane seen in view a mechanism for computing missing data i e when one or several of the plane are not visible in one or several of the image is described finally a bundle adjustment procedure is developed that optimizes camera and plane pose a well a camera calibration 
we formulate face alignment a a model based parameter estimation problem in this paper first we work within a framework that combine two separate subspace model to represent frontal face pattern and pose change independently the combined unified nonlinear model represents varying pose face with a complex manifold then we use a feature based similarity measure fbsm to evaluate image difference in term of pose and match unknown pose face with the model image using a combined 
this paper address the problem of estimating the epipolar geometry from apparent contour in two special case under weak perspective and for circular motion an appropriate parametrization of the fundamental matrix is introduced for both case a well a suitable cost function for the estimation of the epipoles the algorithm used in the affine approximation proved to be robust and accurate under several condition the circular motion case turned out to be much more difficult but for a wide baseline the method introduced here is successful for small viewing angle the technique is too sensitive to noise to be used in practice nevertheless circular motion with small baseline can be well modeled by an affine camera system and this approximation should be used in this circumstance 
this paper proposes a new scheme for multi image projective reconstruction based on a projective grid space the projective grid space is defined by two basis view and the fundamental matrix relating these view given fundamental matrix relating other view to each of the two basis view this projective grid space can be related to any view in the projective grid space a a general space that is related to all image a projective shape can be reconstructed from all the image of weakly calibrated camera the projective reconstruction is one way to reduce the effort of the calibration because it doe not need euclid metric information but rather only correspondence of several point between the image for demonstrating the effectiveness of the proposed projective grid definition we modify the voxel coloring algorithm for the projective voxel scheme the quality of the virtual view image re synthesized from the projective shape demonstrates the effectiveness of our proposed scheme for projective reconstruction from a large number of image 
we describe new algorithm for multi frame structurefrom motion from tracked point feature thealgorithms are essentially linear and give accuraciessimilar to those of a maximum likelihood estimate for the common situation where the calibration is xedand approximately known we experimentally comparethe fully projective version of our algorithm to mixedprojective euclidean strategy our theoretical resultsclarify the natureofdominant plane compensationand the e ect of calibration 
this paper proposes a novel hypergraph skeletal representation for d shape based on a formal derivation of the generic structure of it medial axis by classifying each skeletal point by it order of contact we show that generically the medial axis consists of ve type of point which are then organized into sheet curve and point i sheet manifold with boundary which are the locus of bitangent sphere with regular tangency a two type of curve ii the intersection curve of three sheet and the locus of center of tri tangent sphere a and iii the boundary of sheet which are the locus of center of sphere whose radius equal the larger principal curvature i e higher order contact a point and two type of point iv center of quad tangent sphere a and v center of sphere with one regular tangency and one higher order tangency a a the geometry of the d medial axis thus consists of sheet a bounded by one type of curve a on their free end which corresponds to ridge on the surface and attached to two other sheet at another type of curve a which support a generalized cylinder description the a curve can only end in a a point where they must meet an a curve the a curve meet together in four at an a point this formal result lead to a compact representation for d shape referred to a the medial axis hypergraph representation consisting of node a and a a point ank notation mean n distinct k fold tangency of the sphere of contact a explained in the text 
the national aeronautics and space administration nasa along with member of the aircraft industry recently developed technology for a new supersonic aircraft one of the technological area considered for this aircraft is the use of video camera and image processing equipment to aid the pilot in detecting other aircraft in the sky the detection technique should provide high detection probability for obstacle that can vary from sub pixel to a few pixel in size while maintaining a low false alarm probability in the presence of noise and severe background clutter furthermore the detection algorithm must be able to report such obstacle in a timely fashion imposing severe constraint on their execution time this paper describes approach to detect airborne obstacle on collision course and crossing trajectory in video image captured from an airborne aircraft in both case the approach consist of an image processing stage to identify possible obstacle followed by a tracking stage to distinguish between true obstacle and image clutter based on their behavior the crossing target detection algorithm wa also implemented on a pipelined architecture from datacube and run in real time both algorithm have been successfully tested on flight test conducted by nasa 
newly available high quality inexpensive digital camera enable cheap and easy construction of omnidirectional camera we address several important issue for creating real time panorama including user assisted focusing devignetting and computer controlled brightness contrast and white balance we demonstrate remarkable improvement in panoramic image quality using method requiring very little cpu usage 
given a d object and some measurement for point in this object it is desired to find the d location of the object a new model based pose estimator from stereo pair based on linear programming lp is presented in the presence of outlier the new lp estimator provides better result than maximum likelihood estimator such a weighted least square and is usually almost a good a robust estimator such a least median of square lmeds in the presence of noise the new lp estimator provides better result than robust estimator such a lmeds and is slightly inferior to maximum likelihood estimator such a weighted least square in the presence of noise and outlier especially for wide angle stereo the new estimator provides the best result the lp estimator is based on correspondence of a point to convex polyhedron each point corresponds to a unique polyhedron which represents it uncertainty in d a computed from the stereo pair polyhedron can also be computed for d data point by using a priori depth boundary the lp estimator is a single phase no separate outlier rejection phase estimator solved by single iteration no re weighting and always converges to the global minimum of it error function the estimator can be extended to include random sampling and re weighting within the standard frame work of a linear program 
the complete set of measurement that could ever be used by a stereo algorithm is the plenoptic function or light field we give a concise characterization of when the lightfield of a lambertian scene uniquely determines it shape and conversely when stereo is inherently ambiguous we show that stereo computed from the complete light field is ambiguous if and only if the scene is radiating light of a constant intensity and color over an extended region 
the motion of a non rigid scene over time imposes more constraint on it structure than those derived from image at a single time instant alone an algorithm is presented for simultaneously recovering dense scene shape and scene flow i e the instantaneous d motion at every point in the scene the algorithm operates by carving away hexels or point in the d space of all possible shape and flow that are inconsistent with the image captured at either time instant or across time the recovered shape is demonstrated to be more accurate than that recovered using image at a single time instant application of the combined scene shape and flow include motion capture for animation retiming of video and non rigid motion analysis 
image rectification is the process of applying a pair of dimensional projective transforms or homographies to a pair of image whose epipolar geometry is known so that epipolar line in the original image map to horizontally aligned line in the transformed image we propose anovel technique for image rectification based on geometrically well defined criterion such that image distortion due to rectification is minimized this is achieved by decomposing each homography into a specialized 
this paper make two contribution it provides an operational definition of textons the putative elementary unit of texture perception and an algorithm for partitioning the image into disjoint region of coherent bright ness and texture where boundary of region are defined by peak in contour orientation energy and difference in texton density across the contour julesz introduced the term texton analogous to a phoneme in speech recognition but did not provide an operational definition for gray level image here we re invent textons a frequently co occurring combination of oriented linear filter output these can be learned using a k mean approach by mapping each pixel to it nearest texton the image can be analyzed into texton channel each of which is a point set where discrete technique such a voronoi diagram become applicable local histogram of texton frequency can be used with a x test for significant difference to find texture boundary natural image contain both textured and untextured region so we combine this cue with that of the presence of peak of contour energy derived from output of oddand even symmetric oriented gaussian derivative filter each of these cue ha a domain of applicability so to facilitate cue combination we introduce a gating operator based on a statistical test for isotropy of delaunay neighbor having obtained a local measure of how likely two nearby pixel are to belong to the same region we use the spectral graph theoretic framework of normalized cut to find partition of the image into region of coherent texture and brightness experimental result on a wide range of image are shown 
in this paper we discus work on the use of diffusion tensor mri for inter subject brain matching a multiresolution elastic matching a lgorithm for s patial normalisation of d image data ha been adapted for use with diffusion tensor data the hope is that by exploitation of the added information contained in the diffusion tensor image improved anatomical match can be found particularly in white matter r egions of the brain result show that by matching on the diffusion tensor alone anisotropic region of the brain white matter are aligned better than if the match is computed on standard structural data however there is a cost of some accuracy in the alignment of prominent feature in more conventional structural mri data such a s pd t and t weighted imagery if both type of data to d rive the matching process prominent feature in both image can be aligned simultaneously the motivation for this work lie in the characterisation of t he distribution of brain image taken from population group 
this paper present a computational paradigm called data driven markov chain monte carlo ddmcmc for image segmentation in the bayesian statistical framework the paper contributes to image segmentation in three aspect firstly it design effective and well balanced markov chain dynamic to explore the solution space and make the split and merge process reversible at a middle level vision formulation thus it achieves globally optimal solution independent of initial segmentation secondly instead of computing a single maximum a posteriori solution it proposes a mathematical principle for computing multiple distinct solution to incorporates intrinsic ambiguity in image segmentation a k adventurer algorithm is proposed for extracting distinct multiple solution from the markov chain sequence thirdly it utilizes data driven bottom up technique such a clustering and edge detection to compute importance proposal probability which effectively drive the markov chain dynamic and achieve tremendous speedup in comparison to traditional jump diffusion method thus ddm cmc paradigm provides a unifying framework where the role of existing segmentation algorithm such a edge detection clustering region growing split merge snake region competition are revealed a either realizing markov chain dynamic or computing importance proposal probability we report some result on color and grey level image segmentation in this paper and refer to a detailed report and a web site for extensive discussion 
in this paper we propose a method for generating realistic shadow of virtual object inserted into a real video sequence our aim is to improve and extend the work of sato sato and ikeuchi which is based on a static camera to the case of a video sequence this extension consists of several procedure calibration of a moving video camera and a graphic camera removing false shadow occurring due to a shortcoming of the static camera approach for the estimation of an illumination distribution and so on the calibration of the moving camera is solved by camera self calibration and with it we designed a flexible graphic world coordinate system embedding technique called match move we also show that the shortcoming of the previous static camera approach is overcome by using information from video sequence finally we present the experimental result of a real video sequence 
the aim of this work is to index image in domain specific database using color computed from the object of interest only instead of the whole image the main problem in this task is the segmentation of the region of interest from the background viewing segmentation a a figure ground segregation problem lead to a new approach eliminating the background leaf the figure or object of interest to find possible object color we fir st find background color and eliminate them we then use an edge image at an appropriate scale to eliminate those part of the image which are not in focus and do not contain contain significant structure the edge information is combined with the color based background elimination to produce object figure region we test our approach on a database of bird image we show that in of bird image tested the segmentation is sufficient to determine the color of the bird correctly for retrieval purpose we also show that our approach provides improved retrieval performance 
a comprehensive novel multi view dynamic face model is presented in this paper to address two challenging problem in face recognition and facial analysis modelling face with large pose variation and modelling face dynamically in video sequence the model consists of a sparse d shape model learnt from d image a shape and pose free texture model and an affine geometrical model model fitting is performed by optimising a global fitting criterion on the overall face appearance while it change across view and over time a local fitting criterion on a set of landmark and a temporal fitting criterion between successive frame in a video sequence by temporally estimating the model parameter over a sequence input the identity and geometrical information of a face is extracted separately the former is crucial to face recognition and facial analysis the latter is used to aid tracking and aligning face we demonstrate the result of successfully applying this model on face with large variation of pose and expression over time 
we present a simple approach to combining scene and auto calibration constraint for the calibration of camera from single view and stereo pair calibration constraint are provided by imaged scene structure such a vanishing point of orthogonal direction or rectified plane in addition constraint are available from the nature of the camera and the motion between view we formulate these constraint in term of the geometry of the imaged absolute conic and it relationship to pole polar pair and the imaged circular point of plane three significant advantage result first constraint from scene feature camera characteristic and auto calibration constraint providelinear equation in the element of the image of the absolute conic this mean that constraint may easily be combined and their solution is straightforward second the degeneracy that occur when constraint are not independent may be easily identified lastly the constraint from scene plane and image plane may be treated uniformly example of various case of constraint combination and degeneracy a well a computational technique are presented 
in this paper we extend the notion of affine shape introduced by sparr from finite point set to curve the extension make it possible to reconstruct d curve up to projective transformation from a number of their dprojections we also extend the bundle adjustment technique from point feature to curve the first step of the curve reconstruction algorithm is based on affine shape is independent of choice of coordinate robust doe not rely on any preselected parameter and work for an arbitrary number of image in particular this mean that a solution is given to the aperture problem of finding point correspondence between curve the second step take advantage of any knowledge of measurement error in the image this is possible by extending the bundle adjustment technique to curve finally experiment are performed on both synthetic and real data to show the performance and applicability of the algorithm 
optimal missing data estimation algorithm including deblurring and denoising are designed to restore image captured from large ccd sensor array using a butting technique where to column of data are missed at the butting edge we developed a consistency method with separable deblurring to estimate the missing data this method convert an ill posed restoration problem into a well posed one by making few assumption based on regularization theory under the condition that no noise is inserted and the separable blur kernel is exactly known the consistency method can deblur the original image and at the same time estimate the missing column s exactly however this algorithm becomes unstable when large noise is inserted or inaccurate estimation of the blur kernel is made conditioning analysis is used to quantify the amount of ill condition of the blur kernel when the assumption are relaxed to different level which provides a solid measurement on how stable the system will remain knowing the signal to noise ratio and the inaccuracy of the blur kernel estimation experimental result from different approach are compared 
this paper explores several approach for articulatedpose estimation assuming that video rate depth information is available from either stereo camera or other sensor we use these depth measurement in the traditional linear brightness constraint equation a well a in a depth constraint equation to capture the joint constraint we combine the brightness and depth constraint with twist mathematics we address several important issue in the formation of the constraint equation including updating the body rotation matrix without using a first order matrix approximation and removing the coupling between the rotation and translation update the resulting constraint equation are linear on a modified parameter set after solving these linear constraint there is a single closedform non linear transformation to return the update to the original pose parameter we show result for tracking body pose in oblique view of synthetic walking sequence and in moving camera view of synthetic jumping jack sequence we also show result for tracking body pose in side view of a real walking sequence 
in this paper we present an algorithm for robust absolute position estimation in natural terrain based on landmark extracted from dense surface our landmark are constructed by concatenating pose dependent oriented surface point with pose invariant surface signature into a single feature vector this definition of landmark allows a priori pose information to be used to constrain the search for landmark match the first step in our algorithm is to extract landmark from stable and salient surface patch these landmark are then stored in a closest point search structure with which landmark are matched eficiently using available pose constraint and invariant value finalb an iterative pose estimation algorithm based on least median square is wrapped around landmark matching to eliminate outlier and estimate absolute position to validate our algorithm we show hundred of absolute position estimation result from three different natural scene these result show that our algorithm can incorporate constraint on position and attitude for eficient landmark matching and match small and dense scene surface patch to large and coarse model surface 
hidden markov model hmms are increasingly being used in computer vision for application such a gesture analysis action recognition from video and illumination modeling their use involves an off line learning step that is used a a basis for on line decision making i e a stationarity assumption on the model parameter but realworld application are often non stationary in nature this lead to the need for a dynamic mechanism to learn and update the model topology a well a it parameter this paper present a new framework for hmm topology and parameter estimation in an online dynamic fashion the topology and parameter estimation is posed a a model selection problem with an mdl prior online modification to the topology are made possible by incorporating a state splitting criterion to demonstrate the potential of the algorithm the background modeling problem is considered theoretical validation and real experiment are presented 
the engineering of computer vision system that meet application specific computational and accuracy requirement is crucial to the deployment of real life computer vision system this paper illustrates how past work on a systematic engineering methodology for vision system performance characterization can be used to develop a real time people detection and zooming system to meet given application requirement we illustrate that by judiciously choosing the system module and performing a 
this paper describes a framework for learning probabilistic model of object and scene and for exploiting these model for tracking complex deformable or articulated object in image sequence we focus on the probabilistic tracking of people and learn model of how they appear and move in image in particular we learn the likelihood of observing various spatial and temporal filter response corresponding to edge ridge and motion difference given a model of the person similarly we learn probability distribution over filter response for general scene that define a likelihood of observing the filter response for arbitrary background we then derive a probabilistic model for tracking that exploit the ratio between the likelihood that image pixel corresponding to the foreground person were generated by an actual person or by some unknown background the paper extends previous work on learning image statistic and combine it with bayesian tracking using particle filtering by combining multiple image cue and by using learned likelihood model we demonstrate improved robustness and accuracy when tracking complex object such a people in monocular image sequence with cluttered scene and a moving camera 
we investigate the use of linear and nonlinear principal manifold for learning low dimensional representation for visual recognition three technique principal component analysis pca independent component analysis ica and nonlinear pca nlpca are examined and tested in a visual recognition experiment using a large gallery of facial image from the feret database we compare the recognition performance of a nearest neighbor matching rule with each principal manifold representation to that of a maximum a posteriori map matching rule using a bayesian similarity measure derived from probabilistic subspace and demonstrate the superiority of the latter 
to account for the variability of object appearance due to difference in illumination attention ha recently been focused on representing the set of image for all possible lighting condition approach that address this problem have primarily focused on lighting difference for diffuse reflection using the lambertian model however specular reflection can additionally present considerable disparity in appearance we present a method for representing illumination appearance for both diffuse and specular reflection for object of uniform surface roughness using four photometric image this approach us separation of reflection component extract surface reflectance and roughness and produce arbitrary lighting image without explicit computation of surface shape experimental result demonstrate the validity of the proposed method for constructing diffuse and specular appearance 
o disambiguate the paper from the projectedimage at previous time step finally the two fold ambiguityin the paper orientation ha to be resolved see figure detected quot top quot edgeclipboard projected edge removed detectededgesfigure paper detection the camera see the paperand the projected image from the previous step theorientation of the paper is ambiguous without the clipboard to solve these problem we have developed a paperdetection algorithm that take 
the computation of optical flow is a well studied topic in biological and computational vision however the existence of multiple motion in dynamic imagery due to occlusion or even transparency still raise challenging question in this paper we propose an approach for the detection and characterization of occlusion and transparency we propose a theoretical framework for both type of multiple motion which explicitly show the difference between occlusion and transparency in the frequency domain then we employ an em algorithm for the computation of one or two image velocity and a simple test for the detection of occlusion our approach differs from other em approach which blindly assume the superposition of two model in the spatial domain without providing with a separate formal model for occlusion we test and compare the characterization performance on synthetic and real data 
the paper address the problem of class based image based recognition and rendering with varying illumination the rendering problem is defined a follows given a single input image of an object and a sample of image with varying illumination condition of other object of the same general class re render the input image to simulate new illumination condition the class based recognition problem is similarly defined given a single image of an object in a database of im age of other object some of them are multiply sampled under varying illumination identify match any novel image of that object under varying illumination with the single image of that object in the database we focus on lambertian surface class and in particu lar the class of human face the key result in our approach is based on a definition of an illumination invariant signature im age which enables an analytic generation of the image space with varying illumination we show that a small database of object in our experiment a few a two object is suffi cient for generating the image space with varying illumination of any new object of the class from a single input image of that object in many case the recognition result outperform by far conventional method and the re rendering is of remark able quality considering the size of the database of example image and the mild pre process required for making the algo rithm work 
there is general consensus that context can be a rich source of information about an object s identity location and scale however the issue of how to formalize contextual influence is still largely open here we introduce a simple probabilistic framework for modeling the relationship between context and object property we represent global context information in term of the spatial layout of spectral component the resulting scheme serf a an effective procedure for context driven focus of attention and scale selection on real world scene based on a simple holistic analysis of an image the scheme is able to accurately predict object location and size 
video telephony could be considerably enhanced by provision of a tracking system that allows freedom of movement to the speaker while maintaining a well framed image for transmission over limited bandwidth already commercial multi microphone system exist which track speaker direction in order to reject background noise stereo sound and vision are complementary modality in that sound is good for initialisation where vision is expensive whereas vision is good for localisation where sound is le precise using generative probabilistic model and particle filtering we show that stereo sound and vision can indeed be fused effectively to make a system more capable than with either modality on it own 
many problem in computer vision require estimation of both model parameter and boundary which limit the usefulness of standard estimation technique from statistic exampleproblems include surface reconstructionfrom range data estimation of parametric motion model fitting circular or elliptic arc to edgel data and many others this paperintroducesa new estimationtechnique called the domain bounding m estimator which is a generalization of ordinary m estimatorscombiningerror measure on model parameter and boundary in a joint robust objective function minimization of the objective function given a rough initialization yield simultaneous estimate of parameter and boundary the dbm estimator ha been applied to estimating line segment surface and the symmetry transformation between two edgel chain it is unaffected by outlier and prevents boundary estimate from crossing even small magnitude discontinuity 
magnetic resonance imaging mri of the brain followed by automated segmentation of the corpus callosum cc in midsagittal section have important application in both clinical neurology and neurocognitive research since the size and shape of the cc are shown to be correlated to sex age neurodegenerative disease and various lateralized behavior in man moreover whole head multispectral d mri recording enable voxel based tissue classification and estimation of total brain volume in addition to cc morphometric parameter we propose a new algorithm that us both multispectral mri measurement intensity value and prior information about shape cc template to segment cc in midsagittal slice with very little user interaction the algorithm ha been tested on a sample of subject scanned with multispectral d mri collected for a study of dyslexia with very good agreement between the manually traced true cc outline and the detected cc outline we conclude that the proposed method for cc segmentation is promising for clinical use when multispectral mr image are recorded 
we present a novel efficient initialization free approach to the problem of epipolar geometry estimation by formulating it a one of hyperplane inference from a sparse and noisy point set in an d space given a set of noisy point correspondence in two image a obtained from two view of a static scene without correspondence even in the presence of moving object our method pull out inlier match while rejecting outlier unlike most method which optimize certain objective function our approach doe not involve initialization or any search in the parameter space and therefore is free of the problem of local optimum or poor convergence since no search is involved it is unnecessary to impose simplifying assumption such a affine camera or local planar homography to the scene being analyzed for reducing the search complexity subject to the general epipolar constraint only we detect wrong match by establishing salient extremalities via a naval approach d tensor voting the input set of match is first transformed into a sparse and discrete d point set dense tensor kernel are then applied to vote for the most salient hyperplane normal and intercept that capture all inliers inherent in the input with this filtered set of match the normalized eight point algorithm suffices for the accurate estimation of the fundamental matrix by using efficient data structure and locality our method is both time and space efficient despite the higher dimensionality we demonstrate the general usefulness of our method using example image pair i for aerial image analysis ii with widely different view and iii from non static d scene e g basketball game in an indoor stadium each example contains a considerable amount of wrong match 
many study have been made in the past for optimization using covariance matrix of feature point we first describe how to compute the covariance matrix of a feature point from the gray level by integrating existing method then we experimentally examine if thus computed covariance matrix really reflect the accuracy of the feature point to test this we do subpixel template matching and compute the homography and the fundamental matrix our conclusion is rather surprising pointing out important element often overlooked 
this paper present a linear algorithm for the simultaneous computation of d point and camera position from multiple perspective view based on having four point on a reference plane visible in all view the reconstruction and camera recovery is achieved in a single step by finding the null space of a matrix using singular value decomposition unlike factorization algorithm the presented algorithm doe not require all point to be visible in all view by simultaneously reconstructing point and view the numerically stabilizing effect of having wide spread camera with large mutual baseline is exploited experimental result are presented for both finite and infinite reference plane an especially interesting application of this method is the reconstruction of architectural scene with the reference plane taken a the plane at infinity which is visible via three orthogonal vanishing point this is demonstrated by reconstructing the outside and inside courtyard of a building on the basis of view in one single svd 
we have developed a system for detecting and tracking human face and eye in an unstructured environment we adopt a biologically plausible retinally connected neural network architecture and integrate it with an active vision system while the active vision system track the object moving in real time and the neural network detects the face and eye location from the video stream at a slower rate this paper provides a systematic way of creating and selecting example for training the network by exploring the link between theory and practice experimental result on real sequence of image from a space varying sensor depicts the performance of the system 
we show that the set of all flow field in a sequenceof frame imaging a rigid scene resides in a lowdimensionallinear subspace based on this observation we develop a method for simultaneous estimationof optical flow across multiple frame which us thesesubspace constraint the multi frame subspace constraintsare strong constraint and replace commonlyused heuristic constraint such a spatial or temporalsmoothness the subspace constraint are geometricallymeaningful and are 
a parametric camera model and calibration procedure are developed for an outdoor active camera system with pan tilt and zoom control unlike traditional method active camera motion play a key role in the calibration process and no special laboratory setup are required intrinsic parameter are estimated automatically by fitting parametric model to the optic flow induced by rotating and zooming no knowledge of d scene structure is needed extrinsic parameter are calculated by actively rotating the camera to sight a sparse set of surveyed landmark over a virtual hemispherical field of view yielding a well conditioned pose estimation problem 
camera pose estimation is the problem of determining the position and orientation of an internally calibrated camera from known d reference point and their image we briefly survey several existing method for pose estimation then introduce four new linear algorithm the first three give a unique linear solution from four point by svd null space estimation they are based on resultant matrix the method is the raw resultant matrix and the and method are compressed version of this obtained by gaussian elimination with pivoting on constant entry the final method return the four intrinsic solution to the pose from point problem it is based on eigendecomposition of a matrix one advantage of all these method is that they are simple to implement in particular the matrix entry are simple function of the input data numerical experiment are given comparing the performance of the new algorithm with several existing algebraic and linear method 
in principle the recovery and reconstruction of a d object from it d view projection require the parameterisation of it shape structure and surface reflectance property explicit representation and recovery of such d information is notoriously difficult to achieve alternatively a linear combination of d view can be used which requires the establishment of dense correspondence between view this in general is difficult to compute and necessarily expensive in this paper we examine the use of affine and local feature based transformation in establishing correspondence between very large pose variation in doing so we utilise a generic view template a generic d surface model and kernel pca for modelling shape and texture nonlinearities across view the ability of both approach to reconstruct and recover face from any d image are evaluated and compared 
scene flow is the d motion field of point in the world given n n image sequence gathered with a n eye stereo camera or n calibrated camera we present a novel system which integrates d scene flow and structure recovery in order to complement each other s performance we do not assume rigidity of the scene motion thus allowing for non rigid motion in the scene in our work image are segmented into small region we assume that each small region is undergoing similar motion represented by a d affine model nonlinear motion model fitting based on both optical flow constraint and stereo constraint is then carried over each image region in order to simultaneously estimate d motion correspondence and structure to ensure the robustness several regularization constraint are also introduced a recursive algorithm is designed to incorporate the local and regularization constraint experimental result on both synthetic and real data demonstrate the effectiveness of our integrated d motion and structure analysis scheme 
computer perception of biological motion is key to developing convenient and powerful human computer inter face successful body tracking algorithm have been developed however initialization is done by hand we propose a method for detecting a moving human body and for labeling it part automatically it is based on maximizing the joint probability density function pdf of the position and velocity of the body part the pdf is estimated from training data dynamic programming is used for calculating efficiently the best global labeling on an approximation of the pdf the computational cost is on the order of n where n is the number of feature detected we explore the performance of our method with experiment carried on a variety of periodic and non periodic body motion viewed monocularly for a total of approximately frame point marker were strapped to the joint of the subject for facilitating image analysis we find an average of labeling error the experiment also suggest a high degree of viewpoint invariance 
introductionwe demonstrate a self calibrating system that employ uncalibratedcameras and microportable projector to createnovel interactive display and presentation three benefitsof our system are detailed in the following section automatic keystone correctionthe image generated by an off center projector appearsdistorted figure left using an uncalibrated camerapointed at the presentation screen our system automaticallyrecovers the projector to screen homography 
this paper proposes a method for obtaining surface orientationsof transparent object using polarization in highlight since the highlight the specular component of reflectionlight from object is observed only near the speculardirection it appears merely limited part on an objectsurface in order to obtain orientation of a whole objectsurface we employ a spherical extended light source thispaper report it experimental apparatus a shape recoveryalgorithm and it performance 
a procedure for the parameterization of surface mesh of object with spherical topology is presented the generation of such a parameterization ha been formulated and solved a a large constrained optimization problem by brechb hler but the convergence of this algorithm becomes unstable for object mesh consisting of several thousand vertex we propose a new more stable algorithm to overcome this problem using multi resolution mesh 
in this paper we address the problem of structure and motion recovery from two view of a scene containing plane i e set of coplanar point most of the existing work do only exploit this constraint in a sub optimal manner we propose to parameterize the structure of such scene with plane and point on plane and derive the mle maximum likelihood estimator using a minimal parameterization based on d entity the result is the estimation of camera motion and d structure in projective space that minimizes reprojection error while satisfying the piecewise planarity we propose a quasi linear estimator that provides reliable initialization value for plane equation experimental result show that the reconstruction is of clearly superior quality compared to traditional method based only on point even if the scene is not perfectly piecewise planar 
we address an open and hitherto neglected problem in computer vision how to reconstruct the geometry of object with arbitrary and possibly anisotropic bidirectional reflectance distribution function brdfs present reconstruction technique whether stereo vision structure from motion laser range finding etc make explicit or implicit assumption about the brdf here we introduce two method that were developed by re examining the underlying image formation process the method make no assumption about the object s shape the presence or absence of shadowing or the nature of the brdf which may vary over the surface the first method take advantage of helmholtz reciprocity while the second method exploit the fact that the radiance along a ray of light is constant in particular the first method us stereo pair of image in which point light source are co located at the center of projection of the stereo camera the second method is based on double covering a scene s incident light field the depth of surface point are estimated using a large collection of image in which the viewpoint remains fixed and a point light source illuminates the object result from our implementation lend empirical support to both technique 
the goal of this paper is to present an appropriate method for the segmentation of line at intersection x junction and branch t junction which can be regarded a local region where line occur at multiple orientation a novel representation called orientation space is proposed which is derived by adding the orientation axis to the abscissa and the ordinate of the image the orientation space representation is constructed by treating the orientation parameter to which gabor filter can be tuned a a continuous variable the problem of segmenting line at multiple orientation is dealt with by thresholding d image in the orientation space and then detecting the connected component therein in this way x junction and t junction can be separated effectively curve grouping can also be accomplished the segmentation of mathematically modeled x t and l junction is demonstrated and analyzed the sensitivity limit of the method are also discussed experimental result using both synthesized and real image show the method to be effective for junction segmentation and curve grouping 
in this paper we describe a new method for medical image registration the registration is formulated a a minimization problem involving robust estimator we propose an efficient hierarchical optimization framework which is both multiresolution and multigrid an anatomical segmentation of the cortex is introduced in the adaptive partitioning of the volume on which the multigrid minimization is based this allows to limit the estimation to the area of interest to accelerate the algorithm 
some issue in marker le tracking of human body motion are addressed extended kalman filter have commonly been applied to kinematic variable to combine prediction consistent with plausible motion with the incoming stream of visual measurement kalman filtering is applicable only when the underlying distribution is approximately gaussian often this assumption prof remarkably robust there are two pervasive circumstance under which the gaussianity assumption can break down the first is kinematic singularity and the second is at joint end stop failure of kalman filtering under these circumstance is illustrated the non gaussian nature of the distribution is demonstrated experimentally by mean of monte carlo simulation random simulation particle filtering or condensation prof to provide a robust alternative algorithm for tracking that can also deal with these difficult condition 
we propose a novel method for temporally and spatially corresponding moving object by automatically learning the relevance of the object appearance feature to the task of discrimination efficient correspondence is achieved by enforcing temporal consistency of the relevance for a particular object relevance are learned using a technique we have termed differential discriminative diagnosis an agent is assigned to each moving object in the scene the agent posse the basic capability to decide whether or not an object in the scene is the one it represents each agent customizes itself to the object by mean of differential discriminative diagnosis a the object persists in the scene we explain this correspondence scheme a applied to the task of corresponding moving people in a surveillance system 
real image a realistic image can be generated how ever almost all of the ibr approach are classi ed a a photometric image based rendering pibr con 
we propose a model of appearance and a matching method which combine global model in which a few parameter control global appearance with local elastic or optical flow based method in which deformation is described by many local parameter together with some regularisation constraint we use an active appearance model aam a the global model which can match a statistical model of appearance to a new image rapidly however the amount of variation allowed is constrained by the mode of the model which may be too restrictive for instance when insufficient training example are available or the number of mode is deliberately truncated for efficiency or memory conservation to compensate for this after global aam convergence we allow further local model deformation driven by local aams around each model node this is analogous to optical flow or demon method of non linear image registration we describe the technique in detail and demonstrate that allowing this extra freedom can improve the accuracy of object location with only a modest increase in search time we show the combined method is more accurate than either pure local or pure global model search 
this paper address the problem of reliablyestimating the coe cients of the parameterized image variety piv associated with the set of weak perspectiveimages of a rigid scene with application in image basedrendering exploiting the fact that the constraint deningthe piv are linear in it coe cients and bilinear in the imagedata the estimation procedure is cast in the error invariablesframework and solved using the method proposedin for this type of problem the 
in binocular stereo matching point in left and right image are matched according to feature that characterize each point and identify pair of point when one try to use multiple feature a difficult problem is which feature or combination of feature to use moreover feature are difficult to crossnormalize and so comparison must take into account not only their output but also their distribution their output for different parameter we present a new approach that us geometric constraint on the matching surface to select optimal feature or combination of feature from multiscale edge and intensity feature the approach requires the cyclopean coordinate system to set mutually exclusive matching choice to obtain the matching surface we solve a global optimization problem on an energy functional that model occlusion discontinuity and interepipolar line interaction 
a new method for real time tracking of non rigid objectsseen from a moving cameraisproposed the centralcomputational module is based on the mean shiftiterations and find the most probable target position inthe current frame the dissimilarity between the targetmodel it color distribution and the target candidatesis expressed by a metric derivedfrom the bhattacharyyacoefficient the theoretical analysis of the approachshows that it relates to the bayesian framework whileproviding a 
this paper present nonstationary markovian model and their application to recognitionof string of token such a zip code in the u mailstream unlike traditionalapproaches where digit are simply recognized in isolation the novelty of our approachlies in the manner in which recognition score or probability value along with domainspecific knowledge about the frequency distribution of various combination of digit areall integrated into one unified model the domain specific 
in this paper we show that given two homography matrix for two plane in space there is a linear algorithm for the rotation and translation between the two camera the focal length of the two camera and the plane equation in the space using the estimate a an initial guess we can further optimize the solution by minimizing the difference between observation and reprojections experimental result are shown we also provide a discussion about the relationship between this approach and the kruppa equation 
spectral analysis provides a powerful mean of estimating the perspective pose of texture plane unfortunately one of the problem that restricts the utility of the method is the need to set the size of the spectral window for texture plane viewed under extreme perspective distortion the spectral frequency density may vary rapidly across the image plane if the size of the window is mismatched to the underlying texture distribution then the estimated frequency spectrum may become severely defocussed this in turn limit the accuracy of perspective pose estimation the aim in this paper is to describe an adaptive method for setting the size of the spectral window we provide an analysis which show that there is a window size that minimises the degree of defocusing the minimum is located through an analysis of the spectral covariance matrix we experiment with the new method on both synthetic and real world imagery this demonstrates that the method provides accurate pose angle estimate even when the slant angle is large we also provide a comparison of the accuracy of perspective pose estimation that result both from our adaptive scale method and with one of fixed scale 
we present a new model based bundle adjustment algorithm to recover the d model of a scene object from a sequence of image with unknown motion instead of representing scene object by a collection of isolated d feature usually point our algorithm us a surface controlled by a small set of parameter compared with previous model based approach our approach ha the following advantage first instead of using the model space a a regularizer we directly use it a our search space thus resulting in a more elegant formulation with fewer unknown and fewer equation second our algorithm automatically associate tracked point with their correct location on the surface thereby eliminating the need for a prior d to d association third regarding face modeling we use a very small set of face metric meaningful deformation to parameterize the face geometry resulting in a smaller search space and a better posed system experiment with both synthetic and real data show that this new algorithm is faster more accurate and more stable than existing one 
by using mirror reflection of a scene stereo image can be captured with a single camera catadioptricstereo single camera stereo provides both geometric and radiometric advantage over traditional two camera stereo in this paper we discus the geometryand calibration of catadioptric stereo with two planar mirror and show how the relative orientation the epipolar geometry and the estimation of the focal length are constrained by planar motion in addition we have implementeda real time system which demonstrates the viability of stereo with mirror a an alternative to traditional two camera stereo 
this paper introduces a novel statistical mixture model for probabilistic grouping of distributional histogram data adopting the bayesian framework we propose to perform annealed maximum a posteriori estimation to compute optimal clustering solution in order to accelerate the optimization process an efficient multiscale formulation is developed we present a prototypical application of this method for the unsupervised segmentation of textured image based on local distribution of gabor 
many motion detection and tracking algorithm rely on the process of background subtraction a technique which detects change from a model of the background scene we present a new algorithm for the purpose of background model initialization the algorithm take a input a video sequence in which moving object are present and output a statistical background model describing the static part of the scene multiple hypothesis of the background value at each pixel are generated by locating period of stable intensity in the sequence the likelihood of each hypothesis is then evaluated using opticalow information from the neighborhood around the pixel and the most likely hypothesis is chosen to represent the background our result are compared with those of several standard background modeling technique using surveillance video of human in indoor environment 
we will demonstrate our cvpr paper measurement of color invariant for the case of image retrieval based on query by example and for color image segmentation both are of importance in content based access of image and video data we demonstrate the usefulness of the proposed color invariant in image retrieval by example system we show that an image retrieval query should include the type of invariance expected in the result we demonstrate such query by using the imagesurf retrieval system segmentation of image based on the proposed color invariant is demonstrated by the pictovision system the system provides image processing functionality through the world wide web and is publicly accessible at www science uva nl research isi pictovision html 
a novel trainable snake model called eigensnake is presented in the bayesian framework in the eigensnake prior knowledge of a specific object shape such a that of face outline and facial feature is derived from a training set of the shape and incorporated into a bayesian snake model in the form of the prior distribution further a shape space which is constructed on the basis of a set of eigenvectors obtained from principle component analysis is used to restrict and stabilize the search for the optimal solution the effectiveness is demonstrated by experiment which show that the eigensnake produce more reliable and accurate result than existing model 
we develop a framework for d shape and motion recovery of articulated deformable object we propose a formalism that incorporates the use of implicit surface into earlier robotics approac he that were designed to handle articulated structure w e demonstrate it effectiveness for human body modeling fr om video sequence our method is both robust and generic it could easily be applied to other shape and motion recovery problem 
many natural image contain reflection and transparency i e they contain mixture of reflected and transmitted light when viewed from a moving camera these appear a the superposition of component layer image moving relative to each other the problem of multiple motion recovery ha been previously studied by a number of researcher however no one ha yet demonstrated how to accurately recover the component image themselves in this paper we develop an optimal approach to recovering layer image and their associated motion from an arbitrary number of composite image we develop two different technique for estimating the component layer image given known motion estimate the first approach us constrained least square to recover the layer image the second approach iteratively refines lower and upper bound on the layer image using two novel compositing operation namely minimumand maximum composite of aligned image we combine these layer extraction technique with a dominant motion estimator and a subsequent motion refinement stage this result in a completely automated system that recovers transparent image and motion from a collection of input image 
we consider the problem of reconstructing the location of a moving d point seen from a monocular moving camera i e to reconstruct moving object from line of sight measurement only since the point is moving while the camera is moving then even if the camera motion is known it is impossible to reconstruct the d location of the point under general circumstance however we show that if the point is moving along a straight line then the parameter of the line and hence the d position of the point at each time instance can be uniquely recovered and by linear method from at least view consequently we propose a new approach for dealing with dynamic scene rich with moving object in which once the camera motion is recovered the d trajectory straight line of the moving target can be recovered even when the moving target consists of a single point 
corner model in the literature have lagged behind edge model with respect to color and shading we use both a region model based on distribution of pixel color and an edge model which remove false positive to perform corner detection on color image whose region contain texture we show result on a variety of natural image at different scale that highlight the problem that occur when boundary between region have curvature 
this paper present a variational method for supervised texture segmentation which is based on idea coming from the curve propagation theory we assume that a preferable texture pattern is known e g the pattern that we want to distinguish from the rest of the image the textured feature space is generated by filtering the input and the preferable pattern image using gabor filter and analyzing their response a multi component conditional probability density function the texture segmentation is obtained by minimizing a geodesic active contour model objective function where the boundary based information is expressed via discontinuity on the statistical space associated with the multi modal textured feature space this function is minimized using a gradient descent method where the obtained pde is implemented using a level set approach that handle naturally the topological change finally a fast method is used for the level set implementation the performance of our method is demonstrated on a variety of synthetic and real textured image 
we propose to incorporate a priori geometric constraint in a d stereo reconstruction scheme to cope with the many case where image information alone is not sufficient to accurately recover d shape our approach is based on the iterative deformation of a d surface mesh to minimize an objective function we show that combining anisotropic meshing with a nonquadratic approach to regularization enables u to obtain satisfactory reconstruction result using triangulation with few vertex structural or numerical constraint can then be added locally to the reconstruction process through a constrained optimization scheme they improve the reconstruction result and enforce their consistency with a priori knowledge about object shape the strong description and modeling property of differential feature make them useful tool that can be efficiently used a constraint for d reconstruction nalizes large variation of the function to recover and tends to isotropically smooth the solution no matter what the true variation of the function ought to be this problem ha been especially addressed in the case of image restoration stereo reconstruction optical flow computation and motion estimation these approach however are image based whereas given the task of reconstructing a surface from multiple image whose vantage point may be very different we need a surface representation that can be used to generate image of the surface from arbitrary viewpoint taking into account selfocclusion self shadowing and other viewpoint dependent effect clearly a single image centered representation is inadequate for this purpose instead an object centered surface representation is required furthermore geometric constraint are typically easier to express in the d world which make the use of an object centered representation even more desirable 
a new tracker is presented two set are identified one which contains all possible curve a found in the im age and a second which contains all curve which characterize the object of interest the former is constructed out of edge point in the image while the latter is learned prior to running the tracked curve is taken to be the element of the first set which is nearest the second set the formalism for the learned set of curve allows for mathematically well understood group of transformation e g affine projective to be treated on the same footing a le well understood deformation which may be learned from training curve an algorithm is proposed to solve the tracking problem and it property are theoretically demonstrated it solves the global optimization problem and doe so with certain complexity bound experimental result applying the proposed algorithm to the tracking of a moving finger are presented and compared with the result of a condensation approach 
we develop a clas so f dif ferential motion tracker that automatically stabilize when in finite domain most differential tracker compute motion only relative to one previous frame accumulating error indefinitely we estimate pose change between a set of past frame and develop a probabilistic framework for integrating those estimate we use an approximation to the posterior distribution of pose change a an uncertainty model for parametric motion in order to help arbitrate the use of multiple base frame we demonstrate this framework on a simple d translational tracker and a d degree of freedom tracker 
wepresenttwo solution for the scale selection problemin computer vision the first one is completely nonparametricand is based on the the adaptive estimationof the normalized density gradient employing the samplepoint estimator we define the variable bandwidthmean shift prove it convergence and show it superiorityoverthe fixed bandwidth procedure the secondtechnique ha a semiparametric nature and imposes alocal structure on the data to extract reliable scale information the 
using a saliency measure based on the global property of contour closure we have developed a method that reliably segment out salient contour bounding unknown object from real edge image the measure also incorporates the gestalt principle of proximity and smooth continuity that previous method have exploited unlike previous measure we incorporate contour closure by finding the eigen solution associated with a stochastic process that model the distribution of contour passing through edge in the scene the segmentation algorithm utilizes the saliency measure to identify multiple closed contour by finding stronglyconnected component on an induced graph the determination of strongly connected component is a direct consequence of the property of closure we report for the first time result on large real image for which segmentation take an average of about sec per object on a general purpose workstation the segmentation is made efficient for such large image by exploiting the inherent symmetry in the task 
the compass operator detects step edge without assuming that the region on either side have constant color using distribution of pixel color rather than the mean the operator find the orientation of a diameter that maximizes the difference between two half of a circular window junction can also be detected by exploiting their lack of bilateral symmetry this approach is superior to a multidimensional gradient method in situation that often result in false negative and it localizes edge better a scale increase 
in his paper we introduce two improvement to the three dimensional gamut mapping approach to computational colour constancy this approach consist of two separate part first the possible solution are constrained this part is dependent on the diagonal model of illumination change which in turn is a function of the camera sensor in this work we propose a robust method for relaxing this reliance on the diagonal model the second part of the gamut mapping paradigm is to choose a solution from the feasible set currently there are two general approach for doing so we propose a hybrid method which embodies the benefit of both and generally performs better than either we provide result using both generated data and a carefully calibrated set of image in the case of the modification for diagonal model failure we provide synthetic result using two camera with a distinctly different degree of support for the diagonal model here we verify that the new method doe indeed reduce error due to the diagonal model we also verify that the new method for choosing the solution offer significant improvement both in the case of synthetic data and with real image 
we demonstrate d mode a software system that build d model of object and scene by taking a few minimally photograph using a digital camera at possibly largely separated position it ha recently been commercialized by d medium co ltd d mode ha the following step taking photo manually obtaining and matching a few feature point on the object automatically computing d structure and motion automatic delaunay triangulation and manual modification automatic acquisition of texture for each triangular patch if necessary assign a new coordinate system and scale of space the system doe not need input of camera parameter but requires manual input of feature point in a special manner such that matching information is input simultaneously once epipolar line are available they are used to help locate corresponding point in other image 
a non parametric method for texture synthesis is proposed the texture synthesis process grows a new image outward from an initial seed one pixel at a time a markov random field model is assumed and the conditional distribution of a pixel given all it neighbor synthesized so far is estimated by querying the sample image and finding all similar neighborhood the degree of randomness is controlled by a single perceptually intuitive parameter the method aim at preserving a much local structure a possible and produce good result for a wide variety of synthetic and real world texture 
this paper describes a structure from motion and recognition paradigm for generating d model from d set of image in particular we consider the domain of architectural photograph a model based approach is adopted with the architectural model built from a lego kit of parameterised part the approach taken is different from traditional stereo or shape from x approach in that identification of the parameterised component such a window door buttress etc from one image is combined with parallax information in order to generate the d model this model based approach ha two main benefit first it allows the inference of shape and texture where the evidence from the image is weak and second it recovers not only geometry and texture but also an interpretation of the model which can be used for automatic enhancement technique such a the application of reflective texture to window mrf prior usually fail to adequately account for occlusion or enforce to constraint between adjacent epipolar line whereas a model based approach doe both in this paper we propose a model based approach to structure from motion recovery in which prior on shape and texture are explicitly stated and used to overcome image ambiguity in previous work only the reprojection of the model into each image wa used for it verification whereas in this paper we propose that learnt statistic of the appearance of each model also be used to help determine the most appropriate model and hence the shape of the scene the combined use of correspondence and appearance data help to more accurately identify which model is most appropriate 
research on texture ha been pursued along two different line the first line of research pioneered by julesz seek the essential ingredient in term of feature and statistic in human texture perception this lead u to a mathematical definition of texture a a julesz ensemble a julesz ensemble is the maximum set of image that share the same value of some basic feature statistic a the image math or equivalently it is a uniform distribution on this set the second line of research study statistical model in particular markov random field mrf and frame model zhu wu and mumford to characterize texture pattern locally in this article we bridge the two line by the fundamental principle of equivalence of ensemble in statistical mechanic gibbs we prove that the conditional probability of an arbitrary image patch given it environment under the julesz ensemble or the uniform model is inevitably a frame mrf model and the limit of the frame mrf model which we called the gibbs ensemble is equivalent to a julesz ensemble a math thus the advantage of the two methodology can be fully utilized 
this paper present a new approach to track object in motion when observed by a fixed camera with severe occlusion merging splitting object and defect in the detection we first detect region corresponding to moving object in each frame then try to establish their trajectory we propose to implement the temporal continuity constraint efficiently and apply it to tracking problem in realistic scenario the method is based on a spatiotemporal d t representation of the moving region and us the tensor voting methodology to enforce smoothness in space and time of the tracked object although other characteristic may be considered only the connected component of the moving region are used without further assumption about the object being tracked we demonstrate the performance of the system on several real sequence 
a system for recovering d hand pose from monocular color sequence is proposed the system employ a non linear supervised learning framework the specialized mapping architecture sma to map image feature to likely d hand pose the sma s fundamental component are a set of specialized forward mapping function and a single feedback matching function the forward function are estimated directly from training data which in our case are example of hand joint configuration and their corresponding visual feature the joint angle data in the training set is obtained via a cyberglove a glove with sensor that monitor the angular motion of the palm and finger in training the visual feature are generated using a computer graphic module that render the hand from arbitrary viewpoint given the joint angle the viewpoint is encoded by two real value therefore real value represent a hand pose we test our system both on synthetic sequence and on sequence taken with a color camera the system automatically detects and track both band of the user calculates the appropriate feature and estimate the d hand joint angle and viewpoint from those feature result are encouraging given the complexity of the task 
in this paper we present a novel algorithm for adaptivefuzzy segmentation of mri data and estimation ofintensity inhomogeneity using fuzzy logic mri intensityinhomogeneities can be attributed to imperfectionsin the rf coil or some problem associated with theacquisition sequence the result is a slowly varyingshading artifact over the image that can produce errorswith conventional intensity based classification ouralgorithm is formulated by modifying the objectivefunction of the 
a framework for photo realistic view dependent image synthesis of a shiny object from a sparse set of image and a geometric model is proposed each image is aligned with the d model and decomposed intotwoimages with regard to the reflectance component based on the intensity variation of object surface point the view independent surface reflection diffuse reflection is stored a one texture map the view dependent reflection specular reflection image are used to recover the initial approximation of the illumination distribution and then a two step numerical minimization algorithm utilizing a simplified torrance sparrow reflection model is used to estimate the reflectance parameter and refine the illumination distribution this provides a very compact representation of the datanecessary to render synthetic image from arbitrary viewpoint we have conducted experiment with real object to synthesize photorealistic view dependent image within the proposed framework 
in human perception convex surface have a strong tendency to be perceived a the figure convexity ha a stronger influence on figural organization than other global shape property such a symmetry and yet there ha been very little work on convexity property in computer vision we present a model for figure ground segregation which exhibit a preference for convex region a the figure i e the foreground the model also show a preference for smaller region to be selected a figure which is also known to hold for human visual perception e g koffka the model is based on the machinery of markov random field random walk diffusion process so that the global shape property are obtained via local and stochastic computation experimental result demonstrate that our model performs well on ambiguous figure ground display which were not captured before in particular in ambiguous display where neither region is strictly convex the model show preference to the more convex region thus offering a continuous measure of convexity in agreement with human perception 
diabetic related eye disease are the most common cause of blindness in the world so far the most effective treatment for these eye disease is early detection through regular screening to lower the cost of such screening we employ state of the art image processing technique to automatically detect the presence of abnormality in the retinal image obtained during the screening the author focus on one of the abnormal sign the presence of exudate lesion in the retinal image we propose a novel approach that combine brightness adjustment procedure with statistical classification method and local window based verification strategy experimental result indicate that we are able to achieve accuracy in term of identifying all the retinal image with exudate while maintaining a accuracy in correctly classifying the truly normal retinal image a normal this translates to a huge amount of saving in term of the number of retinal image that need to be manually reviewed by the medical professional each year 
current system for object detection in video sequence rely on explicit dynamical model like kalman filter or hidden markov model there is significant overhead needed in the development of such system a well a the a priori assumption that the object dynamic can be described with such a dynamical model this paper describes a new pattern classification technique for object detection in video sequence that us a rich over complete dictionary of wavelet feature to describe an object class unlike previous work where a small subset of feature wa selected from the dictionary this system doe no feature selection and learns the model in the full dimensional feature space comparison using different sized set of several type of feature are given we extend this representation into the time domain without assuming any explicit model of dynamic this data driven approach produce a model of the physical structure and short time dynamical characteristic of people from a training set of example no assumption are made about the motion of people just that short sequence characterize their dynamic sufficiently for the purpose of detection one of the main benefit of this approach is that transient false positive are reduced this technique compare favorably with the static detection approach and could be applied to other object class we also present a real time version of one of our static people detection system 
a linear self calibration method is given for computing the calibration of a stationary but rotating camera the internal parameter of the camera are allowed to vary from image to image allowing for zooming change of focal length and possible variation of the principal point of the camera in order for calibration to be possible some constraint must be placed on the calibration of each image the method work under the minimal assumption of zeroskew rectangular pixel or the more restrictive but reasonable condition of square pixel known pixel aspect ratio and known principal point being linear the algorithm is extremely rapid and avoids the convergence problem characteristic of iterative algorithm 
diffusion process which are widely used in low level vision are presented a a result of an underlying stochastic process the short time non linear diffusion is interpreted a a fokker planck equation which governs the evolution in time of a probability distribution for a brownian motion on a riemannian surface the non linearity of the diffusion ha a direct relation to the geometry of the surface a short time kernel to the diffusion a well a generalization are found 
abstract this paper describes an approach to characterize camera and object motion based on the analysis of spatio temporal image volume in the spatio temporal slice of image volume motion is depicted a oriented pattern we propose a tensor histogram computation algorithm to represent these oriented pattern the motion trajectory in a histogram are tracked to de scribe both the camera and object motion in addition we exploit the similarity of the temporal slice in a vol ume to reliably partition a volume into motion tractable unit 
the motion of a planar surface between two camera view induces a homography the homography depends on the camera intrinsic and extrinsic parameter a well a on the d plane parameter while camera parameter vary across different view the plane geometry remains the same based on this fact we derive linear subspace constraint on the relative motion of multiple math plane across multiple view the paper ha three main contribution i we show that the collection of all relative homographies of a pair of plane homology across multiple view span a dimensional linear subspace ii we show how this constraint can be extended to the case of multiple plane across multiple view iii we suggest two potential application area which can benefit from these constraint a the accuracy of homography estimation can be improved by enforcing the multi view subspace constraint b violation of these multi view constraint can be used a a cue for moving object detection all the result derived in this paper are true for uncalibrated camera 
in cluster based segmentation pixel are mapped into various feature space whereupon they are subjected to a grouping algorithm in this paper we develop a robust and versatile non parametric clustering algorithm that is able to handle the unbalanced and irregular cluster encountered in such segmentationapplications the strength of our approach lie in the definition and use of two cluster validity index that are independent of the cluster topology by combining them an excellent clustering can be identified and experiment confirm that the associated cluster do indeed correspond to perceptually salient image region 
in this paper we present a novel method for finding the optimal affine transformation for matching of image the method requires no feature point doe not rely on normalization of image and can be tuned to highlight interesting part in the image furthermore the method doe not need any derivative for obtaining the affine transformation and it ha a computational cost proportional to n logn for n n image the problem of finding the optimal affine transformation is solved by an iterative algorithm in each step a global optimization is performed by the use of fft this global characteristic help the algorithm from getting trapped in a local optimum novel theoretical result are presented that show under what restriction the algorithm can be expected to work properly it intended primary use is for reconstruction problem in computer vision these rely heavily on the establishment of point correspondence in the image since the method make no assumption on the image it can be used when feature point are difficult to detect experiment on real image are included and it is shown that the algorithm is robust and performs well even in difficult situation with occlusion 
in this paper we describe a new region based approach to active contour for segmenting image composed of two or three type of region characterizable by a given statistic the essential idea is to derive curve evolution which separate two or more value of a predetermined set of statistic computed over geometrically determined subset of the image both global and local image information is used to evolve the active contour image derivative however are avoided thereby giving rise to a further degree of noise robustness compared to most edge based snake algorithm 
this paper make two contribution the first contribution is an approach called the customized query approach cqa to content based image retrieval the second is an algorithm called fssem that performs feature selection and clustering simultaneously the customizedqueries approach first classifies a query using the feature that best differentiate the major class and then customizes the query to that class by using the feature that best distinguish the image within the chosen major class this approach is motivated by the observation that the feature that are most effective in discriminating among image from different class may not be the most effective for retrieval of visually similar image within a class this occurs for domain in which not all pair of image within one class have equivalent visual similarity i e subclass exists because we are not given subclass label we must simultaneously find the feature that best discriminate the subclass and at the same time find these subclass we use fssem to find these feature we apply this approach to content based retrieval of high resolution tomographic image of patient with lung disease and show that this approach radically improves the retrieval precision over the traditional approach that performs retrieval using a single feature vector 
this paper address the problem of constructing the scale space aspect graph of a solid of revolution whose surface is the zero set of a polynomial volumetric density undergoing a gaussian diffusion process equation for the associated visual event surface are derived and polynomial curve tracing technique are used to delineate these surface an implementation and example are presented and limitation a well a extension of the proposed approach are discussed 
we address the problem of detection and tracking of moving object in a video stream obtained from a moving airborne platform the proposed method relies on a graph representation of moving object which allows to derive and maintain a dynamic template of each moving object by enforcing their temporal coherence this inferred template along with the graph representation used in our approach allows u to characterize object trajectory a an optimal path in a graph the proposed tracker allows to deal with partial occlusion stop and go motion in very challenging situation we demonstrate result on a number of different real sequence we then define an evaluation methodology to quantify our result and show how tracking overcome detection error 
we present a method to learn object class model forthe purpose of object recognition we focus on a particulartype of model where object are represented asconstellations of rigid feature part the variabilitywithin a class is represented by a joint probabilitydensity function pdf on the shape of the constellationand the output of feature detector the pdf maybe estimated from training data once a model structure type and number of feature ha been specied themethod 
this paper focus on the detection of object with lambertian surface under both varying dlumination and pose we offer to apply a novel detection method that proceeds by modeling the d erent illumination from a small number of image in the training set this automatically void the illumination effect allowing fast dlumination invariant detection without having to create a large training set it is demonstrated that the method t in nicely with previous work about the modeling oj the set of object appearance under varying illumination in the experiment an object wa correctly detected under image plane rotation in a degree range and a wide variety of dl erent illumination 
in a known environment object may be tracked in multiple view using a set of background model stereobased model can be illumination invariant but often have undefined value which inevitably lead to foreground classification error we derive dense stereo model for object tracking using long term extended dynamic range imagery and by detecting and interpolating uniform but unoccluded planar region foreground point are detected quickly in new image using pruned disparity search we adopt a late segmentation strategy using an integrate dp lan viewdensity representation foreground point are segmented into object region only when a trajectory is finally estimated using a dynamic programming based method object entry and exit are optimally determined and are not restricted to special spatial zone 
in this paper we introduce a statistic snake that learns and track image feature by mean of statistic learning technique using probabilistic principal component analysis a feature description is obtained from a training set of object profile in our approach a sound statistical model is introduced to define a likelihood estimate of the grey level local image profile together with their local orientation this likelihood estimate allows to define a probabilistic potential field of the snake where the elastic curve deforms to maximise the overall probability of detecting learned image feature to improve the convergence of snake deformation we enhance the likelihood map by a physic based model simulating a dipole dipole interaction a new extended local coherent interaction is introduced defined in term of extended structure tensor of the image to give priority to parallel coherence vector structure to cope with the appearance variance the search space is reduced by adding knowledge from the application domain obtaining better response from feature detector the global snake performance is increased in principal component analysis pca is used to model face shape and grey level image a limiting disadvantage of pca is the absence of a probability density model and an associated likelihood measure the need of a probability density framework is clearly present in problem where saliency is formulated in term of visual similarity the derivation of pca from a perspective of density estimation offer the advantage that the probability density function give a measure of the novelty of a new data point given the advantage of probabilistic pca ppca a a straightforward technique to construct statistic image feature description and snake a a global segmentation and tracking technique in this paper we propose a combination of these technique to track non rigid elongated object object profile are learned from a training set and a statistic classifier is constructed a a potential field of the snake the map is built in two step first a structure tensor is applied to assign a coherence direction to each pixel of the target image second image profile perpendicular to the coherence orientation are weighed by ppca defining a likelihood map therefore each point ha assigned a probability measure to belong to the learned feature category additionally we refine the likelihood map applying to the coherence direction field an extended local coherent detection between neighbour of the likelihood map a a function of derivative up to the second order we show that this detection prioritises region of pixel with parallel coherent direction improving the localisation of elongated structure a a result the refined likelihood map ha good response around the object while small amount of false response are observed to avoid false stationary state of the snake we introduce a hybrid potential map a a combination of refined likelihood map and distance map that assures slow movement far from the object and fast convergence when approaching the object of interest 
this paper describes a novel gabor feature class er gfc method for face recognition the gfc method employ an enhanced fisher discrimination model on an augmented gabor feature vector which is derived from the gabor wavelet transformation office image the gabor wavelet whose kernel are similar to the receptive field profile of the nianinialian cortical simple cell exhibit desirable characteristic of spatial locality and orientation selectivity a a result the gabor transformed face image produce salient local and discriminating feature that are suitable forface recognition the feasibility of the new gfc method ha been successfully tested on face recognition using feret frontal face image which involve different illumination and varied facial expression of subject the effectiveness of the novel gfc method is shown in ternis of both absolute performance index and comparative performance against some popular face recognition scheme such a the eigenfaces method and some other gabor wavelet based class cation method in particular the novel gfc method achieves recognition accuracy using only feature 
this paper introduces a new free form surface representation scheme for the purpose of fast and accurate registration and matching accurate registration of surface is a common task in computer vision the proposed representation scheme capture the surface curvature information seen from certain point and produce image called surface signature at these point matching signature of different surface enables the recovery of the transformation parameter between these surface we propose to use template matching to compare the signature image to enable partial matching another criterion the overlap ratio is used this representation scheme can be used a a global representation of the surface a well a a local one and performs near real time registration we show that the signature representation can be used to match object in d scene in the presence of clutter and occlusion application presented include free form object matching multimodal medical volume registration and dental teeth reconstruction from intra oral image 
this paper present a novel approach for model based realtime tracking of highly articulated structure such a human this approach is based on an algorithm which efciently propagates statistic of probability distribution through a kinematic chain to obtain maximum a posteriori estimate of the motion of the entire structure this algorithm yield the least square solution in linear time in the number of component of the model and can also be applied to non gaussian statistic using a simple but powerful trick the resulting implementation run in real time on standard hardware without any pre processing of the video data and can thus operate on live video result from experiment performed using this system are presented and discussed 
voxel occupancy is one approach for reconstructing the dimensional shape of an object from multiple view in voxel occupancy the task is to produce a binary labeling of a set of voxels that determines which voxels are filled and which are empty in this paper we give an energy minimization formulation of the voxel occupancy problem the global minimum of this energy can be rapidly computed with a single graph cut using a result due to greig porteous and seheult the energy function we minimize contains a data term and a smoothness term the data term is a sum over the individual voxels where the penalty for a voxel is based on the observed intensity of the pixel that intersect it the smoothness term is the number of empty voxels adjacent to filled one our formulation can be viewed a a generalization of silhouette intersection with two advantage we do not compute silhouette which are a major source of error and we can naturally incorporate spatial smoothness we give experimental result showing reconstruction from both real and synthetic imagery reconstruction using this smoothed energy function is not much more time consuming than simple silhouette intersection it take about second to reconstruct a one million voxel volume 
in this paper we present a novel approach for frontal face detection in gray scale image we represent both face and clutter by using two dimensional wavelet decomposition to characterize the statistical dependency between different level of wavelet we introduce a hidden markov model hmm in which a number of discrete state at each level capture the diversity of face a well a clutter our experiment indicate that the proposed algorithm outperforms conventional template based method such a matched filter and eigenface method 
the ability to efficiently and robustly recover accurate d terrain model from set of stereoscopic image is important to many civilian and military application our long term goal is to develop an automatic multi image d reconstruction algorithm that can be applied to these domain to develop an effective and practical terrain modeling system method must be found for detecting unreliable elevation in digital elevation map dems and for fusing several dems from multiple source into an accurate and reliable result this paper focus on two key factor for generating robust d terrain model the ability to detect unreliable elevation estimate and to fuse the reliable elevation into a single optimal terrain model the technique discussed in this paper are based on the concept of using self consistency to identify potentially unreliable point we apply the self consistency methodology to both the two image and multi image scenario we demonstrate that the recently developed concept of self consistency can be effectively employed to determine the reliability of value in a dem estimate with a reliability below an error threshold can be excluded from further processing we test the effectiveness of the methodology a well a the relationship between error rate and scene geometry by processing both real and photo realistic simulation 
the quest for a vision system capable of representing and recognizing arbitrary motion benefit from a low dimensional non specific representation of flow field to be used in high level classification task we present zernike polynomial a an ideal candidate for such a representation the basis of zernike polynomial is complete and orthogonal and can be used for describing many type of motion at many scale starting from image sequence locally smooth image velocity are derived using a robust estimation procedure from which are computed compact representation of the flow using the zernike basis continuous density hidden markov model are trained using the temporal sequence of vector thus obtained and are used for subsequent classification we present result of our method applied to image sequence of facial expression both with and without significant rigid head motion and to sequence of lip motion from a known database we demonstrate that the zernike representation yield result competitive with those obtained using principal component while not committing to specific type of motion it is therefore ideal a a fundamental building block for a vision system capable of classifying arbitrary motion type 
this paper present a d active contour model for boundary detection and tracking of non rigid object which applies stereo vision and motion analysis to the class of energy minimizing deformable contour model known a snake the proposed contour evolves in three dimensional space in reaction to a d potential function which is derived by projecting the contour onto the d stereo image the potential function is augmented by a kinetic term which is related to the velocity field along the contour this term is used to guide the inter image contour displacement the incorporation of inter frame velocity estimate in the tracking algorithm is especially important for contour which evolve in d space where the added freedom of motion can easily result in loss of tracking the proposed scheme incorporates local velocity information seamlessly in the snake model with little computational overhead and doe not require exogenous computation of the optical flow or related quantity in each image the resulting algorithm is shown to provide good tracking performance with only one iteration per frame which provides a considerable advantage for real time operation 
background estimation and removal based on the joint use of range and color data produce superior result than can be achieved with either data source alone this is increasingly relevant a inexpensive real time passive range system become more accessible through novel hardware and increased cpu processing speed range is a powerful signal for segmentation which is largely independent of color and hence not effected by the classic color segmentation problem of shadow and object with color similar to the background however range alone is also not sufficient for the good segmentation depth measurement are rarely available at all pixel in the scene and foreground object may be indistinguishable in depth when they are close to the background color segmentation is complementary in these case surprisingly little work ha been done to date on joint range and color segmentation we describe and demonstrate a background estimation method based on a multidimensional range and color clustering at each image pixel segmentation of the foreground in a given frame is performed via comparison with background statistic in range and normalized color important implementation issue such a treatment of shadow and low confidence measurement are discussed in detail in this paper we present a passive method for background estimation and removal based on the joint use of range and color which produce superior result than can be achieved with either data source alone this approach is now practical for general application a inexpensive real time passive range data is becoming more accessible through novel hardware and increased cpu processing speed the joint use of color and range produce cleaner segmentation of the foreground scene in comparison to the commonly used color based background subtraction or rangebased segmentation 
when designing computer vision system for the blind and visually impaired it is important to determine the orientation of the user relative to the scene we observe that most indoor and outdoor city scene are designed on a manhattan three dimensional grid this manhattan grid structure put strong constraint on the intensity gradient in the image we demonstrate an algorithm for detecting the orientation of the user in such scene based on bayesian inference using statistic which we have learnt in this domain our algorithm requires a single input image and doe not involve pre processing stage such a edge detection and hough grouping we demonstrate strong experimental result on a range of indoor and outdoor image we also show that estimating the grid structure make it significantly easier to detect target object which are not aligned with the grid 
we develop an efficient algorithm to track point feature supported by image patch undergoing affine deformation and change in illumination the algorithm is based on a combined model of geometry and photometry that is used to track feature a well a to detect outlier in a hypothesis testing framework the algorithm run in real time on a personal computer and is available to the public 
we formulate the problem of reconstructing the shape and radiance of a scene a the minimization of the information divergence between blurred image and propose an algorithm that is provably convergent and guarantee that the solution is admissible in the sense of corresponding to a positive radiance and imaging kernel the motivation for the use of information divergence come from the work of csisz r while the fundamental element of the proof of convergence come from work by snyder et al extended to handle unknown imaging kernel i e the shape of the scene 
image sequence capturing hurricane luis throughmeteorological satellite go and go areused to estimate hurricane top height structure andhurricane wind motion this problem is difficultnot only due to the absence of correspondence but alsodue to the lack of depth cue in the d hurricane image scaled orthographic projection in this paper wepresent a structure and motion analysis system calledsmas in this system the hurricane image are firstsegmented into small 
image retrieval algorithm are generally based on the assumption that visually similar image are located close to each other in the feature space since the feature vector usually exist in a very high dimensional space a parametric characterization of their distribution is impossible so non parametric approach like the k nearest neighbor search are used for retrieval this paper introduces a graph theoretic approach for image retrieval by formulating the database search a a graph clustering problem by using a constraint that retrieved image should be consistent with each other close in the feature space a well a being individually similar close to the query image the experiment that compare retrieval precision with and without clustering showed an average precision of after clustering which is an improvement by over the average precision before clustering 
we tackle the problem of d surface reconstruction by a single static camera extracting the maximum amount of information from gray level change caused by object motion under illumination by a fixed set of light source we basically search for the depth at each point on the surface of the object while exploiting the recently proposed geotensity constraint that accurately governs the relationship between four or more image of a moving object in spite of the illumination variance due to object motion the thrust of this paper is then to extend the availability of the geotensity constraint to the case of multiple point light source instead of a single light source we first show that it is mathematically possible to identify multiple illumination subspace for an arbitrary unknown number of light source we then propose a new technique to effectively carry out the separation of the subspace by introducing the surface interaction matrix finally we construct a framework for surface recovery taking the multiple illumination subspace into account the theoretical proposition are investigated through experiment and shown to be practically useful 
charge coupled device ccd camera are widely used imaging sensor in computer vision system many photometric algorithm such a shape from shading color constancy and photometric stereo implicitly assume that the image intensity is proportional to scene radiance the actual image measurement deviate significantly from this assumption since the transformation from scene radiance to image intensity is non linear and is a function of various factor including noise source in the ccd sensor a well a various transformation occurring in the camera including white balancing gamma correction and automatic gain control this paper illustrates how careful modelling of the error source and the various processing step enable u to accurately estimate the response function the inverse mapping from image measurement to scene radiance for a given camera exposure setting it is shown that the estimation algorithm outperforms the calibration procedure known to u in term of reduced bias and variance further we demonstrate how the error modelling help u to obtain uncertainty estimate of the camera irradiance value the power of this uncertainty modeling is illustrated by a vision task involving high dynamic range image generation followed by change detection change can be detected reliably even in situation where the two image the reference scene image and the current image are taken several hour apart 
we present an algorithm for extracting and classifying two dimensional motion in an image sequence based on motion trajectory first a multiscale segmentation is performed to generate homogeneous region in each frame region between consecutive frame are then matched to obtain view correspondence affine transformation are computed from each pair of corresponding region to define pixel match pixel match over consecutive image pair are concatenated to obtain pixel level motion trajectory across the image sequence motion pattern are learned from the extracted trajectory using a time delay neural network we apply the proposed method to recognize hand gesture of american sign language experimental result show that motion pattern in hand gesture can be extracted and recognized with high recognition rate using motion trajectory 
a simplified color image formation model is used to construct an algorithm for image reconstruction from ccd sensor sample the proposed method involves two successive step the first is motivated by cok s template matching technique while the second step us steerable inverse diffusion in color classical linear signal processing technique tend to oversmooth the image and result in noticeable color artifact along edge and sharp feature the question is how should the different color channel support each other to form the best possible reconstruction our answer is to let the edge support the color information and the color channel support the edge and thereby achieve better perceptual result than those that are bounded by the sampling theoretical limit 
the main challenge in articulated body motion tracking is the large number of degree of freedom around to be recovered search algorithm either deterministic or stochastic that search such a space without constraint fall foul of exponential computational complexity one approach is to introduce constraint either labelling using marker or colour coding prior assumption about motion trajectory or view restriction another is to relax constraint arising from articulation and track limb a if their motion were independent in contrast here we aim for general tracking without special preparation of subject or restrictive assumption the principal contribution of this paper is the development of a modified particle filter for search in high dimensional configuration space it us a continuation principle based on annealing to introduce the influence of narrow peak in the fitness function gradually the new algorithm termed annealed particle filtering is shown to be capable of recovering full articulated body motion efficiently 
a simple and effective object recognition scheme is torepresent and match image on the basis of color histogram to obtain robustness against varying imaging circumstance e g a change in illumination object pose andviewpoint color histogram are constructed from color invariant however in general color invariant are negativelyaffected by sensor noise due to the instability of thesecolor invariant transforms at many rgb value to suppressthe effect of noise blow up for 
this paper present a novel algorithm for fast nearest neighbor search at the preprocessing stage the proposed algorithm construct a lower bound tree by agglomeratively clustering the sample point in the database calculation of the distance between the query and the sample point can be avoided if the lower bound of the distance is already larger than the minimum distance the search process can thus be accelerated because the computational cost of the lower bound which can be calculated by using the internal node of the lower bound tree is le than that of the distance to reduce the number of the lower bound actually calculated the winner update search strategy is used for traversing the tree moreover the query and the sample point can be transformed for further efficiency improvement our experiment show that the proposed algorithm can greatly speed up the nearest neighbor search process when applying to the real database used in nayar s object recognition system the proposed algorithm is about one thousand time faster than the exhaustive search 
omnidirectional video camera are becoming increasingly popular in computer vision one family of these camera us a catadioptric system with a paraboloidal mirror and an orthographic lens to produce an omnidirectional image with a single center ofprojection in this paper we develop a novel calibration model that we combine with a beacon based pose estimation algorithm our approach relaxes the assumption of an ideal paraboloidal catadioptric system and achieves an order of magnitude improvement in pose estimation accuracy compared to calibration with an ideal camera model our complete standalone system placed on a radio controlled motorized cart move in a room size environment capturing high resolution frame to disk and recovering camera pose with an average error of in a region foot in diameter 
this paper present a new technique for the perception and recognition of activity using statistical description of their spatio temporal property a set of motion energy receptive field is designed in order to sample the power spectrum of a moving texture their structure relates to the spatio temporal energy model of adelson and bergen where measure of local visual motion information are extracted by comparing the output of a triad of gabor energy filter then the probability density function required for bayes rule is estimated for each class of activity by computing multi dimensional histogram from the output from the set of receptive field the perception of activity is achieved according to bayes rule the result at each instant of time is the map of the conditional probability that each pixel belongs to each one of the activity of the training set since activity are perceived over a short integration time a temporal analysis of output is done using hidden markov model the approach is validated with experiment in the perception and recognition of activity of people walking in visual surveillance scenari the presented work is in progress and preliminary result are encouraging since recognition is robust to variation in illumination condition to partial occlusion and to change in texture it is shown that it constitute a powerful early vision tool for human behavior analysis for smart environnements 
this paper describes afastandrobust approach torecovering structure and motion from videoframes itfirst describes a robust recursive factorization methodfor affine projection using the least median ofsquares lmeds criterion the method estimate thedominant d affine motion and discard featurepointsregarded a outlier the computational cost of theoverall procedureisreducedbycombining this robuststatistics based method with a recursive factorizationmethod that can at each frame 
in this paper we address the problem of curve and surface reconstruction from set of point we introduce regular interpolants which are polygonal approximation of planar curve and surface verifying a local sampling criterion property of regular interpolants lead to new polygonal reconstruction method from set of organized and unorganized point these method do not need any parameter or additional information apart from the original point and allow unorganized set of point to be easily handled 
rendering photorealistic virtual object from their real image is one of the main research issue in mixed reality system we previously proposed the eigen texture method a new rendering method for generating virtual image of object from thier real image to deal with the problem posed by past work in image based method and modelbased method eigen texture method sample apperances of a real object under various illumination and viewing condition and compress them in the d coordinate system defined on the d model surface however we had a serious limitation in our system due to the alignment problem of the d model and color image in this paper we deal with this limitation by solving the alignment problem we do this by using the method orginally designed by viola this paper describes the method and report on how we implement it 
we propose a flexible new technique to easily calibrate a camera it only requires the camera to observe a planar pattern shown at a few at least two different orientation either the camera or the planar pattern can be freely moved the motion need not be known radial lens distortion is modeled the proposed procedure consists of a closed form solution followed by a nonlinear refinement based on the maximum likelihood criterion both computer simulation and real data have been used to test the proposed technique and very good result have been obtained compared with classical technique which use expensive equipment such a two or three orthogonal plane the proposed technique is easy to use and flexible it advance d computer vision one step from laboratory environment to real world use the corresponding software is available from the author s web page 
the error in variable eiv model from statistic is often employedin computervision thoughonly rarely under this name in an eiv model all the measurement are corrupted by noise while the a priori information is captured with a nonlinear constraint among the true unknown value of these measurement to estimate the model parameter and the uncorrupted data the constraint can be linearized i e embedded in a higher dimensional space we show that linearization introducesdata dependent heteroscedastic noise and propose an iterative procedure the heteroscedastic eiv heiv estimator to obtain consistent estimate in the most general multivariate case analytical expression for the covariance of the parameter estimate and corrected data point a generic method for the enforcement of ancillary constraint arising from the underlyinggeometryare also given the heivestimatorminimizes the firstorder approximation of the geometric distance between the measurement and the true data point and thus can be a substitute for the widely used levenbergmarquardt based direct solution of the original nonlinear problem the heiv estimator ha however the advantage of a weaker dependenceon the initial solution and a faster convergence in comparison to kanatani s renormalization paradigm an earlier solution of the same problem the heiv estimator ha more solid theoretical foundation which translate into better numerical behavior we show that the heiv estimator can provide an accurate solution to most d vision estimation task and illustrate it performancethrough two case study calibration and the estimation of the fundamentalmatrix 
projection matrix from projective space to have long been used in multiple view geometry to model the perspective projection created by the pin hole camera in this work we introduce higher dimensional mapping for the representation of various application in which the world we view is no longer rigid we also describe the multi view constraint from these new projection matrix and method for extracting the nonrigid structure and motion for each application 
we present a method for learning a set of visual landmark which are useful for pose estimation the landmark learning mechanism is designed to be applicable to a wide range of environment and generalized for different approach to computing a pose estimate initially each landmark is detected a a local extreme of a measure of distinctiveness and represented by a principal component encoding which is exploited for matching attribute of the observed landmark can be parameterized using a generic parameterization method and then evaluated in term of their utility for pose estimation we present experimental evidence that demonstrates the utility of the method 
this paper describes a correlation based iterative multi resolution algorithm which estimate both scene structure and the motion of the camera rig through an environment from the stream s of incoming image both single camera rig and multiple camera rig can be accommodated the use of multiple synchronized camera result in more rapid convergence of the iterative approach the algorithm us a global ego motion constraint to refine estimate of inter frame camera rotation and translation it us local window based correlation to refine the current estimate of scene structure all analysis is performed at multiple resolution in order to combine in a straightforward way the correlation surface from multiple viewpoint and from multiple pixel in a support region each pixel s correlation surface is modeled a a quadratic this parameterization allows direct explicit computation of incremental refinement for ego motion and structure using linear algebra batch can be of arbitrary size allowing a trade off between accuracy and latency batch can also be daisychained for extended sequence result of the algorithm are shown on synthetic and real outdoor image sequence 
this paper deal with first the uniqueness of the selfcalibrationof a rotating and zooming camera theoretically we assume that the principal point and the aspect ratio arefixed but the focal length change a the camera move inthis case at least one inter image homography is requiredin order to compute the internal calibration parameter aswell a the rotation secondly we analyze the effect of thedeviation of the principal point on the estimation of the focallength and the 
this paper focus on the problem of calibration from a single view and a map of a scene this situation arises quite often when modelling urban scene e g for augmented reality purpose we show how some scene constraint can be used to achieve a calibration like procedure an example excerpted from a sequence of picture for which selfcalibration like technique consistently fail illustrat e some of the benefit of the approach 
accurate d surface model of dense urban areasare essential for a variety of application such a cartography urban planning and monitoring mobile communication etc since manual surface reconstructionis very costly and time consuming the development ofautomated algorithm is of great importance whilemost of existing algorithm focus on surface reconstructioneither in rural or sub urban area we presentan approach dealing with dense urban scene the approachutilizes different 
towards the goal of realizing a generic automatic human activity recognition system a new formalism is proposed activity are described by a chained hierarchical representation using three type of entity image feature mobile object property and scenario taking image feature of tracked moving region from an image sequence a i nput mobile object property are first computed by specific method while noise is suppressed by statistical method scenario are recognized from mobile object property based on bayesian analysis a sequential occurrence s everal scenario are recognized by an algorithm using a probabilistic finite state automaton a variant of structured hmm the demonstration of the optimality of these recognition method is discussed finally the validity and the effectiveness of our approach is demonstrated on both real world and perturbed data 
in order to build a statistical model of appearance we require a set of image each with a consistent set of landmark we address the problem of automatically placing a set of landmark to define the correspondence across an image set we can estimate correspondence between any pair of image by locating salient point on one and finding their corresponding position in the second however we wish to determine a globally consistent set of correspondence across all the image we present an iterative scheme in which these pair wise correspondence are used to determine a global correspondence across the entire set we show result on several training set and demonstrate that an appearance model trained on the correspondence can be of higher quality than one built from hand marked image 
in this paper we propose some new idea for tracking multiple moving object by the propagation of curve we assume a static observer a well a the existence of a background reference frame the tracking is performed using an improved geodesic active contour model that incorporates boundary based and region based motion information this model is called a geodesic active region model initially a statistical analysis is performed which provides a measurement that distinguishes between the 
although behavior knowledge space bk method doe not need any assumption in combining multiple expert it should build theoretically exponential storage space for storing and managing jointly observed k decision from k expert that is combining k expert need a k st order probability distribution however it is well known that the distribution becomes unmanageable in storing and estimating even for a small k in order to overcome such weakness it would be attractive to decompose the distribution into a number of component distribution and to approximate the distribution with a product of the component distribution one of such previous work is to apply a conditional independence assumption to the distribution another work is to approximate the distribution with a product of only first order tree dependency or second order distribution in this paper a dependency based framework is proposed to optimality approximate a probability distribution with a product set of dth order dependency where d k and to combine multiple expert based on the product set using the bayesian formalism this framework wa experimented and evaluated with a standardized cen pariml data base 
linear perspective projection ha served a the dominant imaging model in computer vision recent development in image sensing make the perspective model highly restrictive this paper present a general imaging model that can be used to represent an arbitrary imaging system it is observed that all imaging system perform a mapping from incoming scene ray to photo sensitive element on the image detector this mapping can be conveniently described using a set of virtual sensing element called raxels raxels include geometric radiometric and optical property we present a novel calibration method that us structured light pattern to extract the raxel parameter of an arbitrary imaging system experimental result for perspective a well a non perspective imaging system are included 
in this paper we describe a new strategy for combining orientation adaptive filtering and edge preserving filtering the filter adapts to the local orientation and avoids filtering across border the local orientation for steering the filter will be estimated in a fixed sized window which never contains two orientation field this can be achieved using generalized kuwahara filtering this filter selects from a set of fixed sized window that contain the current pixel the orientation of the window with the highest anisotropy we compare our filter strategy with a multi scale approach we found that our filter strategy ha a lower complexity and yield a constant improvement of the snr 
this paper present a method of evaluating unsupervised texture segmentation algorithm the control scheme of texture segmentation ha been conceptualized a two modular process l feature computation and segmentation of homogeneous region based on the feature value three feature extraction method are considered gray level co occurrence matrax law texture energy and gabor multi channel filtering three segmentation algorithm are considered fuzzy c mean clustering square error clustering and split and merge a set of real scene image with manually specified ground truth wa compiled performance is measured against ground truth on real image using region based and pixel based performance metric 
stereo correspondence is a central issue in computer vision the traditional approach involves extracting image feature establishing correspondence based on photometric and geometric criterion and finally determine a dense disparity field by interpolation in this context occlusion are considered a undesirable artifact and often ignored the challenging problem addressed in this paper are a finding an image representation that facilitates or even trivializes the matching procedure and b detecting and including occlusion point in such representation we propose a new image representation called intrinsic image that can be used to solve correspondence problem within a natural and intuitive framework intrinsic image combine photometric and geometric descriptor of a stereo image pair we extend this framework to deal with occlusion and brightness change between two view we show that this new representation greatly simplifies the computation of dense disparity map and the synthesis of novel view of a given scene obtained directly from this image representation result are shown to illustrate the performance of the proposed methodology under perspective effect and in the presence of occlusion 
a pictorial structure is a collection of part arranged in a deformable configuration each part is represented using a simple appearance model and the deformable configuration is represented by spring like connection between pair of part while pictorial structure were introduced a number of year ago they have not been broadly applied to matching and recognition problem this ha been due in part to the computational difficulty of matching pictorial structure to image in this paper 
an algorithm is described for modelling and recognising temporal structure of visual activity the method is based on learning prior probabilistic knowledge using hidden markov model automatic temporal clustering of hidden markov state based on expectation maximisation and using observation augmented conditional density distribution to reduce the number of sample required for propagation and therefore improve recognition speed and robustness 
robust real time tracking of object from visual data requires probabilistic fusion of multiple visual cue previous approach have either been ad hoc or relied on a bayesian network with discrete spatial variable which suffers from discretisation and computational complexity problem we present a new bayesian modalityfusion network that us continuous domain variable the network architecture distinguishes between cue that are necessary or unnecessary for the object s presence computationally expensive and inexpensive modality are also handled differently to minimise cost the method provides a formal tractable and robust probabilistic method for simultaneously tracking multiple object while instantaneous inference is exact approximation is required for propagation over time 
this paper describes new technique for self calibration and for recovering the motion from a projective reconstruction when the calibration is known we show that our approach deal with the ambiguity in self calibration produced by special motion we extend our technique to deal with varying calibration parameter in passing we prove convergence for the iterative projective reconstruction algorithm of sturm triggs and berthilsson heyden sparr 
in this paper we investigate determine and classify the critical configuration for solving structure and motion problem for d retina vision we give a complete categorization of all ambiguous configuration for a d perspective camera irrespective of the number of point and view both calibrated and uncalibrated camera are considered several example and illustration are provided to explain the result and to provide geometrical insight 
perceptual experiment indicate that corner and curvature are very important feature in the process of recognition this paper present a new method to efficiently detect rotational symmetry which describe complex curvature such a corner circle starand spiral pattern the method is designed to give selective and sparse response it work in three step first extract local orientation from a gray scale or color image second correlate the orientation image with rotational symmetry filter and third let the filter response inhibit each other in order to get more selective response the correlation can be made efficient by separating the d filter into a small number of d filter these symmetry can serve a feature point at a high abstraction level for use in hierarchical matching structure for d estimation object recognition etc 
a common method for texture representation is to use the marginal probability density over the output of a set of multi orientation multi scale filter a a description of the texture we propose a technique based on independent component analysis for choosing the set of filter that yield the most informative marginals meaning that the product over the marginals most closely approximates the joint probability density function of the filter output the algorithm is implemented using a steerable filter space experiment involving both texture classification and synthesis show that compared to principal component analysis ica provides superior performance for modeling of natural and synthetic texture 
the fundamental matrix defines a nonlinear d variety in the joint image space of multiple projective or uncalibrated perspective image we show that in the case of two image this variety is a d cone whose vertex is the joint epipole namely the d point obtained by stacking the two epipoles in the two image affine or para perspective projection approximates this nonlinear variety with a linear subspace both in two view and in multiple view we also show that the tangent to the projective joint image at any point on that image is obtained by using local affine projection approximation around the corresponding d point we use these observation to develop a new approach for recovering multiview geometry by integrating multiple local affine joint image into the global projective joint image given multiple projective image the tangent to the projective joint image are computed using local affine approximation for multiple image patch the affine parameter from different patch are combined to obtain the epipolar geometry of pair of projective image we describe two algorithm for this purpose including one that directly recovers the image epipoles without recovering the fundamental matrix a an intermediate step 
we describe a set of image measurement which areinvariant to the camera internals but are location variant we show that using these measurement it is possibleto calculate the self localization of a robot usingknown landmark and uncalibrated camera we alsoshow that it is possible to compute using uncalibratedcameras the euclidean structure of d world pointsusing multiple view from known position we are freeto alter the internal parameter of the camera duringthese 
while several image based rendering technique have been proposed to successfully render scene object from a large collection e g thousand of image without ex plicitly recovering d structure the minimum number of image needed to achieve a satisfactory rendering result re main an open problem this paper is the first attempt to in vestigate the lower bound for the number of sample needed in the lumigraph light field rendering to simplify the analysis we consider an ideal scene with only a point that is between a minimum and a maximum range furthermore constant depth assumption and bilin ear interpolation are used for rendering the constant depth assumption serf to choose nearby ray for interpola tion our criterion to determine the lower bound is to avoid horizontal and vertical double image which are caused by interpolation using multiple nearby ray this criterion is based on the causality requirement in scale space theory i e no spurious detail should be generated while smooth ing using this criterion closed form solution of lower bound are obtained for both d plenoptic function concen tric mosaic and d plenoptic function light field the bound are derived completely from the aspect of geometry and are closely related to the resolution of the camera and the depth range of the scene these lower bound are further verified by our experimental result 
we present a new image segmentation algorithm based on graph cut our main tool is separation of each pixel from a special point outside the image by a cut of a minimum cost such a cut creates a group of pixel around each pixel we show that these group are either disjoint or nested in each other and so they give a natural segmentation of the image in addition this property allows an efficient implementation of the algorithm because for most pixel the computation of is not performed on the whole graph we inspect all s and discard those which are not interesting for example if they are too small this procedure automatically group small component together or merges them into nearby large cluster effectively our segmentation is performed by extracting significant non intersecting closed contour we present interes ting segmentation result on real and artificial image 
an approach that allows a user to assist an automatic system in modeling building is described the approach is designed to be efficient in user time and effort while preserving the quality of the model created currently our system is able to handle the rectangular building with flat roof or symmetric gabled roof model can be created by only one or two click in many case efficient editing of automatically derived model is also possible introduction and overview generating d model from a set of image is a common task for computer vision in spite of substantial research in this area the performance of machine algorithm remains significantly below that of human in this paper we explore an approach to bridge this gap by allowing a human in the loop but by requiring only simple interaction from the user to generate accurate model efficiently we illustrate this approach for the task of building modeling from aerial image which is a difficult and important task significant progress ha been made in recent year in the goal of extracting model of building from aerial image by completely automatic system but the result are not completely accurate completely manual system require an unacceptable amount of effort from a human modeler both in term of time and cost we describe an approach that attempt to provide user assist to an automatic system in a way that the user effort is diminished significantly while the quality of the result is still preserved several approach to user assisted modeling are possible the conventional approach is to provide a set of generic model which are then fit to the image data by changing model and viewing parameter in this approach the system provides geometric computation but substantial time and effort are required from the user newer approach have attempted to combine user input with varying amount of automatic processing in the author suggest providing just an approximate building location to extract a building in other interactive tool are described including method for replicating to model building that are identical or very similar to others in an automatic system construct topological relation among d roof point collected by a user for each roof this system can work with several type of complex roof in our approach basic modeling task are still performed by an automatic system but this system receives simple but critical assist from a user the assisted system s capability are limited by those of the underlying system in our case the shape of the building are restricted to be rectilinear the roof may be either flat or symmetric gable the underlying automatic system is the multi view 
we develop a linear model of commonly observed joint color change in image due to variation in lighting and certain non geometric camera parameter this is done by observing how all of the color are mapped between two image of the same scene under various real world lighting change we represent each instance of such a joint color mapping a a d vector field in rgb color space we show that the variance in these map is well represented by a lowdimensional linear subspace of these vector field we dub the principal component of this space the color eigenflows when applied to a new image the map define an image subspace different for each new image of plausible variation of the image a seen under a wide variety of naturally observed lighting condition we examine the ability of the eigenflows and a base image to reconstruct a second image taken under different lighting condition showing our technique to be superior to other method setting a threshold on this reconstruction error give a simple system for scene recognition 
application of dynamic programming to the deformablecontours ha many advantage such a guaranteed optimalityand numerical stability however long executiontimes of these method almost always force researcher touse dynamic programming in combination with multiresolutionmethods multiresolution method shorten the executiontime by subsampling the original image after anapplication of a smoothing filter however this speedupcomes at the expense of contour optimality due to the 
we consider a scene containing many object moving with constant velocity along straight line path seen from three reference viewpoint at three different time the scene mayeven consist only of moving object with no static feature we wish to create a new image sequence showing the scene from arbitrary viewing position and arbitrary time we make use of a newly discovered tool the dual htensor that connects together three view of a coplanar configuration of unlabeled static and moving point the newly synthesized image use constant velocity in the world to achive realistic and physically correct image 
in recent year increasing effort ha gone into evaluating computer vision algorithm in general and edge detection algorithm in particular most of the evaluation technique use only a few test image leaving open the question of how broadly their result can be interpreted our research test the consistency of the receiver operating characteristic roc curve and demonstrates why consistent edge detector evaluation is difficult to a chieve we show how easily the framework can be 
when image captured by a tilted camera are mosaiced into a panorama the resulting mosaic is curled this happens for example with a panning camera that is not perfectly horizontal and with a translating camera facing a tilted planar surface the tilt of the camera cause difference in image velocity between the top and bottom part of the image causing the curled mosaic in rectified mosaicing these distortion are overcome by warping the strip into rectangle while keeping some image feature invariant this warping equalizes the image motion at the different image part and the resulting mosaic is straight mosaicing is done without camera calibration or knowledge of the scene and the process adapts automatically to smooth change in the scene and the imaging condition figure a curled mosaic constructed by manifold mosaicing the panning camera wa slightly tilted upwards 
a novel approach to colour based object recognition and image retrieval the multimodal neighbourhood signatureis proposed object appearance is represented by colour based feature computed from image neighbourhood with multi modal colour density function stable invariant are derived from mode of the density function that are robustly located by the mean shift algorithm the problem of extracting local invariant colour feature is addressed directly without a need for prior segmentation or edge detection the signature is concise an image is typically represented by a few hundred byte a few thousand for very complex scene the algorithm s performance is first tested on a region based image retrieval task achieving a good hit rate at a speed of image comparison per second the method is shown to operate successfully under changing illumination viewpoint and object pose a well a non rigid object deformation partial occlusion and the presence of background clutter dominating the scene the performance of the multimodal neighbourhood signature method is also evaluated on a standard colour object recognition task using a publicly available dataset very good recognition performance average match percentile wa achieved in real time average second for recognising a single image which compare favourably with result reported in the literature 
a new algorithm for approximating intensity image with adaptive triangular mesh keeping image discontinuity and avoiding optimization is presented the algorithm consists of two main stage in the first stage the original image is adaptively sampled at a set of point taking into account both image discontinuity and curvature in the second stage the sampled point are triangulated by applying a constrained d delaunay algorithm the obtained triangular mesh are compact representation that model the region and discontinuity present in the original image with many fewer point thus image processing operation applied upon those mesh can perform faster than upon the original image a an example four simple operation translation rotation scaling and deformation have been implemented in the d geometric domain and compared to their image domain counterpart 
this paper present the dynamic scene analysis partof an original unified and efficient framework to videopartitioning camera motion estimation and multiplemotion analysis in the context of content based videoindexing all the information required to achieve thesegoals result from handling the apparent motion withinconsecutive image pair through robust estimation of d parametric motion model using the estimatedglobal dominant motion and it spatial support thevideo is 
pinhole camera model is a simplified subset of geometric optic in special case like the image formation of the cone a degenerate conic section mirror in an omnidirectional view catadioptric system there are more complex optical phenomenon involved that the simple pinhole model can not explain we show that using the full geometric optic model a true single viewpoint cone mirror omni directional system can be built we show how such system is built first and then show in detail how each optical phenomenon work together to make the system true single viewpoint the new system requires only simple off the shelf component and still outperforms other single viewpoint omni system for many application 
the human figure exhibit complex and rich dynamic behavior that is both nonlinear and time varying however most work on tracking and analysis of figure motion ha employed either generic or highly specific hand tailored dynamic model superficially coupled with hidden markov model hmms of motion regime recently an alternative class of learned dynamic model known a switching linear dynamic system sldss ha been cast in the framework of dynamic bayesian network dbns and applied to analysis and tracking of the human figure in this paper we further study the impact of learned slds model on analysis and tracking of human motion and contrast them to the more common hmm model we develop a novel approximate structured variational inference algorithm for slds a globally convergent dbn inference scheme and compare it with standard slds inference technique experimental result on learning and analysis of figure dynamic from video data indicate the significant potential of the slds approach 
we analyze the problem of detecting a road target in background clutter and investigate the amount of prior i e target specific knowledge needed to perform this search task the problem is formulated in term of bayesian inference and we define a bayesian ensemble of problem instance this formulation implies that the performance measure of different model depend on order parameter which characterize the problem this demonstrates that if there is little clutter then only weak knowledge about the target is required in order to detect the target however at a critical value of the order parameter there is a phase transition and it becomes effectively impossible to detect the target unless high level target specific knowledge is used these phase transition determine different regime within which different search strategy will be effective these result have implication for bottom up and top down theory of vision 
this paper describes a machine learning approach for visualobject detection which is capable of processing image extremely rapidly and achieving high detection rate this work is distinguished by three key contribution the first is the introduction of a new image representation called the integral image which allows the feature used by our detector to be computed very quickly the second is a learning algorithm based on adaboost which selects a small number of critical visual feature from a larger set and yield extremely efficient classifier the third contribution is a method for combining increasingly more complex classifier in a cascade which allows background region of the image to be quickly discarded while spending more computation on promising object like region the cascade can be viewed a an object specific focus of attention mechanism which unlike previous approach provides statistical guarantee that discarded region are unlikely to contain the object of interest in the domain of face detection the system yield detection rate comparable to the best previous system used in real time application the detector run at frame per second without resorting to image differencing or skin color detection 
multiple camera are needed to cover large environment for monitoring activity to track people successfully in multiple perspective imagery one need to establish correspondence between object captured in multiple camera we present a system for tracking people in multiple uncalibrated camera the system is able to discover spatial relationship between the camera field of view and use this information to correspond between different perspective view of the same person we employ the novel approach of finding the limit of field of view fov of a camera a visible in the other camera using this information when a person is seen in one camera we are able to predict all the other camera in which this person will be visible moreover we apply the fov constraint to disambiguate between possible candidate of correspondence we present result on sequence of up to three camera with multiple people the proposed approach is very fast compared to camera calibration based approach 
many problem in vision can be formulated a bayesian inference it is important to determine the accuracy of these inference and how they depend on the problem domain in recent work coughlan and yuille showed that for a restricted class of problem the performance of bayesian inference could be summarized by an order parameter k which depends on the probability distribution which characterize the problem domain in this paper we generalize the theory of order parameter so that it applies to domain for which the probability model can be obtained by minimax entropy learning theory by analyzing order parameter it is possible to determine whether a target can be detected using a general purpose generic model or whether a more specific high level model is needed at critical value of the order parameter the problem becomes unsolvable without the addition of extra prior knowledge 
intelligent scissors is an interactive image segmentation tool that allows a user to select piece wise globally optimal contour segment that correspond to a desired object boundary we present a new and faster method of computing the optimal path by over segmenting the image using tobogganing and then imposing a weighted planar graph on top of the resulting region boundary the resulting region based graph is many time smaller than the pixel based graph used previously thus providing faster graph search and immediate user interaction further the region based graph provides an efficient framework to compute a parameter edge model allowing subpixel localization a well a a measure of edge blur 
abstract a specialized formulation of azarbayejani and pentland s framework for recursive recovery of motion structure and focal length from feature correspondence tracked through an image sequence is presented the specialized formulation address the case where all tracked point lie on a plane this planarity constraint reduces the dimension of the original state vector and consequently the number of feature point needed to estimate the state experiment with synthetic data and real imagery illustrate the system performance the experiment confirm that the specialized formulation provides improved accuracy stability to observation noise and rate of convergence in estimation for the case where the tracked point lie on a plane 
we introduce a d tracing method based on differential geometry in gaussian blurred image the line point detection part of the tracing method start with calculation of the line direction from the eigenvectors of the hessian matrix the sub voxel center line position is estimated from a second order taylor approximation of the d intensity profile perpendicular to the line in curved line structure the method turn out to be biased we model the bias in center line position using the first order taylor expansion of the gradient in scale and position based on this model we found that the bias in a torus with a generalized line profile wa proportional to this result wa applied in a procedure to remove the bias and to measure the radius of curvature in a curved line structure the line diameter is obtained using the theoretical scale dependency of the th and nd order gaussian derivative at the line center experiment on synthetic image reveal that the localization of the centerline is mainly affected by line curvature and is well predicted by our theoretical analysis the diameter measurement is accurate for diameter a low a voxels result in image from a confocal microscope show that the tracing method is able to trace in image highly corrupted with noise and clutter the diameter measurement procedure turn out to be accurate and largely independent of the scale of observation 
in this contribution we focus on the calibration of very long image sequence from a hand held camera that sample the viewing sphere of a scene view sphere sampling is important for plenoptic image based modeling that capture the appearance of a scene by storing image from all possible direction the plenoptic approach is appealing since it allows in principle fast scene rendering of scene with complex geometry and surface reflection without the need for an explicit geometrical scene model however the acquired image have to be calibrated and current approach mostly use pre calibrated acquisition system this limit the generality of the approach we propose a way out by using an uncalibrated handheld camera only the image sequence is acquired by simply waving the camera around the scene object creating a zigzag scan path over the viewing sphere we extend the sequential camera tracking of an existing structure frommotion approach to the calibration of a mesh of viewpoint novel view are generated by piecewise mapping and interpolating the new image from the nearest viewpoint according to the viewpoint mesh local depth map estimate enhance the rendering process extensive experiment with ground truth data and hand heldsequencesconfirm the performance of our approach 
new face recognition approach are needed becausealthough much progress ha been recently achieved inthe field e g within the eigenspace domain still manyproblems are to be robustly solved two of these problemsare occlusion and the imprecise localization offaces which ultimately imply a failure in identification while little ha been done to account for thefirst problem almost nothing ha been proposed to accountfor the second this paper present a probabilisticapproach 
in this paper we address the problem of global registration between multiple dimensional point pattern with a given correspondence the actual overlapping is not necessarily between pair instead it can be between any number of pattern it is assumed that each pattern is a portion of an image of an unobserved object under a distinct rigid transformation we derive an iterative solution for the problem of global registration of the pattern in order to reconstruct the original object our solution is based on the em algorithm and it generalizes the well known solution for the two pattern case we also suggest a very efficient method to implement the proposed algorithm experimental result demonstrate the improved performance of the proposed method 
abstract most imaging sensor have a limited dynamic range and hence can satisfactorily respond to only a part of il lumination level present in a scene this is particularly disadvantageous for omnidirectional and panoramic camera since larger eld of view have larger bright ness range we propose a simple modi cation to exist ing high resolution omnidirectional panoramic camera in which the process of increasing the dynamic range is coupled with the process of increasing the eld of view this is achieved by placing a graded transparency mask in front of the sensor which allows every scene point to be imaged under multiple exposure setting a the camera pan a process anyway required to capture large eld of view at high resolution the sequence of image are then mosaiced to construct a high resolution high dynamic range panoramic omnidirectional image our method is robust to alignment error between the mask and the sensor grid and doe not require the mask to be placed on the sensing surface we have designed a panoramic camera with the proposed modi cation and have discussed various theoretical and practical issue encountered in obtaining a robust design we show with an example of high resolution high dynamic range panoramic image obtained from the camera we designed 
to navigate reliably in indoor environment a mobile robot must know where it is this includes both the ability of globally localizing the robot from scratch a well a tracking the robot s position once it location is known vision ha long been advertised a providing a solution to these problem but we still lack efficient solution in unmodified environment many existing approach require modification of the environment to function properly and those that work within unmodified environment seldomly address the problem of global localization in this paper we present a novel vision based localization method based on the condensation algorithm a bayesian filtering method that us a samplingbased density representation we show how thecondensation algorithm can be used in a novel way to track the position of the camera platform rather than tracking an object in the scene in addition it can also be used to globally localize the camera platform given a visual map of the environment based on these two observation we present a visionbased robot localization method that provides a solution to a difficult and open problem in the mobile robotics community a evidence for the viability of our approach we show both global localization and tracking result in the contex t of a state of the art robotics application 
a new method to pre segment image by mean of a hierarchical description is proposed this description is obtained from an investigation of the deep structure of a scale space image the input image and the gaussian filtered one simultaneously we concentrate on scale space critical point point with vanishing gradient with respect to both spatial and scale direction we show that these point are always saddle point they turn out to be extremely useful since the iso intensity manifold through these point provide a scale space hierarchy tree and induce a segmentation without a priori knowledge moreover together with the so called catastrophe point these scale space saddle form the critical point of the parameterised critical curve the curve along which the spatial saddle point move in scale space experimental result with respect to the hierarchy and segmentation are given based on an artificial image and a simulated mri 
this paper address the problem of tracking several non rigid object over a sequence of frame acquired from a static observer using boundary and region based information under a coupled geodesic active contour framework given the current frame a statistical analysis is performe d on the observed difference frame which provides a measurement that distinguishes between the static and mobile region in term of conditional probability an objective function is defined that integrates boundary based and region based module by seeking curve that attract the object boundary and maximize the a posteriori segmentation probability on the interior curve region with respect to in tensity and motion property this function is minimized using a gradient descent method the associated eulerlagrange pde is implemented using a level set approach where a very fast front propagation algorithm evolves the initial curve towards the final tracking result very promis ing experimental result are provided using real video sequence 
the necessary and sufficient condition for being able to estimate scene structure motion and camera calibration from a sequence of image are very rarely satisfied in practice what exactly can be estimated in sequence of practical importance when such condition are not satisfied in this paper we give a complete answer to this question for every camera motion that fails to meet the condition we give explicit formula for the ambiguity in the reconstructed scene motion and calibration such a characterization is crucial both for designing robust estimation algorithm that do not try to recover parameter that cannot be recovered and for generating novel view of the scene by controlling the vantage point to this end we characterize explicitly all the vantage point that give rise to a valid euclidean reprojection regardless of the ambiguity in the reconstruction we also characterize vantage point that generate view that are altogether invariant to the ambiguity all the result are presented using simple notation that involves no tensor nor complex projective geometry and should be accessible with basic background in linear algebra 
this paper proposes a new method for effecting feature correspondence between image the method operates from coarse to fine and is superior to previous method in that it can solve the wide baseline stereo problem even when the image ha been deformed or rotated at the coarsest level a ransac style estimator is used to estimate the two view image constraint r which is then used to guide matching the two view relation is an augmented fundamental matrix being a fundamental matrix plus a homography consistent with that fundamental matrix this is akin to the plane plus parallax representation with the homography being used to help guide matching and to mitigate the effect of image deformation in order to propagate the information from coarse to fine image the distribution of the parameter of r is encoded using a set of particle and an importance sampling function it is not known in general how to choose the importance sampling function but a new method impsac is presented that automatically generates such a function it is shown that the method is superior to previous single resolution ransac style feature matcher 
tomasi and kanade introduced the factorization method for recovering d structure from d video in their formulation the d shape and d motion are computed by using an svd to approximate a matrix that is rank in a noiseless situation in this paper we reformulate the problem using the fact that the x and y coordinate of each feature are known from their projection onto the image plane in frame w e show how to compute the d shape i e the relative depth z and the d motion by a simple factorization of a matrix that is rank in a noiseless situation this allows the use of very fast algorithm even when using a large number of feature and large number of frame we also show how to accommodate confidence weight for the feature trajectory this is done without additional computational cost by rewriting the problem a the factorization of a modified matrix 
in this paper an efficient global algorithm for vectorizing line drawing is presented it first extract a seed segment of a graphic entity from a raster image to obtain it direction and width then track the pixel under the guidance of the direction so that the tracking can track through function and is not affected by noise and degradation of image quality thus an entity will be vectorized in one step without postprocessing the relation among line are also used to realize the continuous vectorization of a line net the speed and quality of vectorization are greatly improved with this algorithm the performance evaluation is carried out both by theoretical analysis and by experiment comparison with other vectorization algorithm are also made 
large collection of image can be indexed by projection on a few eigenfeatures the dominant eigenvectors of the image covariance matrix a preliminary step of registering the image is common practice a quantitative analysis of what is being gained by registration wa not performed in previous work and heuristic were used to determine on what to register the image we show that the registration improves the accuracy of indexing and optimal improvement is obtained when the image are registered on their eigenfeatures subspace similarly if multiple image are to be registered on a subspace the optimal subspace is the one spanned by the dominant eigenfeatures of the registered image an algorithm that simultaneously register the image and computes their eigenfeatures is proposed the key idea is to iterate the following two step eigenfeatures are computed from the image new image are computed by registering the image on the subspace of these eigenfeatures in the next iteration step is applied to the set of image that were most recently computed in step it is demonstrated that the algorithm produce improved eigenfeatures and register multiple image 
we present two family of reflective surface that are capable of providing a wide field of view and yet still approximate a perspective projection to a high degree these surface are derived by considering a plane perpendicular to the axis of a surface of revolution and finding the equation governing the distortion of the image of the plane in this surface we then view this relation a a differential equation and prescribe the distortion term to be linear by choosing appropriate initial condition for the differential equation and solving it numerically we derive the surface shape and obtain a precise estimate a to what degree the resulting sensor can approximate a perspective projection thus these surface act a computational sensor allowing for a wide angle perspective view of a scene without processing the image in software the application of such a sensor should be numerous including surveillance robotics and traditional photography recently many researcher in the robotics and vision community have begun to consider visual sensor that are able to obtain wide field of view such device are the natural solution to various difficulty encountered with conventional imaging system the two most common mean of obtaining wide field of view are fish eye lens and reflective surface also known a catoptrics when catoptrics are combined with conventional lens system known a dioptrics the resulting sensor are known a catadioptrics the possible us of these system include application such a robot control and surveillance in this paper we will consider only catadioptri based sensor often such system consist of a camera pointing at a convex mirror how to interpret and make use of the visual information obtained by such system e g how they should be used to control robot is not at all obvious there are infinitely many different shape that a mirror can have and at least two different camera model perspective and orthographic projection with which to combine each mirror the property of the resulting sensor are very sensitive to these choice the classic need for wide angle lens have of course been in photography in particular underwater and architectural photography are two example in which having a wide angle lens is often crucial the commercially available lens with the widest field of view without radial distortion that the author are aware of is the nikon mm f nikkor ai which provides a field of view of degree at a cost of u note that our prototype orthographic sensor provides a field of view of degree 
the general problem of surface matching is taken up in this study the process described in this work hinge on a geodesic distance equation for a family of surface embedded in the graph of a cost function the cost function represents the geometrical matching criterion between the two d surface this graph is a hypersurface in dimensional space and the theory presented herein is a generalization of the geodesic curve evolution method introduced by r kimmel et al it also generalizes a d matching process developed in an eulerian level set formulation of the geodesic surface evolution is also used leading to a numerical scheme for solving partial differential equation originating from hyperbolic conservation law which ha proven to be very robust and stable the method is applied on example showing both small and large deformation and arbitrary topological change 
we propose a class of benchmark for edge detector evaluation that require no ground truth each benchmark consists of a large number of image of a carefully designed scene for which we enforce a constraint on the edge for example that they are co linear we sample the space of edge appearance a densely a possible by capturing the image under widely varying imaging condition not only do we change the viewing geometry and the illumination direction but we also vary the camera parameter and the physical property of the object in the scene we show that the degree to which the constraint hold in the output edge map can be used a highly discriminating measure of edge detector performance the code image and result which form our benchmark are all available from the website http www c columbia edu cave the code and image enable a user to compare any new detector against several previous one with minimal effort 
we describe two direct quasilinear method for camera pose absolute orientation and calibration from a single image of or known d point they generalize the point direct linear transform method by incorporating partial prior camera knowledge while still allowing some unknown calibration parameter to be recovered only linear algebra is required the solution is unique in non degenerate case and additional point can be included for improved stability both method fail for coplanar point but we give an experimental eigendecomposition based one that handle both planar and nonplanar case our method use recent polynomial solving technology and we give a brief summary of this one of our aim wa to try to understand the numerical behaviour of modern polynomial solver on some relatively simple test case with a view to other vision application 
in this contribution we introduce a new model free method for object tracking the tracking is posed a a segmentation problem which we solve using the watershed algorithm a framework is defined to compute the required topographic surface from distance to the predicted contour intensity edge and motion edge this multifeature tracking approach yield accurate result in the presence of object corner image clutter and camera motion result on real sequence confirm the stability and robustness of the method object are tracked over long sequence and in the presence of fast object motion 
a general formulation for geodesic distance propagation of surface is presented starting from a surface lying on a manifold in ir we set up a partial differential equation governing the propagation of surface at equal geodesic distance on the manifold from the given original surface this propagation scheme generalizes a result of kimmel et al and provides a way to compute distance map on manifold moreover the propagation equation is generalized to any number of dimension using an eulerian formulation with level set it give stable numerical algorithm for computing distance map this theory is used to present a new method for surface matching which generalizes a curve matching method matching path are obtained a the orbit of the vector field defined a the sum of two distance map gradient value this surface matching technique applies to the case of large deformation and topological change 
a common method for real time segmentation of moving region in image sequence involves background subtraction or thresholding the error between an estimate of the image without moving object and the current image the numerous approach to this problem differ in the type of background model used and the procedure used to update the model this paper discus modeling each pixel a a mixture of gaussians and using an on line approximation to update the model the gaussian distribution of the adaptive mixture model are then evaluated to determine which are most likelyto result from a background process each pixel is classified based on whether the gaussian distribution which represents it most effectivelyis considered part of the background model this result in a stable real time outdoor tracker which reliablydeals with lighting change repetitive motion from clutter and long term scene change this system ha been run almost continuously for month hour a day through rain and snow 
we present a linear approach to the d reconstruction problem from occluding contour using algebraic surface the problem of noise and missing data in the occluding contour extracted from the image lead u to this approach our approach is based first on the intensive use of the duality property between d point and tangent plane and second on the algebraic representation of d surface by implicit polynomial of degree and higher 
in this paper we specialize the projective unifocal bifocal and trifocal tensor to the affine case and show how the tensor obtained relate to the registered tensor encountered in previous work this enables u to obtain an affine specialization of known projective relation connecting point and line across two or three view in the simpler case of affine camera we give neccessary and sufficient constraint on the component of the trifocal tensor together with a simple geometric interpretation finally we show how the estimation of the tensor from point correspondence is achieved through factorization and discus the estimation from line correspondence 
many boundary between object in the world project onto curve in an image however boundary involving natural object e g tree hair water smoke are often unworkable under this model because many pixel r eceive light from more than one object we propose a technique for estimating alpha the proportion in which two color mix to produce a color at the boundary the technique extends blue screen matting to background that have almost arbitrary color distribution though coarse knowledge of the boundary s location is required result show a number of different object moved from one image to another while maintaining naturalism 
this paper introduces a novel linear algorithm fordetermining the affine calibration between two cameraviews of a dynamic scene the affine calibration iscomputed directly from the fundamental matrix associatedwith various moving object in the scene aswell a from the fundamental matrix for the static backgroundif the camera are at different location a minimumof two fundamental matrix are required butany number of additional fundamental matrix canbe incorporated into the 
we address the problem of rejecting false match of point between two perspective view even the best algorithm for image matching make some mistake and output some false match we present an algorithm for identification of the false match between the view the algorithm exploit the possibility of rotating one of the image to achieve some common behaviour of the correct match those match that deviate from this common behaviour turn out to be false match the statistical tool we use is the mean shift mode estimator our algorithm doe not use in any way the image characteristic of the matched feature in particular it avoids problem that cause the false match in the first place the algorithm may be run a a post processing step on output from any point matching algorithm use of the algorithm may significantly improve the ratio of correct match to incorrect match on real image our algorithm ha improved the percentage of correct match from an initial to a final for robust estimation algorithm which are later employed this is a very desirable quality since it reduces significantly their computational cost we present the algorithm identify the condition under which it work and present result of testing it on both synthetic and real image 
an algebraic curve is defined a the zero set of a polynomial in two variable algebraic curve are practical for modeling shape much more complicated than conic or superquadrics the main drawback in representing shape by algebraic curve ha been the lack of repeatability in fitting algebraic curve to data a regularized fast linear fitting method based on ridge regression and restricting the representation to well behaved subset of polynomial is proposed and it property are investigated the fitting algorithm is of sufficient stability for very fast position invariant shape recognition position estimation and shape tracking based on new invariant and representation and is appropriate to open a well a closed curve of unorganized data among appropriate application are shape based indexing into image database 
in this paper we present a method to removecommercials from talk and game show video and tosegment these video into host and guest shot in ourapproach we mainly rely on information contained inshot transition rather than analyzing the scene contentof individual frame we utilize the inherent difference inscene structure of commercial and talk show todifferentiate between them similarly we make use of thewell defined structure of talk show which can beexploited to 
ongoing work towards appearance based d hand pose estimation from a single image is presented using a d hand model and computer graphic a large database of synthetic view is generated the view display different hand shape a seen from arbitrary viewpoint each syntheticview is automaticallylabeledwith parametersdescribing it hand shape and viewing parameter given an input image the system retrieves the most similar database view and us the shape and viewing parameter of those view a candidate estimate for the parameter of the input image preliminary result are presented in which appearance based similarity is defined in term of the chamfer distance between edge image 
this paper show how two image sequence that have no spatial overlap between their field of view can be aligned both in time and in space such alignment is possible when the two camera are attached closely together and are moved jointly in space the common motion induces similar change over time within the two sequence this correlated temporal behavior is used to recover the spatial and temporal transformation between the two sequence the requirement of coherent appearance in standard image alignment technique is therefore replaced by coherent temporal behavior which is often easier to satisfy this approach to alignment can be used not only for aligning non overlapping sequence but also for handling other case that are inherently difficult for standard image alignment technique we demonstrate application of this approach to three real world problem i alignment of non overlapping sequence for generating wide screen movie ii alignment of image sequence obtained at significantly different zoom for surveillance application and iii multi sensor image alignment for multi sensor fusion 
nearest neighbor classification assumes locally constant class conditional probability this assumption becomes invalid in high dimension with finite sample due to the curse of dimensionality severe bias can be introduced under these condition when using the nearest neighbor rule we propose a locally adaptive nearest neighbor classification method to try to minimize bias we use achisquared distance analysis to compute a flexible metric for producing neighborhood that are highly adaptive to query location neighborhood are elongated along le relevant feature dimension and constricted along most influential one a a result the class conditional probability tend to be smoother in the modified neighborhood whereby better classification performance can be achieved the efficacy of our method is validated and compared against other technique using a variety of simulated and real world data 
a spatio temporal representation for complex optical flow event is developed that generalizes traditional parameterized motion model e g affine these generative spatio temporal model may be non linear or stochastic and are event specific in that they characterize a particular type of object motion e g sitting or walking within a bayesian framework we seek the appropriate model phase rate spatial position and scale to account for the image variation the posterior distribution over this parameter space conditioned on image measurement is typically nongaussian the distribution is represented using factored sampling and is predicted and updated over time using the condensation algorithm the resulting framework automatically detects localizes and recognizes motion event 
a fast and general method to extract anomaly in an arbitrary iniage is proposed the basic idea is to compute a probability density for sub region in an image conditioned upon the area surrounding the sub region linear estimation and independent component analysis ica are combined to obtain the probability estimate pseudo non parametric correlation is used to group set of similar surrounding pattern from which a probability for the occurrence of a given sub region is derived a carefully designed multi dimensional histogram based on compressed vector representation enables eficient and high resolution extraction of anonlalies from the image our current unoptimized implementation performs anomaly extraction in about second for a x image using a mhz pc experimental result are included that demonstrate the perforniance of the proposed method 
we address the problem of moving object segmentationusing active contour a far a segmentation of movingobjects is concerned region based term must be incorporatedin the evolution equation of the active contour in additionto classical boundary based term in this paper wepropose a general framework for region based active contour novel aspect of the segmentation method includea new eulerian proof to compute the evolution equation ofthe active contour from the minimization of a 
we address the problem of moving object segmentation using active contour a far a segmentation of moving object is concerned region based term must be incorporated in the evolution equation of the active contour in addition to classical boundary basedterms in this paper we propose a general framework for region based active contour novel aspect of the segmentation method include a new eulerian proof to compute the evolution equation of the active contour from the minimization of a criterion and the introduction of function named descriptor of the region in this proof the dynamical scheme is directly introduced in the criterion before differentiation with such a method the case of descriptor depending on the evolution of the curve i e depending upon feature globally attached to the region can readily be taken into account the variation of these descriptor upon the evolution of the curve induces additional term in the evolution equation of the active contour the proof ensures the fastest decrease of the active contour towards a minimum of the criterion inside this theoretical framework a set of descriptor is evaluated on real sequence for the detection of moving object 
the appearance of an object can vary considerably with change in illumination condition method have been developed to describe these difference for diffuse reflection using the lambertian model but little work ha been done in characterizing specular appearance towards a more comprehensive global reflectance descriptor this paper focus on a representation of specular appearance based on an approximate specular reflection model derived from torrance sparrow we propose that under certain illumination and surface condition local specular structure can be expressed by the logarithm of three intensity normalized photometric image the total number of photometric image needed for representing global specular appearance depends on the object surface roughness and we suggest an illumination planning method for determining the number of image experimental result demonstrate the effectiveness of this logarithmic model a a specular descriptor 
this paper present a method of matching ambiguous feature set extracted from image the method is based on wilson and hancock s bayesian matching framework which is extended to handle the case where the feature measurement are ambiguous a multimodal evolutionary optimisation framework is proposed which is capable of simultaneously producing several good alternative solution unlike other multimodal genetic algorithm the one reported here requires no extra parameter solution yield are maximised by removing bias in the selection step while optimisation performance is maintained by a local search step an experimental study demonstrates the effectiveness of the new approach on synthetic and real data the framework is in principle applicable to any multimodal optimisation problem where local search performs well 
we describe a new technique to detect and analyze periodic motion a seen from both a static and moving camera by tracking object of interest we compute an object s self similarity a it evolves in time for periodic motion the self similarity measure is also periodic and we apply time frequency analysis to detect and characterize the periodic motion a real time system ha been implemented to track and classify object using periodicity example of object classification person counting and non stationar y periodicity are provided 
the minimal data necessary for projective reconstruction from point correspondence is well known when the point are visible in all image in this paper we formulate and propose solution to a new family of reconstruction problem from multiple image with minimal data where there are missing point in some of the image the ability to handle the minimal case with missing data is of great theoretical and practical importance it is unavoidable to use them to bootstrap robust estimation such a ransac and lm algorithm and optimal estimation such a bundle adjustment first we develop a framework to parametrize the multiple view geometry needed to handle the missing data case then we present a solution to the minimal case of point in image where one of the point is missing in one of the three image we prove that there are in general a many a solution for this minimal case furthermore all minimal case with missing data for and in image are catalogued finally we demonstrate the method on both simulated and real image and show that the algorithm presented in this paper can be used for practical problem 
this paper address the issue of motion estimation on image sequence the standard motion equation used to compute the apparent motion of image irradiance pattern is an invariance brightness based hypothesis called the optical flow constraint other equation can be used in particular the extended optical flow constraint which is a variant of the optical flow constraint inspired by the fluid mechanic mass conservation principle in this paper we propose a physical interpretation of this extended optical flow equation and a new model unifying the optical flow and the extended optical flow constraint we present result obtained for synthetic and meteorological image 
background modeling is a common component in video surveillance system and is used to quickly identify region of interest to increase the robustness of background subtraction technique researcher have developed technique to update the background model and also developed probabilistic statistical approach for thresholding the difference this paper present an error analysis of this type of background modeling and pixel labeling providing both theoretical analysis and experimental validation evaluation is centered around the tradeoff of probability of false alarm and probability of miss detection and this paper show how to efficiently compute these probability from simpler value that are more easily measured it includes an analysis for both static and dynamic background modeling the paper also examines the assumption of gaussian and mixture of gaussian model for a pixel 
in this paper we present approach for detectingcamera cut wipe and dissolve based on the analysisof spatio temporal slice obtained from video theseslices are composed of spatially and temporally coherentregions which can be perceived a shot in the proposedmethods camera break are located by performingcolor texture segmentation and statistical analysison these video slice in addition to detecting camerabreaks our method can classify the detected break ascamera cut 
in stereoscopic image the behavior of a curve in space is related to the appearance of the curve in the left and right image plane formally this relationship is governed by the projective geometry induced by the stereo camera configuration and by the differential structure of the curve in the scene we propose that the correspondence problem matching corresponding point in the image plane can be solved by relating the differential structure in the left and right image plane to the geometry of curve in space specifically the compatibility between two pair of corresponding point and tangent at those point is related to the local approximation of a space curve using an osculating helix to guarantee robustness against small change in the camera parameter we select a specific osculating helix a relaxation labeling network demonstrates that the compatibility can be used to infer the appropriate correspondence in a scene example on which standard approach fail are demonstrated 
in proc of ieee int l conf on computer vision vancouver canada it is often tedious and expensive to label largetraining data set for learning based object recognitionsystems this problem could be alleviated by selfsupervisedlearning technique which take a hybrid oflabeled and unlabeled training data to learn classifier discriminant em d em proposed a framework forsuch task and current d em algorithm employed lineardiscriminant analysis however the algorithm is 
color is a useful feature for machine vision task however it effectiveness is often limited by the fact that the measured pixel value in a scene are influenced by both object surface reflectance property and incident illumination color constancy algorithm attempt to compute color feature which are invariant of the incident illumination by estimating the parameter of the global scene illumination and factoring out it effect a number of recently developed algorithm utilize statistical method to estimate the maximum likelihood value of the illumination parameter this paper detail the use of kl divergence a a mean of selecting estimated illumination parameter value we provide experimental result demonstrating the usefulness of the kl divergence technique for accurately estimating the global illumination parameter of real world image 
a panorama for visual stereo consists of a pair of panoramic image where one panorama is for the left eye and another panorama is for the right eye a panoramic stereo pair provides a stereo sensation up to a full degree a stereo panorama cannot be photographed by two omnidirectional camera from two viewpoint it is normally constructed by mosaicing together image from a rotating stereo pair or from a single moving camera capturing stereo panoramic image by a rotating camera make it impossible to capture dynamic scene at video rate and limit stereo panoramic imaging to stationary scene this paper present two possibility for capturing stereo panoramic image using optic without any moving part a special mirror is introduced such that viewing the scene through this mirror creates the same ray a those used with the rotating camera such a mirror enables the capture of stereo panoramic movie with a regular video camera a lens for stereo panorama is also introduced the design of the mirror and of the lens are based on curve whose caustic is a circle 
the problem of extracting continuous structure from noisy or cluttered image is a difficult one successful extraction depends critically on the ability to balance prior constraint on continuity and smoothness against evidence garnered from image analysis exact deterministic optimisation algorithm based on discretized functionals suffer from severe limitation on the form of prior constraint that can be imposed tractably this paper proposes a sequential monte carlo technique termed jetstream that enables constraint on curvature corner and contour parallelism to be mobilized all of which are infeasible under exact optimization the power of jetstream is demonstrated in two context interactive cut out in photo editing application and the recovery of road in aerial photograph 
in this paper we show how the use of hard constraint in solving estimation problem by allowing multiple source of information to be taken into account during optimization increase robustness and improves efficiency over alternative method such a the statistical combination of separate optimization result our argument is based on an empirical evaluation of the technique which us a model based optical flow constraint in a deformable model framework for tracking a face the flow constraint make the model toedge alignment optimization problem easier by projecting away the portion of the search space that optical flow make unlikely while a kalman filter is used to reconcile hard constraint with the uncertainty in the optical flow data using these hard constraint the system converges more quickly at each iteration and avoids local minimum in solution that cause other method to lose track we conjecture that this use of constraint will be effective in any integration application where there are disparity in the difficulty of computational problem associated with the use of different information source 
we present a novel mixed state dynamic bayesian network dbn framework for modeling and classifying timeseries data such a object trajectory a hidden markov model hmm of discrete action is coupled with a linear dynamical system lds model of continuous trajectory motion this combination allows u to model both the discrete and continuous cause of trajectory such a human gesture the model is derived using a rich theoretical corpus from the bayesian network literature this allows u to use an approximate structured variational inference technique to solve the otherwise intractable inference of action and system state using the same dbn framework we show how to learn the mixed state model parameter from data experiment show that with high statistical confidence the mixed state dbns perform favorably when compared to decoupled hmm lds model on the task of recognizing human gesture made with a computer mouse 
the classification of human body motion is a difficult problem in particular the automatic segmentation of sequence containing more than one class of motion is challenging an effective approach is to use mixed discrete continuous state to couple perception with classification a spline contour is used to track the outline of the person we show that for a quasi periodic human body motion an autoregressive process is a suitable model for the contour dynamic this can then be used a a dynamical model for mixed statecondensation filtering switching automatically between different motion class we have developed partial importance sampling to enhance the efficiency of the mixed state condensation filter it is also shown here that the importance sampling can be done in linear time in place of the previous quadratic algorithm tying of discrete state is used to obtain further efficiency improvement automatic segmentation is demonstrated on video sequence of aerobic exercise performance is promising but there remains a residual misclassification rate and possible explanation for this are discussed 
we propose a new framework for calibrating parameter of energy functionals a used in image analysis the method learns parameter from a family of correct example and given a probabilistic construct for generating wrong example from correct one we introduce a measure of frustration to penalize case in which wrong response are preferred to correct one and we design a stochastic gradient algorithm which converges to parameter which minimize this measure of frustration we also present a rst set of experiment in this context and introduce extension to deal with data dependent energy 
we present an algorithm that extract curve from a set of edgels within a specific class in a decreasing order of their length the algorithm inherits the perceptual grouping approach but instead of using only local cue a global constraint is imposed to each extracted subset of edgels that the underlying curve belongs to a specific class in order to reduce the complexity of the solution we work with a linearly parameterized class of curve function of one image coordinate this allows first to use a recursive kalman based fitting and second to cast the problem a an optimal path search in an directed graph experiment on finding lane marking on road demonstrate that real time processing is achievable 
while an exact definition of texture is somewhat elusive texture can be qualitatively described a a distribution of color albedo or local normal on a surface in the literature the word texture is often used to describe a color or albedo variation on a smooth surface we refer to such texture a d texture in real world scene texture is often due to surface height variation and can be termed d texture because of local foreshortening and masking oblique view of d texture are not simple transformation of the frontal view consequently texture representation such a the correlation function or power spectrum are also affected by local foreshortening and masking this work present a correlation model for a particular class of d texture the model characterizes the spatial relationship among neighboring pixel in an image of d texture and the change of this spatial relationship with viewing direction 
this paper describes a system that us a camera and a point light source to track a user s hand in three dimension using depth cue obtained from projection of the hand and it shadow the system computes the d position and orientation of two finger thumb and pointing finger the system recognizes one dynamic and two static gesture recognition and pose estimation are user independent and robust the system operates at the rate of hz and can be used a an intuitive input interface 
we propose a general framework for object tracking in video image it consists in low order parametric model for the image motion of a target region these model are used to predict the movement and to track the target the difference of intensity between the pixel belonging to the current region and the pixel of the selected target learnt during an off line stage allows a straightforward prediction of the region position in the current image the proposed algorithm allows to track in real time le than m any planar textured target under homographic motion this algorithm is very simple a few line of code and very efficient le than m on a mhz hardware 
one of the difficulty of color tracking is that color change in different lighting condition and static color model would be inadequate to capture the nonstationary color distribution over time although some work ha been done on adaptive color model this problem still need further investigation different from many other approach we formulate the nonstationary color tracking problem a a transductive learning problem in which the generalization of a trained color classifier is only defined on the pixel in a specific image rather than the whole color space this formulation offer a way to design and transduce color classifier through non stationary color distribution instead of assuming a color transition model we assume that some unlabeled pixel in a new image frame can be confidently labeled by a weak classifier according to a preset confidence level the proposed discriminant em d em algorithm offer an effective way to transduce color classifier a well a automatically select a good color space experiment show that d em successfully handle some problem in color tracking a a component our natural gesture interface this algorithm give tight bounding box of the hand or face region in video sequence 
submitted to the ieee conference on computer vision and pattern recognition in this paper we describe a novel generative modelfor video analysis called the transformed hidden markovmodel thmm the video sequence is modeled a a set offrames generated by transforming a small number of classimages that summarize the sequence for each frame thetransformation and the class are discrete latent variablesthat depend on the previous class and transformation inthe sequence the set of 
this paper considers the problem of self calibration of a camera from an image sequence in the case where the camera s internal parameter most notably focal length may change the problem of camera self calibration from a sequence of image ha proven to be a difficult one in practice due to the need ultimately to resort to non linear method which have often proven to be unreliable in a stratified approach to self calibration a projective reconstruction is obtained first and this is successively refined first to an affine and then to a euclidean or metric reconstruction it ha been observed that the difficult step is to obtain the affine reconstruction or equivalently to locate the plane at infinity in the projective coordinate frame the problem is inherently non linear and requires iterative method that risk not finding the optimal solution the present paper overcomes this difficulty by imposing cheirality constraint to limit the search for the plane at infinity to a dimensional cubic region of parameter space it is then possible to carry out a dense search over this cube in reasonable time for each hypothesised placement of the plane at infinity the calibration problem is reduced to one of calibration of a nontranslating camera for which fast non iterative algorithm exist a cost function based on the result of the trial calibration is used to determine the best placement of the plane at infinity because of the simplicity of each trial speed of over trial per second are achieved on a mhz processor it is shown that this dense search allows one to avoid area of local minimum effectively and find global minimum of the cost function 
the visual hull is a geometric tool which relates the d shape of a concave object to it silhouette or shadow this paper develops the theory of the visual hull of object bounded by smooth curved surface from the basic definition of visual hull we determine the surface which bound the visual hull of such object we show that these surface are patch of some surface which partition the viewpoint space of the aspect graph of the object the surface concerned are those generated by the visual event tangent crossing and triple point these ruled surface are analyzed for finding their active part i e the part which could actually bound the visual hull this analysis is based on the shape of the surface of the object at the tangency point of the ruled surface an algorithm for computing the visual hull of a smooth curved object is outlined which exploit the algorithm for computing it aspect graph 
study of image motion typically address motion category on a case by case basis example include a moving point a moving contour or a d optical flow field the typical assumption made in these study is that there is a unique velocity at each moving point in the image in this paper we relax this assumption we introduce a broader set of motion category in which the set of motion at a moving point can be d d or d we consider one new motion category in detail which we call optical snow this motion category occurs for example when an observer translates relative to a massively cluttered scene example include the motion seen by an observer moving through bush or falling snow seen by a stationary observer optical snow is characterized by a d set of velocity at each moving point and a such it cannot be analyzed using a classical computational method such a optical flow we introduce a technique for analyzing optical snow which is based on a bow tie signature of the motion in the frequency domain we demonstrate the effectiveness of the technique using both synthetic and real image sequence 
the paper describes a scheme for detecting vehicle in image the proposed method approximately model the unknown distribution of the image of vehicle by learning higher order statistic ho information of the vehicle class from sample image given a test image statistical information about the background is learnt on the y an ho based decision measure then classifies test pattern a vehicle or otherwise when tested on real image of aerial view of vehicular activity the method give good result even on complicated scene it doe not require any a priori information about the site however it is amenable to augmentation with contextual information the method can serve a an important step towards building an automated roadway monitoring system 
classifying an unknown input is a fundamental problem in pattern recognition one standard method is finding it nearest neighbor in a reference set it would be very time consuming if computed feature by feature for all template in the reference set this naive method is o nd where n is the number of template in the reference set and d is the number of feature or dimension for this reason we present a technique for quickly eliminating most template from consideration a possible neighbor the remaining candidate template are then evaluated feature by feature against the query vector we utilize frequency of feature a a pre processing to reduce query processing time burden the most notable advantage of the new method over other existing technique occurs where the number of feature is large and the type of each feature is binary although it work for other type feature we improved our ocr system by at least a factor of without a threshold or faster with higher threshold value 
we present a new formulation of sequential least square applied to scene and motion reconstruction from image feature we argue that recursive technique will become more important both for real time control application and also interactive vision application the aim is to approximate a well a possible the result of the batch bundle adjustment method in previously published work we described an algorithm which work well if the same feature are visible throughout the sequence here we show how to deal with new feature in a way that avoids deterioration of the result the main theoretical advance here is showing how to adjust the system information matrix when scene camera parameter are removed from the reconstruction we show how this procedure affect the sparseness of the information matrix and thus how to achieve an efficient recursive solution to the reconstruction problem 
two basic problem in image interpretation are a determining which interpretation are the most plausible amongst many possibility and b controlling the search for plausible interpretation we address these issue using a bayesian approach with the plausibility ordering and search pruning based on the posterior probability of interpretation however due to the need for detailed quantitative prior probability and the need to evaluate complex integral over various conditional distribution a full bayesian approach is currently impractical except in tightly constrained domain to circumvent these difficulty we introduce the notion of qualitative probabilistic analysis in particular given spatial and contrast resolution parameter we consider only the asymptotic order of the posterior probability for any interpretation a these resolution are made finer we introduce this approach for a simple card world domain and present computational result for block world image 
we propose in this paper a new d fully parallelthinning algorithm that we believe to be the most concisedue to it simple characterization the algorithmis indeed completely dened by a set of ve pattern three removing condition and two non removing condition these pattern are designed from the two fundamentaland compatible constraint usually expectedin skeleta topology preservation and medialsurface from these two constraint the removing pattern and 
we present a new method to shape based segmentation of deformable anatomical structure in medical image and validate this approach by detecting and tracking the endocardial border in an echographic image sequence to this end a global prior knowledge of the endocardial contour is captured by a prototype template with a set of admissible deformation to take into account it inherent natural variability over time in this approach the data likelihood model rely on an accurate statistical modeling of the grey level distribution of each class present in the image the parameter of this distribution mixture are given by a preliminary estimation step which take into account the distribution shape of each class then the tracking problem is stated in a bayesian framework where it end up a an optimization problem this one is then efficiently solved by a genetic algorithm combined with a steepest ascent procedure this technique ha been successfully applied on synthetic image and on a real echocardiographic image sequence 
consider the situation of a monocular image sequence with known ego motion observing a d point moving simultaneously but along a path of up to second order i e it can trace a line in d or a conic shaped path we wish to reconstruct the d path from the projection of the tangent to the path at each time instance this problem is analogue to the trajectory triangulation of line and conic section recently introduced in but instead of observing a point projection we observe a tangent projection and thus obtain a far simpler solution to the problem we show that the d path can be solved in a natural manner and linearly using degenerate quadric envelope specifically the disk quadric our approach work seamlessly with both linear and second order path thus there is no need to know in advance the shape of the path a with the previous approach for which line and conic were treated a distinct our approach is linear in both straight line and conic path unlike the non linear solution associated with point trajectory we provide experiment that show that our method behaves extremely well on a wide variety of scenario including those with multiple moving object along line and conic shaped path 
this paper describes a probabilistic multiple hypothesis framework for tracking highly articulated object in this framework the probability density of the tracker state is represented a a set of mode with piecewise gaussians characterizing the neighborhood around these mode the temporal evolution of the probability density is achieved through sampling from the prior distribution followed by local optimization of the sample position to obtain updated mode this method of generating hypothesis from state space search doe not require the use of discrete feature unlike classical multiple hypothesis tracking the parametric form of the model is suited for high dimensional state space which cannot be efficiently modeled using non parametric approach result are shown for tracking fred astaire in a movie dance sequence 
in this paper we present a new method for vision based reactive robot navigation that enables a robot to move in the middle of the free space by exploiting both central and peripheral vision the robot employ a forward looking camera for central vision and two side looking camera for sensing the periphery of it visual field the developed method combine the information acquired by this trinocular vision system and produce low level motor command that keep the robot in the middle of the free space the approach follows the purposive vision paradigm in the sense that vision is not studied in isolation but in the context of the behavior that the system is engaged a well a the environment and the robot s motor capability it is demonstrated that by taking into account these issue vision processing can be drastically simplified still giving rise to quite complex behavior the proposed method doe not make strict assumption about the environment requires very low level information to be extracted from the image produce a robust robot behavior and is computationally efficient result obtained by bath simulation and from a prototype on line implementation demonstrate the effectiveness of the method 
we use cluster analysis a a unifying principle for problem from low middle and high level vision the clustering problem is viewed a graph partitioning where node represent data element and the weight of the edge represent pairwise similarity our algorithm generates sample of cut in this graph by using david karger s contraction algorithm and computes an ave rage cut which provides the basis for our solution to the clustering problem the stochastic nature of our method make it robust against noise including accidental edge and small spurious cluster the complexity of our algorithm is very low for object and a fixed accuracy level without additional computational cost our algorithm provides a hierarchy of nested partition we demonstrate the superiority of our method for image segmentation on a few real color image our second application includes the concatenation of edge in a cluttered scene perceptual grouping where we show that the same clustering algorithm achieves a good a grouping if not better a more specialized method tween the visual entity the affinity is a function of the relevant attribute low level attribute may be the spatial location intensity level color composition or filter response of a pixel in the image mid level attribute in the case of edge element may be spatial location orientation or curvature and the affinity associated with them may reflect property such a proximity symmetry co circuitry and good continuity high level attribute may be a complex a the entire shape of an object in the scene or the color distribution of all the pixel in an image the second stage in this approach follows the unifying principle and applies cluster analysis to the organizion of the visual object pixel edgels image into coherent group these group reflect internal structure among the entity where roughly speaking the affinity within group is larger than the affinity between group therefore a cluster of pixel in the image sharing similar location and color is expected to account for an object or a part of an object in the scene a cluster of edge element is expected to exhibit a meaningful aggregation into a complete edge and a cluster of image in a database is expected to be related with a common topic we present in section our stochastic pairwise clustering algorithm it is an efficient robust and model free pairwise hierarchical algorithm see also the robust 
we present a new on line scheme for the recognition and pose estimation of a large isolated d object which may not entirely fit in a camera s field of view we do not assume any knowledge of the internal parameter of the camera or their constancy we use a probabilistic reasoning framework for recognition and next view planning we show result of successful recognition and pose estimation even in case of a high degree of interpretation ambiguity associated with the initial view 
we present a live web defect detection and classification system that run on a laptop pc with an attached camera feature invariant with respect to rotation and translation based on local integration are extracted from the grabbed image they are then presented to a neural network for classification 
abstract this paper describes a new methodfortracking of a human body in d motion by using constraint imposed on the body from the scene an image basedapproach for tracking exclusively us a geometrical model of the human body since the model usually ha a large number of degree of freedom dof a chancetobe corrupted by noise increase during the tracking process and the tracking may fall in an ill posedproblem tocope with this problem we pay our attention to that a human body can not move 
this paper describes a face detection framework that is capable of processing image extremely rapidly while achieving high detection rate there are three key contribution the first is the introduction of a new image representation called the integral image which allows the feature used by our detector to be computed very quickly the second is a simple and efficient classifier which is built using the adaboost learning algorithm freund and schapire to select a small number of critical visual feature from a very large set of potential feature the third contribution is a method for combining classifier in a cascade which allows background region of the image to be quickly discarded while spending more computation on promising face like region a set of experiment in the domain of face detection is presented the system yield face detection performance comparable to the best previous system sung and poggio rowley et al schneiderman and kanade roth et al implemented on a conventional desktop face detection proceeds at frame per second 
ing the sequence causally the pose ofthe virtual object at time t is decided based on observationsof the sequence up to time t this enables a whole newthis research is supported in part by intel grant figure once the camera motion and the scene structure areestimated we insert a quot virtual quot vase into the scene a it can be observed it relative position is fixed within the scene four renderedviews corresponding to the snapshot in figure are shown range of 
for grey value image it is well accepted that the neighborhood rather than the pixel carry the geometrical interpretation interestingly the spatial configuration of the neighborhood is the basis for the perception of human common practise in color image processing is to use the color information without considering the spatial structure we aim at a physical basis for the local interpretation of color image we propose a framework for spatial color measurement based on the gaussian scale space theory we consider a gaussian color model which inherently us the spatial and color information in an integrated model the framework is well founded in physic a well a in measurement science the framework delivers sound and robust spatial color invariant feature the usefulness of the proposed measurement framework is illustrated by edge detection where edge are discriminated a shadow highlight or object boundary other application of the framework include color invariant image retrieval and color constant edge detection 
existing sequential feature based registration algorithm involving search typically either select feature randomly e g the ransac approach m fischler and r bolles or assume a predefined intuitive ordering for the feature e g based on size or resolution the paper present a formal framework for computing an ordering for feature which maximizes search efficiency feature are ranked according to matching ambiguity measure and an algorithm is proposed which couple the feature selection with the parameter estimation resulting in a dynamic feature ordering the analysis is extended to template feature where the matching is non discrete and a sample refinement process is proposed the framework is demonstrated effectively on the localization of a person in an image using a kinematic model with template feature different prior are used on the model parameter and the result demonstrate nontrivial variation in the optimal feature hierarchy 
we present a framework for tracking rigid object based on an adaptive bayesian recognition technique that incorporates dependency between object feature at each frame we find a maximum a posteriori map estimate of the object parameter that include positioning and configuration of non occluded feature this estimate may be rejected based on it quality our careful selection of data point in each frame allows temporal fusion via kalman filtering despite unimodality of our tracking scheme we demonstrate fairly robust result in highly cluttered aerial scene our technique form a natural feedback loop between the recognition method and the filter that help to explain such robustness we study this loop and derive a number of interesting property first the effective threshold for recognition in each frame is adaptive it depends on the current level of noise in the system this allows the system to identify partially occluded or distorted object a long a the predicted location are accurate but requires a very good match if there is uncertainty a to the object location second the search area for the recognition method is automatically pruned based on the current system uncertainty yielding an efficient overall method 
an algorithm is given for computing projective structure from a set of six point seen in a sequence of many image the method is based on the notion of duality between camera and point first pointed out by carlsson and weinshall the current implementation avoids the weakness inherent in previous implementation of this method in which numerical accuracy is compromised by the distortion of image point error distribution under projective transformation it is shown in this paper that one may compute the dual fundamental matrix by minimizing a cost function giving a first order approximation to geometric distance error in the original untransformed image measurement this is done by a modification of a standard near optimal method for computing the fundamental matrix subsequently the error measurement are adjusted optimally to conform with exact imaging geometry by application of the triangulation method of hartley sturm 
in this paper we present a theory for obtaining density that are important for computer vision a a result of the theory we compute the exact and novel density of the slope of a line fitted to image point this density make it possible to obtain confidence interval for the slope or to make hypothesis testing about if two intersecting line form a corner or not the theory also let u derive a novel technique for maximum likelihood estimation that can be used for computing the fundamental matrix conic or any other constraint that can be expressed by polynomial of degree we present exact and novel density for the fundamental matrix and conic constraint that are needed for the estimation experiment show how the result can be used in practice to compute maximum likelihood estimate of the fundamental matrix 
we present an aspect graph approach to d object recognition where the definition of an aspect is motivated by it role in the subsequent recognition step specifically we measure the similarity between two view by a d shape metric of similarity measuring the distance between the pro jected segmented shape of the d object this endows the viewing sphere with a metric which is used to group similar view into aspect and to represent each aspect by a prototype the same shape similarity metric is then used to rate the similarity between unknown view of unknown object and stored prototype to identify the object and it pose the performance of this approach on a database of object each viewed in five degree increment along the ground viewing plane is demonstrated 
we present a method for region identification in multiple image a set of region in different image and the correspondence on their boundary can be thought of a a boundary in the multi dimensional space formed by the product of the individual image domain we minimize an energy functional on the space of such boundary thereby identifying simultaneously both the optimal region in each image and the optimal correspondence on their boundary we use a ratio form for the energy functional thus enabling the global minimization of the energy functional using a polynomial time graph algorithm among other desirable property we choose a simple form for this energy that favour boundary that lie on high intensity gradient in each image while encouraging correspondence between boundary in different image that match intensity value the latter tendency is weighted by a novel heuristic energy that encourages the boundary to lie on disparity or optical flow discontinuity although no dense optical flow or disparity map is computed 
there ha recently been significant interest in using representation based on abstraction of blum s skeleton into a graph for qualitative shape matching the application of these technique to large database of shape hinge on the availability of numerical algorithm for computing the medial axis unfortunately this computation can be extremely subtle approach based on voronoi technique preserve topology but heuristic pruning measure are introduced to remove unwanted edge method based on euclidean distance function can localize skeletal point accurately but often at the cost of altering the object s topology in this paper we introduce a new algorithm for computing subpixel skeleton which is robust and accurate ha low computational complexity and preserve topology the key idea is to measure the net outward flux of a vector field per unit area and to detect location where a conservation of energy principle is violated this is done in conjunction with a thinning process applied in a rectangular lattice we illustrate the approach with several example of skeletal graph for biological and man made silhouette 
the light reflected from a surface depends on the scene geometry the incident illumination and the surface material one of the property of the material is it albedo r l and it variation with respect to wavelength the albedo of a surface is purely a physical property our perception of albedo is commonly referred to a colour this paper present a novel methodology for extracting the albedo of the various material in the scene independent of incident light and scene geometry a scene is captured under different narrow band colour filter and the spectral derivative of the scene are computed the resulting spectral derivative form a spectral gradient at each pixel this spectral gradient is a normalized albedo descriptor which is invariant to scene geometry and incident illumination for diffuse surface 
this paper present a database containing ground truth segmentation produced by human for image of a wide variety of natural scene we define an error measure which quantifies the consistency between segmentation of differing granularity and find that different human segmentation of the same image are highly consistent use of this dataset is demonstrated in two application evaluating the performance of segmentation algorithm and measuring probability distribution associated with gestalt grouping factor a well a statistic of image region property 
inferring both d structure and motion of nonrigidobjects from monocular image is an important problemin computational vision the challenge stem notonly from the absence of point correspondence but alsofrom the structure ambiguity in this paper a hierarchicalmethod which integrates both local patch analysisand global shape description is devised to solvethe dual problem of structure and nonrigid motion recoveryby using an elastic geometric model extendedsuperquadrics the 
maximization of cross correlation is a commonly used principle for intensity based object localization that give a single estimate of location however to facilitate sequential inference eg over time or scale and to allow the representation of ambiguity it is desirable to represent an entire probability distribution for object location although the cross correlation itself or some function of it ha sometimes been treated a a probability distribution this is not generally justifiable bayesian correlation achieves a consistent probabilistic treatment by combining several development the first is the interpretation of correlation matching function in probabilistic term a observation likelihood second probability distribution of filter bank response are learned from training example inescapably response learning also demand statistical modeling of background intensity and there are link here with image coding and independent component analysis lastly multi scale processing is achieved in a bayesian context by mean of a new algorithm layered sampling for which asymptotic property are derived 
combining learning with vision technique in interactive image retrieval ha been an active research topic during the past few year however existing learning technique eith er are based on heuristic or fail to analyze the working condition furthermore there is almost no in depth study on how to effectively learn from the user when there are multiple visual feature in the retrieval system to address thes e limitation in this paper we present a vigorous optimization formulation of the learning process and solve the problem in a principled way by using lagrange multiplier we have derived explicit solution which are both optimal and fast to compute extensive comparison against state ofthe art technique have been performed experiment were carried out on a large size heterogeneous image collection consisting of image retrieval performance wa tested under a wide range of condition various evaluation criterion including precision recall curve and rank measu re have demonstrated the effectiveness and robustness of the proposed technique 
given video footage of a person s face we present new technique to automatically recover the face position and the facial expression from each frame in the video sequence a d face model is fitted to each frame using a continuous optimization technique our model is based on a set of d face model that are linearly combined using d morphing our method ha the advantage over previous technique of fitting directly a realistic dimensional face model and of recovering parameter that can be used directly in an animation system we also explore many application including performance driven animation applying the recovered position and expression of the face to a synthetic character to produce an animation that mimic the input video relighting the face varying the camera position and adding facial ornament such a tattoo and scar 
abstract an improved method for deformable shape based image segmentation is described image region are merged together and or split apart based on their agreement with an a priori distribution on the global deformation parameter for a shape template the quality of a candidate region merging is evaluated by a cost measure that includes homogeneity of image property within the combined region degree of overlap with a deformed shape model and a deformation likelihood term perceptually motivated criterion are used to determine where how to split region based on the local shape property of the region group s bounding contour a globally consistent interpretation is determined in part by the minimum description length principle experiment show that the model based splitting strategy yield a significant improvement in segmention over a method that us merging alone 
in recent year several technique have been proposed for modelling the low dimensional manifold or subspace of natural image example include principal component analysis a used for instance in eigen face independent component analysis and auto encoder neural network such method suffer from a number of restriction such a the limitation to linear manifold or the absence of a probablistic representation in this paper we exploit recent development in the field of variational inference and latent variable model to develop a novel and tractable probabilistic approach to modelling manifold which can handle complex non linearity our framework comprises a mixture of sub space component in which both the number of component and the effective dimensionality of the subspace are determined automatically a part of the bayesian inference procedure we illustrate our approach using two classical problem modelling the manifold of face image and modelling the manifold of hand written digit 
we present a modeland exemplar based technique for head pose tracking because of the dynamic nature it is not possible to represent face appearance by a single texture image instead we sample the complex face appearance space by a few reference image exemplar by taking advantage of the rich geometric information of a d face model and the flexible representation provided by exemplar our system is able to track head pose robustly under occlusion and or varying facial expression the system start with a simple learning stage the user move his her head with a neutral expression in front of the camera within the working space our system automatically build a personalized d face model by fitting a generic mesh model to a near frontal facial image and acquires a few reference image at distinct pose to sparsely sample the facial appearance space when tracking the head under occlusion and varying expression we match the current view against the most appropriate reference image according to the predicted pose which is much easier and more robust than if only a single texture image is used a robust motion segmentation algorithm is used to separate point match corresponding to rigid head motion from those corresponding to facial deformation the head pose can then be reliably estimated from the rigid motion point with the help of the d face mesh model even when the number of point is small since we use reference image during tracking the accumulative error inherent in frame by frame tracking is avoided and more accurate pose estimation is achieved we demonstrate the validity of our approach with several video sequence acquired in a casual environment 
this paper address the problem of predicting fundamentalperformance of vote based object recognitionusing d point feature it present a method for predictinga tight lower bound on performance unlikeprevious approach the proposed method considersdata distortion factor namely uncertainty occlusion and clutter in addition to model similarity simultaneously the similarity between every pair of modelobjects is captured by comparing their structure a afunction of the 
line scratch are common degradation in motion picture film this paper present an efficient method for line scratch detection strengthened by a kalman filter a new interpolation technique dealing with both low and high frequency i e film grain around the line artifact is investigated to achieve a nearby invisible reconstruction of damaged area our line scratch detection and removal technique have been validated on several film sequence 
the quadrifocal tensor which connects image measurement along view is not yet well understood a it counterpart the fundamental matrix and the trifocal tensor this paper establishes the structure of the tensor a an epipole homography pairing qijkl v j hikl v k hijl v l hijk where v v v are the epipoles in view h is the homography tensor the view analogue of the homography matrix and the index i j k l are attached to view respectively i e hikl is the homography tensor of view in the course of deriving the structure qijkl we show that linear line complex llc mapping are the basic building block in the process we also introduce a complete break down of the tensor slice slice are homography tensor and slice are llc mapping furthermore we present a closed form formula of the quadrifocal tensor described by the trifocal tensor and fundamental matrix and also show how to recover projection matrix from the quadrifocal tensor we also describe the form of the non linear constraint a quadrifocal tensor must adhere to 
this paper present a novel variational method for supervised texture segmentation the textured feature space is generated by filtering the given textured image using isotropic and anisotropic filter and analyzing their response a multi component conditional probability density function the texture segmentation is obtained by unifying region and boundary based information a an improved geodesic active contour model the defined objective function is minimized using a gradient descent method where a level set approach is used to implement the obtained pde according to this pde the curve propagation towards the final solution is guided by boundary and region based segmentation force and is constrained by a regularity force the level set implementation is performed using a fast front propagation algorithm where topological change are naturally handled the performance of our method is demonstrated on a variety of synthetic and real textured frame 
this paper describes method for tracking using point and line feature in affine view to provide fundamental invariance to change of focal length it first demonstrates how an earlier method of transfer based tracking using spatio temporal matching of point feature in a stereo active head is indeed zoom invariant in order to also make use of line the paper then illustrates how the affine triand quadrifocal tensor may be applied to tracking with zoom in monocular and stereo system respectively the usefulness of the tensor is evident from their ability to transfer a fixation point in two uncalibrated image into novel view whereas the trifocal tensor is already familiar and in common use for matching and reconstruction we believe this to be the first practical application of a quadrifocal tensor we develop expression for affine triand quadrifocal tensor and using novel affine specialization of existing projective algorithm we show how computation of the tensor is faster simpler and more stable experiment on real image are presented 
we introduce radial basis function with compact support for elastic registration of medical image with these basis function the influence of a landmark on the registration result is limited to a circle in d and respectively to a sphere in d therefore the registration can be locally constrained which especially allows to deal with rather local change in medical image due to e g tumor resection an important property of the used rbfs is that they are positive definite thus the solvability of the resulting system of equation is always guaranteed we demonstrate our approach for synthetic a well a for d and d tomographic image 
presented at the ieee conference on computer vision and pattern recognition ft collins co june mixture modeling and clustering algorithm are effective simple way to represent image using a set of data center however in situation where the image include background clutter and transformation such a translation rotation shearing and warping these method extract data center that include clutterand represent different transformation of essentiallythe same data taking 
conventional vision system are designed to perform in clear weather however any outdoor vision system is incomplete without mechanism that guarantee satisfactory performance under poor weather condition it is known that the atmosphere can significantly alter light energy reaching an observer therefore atmospheric scattering model must be used to make vision system robust in bad weather in this paper we develop a geometric framework for analyzing the chromatic effect of atmospheric scattering first we study a simple color model for atmospheric scattering and verify it for fog and haze then based on the physic of scattering we derive several geometric constraint on scene color change caused by varying atmospheric condition finally using these constraint we develop algorithm for computing fog or haze color depth segmentation extracting three dimensional structure and recovering true scene color from two or more image taken under different but unknown weather condition spective of scene radiance they also proposed a dichromatic atmospheric scattering model that describes the dependence of atmospheric scattering on wavelength however the algorithm they developed to recover structure using this model requires a clear day image of the scene in this paper we develop a general chromatic framework for the analysis of image taken under poor weather condition the wide spectrum of atmospheric particle make a general study of vision in bad weather hard so we limit ourselves to weather condition that result from fog and haze we begin by describing the key mechanism of scattering next we analyze the dichromatic model proposed in nn a nd experimentally verify it for fog and haze then we derive several useful geometric constraint on scene color change due to different but unknown atmospheric condition finally we develop algorithm to compute fog or haze color to construct depth map of arbitrary scene and to recover scene color a they would appear on a clear day all of our method only require image of the scene taken under two or more poor weather condition and not a clear day image of the scene 
object shape and camera motion recovery from animage sequence is a crucial issue in computer visionand many method have been proposed by researcher theoretically these method are perfect but they aresensitive to noise so that in many practical situation satisfactory result cannot be obtained to solvethis problem we propose a shape and motion recoverymethod using a gyro sensor attached on a video camerafor compensating image we made an experimentalsystem with a ccd camera 
we present a novel algorithm performing projective rectification which doe not require explicit computation of the epipolar geometry and specifically of the fundamental matrix instead of finding the epipoles and computing two homographies mapping the epipoles to infinity a done in recent work on projective rectification we exploit the fact that the fundamental matrix of a pair of rectified image ha a particular known form this allows u to set up a minimization that yield the rectifying homographies directly from image correspondence experimental result show that our method work quite robustly even in the presence of noise and with inaccurate point correspondence the code of our implementation will be made available at the author s web site 
design and development of novel human computer interface pose a challenging problem action and intention of user have to be inferred from sequence of noisy and ambiguous multi sensory data such a video and sound temporal fusion of multiple sensor ha been efficiently formulated using dynamic bayesian network dbns which allow the power of statistical inference and learning to be combined with contextual knowledge of the problem unfortunately simple learning method can cause such appealing model to fail when the data exhibit complex behavior we formulate a learning framework for dbns based on error feedback and statistical boosting theory we apply this framework to the problem of audio visual speaker detection in an interactive kiosk environment using off theshelf visual and audio sensor face skin texture mouth motion and silence detector detection result obtained in this setup demonstrate superiority of our learning framework over that of the classical ml learning in dbns 
the appearance of object consists of region of localstructure a well a dependency between these region the local structure can be characterized by a vector oflocal feature measured by local operator such a gaussianderivatives or gabor filter this paper present atechnique in which the appearance of object is representedby the joint statistic of local neighborhood operator a probabilistic technique based on joint statisticsis developed for the identification of multiple 
this paper proposes a novel technique to computing geometric information from image captured under parallel projection parallel image are desirable for stereo reconstruction because parallel projection significantly reduces foreshortening a a result correlation based matching becomes more effective since parallel projection camera are not commonly available we construct parallel image by rebinning a large sequence of perspective image epipolar geometry depth recovery and projective invariant for both d and d parallel stereo are studied from the uncertainty analysis of depth reconstruction it is shown that parallel stereo is superior to both conventional perspective stereo and the recently developed multiperspective stereo for vision reconstruction in that uniform reconstruction error is obtained in parallel stereo traditional stereo reconstruction technique e g multi baseline stereo can still be applicable to parallel stereo without any modification because epipolar line in a parallel stereo are perfectly straight experimental result further confirm the performance of our approach 
we propose an efficient solution to the general m view projective reconstruction problem using matrix factorization and iterative least square the method can accept input with missing data meaning that not all point are necessarily visible in all view it run much faster than the often used non linear minimization method while preserving the accuracy of the latter the key idea is to convert the minimization problem into a series of weighted least square sub problem with drastically reduced matrix size additionally we show that good initial value can always be obtained experimental result on both synthetic and real data are presented potential application are also demonstrated 
we propose a new method for tracking rigid object in image sequence using template matching a kalman filter is used to make the template adapt to change in object orientation or illumination this approach is novel since the kalman filter ha been used in tracking mainly for smoothing the object trajectory the performance of the kalman filter is further improved by employing a robust and adaptive filtering algorithm special attention is paid to occlusion handling 
we investigate the motion that lead to ambiguous euclidean scene reconstruction under several common calibration constraint giving a complete description of such critical motion for i internally calibrated orthographic and perspective camera ii in two image for camera with unknown focal length either different or equal one aim of the work wa to evaluate the potential of modern algebraic geometry tool for rigorously proving property of vision algorithm so we use idealtheoretic calculation a well a classical algebra and geometry we also present numerical experiment showing the effect of near critical configuration for the varying and fixed focal length method 
in this paper we introduce a new tool called a pseudo distance map pdm for extracting skeleton from grayscale image without region segmentation or edge detection given an edge strength function esf of a gray scale image the pdm is computed from the esf using the partial differential equation we propose the pdm can be thought of a a relaxed version of a euclidean distance map therefore it ridge correspond to the skeleton of the original gray scale image and it provides information on the approximate width of skeletonized structure since the pdm is directly computed from the esf without thresholding it the skeletonization result is generally robust and le noisy we tested our method using a variety of synthetic and real image the experimental result show that our method work well on such image 
a new definition of affine invariant skeleton for shape representation is introduced a point belongs to the affine skeleton if and only if it is equidistant from at least two point of the curve with the distance being a minimum and given by the area between the curve and it corresponding chord the skeleton is robust eliminating the need for curve denoising previous approach have used either the euclidean or affine distance thereby resulting in a much le robust computation we propose a simple method to compute the skeleton and give example with real image and show that the proposed definition work also for noisy data we also demonstrate how to use this method to detect affine skew symmetry 
this paper present a technique for blindly removing image non linearity in the absence of any calibration information or explicit knowledge of the imaging device the basic approach exploit the fact that a non linearity introduces specific higher order correlation in the frequency domain beyond second order these correlation can be detected using tool from polyspectral analysis the non linearity can then be estimated and removed by simply minimizing these correlation 
since the human hand is highly articulated and deformable hand posture recognition is a challenging example in the research on view independent object recognition due to the difficulty of the model based approach the appearance based learning approach is promising to handle large variation in visual input however the generalization of many proposed supervised learning method to this problem often suffers from the insufficiency of labeled training data this paper describes an approach to alleviate this difficulty by adding a large unlabeled training set combining supervised and unsupervised learning paradigm a novel and powerful learning approach the discriminant em d em algorithm is proposed in this paper to handle the case of a small labeled training set experiment show that d em outperforms many other learning method based on this approach we implement a gesture interface to recognize a set of predefined gesture command and it is also extended to hand detection this algorithm can also apply to other object recognition task 
the initialisation of segmentation method aiming at the localisation of biological structure in medical imagery is frequently regarded a a given precondition in practice however initialisation is usually performed manually or by some heuristic preprocessing step moreover the same framework is often employed to recover from imperfect result of the subsequent segmentation therefore it is of crucial importance for everyday application to have a simple and effective initialisation method at one s disposal this paper proposes a new model based framework to synthesise sound initialisation by calculating the most probable shape given a minimal set of statistical landmark and the applied shape model shape information coded by particular point is first iteratively removed from a statistical shape description that is based on the principal component analysis of a collection of shape instance by using the inverse of the resulting operation it is subsequently possible to construct initial outline with minimal effort the whole framework is demonstrated by mean of a shape database consisting of a set of corpus callosum instance furthermore both manual and fully automatic initialisation with the proposed approach is evaluated the obtained result validate it suitability a a preprocessing step for semi automatic a well a fully automatic segmentation and last but not least the iterative construction of increasingly point invariant shape statistic provides a deeper insight into the nature of the shape under investigation 
abstract traditional plane alignment technique are typically performed between pair of frame in this paper we present a method for extending existing two frame planar motion estimation technique into a simultane ous multi frame estimation by exploiting multi frame geometric constraint of planar surface the paper ha three main contribution i we show that when the camera calibration doe not change the collection of all parametric image motion of a planar surface in the scene across multiple frame is embedded in a low dimensional linear subspace ii we show that the rel ative image motion of multiple planar surface across multiple frame is embedded in a yet lower dimensional linear subspace even with varying camera calibration and iii we show how these multi frame constraint can be incorporated into simultaneous multi frame e timation of planar motion without explicitly recovering any d information or camera calibration the result ing multi frame estimation process is more constrained than the individual two frame estimation leading to more accurate alignment even when applied to small image region 
a new method for d rigid motion estimation from stereo is proposed in this paper the appealing feature of this method is that it directly us the disparity image obtained from stereo matching we assume that the stereo rig ha parallel camera and show in that case the geometric and topological property of the disparity image then we introduce a rigid transformation called d motion that map two disparity image of a rigidly moving object we show how it is related to the euclidean rigid motion and a motion estimation algorithm is derived we show with experiment that our approach is simple and more accurate than standard approach 
a mechanism is proposed that integrates low level image processing mid level recursive d trajectory estimation and high level action recognition process it is assumed that the system observes multiple moving object via a single uncalibrated video camera a novel extended kalman filter formulation is used in estimating the relative d motion trajectory up to a scale factor the recursive estimation process provides a prediction and error measure that is exploited in higher level stage of action recognition conversely higher level mechanism provide feedback that allows the system to reliable segment and maintain the tracking of moving object before during and after occlusion the d trajectory occlusion and segmentation information are utilized in extracting stabilized view of the moving object trajectory guided recognition tgr is proposed a a new and efficient method for adaptive classification of action the tgr approach is demonstrated using motion history image that are then recognized via a mixture of gaussian classifier the system wa tested in recognizing various dynamic human outdoor activity e g running walking roller blading and cycling experiment with synthetic data set are used to evaluate stability of the trajectory estimator with respect to noise 
in this paper parallelepiped and their use in camera calibration and d reconstruction process are studied parallelepiped naturally characterize rigidity constra ints present in a scene such a parallelism and orthogonality a subclass of parallelepiped the cuboid ha been frequently used over the past to partially calibrate camera however the full potential of parallelepiped in camera calibration a well a in scene reconstruction ha never been clearly established we propose a new framework for the use of parallelepiped which is based on an extensive study of this potential in particular we exhibit the complete duality that exists between the intrinsic metric char acteristics of a parallelepiped and the intrinsic paramete r of a camera our framework allows to fully exploit parallelepiped and thus overcomes several limitation of calibration approach based on cuboid to illustrate this framework we present an original and very efficient interactive method for d reconstruction from single image this method allows to quickly build a scene model from a single uncalibrated image 
several new algorithm for visual correspondence based on graph cut have recently been developed while these method give very strong result in practice they do not handle occlusion properly specifically they treat the two input image asymmetrically and they do not ensure that a pixel corresponds to at most one pixel in the other image in this paper we present two new method which properly address occlusion while preserving the advantage of graph cut algorithm we give experimental result for stereo a well a motion which demonstrate that our method perform well both at detecting occlusion and computing disparity 
in this paper we describe a statistical method for d object detection we represent the statistic of both object appearance and non object appearance using a product of histogram each histogram represents the joint statistic of a subset of wavelet coefficient and their position on the object our approach is to use many such histogram representing a wide variety of visual attribute using this method we have developed the first algorithm that can reliably detect human face with out of plane rotation and the first algorithm that can reliably detect passenger car over a wide range of viewpoint 
a simple effective way to model image is to represent each input pattern by a linear combination of component vector where the amplitude of the vector are modulated to match the input this approach includes principal component analysis independent component analysis and factor analysis in practice image are subjected to randomly selected transformation of a known nature such a translation and rotation direct use of the above method will lead to severely blurred component that tend to ignore the more interesting and useful structure in previous work we introduced a clustering algorithm that is invariant to transformation in this paper we propose a method called transformed component analysis which incorporates a discrete hidden variable that account for transformation and us the expectation maximization algorithm to jointly extract component and normalize for transformation we illustrate the algorithm using a shading problem facial expression modeling and written digit recognition 
it is commonly held that skeleton are sensitive to noise it is also believed that smoothing typically invoked to combat noise obeys the causality principle that no new structure are created via smoothing we demonstrate that both view are incorrect we characterize how smooth point of the skeleton evolve under a general boundary evolution with the corollary that when the boundary is smoothed by a geometric heat equation the skeleton evolves according to a related geometric heat equation the surprise is that while certain aspect of the skeleton simplify a one would expect others can behave wildly including the creation of new skeleton branch fortunately such section can be flagged a ligature or those portion of the skeleton related to shape concavity our analysis also includes junction and an explicit model for boundary noise provided a smoothness condition is met the skeleton can often reduce noise however when the smoothness condition is violated the skeleton can change violently which we speculate corresponds to situation in which part are created e g when the handle appears on a rotating cup 
this paper is concerned with the simulation of the partial differential equation pde driven evolution of a closed surface by mean of an implicit representation in most application the natural choice for the implicit representation is the signed distance function to the closed surface osher and sethian propose to evolve the distance function with a hamilton jacobi equation unfortunately the solution to this equation is not a distance function a a consequence the practical application of the level set method is plagued with such question a when do we have to reinitialize the distance function how do we reinitialize the distance function etc which reveal a disagreement between the theory and it implementation this paper proposes an alternative to the use of hamilton jacobi equation which eliminates this contradiction in our method the implicit representation always remains a distance function by construction and the implementation doe not differ from the theory anymore this is achieved through the introduction of a new equation besides it theoretical advantage the proposed method also ha several practical advantage which we demonstrate in three application i the segmentation of the human cortex surface from mri image using two coupled surface ii the construction of a hierarchy of euclidean skeleton of a d surface iii the reconstruction of the surface of d object through stereo 
abstract we address the problem of integrating multi frame stereo and shading cue within the framework of optimization in the inflnite dimensional space of piecewise smooth surface cue integration then reduces to the determination of region where prior assumption on the re ectance of the surface can be enforced by combining cue our formulation allows deflning a well posed problem even when reconstruction from stereo or shading in isolation would be ill posed for a simplifled model we prove the necessary condition for optimality and propose an iterative optimization algorithm which we implement using ultranarrowband level set method 
this paper present a novel approach for generating and analyzing epipolar plane image epi from video s equences taken from a moving platform subject to vibration s o that the d model of an arbitrary scene can be constructed two problem are solved in our approach how to gen erate epi from video under a more general motion than a pure translation how to analyze the huge amount of data in the epi robustly and efficiently for the first proble m a d image stabilization method is proposed which decoup le the vibration from the vehicle s motion so that good ep is and panoramic view image pvis can be generated for the second problem we propose an efficient panoramic e pi analysis pepia method in which only one scanline of each epi is processed the pepia combine advantage of pvis and epi and consists of three important step loc u orientation detection motion boundary localization and occlusion resolution recovery the output of the pe pia a layered d panorama is very useful in visual navig ation and virtual reality modeling since camera calibration image segmentation feature extraction and matching are a voided all the proposed algorithm are fully automatic and rather general result on real image sequence are given 
this paper describes an extension of a technique for the recognition and tracking of every day object in cluttered scene the goal is to build a system in which ordinary desktop object serve a physical icon in a vision based system for man machine interaction in such a system the manipulation of object replaces user command a view variant recognition technique developed by the second author ha been adapted by the first author for a problem of recognising and tracking object on a cluttered background in the presence of occlusion this method is based on sampling a local appearance function at discrete viewpoint by projecting it onto a vector of receptive field which have been normalised to local scale and orientation this paper report on the experimental validation of the approach and of it extension to the use of receptive field based on colour the experimental result indicate that the second author s technique doe indeed provide a method for building a fast and robust recognition technique furthermore the extension to coloured receptive field provides a greater degree of local discrimination and an enhanced robustness to variable background condition the approach is suitable for the recognition of general object a physical icon in an augmented reality 
we use the color cooccurrence histogram ch for recognizing object in image the color ch keep track of the number of pair of certain colored pixel that occur at certain separation distance in image space the color ch add geometric information to the normal color histogram which abstract away all geometry we compute model chs based on image of known object taken from different point of view these model chs are then matched to subregions in test image to find the object by adjusting the number of color and the number of distance used in the ch we can adjust the tolerance of the algorithm to change in lighting viewpoint and the flexibility of the object we develop a mathematical model of the algorithm s false alarm probability and use this a a principled way of picking most of the algorithm s adjustable parameter we demonstrate our algorithm on different object showing that it recognizes object in spite of confusing background clutter partial occlusion and flexing of the object 
we present a system that consists of one camera connected to a personal computer that can a select and track a number of high contrast point feature on a sequence of image b estimate their three dimensional motion and position relative to an inertial reference frame assuming rigidity c handle occlusion that cause point feature to disappear a well a new feature to appear the system can also d perform partial self calibration and e check for consistency of the rigidity 
the ability to learn from user interaction is an important asset for content based image retrieval cbir system over short time scale it enables the integration of information from successive query assuring faster convergence to the desired target image over long time scale retrieval session it allows the retrieval system to tailor itself to the preference of particular user we address the issue of learning by formulating retrieval a a problem of bayesian inference the new formulation is shown to have various advantage over previous approach it lead to the minimization of the probability of retrieval error enables region based query without prior image segmentation and suggests elegant procedure for combining multiple user specification a a consequence of all this it enables the design of short and long term learning mechanism that are simple intuitive and extremely efficient in term of computational and storage requirement we introduce two such algorithm and present experimental evidence illustrating the clear advantage of learning for cbir 
intelligent room equipped with video camera can exhibit compelling behavior many of which depend on object recognition unfortunately object recognition algorithm are rarely written with a normal consumer in mind leading to program that would be impractical to use for a typical person these impracticality include speed of execution elaborate training ritual and setting adjustable parameter we present an algorithm that can be trained with only a few image of the object that requires only two parameter to be set and that run at hz on a normal pc with a normal color camera the algorithm represents an object s feature a small quantized edge template and it represents the object s geometry with hough kernel the hough kernel implement a variant of the generalized hough transform using simple d image correlation the algorithm also us color information to eliminate part of the image from consideration we give our result in term of roc curve for recognizing a computer keyboard with partial occlusion and background clutter even with two hand occluding the keyboard the detection rate is with a false alarm rate of 
we propose a method to learn heterogeneous model of object class for visual recognition the training image contain a preponderance of clutter and learning is unsupervised our model represent object a probabilistic constellation of rigid part feature the variability within a class is represented by a joint probability density function on the shape of the constellation and the appearance of the part our method automatically identifies distinctive feature in the training set the set of model parameter is then learned using expectation maximization see the companion paper for detail when trained on different unlabeled and unsegmented view of a class of object each component of the mixture model can adapt to represent a subset of the view similarly different component model can also specialize on sub class of an object class experiment on image of human head leaf from different specie of tree and motor car demonstrate that the method work well over a wide variety of object 
an algorithm is presented for video georegistration with a particular concern for aerial video i e video captured from an airborne platform the algorithm s input is a video stream with telemetry camera model specifcation suficient to define an initial estimate of the view and geodetically calibrated reference imagery coaligned digital orthoimage and elevation map the output is a spatial registration of the video to the reference so that it inherits the available geodetic coordinate the video is processed in a continuous fashion to yield a corresponding stream of georegistered result quantitative result of evaluating the developed approach with real world aerial video also are presented the result suggest that the developed approach may provide valuable input to the analysis and interpretation of aerial video 
this paper deal with the problem of incorporating natural regularity condition on the motion in an map estimator for structure and motion recovery from uncalibrated image sequence the purpose of incorporating these constraint is to increase performance and robustness autocalibration and structure and motion algorithm are known to have problem with i the frequently occurring critical camera motion ii local minimum in the non linear optimization and iii the high correlation between different intrinsic and extrinsic parameter of the camera e g the coupling between focal length and camera position the camera motion both intrinsic and extrinsic parameter is modelled a a random walk process where the inter frame motion are assumed to be independentlynormally distributed the proposed scheme is demonstrated on both simulated and real data showing the increased performance 
an energy model based approach for estimating object boundary is presented we study a particular energy which minimizer can be determined the method estimate the unknown number of object and draw object boundary by selecting the best level line computed from level set of the original image unlike previous standard method the proposed method doe not require iteration for minimizing the energy in addition our segmentation algorithm combine anisotropic diffusion based regularization with level line selection to extract smooth object boundary experimental result on d biomedical and meteorological image are reported 
a non parametric estimator of density gradient the mean shift is employed in the joint spatial range value domain of gray level and color image for discontinuity preserving filtering and image segmentation property of the mean shift are reviewed and it convergence on lattice is proven the proposed filtering method associate with each pixel in the image the closest local mode in the density distribution of the joint domain segmentation into a piecewise constant structure requires only one more step fusion of the region associated with nearby mode the proposed technique ha two parameter controlling the resolution in the spatial and range domain since convergence is guaranteed the technique doe not require the intervention of the user to stop the filtering at the desired image quality several example for gray and color image show the versatility of the method and compare favorably with result described in the literature for the same image 
in this paper we propose a novel inhomogeneous gibbs model by the minimax entropy principle and apply it to face modeling the maximum entropy principle generalizes the statistical property of the observed sample and result in the gibbs distribution while the minimum entropy principle make the learnt distribution close to the observed one to capture the fine detail of a face an inhomogeneous gibbs model is derived to learn the local statistic of facial feature paint to alleviate the high dimensionality problem of face model we propose to learn the distribution in a subspace reduced by principal component analysis or pca we demonstrate that our model effectively capture important and subtle non gaussian face pattern and efficiently generates good face model 
accurate tracking can facilitate the automatic extraction of metric information from video analysis many tracking system rely on a sufficiently accurate dynamic model these dynamic model must be either known a priori or learnt this paper address the problem of determining dynamical system model from observed visual motion where it is assumed that the motion cannot be modeled by a single dynamical system the change in motion from one system to another need to be detected previous work ha dealt with maintaining multiple hypothesis for repetitive motion rather than maintaining multiple hypothesis one can learn the dynamic model that apply and identify the change between the model specifically a method for high dimensional motion segmentation is presented by using a two step recursive least square algorithm break point of system dynamic at which a model switching must be performed are predicted after segmentation system identification technique can be used to fit dynamic model 
machine perception can benefit from the use of feature extracted from data provided by a variety of sensor modality recent advance in sensor design make it possible to incorporate multiple sensor into vision system for increased capability two important issue must be considered for the integration task the sensor must be spatially coregistered and the phenomenology must be compatible in this paper we address these issue a they apply to the problem of automatic modeling of building structure from aerial view we present a methodology to incorporate cue extracted from ifsar interferometric synthetic aperture radar to significantly improve the performance and the quality of the result of an existing system that relies on electro optical panchromatic image while reducing processing time quantitative evaluation are given 
in this paper we describe a new technique for general purpose interactive segmentation of n dimensional image the user mark certain pixel a object or background to provide hard constraint for segmentation additional soft constraint incorporate both boundary and region information graph cut are used to find the globally optimal segmentation of the n dimensional image the obtained solution give the best balance of boundary and region property among all segmentation satisfying the constraint the topology of our segmentation is unrestricted and both object and background segment may consist of several isolated part some experimental result are present ed in the context of photo video editing and medical image segmentation we also demonstrate an interesting gestalt example a fast implementation of our segmentation method is possible via a new max flow algorithm in 
in this paper we address the problem of matching two image with two different resolution a high resolution image and a low resolution one on the premise that change in resolution act a a smoothing equivalent to change in scale a scale space representation of the high resolution image is produced hence the one to one classical image matching paradigm becomes one to many because the lowresolution image is compared with all the scale space representation of the high resolution one key to the success of such a process is the proper representation of the feature to be matched in scale space we show how to extract interest point at variable scale and we devise a method allowing the comparison of two image at two different resolution the method comprises the use of photometricand rotationinvariant descriptor a geometric model mapping the highresolution image onto a low resolution image region and an image matching strategy based on the robust estimation of this geometric model extensive experiment show that our matching method can be used for scale change up to a factor 
in this paper a new rectification methodis proposed the method is both simple and efficient and can deal with all possible camera motion a minimal image size without any pixel loss is guaranteed the only required information is the oriented fundamental matrix the whole rectification process is carried out directly in the image the idea consists of using a polar parametrization of the image around the epipole the transfer between the image is obtained through the fundamental matrix the proposed method ha important advantage compared to the traditional rectification scheme in some case these approach yield very large image or can not rectify at all even the recently proposed cylindrical rectification method can encounter problem in some case these problem are mainly due to the fact that the matching ambiguity is not reduced to half epipolar line although this last method is more complex than the one proposed in this paper the resulting image are in general larger the performance of the new approach is illustrated with some result on real image pair 
bayesian inference ha been used successfully formany problem where the aim is to infer the parametersof a model of interest in this paper we formulatethe three dimensional reconstruction problemas the problem of inferring the parameter of a surfacemodel from image data and show how bayesianmethods can be used to estimate the parameter of thismodel given the image data thus we recover the threedimensional description of the scene this approachalso give great flexibility we can 
abstract a new method for d rigid motion estimation is derived under the most general assumption that the measurement are corrupted by inhomogeneous and anisotropic i e heteroscedastic noise this is the case for example when the motion of a calibrated stereo head is to be determined from image pair linearization in the quaternion space transforms the problem into a multivariate heteroscedastic error in variable heiv regression from which the rota tion and translation estimate are obtained simultane ously the signi cant performance improvement is il lustrated for real data by comparison with the result of quaternion subspace and renormalization based ap proaches described in the literature extensive use is made of bootstrap an advanced numerical tool from statistic both to estimate the covariance of the d data point and to obtain con dence region for the rotation and translation estimate bootstrap enables an accurate recovery of these information using only the two image pair serving a input 
the paper address the problem of class based recognition and image synthesis with varying illumination the classbased synthesis and recognition task are defined a follows given a single input image of an object and a sample of image with varying illumination condition of other object of the same general class capture the equivalence relationship by generation of new image or by invariant among all image of the object corresponding to new illumination condition the key result in our approach is based on a definition of an illumination invariant signature image we call the quotient image which enables an analytic generation of the image space with varying illumination from a single input image and a very small sample of other object of the class in our experiment a few a two object in many case the recognition result outperform by far conventional method and the image synthesis is of remarkable quality considering the size of the database of example image and the mild pre process required for making the algorithm work 
the analysis of human action captured in video sequence ha been a topic of considerable interest in computer vision much of the previous work ha focused on the problem of action or activity recognition but ignored the problem of detecting action boundary in a video sequence containing unfamiliar and arbitrary visual action this paper present an approach to this problem based on detecting temporal discontinuity of the spatial pattern of image motion that capture the action we represent frame to frame optical flow in term of the coefficient of the most significant principal component computed from all the flow field within a given video sequence we then detect the discontinuity in the temporal trajectory of these coefficient based on three different measure we compare our segment boundary against those detected by human observer on the same sequence in a recent independent psychological study of human perception of visual event we show experimental result on the two sequence that were used in this study our experimental result are promising both from visual evaluation and when compared against the result of the psychological study 
an approach for estimating composite independentobject and camera image motion is proposed the approach employ spatio temporal flow modelslearned through observing typical movement ofthe object to decompose image motion into independentobject and camera motion the spatiotemporalflow model of the object motion are representedas a set of orthogonal flow base that arelearned using principal component analysis of instantaneousflow measurement from a stationarycamera these model 
we describe a reconstruction method of multiple motion scene which are the scene containing multiple moving object from uncalibrated view assuming that the object are moving with constant velocity the method recovers the scene structure the trajectory of the moving object the camera motion and the camera intrinsic parameter except skews simultaneously the number of the moving object is automatically detected without prior motion segmentation the method is based on a uni ed geometrical representation of the static scene and the moving object it rst performs a projective reconstruction using a bilinear factorization algorithm and then convert the projective solution to a euclidean one by enforcing metric constraint experimental result on synthetic and real image are presented 
this paper is to definetransformations on the symmetry map and illustrateresults for them specifically we illustrate how spuriouselements can be removed gap completed andparts computed despite significant noise 
in this paper we consider the problem of estimating the fundamental matrix from point correspondence it is well known that the most accurate estimate of this matrix are obtained by criterion minimizing geometric error when the data are affected by noise it is also well known that these criterion amount to solving non convex optimization problem and hence their solution is affected by the optimization starting point generally the starting point is chosen a the fundamental matrix estimated by a linear criterion but this estimate can be very inaccurate and therefore inadequate to initialize method with other error criterion here we present a method for obtaining a more accurate estimate of the fundamental matrix with respect to the linear criterion it consists of the minimization of the algebraic error taking into account the rank constraint of the matrix our aim is twofold first we show how this nonconvex optimization problem can be solved avoiding local minimum using recently developed convexification technique second we show that the estimate of the fundamental matrix obtained using our method is more accurate than the one obtained from the linear criterion where the rank constraint of the matrix is imposed after it computation by setting the smallest singular value to zero this suggests that our estimate can be used to initialize non linear criterion such a the distance to epipolar line and the gradient criterion in order to obtain a more accurate estimate of the fundamental matrix a a measure of the accuracy the obtained estimate of the epipolar geometry are compared in experiment with synthetic and real data 
we propose a novel method for continuous d depth recovery and tracking using calibrated stereo the method integrates stereo correspondence surface reconstruction and tracking by using a new single deformable dual mesh optimization resulting in simplicity robustness and efficiency in order to combine stereo correspondence and structure recovery the method introduces an external energy function defined for a d volume based on cross correlation between the stereo pair the internal energy functional of the deformable dual mesh imposes smoothness on the surface and it serf a a communication tool between the two mesh under the force produced by the energy term the dual mesh deforms to recover and track the d surface the newly introduced dual mesh model which is one of the main contribution of this paper make the system robust against local minimum and yet it is efficient a coarse to fine minimization approach make the system even more efficient tracking is achieved by using the recovered surface a an initial position for the next time frame although the system can effectively utilize initial surface position and disparity data they are not needed for a successful operation which make this system applicable to a wide range of area we present the result of a number of experiment on stereo human face and cloud image which prof that our new method is very effective 
in this paper we study the structure from motion problem a a constrained nonlinear least square problem which minimizes the so called reprojection error subject to all co nstraints among multiple image by converting this constrained optimization problem to an unconstrained one we obtain a multiview version of the normalized epipolar constraint of two view such a multiview normalized epipolar constraint serf a a statistically optimal objective fun ction for motion and structure estimation since such a function is defined naturally on a product of stiefel manifold we show how to use geometric optimization technique to minimize it we present experimental result on real image to evaluate the proposed algorithm 
we introduce a number of new result in the context of multiview geometry from general algebraic curve we start with the derivation of the extended kruppa s equation which are responsible for describing the epipolar constraint of two projection of a general non planar algebraic curve a part of the derivation of those constraint we address the issue of dimension analysis and a a result establish the minimal number of algebraic curve required for a solution of the epipolar geometry a a function of their degree and genus we then establish new result on the reconstruction of general algebraic curve from multiple view we address three different representation of curve i the regular point representation for which we show that the reconstruction from two view of a curve of degree admits two solution one of degree and the other of degree ii the dual space representation tangent for which we derive a lower bound for the number of view necessary for reconstruction a a function of the curve degree and genus and iii a new representation to computer vision based on the set of line meeting the curve which doe not require any curve fitting in image space for which we also derive lower bound for the number of view necessary for reconstruction a a function of the curve degree alone 
in this paper a novel framework for the recovery of d surface of face from single image is developed the underlying principle is shape from recognition i e the idea that pre recognizing face part can constrain the space of possible solution to the image irradiance equation thus allowing robust recovery of the d structure of a specific part shape recovery of the recognized part is based on specialized backpropagation based neural network each of which is employed in the recovery of a particular face part representation using principal component allows to efficiently encode class of object such a nose lip etc the specialized network are designed and trained to map the principal component coefficient of the shading image to another set of principal component coefficient that represent the corresponding d surface shape a method for integrating recovered d surface region by minimizing the sum squared error in overlapping area is also derived quantitative analysis of the reconstruction of the surface part show relatively small error indicating that the method is robust and accurate the recovery of a complete face is performed by minimal squared error merging of face part 
this paper address the problem of probabilistic recognition of activity from local spatio temporal appearance joint statistic of space time filter are employed to define histogram which characterize the activity to be recognized these histogram provide the joint probability density function required for recognition using bayes rule the result is a technique for recognition of activity which is robust to partial occlusion a well a change in illumination in this paper the framework and background for this approach is first described then the family of spatio temporal receptive field used for characterizing activity is presented this is followed by a review of probabilistic recognition of pattern from joint statistic of receptive field response the approach is validated with the result of experiment in the discrimination of person walking in different direction and the recognition of a simple set of hand gesture in an augmented reality scenario 
we propose a solution to the generic bilinear calibration estimation problem when using a quadratic cost function and restricting to locally translation invariant imaging model we apply the solution to the problem of reconstructing the three dimensional shape and radiance of a scene from a number of defocused image since the imaging process map the continuum of three dimensional space onto the discrete pixel grid rather than discretizing the continuum we exploit the structure of map between finite and infinite dimensional hilbert space and arrive at a principled algorithm that doe not involve any choice of basis or discretization rather these are uniquely determined by the data and exploited in a functional singular value decomposition in order to obtain a regularized solution 
in this paper we investigate the geometry and algebra of multiple projection of line with affine camera previously the case of seven line in three image ha been studied it wa thought that this wa the minimal data necessary for recovering affine structure and motion and that there are in general two solution it wa also thought that these two solution persist with more than seven line in this paper it is shown that the minimal case are six line in three image and five line in four image these case are solved and it is shown that there are in general four solution in both problem two almost minimal case seven line in three image and six line in four image are solved using linear method furthermore it is shown that the solution is in general unique in these almost minimal case finally experiment are conducted on both simulated and real data in order to show the applicability of the theory 
the author propose a novel technique for video summarization based on singular value decomposition svd for the input video sequence we create a feature frame matrix a and perform the svd on it from this svd we are able to not only derive the refined feature space to better cluster visually similar frame but also define a metric to measure the amount of visual content contained in each frame cluster using it degree of visual change then in the refined feature space we find the most static frame cluster define it a the content unit and use the context value computed from it a the threshold to cluster the rest of the frame based on this clustering result either the optimal set of keyframes or a summarized motion video with the user specified time length can be generated to support different user requirement for video browsing and content overview our approach ensures that the summarized video representation contains little redundancy and give equal attention to the same amount of content 
it is known that recovering projection matrix from planar configuration is ambiguous thus posing the problem of model selection is the scene planar d or non planar d for a d scene one would recover a homography matrix whereas for a d scene one would recover the fundamental matrix or trifocal tensor the task of model selection is especially problematic when the scene is neither d nor d for example a thin volume in space in this paper we show that for certain task such a reprojection there is no need to select a model the ambiguity that arises from a d scene is orthogonal to the reprojection process thus if one desire to use multilinear matching constraint for transferring point along a sequence of view it is possible to do so under any situation of d d or thin volume 
when a transparent surface is present between an observer and an object an image reflected by the surface may be superimposed on the image of the observed object we present a new approach to recover the scene layer and to classify which is the reflected transmitted one based on imaging through a polarizing filter at two orientation estimate of the separate layer are obtained by weighted pixel wise difference of these image inverting the image formation process however the weight depend on the angle of incidence hence on the inclination of the transparent invisible surface this angle is estimated by seeking the angle value which through the weight lead to decorrelation of the estimated layer experimental result obtained using real photo of actual object demonstrate the success of angle estimation and consequent layer separation and labeling the method is shown to be superior to earlier method where only raw optical data wa used 
we describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformation and insensitive to the shape of the textur e region it is applicable to texture patch which are locall y planar and have stationary statistic the novelty of the de scriptor is that it is based on statistic aggregated over th e region resulting in richer and more stable descriptor tha n those computed at a point two texture matching application of this descriptor are demonstrated it is used to automatically identify region of the same type of texture but with varying surface pose within a single image it is used to support wide baseline stereo i e to enable the automatic computation o f the epipolar geometry between two image acquired from quite separated viewpoint result are presented on several set of real image 
we describe a video rate surveillance algorithm for determining whether people are carrying object or moving unencumbered from a stationary camera the contribution of the paper is the shape analysis algorithm that both determines whether a person is carrying an object and segment the object from the person so that it can be tracked e g during an exchange of object between two people a the object is segmented an appearance model of the object is constructed the method combine periodic motion estimation with static symmetry analysis of the silhouette of a person in each frame of the sequence experimental result demonstrate robustness and real time performance of the proposed algorithm 
we describe in this paper closed form solution to the following problem in multi view geometry of n th order curve i recovery of the fundamental matrix from or more conic match in two view ii recovery of the homography matrix from a single n th order n matching curve and in turn recovery of the fundamental matrix from two matching n th order planar curve and iii d reconstruction of a planar algebraic curve from two view although some of these problem notably i and iii were introduced in the past our derivation are analytic with resulting closed form solution we have also conducted synthetic experiment on i and real image experiment on ii and iii with subpixel performance level thus demonstrating the practical use of our result 
we introduce in this paper a new face coding and recognition method which employ the enhanced fld fisher linear discrimimant model efm on integrated shape vector and texture shape free image information shape encodes the feature geometry of a face while texture provides a normalized shape free image by warping the original face image to the mean shape i e the average of aligned shape the dimensionality of the shape and the texture space are first reduced using principal component analysis pca the corresponding but reduced shape find texture feature are then integrated through a normalization procedure to form augmented feature the dimensionality reduction procedure constrained by efm for enhanced generalization maintains a proper balance between the spectral energy need of pca for adequate representation and the fld discrimination requirement that the eigenvalue of the within class scatter matrix should not include small trailing value after the dimensionality reduction procedure a they appear in the denominator 
corner and curve are important image feature in many vision based application corner are usually more stable and easier to match than curve while curve contain richer information of scene structure in previously work corner are often used to recover the epipolar geometry between two view which is then used in curve matching to reduce the search space however information of the scene structure contained in this set of matched corner is ignored in this paper we present a curve matching algorithm that is guided by a set of matched corner within a probabilistic framework the role of the corner guidance is explicitly defined by a set of similarity invariant unary measurement and by a similarity function the similarity function provides stronger capability of resolving matching ambiguity than the epipolar constraint and is integrated into a relaxation scheme to reduce computational complexity and improve accuracy of curve matching experimental result clearly demonstrate the benefit of integrating corner match into the curve matching procedure 
a recursive method is presented for recovering d object shape and camera motion under orthography from an extended sequence of video image this may be viewed a a natural extension of both the original and the sequential factorization method a critical aspect of these factorization approach is the estimation of the so called shape space and they may in part be characterized by the manner in which this subspace is computed if point are tracked through frame the recursive leastsquares method proposed in this paper update the shape space with complexity per frame in contrast the sequential factorization method update the shape space with complexity per frame the original factorization method is intended to be used in batch mode using point tracked across all available frame it effectively computes the shape space with complexity after frame unlike other method the recursive approach doe not require the estimation or updating of a large measurement or covariance matrix experiment with real and synthetic image sequence confirm the recursive method s low computational complexity and good performance and indicate that it is well suited to real time application 
this paper investigates whether region of uniform surface topography can be extracted from intensity image using shape from shading and subsequently used for the purpose of d object recognition we draw on the constant shape index maximal patch representation of dorai and jain we commence by showing that the resulting shape index region are stable under different viewing angle based on this observation we investigate the effectiveness of various structural representation and region attribute for d object recognition we show that region curvedness and a string ordering of the region according to size provides recognition accuracy of about by polling various recognition scheme including a graph matching method we show that a recognition rate of is achievable 
this paper considers projective reconstruction with a hierarchical computational structure of trifocal tensor that integrates feature tracking and geometrical validation of the feature track the algorithm wa embedded into a system aimed at completely automatic euclidean reconstruction from uncalibrated handheld amateur video sequence the algorithm wa tested a part of this system on a number of sequence grabbed directly from a low end video camera without editing the proposed approach can be considered a generalisation of a scheme of fitzgibbon and zisserman eccv the proposed scheme try to adapt itself to the motion and frame rate in the sequence by finding good triplet of view from which accurate and unique trifocal tensor can be calculated this is in contrast to the assumption that three consecutive view in the video sequence are a good choice using trifocal tensor with a wider span suppresses error accumulation and make the scheme le reliant on bundle adjustment the proposed computational structure may also be used with fundamental matrix a the basic building block 
this paper deal with the automated creation of geometricand photometric correct d model of theworld those model can be used for virtual reality tele presence digital cinematography and urban planning application the combination of range dense depth estimate and image sensing color information providesdata set which allow u to create geometrically correct photorealistic model of high quality the d model are first built from range data using avolumetric set 
background maintenance is a frequent element of video surveillance system we develop wallflower a threecomponent system for background maintenance the pixellevel component performs wiener filtering to make probabilistic prediction of the expected background the region level component fill in homogeneous region of foreground object and the frame level component detects sudden global change in the image and swap in better approximation of the background we compare our system with other background subtraction algorithm wallflower is shown to outperform previous algorithm by handling a greater set of the difficult situation that can occur finally we analyze the experimental result and propose normative principle for background maintenance 
this paper address the problem of self calibration from one unknown motion of an uncalibrated stereo rig unlike the existing method for stereo rig self calibration which have been focused on applying the autocalibration paradigm using both motion and stereo correspondence our method doe not require the recovery of stereo correspondence our method combine purely algebraic constraint with implicit geometric constraint assuming that the rotational part of the stereo geometry ha two unknown degree of freedom i e the third dof is roughly known and that the principle point of each camera is known we first show that the computation of the intrinsic and extrinsic parameter of the stereo rig can be recovered from the motion correspondence only i e the monocular fundamental matrix we then provide an initialization procedure for the proposed non linear method we provide an extensive performance study for the method in the presence of image noise in addition we study some of the aspect related to the d motion that govern the accuracy of the proposed self calibration method experiment conducted on synthetic and real data image demonstrate the effectiveness and efficiency of the proposed method 
image segmentation is not only hard and unnecessary for texture based image retrieval but can even be harmful image of either individual or multiple texture are best described by distribution of spatial frequency descriptor rather than single descriptor vector over pre segmented region a retrieval method based on the earth mover distance with an appropriate ground distance is shown to handle both complete and partial multi textured query a an illustration different image of the same type of animal are easily retrieved together at the same time animal with subtly different coat like cheetah and leopard are properly distinguished 
this paper describes a generalized formulation of optical flow estimation based on modelsof brightness variation that are caused by time dependent physical process these include changing surface orientation withrespect to a directional illuminant motion of the illuminant and physical model of heat transport in infrared image with thesemodels we simultaneously estimate the d image motion and the relevant physical parameter of the brightness change model theestimation problem 
method for the analysis of image of the same scene taken under three different lighting condition are illustrated a technique that separate the effect of geometry and surface coloration texture in this tri luminal environment is developed and experimental result are shown exploiting this technique to isolate geometric information two method which extract differential geometric property of surface the sign of gaussian curvature and it magnitude to within a multiplicative factor directly from tri luminal photometric data are derived and demonstrated 
method are presented for increasing the coverage and accuracy of image mosaic constructed from multiple uncalibrated weak perspective view of the human retina ex tending our previous algorithm for registering pair of image using a non invertible parameter quadratic image transformation model and a hierarchical robust estimatio n technique two important innovation are presented th e first is a linear non iterative method for jointly estimating the transformation of all image onto the mosaic this employ constraint derived from pairwise matching between the non mosaic image frame it allows the transformation to be estimated for image that do not overlap the mosaic anchor frame and result in mutually consistent transformation for all image this mean the mosaic can cover a much broader area of the retinal surface even though the transformation model is not closed under composition this capability is particularly valuable for mosaicing the reti nal periphery in the context of disease such a aid cmv the second innovation is a method to improve the accuracy of the pairwise match a well a the joint estimation by refining the feature location and by adding new feature based on the transformation estimate themselves fo r matching image frame of size this cut the registration error from the range of to pixel to about pixel the overall transformation error in final mosaic construction is pixel based on experiment over a large set of eye 
abstract bagging form a committee of classifier by bootstrap aggregationof training set from a pool of training data asimple alternative to bagging is to partition the data intodisjoint subset experiment on various datasets show that given the same size partition and bag the use of disjointpartitions result in better performance than the useof bag many application e g protein structure prediction involve the use of datasets that are too large to handlein the memory of the 
we introduce a framework for recovering the d shape and motion of unknown arbitrarily moving curve from two or more image sequence acquired simultaneously from distinct point in space we use this framework to identify ambiguity in the multi view recovery of rigid or nonrigid d motion for arbitrary curve and identify a novel spatio temporal constraint that couple the problem of d shape and d motion recovery in the multi view case we show that this constraint lead to a simple hypothesizeand test algorithm for estimating d curve shape and motion simultaneously experiment performed with synthetic data suggest that in addition to recovering d curve motion our approach yield shape estimate of higher accuracy than those obtained when stereo analysis alone is applied to a multi view sequence 
camera calibration is a primary crucial step inmany computer vision task in this paper we presenta new neural approach for cameracalibration unlikesome existing neural approach our calibrating networkcan tell the perspective projection transformationmatrix between the world d point and the corresponding d image pixel starting from random initialweights the net can specify the cameramodel parameterssatisfying the orthogonality constraint onthe rotational transformation the 
the light reflected from a surface depends on the scene geometry the incident illumination and the surface material a novel methodology is presented which extract reflectivity information of the various material in the scene independent of incident light and scene geometry a scene is captured under different narrow band color filter and the spectral derivative of the scene are computed the resulting spectral derivative form a spectral gradient at each pixel this spectral gradient is a material descriptor which is invariant to scene geometry and incident illumination for smooth diffuse surface spectral gradient can discriminate among smooth dielectric with different reflectance property independent of viewing condition 
this paper address the problem of the local scale parameter selection for recognition technique based on gaussian derivative pattern are described in a feature space of which each dimension is a scale and orientation normalized receptive field a unit composed of normalized gaussian based filter scale invariance is obtained by automatic selection of an appropriate local scale lin b and followed by normalisation of the receptive field to the appropriate scale orientation invariance is obtained by the determination of the dominant local orientation and by steering the receptive field to this orientation data is represented structurally in a feature space that is designed for the recognition of static object configuration in this space an image is modeled by the vectorial representation of the receptive field response at each pixel forming a surface in the feature space recognition is achieved by measuring the distance between the vector of normalized receptive field response of an observed neighborhood and the surface point of the image model the power of a scale equivariant feature space is validated by experimental result for point correspondence in image of different scale and the recognition of object under different view point 
the number of feature that can be computed over an image is for practical purpose limitless unfortunately the number of feature that can be computed and exploited by most computer vision system is considerably le a a result it is important to develop technique for selecting feature from very large data set that include many irrelevant or redundant feature this work address the feature selection problem by proposing a three step algorithm the first step us a variation of the well known relief algorithm to remove irrelevance the second step cluster feature using k mean to remove redundancy and the third step is a standard combinatorial feature selection algorithm this three step combination is shown to be more effective than standard feature selection algorithm for large data set with lot of irrelevant and redundant feature it is also shown to be no worse than standard technique for data set that do not have these property finally we show a third experiment in which a data set with feature is reduced to of it original size with very little information loss 
the problem of selecting a camera model is addressed here using the geometric aic akaike information criterion proposed by kanatani which considers both the residual of the data fitting to the model a well a the complexity of the model camera model describe the geometrical relation between the d location of object point and the image location of their projection the most commonly used camera model are the projective perspective camera model and the affine camera model intuitively the projective camera model which is nonlinear and is characterized by more parameter model the imaging geometry better but also is believed to lead to numerically le stable solution the affine camera model which is an approximation to the projective camera model with le parameter is recommended to be used when the object depth is much smaller than the object distance however there is no quantitative criterion for the decision which camera model should be used projective or affine in this paper the geometric aic criterion is used for deciding between the two camera model is the context of two task estimating the projection matrix from d and corresponding d data and estimating the fundamental matrix from two set of d data it is found that in most case it is the projective camera model which is more appropriate still in the case where the affine camera model is traditionally used the measure of appropriateness of the two model are roughly the same with a small advantage to the affine camera model 
this paper present a new method for detecting scale invariant interest point the method is based on two recent result on scale space interest point can be adapted to scale and give repeatable result geometrically stable local extremum over scale of normalized derivative indicate the presence of characteristic local structure ou r method first computes a multi scale representation for the harris interest point detector we then select point at whi ch a local measure the laplacian is maximal over scale this allows a selection of distinctive point for which the characteristic scale is known these point are invariant t o scale rotation and translation a well a robust to illumin ation change and limited change of viewpoint for indexing the image is characterized by a set of scale invariant point the scale associated with each point allows the computation of a scale invariant descriptor our descriptor are in addition invariant to image rotation to affine illumination change and robust to small perspective deformation experimental result for indexing show an excellent performance up to a scale factor of for a database with more than image 
we show that a simple memory based technique for view based face recognition motivated by the real world task of visitor identification can outperform more sophisticated algorithm that use principal component analysis pca and neural network this technique is closely related to correlation template however we show that the use of novel similarity measure greatly improves performance we also show that augmenting the memory base with additional synthetic face image result in further improvement in performance result of extensive empirical testing on two standard face recognition datasets are presented and direct comparison with published work show that our algorithm achieves comparable or superior result this paper further demonstrates that our algorithm ha desirable asymptotic computational and storage behavior and is ideal for incremental training our system is incorporated into an automated visitor identification system that ha been operating successfully in an outdoor environment for several month 
this paper present a new approach for achieving distortion invariant recognition and classification a test example to be classified is viewed a a query intended to find similar example in the training set or class model derived from the training set the key idea is that instead of querying with a single pattern we construct a more robust query based on the family of pattern formed by distorting the test example although query execution is slower than if the invariance were successfully pre compiled during training there are significant advantage in several context i providing invariance in memory based learning ii in model selection where reducing training time at the expense of test time is a desirable trade off and iii in enabling robust ad hoc search based on a single example preliminary test for memory based learning on the nist handwritten digit database with a limited set of shearing and translation distortion produced an error rate of 
the design of an effective architecture for content based retrieval from visual library requires careful consideration of the interplay between feature selection feature representation and similarity metric we present a solution where all the module strive to optimize the same performance criterion the probability of retrieval error this solution consists of a bayesian retrieval criterion shown to generalize the most prevalent similarity metric in current use and an embedded mixture representation over a multiresolution feature space shown to provide a good trade off between retrieval accuracy invariance perceptual relevance of similarity judgment and complexity the new representation extends standard model histogram and gaussian by providing simultaneous support for high dimensional feature and multi modal density and performs well on color texture and generic image database 
in many vision application the practice of supervised learning face several difficulty one of which is that insufficient labeled training data result in poor generalization in image retrieval we have very few labeled image from query and relevance feedback so that it is hard to automatically weight image feature and select similarity metric for image classification this paper investigates the possibility of including an unlabeled data set to make up the insufficiency of labeled data different from most current research in image retrieval the proposed approach try to cast image retrieval a a transductive learning problem in which the generalization of an image classifier is only defined on a set of image such a the given image database formulating this transductive problem in a probabilistic framework the proposed algorithm discriminantem d em not only estimate the parameter of a generative model but also find a linear transformation to relax the assumption of probabilistic structure of data distribution a well a select good feature automatically our experiment show that d em ha a satisfactory performance in image retrieval application d em algorithm ha the potential to many other application 
several method for computing observer motion from monocular and stereo image sequence have been proposed however accurate positioning over long distance requires a higher level of robustness than previously achieved this paper describes several mechanism for improving robustness in the context of a maximum likelihood stereo egomotion method we demonstrate that even a robust system will accumulate super linear error in the distance traveled due to increasing orientation error however when an absolute orientation sensor is incorporated the error growth is reduced to linear in the distance traveled and grows much more slowly in practice our experiment including a trial with stereo pair indicate that these technique can achieve error below of the distance traveled this method ha been implemented to run on board a prototype mar rover 
we have developed an easy and cost effective system that construct textured d animated face model from video with minimal user interaction our system first take with an ordinary video camera image of a face of a person sitting in front of the camera turning the head from one side to the other after five manual click on two image to tell the system where the eye corner nose top and mouth corner are the system automatically generates a realistic looking d human head model and the constructed model can be animated immediately different pose facial expression and talking a user with a pc and a video camera can use our system to generate his her face model in a few minute the face model can then be imported in his her favorite game and the user see themselves and their friend take part in the game they are playing we will demonstrate the system on a laptop computer live at the conference and participant can try it to model their own face 
abstract a novel approach for estimating articulated body posture and motion from monocular video sequence is proposed human pose is defined a the instantaneous two dimensional configuration i e the projection onto the image plane of a single articulated body in term of the position of a predetermined set of joint first statistical segmentation of the human body from the background is performed and low level visual feature are found given the segmented body shape the goal is to be able to map these generally low level visual feature to body configuration the system estimate different mapping each one with a specific cluster in the visual feature space given a set of body motion sequence for training unsupervised clustering is obtained via the expectation maximation algorithm then for each of the cluster a function is estimated to build the mapping between low level feature to d pose currently this mapping is modeled by a neural network given new visual feature a mapping from each cluster is performed to yield a set of possible pose from this set the system selects the most likely pose given the learned probability distribution and the visual feature similarity between hypothesis and input performance of the proposed approach is characterized using a new set of known body posture showing promising result 
imagine a professional web site designer who constantly ha to come up with innovative look for the client s homepage how doe he find the new content the major search engine such a hotbot http www hotbot com allow u to find text on the web but typically have few or no capability for finding visual medium in this article we discus method for finding visual medium on the www the emphasis is on iconic query which are essentially drag and drop visual concept or simple semantics we describe our method for finding static feature set and then describe a novel method called active feature set which chooses a feature set based on the context in the image 
principal component analysis pca ha been widely used for the representation of shape appearance and motion one drawback of typical pca method is that they are least square estimation technique and hence fail to account for outlier which are common in realistic training set in computer vision application outlier typically occur within a sample image due to pixel that are corrupted by noise alignment error or occlusion we review previous approach for making pca robust to outlier and present a new method that us anintra sample outlier process to account for pixel outlier we develop the theory of robust principal component analysis rpca and describe a robust m estimation algorithm for learning linear multivariate representation of high dimensional data such a image quantitative comparison with traditional pca and previous robust algorithm illustrate the benefit of rpca when outlier are present detail of the algorithm are described and a software implementation is being made publically available 
in this paper we introduce virtual snake for generatingocclusion hypothesis initially snake are clusteredbased on their motion to form object hypothesesa type of motion segmentation when two snakesintersect four virtual snake are generated a backgroundand a foreground snake for each of the originaltwo the two foreground virtual snake are allowed torelax while the two background virtual snake move inaccordance with their previous motion the combinedenergies of the snake 
this paper present a novel landmark based shape deformation method this method effectively solves two problem inherent in landmark based shape deformation a identification of landmark point from a given input image and b regularized deformation of the shape of an object defined in a template the second problem is solved using a new constrained support vector machine svm regression technique in which a thin plate kernel is utilized to provide non rigid shape deformation this method offer several advantage over existing landmark based method first it ha a unique capability to detect and use multiple candidate landmark point in an input image to improve landmark detection second it can handle the case of missing landmark which often arises in dealing with occluded image we have applied the proposed method to extract the scalp contour from brain cryosection image with very encouraging result 
an object recognition system ha been developed that us a new class of local image feature the feature are invariant to image scaling translation and rotation and partially invariant to illumination change and affine or d projection these feature share similar property with neuron in inferior temporal cortex that are used for object recognition in primate vision feature are efficiently detected through a staged filtering approach that identifies stable point in scale space image key are created that allow for local geometric deformation by representing blurred image gradient in multiple orientation plane and at multiple scale the key are used a input to a nearest neighbor indexing method that identifies candidate object match final verification of each match is achieved by finding a low residual least square solution for the unknown model parameter experimental result show that robust object recognition can be achieved in cluttered partially occluded image with a computation time of under second 
we demonstrate a method for evaluating edge detector performance based on receiver operating characteristic roc curve edge detector output is matched against ground truth to count true positive and false positive edge pixel a detector s parameter setting are trained to give a best roc curve on one image and then tested on separate image we compute aggregate roc curve based on set of object image and another set of aerial image we analyze the performance of different edge detector reported in the literature 
in many application one would like to use information from both color and texture feature in order to segment an image we propose a novel technique to combine soft segmentation computed for two or more feature independently our algorithm merges model according to a maximum descriptiveness criterion and allows to choose any number of class for the final grouping this technique also allows to improve the quality of supervised classification based on one feature e g color by merging information from unsupervised segmentation based on another feature e g texture 
new application in field such a augmented or virtualized reality have created a demand for dense accurate real time stereo reconstruction our goal is to reconstruct a user and her office environment for networked tele immersion which requires accurate depth value in a relatively large workspace in order to cope with the combinatorics of stereo correspondence we can exploit the temporal coherence of image sequence by using coarse optical flow estimate to bound disparity search range at the next iteration we use a simple flood fill segmentation method to cluster similar disparity value into overlapping window and predict their motion over time using a single optical flow calculation per window we assume that a contiguous region of disparity represents a single smooth surface which allows u to restrict our search to a narrow disparity range the value in the range may vary over time a object move nearer or farther away in z but we can limit the number of disparity to a feasible search size per window further the disparity search and optical flow calculation are independent for each window and allow natural distribution over a multi processor architecture we have examined the relative complexity of stereo correspondence on full image versus our proposed window system and found that depending on the number of frame in time used to estimate optical flow the window based system requires about half the time of standard correlation stereo experimental comparison to full image correspondence search show our window based reconstruction compare favourably to those generated by the full algorithm even after several frame of propagation via estimated optical flow the result is a system twice a fast a conventional dense correspondence without significant degradation of extracted depth value 
reliable estimation of the trifocal tensor is crucial for d reconstruction from uncalibrated camera the estimation process is based on minimizing the geometric distance between the measurement and the corrected data point the underlyingnonlinearoptimizationproblembeing most often solved with the levenberg marquardt lm algorithm we employ for this task the heteroscedastic error in variable heiv estimator and take into account both the singularity of the multivariate tensor constraint and the bifurcation which can appear for noisy data in comparisonto the gold standard method the new approach is significantlyfaster while having the same performance and it is le sensitive to initialization when the data is close to degenerate analytical expression for the covariancesof the parameterand corrected image point estimate are available for the heiv estimator and thus the confidenceregions of the corrected measurement can be delineated in the image trifocal tensor the trifocal tensor describes the intrinsic projective property of a group of three image taken with uncalibrated camera the role of trifocal tensor in the projective reconstruction of d structure is extensively discussed in the literature and we refer to the recent book pp for an excellent treatment of all the relevant topic and to for an comprehensive discussion of the involved optimization method in this paper will focus on the problem of estimating the trifocal tensor from view point correspondence i e from the matched image of d point we will assume that all the correspondence are correct while the estimation method presented here can be easily robustifiedsimilar to we concentrate on issue related to the behavior of the estimation process i e on numerical robustness will start by reviewing the geometric relation needed in the sequel given three camera characterized by unknown projective matrix the image of a d point in each view will be denoted in homogeneous coordinate and similarly for the point in the other two image the projective ambiguity allows to express the camera matrix a 
in we presented a new velocity estimation algorithm using orientation tensor and parametric motion model to provide both fast and accurate result one of the tradeoff between accuracy and speed wa that no attempt were made to obtain region of coherent motion when estimating the parametric model in this paper we show how this can be improved by doing a simultaneous segmentation of the motion field the resulting algorithm is slower than the previous one but more accurate this is shown by evaluation on the well known yosemite sequence where already the previous algorithm showed an accuracy which wa substantially better than for earlier published method this result ha now been improved further 
we describe a shape from texture method that construct a maximum a posteriori estimate of surface coefficient using both the deformation of individual texture element a in local method and the overall distribution of element a in global method the method described applies to a much larger family of texture than any previous method local or global we demonstrate an analogy with shape from shading and use this to produce a numerical method example of reconstruction for synthetic image of surface are provided and compared with ground truth the method is defined for orthographic view but can be generalised to perspective view simply keywords shape from texture texture computer vision surface fit 
this paper is a contribution to the recovery of shape from texture under perspective projection we regard shape from texture a a statistical estimation problem the texture be ing the realization of a stochastic process there are two minimal condition in order for the problem to be solvable the first is a stationarity condition on the texture with respect to the surface the second is the regularity of the surface information about the surface is obtained by estimating a deformation map we prove that at a fine scale the wavelet decomposition of the image obeys a transport pde the coefficient of which can be estimated and related to the deformation map we show how the global surface shape can then be integrated 
a method is presented to recover d scene structure and camera motion from multiple image without the need for correspondence information the problem is framed a finding the maximum likelihood structure and motion given only the d measurement integrating over all possible assignment of d feature to d measurement this goal is achieved by mean of an algorithm which iteratively refines a probability distribution over the set of all correspondence assignment at each iteration a new structure from motion problem is solved using a input a set of virtual measurement derived from this probability distribution the distribution needed can be efficiently obtained by markov chain monte carlo sampling the approach is cast within the framework of expectation maximization which guarantee convergence to a local maximizer of the likelihood the algorithm work well in practice a will be demonstrated using result on several real image sequence 
we have been developing a theory for the generic representation of d shape where structural description are derived from theshocks singularity of a curve evolution process acting on boundingcontours we now apply the theory to the problem of shape matching the shocksare organized into a directed acyclic shock graph and complexity ismanaged by attending to the most significant central shape componentsfirst the space of all such graph is highly structured and can becharacterized by the rule of a shock graph grammar the grammarpermits a reduction of a shock graph to a unique rooted shock tree weintroduce a novel tree matching algorithm which find the best set ofcorresponding node between two shock tree in polynomial time using adiverse database of shape we demonstrate our system s performance underarticulation occlusion and moderate change in viewpoint 
the major challenge that face american sign language asl recognition now is to develop method that will scale well with increasing vocabulary size unlike in spoken language phoneme can occur simultaneously in asl the number of possible combination of phonemesafter enforcing linguistic constraint is approximately gesture recognition which is le constrained than asl recognition suffers from the same problem thus it is not feasible to train conventional hidden markov model hmms for large scale asl application factorial hmms and coupled hmms are two extension to hmms that explicitly attempt to model several process occuring in parallel unfortunately they still require consideration of the combination at training time in this paper we present a novel approach to asl recognition that aspires to being a solution to the scalability problem it is based on parallel hmms pahmms which model the parallel process independently thus they can also be trained independently and do not require consideration of the different combination at training time we develop the recognition algorithm for pahmms and show that it run in time polynomial in the number of state and in time linear in the number of parallel process we run several experiment with a sign vocabulary and demonstrate that pahmms can improve the robustness of hmm based recognition even on a small scale thus pahmms are a very promising general recognition scheme with application in both gesture and asl recognition 
we define a new image feature called the color correlogramand use it for image indexing and comparison this feature distills the spatial correlation of color and when computed efficiently turn out to be both effective and inexpensive for content based image retrieval the correlogram is robust in tolerating large change in appearance and shape caused by change in viewing position camera zoom etc experimental evidence show that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement method for image indexing retrieval we also provide a technique to cut down the storage requirement of the correlogram so that it is the same a that of histogram with only negligible performance penalty compared to the original correlogram we also suggest the use of color correlogram a a generic indexing tool to tackle various problem arising from image retrieval and video browsing we adapt the correlogram to handle the problem of image subregion querying object localization object tracking and cut detection experimental result again suggest that the color correlogram is more effective than the histogram for these application with insignificant additionalstorage or processing cost 
this paper focus on matching d structure by variational method we provide rigorous rule for the construction of the cost function on the basis of an analysis of property which should be satisfied by the optimal matching a new exact dynamic programming algorithm is then designed for the minimization we conclude with experimental result on shape comparison 
this paper address the problem of recovering structure and motion from silhouette silhouette are projection of contour generator which are viewpoint dependent and hence do not readily provide point correspondence for exploitation in motion estimation previous work have exploited correspondence induced by epipolar tangency and a successful solution ha been developed in the special case of circular motion turntable sequence however the main drawback are new view cannot be added easily at a later time and part of the structure will always remain invisible under circular motion in this paper we overcome the above problem by incorporating arbitrary general view and estimating the camera pose using silhouette alone we present a complete and practical system which produce high quality d model from d uncalibrated silhouette the d model thus obtained can be refined incrementally by adding new arbitrary view and estimating their pose experimental result on various object are presented demonstrating the quality of the reconstruction 
the computation of optical flow from image derivativesis biased in region of non uniform gradient distribution a least square or total least square approachto computing optic flow from image derivativeseven in region of consistent flow can lead to a systematicbias dependent upon the direction of the opticflow the distribution of the gradient direction andthe distribution of the image noise the bias a consistentunderestimation of length and a directional error similar result 
tree structured probabilistic model admit simple fast inference however they are not well suited to phenomenon such a occlusion where multiple component of an object may disappear simultaneously mixture of tree appear to address this problem at the cost of representing a large mixture we demonstrate an efficient and compact representation of this mixture which admits simple learning and inference algorithm we use this method to build an automated tracker for muybridge sequence of a variety of human activity tracking is difficult because the temporal dependency rule out simple inference method we show how to use our model for efficient inference using a method that employ alternate spatial and temporal inference the result is a tracker that a us a very loose motion model and so can track many different activity at a variable frame rate and b is entirely automatic 
croma keying is the process of segmenting object from image and video using color cue a blue or green screen placed behind an object during recording is used in special effect and in virtual studio the blue color is later replaced by a different background blue screen is an example ofchroma keying where the keying signal is chroma difference a new method for automatic keying using invisible signal is presented the advantage of the new approach over conventional chroma keying include i unlimited color range for foreground object ii no foreground contamination by background color iii better performance in non uniform illumination iv feature for generating refraction and reflection of dynamic object the method can be used in real time and no user assistance is required new design of catadioptric camera and a single chip sensor for keying is also presented 
abstract 
the singular value decomposition svd of a matrix is a linear algebra tool that ha been successfully applied to a wide variety of domain the present paper is concerned with the problem of estimating the jacobian of the svd component of a matrix with respect to the matrix itself an exact analytic technique is developed that facilitates the estimation of the jacobian using calculation based on simple linear algebra knowledge of the jacobian of the svd is very useful in certain application involving multivariate regression or the computation of the uncertainty related to estimate obtained through the svd the usefulness and generality of the proposed technique is demonstrated by applying it to the estimation of the uncertainty for three different vision problem namely self calibration epipole computation and rigid motion estimation 
multi resolution technique have been used in a wide range of vision application unfortunately the costly operation of building a proper pyramid strongly reduces it value a a tool for reducing computational cost a new approach physical panoramic pyramid is introduced in this paper physical panoramic pyramid measure multiple resolution simultaneouslyresulting in multi resolution panoramic image no computationis needed to construct these image pyramid we also analyze general noise sensitivity in image pyramid including the interaction of the loss of resolution random background noise and aliasing noise the paper also discus the issue of indexing between the neighboring layer the viewpoint variation and the application of the physical panoramic pyramid 
image based interpolation creates smooth and photorealistic view between two view point the concept of joint view triangulation jvt ha been proven to be an efficient multi view representation to handle visibility issue however the existing jvt built only on a regular sampling grid often produce undesirable artifact for artificial object to tackle these problem a new edge constrained joint view triangulation is developed in this paper to integrate contour point and artificial rectilinear object a triangulation constraint also a super sampling technique is introduced to refine visible boundary the new algorithm is successfully demonstrated on many real image pair 
given a sequence of pair of image gathered with an uncalibrated stereo camera pair and given a set of point to point correspondence between these image pair we describe a method that segment the observed scene into static and moving object while it reject badly matched point unlike many approach which were suggested in the past the method allows for both motion of the camera pair egomotion and non rigid scene scene composed of static object a well a object undergoing various motion first we establish the projective framework enabling u to characterize rigid motion in projective space second we use this characterization in conjunction with a robust estimation technique to determine egomotion third we describe a method based on data classification which further considers the non static scene point anal group them into several moving object finally we show some preliminary experiment involving a moving stereo head observing both static and moving object 
the paper present a new approach to computing depth map from a large collection of image where the camera motion ha been constrained to planar concentric circle we resample the resulting collection of regular perspective image into a set of multiperspective panorama and then compute depth map directly from these resampled image only a small number of multiperspective panorama is needed to obtain a dense and accurate d reconstruction since our panorama sample uniformly in three dimension rotation angle inverse radial distance and vertical elevation using multiperspective panorama avoids the limited overlap between the original input image that cause problem in conventional multi baseline stereo our approach differs from stereo matching of panoramic image taken from different location where the epipolar constraint are sine curve for our multiperspective panorama the epipolar geometry to first order consists of horizontal line therefore any traditional stereo algorithm can be applied to multiperspective panorama without modification experimental result show that our approach generates good depth map that can be used for image based rendering task such a view interpolation and extrapolation 
we formulate colour constancy a a problem ofbayesian inference where one is trying to representthe posterior on possible interpretation given imagedata we represent the posterior a a set of sample drawn from that distribution using a markov chainmonte carlo method we show how to build an efficientsampler this approach ha the advantage that it unifies theconstraints on the problem and represents possibleambiguities in turn a good description of possibleambiguities mean that 
an approach to extract watershed and watercourse a well a their corresponding valley and hill from image with subpixel precision is proposed the critical point of the terrain are essential a the starting point for the construction of these separatrix they are extracted efficiently with subpixel precision using an approach based on derivative of gaussian filter the separatrix are extracted by integrating their defining differential equation finally the hill and valley are constructed by an efficient graph search algorithm example show the quality of the result that can be achieved with the proposed approach 
we present in this paper the design of an interactive tool for selecting object using simple freehand sketch the objective is to extract object boundary precisely while requiring little skill and time from the user the tool proposed achieves this objective by integrating user input and image computation in a two phase algorithm in the first phase the input sketch is used along with a coarse global segmentation of the image to derive an initial selection and a triangulation of the region around the boundary the triangle are used to formulate subproblems of local finer grained segmentation and selection each of the subproblems is processed independently in the second phase where a linear approximation of the local boundary a well a a local finer grained segmentation are computed the approximate boundary is then used with the local segmentation to compute a final selection represented with an alpha channel to fully capture diffused object boundary experimental result show that the tool allows very simple sketch to be used to select object with complex boundary therefore the tool ha immediate application in graphic system for image editing manipulation synthesis retrieval and processing 
we propose a method to estimate the motion of a person filmed by two or more fixed camera the novelty of our technique is it ability to cope with fast movement self occlusion and noisy image our algorithm are based on the latest work on calibration and image segmentation developed in our lab we compare the projection of a d model of a person on the image to the detected silhouette of the person and create force that will move the d model towards the final estimation of the real pose we developed a fast algorithm that computes the motion of the articulated d model we show that our result are good even if the camera are not synchronized 
object oriented representation of image sequence require s accurate motion segmentation and depth ordering technique unfortunately the lack of precise motion estimate s at the object boundary make these two task very difficult in this paper we present a detailed analysis of the behaviour of dense motion estimation technique at object boundary which reveals the systematic nature of the motion estimatio n error the motion of the occluding surface is observed in a small neighbourhood on the occluded side we then show how the joint use of still image segmentation and robust regression can eliminate this error furthermore we present a novel technique which us the position of the error a a depth cue the validity of this technique which requires only sub pixel motion and which is capable of distinguishing between different type of intensity discontinuity such a object boundary surface mark and illumination discontinuity is then demonstrated on several synthetic an d real image sequence 
we describe a theoretically optimal algorithm for computing the homography between two image in relation to image mosaicing application first we derive a theoretical accuracy bound based on a mathematical model of image noise and do simulation to confirm that our renormalization technique effectively attains that bound our algorithm is optimal in that sense then we apply our technique to mosaicing of image with small overlap by using real image we show how our algorithm reduces the instability of the image mapping 
while real scene produce a wide range of brightness variation vision system use low dynamic range image detector that typically provide bit of brightness data at each pixel the resulting low quality image greatly limit what vision can accomplish today this paper proposes a very simple method for significantly enhancing the dynamic range of virtually any imaging system the basic principle is to simultaneously sample the spatial and exposure dimension of image irradiance one of several way to achieve this is by placing an optical mask adjacent to a conventional image detector array the mask ha a pattern with spatially varying transmittance thereby giving adjacent pixel on the detector different exposure to the scene the captured image is mapped to a high dynamic range image using an efficient image reconstruction algorithm the end result is an imaging system that can measure a very wide range of scene radiance and produce a substantially larger number of brightness level with a slight reduction in spatial resolution we conclude with several example of high dynamic range image computed using spatially varying pixel exposure 
the paper ha two main contribution the first is a set of method for computing structure and motion for m view of point it is shown that a geometric image error can be minimized over all view by a simple three parameter numerical optimization then that an algebraic image error can be minimized over all view by computing the solution to a cubic in one variable finally a minor point is that this quasi linear linear solution enables a more concise algorithm than any given previously for the reconstruction of point in view the second contribution is an m view n point robust reconstruction algorithm which us the point method a a search engine this extends the successful ransac based algorithm for view and view to m view the algorithm can cope with missing data and mismatched data and may be used a an efficient initializer for bundle adjustment the new algorithm are evaluated on synthetic and real image sequence and compared to optimal estimation result bundle adjustment 
a new method for tracking contour of moving object in clutter is presented for a given object a model of it contour is learned from training data in the form of a subset of contour space greater complexity is added to the contour model by analyzing rigid and non rigid transformation of contour separately in the course of tracking multiple contour may be observed due to the presence of extraneous edge in the form of clutter the learned model guide the algorithm in picking out the correct one the algorithm which is posed a a solution to a minimization problem is made efficient by the use of several iterative scheme result applying the proposed algorithm to the tracking of a fle xing fing er and to a conversing individual s lip are presented describes the evolution of the contour to be tracked assuming that the observation of the contour ha been corrupted by gaussian noise the conditional density of the contour given all past observation may be found and then used to estimate the contour position the condensation tracker also assumes a dynamical model describing contour motion is known and that imprecise observation are made however both the dynamical system and the observation process may be completely general and the conditional density may be propagated forward in time using the numerical technique known a the condensation method this density may then be used for estimating the current contour 
human learn strategy for visual discrimination through interaction with their environment discrimination skill s are refined a demanded by the task at hand and are not a priori determined by any particular feature set task are typically incompletely specified and evolve continually this work present a general framework for learning visual discrimination that address some of these characteristic it is based on an infinite combinatorial feature space consisting of primitive feature such a oriented edgels and textur e signature and composition thereof feature are progre ssively sampled from this space in a simple to complex manner a simple recognition procedure query learned featur e one by one and rule out candidate object class that do not sufficiently exhibit the queried feature training image a re presented sequentially to the learning system which incre mentally discovers feature for recognition experimenta l result on two database of geometric object illustrate th e applicability of the framework 
detecting human in image is a useful application of computer vision loose and textured clothing occlusion and scene clutter make it a difficult problem because bottom up segmentation and grouping do not always work we address the problem of detecting human from their motion pattern in monocular image sequence extraneous motion and occlusion may be present we assume that we may not rely on segmentation or grouping and that the vision front end is limited to observing the motion of key point and textured patch in between pair of frame we do not assume that we are able to track feature for more than two frame our method is based on learning an approximate probabilistic model of the joint position and velocity of different body feature detection is performed by hypothesis testing on the maximum a posteriori estimate of the pose and motion of the body our experiment on a dozen of walking sequence indicate that our algorithm is accurate and efficient 
we review our work on how to teach deformable model to maximize image segmentation correctness based on user specified criterion we then present new variant and application of learned snake modeled by four different probability density function pdfs at three scale and in the two very different medical domain of abdominalct slice and echocardiogram we review and extend our method for evaluating which criterion work best success depends on the relation of objective function the pdf output to shape correctness this relationship for all the above learned snake variant and domain is evaluated on perturbed ground truth shape in three way by the incidence of false positive scoring better than ground truth of randomized shape by the monotonicity of the objective function versus shape closeness to ground truth a given by a correlation coefficient and by the distance of this relationship to the nearest monotonicallyincreasing function a new performance measure which we introduce here we exhaustively demonstrate such evaluation on traditional snake and on snake for which image intensity and perpendicular gradient are learned separately and with their covariance and with separate learning over equallength sector optimal blur appears to depend on domain both sectoring and the use of covariance markedly improve result in abdominalct image where nearby image landmark i e organ stabilize learning result on echocardiogram however are le striking although the use of covariance doe show improvement on investigation this appears due to the non gaussian distribution of image feature in this domain 
much of the recent research in object recognition hasadopted an appearance based scheme wherein objectsto be recognized are represented a a collection of prototypesin a multidimensional space spanned by a numberof characteristic vector eigen image obtainedfrom training view in this paper we extend theappearance based recognition scheme to handle range shape data the result of training is a set of eigensurfaces that capture the gross shape of the object these technique 
herein we present a variational model devoted to image classification coupled with an edge preserving regularization process in the last decade the variational approach ha proven it efficiency in the field of edge preserving restoration in this paper we add a classification capability which contributes to provide image compound of homogeneous region with regularized boundary the soundness of this model is based on the work developed on the phase transition theory in mechanic the 
we consider the problem of reconstructing the d coordinate of a moving point seen from a monocular moving camera i e to reconstruct moving object from line of sight measurement only the task is feasible only when some constraint are placed on the shape of the trajectory of the moving point we coin the family of such task a quot trajectory triangulation quot in this paper we focus on trajectory whose shape is a conic section and show that generally view are sufficient for a unique 
consider two view of a multi body scene consisting of planar body moving in pure translation one relative to the other we show that the fundamental matrix one per body live in a dimensional subspace which when represented a a step extensor is the common transversal on the collection of extensor defined by the homography matrix of the moving plane we show that a much a five body are necessary for recovering the common transversal from the homography matrix from which we show how to recover the fundamental matrix and the affine calibration between the two camera 
this paper empirically compare nine image dissimilarity measure that are based on distribution of color and texture feature summarizing over cpu hour of computational experiment ground truth is collected via a novel random sampling scheme for color and via an image partitioning method for texture quantitative performance evaluation are given for classification image retrieval and segmentation task and for a wide variety of dissimilarity measure it is demonstrated how the selection of a measure based on large scale evaluation substantially improves the quality of classification retrieval and unsupervised segmentation of color and texture image 
intrinsic image are a useful midlevel description of scene proposed by barrow and tenenbaum an image is decomposed into two image a reflectance image and an illumination image finding such a decomposition remains a difficult problem in computer vision here we focus on a slightly easier problem given a sequence of image where the reflectance is constant and the illumination change can we recover illumination image and a single reflectance image we show that this problem is still illposed and suggest approaching it a a maximum likelihood estimation problem following recent work on the statistic of natural image we use a prior that assumes that illumination image will give rise to sparse filter output we show that this lead to a simple novel algorithm for recovering reflectance image we illustrate the algorithm s performanceon real and synthetic image sequence in proc iccv 
we present a unified computational framework which properly implement the smoothness constraint to generate description in term of surface region curve and labelled junction from sparse noisy binary data in d or d each input site can be a point a point with an associated tangent direction a point with an associated normal direction or any combination of the above the methodology is grounded on two element tensor calculus for representation and linear voting for communication each input site communicates it information a tensor to it neighborhood through a predefined tensor field and therefore cast a tensor vote each site collect all the vote cast at it location and encodes them into a new tensor a local parallel marching process then simultaneously detects feature the proposed approach is very different from traditional variational approach a it is non iterative furthermore the only free parameter is the size of the neighborhood related to the scale we have developed several algorithm based on the proposed methodology to address a number of early vision problem including perceptual grouping in d and d shape from stereo and motion grouping and segmentation and the result are very encouraging 
principal component analysis pca approach to face recognition are data dependent and computationally expensive to classify unknown face they need to match the nearest neighbour in the stored database of extracted face feature in this paper discrete cosine transforms dcts are used to reduce the dimensionality of face space by truncating high frequency dct component the remaining coefficient are fed into a neural network for classification because only a small number of low 
this paper present a novel approach for reconstructing free form texture mapped d scene model from a single painting or photograph given a sparse set of user specified constraint on the local shape of the scene a smooth d surface that satisfies the constraint is generated this problem is formulated a a constrained variational optimization problem in contrast to previous work in single view reconstruction our technique enables high quality reconstruction of free form curved surface with arbitrary reflectance property a key feature of the approach is a novel hierarchical transformation technique for accelerating convergence on a non uniform piecewise continuous grid the technique is interactive and update the model in real time a constraint are added allowing fast reconstruction of photorealistic scene model the approach is shown to yield high quality result on a large variety of image 
an automated method for left ventricle detection in mr cardiac image is presented ventricle detection is the first step in a fully automated segmentation system used to compute volumetric information about the heart our method is based on learning the gray level appearance of the ventricle by maximizing the discrimination between positive and negative example in a training set the main difference from previously reported method are feature definition and solution to the optimization problem involved in the learning process our method wa trained on a set of mr cardiac image from which positive example and negative example were generated the detection result on a test set of different image demonstrate an excellent performance detection rate a false alarm rate of of the number of window analyzed false alarm per image and a detection time of second per image on a sun ultra for an scale search the false alarm are eventually eliminated by a position scale consistency check along all the image that represent the same anatomical slice 
reliable detection and tracking of eye is an important requirement for attentive user interface in this paper we present a methodology for detecting eye robustly in indoor environment in real time we exploit the physiological property and appearance of eye a well a head eye motion dynamic structured infrared lighting is used to capture the physiological property of eye kalman tracker are used to model eye head dynamic and a probabilistic based appearance model is used to represent eye appearance by combining three separate modality with specific enhancement within each modality our approach allows eye to be treated a robust feature that can be used for other higher level processing 
we present a stochastic clustering algorithm which us pairwise similarity of element based on a new graph theoretical algorithm for the sampling of cut in graph the stochastic nature of our method make it robust against noise including accidental edge and small spurious cluster we demonstrate the robustness and superiority of our method for image segmentation on a few synthetic example where other recently proposed method such a normalized cut fail in addition the complexity of our method is lower we describe experiment with real image showing good segmentation result 
optical flow estimation in noisy image sequence requires a special denoising strategy towards this end we introduce a new tensor driven anisotropic diffusion scheme which is designed to enhance optical flow like spatiotemporal structure this is achieved by selecting diffusivities in a special manner depending on the eigenvalue of the well known structure tensor we illustrate how the proposed choice differs from edgeand coherence enhancing anisotropic diffusion furthermore we extend a recently discovered discretization scheme for anisotropic diffusion to d data an automatic stop criterion to terminate the diffusion after a suitable time is given the performance of the introduced method is examined quantitatively using image sequence with a substantial amount of noise added 
the surface matching problem is investigated in this paper using a mathematical tool called harmonic map the theory of harmonic map study the mapping between different metric manifold from the energyminimization point of view with the application of harmonic map a surface representation called harmonic shape image is generated to represent and match d freeform surface the basic idea of harmonic shape image is to map a d surface patch with disc topology to a d domain and encode the shape information of the surface patch into the d image this simplifies the surface matching problem to a d image matching problem due to the application of harmonic map in generating harmonic shape image harmonic shape image have the following advantage they have sound mathematical background they preserve both the shape and continuity of the underlying surface and they are robust to occlusion and independent of any specific surface sampling scheme the performance of surface matching using harmonic map is evaluated using real data preliminary result are presented in the paper 
the critical configuration for projective reconstruction from three view are discussed a set of camera and point is said to be critical if the projected image point are insufficient to determine the placement of the point and camera uniquely up to projective transformation for two view the classification of critical configuration is well known the configuration is critical if and only if the point and camera centre all lie on a ruled quadric for three view the critical configuration have not been identified previously in this paper it is shown that for any placement of three given camera there always exists a critical set consisting of a fourth degree curve any number of point on the curve form a critical set for the three camera dual to this result for a set of seven point there exists a fourth degree curve such that a configuration of any number of camera placed on this curve is critical for the set of point other critical configuration exist in case where the point all lie in a plane or one of the camera lie on a twisted cubic 
we present a general algorithm for plane based calibration that can deal with arbitrary number of view and calibration plane the algorithm can simultaneously calibrate different view from a camera with variable intrinsic parameter and it is easy to incorporate known value of intrinsic parameter for some minimal case we describe all singularity naming the parameter that can not be estimated experimental result of our method are shown that exhibit the singularity while revealing good performance in non singular condition several application of plane based d geometry inference are discussed a well in this paper we propose a general algorithm for calibrating a camera with possibly variable intrinsic parameter and position that cope well with an arbitrary number of calibration plane and camera view calibration is essentially done in two step first the d to d projection of planar calibration object onto the image plane s are computed each of these projection contributes to a system of homogeneous linear equation in the intrinsic parameter which are hence easily determined calibration can thus be achieved by solving linear equation but can of course be enhanced by subsequent non linear optimization in we describe our camera model and projection of planar object in we introduce the principle of plane based calibration a general algorithm is proposed in singularity are revealed in experimental result are presented in and some application described in 
a problem of using mixture of gaussian model for unsupervised texture segmentation is that multimodal texture such a can often be encountered in natural image cannot be well represented by a single gaussian cluster we propose a divide andconquer method that group together gaussian cluster estimated via expectation maximization into homogeneous texture class this method allows to succesfully segment even rather complex texture a demonstrated by experimental test on natural image 
this paper describes a new method for determiningcorrespondence between point on pair of surfacesbased on shape using a combination of geodesic distanceand surface curvature an initial sparse setof corresponding point are generated using a shapebasedmatching procedure geodesic interpolation isemployed in order to capture the complex surface inaddition surface correspondence and triangulation arecomputed simultaneously in a hierarchical way resultsapplied to human cerebral 
in this paper we propose an invariant signature representation for appearance of d object under varying view and illumination and a method for learning the signature from multi view appearance example the signature a nonlinear feature provides a good basis for d object detection and pose estimation due to it following property it location in the signature feature space is a simple function of the view and is insensitive or invariant to illumination it change continuously a the view change so that the object appearance at all possible view should constitute a known simple curve segment manifold in the feature space the coordinate of the object appearance in the feature space are correlated in a known way according to a predefined function of the view the first two property provide a basis for object detection and the third for view pose estimation to compute the signature representation from input we present a nonlinear regression method for learning a nonlinear mapping from the input e g image space to the feature space the idea of the signature representation and the learning method are illustrated with experimental result for the object of human face it is shown that the face object can be effectively modeled compactly in a d nonlinear feature space the d signature present excellent insensitivity to change in illumination for any view the correlation of the signature coordinate is well determined by the predefined parametric function application of the proposed method in face detection and pose estimation are demonstrated 
we present a bayesian recognition framework in which a model of the whole face is enhanced by model of facial feature position and appearance face recognition and facial expression recognition are carried out using maximum likelihood decision the algorithm find the model and facial expression that maximizes the likelihood of a test image in this framework facial appearance matching is improved by facial expression matching also change in facial feature due to expression are used 
we present a method for modeling a scene that is observed by a moving camera where only a portion of the scene is visible at any time this method us mixture model to represent pixel in a panoramic view and to construct a background image that contains only static non moving part of the scene the method can be used to reliably detect moving object in a video sequence detect pattern of activity over a wide eld of view and remove moving object from a video or panoramic mosaic the method also yield improved result in detecting moving object and in constructing mosaic in the presence of moving object when compared with technique that are not based on scene modeling we present example illustrating the result 
we describe a robust technique for detecting nonstationaryperiodic motion from a moving and static camera we also describe a robust technique for discriminatingmotion symmetry periodic motion classification whichwe apply to classifying running human biped and canine quadruped the system ha been implemented torun in real time hz on standard pc workstation introductionperiodic and cyclic motion are commonly found in theworld perhaps the most prevalent periodic 
a novel approach to visual servoing is presented which take advantage of the structure of the lie algebraof affine transformation the aim of this projectis to use feedback from a visual sensor to guide arobot arm to a target position the sensor is placedin the end effector of the robot the camera in hand approach and thus provides direct feedback of the robotmotion relative to the target scene via observed transformationsof the scene these scene transformationsare obtained by 
recognition using only visual evidence cannot always be successful due to limitation of information and resource available during training considering relation among lexicon entry is sometimes useful for decision making in this paper we present a method to capture lexical similarity of a lexicon and reliability of a character recognizer which serve to capture the dynamism of the environment a parameter lexical similarity is defined by measuring these two factor a edit distance between lexicon entry and separability of each character s recognition result our experiment show that a utility function considering lexical similarity in a decision stage can enhance the performance of a conventional word recognizer 
a technique is presented for representing linear feature a probability density function in two or three dimension three chief advantage of this approach are a unified representation and algebra for manipulating point line and plane seamless incorporation of uncertainty information and a very simple recursive solution for maximum likelihood shape estimation application to uncalibrated affine scene reconstruction are presented with result on image of an outdoor environment 
the earth mover s distance emd is a distance measure between distribution with application in image retrieval and matching we consider the problem of computing a transformation of one distribution which minimizes it emd to another the application discussed here include estimation of the size at which a color pattern occurs in an image lighting invariant object recognition and point feature matching in stereo image pair we present a monotonically convergent iteration which can be applied to a large class of emd under transformation problem although the iteration may converge to only a locally optimal transformation we also provide algorithm that are guaranteed to compute a globally optimal transformation for a few specific problem including some emd under translation problem 
an increase in the off nadir viewing angle for an airborne visible near infrared through short wave infrared vnir swir imaging spectrometer lead to a decrease in upward atmospheric transmittance and an increase in line of sight scattered path radiance these effect combine to reduce the spectral contrast between different material in the sensed signal we analyze the impact of viewing angle on material discriminability for material over a wide range of condition material discriminability is quantified using a statistical algorithm that employ a subspace model to represent the set of spectrum for a material a condition vary we show that reliable material discrimination is possible over a range of condition even for large off nadir viewing angle we illustrate the performance of material identification over different viewing angle using simulated forest hyperspectral image 
we present a new robust point matching algorithm rpm that can jointly estimate the correspondence and non rigid transformation between two point set that may be of different size the algorithm utilizes the softassign for the correspondence and the thinplate spline for the non rigid mapping embedded within a deterministic annealing framework the algorithm can automatically reject a raction of the point a outlier experiment on both d synthetic pointsets with varying degree of 
we present a multiview method for the computation ofobject shape and reflectance characteristic based on the integrationof shape from shading sfs and stereo for nonconstantalbedo and non uniformly lambertian surface first we perform stereo fitting on the input stereo pair orimage sequence when the image are uncalibrated werecover the camera parameter using bundle adjustment based on the stereo result we can automatically segmentthe albedo map which is taken to be piece wise 
facial variation divide into a number of functional subspace an improved method of measuring these wa designed within the space defined by an appearance model initial estimate of the subspace lighting pose identi ty expression were obtained by principal component analysis on appropriate group of face an iterative algorith m wa applied to image coding to maximise the probability of coding across these non orthogonal subspace before obtaining the projection on each sub space and recalculating the space this procedure enhances identity recognition reduces overall sub space variance and produce principal component with greater span and le contamination 
in this paper the problem of controlling the spatialposition and orientation of a robotic platform based onthe image data obtained from a video camera mountedon that platform is considered more specifically wepropose control law that generate translational andangular velocity that will cause the robot to achieveand maintain a fixed position and orientation with respectto a set of feature point in the scene the proposed control scheme make use of well establishedtechniques for 
the development of user interface based on vision and speech requires the solution of a challenging statistical inference problem the intention and action of multiple individual must be inferred from noisy and ambiguousdata we argue that bayesian network model are an attractive statistical framework for cue fusion in these application bayes net combine a natural mechanism for expressing contextual information with efficient algorithm for learning and inference we illustrate these point through the development of a bayes net model for detecting when a user is speaking the model combine four simple vision sensor face detection skin color skin texture and mouth motion we present some promising experimental result 
this paper present a new approach to computing dense depth and motion estimate from multiple image rather than computing a single depth or motion map from such a collection we associate motion or depth estimate with each image in the collection or at least some subset of the image this ha the advantage that the depth or motion of region occluded in one image will still be represented in some other image thus task such a novel view interpolation or motion compensated prediction can be solved with greater fidelity furthermore the natural variation in appearance between different image can be captured to formulate motion and structure recovery we cast the problem a a global optimization over the unknown motion or depth map and use robust smoothness constraint to constrain the space of possible solution we develop and evaluate some motion and depth estimation algorithm based on this framework 
there have been relatively little work to shed light on the effect of error in the intrinsic parameter on motion estimation and scene reconstruction given that the estimation of the extrinsic and intrinsic parameter from uncalibrated motion apts to be imprecise it is important to study the resulting distortion on the recovered structure by making use of the iso distortion framework we explicitly characterize the geometry of the distorted space recovered from d motion with freely varying focal length this characterization allows u to investigate the effectiveness of the visibility constraint in disambiguating uncalibrated motion by studying the negative distortion region and to make explicit those ambiguous error situation under which the visibility constraint is not effective an important finding is that under these ambiguous situation the direction of heading can nevertheless be accurately recovered and the structure recovered experienced a well behaved distortion the distortion is given by a relief transformation which preserve ordinal depth relation thus in the case where the only unknown intrinsic parameter is the focal length structure information in the form of depth relief can be obtained experiment were presented to support the use of the visibility constraint in obtaining such partial motion and structure solution 
in this paper a compact representation d layered adaptive resolution and multi perspective panorama lamp is proposed for representing large scale and d scene with occlusion two kind of d lamp representation are constructed i e the relief like lamp and the image based lamp both of which concisely represent almost all the information from a long image sequence the relief like lamp is basically a single extended multi perspective panoramic view image with both texture and depth value but each pixel ha multiple value to represent result of occlusion recovery and resolution enhancement the image based lamp on the other hand consists of a set of multi perspective layer each of which ha both texture and depth map with adaptive time sampling scale depending on depth of scene point several example of d lamp construction for real image sequence are given the d lamp is a concise and powerful representation for image based rendering 
we define a process called congealing in which element of a dataset image are brought into correspondence with each other jointly producing a data defined model it is based upon minimizing the summed component wise pixelwise entropy over a continuous set of transforms on the data one of the biproducts of this minimization is a set of transforms one associated with each original training sam ple we then demonstrate a procedure for effectively bringing test data into correspondence with the data defined model produced in the congealing process subsequently we develop a probability density over the set of transforms that arose from the congealing process we suggest that this density over transforms may be shared by many class and demonstrate how using this density a prior knowledge can be used to develop a classifier based on only a single training example for each class 
this paper formulates and solves a new variant of the stereocorrespondence problem simultaneously recovering the disparity true color and opacity of visible surface element this problemarises in newer application of stereo reconstruction such a viewinterpolation and the layering of real imagery with synthetic graphicsfor special effect and virtual studio application while this problemis intrinsically more difficult than traditional stereo correspondence where only the disparity are being recovered it provides a principledway of dealing with commonly occurring problem such a occlusion andthe handling of mixed foreground background pixel near depthdiscontinuities it also provides a novel mean for separatingforeground and background object matting without the use of a specialblue screen we formulate the problem a the recovery of color andopacities in a generalized d x y d disparity space and solve theproblem using a combination of initial evidence aggregation followed byiterative energy minimization 
this paper describes computer vision algorithm to assist in retinal laser surgery which is widely used to treat leading blindness causing condition but only ha a success rate mostly due to a lack of spatial mapping and reckoning capability in current instrument the novel technique described here automatically construct a composite mosaic image of the retina from a sequence of incomplete view this mosaic will be useful to opthalmologists for both diagnosis and surgery the new technique go beyond published method in both the medical and computer vision literature because it is fully automated model the patient dependent curvature of the retina handle large interframe motion and doe not require calibra tion at the heart of the technique is a parameter image transformation model derived by modeling the retina a a quadratic surface and assuming a weak perspective camera and rigid motion estimating the parameter of this transformation model requires robustness to unmatchable image feature and mismatch between feature caused by large interframe motion the described estimation technique is a hierarchy of model and method the initial match set is pruned based on a th order transformation estimated using a similarity weighted histogram a st order affine transformation is estimated using the reduced match set and least median of square and the final nd order parameter transformation is estimated using an m estimator initialized from the st order result initia l experimental result show the method to be robust and accurate in accounting for the unknown retinal curvature in a fully automatic manner while preserving image detail 
in this paper we investigate the structure and motion problem for calibrated one dimensional projection of a two dimensional environment in a previous paper the structure and motion problem for all case with non missing data wa classified and solved our aim is here to classify all structure and motion problem even those with missing data and to solve them although our focus here is on onedimensional retina the classification part work equally well for ordinary camera and we give some result for those a well 
this paper describes a new method for estimating the illumination distribution of a real scene from a radiance distribution inside shadow cast by an object in the scene first the illumination distribution of the scene is approximated by discrete sampling of an extended light source then the illumination distribution of the scene is estimated from a radiance distribution inside shadow cast by an object of known shape onto another object in the scene instead of assuming any particular reflectance property of the surface inside the shadow both the illumination distribution of the scene and the reflectance property of the surface are estimated simultaneously based on iterative optimization framework in addition this paper introduces an adaptive sampling of the illumination distribution of a scene rather than using a uniform discretization of the overall illumination distribution we adaptively increase sampling direction of the illumination distribution based on the estimation at the previous iteration using the adaptive sampling framework we are able to estimate overall illumination more efficiently by using fewer sampling direction the proposed method is effective for estimating an illumination distribution even under a complex illumination environment 
new invariant feature are presented that can be usedfor the recognition of planar color pattern such a label logo sign pictograms etc irrespective of theviewpoint or the illumination condition and withoutthe need for error prone contour extraction the newfeatures are based on moment of power of the intensitiesin the individual color band and combinationsthereof these moment implicitly characterizethe shape the intensity and the color distributionof the pattern in a 
this paper describes a probabilistic syntactic approach to the detection and recognition of temporally extended activity and interaction between multiple agent a complete system consisting of an adaptive tracker an event generator and the parser performs segmentation and labeling of a surveillance video of a parking lot the system correctly identifies activity such a pick up and drop off which involve person vehicle interaction the main contribution of this paper are extending the parsing algorithm to handle multi agent interaction within a single parser providing a general mechanism for consistency based pruning and developing an efficient incremental parsing algorithm 
we introduce new small motion multi frame equation applicable to the reconstruction ofdynamic scene in which point are allowed to move along straight line path with constant velocity the motion equation apply to both static and dynamic point thus prior segmentation is not necessary we present a reconstruction algorithm of camera motion scene structure and point trajectory embedded into a multi frame factorization principle which requires the minimum of image and point out of which at least are dynamic we show that the minimal number of view necessary for a factorization is and the minimal number of point required for a recovery of camera motion scene structure and point trajectory is we also derive the solution to reduced situation such a when the trajectory are embedded in a coplanar or collinear configuration and when the point position are coplanar 
we present an algorithm to solve the sensor planning problem for a trinocular active vision system this algorithm us an iterative optimization method to first solve for the translation between the three camera and then us this result to solve for parameter such a pan tilt angle of the camera and zoom setting 
measure of scatter are used in statistical pattern recognition to identify and select important feature computed a linear combination of the given feature example include principal component and linear discriminants the classic computational procedure require eigenvector decomposition of large matrix and in the case of image they are only practical for identifying a low dimensional feature subspace we investigate the case in which the selected feature are required to be a subset of the given feature it is shown that the same scatter measure used in the general case can also be used in this discrete selection case but the computational procedure no longer involves matrix eigenvector decomposition instead the selection of pixel that optimize scatter measure can be accomplished by a very simple and efficient discrete optimization technique that run in linear time regardless of the subspace size application to clustering and content based indexing are discussed 
a sequence of image taken along a camera trajectory capture a subset of scene appearance if visibility space is the space that encapsulates the appearance of the scene at every conceivable pose and viewing angle then the act of acquiring the image sequence constitutes carving a volume in visibility space we call such a volume a visual tunnel the analysis of the visual tunnel allows u to do the following predict the range of virtual camera pose in which the image can be reconstructed totally using the captured ray predict which part of the image can be generated for a given virtual camera pose and plan camera path for scene visualization at desired location we describe our visual tunnel concept and provide illustrative example in d and d 
this paper present a theoretically very simple yet efficient approach for gray scale and rotation invariant texture classification based on local binary pattern and nonparametric discrimination of sample and prototype distribution the proposed approach is very robust in term of gray scale variation since the operator are by definition invariant against any monotonic transformation of the gray scale another advantage is computational simplicity a the operator can be realized with a few operation in a small neighborhood and a lookup table excellent experimental result obtained in two true problem of rotation invariance where the classifier is trained at one particular rotation angle and tested with sample from other rotation angle demonstrate that good discrimination can be achieved with the statistic of simple rotation invariant local binary pattern these operator characterize the spatial configuration of local image texture and the performance can be further improved by combining them with rotation invariant variance measure that characterize the contrast of local image texture the joint distribution of these orthogonal measure are shown to be very powerful tool for rotation invariant texture analysis 
we propose a three level video event detection algorithmand apply it to animal hunt detection in wildlife documentary the thetarst level extract texture color and motionfeatures and detects motion blob the mid level employsa neural network to verify whether the motion blob belongto object of interest this level also generates shotsummaries in term of intermediate level descriptor whichcombine low level feature from the thetarst level and containresults of mid level 
we present a component based method and two global method for face recognition and evaluate them with respect to robustness against pose change in the component system we first locate facial component extract them and combine them into a single feature vector which is classified by a support vector machine svm the two global system recognize face by classifying a single feature vector consisting of the gray value of the whole face image in the first global system we trained a single svm classifier for each person in the database the second system consists of set of viewpoint specific svm classifier and involves clustering during training we performed extensive test on a database which included face rotated up to about in depth the component system clearly outperformed both global system on all test 
we introduce a new graph theoretic approach to image segmentation based on minimizing a novel class of mean cut cost function minimizing these cost function corresponds to finding a cut with minimum mean edge weight in a connected planar graph this approach ha several advantage over prior approach to image segmentation first it allows cut with both open and closed boundary second it guarantee that the partition are connected third the cost function doe not introduce an explicit bias such a a preference for large area foreground smooth or short boundary or similar weight partition this lack of bias allows it to produce segmentation that are better aligned with image edge even in the presence of long thin region finally the global minimum of this cost function is largely insensitive to the precise choice of edge weight function in particular we show that the global minimum is invariant under a linear transformation of the edge weight and thus insensitive to image contrast building on algorithm by ahuja magnanti and orlin we present a polynomial time algorithm for finding a global minimum of the mean cut cost function and illustrate the result of applying that algorithm to several synthetic and real image 
we present a practical vision based calibration system for large format multi projector display a spanning tree of homographies automatically constructed from several camera image accurately register arbitrarily mounted projector to a global reference frame experiment on the princeton display wall a projector array with resolution demonstrate that our algorithm achieves sub pixel accuracy even on large display surface a direct comparison with the previous best 
similarity between image in image retrieval is measured by computing distance between feature vector this paper present a probabilistic approach and describes two likelihood based similarity measure for image retrieval popular distance measure like the euclidean distance implicitly assign more weighting to feature with large range s than those with small range first we discus the effect of five feature normalization method on retrieval per formance then we show that the probabilistic method perform significantly better than geometric approach lik e the nearest neighbor rule with city block or euclidean distance they are also more robust to normalization effect and using better model for the feature improves the retrieval result compared to making only general assumption experiment on a database of approximately image show that studying the feature distribution are important and this information should be used in designing feature normalization method and similarity measure 
in this paper we present an example based facial sketch system our system automatically generates a sketch from an input image by learning from example sketch drawn with a particular style by an artist there are two key element in our system a non parametric sampling method and a flexible sketch model given an input image pixel and it neighborhood the conditional distribution of a sketch point is computed by querying the example and finding all similar neighborhood an expected sketch image is then drawn from the distribution to reflect the drawing style finally facial sketch are obtained by incorporating the sketch model experimental result demonstrate the effectiveness of our technique 
blob tracker have become increasingly powerful in recent year largely due to the adoption of statistical appearance model which allow effective background subtraction and robust tracking of deforming foreground object it ha been standard however to treat background and foreground modelling a separate process background subtraction is followed by blob detection and tracking which prevents a principled computation of image likelihood this paper present two theoretical advance which address this limitation and lead to a robust multiple person tracking system suitable for single camera real time surveillance application the first innovation is a multi blob likelihood function which assigns directly comparable likelihood to hypothesis containing different number of object this likelihood function ha a rigorous mathematical basis it is adapted from the theory of bayesian correlation but us the assumption of a static camera to create a more specific background model while retaining a unified approach to background and foreground modelling second we introduce a bayesian filter for tracking multiple object when the number of object present is unknown and varies over time we show how a particle filter can be used to perform joint inference on both the number of object present and their configuration finally we demonstrate that our system run comfortably in real time on a modest workstation when the number of blob in the scene is small 
we describe an effective and novel approach to infer sign and direction of principal curvature at each input site from noisy d data unlike most previous approach no local surface fitting partial derivative computation of any kind nor oriented normal vector recovery is performed in our method these approach are noise sensitive since accurate local partial derivative information is often required which is usually unavailable from real data because of the unavoidable outlier noise inherent in many measurement phase also we can handle point with zero gaussian curvature uniformly i e without the need to localize and handle them first a a separate process our approach is based on tensor voting a unified salient structure inference process both the sign and the direction of principal curvature are inferred directly from the input each input is first transformed into a synthetic tensor a novel and robust approach based on tensor voting is proposed for curvature information estimation with faithfully inferred curvature information each input ellipsoid is aligned with curvature based dense tensor kernel to produce a dense tensor field surface and crease curve are extracted from this dense field by using an extremal feature extraction process the computation is non iterative doe not require initialization and robust to considerable amount of outlier noise a it effect is reduced by collecting a large number of tensor vote qualitative and quantitative result on synthetic a well a real and complex data are presented 
we describe the principle of building a moving vision platform a rig that once calibrated can thereon self adjust to change in it internal configuration and maintain an euclidean representation of the d world using only projective measurement we term this calibration paradigm omnirig we assume that after calibration the camera may change critical element of their configuration including internal parameter and center of projection theoretically we show that knowing only the rotation between a set of camera is sufficient for euclidean calibration even with varying internal parameter and unknown translation no other information of the world is required 
this paper address the problem of recovering d non rigid shape model from image sequence for example given a video recording of a talking person we would like to estimate a d model of the lip and the full head and it internal mode of variation many solution that recover d shape from d image sequence have been proposed these so called structure from motion technique usually assume that the d object is rigid for example tomasi and kanade s factorization technique is based on a rigid shape matrix which produce a tracking matrix of rank under orthographic projection we propose a novel technique based on a non rigid model where the d shape in each frame is a linear combination of a set of basis shape under this model the tracking matrix is of higher rank and can be factored in a three step process to yield to pose configuration and shape we demonstrate this simple but effective algorithm on video sequence of speaking people we were able to recover d non rigid facial model with high accuracy 
in this work we use point line and the linear extremal contour of cylinder to estimate the position and orientation of the camera in the world coordinate system other line basedpose estimation method use the correspondence between d line in space and d image line although the model and it observation are nite line segment we present a noise model describing the probabilistic relationship between d line and cylinder and their noisy observation the noise model take the 
abstract this paper present a novel approach for detection and segmentation of generic shape in cluttered image the underlying assumption is that generic object that are man made frequently have surface which closely resemble standard model shape such a rectangle semi circle etc due to the perspective transformation of optical imaging system a model shape may appear differently in the image with various orientation and aspect ratio the set of possible appearance can be represented compactly by a few vectorial eigenbases that are derived from a small set of model shape which are affine transformed in a wide parameter range instead of regular boundary of standard model we apply a vectorial boundary which improves robustness to noise background clutter and partial occlusion the detection of generic shape is realized by detecting local peak of a similarity measure between the image edge map and an eigenspace combined set of the appearance at each local maximum a fast search approach based on a novel representation by an angle space is employed to determine the best matching between model and the underlying subimage we findthat angular representation in multidimensional search corresponds better to euclidean distance than conventional projection and yield improved classification of noisy shape experiment are performed in various interfering distortion and robust detection and segmentation are achieved 
this paper considers a fundamental problem in visual motion perception namely the problem of egomotion estimation based on visual input many of the existing technique for solving this problem rely on restrictive assumption regarding the observer s motion or even the scene structure moreover they often resort to searching the high dimensional space of possible solution a strategy which might be inefficient in term of computational complexity and exhibit convergence problem if the search is initiated far away from the correct solution in this work a novel linear constraint that involves quantity that depend on the egomotion parameter is developed the constraint is defined in term of the optical flow vector pertaining to four collinear image point and is applicable regardless of the egomotion or the scene structure in addition it is exact in the sense that no approximation are made for deriving it combined with robust linear regression technique the constraint enables the recovery of the foe thereby decoupling the d motion parameter extensive simulation a well a experiment with real optical flow field provide evidence regarding the performance of the proposed method under varying noise level and camera motion 
in this work we approach the classic mumford shah problem from a curve evolution perspective in particular we let a given family of curve define the boundary between region in an image within which the data are modeled by piecewise smooth function plus noise a in the standard mumford shah functional the gradient descent equation of this functional is then used to evolve the curve each gradient descent step involves solving a corresponding optimal estimation problem which connects the mumford shah functional and our curve evolution implementation with the theory of boundary value stochastic process the resulting active contour model therefore inherits the attractive ability of the mumford shah technique to generate in a coupled manner both a smooth reconstruction of the image and a segmentation a well we demonstrate application of our method to problem in which data quality is spatially varying and to problem in which set of pixel measurement are missing finally we demonstrate a hierarchical implementation of our model which lead to a fast and efficient algorithm capable of dealing with important image feature such a triple point 
in this paper we present an algorithm for real time tracking of articulated structure in dense disparity map derived from stereo image sequence a statistical image formation model that account for occlusion play the central role in our tracking approach this graphical model a bayesian network assumes that the range image of each part of the structure is formed by drawing the depth candidate from a d gaussian distribution the advantage over the classical mixture of gaussians is that our model take into account occlusion by picking the minimum depth which could be regarded a a probabilistic version of z buffering the model also enforces articulation constraint among the part of the structure the tracking problem is formulated a an inference problem in the image formation model this model can be extended and used for other task in addition to the one described in the paper and can also be used for estimating probability distribution function instead of the ml estimate of the tracked parameter for the purpose of real time tracking we used certain approximation in the inference process which resulted in a real time two stage inference algorithm we were able to successfully track upper human body motion in real time and in the presence of self occlusion 
in this paper we consider the problem of color constancy how given an image of a scene under an unknown illuminant can we recover an estimate of that light rather than recovering a single estimate of the illuminant a many previous author have done in the first instance we recover a measure of the likelihood that each possible illuminant wa the scene illuminant we do this by correlating image color with the color that can occur under each of a set of possible light we then recover an estimate of the scene illuminant based on these likelihood computation is expressed and performed in a generic correlation framework which we develop in this paper we develop a new probabilistic instantiation of this framework which delivers very good color constancy on synthetic and real image we show that the proposed framework is rich enough to allow many existing algorithm to be expressed within it e g the grey world and gamut mapping algorithm we explore too the relationship of these algorithm to other probabilistic and neural network approach 
this paper present a new method for renderingviews especially those of large scale scene such asbroad city landscape the main contribution of ourmethod is that we are able to easily render any viewfrom an arbitrary point to an arbitrary direction on theground in a virtual environment our methodbelongsto the family of work that employ plenoptic function however unlike other work of this type this particularmethod allows u to render a novel view from almostany point on the 
in this paper we present an efficient hierarchical approach to structure from motion for long image sequence there are two key element to our approach accurate d reconstruction for each segment and efficient bundle adjustment for the whole sequence the image sequence is first divided into a number of segment so that feature point can be reliably tracked across each segment each segment ha a long baseline to ensure accurate d reconstruction to efficiently bundle adjust d structure from ail segment we reduce the number of frame in each segment by introducing virtual keyframes the virtual frame encode the d structure of each segment along with it uncertainty but they form a small subset of the original frame our method achieves significant speedup over conventional bundle adjustment method 
motion is one of the important visual cue for scene analysis it is particularly useful when the scene is cluttered such a in typical home or office environment we present a motion segmentation algorithm that make use of temporal differencing to detect moving people in cluttered indoor scene the algorithm is devised based on a couple of perceptual organization principle to deal with missing data noise and outlier a robust segmentation and grouping technique called tensor voting is employed the resulting real time people detector can handle the presence of multiple person and varying body size and pose it requires no initialization us subjective threshold which defines the minimum saliency of significant motion and the only two parameter are the scale size of the local neighborhood for region and contour analysis 
most lighting can be accurately modeled using a simplified planckian function if we form logarithm of color ratio of camera sensor value then in a lambertian plus specular two lobe model of reflection the temperaturedependent term is separate and is seen a a straight line i e changing lighting amount to changing each pixel value in a straight line for a given camera here we use a sensor camera in this case forming color ratio reduces the dimensionality to applying logarithm and projecting onto the plane in the d color space orthogonal to the lightchange direction result in an image representation that is invariant to illumination change for a given camera the position of the specular point in the d plane is always the same independent of the lighting thus a camera calibration produce illumination invariance at a single pixel in the plane matte surface reduce to point and specularities are almost straight line extending each pixel value back to the matte position postulated to be the maximum radius from the fixed specular point at any angle in the d plane remove specularity thus image are independent of shading by forming ratio independent of shadow by making them independent of illumination temperature and independent of specularities the method is examined by forming d image from hyperspectral image using real camera sensor with encouraging result 
this paper deal with the concept of auto calibration i e method to calibrate a camera on line in particular w e deal with minimal condition on the intrinsic parameter needed to make a euclidean reconstruction called flexible calibration the main theoretical result are that it is onl y needed to know that one intrinsic parameter is constant the method is based on an initial projective reconstruction which is upgraded to a euclidean one the number of image needed increase with the complexity of the constraint but the number of point needed is only the number needed in order to obtain a projective reconstruction the theoretical result are exemplified in a number of experiment an algorithm based on bundle adjustment and a linear initialization method are presented and experiment s are performed on both synthetic and real data 
we present an approach to appearance based objectrecognition using single camera image our approachis based on using an attention mechanism to obtain visualfeatures that are generic robust and informative the feature themselves are recognized using principalcomponents in the frequency domain in this paper we show how the visual characteristicsof only a small number of such feature can be usedfor appearance based object recognition that is not confoundedby planar rotation or 
reformulating the costeira kanade algorithm a a pure mathematical theorem independent of the tomasi kanade factorization we present a robust segmentation algorithm by incorporating such technique a dimension correction model selection using the geometric aic and least median fitting doing numerical simulation we demonstrate that our algorithm dramatically outperforms existing method it doe not involve any parameter which need to be adjusted empirically 
general sfm method give poor result for image captured by constrained motion such a planar motion of concentric mosaic cm in this paper we propose new sfm algorithm for both image captured by cm and composite mosaic image from cm we first introduce d affine camera model for completing d camera model then we show that a d image captured by cm can be decoupled into two d image one d projective and one d affine a composite mosaic image can by rebinned into a calibrated d panorama projective camera finally we describe subspace reconstruction method and demonstrate both in theory and experiment the advantage of the decomposition method over the general sfm method by incorporating the constrained motion into the earliest stage of motion analysis 
this paper introduces an extension of hartley s selfcalibration technique based on property of the essential matrix allowing for the stable computation of varying focal length and principal point it is well known that the three singular value of an essential must satisfy two condition one of them must be zero and the other two must be identical an essential matrix is obtained from the fundamental matrix by a transformation involving the intrinsic parameter of the pair of camera associated with the two view thus constraint on the essential matrix can be translated into constraint on the intrinsic parameter of the pair of camera this allows for a search in the space of intrinsic parameter of the camera in order to minimize a cost function related to the constraint this approach is shown to be simpler than other method with comparable accuracy in the result another advantage of the technique is that it doe not require a input a consistent set of weakly calibrated camera matrix a defined by hartley for the whole image sequence i e a set of camera consistent with the correspondence and known up to a projective transformation 
the object of this paper is to find a quick and accuratemethod for computing the projection matricesof an image sequence so that the error is distributedevenly along the sequence it assumes that a set of correspondencesbetween point in the image is known and that these point represent rigid point in theworld this paper extends the algebraic minimisationapproach developed by hartley so that it can be usedfor long image sequence this is achieved by initiallycomputing a trifocal 
given estimate of the motion field optic flow from an image sequence it is possible to recover translational direction t using a variety of technique one such technique known a subspace method generates constraint which are perpendicular to t so that two distinct constraint allow a solution for t in practice many constraint are used in a least square solution but it ha been observed that the recovered estimate for t are biased towards the optical axis while the cause of the bias is well known previous attempt to remove it have been awed this paper outline a new method which remove the bias the technique is simple to apply and computationally efficient 
we present a framework for d shape contour silhouette comparison that can account for stretching occlusion and region information topological change due to the original d scenario and articulation are also addressed to compare the degree of similarity between any two shape our approach is to represent each shape contour with a free tree structure derived from a shape axis sa model which we have recently proposed we then use a tree matching scheme to find the best approximate match and the matching cost to deal with articulation stretching and occlusion three local tree matching operation merge cut and merge and cut are introduced to yield optimally approximate match which can accommodate not only one to one but many to many mapping the optimization process give guaranteed globally optimal match efficiently experimental result on a variety of shape contour are provided 
this paper address the problem of estimating time to collision from focal motion field measurement in the case of unconstrained relative rigid motion and surface orientation it is first observed that a long a time to collision is regarded a a scaled depth the above problem doe not admit a solution unless a narrow camera field of view is assumed by a careful generalization of the time to collision concept it is then expounded how to compute novel solution which hold however wide the field of view the formulation which reduces to known literature approach in the narrow field of view case extends the applicability range of time to collision based technique in area such a mobile robotics and visual surveillance the experimental validation of the main theoretical result includes a comparison of narrowand wide field of view time to collision approach using both dense and sparse motion estimate 
this paper present a first investigation on the structure from motion problem from the combination of full and weak perspective image this problem arises in multiresolution object modeling where multiple zoomed in or close up view are combined with wider or distant reference view the narrow field of view fov image from the zoomed in or closeup view can be approximated a weak perspective projection using a full perspective projection model for the narrow fov image although more accurate actually lead to instability during the estimation process due to the non linearity in the imaging model the weak perspective approximation lead to more stable estimation algorithm although at the cost of a small amount of modeling inaccuracy previous work in structure from motion focused either on two or more perspective image or on a set of weak perspective more generally affine image the main contribution of this paper is the study of the sfm problem for the much neglected case of one perspective and one or more weak perspective image we show that in contrast to the case of a pair of weak perspective image there is adequate information to recover euclidean structure from a single perspective and a single weak perspective image the epipolar geometry is simpler than with two perspective image leading to simpler and more stable estimation algorithm computer simulation show that more stable result can be obtained with the technique presented in this paper than if two image are both considered to be full perspective 
we show that we can effectively and automatically fit a complex facial animation model to uncalibrated image sequence our approach is based on model driven bundleadjustment followed by least square fitting it take advantage of three complementary source of information stereo data silhouette edge and d feature point in this way complete head model can be acquired with a cheap and entirely passive sensor such a an ordinary video camera they can then be fed to existing animation software to produce synthetic sequence 
this paper present a control structure for general purpose image understanding that address both the high level of uncertainty in local hypothesis and the computational complexity of image interpretation the control of vision algorithm is performed by an independent subsystem that us bayesian network and utility theory to compute the marginal value of information provided by alternative operator and selects the one with the highest value we have implemented and tested this control structure with several aerial image data set the result show that the knowledge base used by the system can be acquired using standard learning technique and that the value driven approach to the selection of vision algorithm lead to performance gain moreover the modular system architecture simplifies the addition of both control knowledge and new vision algorithm 
we consider a problem central in aerial visual surveil lance application detection and tracking of small independently moving object in long and noisy video sequence we directly use spatiotemporal image inten sity gradient measurement to compute an exact model of background motion this allows the creation of ac curate mosaic over many frame and the de nition of a constraint violation function which act a an in dicator of independent motion a novel temporal in tegration method maintains con dence measure over long subsequence without computing the optic ow re quiring object model or using a kalman lter the mosaic act a a stable feature frame allowing pre cise localization of the independently moving object we present a statistical analysis of the e ect of image noise on the constraint violation measure and nd a good match between the predicted probability distribu tion function and the measured sample frequency in a test sequence 
we present an algorithm for identifying linear mixture of a specified set of material in m airborne imaging spectrometer data the algorithm is invariant to the illumination and atmospheric condition and the relative amount of the specified material within a pixel only the spectral reflectance function for the specified material are required by the algorithm invariance over illumination and atmosphere condition is achieved by incorporating a physical model for scene variability in the constrained optimization formulation the algorithm also computes estimate of the amount of the specified material in identified mixture we demonstrate the effectiveness of the algorithm using real and synthetic hydice imagery acquired over a range of condition and altitude 
a pulsed ladar based object recognition system with application to automatic target recognition atr is presented the approach used is to fit the sensed range image to range template extracted through a laser physic based simulation applied to geometric target model a projection based prescreener filter out more than of candidate template for recognition an m of n pixel matching scheme for internal shape matching is combined with a silhouette matching scheme the system wa trained on synthetic data obtained from the simulation and ha been blind tested on a data set containing real ladar image of military vehicle at various orientation and range successful blind testing on real imagery demonstrates the utility of synthetic imagery for training of recognizers operating on ladar imagery 
a new method is described for automatically reconstructing d planar face from multiple image of a scene the novelty of the approach lie in the use of inter image homographies to validate and best estimate the plane and in the minimal initialization requirement only a single d line with a textured neighbourhood is required to generate a plane hypothesis the planar facet enable line grouping and also the construction of part of the wireframe which were missed due to the inevitable shortcoming of feature detection and matching the method allows a piecewise planar model of a scene to be built completely automatically with no user intervention at any stage given only the image and camera projection matrix a input the robustness and reliability of the method are illustrated on several example from both aerial and interior view 
in this paper we present an object recognition framework integrating several recognition paradigm and context information from the scene history to recognize elementary part contained in assembly we use a symbolic approach to detect action based on the object change in the scene to monitor the construction process the information about the element used to construct a new assembly serf a additional source of information for recognition process knowledge is exploited also for selecting the best interpre tation out of several alternative for a single scene which result from contradiction and uncertainty during integ ration of the different cue 
a new method for computing precise depth map estimate of d shape of a moving object is proposed d shape recovery in motion stereo is formulated a a matching optimization problem of multiple stereo image the proposed method is a heuristic modification of dynamic programming applied to two dimensional optimization problem d shape recovery using real motion stereo image demonstrates a good performance of the algorithm in term of reconstruction accuracy 
signature can be acquired with a camera basedsystem with enough resolution to perform verification this paper present the performance of avisual acquisition signature verification system emphasizingon the importance of the parameterizationof the signature in order to achieve good classificationresults a technique to overcome the lack ofexamples in order to estimate the generalization errorof the algorithm is also described introduction and motivationone of the research area 
the use of the human hand a a natural interface device serf a a motivating force for research in the modeling analysis and capture of the motion of an articulated hand model based hand motion capture can be formulated a a large nonlinear programming problem but this approach is plagued by local minimum an alternative way is to use analysis by synthesis by searching a huge space but the result are rough and the computation expensive in this paper articulated hand motion is decoupled a new two step iterative model based algorithm is proposed to capture articulated human hand motion and a proof of convergence of this iterative algorithm is also given in our proposed work the decoupled global hand motion and local finger motion are parameterized by the d hand pose and the state of the hand respectively hand pose determination is formulated a a least median of square lm problem rather than the nonrobust least square l problem so that d hand pose can be reliably calculated even if there are outlier local finger motion is formulated a an inverse kinematics problem a genetic algorithm based method is proposed to find a sub optimal solution of the inverse kinematics effectively our algorithm and the l based algorithm are compared in several experiment both algorithm converge when local finger motion between consecutive frame is small when large finger motion is present the l based method fails but our algorithm can still estimate the global and local finger motion well 
image based and model based method are two representative rendering method for generating virtual image of object from their real image extensive research on these two method ha been made in cv and cg community however both method still have several drawback when it come to applying them to the mixed reality where we integrate such virtual image with real background image to overcome these difficulty we propose a new method which we refer to a the eigen texture method the proposed method sample appearance of a real object under various illumination and viewing condition and compress them in the d coordinate system defined on the d model surface the d model is generated from a sequence of range image the eigen texture method is practical because it doe not require any detailed reflectance analysis of the object surface and ha great advantage due to the accurate d geometric model this paper describes the method and report on it implementation 
in this paper we derive a probabilistic model for recognition based on local descriptor and spatial relation between these descriptor our model take into account the variability of local descriptor their saliency a well a the probability of spatial configuration it is structured to clearly separate the probability of point wise correspondence from the spatial coherence of set of correspondence for each descriptor of the query image several correspondence in the image database 
human have an innate ability to perceive symmetry but it is not obvious how to automatethis powerful insight in this paper the mathematical theory of frieze and wallpaper group isused to extract visually meaningful building block motif from a repeated pattern a novelpeak detection algorithm based on quot region of dominance quot is used to automatically detect theunderlying translational lattice of a repeated pattern following automatic classification of thepattern s symmetry group 
the core experiment ce shape for shape descriptor performed for the mpeg standard gave a unique opportunity to compare various shape descriptor for non rigid shape with a single closed contour there are two main difference with respect to other comparison result reported in the literature for each shape descriptor the experiment were carried out by an institute that is in favor of this descriptor this implies that the parameter for each system were optimally determined and the implementation were throughly tested it wa possible to compare the performance of shape descriptor based on totally different mathematical approach a more theoretical comparison of these descriptor seems to be extremely hard in this paper we report on the mpeg core experiment ce shape 
in proc of ieee int l conf on computer vision vancouver canada visual tracking could be treated a a parameter estimation problem of target representation based on observation in image sequence a richer target representation would incur better chance of successful tracking in cluttered and dynamic environment however the dimensionality of target s state space also increase making tracking a formidable estimation problem in this paper the problem of tracking and integrating multiple cue is formulated in a probabilistic framework and represented by a factorized graphical model structured variational analysis of such graphical model factorizes different modality and suggests a co inference process among these modality a sequential monte carlo algorithm is proposed to give an efficient approximation of the co inference based on the importance sampling technique this algorithm is implemented in real time at around hz specifically tracking both position shape and color distribution of a target is investigated in this paper our extensive experiment show that the proposed algorithm performs robustly in a large variety of tracking scenario the approach presented in this paper ha the potential to solve other sensor fusion problem 
many parameter estimation method used in computer vision are able to utilise covariance information describing the uncertainty of data measurement this paper considers the value of this information to the estimation process when applied to measured image point location covariance matrix are first described and a procedure is then outlined whereby covariance may be associated with image feature located via a measurement process an empirical study is made of the condition under which covariance information enables generation of improved parameter estimate also explored is the extent to which the noise should be anisotropic and inhomogeneous if improvement are to be obtained over covariance free method critical in this is the devising of synthetic experiment under which noise condition can be precisely controlled given that covariance information is in itself subject to estimation error test are also undertaken to determine the impact of imprecise covariance information upon the quality of parameter estimate finally an experiment is carried out to ass the value of covariance in estimating the fundamental matrix from real image 
full panoramic image covering degree can be created either by using panoramic camera or by mosaicing together many regular image creating panoramic view in stereo where one panorama is generated for the left eye and another panorama is generated for the right eye is more problematic earlier attempt to mosaic image from a rotating pair of stereo camera faced severe problem of parallax and of scale change a new family of multiple viewpoint image projection the circular projection is developed two panoramic image taken using such projection can serve a a panoramic stereo pair a system is described to generates a stereo panoramic image using circular projection from image or video taken by asingle rotating camera the system work in real time on a pc it should be noted that the stereo image are created without computation of d structure and the depth effect are created only in the viewer s brain 
in an immersive tele presence environment a d remote real scene is projected from the viewpoint of the local user this d world is acquired through stereo reconstruction at the remote site in this paper we start a performance analysis of stereo algorithm with respect to the task of immersive visualization a opposed to usual monocular image based rendering we are also interested in the depth error in novel view because our rendering is stereoscopic we describe an evaluation test bed which provides a world wide first available set of registered dense ground truth laser data and image data from multiple view we establish metric for novel depth view that reflect discrepancy both in the image and in d space it is well known that stereo performance is affected by both erroneous matching a well a incorrect depth triangulation we experimentally study the effect of occlusion and low texture on the distribution of the error metric then we algebraically predict the behavior of depth and novel projection error a a function of the camera set up and the error in the disparity these are first step towards building a laboratory for psychophysical judgement of depth estimate which is the ultimate performance test of tele presence stereo 
image taken with wide angle camera tend to have severe distortion which pull point towards the optical center this paper proposes a method for recovering the disrortion parameter without the use of any calibration object the distortion cause straight line in the scene to appear a curve in the image our algorithm seek tojind the distortion parameter that would map the image curve to straight line the user selects a small set of point along the image curve recovery of the parameter is formulated a the minimization of an objective function which is designed to explicitly account for noise in the selected image point experimental result are presented for synthetic data with difserent noise level a well a for real image once calibrated the image stream from these camera can be undistorted in real time using look up table we also present an application of this calibration method for wide angle camera cluster which we call polycameras we apply our distortion correction technique to a polycamera with four wide angle camera to create a high resolution degree panorama in real time 
particle filter are used for hidden state estimation with nonlinear dynamical system the inference of d human motion is a natural application given the nonlinear dynamic of the body and the nonlinear relation between state and image observation however the application of particle filter ha been limited to case where the number of state variable is relatively small because the number of sample needed with high dimensional problem can be prohibitive we describe a filter that us hybrid monte carlo hmc to obtain sample in high dimensional space it us multiple markov chain that use posterior gradient to rapidly explore the state space yielding fair sample from the posterior we find that the hmc filter is several thousand time faster than a conventional particle filter on a d people tracking problem 
we present a system to detect passenger car in aerial image where car appear a small object we pose this a a d object recognition problem to account for the variation in viewpoint and the shadow we started from psychological test to find important feature for human detection of car based on these observation we selected the boundary of the car body the boundary of the front windshield and the shadow a the feature some of these feature are affected by the intensity of the car and whether or not there is a shadow along it this information is represented in the structure of the bayesian network that we use to integrate all feature experiment show very promising result even on some very challenging image 
this paper present an algorithmic approach to the problem of detecting independently moving object in d scene that are viewed under camera motion there are two fundamental constraint that can be exploited for the problem two multiview camera motion constraint for instance the epipolar trilinear constraint and shape constancy constraint previous approach to the problem either use only partial constraint or rely on dense correspondence or flow we employ both the fundamental constraint in an algorithm that doe not demand a priori availability of correspondence or flow our approach us the plane plus parallax decomposition to enforce the two constraint it is also demonstrated that for a class of scene called sparse d scene in which genuine parallax and independent motion may be confounded how the plane plus parallax decomposition allows progressive introduction and verification of the fundamental constraint result of the algorithm on some difficult sparse d scene are promising 
the human figure exhibit complex and rich dynamic behavior that is both nonlinear and time varying however most work on tracking and synthesizing figure motion ha employed either simple generic dynamic model or highly specific hand tailored one recently a broad class of learning and inference algorithm for time series model have been successfully cast in the framework of dynamic bayesian network dbns this paper describes a novel dbn based switching linear dynamic system slds model and present it application to figure motion analysis a key feature of our approach is an approximate viterbi inference technique for overcoming the intractability of exact inference in mixed state dbns we present experimental result for learning figure dynamic from video data and show promising initial result for tracking interpolation synthesis and classification using learned model 
background subtraction is a method typically used to segment moving region in image sequence taken from a static camera by comparing each new frame to a model of the scene background we present a novel non parametric background model and a background subtraction approach the model can handle situation where the background of the scene is cluttered and not completely static but contains small motion such a tree branch and bush the model estimate the probability of observing pixel intensity value based on a sample of intensity value for each pixel the model adapts quickly to change in the scene which enables very sensitive detection of moving target we also show how the model can use color information to suppress detection of shadow the implementation of the model run in real time for both gray level and color imagery evaluation show that this approach achieves very sensitive detection with very low false alarm rate 
a method to compute motion model in real time from point to line correspondence using linear programming is presented point to line correspondence are the most reliable motion measurement given the aperture effect and it is shown how they can approximate other motion measurement a well using an l error measure for image alignment based on point to line correspondence and minimizing this measure using linear programming achieves result which are more robust than the commonly used l metric while estimator based on l are not theoretically robust experiment show that the proposed method is robust enough to allow accurate motion recovery in hundred of consecutive frame the entire computation is performed in real time on a pc with no special hardware 
large calibrated datasets of random natural image have recently become available these make possible precise and intensive statistical study of the local nature of image we report result ranging from the simplest single pixel intensity to joint distribution of haar wavelet response some of these statistic shed light on old issue such a the near scale invariance of image statistic and some are entirely new we fit mathematical model to some of the statistic and explain others in term of local image feature 
this paper introduces a method to calibrate a wide area system of unsynchronized camera with respect to a single global coordinate system the method is simple and doe not require the physical construction of a large calibration object the user need only wave an identifiable point i n front of all camera the method generates a rough estimate of camera po se by first performing pa ir wise structure from motion on observed point and then combining the pair wise registration into a single c oordinate frame using the initial camera pose the moving point can be tracked in world space the path o f t he point defines a virtual calibration ob ject which can b e used to improve the initial estimate of camera po se iterating the above process yield a more precise estimate of both camera pose and the point path experimental result s how that it performs a well a calibration from a ph ysical t arget in case where all camera s hare some c ommon working volume we then demonstrate it effectiveness in wide area setting by calibrating a system of camera in a configuration where traditional method cannot be applied directly 
recovering the projection geometry of an x ray system or an augmented reality video see through head mounted display hmd are mathematically quite similar recent work in both medical imaging and augmented reality use external optical sensor in order to recover the motion of the imaging system in this paper we take the example of the recovery of an x ray projection geometry we show that the mathematical problem which need to be solved is equivalent to the hand eye calibration well studied in both computer vision and robotics community we present a comparative study for the recovery of the motion and therefore projection geometry using ve dierent hand eye calibration method proposed in the literature we compare the motion estimation result using expensive external stereo based tracking system with one obtained by using an integrated optical camera the paper concludes by showing that even if the motion estimation is more accurate when using an external sensor the projection geometry is better estimated by the integrated optical camera these result are of crucial importance to both medical imaging and augmented reality community 
we use well established result in biological vision to construct a novel vision model for handwritten digit recognition we show empirically that the feature extracted by our model are linearly separable over a large training set mnist using only a linear classifier on these feature our model is relatively simple yet outperforms other model on the same data set 
condensation is a popular algorithm for sequential inference that resamples a sampled representation of the posterior the algorithm is known to be asymptotically correct a the number of sample tends to infinity however the resampling phase involves a loss of information the sequence of representation produced by the algorithm is a markov chain which is usually inhomogeneous we show simple discrete example where this chain is homogeneous and ha absorbing state in these example the representation move to one of these state in time apparently linear in the number of sample and remains there this phenomenon appears in the continuous case a well where the algorithm tends to produce clumpy representation in practice this mean that different run of a tracker on the same data can give very different answer while a particular run of the tracker will look stable furthermore the state of the tracker can collapse to a single peak which ha non zero probability of being the wrong peak within time linear in the number of sample and the tracker can appear to be following tight peak in the posterior even in the absence of any meaningful measurement this mean that if theoretical lower bound on the number of sample are not available experiment must be very carefully designed to avoid these effect 
a fundamental unsolved vision problem is to distinguish image intensity variation caused by surface normal variation from those caused by reflectance change ie to tell shading from paint a solution to this problem is necessary for machine to interpret image a people do and could have many application the labelling allows u to reconstruct bandpassed image containing only those part of the input image caused by shading effect and a separate image containing only those part caused by reflectance change the resulting classification compare well with human psychophysical performance on a test set of image and show good result for test photograph 
we formulate stereo matching a an extremal surface extraction problem this is made possible by embedding the disparity surface inside a volume where the surface is composed of voxels with locally maximal similarity value this formulation naturally implement the coherence principle and allows u to incorporate most known global constraint time efficiency is achieved by executing the algorithm in a coarse to fine fashion and only populating the full volume at the coarsest level to make the system more practical we present a rectification algorithm based on the fundamental matrix avoiding full camera calibration we present result on standard stereo pair and on our own data set the result are qualitatively evaluated in term of both the generated disparity map and the d model 
we propose a method of image segmentation by integrating pairwise attraction and directional repulsion derived from local grouping and figure ground cue these two kind of pairwise relationship are encoded in the real and imaginary part of an hermitian graph weight matrix through which we can directly generalize the normalized cut criterion with bi graph construction this method can be readily extended to handle nondirectional repulsion that capture dissimilarity we demonstrate the use of repulsion in image segmentation with relative depth cue which allows segmentation and figure ground segregation to be computed simultaneously a a general mechanism to represent the dual measure of attraction and repulsion this method can also be employed to solve other constraint satisfaction and optimization problem 
creating novel view by interpolating prestored image or view morphing ha many application in visual simulation we present in this paper a new method of automatically interpolating two image which tackle two most difficult problem of morphing due to the lack of depth information pixel matching and visibility handling we first describe a quasi dense matching algorithm based on region growing with the best first strategy for match propagation then we describe a robust construction of matched planar patch using local geometric constraint encoded by a homography after that we introduce a novel representation joint view triangulation for visible and half occluded patch in two image to handle their visibility during the creation of new view finally we demonstrate these technique on real image pair 
our goal is to exploit human motion and object context to perform action recognition and object classification towards this end we introduce a framework for recognizing action and object by measuring image objectand action based information from video hidden markov model are combined with object context to classify hand action which are aggregated by a bayesian classifier to summarize activity we also use bayesian method to differentiate the class of unknown object by evaluating detected action along with lowlevel extracted object feature our approach is appropriate for locating and classifying object under a variety of condition including full occlusion we show experiment where both familiar and previously unseen object are recognized using action and context information this paper proposes a novel approach to human activity recognition that us context information of particular object in the scene we define class that contain object specific information including associated property appearance based description and action object provide a mean to focus attention on an individual interaction while maintaining awareness of other interaction in the scene by tracking hand contact with known object is detected once contact ha been established context is used to suggest specific hidden markov model hmms if any that may provide more explicit description of action associated with the object interaction captured over time are aggregated using bayesian statistic producing summary of activity additionally we show that the relationship between human action and object can be exploited to detect and classify object object classification is inferred in part by detecting learned action prior knowledge about object category and image analysis provides additional discrimination 
this paper extends the recovery of structure and motion to image sequence with several independently moving object the motion structure and camera calibration are all a priori unknown the fundamental constraint that we introduce is that multiple motion must share the same camera parameter existing work on independent motion ha not employed this constraint and therefore ha not gained over independent static scene reconstruction we show how this constraint lead to several new result in structure and motion recovery where euclidean reconstruction becomes possible in the multibody case when it wa underconstrained for a static scene we show how to combine motion of high relief low relief and planar object additionally we show that structure and motion can be recovered from just point in the uncalibrated fixed camera case experiment on real and synthetic imagery demonstrate the validity of the theory and the improvement in accuracy obtained using multibody analysis 
in d object detection and recognition an object of interest is subject to change in view a well a in illumination and shape for image classification purpose it is desirable to derive a representation in which intrinsic characteristic of the object are captured in a low dimensional space while effect due to artifact are reduced in this paper we propose a method for view based unsupervised learning of object appearance first view subspace are learned from a view unlabeled data set of multi view appearance using independent subspace analysis isa a learned viewsubspace provides a representation of appearance at that view regardless of illumination effect a measure called view subspace activity is calculated thereby to provide a metric for view based classification view based clustering is then performed by using maximum view subspace activity mvsa criterion this work is to the best of our knowledge the first devoted research on view based clustering of image 
we present a novel approach to real time structured light range scanning after an analysis of the underlying assumption of existing structured light technique we derive a new set of illumination pattern based on coding the boundary between projected stripe these stripe boundary code allow range scanning of moving object with only modest assumption about scene continuity and reflectance we describe an implementation that integrates these new code with real time algorithm for tracking stripe boundary and determining depth our system us a standard video camera and dlp projector and produce dense range image at hz with m accuracy over a cm working volume a an application we demonstrate the creation of complete model of rigid object the object are rotated in front of the scanner by hand and successive range image are automatically aligned 
previous algorithm that recover camera motion from image velocity suffer from both bias and excessive variance in the result we propose a robust estimator of camera motion that is statistically consistent when image noise is isotropic consistency mean that the estimated motion converges in probability to the true value a the number of image point increase an algorithm based on reweighted gauss newton iteration handle velocity measurement in about millisecond on a workstation 
this paper study the structural sensitivity of line pattern recognition using shape graph we compare the recognition performance for four different algorithm each algorithm us a set of pair wise geometric attribute and a neighborhood graph to represent the structure of the line pattern the first algorithm us a pair wise geometric histogram the second us a relational histogram on the edge of the shape graph the third compare the set of attribute on the edge of the shape graph and the final algorithm compare the arrangement of line correspondence using graph matching the different algorithm are compared under line deletion line addition line fragmentation and line end point measurement error it is the graph matching algorithm which prof to be the most effective 
this paper present a new geometric relation between a solid bounded by a smooth surface and it silhouette in image formed under weak perspective projection the relation ha the potential to be used for recognizing complex d object from a single image object are modeled by showing them to a camera without any knowledge of their motion the main idea is to consider the dual of the d surface and the family of dual curve of the silhouette over all viewing direction occluding contour correspond to planar slice of the dual surface we introduce an affine invariant representation of this surface that can constructed from a sequence of image and allows an object to be recognized from arbitrary viewing direction we illustrate the proposed object representation scheme through synthetic example and image contour detected in real image 
this paper present a mathematical framework for visual learning that integrates two popular statistical learning paradigm in the literature i descriptive learning such a markov random field and minimax entropy learning and ii generative learning such a pca ica tca image coding and hmm we apply this integrated learning framework to texton modeling and we assume that an observed texture image is generated by multiple layer of hidden stochastic texton process with each texton being a window function like a mini template or a wavelet under affine transformation the spatial arrangement of the textons are characterized by minimax entropy model the texton process generate image by occlusion or linear addition thus given a raw input image the learning framework achieves four goal i computing the appearance of the textons ii inferring the hidden stochastic texton process iii learning gibbs model for each texton process and iv verifying the learnt textons and gibbs model through random sampling and texture synthesis the integrated framework subsumes the minimax entropy learning paradigm and creates a richer class of probability model for visual pattern which are suited for middle level vision representation furthermore we show that the integration of description and generative method yield a natural and general framework of visual learning we demonstrate the proposed framework and algorithm on many real image 
we describe preliminary result on combining depth information from a laser range nder and color and texture image cue to train classiers to segment illstructured dirt gravel and asphalt road a input to an autonomous road following system a large number of registered laser and camera image were captured at frame rate on a variety of rural road allowing laser feature such a d height and smoothness to be correlated with image feature such color histogram and gabor lter response a small set of road model were generated by training separate neural network on labeled feature vector clustered by road type by rst classifying the type of a novel road image an appropriate second stage classier wa selected to segment individual pixel achieving a high degree of accuracy on arbitrary image from the dataset 
this paper proposes a novel pattern classification approach called the nearest linear combination nlc approach for eigenface based face recognition assume that multiple prototypical vector are available per class each vector being a point in an eigenface space a linear combination of prototypical vector belonging to a face class is used to define a measure of distance from the query vector to the class the measure being defined a the euclidean distance from the query to the linear combination nearest to the query vector hence nlc this contrast to the nearest neighbor nn classification where a query vector is compared with each prototypical vector individually using a linear combination of prototypical vector instead of each of them individually extends the representational capacity of the prototype by generalization through interpolation and extrapolation experiment show that it lead to better result than existing classification method 
this paper examines the problem of image retrieval from large heterogeneous image database we present a technique that fulfills several need identified by surveying recent research in the field this technique fairly integrates a diverse and expandable set of image property for example color texture and location in a retrieval framework and allows end user substantial control over their use we propose a novel set of evaluation method in addition to applying established test for image retrieval our technique prof competitive with state of the art method in these test and doe better on certain task furthermore it improves on many standard image retrieval algorithm by supporting query based on subsection of image for certain query this capability significantly increase the relevance of the image retrieved and further expands the user s control over the retrieval process 
zebra crossing are useful road feature for outdoor navigation in mobility aid for the partially sighted in this paper zebra crossing are detected by looking for group of concurrent line edge are then partitioned using intensity variation information in order to tackle the ambiguity of the detection algorithm in distinguishing zebra crossing and stair case pose information is sought three method are developed to estimate the pose homography search approach using an a priori model nding normal using the vanishing line computed from equally spaced line and with two vanishing point these algorithm have been applied to real image with promising result and they are also useful in some other shape from texture application 
a motion segmentation algorithm based on factorization method and discriminant criterion is proposed this method us a feature with the most useful similarity for grouping selected using motion information calculated by factorization method and discriminant criterion a group is extracted based on discriminant analysis for the selected feature s similarity the same procedure is applied recursively to the remaining feature to extract other group this grouping is robust against noise and outlier because feature with no useful information are automatically rejected numerical computation is simple and stable no prior knowledge is needed on the number of object experimental result are shown for synthetic data and real image sequence 
the image of an object can vary dramatically depending on lighting specularities reflection and shadow it is often advantageous to separate these incidental variation from the intrinsic aspect of an image this paper describes how the statistical tool of independent component analysis can be used to separate some of these incidental component we describe the detail of this method and show it efficacy with example of separating reflection off glass and separating the relative contribution of individual light source 
this paper present an efficient shape based object detectionmethod based on distance transforms and describesits use for real time vision on board vehicle the method us a template hierarchy to capture thevariety of object shape efficient hierarchy can begenerated offline for given shape distribution usingstochastic optimization technique i e simulated annealing online matching involves a simultaneouscoarse to fine approach over the shape hierarchy andover the 
this paper present an approach for establishing correspondence in time and in space between two different video sequence of the same dynamic scene recorded by stationary uncalibrated video camera the method simultaneously estimate both spatial alignment a well a temporal synchronization temporal alignment between the two sequence using all available spatio temporal information temporal variation between image frame such a moving object or change in scene illumination are powerful cue for alignment which cannot be exploited by standard image to image alignment technique we show that by folding spatial and temporal cue into a single alignment framework situation which are inherently ambiguous for traditional image to image alignment method are often uniquely resolved by sequence to sequence alignment we also present a direct method for sequence tosequence alignment the algorithm simultaneously estimate spatial and temporal alignment parameter directly from measurable sequence quantity without requiring prior estimation of point correspondence frame correspondence or moving object detection result are shown on real image sequence taken by multiple video camera 
in this paper we study how to compute a dense depth map with panoramic field of view e g degree from multiperspective panorama a dense sequence of multiperspective panorama is used for better accuracy and reduced ambiguity by taking advantage of significant data redundancy to speed up the reconstruction we derive an approximate epipolar plane image that is associated with the planar sweeping camera setup and use one dimensional window for efficient matching to address the aperture problem introduced by one dimensional window matching we keep a set of possible depth candidate from matching score these candidate are then passed to a novel two pas tensor voting scheme to select the optimal depth by propagating the continuity and uniqueness constraint noniteratively in the voting process our method produce highquality reconstruction result even when significant occlusion is present experiment on challenging synthetic and real scene demonstrate the effectiveness and efficacy of our method 
application that interpret video data need to track object a they move in a scene tracking method that estimate the state trajectory of object a they change over time e g kalman filter have difficulty a the number of object and clutter increase we present an alternative call ed statistical tracking that is based on the concept of network tomography a scene is modeled a a network of interconnected region statistical tracking estimate the number of trip made from one region to another based on interregion boundary traffic count accumulated over time it is not necessary to track an object through a scene just to determine when an object cross a boundary something that is generally easier than estimating a continuous traje ctory in achieving this simplicity statistical tracking g ives up the ability to determine an object s state a the motion occurs instead it determines mean traffic intensity based on statistic accumulated over a period of time in spite of this limitation there are several application for whic h statistical tracking is useful we demonstrate the applica tion of the method to a large sample of video traffic surveillance data the method doe not require any data association which ha some important implication concerning personal privacy 
this paper address the derivation of likelihood function and confidence bound for problem involving overdetermined linear system with noise in all measurement often referred to a total least square tl it ha been shown previously that tl provides maximum likelihood estimate but rather than being a function solely of the variable of interest the associated likelihood function increase in dimensionality with the number of equation this ha made it difficult to derive suitable confidence bound and impractical to use these probability function with bayesian belief propagation or bayesian tracking this paper derives likelihood function that are defined only on the parameter of interest this ha two main advantage first the likelihood function are much easier to use within a bayesian framework and second it is straightforward to obtain a reliable confidence bound on the estimate we demonstrate the accuracy of our confidence bound in relation to others that have been proposed also we use our theoretical result to obtain likelihood function for estimating the direction of d camera translation 
automatic grouping and segmentation of image remains a challenging problem in computer vision recently a number of author have demonstrated good performance on this task using method that are based on eigenvectors of the affinity matrix these approach are extremely attractive in that they are based on simple eigen decomposition algorithm whose stability is well understood nevertheless the use of eigen decomposition in the context of segmentation is far from well understood in this paper we give a unified treatment of these algorithm and show the close connection between them while highlighting their distinguishing feature we then prove result on eigenvectors of block matrix that allow u to analyze the performance of these algorithm in simple grouping setting finally we use our analysis to motivate a variation on the existing method that combine aspect from different eigenvector segmentation algorithm we illustrate our analysis with result on real and synthetic image 
a method for reliably detecting change in the d shape of object that are well modeled a single value function zf x y is presented it us an estimate of the accuracy of the d model derived from a set of image taken simultaneously this accuracy estimate is used to distinguish between significant and insignificant change in d model derived from different image set the accuracy of the d model is estimated using a general methodology called self consistency for estimating the accuracy of computer vision algorithm which doe not require prior establishment of ground truth a novel image matching measure based on minimum description length mdl theory allows u to estimate the accuracy of individual element of the d model experiment to demonstrate the utility of the procedure are presented 
this paper proposes a new front propagation method to deal accurately with the challenging problem of tracking non rigid moving object this is obtained by employing a geodesic active region model where the designed objective function is composed of boundary and region based term and optimizes the curve position with respect to motion and intensity property the main novelty of our approach is that we deal with the motion estimation linear model are assumed and the tracking problem simultaneously in other word the optimization problem contains a coupled set of unknown variable the curve position and the corresponding motion model the designed objective function is minimized using a gradient descent method the curve is propagated towards the object boundary under the influence of boundary intensity and motion based force using a pde while given the curve position an incremental analytical solution is obtained for the motion model besides this pde is implemented using a level set approachwhere topological change are naturally handled very promising experimental result are provided using real video sequence 
we consider the problem of wrapping around an object of which two view are available a reference surface and recovering the resulting parametric flow using direct computation via spatio temporal derivative the well known example are affine flow model and parameter flow model both describing a flow field of a planar reference surface we extend those classic flow model to deal with a quadric reference surface and work out the explicit parametric form of the flow field a a result we derive a simple warping algorithm that map between two view and leaf a residual flow proportional to the d deviation of the surface from a virtual quadric surface the application include image morphing model building image stabilization and disparate view correspondence 
in this paper we present a new bayesian framework for partially occluded object recognition with one to one correspondence we introduce two different statistical model for occlusion one model assumes that each feature in the model can be occluded independent of whether any other feature are occluded whereas the second model us spatially correlated occlusion to represent the extent of occlusion using these model the object recognition problem reduces to finding the object hypothesis with largest generalized likelihood we develop fast algorithm for finding the optimal one to one correspondence between scene feature and object model feature to compute the generalized likelihood we evaluate our algorithm using example extracted from synthetic aperture radar imagery and illustrate the performance advantage of our approach over alternative algorithm proposed by others 
this paper present a novel recognition framework which is based on matching shock graph of d shape outline where the distance between two shape is defined to be the cost of the least action path deforming one shape to another three key idea render the implementation of this framework practical first the shape space is partitioned by defining an equivalence class on shape where two shape with the same shock graph topology are considered to be equivalent second the space of deformation is discretiz ed by defining all deformation with the same sequence of shock graph transition a equivalent shock transition a re point along the deformation where the shock graph topology change third we employ a graph edit distance algorithm that search in the space of all possible transitio n sequence and find the globally optimal sequence in polynomial time the effectiveness of the proposed technique in the presence of a variety of visual transformation including occlusion articulation and deformation of part shadow and highlight viewpoint variation and boundary perturbation is demonstrated indexing into two separate database of roughly shape result in accuracy for top three match and for the next three match 
this paper present an algorithm for constructing object representation suitable for recognition the system automatically selects a representative subset of the view of the object while constructing the eigenspace basis these view are actively located for object identification and pose determination all processing is performed on line the camera is actively positioned during both representation and recognition when tested with view for each of seven object the system achieves accurate object recognition and pose determination these result are shown to degrade gracefully a condition deteriorate 
we present a new technique that improves upon existing structure from motion sfm method we propose a sfm algorithm that is both recursive and optimal our method incorporates innovative information from new frame into an existing solution without optimizing every camera pose and scene structure parameter to do this we incrementally optimize larger subset of parameter until the error is minimized these additional parameter are included in the optimization by tracing connection between point and frame in many case the complexity of adding a frame is much smaller than full bundle adjustment of all the parameter our algorithm is best described a incremental bundle adjustment a it allows new information to be added to an existing non linear least square solution 
many modeling task in computer vision e g structure from motion shape reflectance from shading filter synthesis have a low dimensional intrinsicstructure even though the dimension of the input datacan be relatively large we propose a simple but surprisinglyeffective iterative randomized algorithm thatdrastically cut down the time required for recoveringthe intrinsic structure the computational cost dependsonly on the intrinsic dimension of the structureof the task it is based on 
a simple algorithm for tracking the pose of articulated object in real time range image sequence is proposed this method model each target segment a a planar patch bounded by the convex hull of two circle and utilizes both edge like and region like information in matching the mode l to the target it us hard constraint for joint attachment and is designed to be robust to occlusion and missing data experimental result are presented in which a human arm is successfully tracked over frame of real video rate range imagery 
this paper describes an efficient method to obtain d information by using spatio temporal analysis of omni image for outdoor navigation and map making in the intelligent transportation system it application two type of omni directional camera are employed to make a spatio temporal volume which is a sequence of omni image stacked in the spatio temporal space for the spatio temporal analysis of an omni image we define several different cross section in such spatio temporal volume and examine characteristic of the trace of image feature on the cross section we determine that the vertical straight line in the real world are preserved a straight line on these cross section and that the degree of this slope represents the quotient of the velocity of the camera motion and the depth of the object to acquire d information using these characteristic we propose a hybrid method of the epipolar plane image epi analysis and the model based analysis to demonstrate the effectiveness of this method we present some experimental result and the it application using an omni directional video camera to obtain image in outdoor environment 
a new approach to characterizing the performance of point correspondence algorithm is presented instead of relying on any ground truth it us the self consistency of the output of an algorithm independently applied to different set of view of a static scene it allows one to evaluate algorithm for a given class of scene a well a to estimate the accuracy of every element of the output of the algorithm for a given set of view experiment to demonstrate the usefulness of the methodology are presented 
this paper present an application of perceptual grouping rule for content based image retrieval the semantic interrelationship between dier ent primitive image feature are exploited by perceptual grouping to detect the presence of manmade structure a methodology based on these principle in a bayesian framework for the retrieval of building image and the result obtained are presented the image database consists of monocular grayscale outdoor image taken from a ground level camera discrete primitive image feature the grouping principle proposed by gestalt psychologist embodied such concept a grouping by proximity similarity continuation closure and symmetry the grouping of low level feature provides a higher level structure these higher level structure may be further combined to yield another level of higher level structure the process may be repeated until a meaningful semantic representation is achieved that may be used by a 
an approach for tracking the motion of a rigidobject using parameterized flow model and acompact structure constraint is proposed whilepolynomial parameterized flow model have beenshown to be effective in tracking the rigid motionof planar object these model are inappropriatefor tracking moving object that change appearancerevealing their d structure we extendthese model by adding a structure compactnessconstraint that account for image motion that deviatesfrom a planar 
in this paper we present a new method for estimating confidence and curvature of d curvilinear structure the gradient structure tensor gst model shift invariance the eigenstructure of the tensor allows estimation of local dimensionality orientation and the corresponding confidence value local rotational invariance which occurs often in image cause a lower confidence estimate this underestimation can be corrected for by a parabolic deformation of the data in such a way that it becomes translational invariant we show that the optimal deformation can be found analytically and yield a local curvature estimate a a valuable by product we tested our new method on synthetic image and applied it to the detection of channel in d seismic data 
this paper offer computational theory and an algorithmicframework for perceptual organization of imagecontours arising from static occluding surface ofconstant lightness we articulate constraint and biasesunderlying the inference of such physical eventsas visible surface overlap and invisible modal andamodal surface boundary from ambiguous visualevidence including visible contrast edge and l typeand t type junction for any given scene an energyor cost function is 
we present an original method for tracking in an image sequence complex object which can be approximately modeled by a polyhedral shape the approach relies on the estimation of the d object image motion along with the computation of the d object pose the proposed method fulfills real time constraint along with reliability and robustness requirement real tracking experiment and result concerning a visual servoing positioning task are presented 
slanted surface pose a problem for correspondence algorithm utilizing search because of the greatly increased number of possibility when compared with fronto parallel surface in this paper we propose an algorithm to compute correspondence between stereo image or between frame of a motion sequence by minimizing an energy functional that account for slanted surface the energy is minimized in a greedy strategy that alternate between segmenting the image into a number of non overlapping region using the multiway cut algorithm of boykov veksler and zabih and finding the affine parameter describing the displacement function of each region a follow up step enables the algorithm to escape local minimum due to oversegmentation experiment on real image show the algorithm s ability to find an accurate segmentation and displacement map a well a discontinuity and crease from a wide variety of stereo and motion imagery 
