{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 327kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.8.2 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 110kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy>=0.13.3 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 75kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, scikit-learn, sklearn\n",
      "Successfully installed numpy-1.16.2 scikit-learn-0.20.3 scipy-1.2.1 sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "Collecting numpy>=1.9.2 (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting jinja2>=2.7.2 (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl\n",
      "Collecting pytest (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/16/83b2a35c427b838df9836c9e7e4ae6dfbcbdea643db44652f693b1c57d70/pytest-4.4.0-py2.py3-none-any.whl\n",
      "Collecting future (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz\n",
      "Collecting wheel>=0.23.0 (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/ba/a4702cbb6a3a485239fbe9525443446203f00771af9ac000fa3ef2788201/wheel-0.33.1-py2.py3-none-any.whl\n",
      "Collecting scipy>=0.18.0 (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numexpr (from pyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/13/d38d56c4c49e50b35b6912c80d89f856d50aff605c9e3a4dbba91fc3df44/numexpr-2.6.9-cp36-cp36m-manylinux1_x86_64.whl (163kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 2.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting funcy (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/47/a4/204fa23012e913839c2da4514b92f17da82bf5fc8c2c3d902fa3fa3c6eec/funcy-1.11-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.8.4 (from pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl\n",
      "Collecting pandas>=0.17.0 (from pyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 152kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2>=2.7.2->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting setuptools (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/6a/4b2fcefd2ea0868810e92d519dacac1ddc64a2e53ba9e3422c3b62b378a6/setuptools-40.8.0-py2.py3-none-any.whl\n",
      "Collecting atomicwrites>=1.0 (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl\n",
      "Collecting py>=1.5.0 (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/bc/394ad449851729244a97857ee14d7cba61ddb268dce3db538ba2f2ba1f0f/py-1.8.0-py2.py3-none-any.whl\n",
      "Collecting attrs>=17.4.0 (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting more-itertools>=4.0.0; python_version > \"2.7\" (from pytest->pyLDAvis)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/73/64fb5922b745fc1daee8a2880d907d2a70d9c7bb71eea86fcb9445daab5e/more_itertools-7.0.0-py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pluggy>=0.9 (from pytest->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/e8/4ddac125b5a0e84ea6ffc93cfccf1e7ee1924e88f53c64e98227f0af2a5f/pluggy-0.9.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas>=0.17.0->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas>=0.17.0->pyLDAvis)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: future\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/tonyzhou/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built future\n",
      "Installing collected packages: numpy, MarkupSafe, jinja2, setuptools, atomicwrites, py, attrs, six, more-itertools, pluggy, pytest, future, wheel, scipy, numexpr, funcy, joblib, python-dateutil, pytz, pandas, pyLDAvis\n",
      "Successfully installed MarkupSafe-1.1.1 atomicwrites-1.3.0 attrs-19.1.0 funcy-1.11 future-0.17.1 jinja2-2.10 joblib-0.13.2 more-itertools-7.0.0 numexpr-2.6.9 numpy-1.16.2 pandas-0.24.2 pluggy-0.9.0 py-1.8.0 pyLDAvis-2.1.2 pytest-4.4.0 python-dateutil-2.8.0 pytz-2018.9 scipy-1.2.1 setuptools-40.8.0 six-1.12.0 wheel-0.33.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "order presented representation real general use\n",
      "Topic #1:\n",
      "time real use task new presented\n",
      "Topic #2:\n",
      "technique presented application real information number\n",
      "Topic #3:\n",
      "performance application task real new presented\n",
      "Topic #4:\n",
      "use representation general information order presented\n",
      "Topic #5:\n",
      "language representation set knowledge use information\n",
      "Topic #6:\n",
      "theory general representation reasoning presented domain\n",
      "Topic #7:\n",
      "domain use process knowledge presented reasoning\n",
      "Topic #8:\n",
      "object presented real representation general information\n",
      "Topic #9:\n",
      "real application time presented new data\n",
      "Topic #10:\n",
      "number data presented application structure new\n",
      "Topic #11:\n",
      "point presented real number representation set\n",
      "Topic #12:\n",
      "new presented knowledge real task set\n",
      "Topic #13:\n",
      "feature presented representation application number set\n",
      "Topic #14:\n",
      "constraint representation application language presented task\n",
      "Topic #15:\n",
      "different presented real representation information order\n",
      "Topic #16:\n",
      "representation task presented knowledge real set\n",
      "Topic #17:\n",
      "information representation process use presented task\n",
      "Topic #18:\n",
      "learning language analysis technique general application\n",
      "Topic #19:\n",
      "structure presented information representation real use\n",
      "Topic #20:\n",
      "set number general representation real new\n",
      "Topic #21:\n",
      "reasoning application example knowledge representation task\n",
      "Topic #22:\n",
      "process presented structure technique representation real\n",
      "Topic #23:\n",
      "analysis presented application real representation task\n",
      "Topic #24:\n",
      "general presented structure representation task use\n",
      "Topic #25:\n",
      "example presented learning representation domain task\n",
      "Topic #26:\n",
      "knowledge representation order information set reasoning\n",
      "Topic #27:\n",
      "data real set presented application task\n",
      "Topic #28:\n",
      "learning task set general knowledge representation\n",
      "Topic #29:\n",
      "application theory task reasoning general number\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyzhou/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/Mar/2019 22:58:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Mar/2019 22:58:20] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Mar/2019 22:58:20] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Mar/2019 22:58:20] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "def topic_classification(filename):\n",
    "    corpus = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            corpus.append(line.strip('\\n'))\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_df=0.2, min_df=0.1)\n",
    "    cntTf = vectorizer.fit_transform(corpus)\n",
    "    lda = LatentDirichletAllocation(n_components=30,\n",
    "                                    learning_method='batch',\n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)\n",
    "    lda.fit(cntTf)\n",
    "    tf_feature_names = vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, 6)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    data = pyLDAvis.sklearn.prepare(lda, cntTf, vectorizer)\n",
    "    pyLDAvis.show(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    topic_classification('word90-92.txt')\n",
    "    '''\n",
    "    topic_classification('word90-92.txt')\n",
    "    topic_classification('word93-95.txt')\n",
    "    topic_classification('word96-98.txt')\n",
    "    topic_classification('word99-01.txt')\n",
    "    topic_classification('word02-04.txt')\n",
    "    topic_classification('word05-07.txt')\n",
    "    topic_classification('word08-10.txt')\n",
    "    topic_classification('word11-13.txt')\n",
    "    '''\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b9/6c93685bed0026b6a1cce55ab173f6b617f6db0d1325d25489c2fd43e711/gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.2MB 78kB/s eta 0:00:011    88% |████████████████████████████▍   | 21.5MB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.7.0 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/c8/de7dcf34d4b5f2ae94fe1055e0d6418fb97a63c9dc3428edd264704983a2/smart_open-1.8.0.tar.gz (40kB)\n",
      "\u001b[K    100% |████████████████████████████████| 40kB 3.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.18.1 (from gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting six>=1.5.0 (from gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.11.3 (from gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting boto>=2.32 (from smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Collecting requests (from smart-open>=1.7.0->gensim)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl\n",
      "Collecting boto3 (from smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/71/35e2fb5cee31d846f1139913cbfcdd9dafa49449b33ce712e8e81b70eb81/boto3-1.9.125-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 5.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests->smart-open>=1.7.0->gensim)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.25,>=1.21.1 (from requests->smart-open>=1.7.0->gensim)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests->smart-open>=1.7.0->gensim)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->smart-open>=1.7.0->gensim)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/60/75/f692a584e85b7eaba0e03827b3d51f45f571c2e793dd731e598828d380aa/certifi-2019.3.9-py2.py3-none-any.whl (158kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.13.0,>=1.12.125 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/e6/8f50d5442cef835bc83a0555d23305b9210f20eac62990d3ec3911b591d9/botocore-1.12.125-py2.py3-none-any.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 325kB/s ta 0:00:011   5% |█▊                              | 296kB 7.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/de/5737f602e22073ecbded7a0c590707085e154e32b68d86545dcc31004c02/s3transfer-0.2.0-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 3.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" (from botocore<1.13.0,>=1.12.125->boto3->smart-open>=1.7.0->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.125->boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 2.3MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/tonyzhou/.cache/pip/wheels/f7/a6/ff/9ab5842c14e50e95a06a4675b0b4a689c9cab6064dac2b01d0\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/tonyzhou/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, idna, urllib3, chardet, certifi, requests, jmespath, six, python-dateutil, docutils, botocore, s3transfer, boto3, smart-open, numpy, scipy, gensim\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim.parsing\n",
      "\u001b[31m  Could not find a version that satisfies the requirement gensim.parsing (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for gensim.parsing\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim.parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.parsing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f88131d0d41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhashdictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHashDictionary\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwikicorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWikiCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtextcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextDirectoryCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mucicorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUciCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/corpora/wikicorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# cannot import whole gensim.corpora, because that imports wikicorpus...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/corpora/textcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRE_WHITESPACE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeaccent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.parsing'"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "def topic_classification_gensim(filename_1, filename_2):\n",
    "    common_texts = []\n",
    "    with open(filename_1, 'r') as file:\n",
    "        for line in file:\n",
    "            line_1 = line.strip('\\n')\n",
    "            if line_1.split(' ')[-1] == \"\":\n",
    "                common_texts.append(line_1.split(' ')[:-1])\n",
    "            else:\n",
    "                common_texts.append(line_1.split(' '))\n",
    "    common_dictionary = corpora.Dictionary(common_texts)\n",
    "    common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "    lda = LdaModel(common_corpus, num_topics=20)\n",
    "    other_texts = []\n",
    "    with open(filename_2, 'r') as file:\n",
    "        for line in file:\n",
    "            line_1 = line.strip('\\n')\n",
    "            if line_1.split(' ')[-1] == \"\":\n",
    "                other_texts.append(line_1.split(' ')[:-1])\n",
    "            else:\n",
    "                other_texts.append(line_1.split(' '))\n",
    "    other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "    for unseen_doc in other_corpus:\n",
    "        vector = lda[unseen_doc]\n",
    "    for seen_doc in common_corpus:\n",
    "        vector_1 = lda[seen_doc]\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(lda, common_corpus, cmommon_dictionary)\n",
    "    pyLDAvis.show(vis)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    topic_classification_gensim('word90-92.txt', 'word93-95.txt')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
