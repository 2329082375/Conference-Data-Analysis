we deal with the calibration problem of an active head eye system which consists of a pair of camera mounted on a head with degree of freedom the aim of the calibration is to establish relative position of different d system between camera and neck eye and neck etc so that we can keep track of the camera position in a fixed calibration reference system a a function of the visual parameter of the head eye system we formulate the problem and propose both closed form and nonlinear optimization approach to solve it experiment were carried out and comparison of result with other algorithm were made on both simulated and real data 
visual representation are chosen to meet the requirement of specified task such a object recognition or siereoscopic matching when vision is regarded a a haptic sense a new operational description is called for in support of dezirous manipulation in the contett of two fingered grasp an appropriate description can be constructed in term of local reflectional and rotational symmetry relaied to sgmmetry based representation that have been used in pattern and object recognition ifs siructure is deiemined not heuristically but precisely by the natun of ihe grasping iask it value is demonstrated by it incorporation into the control of a robot that can manipulate object under visual guidance 
a new approach to tracking weakly modeled object in a semantically rich domain is presented we define a closed world a a space time region of an image sequence in which the complete taxonomy of object is known and in which each pixel should be explained a belonging to one of those object given contextual object information context specific feature can be dynamically selected a the basis for tracking a context specific feature is one that ha been chosen based upon the context to maximize the chance of successful tracking between frame our work is motivated by the goal of video annotation the semi automatic generation of symbolic description of action taking place in a contextually rich dynamic scene we describe how contextual knowledge in the football domain can be applied to closed world football player tracking and present the detail of our implementation we include tracking result based on hundred of image that demonstrate the wide range of tracking situation the algorithm successfully handle a well a a few example of where the algorithm fails 
visual motion boundary provide a powerful cue for the perceptual organization of scene motion boundary are present when surface in motion occlude one another conventional approach to motion analysis have relied on assumption of data conservation and smoothness which ha made analysis of motion boundary difficult we show that a common source of motion boundary kinetic occlusion can be detected using spatiotemporal junction analysis junction analysis is accomplished by utilizing distributed representation of motion used in model of human visual motion sensing by detecting change in the direction of motion in these representation spatiotemporal junction are detected in a manner which differentiates accretion from deletion we demonstrate successful occlusion detection on spatiotemporal imagery containing occluding surface in motion 
this paper present a method for recognizing human handgestures using a model based approach a finite state machine is used tomodel four qualitatively distinct phase of a generic gesture fingertipsare tracked in multiple frame to compute motion trajectory which arethen used for finding the start and stop position of the gesture gesturesare represented a a list of vector and are then matched to stored gesturevector model using table lookup based on vector displacement 
the location of object in image is difficult owing to the view variance of geometric feature but can be determined by developing view insensitive description of the intensity local to image point view insensitive description are achieved in this work by describing point in term of the response of steerable filter at multiple scale owing to the use of multiple scale the vector for each point is for all practical purpose unique and thus can be easily matched to other instance of the point in other image we show that this method can be extended to handle the case where the area near a point of interest is partially occluded the method us a description of the occluder in the form of a template that can be obtained easily via active vision system using a method such a disparity filtering 
a new technique called shape from photomotion is introduced it us a series of d lambertian image generated by moving a light source around a scene to recover the depth map in each of the image the object in the scene remains at a fixed position and the only variable is the light source direction the movement of the light source cause a change in the intensity of any given point in the image the change in intensity is what enables recovery of the unknown parameter the depth map since it remains constant in each of the input image the author method differs from photometric stereo in the sense that the shape estimate is not only computed for each light source orientation but also gradually refined by photomotion 
steerable filter a developed by freeman and adelson are a class of rotation invariant linear operator that may be used to analyze local orientation pattern in imagery the most common example of such operator are directional derivative of gaussians and their d hilbert transforms the inherent symmetry of these filter produce an orientation response that is periodic with period spl pi even when the underlying image structure doe not have such symmetry this problem may be alleviated by reconsidering the full class of steerable filter we develop a family of evenand odd symmetric steerable filter that have a spatially asymmetric wedge like shape and are optimally localized in their orientation response unlike the original steerable filter these filter are not based on directional derivative and the hilbert transform relationship is imposed on their angular component we demonstrate the ability of these filter to properly represent oriented structure 
the paper present a typologically adaptable snake model for image segmentation and object representation the model is embedded in the framework of domain subdivision using simplicial decomposition this framework extends the geometric and topological adaptability of snake while retaining all of the feature of traditional snake such a user interaction and overcoming many of the limitation of traditional snake by superposing a simplicial grid over the image domain and using this grid to iteratively reparameterize the deforming snake model the model is able to flow into complex shape even shape with significant protrusion or branch and to dynamically change topology a necessitated by the data snake can be created and can split into multiple part or seamlessly merge into other snake the model can also be easily converted to and from the traditional parametric snake model representation we apply a d model to various synthetic and real image in order to segment object with complicated shape and topology 
three different algorithm for qualitative obstacle detection are presented in this paper each one is based on different assumption the first two algorithm are aimed at yes no obstacle detection without indicating which point are obstacle they have the advantage of fast determination of the existence of obstacle in a scene based on the solvability of a linear system the first algorithm us information about the ground plane while the second algorithm only assumes that the ground is planar the third algorithm continuously estimate the ground plane and based on that determines the height of each matched point in the scene experimental result are presented for real and simulated data and performance of the three algorithm under different noise level are compared in simulation we conclude that in term of the robustness of performance the third one work best 
modelling and analyzing pushbroom sensor commonly used in satellite imagery is difficult and computationally intensive due to the motion of an orbiting satellite with respect to the rotating earth and the non linearity of the mathematical model involving orbital dynamic in this paper a simplified model of a pushbroom sensor the linear pushbroom model is introduced it ha the advantage of computational simplicity while at the same time giving very accurate result compared with the full orbiting pushbroom model besides remote sensing the linear pushbroom model is also useful in many other imaging application simple non iterative method are given for solving the major standard photogrammetric problem for the linear pushbroom model computation of the model parameter from ground control point determination of relative model parameter from image correspondence between two image and scene reconstruction given image correspondence and ground control point the linear pushbroom model lead to theoretical insight that are approximately valid for the full model a well the epipolar geometry of linear pushbroom camera in investigated and shown to be totally different from that of a perspective camera nevertheless a matrix analogous to the fundamental matrix of perspective camera is shown to exist for linear pushbroom sensor from this it is shown that a scene is determined up to an affine transformation from two view with linear pushbroom camera 
the overall movement of articulated body such asthe human body is enabled by the coordinated movementof it rigid body part the body part are connectedby joint and in general move differently forinterpreting these movement a the movement of onesingle body it seems to be necessary to incorporateknowledge in the analysis process therefore in orderto recognize pedestrian from monocular image sequence we introduce a model based approach werepresent the human body by a 
what real time qualitative viewpoint control behaviorsare important for performing global visual exploration taskssuch a searching for specific surface marking buildinga global model of an arbitrary object or recognizing anobject in this paper we consider the task of purposefully controlling the motion of an active monocular observerin order to recover a global description of a smooth arbitrarily shaped object using the occluding contour bystudying the epipolar parameterization 
observation based modeling can reduce the cost and effort of model construction for task such a virtual reality environment object modeling from a sequence of range image ha been formulated a a problem of principal component analysis with missing data pcamd which can be generalized a a weighted least square wls minimization problem after all visible region appeared over the whole sequence are segmented and tracked a normal measurement matrix of surface normal and a distance measurement matrix of normal distance to the origin are constructed respectively these two measurement matrix with possibly many missing element due to occlusion and mismatching enable u to formulate multiple view merging a a combination of two wls problem the solution to the first wls problem which employ the quaternion representation of the rotation matrix yield surface normal and rotation matrix subsequently the normal distance and translation vector are computed by solving the second wls problem experiment using synthetic data and real range image show that our approach is robust against noise and mismatch because it produce a statistically optimal object model by making use of redundancy from multiple view a toy house model from a sequence of real range image is presented 
the lure of using motion vision a a fundamental element in the perception of space drive this effort to use flow feature a the sole cue for robot mobility real time estimate of image flow and flow divergence provide the robot s sense of space the robot steer down a conceptual corridor comparing left and right peripheral flow large central flow divergence warns the robot of impending collision at dead end when this occurs the robot turn around and resume wandering behavior is generated by directly using flow based information in the d image sequence no d reconstruction is attempted active mechanical gate stabilization simplifies the visual interpretation problem by reducing camera rotation by combining corridor following and dead end deflection the robot ha wandered around the lab at cm s for a long a minute without collision the ability to support this behavior in real time with current equipment promise expanded capability a computational power increase in the future 
we present an unsupervised technique for visual learning which is based on density estimation in high dimensional space using an eigenspace decomposition two type of density estimate are derived for modeling the training data a multivariate gaussian for a unimodal distribution and a multivariate mixture of gaussians model for multimodal distribution these probability density are then used to formulate a maximum likelihood estimation framework for visual search and target detection for automatic object recognition this learning technique is tested in experiment with modeling and subsequent detection of human face and non rigid object such a hand 
in previous application bilateral symmetry of object wasused either a a descriptive feature in domain such a recognition andgrasping or a a way to reduce the complexity of structure from motion in this paper we propose a novel application using the symmetry propertyto quot symmetrize quot data before and after reconstruction we first showhow to compute the closest symmetric d and d configuration givennoisy data this give u a symmetrization procedure which we applyto image 
a new technique for the calibration of the intrinsic parameter of camera for active vision system is presented by making deliberate camera motion the intrinsics of the camera can be calibrated based either on the positional difference of optical flow field pdoff or the trajectory of feature tof on the image plane a way to detect the distortion of a camera lens is also presented the calibration method is simple fast reliable and very easy to combine with task performing process the performance of the technique is illustrated the method can be used for general calibration of camera intrinsics 
the first order spatial derivative of optic flow dilation shear and rotation provide powerful information about motion and surface layout the log polar sampled image lsi is of increasing interest for active vision and is particularly well suited to the measurement of local first order flow we explain why this is propose a simple least square method for measuring first order flow in an lsi sequence and demonstrate that the method work well when applied to real image 
a method for computing the d camera motion the ego motion in a static scene is introduced whichis based on computing the d image motion of a singleimage region directly from image intensity thecomputed image motion of this image region is used toregister the image so that the detected image regionappears stationary the resulting displacement fieldfor the entire scene between the registered frame is affectedonly by the d translation of the camera aftercanceling the effect 
a method of determining the motion of a camera from it image velocity is described that is insensitive to noise and intrinsic camera parameter this algorithm is based on a novel extension of motion parallax which doe not require the instantaneous alignment of feature but us sparse visual motion estimate to extract the direction of translation of the camera directly after which determination of the camera rotation and the depth of the image feature follows easily a method for calculating the expected uncertainty in the estimate is also described which allows optimal estimation and can also detect and reject independent motion and false correspondence experiment using small perturbation analysis show a favourable comparison with existing method and specifically the fundamental matrix method 
a recursive estimation technique for recovering the d motion and pointwise structure of an object is presented it is based on the use of relative orientation constraint in a local coordinate frame by carefully formulating the problem to propagate all constraint and to use the minimal number of parameter an estimator is obtained which is remarkably accurate stable and fast conveying numerous experiment using both real and synthetic data demonstrate structure recovery with a typical error of and typical motion recovery error of in translation and in rotation 
this paper describes an automated process for the dynamic creation of a pattern recognizing computer program consisting of initially unknown detector an initially unknown iterative calculation incorporating the a yet uncreated detector and an initially unspecified final calculation incorporating the result of the a yetuncreated iteration the program s goal is to recognize a given protein segment a being a transmembrane domain or non transmembrane area the recognizing program to solve this problem will be evolved using the recentlydeveloped genetic programming paradigm genetic programming start with a primordial ooze of randomly generated computer program composed of available programmatic ingredient and then genetically breed the population using the darwinian principle of survival of the fittest and the genetic crossover sexual recombination operation automatic function definition enables genetic programming to dynamically create subroutine detector when cross validated the best genetically evolved recognizer achieves an out of sample correlation of and an outof sample error rate of this error rate is better than that recently reported for five other method statement of the problem the goal in this paper is to use genetic programming with automatically defined function adfs to create a computer program for recognizing a given subsequence of amino acid in a protein a being a transmembrane domain or non transmembrane area of the protein the automated process that will create the recognizing program for this problem will be given a set of differently sized protein segment and the correct classification for each segment the recognizing program will consist of initiallyunspecified detector an initially unspecified iterative calculation incorporating the a yet undiscovered detector and an initially unspecified final calculation incorporating the result of the a yet undiscovered iteration although genetic programming doe not know the chemical characteristic or biological meaning of the sequence of amino acid appearing in the protein segment we will show that the result have an interesting biological interpretation of course the reader may ignore the biological interpretation and view this problem a a onedimensional pattern recognition problem genetic programming is a domain independent method for evolving computer program that solve or approximately solve problem to accomplish this genetic programming start with a primordial ooze of randomly generated computer program composed of the available programmatic ingredient and breed the population or program using the darwinian principle of survival of the fittest and an analog of the naturally occurring genetic operation of crossover sexual recombination automatic function definition enables genetic programming to dynamically create subroutine dynamically during the run the question arises a to whether genetic programming can evolve a recognizing program consisting of initially unspecified detector an initially unspecified iterative calculation incorporating the a yet undiscovered detector and an initially unspecified final calculation incorporating the result of the a yet undiscovered iteration the genetically evolved program in this paper accomplishes this it achieves a better error rate than all four algorithm described in wei et al when analyzed the genetically evolved program ha a simple biological interpretation 
in this paper area preserving multi scale representation of planar curve are described this allows smoothing without shrinkage at the same time preserving all the scale space property the representation are obtained deforming the curve via geometric heat flow while simultaneously magnifying the plane by a homethety which keep the enclosed area constant when the euclidean geometric heat flow is used the resulting representation is euclidean invariant and similarly it is affine invariant when the affine one is used the flow are geometrically intrinsic to the curve and exactly satisfy all the basic requirement of scale space representation in the case of the euclidean heat flow it is completely local a well the same approach is used to define length preserving geometric flow a similarity scale invariant geometric heat flow is studied a well in this work 
a new representation for object with multiple colour the colour adjacency graph cag is proposed each node of the cag represents a single chromatic component of the image defined a a set of pixel forming a unimodal cluster in the chromatic scattergram edge encode information about adjacency of colour component and their reflectance ratio the cag is related to both the histogram and region adjacency graph representation it is shown to be preserving and combining the best feature of these two approach while avoiding their drawback the proposed approach is tested on a range of difficult object recognition and localisation problem involving complex imagery of non rigid d object under varied viewing condition with excellent result 
the problem of scale in shape from textureis addressed the need for at least two scale parametersis emphasized a local scale describing the amount ofsmoothing used for suppressing noise and irrelevant detailswhen computing primitive texture descriptor fromimage data and an integration scale describing the sizeof the region in space over which the statistic of thelocal descriptor is accumulated a novel mechanism for automatic scale selection isproposed based on normalized 
a number of recent paper have argued that invariantsdo not exist for three dimensional point set in generalposition this ha often been misinterpretedto mean that invariant cannot be computed for anythree dimensional structure this paper prof by examplethat although the general statement is true invariantsdo exist for structured three dimensional pointsets projective invariant are derived for two class ofobject the first is for point that lie on the vertex of 
we describe a technique for surface recovery of a rotating object illuminated under a collinear light source where the light source lie on or near the optical axis we show that the surface reflectance function can be directly estimated from the image sequence without any assumption on the reflectance property of the object surface from the image sequence the d location of some singular surface point are calculated and their brightness value are extracted for the estimation of the reflectance function we also show that the surface can be recovered by using shading information in two image of the rotating object iteratively using the first order taylor series approximation and the estimated reflectance function the depth and orientation of the surface can be recovered simultaneously the experimental result on real image sequence of both matte and specular surface demonstrate that the technique is feasible and robust 
we deal with the calibration problem of an active head eye system which consists of a pair of camera mounted on a head with degree of freedom the aim of the calibration is to establish relative position of different d system between camera and neck eye and neck etc so that we can keep track of the camera position in a fixed calibration reference system a a function of the visual parameter of the head eye system we formulate the problem and propose both closed form and nonlinear optimization approach to solve it experiment were carried out and comparison of result with other algorithm were made on both simulated and real data 
visual representation are chosen to meet the requirement of specified task such a object recognition or siereoscopic matching when vision is regarded a a haptic sense a new operational description is called for in support of dezirous manipulation in the contett of two fingered grasp an appropriate description can be constructed in term of local reflectional and rotational symmetry relaied to sgmmetry based representation that have been used in pattern and object recognition ifs siructure is deiemined not heuristically but precisely by the natun of ihe grasping iask it value is demonstrated by it incorporation into the control of a robot that can manipulate object under visual guidance 
a new approach to tracking weakly modeled object in a semantically rich domain is presented we define a closed world a a space time region of an image sequence in which the complete taxonomy of object is known and in which each pixel should be explained a belonging to one of those object given contextual object information context specific feature can be dynamically selected a the basis for tracking a context specific feature is one that ha been chosen based upon the context to maximize the chance of successful tracking between frame our work is motivated by the goal of video annotation the semi automatic generation of symbolic description of action taking place in a contextually rich dynamic scene we describe how contextual knowledge in the football domain can be applied to closed world football player tracking and present the detail of our implementation we include tracking result based on hundred of image that demonstrate the wide range of tracking situation the algorithm successfully handle a well a a few example of where the algorithm fails 
visual motion boundary provide a powerful cue for the perceptual organization of scene motion boundary are present when surface in motion occlude one another conventional approach to motion analysis have relied on assumption of data conservation and smoothness which ha made analysis of motion boundary difficult we show that a common source of motion boundary kinetic occlusion can be detected using spatiotemporal junction analysis junction analysis is accomplished by utilizing distributed representation of motion used in model of human visual motion sensing by detecting change in the direction of motion in these representation spatiotemporal junction are detected in a manner which differentiates accretion from deletion we demonstrate successful occlusion detection on spatiotemporal imagery containing occluding surface in motion 
this paper present a method for recognizing human handgestures using a model based approach a finite state machine is used tomodel four qualitatively distinct phase of a generic gesture fingertipsare tracked in multiple frame to compute motion trajectory which arethen used for finding the start and stop position of the gesture gesturesare represented a a list of vector and are then matched to stored gesturevector model using table lookup based on vector displacement 
the location of object in image is difficult owing to the view variance of geometric feature but can be determined by developing view insensitive description of the intensity local to image point view insensitive description are achieved in this work by describing point in term of the response of steerable filter at multiple scale owing to the use of multiple scale the vector for each point is for all practical purpose unique and thus can be easily matched to other instance of the point in other image we show that this method can be extended to handle the case where the area near a point of interest is partially occluded the method us a description of the occluder in the form of a template that can be obtained easily via active vision system using a method such a disparity filtering 
a new technique called shape from photomotion is introduced it us a series of d lambertian image generated by moving a light source around a scene to recover the depth map in each of the image the object in the scene remains at a fixed position and the only variable is the light source direction the movement of the light source cause a change in the intensity of any given point in the image the change in intensity is what enables recovery of the unknown parameter the depth map since it remains constant in each of the input image the author method differs from photometric stereo in the sense that the shape estimate is not only computed for each light source orientation but also gradually refined by photomotion 
steerable filter a developed by freeman and adelson are a class of rotation invariant linear operator that may be used to analyze local orientation pattern in imagery the most common example of such operator are directional derivative of gaussians and their d hilbert transforms the inherent symmetry of these filter produce an orientation response that is periodic with period spl pi even when the underlying image structure doe not have such symmetry this problem may be alleviated by reconsidering the full class of steerable filter we develop a family of evenand odd symmetric steerable filter that have a spatially asymmetric wedge like shape and are optimally localized in their orientation response unlike the original steerable filter these filter are not based on directional derivative and the hilbert transform relationship is imposed on their angular component we demonstrate the ability of these filter to properly represent oriented structure 
the paper present a typologically adaptable snake model for image segmentation and object representation the model is embedded in the framework of domain subdivision using simplicial decomposition this framework extends the geometric and topological adaptability of snake while retaining all of the feature of traditional snake such a user interaction and overcoming many of the limitation of traditional snake by superposing a simplicial grid over the image domain and using this grid to iteratively reparameterize the deforming snake model the model is able to flow into complex shape even shape with significant protrusion or branch and to dynamically change topology a necessitated by the data snake can be created and can split into multiple part or seamlessly merge into other snake the model can also be easily converted to and from the traditional parametric snake model representation we apply a d model to various synthetic and real image in order to segment object with complicated shape and topology 
three different algorithm for qualitative obstacle detection are presented in this paper each one is based on different assumption the first two algorithm are aimed at yes no obstacle detection without indicating which point are obstacle they have the advantage of fast determination of the existence of obstacle in a scene based on the solvability of a linear system the first algorithm us information about the ground plane while the second algorithm only assumes that the ground is planar the third algorithm continuously estimate the ground plane and based on that determines the height of each matched point in the scene experimental result are presented for real and simulated data and performance of the three algorithm under different noise level are compared in simulation we conclude that in term of the robustness of performance the third one work best 
modelling and analyzing pushbroom sensor commonly used in satellite imagery is difficult and computationally intensive due to the motion of an orbiting satellite with respect to the rotating earth and the non linearity of the mathematical model involving orbital dynamic in this paper a simplified model of a pushbroom sensor the linear pushbroom model is introduced it ha the advantage of computational simplicity while at the same time giving very accurate result compared with the full orbiting pushbroom model besides remote sensing the linear pushbroom model is also useful in many other imaging application simple non iterative method are given for solving the major standard photogrammetric problem for the linear pushbroom model computation of the model parameter from ground control point determination of relative model parameter from image correspondence between two image and scene reconstruction given image correspondence and ground control point the linear pushbroom model lead to theoretical insight that are approximately valid for the full model a well the epipolar geometry of linear pushbroom camera in investigated and shown to be totally different from that of a perspective camera nevertheless a matrix analogous to the fundamental matrix of perspective camera is shown to exist for linear pushbroom sensor from this it is shown that a scene is determined up to an affine transformation from two view with linear pushbroom camera 
the overall movement of articulated body such asthe human body is enabled by the coordinated movementof it rigid body part the body part are connectedby joint and in general move differently forinterpreting these movement a the movement of onesingle body it seems to be necessary to incorporateknowledge in the analysis process therefore in orderto recognize pedestrian from monocular image sequence we introduce a model based approach werepresent the human body by a 
what real time qualitative viewpoint control behaviorsare important for performing global visual exploration taskssuch a searching for specific surface marking buildinga global model of an arbitrary object or recognizing anobject in this paper we consider the task of purposefully controlling the motion of an active monocular observerin order to recover a global description of a smooth arbitrarily shaped object using the occluding contour bystudying the epipolar parameterization 
observation based modeling can reduce the cost and effort of model construction for task such a virtual reality environment object modeling from a sequence of range image ha been formulated a a problem of principal component analysis with missing data pcamd which can be generalized a a weighted least square wls minimization problem after all visible region appeared over the whole sequence are segmented and tracked a normal measurement matrix of surface normal and a distance measurement matrix of normal distance to the origin are constructed respectively these two measurement matrix with possibly many missing element due to occlusion and mismatching enable u to formulate multiple view merging a a combination of two wls problem the solution to the first wls problem which employ the quaternion representation of the rotation matrix yield surface normal and rotation matrix subsequently the normal distance and translation vector are computed by solving the second wls problem experiment using synthetic data and real range image show that our approach is robust against noise and mismatch because it produce a statistically optimal object model by making use of redundancy from multiple view a toy house model from a sequence of real range image is presented 
the lure of using motion vision a a fundamental element in the perception of space drive this effort to use flow feature a the sole cue for robot mobility real time estimate of image flow and flow divergence provide the robot s sense of space the robot steer down a conceptual corridor comparing left and right peripheral flow large central flow divergence warns the robot of impending collision at dead end when this occurs the robot turn around and resume wandering behavior is generated by directly using flow based information in the d image sequence no d reconstruction is attempted active mechanical gate stabilization simplifies the visual interpretation problem by reducing camera rotation by combining corridor following and dead end deflection the robot ha wandered around the lab at cm s for a long a minute without collision the ability to support this behavior in real time with current equipment promise expanded capability a computational power increase in the future 
we present an unsupervised technique for visual learning which is based on density estimation in high dimensional space using an eigenspace decomposition two type of density estimate are derived for modeling the training data a multivariate gaussian for a unimodal distribution and a multivariate mixture of gaussians model for multimodal distribution these probability density are then used to formulate a maximum likelihood estimation framework for visual search and target detection for automatic object recognition this learning technique is tested in experiment with modeling and subsequent detection of human face and non rigid object such a hand 
in previous application bilateral symmetry of object wasused either a a descriptive feature in domain such a recognition andgrasping or a a way to reduce the complexity of structure from motion in this paper we propose a novel application using the symmetry propertyto quot symmetrize quot data before and after reconstruction we first showhow to compute the closest symmetric d and d configuration givennoisy data this give u a symmetrization procedure which we applyto image 
a new technique for the calibration of the intrinsic parameter of camera for active vision system is presented by making deliberate camera motion the intrinsics of the camera can be calibrated based either on the positional difference of optical flow field pdoff or the trajectory of feature tof on the image plane a way to detect the distortion of a camera lens is also presented the calibration method is simple fast reliable and very easy to combine with task performing process the performance of the technique is illustrated the method can be used for general calibration of camera intrinsics 
the first order spatial derivative of optic flow dilation shear and rotation provide powerful information about motion and surface layout the log polar sampled image lsi is of increasing interest for active vision and is particularly well suited to the measurement of local first order flow we explain why this is propose a simple least square method for measuring first order flow in an lsi sequence and demonstrate that the method work well when applied to real image 
a method for computing the d camera motion the ego motion in a static scene is introduced whichis based on computing the d image motion of a singleimage region directly from image intensity thecomputed image motion of this image region is used toregister the image so that the detected image regionappears stationary the resulting displacement fieldfor the entire scene between the registered frame is affectedonly by the d translation of the camera aftercanceling the effect 
a method of determining the motion of a camera from it image velocity is described that is insensitive to noise and intrinsic camera parameter this algorithm is based on a novel extension of motion parallax which doe not require the instantaneous alignment of feature but us sparse visual motion estimate to extract the direction of translation of the camera directly after which determination of the camera rotation and the depth of the image feature follows easily a method for calculating the expected uncertainty in the estimate is also described which allows optimal estimation and can also detect and reject independent motion and false correspondence experiment using small perturbation analysis show a favourable comparison with existing method and specifically the fundamental matrix method 
a recursive estimation technique for recovering the d motion and pointwise structure of an object is presented it is based on the use of relative orientation constraint in a local coordinate frame by carefully formulating the problem to propagate all constraint and to use the minimal number of parameter an estimator is obtained which is remarkably accurate stable and fast conveying numerous experiment using both real and synthetic data demonstrate structure recovery with a typical error of and typical motion recovery error of in translation and in rotation 
this paper describes an automated process for the dynamic creation of a pattern recognizing computer program consisting of initially unknown detector an initially unknown iterative calculation incorporating the a yet uncreated detector and an initially unspecified final calculation incorporating the result of the a yetuncreated iteration the program s goal is to recognize a given protein segment a being a transmembrane domain or non transmembrane area the recognizing program to solve this problem will be evolved using the recentlydeveloped genetic programming paradigm genetic programming start with a primordial ooze of randomly generated computer program composed of available programmatic ingredient and then genetically breed the population using the darwinian principle of survival of the fittest and the genetic crossover sexual recombination operation automatic function definition enables genetic programming to dynamically create subroutine detector when cross validated the best genetically evolved recognizer achieves an out of sample correlation of and an outof sample error rate of this error rate is better than that recently reported for five other method statement of the problem the goal in this paper is to use genetic programming with automatically defined function adfs to create a computer program for recognizing a given subsequence of amino acid in a protein a being a transmembrane domain or non transmembrane area of the protein the automated process that will create the recognizing program for this problem will be given a set of differently sized protein segment and the correct classification for each segment the recognizing program will consist of initiallyunspecified detector an initially unspecified iterative calculation incorporating the a yet undiscovered detector and an initially unspecified final calculation incorporating the result of the a yet undiscovered iteration although genetic programming doe not know the chemical characteristic or biological meaning of the sequence of amino acid appearing in the protein segment we will show that the result have an interesting biological interpretation of course the reader may ignore the biological interpretation and view this problem a a onedimensional pattern recognition problem genetic programming is a domain independent method for evolving computer program that solve or approximately solve problem to accomplish this genetic programming start with a primordial ooze of randomly generated computer program composed of the available programmatic ingredient and breed the population or program using the darwinian principle of survival of the fittest and an analog of the naturally occurring genetic operation of crossover sexual recombination automatic function definition enables genetic programming to dynamically create subroutine dynamically during the run the question arises a to whether genetic programming can evolve a recognizing program consisting of initially unspecified detector an initially unspecified iterative calculation incorporating the a yet undiscovered detector and an initially unspecified final calculation incorporating the result of the a yet undiscovered iteration the genetically evolved program in this paper accomplishes this it achieves a better error rate than all four algorithm described in wei et al when analyzed the genetically evolved program ha a simple biological interpretation 
in this paper area preserving multi scale representation of planar curve are described this allows smoothing without shrinkage at the same time preserving all the scale space property the representation are obtained deforming the curve via geometric heat flow while simultaneously magnifying the plane by a homethety which keep the enclosed area constant when the euclidean geometric heat flow is used the resulting representation is euclidean invariant and similarly it is affine invariant when the affine one is used the flow are geometrically intrinsic to the curve and exactly satisfy all the basic requirement of scale space representation in the case of the euclidean heat flow it is completely local a well the same approach is used to define length preserving geometric flow a similarity scale invariant geometric heat flow is studied a well in this work 
a new representation for object with multiple colour the colour adjacency graph cag is proposed each node of the cag represents a single chromatic component of the image defined a a set of pixel forming a unimodal cluster in the chromatic scattergram edge encode information about adjacency of colour component and their reflectance ratio the cag is related to both the histogram and region adjacency graph representation it is shown to be preserving and combining the best feature of these two approach while avoiding their drawback the proposed approach is tested on a range of difficult object recognition and localisation problem involving complex imagery of non rigid d object under varied viewing condition with excellent result 
the problem of scale in shape from textureis addressed the need for at least two scale parametersis emphasized a local scale describing the amount ofsmoothing used for suppressing noise and irrelevant detailswhen computing primitive texture descriptor fromimage data and an integration scale describing the sizeof the region in space over which the statistic of thelocal descriptor is accumulated a novel mechanism for automatic scale selection isproposed based on normalized 
a number of recent paper have argued that invariantsdo not exist for three dimensional point set in generalposition this ha often been misinterpretedto mean that invariant cannot be computed for anythree dimensional structure this paper prof by examplethat although the general statement is true invariantsdo exist for structured three dimensional pointsets projective invariant are derived for two class ofobject the first is for point that lie on the vertex of 
we describe a technique for surface recovery of a rotating object illuminated under a collinear light source where the light source lie on or near the optical axis we show that the surface reflectance function can be directly estimated from the image sequence without any assumption on the reflectance property of the object surface from the image sequence the d location of some singular surface point are calculated and their brightness value are extracted for the estimation of the reflectance function we also show that the surface can be recovered by using shading information in two image of the rotating object iteratively using the first order taylor series approximation and the estimated reflectance function the depth and orientation of the surface can be recovered simultaneously the experimental result on real image sequence of both matte and specular surface demonstrate that the technique is feasible and robust 
this paper give a new method for image rectification the process of resampling pair of stereo image taken from widely differing viewpoint in order to produce a pair of matched epipolar projection these are projection in which the epipolar line run parallel with the x axis and consequently disparity between the image are in the x direction only the method is based on an examination of the essential matrix of longuet higgins which describes the epipolar geometry of the image pair the approach taken is consistent with that recently advocated strongly by faugeras of avoiding camera calibration the paper us method of projective geometry to define a matrix called the epipolar transformation matrix used to determine a pair of d projective transforms to be applied to the two image in order to match the epipolar line the advantage include the simplicity of the d projective transformation which allows very fast resampling a well a subsequent simplification in the identification of matched point and scene reconstruction 
even though method based on the use of deformable model have become prevalent the quality oftheir output depends critically on the model s initial state the issue of initializing such model however ha not received much attention even though it is often key to the implementation ofa truly useful system 
a key to developing computationally efficient stereo vision is the incorporation of intelligent control stereo is most effective when it is able to focus it analysis on region and detail of a scene that are important to the task at hand while avoiding le important region and unnecessary detail the paper describes two method for electronically focusing stereo measurement through simple image pre processing the first allows measurement sensitivity to be adjusted the second allows the shape of the d region in which measurement are gathered to be matched to the shape of surface in the scene 
the view line associated with a family of profile curve of the projection of a surface onto the retina of a moving camera defines a multi valued vector field on the surface the integral curve of this field are called epipolar curve and together with a parametrization of the profile provide a parametrization of region of the surface in addition one ha the epipolar constraint which define curve in the image these image curve are related to the epipolar curve on the surface but not by a simple projection we present an investigation of epipolar curve on the object surface in the spatio temporal surface and the trace in the image we address the question of when there is an epipolar parametrization we have obtained detailed result which depend on a classification cite davydov of vector field on surface with boundary these result give a systematic way of detecting the gap left by reconstruction of a surface from profile they also suggest method for filling in these gap this work wa supported by nato grant crg in addition the second author would like to acknowledge the support of darpa and tacom under contract daae c r and nsf under grant iri and iri 
we address the problem of optical flow reconstruction and in particular the problem of resolving ambiguity near edge they occur due to i the aperture problem and ii the occlusion problem where pixel on both side of an intensity edge are assigned the same velocity estimate and confidence however these measurement are correct for just one side of the edge the non occluded one we note that the confidence measure are large at intensity edge and larger at the convex side of the edge i e inside corner than at the concave side we resolve the ambiguity through local interaction via coupled markov random field mrf the result is the detection of motion for region of image with large global convexity 
this paper describes a simple construction for building a combinatorial model of a smooth manifold solid from a labeled figure representing it occluding contour the motivation is twofold first deriving the combinatorial model is an essential intermediate step in the visual reconstruction of solid shape from image contour a description of solid shape consists of a metric and a topological component both are necessary the metric component specifies how the topological component is embedded in three dimensional space the it paneling construction described in this paper is a procedure for generating the topological component from a labeled figure representing the occluding contour second the existence of this construction establishes the sufficiency of a labeling scheme for line drawing of smooth solid object originally proposed by huffman by sufficiency it is meant that every set of closed plane curve satisfying this labeling scheme is shown to correspond to a generic view of a manifold solid together with the whitney theorem this confirms that huffman s labeling scheme correctly distinguishes possible from impossible solid object 
in this paper we show how geometry driven diffusion can be used to develop a system of curve evolution that is able to preserve salient feature of closed curve such a corner and straight line segment while simultaneously suppressing noise and irrelevant detail the idea is to characterise the curve by mean of it angle function i e the angle between the tangent and a fixed axis and to apply geometry driven diffusion to this one dimensional representation 
no feature based vision system can work until good feature can be identified and tracked from frame to frame although tracking itself is by and large a solved problem selecting feature that can be tracked well and correspond to physical point in the world is still an open problem we propose a feature selection criterion that is optimal by construction because it is based on how the tracker work a well a a feature monitoring method that can detect occlusion disocclusions and feature that do not correspond to point in the world these method are based on a new tracking algorithm that extends previous newton raphson style search method to work under affine image transformation we test performance with several simulation and experiment on real image 
this paper present a class of nonlinear hierarchical algorithm for the fusion of multiresolution image data in low level vision the approach combine nonlinear causal markov model defined on hierarchical graph structure with standard bayesian estimation theory two random process defined on simple hierarchical graph quadtrees or ternary graph are introduced to represent the multiresolution observation at hand and the hidden label to be estimated an optimal algorithm inspired from the viterbi algorithm is developed to compute the bayesian estimate on the hierarchical graph structure estimate are obtained within two pass on the graph structure this algorithm is non iterative and yield a per pixel computational complexity which is independent of image size this approach is compared to the multiscale algorithm proposed by bouman et al for single resolution image segmentation that we have extended for multiresolution data fusion 
in many computer vision problem it is necessary to robustly estimate parameter value from a large quantity of image data in such problem least square minimization is computationally the most convenient and practical solution method the author show that the least square solution is in general statistically biased in the presence of noise a scheme called renormalization that iteratively remove the statistical bias by automatically adjusting to the image noise is presented it is applied to the problem of estimating vanishing point and focus of expansion and conic fitting 
recognition system attempt to recover information about theidentity of observed object and their location in the environment afundamental problem in recognition is pose estimation this is the problem of using a correspondence between some portion of anobject model and some portion of an image to determine whether the imagecontains an instance of the object and in case it doe to determine thetransformation that relates the model to the image the current approachesto this problem are divided into method that use global property of the object e g centroid and moment of inertia and methodsthat use local property of the object e g corner andline segment global property are sensitive to occlusion and specifically to self occlusion local property are difficult to locatereliably and their matching involves intensive computation we present a novel method for recognition that us region information in our approach the model and the image are divided into region given amatch between subset of region without any explicit correspondencebetween different piece of the region the alignment transformation iscomputed the method applies to planar object under similarity affine andprojective transformation and to projection of d object undergoingaffine and projective transformation the new approach combine many of theadvantages of the previous two approach while avoiding some of theirpitfalls like the global method our approach make use of regioninformation that reflects the true shape of the object but like localmethods our approach can handle occlusion 
since the first shape from shading technique wa developed by horn in the early s different approach have been continuously emerging in the past two decade some of them improve existing technique while others are completely new approach however there is no literature on the comparison and performance analysis of these technique this is exactly what is addressed in this paper introduction shape from shading sfs deal with the recovery of shape from a gradual variation of 
time varying multispectral observation of cloud from meteorological satellite are used to estimate cloud top height structure and cloud wind semi fluid motion stereo image pair over several time step were acquired by two geostationary satellite with synchronized scanning instrument cloud top height estimation from these image pair is performed using an improved automatic stereo analysis algorithm on a massively parallel maspar computer with k processor a new category of motion behavior known a semi fluid motion is described for modeling cloud motion and an automatic algorithm for extracting semi fluid motion is developed to track cloud wind the time sequential dense estimate of cloud top height depth map in conjunction with intensity data are used to estimate local semi fluid motion parameter for cloud tracking both stereo disparity and motion correspondence are estimated to sub pixel accuracy the interactive image spreadsheet iis is a new versatile visualization tool that wa enhanced to analyze and visualize the result of the stereo analysis and semi fluid motion estimation algorithm experimental result using time varying data of the visible channel from two satellite in geosynchronous orbit is presented for the hurricane frederic 
the paper present a model of image segmentation that can distinguish foreground from background purely on the basis of motion information the main processing step involved are detection of motion boundary and analysis of figure ground relationship the proposed model utilizes the observation that in kinetic occlusion motion boundary typically display mixture motion information and foreground surface tend to move with motion boundary through distributed probabilistic modeling these constraint can be embedded into computation with efficient network representation the resulting network use spatiotemporal gabor filter a front end and are suitable for parallel distributed processing we demonstrate the application of the model in the decomposition of moving image into surface according to depth 
we present a machine vision system in which segmentation is computed in conjunction with a structural description of object in the scene it is assumed that contrast edge capture all relevant object information the principle which dictate how edge feature are grouped to infer object are based upon detecting symmetrical enclosing edge configuration these are detected using annular operator applied at multiple scale to edge data which have been extracted at multiple scale from a gray level image the subsequent grouping of symmetry point result in a set of part which make it possible to identify the location of object within an image these part are used a a basis for constructing coarse graph based descriptor for the perceptually significant object found in the scene result are presented to illustrate the method s performance on several image 
this paper present a physic based approach for recoveringthe d shape and tracking the motion of nonrigid objectsusing a d elastically deformable balloon model theballoon model is based on a thin plate under tension splinewhich deforms to fit visual data according to internal forcesstemming from the elastic property of the surface and externalforces which are produced from the data we employthe finite element method to represent the model a a continuoussurface we use a 
a technique is presented for computing d scene structure from point and line feature in monocular image sequence unlike previous method the technique guarantee the completeness of the recovered scene ensuring that every scene feature that is detected in each image is reconstructed the approach relies on the presence of four or more reference feature whose correspondence are known in all the image under an orthographic or affine camera model the parallax of the reference feature provides constraint that simplify the recovery of the rest of the visible scene an efficient recursive algorithm is described that us a unified framework for point and line feature the algorithm integrates the task of feature correspondence and structure recovery ensuring that all reconstructible feature are tracked in addition the algorithm is immune to outlier and feature drift two weakness of existing structure from motion technique experimental result are presented for real image 
a new technique exploiting d correlation of d or even d patch between successive frame may be sufficient to compute an estimation of optical flow field sparse measurement are used to compute qualitative property of the flow for different visual task we can combine our technique with a scheme for detecting expansion or rotation in an algorithm which suggests interesting biological implication the algorithm provides a rough estimate of time to crash it is well suited for vlsi implementation it wa tested on real image sequence we show it performance and compare the result to previous approach 
a technique for representing and learning smooth nonlinear manifold is presented and applied to several lip reading task given a set of point drawn from a smooth manifold in an abstract feature space the technique is capable of determining the structure of the surface and of finding the closest manifold point to a given query point we use this technique to learn the space of lip in a visual speech recognition task the learned manifold is used for tracking and extracting the lip for interpolating between frame in an image sequence and for providing feature for recognition we describe a system based on hidden markov model and this learned lip manifold that significantly improves the performance of acoustic speech recognizers in degraded environment we also present preliminary result on a purely visual lip reader 
we describe an efficient algorithm for recognizing d object by combining photometric and geometric invariant a photometric property is derived that is invariant to the change of illumination and to relative object motion with respect to the camera and or the lighting source in d space we argue that conventional color constancy algorithm can not be used in the recognition of d object further we show recognition doe not require a full constancy of color rather it only need something that remains unchanged under the varying light condition and pose of the object combining the derived color invariant and the spatial constraint on the object surface we identify corresponding position in the model and the data space coordinate using centroid invariance of corresponding group of feature position test are given to show the stability and efficiency of our approach to d object recognition 
junction of line or edge are important visual cue in various field of computer vision they are characterized by the existence of more than one orientation at one single point the so called keypoint in this work we investigate the performance of highly orientation selective function to detect multiple orientation and to characterize junction a quadrature pair of function is used to detect line a well a edge and to distinguish between them an associated one sided function with an angular periodicity of can distinguish between terminating and non terminating line and edge which constitute the junction to calculate the response of these function in a continuum of orientation and scale a method is used that wa introduced recently by p perona 
we present a physically based deformable modelwhich can be used to track and to analyze non rigidmotion of dynamic structure in time sequence of d or d medical image the model considers anobject undergoing an elastic deformation a a set ofmasses linked by spring where the natural length ofthe spring is set equal to zero and is replaced by a setof constant equilibrium force which characterize theshape of the elastic structure in the absence of externalforces this model ha 
we address the problem of representing and recognizing arbitrarily curved d rigid object when the object may vary in shape and complexity and no restrictive assumption are made about the type of surface on the object we propose a new and general surface representation scheme for recognizing object with free form sculpted surface from range data in this scheme an object is described concisely in term of maximal surface patch of constant shape index these maximal patch are mapped onto the unit sphere via their orientation and aggregated via shape spectral function property such a surface area curvedness and connectivity that capture local and global information are also built into the representation the scheme yield not only a meaningful and rich surface description useful for the recoverability of the object but also a set of powerful indexing primitive for object matching we demonstrate the generality and the effectiveness of our scheme using real range image of complex object we also present result on the categorization of object view based on a novel shape spectral matching technique 
a major problem associated with geometric hashing and method which have emerged from it is the non uniform distribution of invariant over the hash space this problem can affect the performance of the method significantly finding a good geometric hash function which redistributes the invariant uniformly over the hash space is not easy in this paper a new approach is proposed for alleviating the above problem it is based on the use of an elastic hash table which is implemented a a self organizing feature map neural network sofm nn in contrast to existing approach which try to redistribute the invariant over the hash bin we proceed oppositely spreading the hash bin over the invariant during training the sofm nn resembles an elastic net which deforms over the hash space the objective of the deformation process is to spread more hash bin in hash space area which are heavily occupied and le hash bin in lower density area the advantage of the proposed approach is that it is a process that adapts to the invariant through learning hence it make absolutely no assumption about the statistical characteristic of the invariant and the geometric hash function is actually computed through learning furthermore the well known topology preserving property of the sofm nn guarantee that the computed geometric hash function should be well behaved finally the proposed approach is inherently parallelizable 
recently a novel shape representation of general curvedobjects which is suitable for object recognition ha beenproposed it is based on a set of surface curve namedhot curve defined by the locus of point where a linehas high order tangency with the surface these curvesdetermine the structure of an object s image contour andtheir catastrophic change a nat ural correspondencebetween a point in an intensity image and some of thesecurves can be directly established this 
motion based image segmentation becomes inherently ambiguous when apparent motion of different object are locally or globally similar during a period to disambiguate the segmentation temporal coherence between the local image motion at each edge point and the apparent motion of every object is examined over a long sequence the point is grouped into that segment of the object whose apparent motion is temporally most coherent with the local image motion at the point 
we define a gesture to be a sequence of state in a measurement or configuration space for a given gesture these state are used to capture both the repeatability and variability evidenced in a training set of example trajectory the state are positioned along a prototype of the gesture and shaped such that they are narrow in the direction in which the ensemble of example is tightly constrained and wide in direction in which a great deal of variability is observed we develop technique for computing a prototype trajectory of an ensemble of trajectory for defining configuration state along the prototype and for recognizing gesture from an unsegmented continuous stream of sensor data the approach is illustrated by application to a range of gesture related sensory data the two dimensional movement of a mouse input device the movement of the hand measured by a magnetic spatial position and orientation sensor and lastly the changing eigenvector projection coefficient computed from an image sequence 
given a set of low resolution camera image it is possible to reconstruct high resolution luminance and depth information specially if the relative displacement of the image frame are known we have proposed iterative algorithm for recovering high resolution albedo and depth map that require no a priori knowledge of the scene and therefore do not depend on other method a regard boundary and initial condition the problem of surface reconstruction ha been formulated a one of expectation maximization em and ha been tackled in a probabilistic framework asing markov random field mrf a for the depth map our method is directly recovering surface height without refering to surface orientation whale increasing the resolution by camera jittering conventional statistical model have been coupled with geometrical technique to construct a general model of t he world and the imaging process 
when a lambertian surface is illuminated by severalchromatic light the surface normal may be recoveredfrom a single color image a robust regression is usedto find the ellipsoid in color space on which at leasthalf the pixel lie then the matrix giving the linearrelationship between the color and the surface normal for non outlier point is found a a root of the ellipsoidquadratic form but this root is recovered only upto an arbitrary rotation an integrability condition canbe 
precise segmentation of underlying object in an image is very important especially for biomedical image analysis we present an integrated approach for boundary finding using region and curvature information along with the gradient unlike the previous method where smoothing is enforced by penalizing curvature here the grey level curvature is used a an extra source of information however information fusion may not be useful unless used properly to address that we present result that highlight the pro and con of using the various source of information and indicate when one should get precedence over the others 
a method for localization the act of recognizing the environment is presented the method is based on representing the scene a a set of view and predicting the appearance of novel view by linear combination of the model view the method accurately approximates the appearance of scene under weak perspective projection analysis of this projection a well a experimental result demonstrate that in many case this approximation is s uficient to accurately describe the scene when weak perspective approximation is invalid either a larger number of model can be acquired or an iterative solution to account for the perspective distortion can be employed the method ha several advantage over other approach it us relatively rich representation the representation are d rather than d and localization can be done from only a single d view 
accurate estimation of heart wall dense field motion and deformation could help to better understand the physiological process associated with ischemic heart disease and to provide significant improvement in patient treatment we present a new method of estimating left ventricular deformation which integrates instantaneous velocity information obtained within the mid wall region with shape information found on the boundary of the left ventricle velocity information is obtained from phase contrast magnetic resonance image and boundary information is obtained from shape based motion tracking of the endoand cardial boundary the integration take place within a continuum biomechanical heart model which is embedded in a finite element framework we also employ a feedback mechanism to improve tracking accuracy the integration of the two disparate but complementary source overcomes some of the limitation of previous work in the field which concentrate on motion estimation from a single image derived source 
attitude is the d rotation between the coordinate system of a known object and that of a sensed portion of it surface combination of the support function of a known object with curvature measurement from a visible surface transform attitude determination into optimization problem that can be solved using standard numerical method previous work using the extended gaussian image egi defined for convex polyhedron is extended to the domain of smooth strictly convex object where the egi becomes equivalent to the second curvature function three dimensional shape matching using the first curvature function is new emphasis is placed on theoretical foundation algorithm development and experimental proof of concept using real object and surface data obtained from an existing photometric stereo system 
this paper develops a new class of physic based deformable model which can deform both globally and locally their global parameter are function allowing the definition of new parameterized primitive and parameterized global deformation these new global parameter function improve the accuracy of shape description through the use of a few intuitive parameter such a functional bending and twisting using a physic based approach we convert these geometric model into deformable model that deform due to force exerted from the data point so a to conform to the given dataset we present an experiment involving the extraction of shape and motion of the left ventricle lv of a heart from mri spamm data based on a few global parameter function 
we investigate to what extent texture can be distinguished using conditional markov field and small sample we establish that the least square l estimator is the only reasonable choice for this task and we prove it asymptotic consistency and normality for a general class of random field that include gaussian markov field a a special case the performance of this estimator when applied to textured image of real surface is poor if small box are used spl time or le we investigate the nature of this problem by comparing the behavior predicted by the rigorous theory to the one that ha been experimentally observed our analysis reveal that spl time sample contain enough information to distinguish between the texture in our experiment and that the poor performance mentioned above should be attributed to the fact that conditional markov field do not provide accurate model for textured image of many real surface a more general model that exploit more efficiently the information contained in small sample is also suggested 
address the problem of constructing a complete surface model of an object using a set of registered range image our approach is based on a dynamic balloon model represented by using a triangulated mesh the vertex in the mesh are linked to their neighboring vertex by spring to simulate the surface tension and to keep the shell smooth unlike other dynamic model proposed by previous researcher our balloon model is driven purely by an applied inflation force towards the object surface from inside the object until the mesh element reach the object surface the system includes an adaptive local triangle mesh subdivision scheme that result in an evenly distributed mesh since our approach is not based on global minimization it can handle complex non star shaped object without relying on a carefully selected initial state or encountering a local minimum problem it also allows u to adapt the mesh surface to change in local surface shape and to handle any hole that are present in the input data by adjusting certain system parameter adaptively and locally we present result on some complex non star shaped object from real range image 
the aim of the unmanned ground vehicle ugv project at the university of massachusetts is to develop a system capable of navigating both on road and cross country avoiding obstacle and determining it position using landmark complex problem such a driving can be solved more easily by decomposing them into smaller sub problem solving each sub problem and then integrating the solution in case of an autonomous vehicle the integrated system should be able to react in real time to a changing environment and to reason about way to achieve it goal this paper describes the approach taken on the uma mobile perception laboratory mpl to integrate independent process each solving a particular aspect of the navigation problem into a fully capable autonomous vehicle 
the point distribution model derived by analysing the mode of variation of a set of training example can be a useful tool in machine vision one of the drawback of this approach to date is that the training data is acquired with human intervention where fixed point must be selected by eye from example image a method is described for generating a similar flexible shape model automatically from real image data a cubic b spline is used a the shape vector for training the model large training set are used to generate a robust model of the human profile for use in the labelling and tracking of pedestrian in real world scene furthermore an extended model is described which incorporates direction of motion allowing the extrapolation of direction from shape 
we derive sufficient condition on image structure that permitsdetermination of d motion parameter and depth from motionrelative a rigid surface in front of the camera we assume that only thefirst order spatio temporal derivative or of the image is given and thatthe image intensity is continuously differentiable everywhere or that imagecontours are continuously differentiable this mean that only thecomponent of the image motion field orthogonal to iso intensity contour the so 
uniformly textured surface in d scene provide important cue for image understanding texture can be used for both segmentation and for d shape inference unfortunately virtually all current algorithm are based on assumption that make it impossible to do texture segmentation and shape from texture in the same image texture segmentation algorithm rely on an absence of d effect that tend to distort the texture shape from texture algorithm depend on these effect relying instead on the texture being already segmented to really understand texture in image texture segmentation and shape from texture must be viewed a a combined problem to be solved simultaneously we present a solution to this problem with a region growing algorithm that explicitly account for perspective distortion of otherwise uniform texture we use the image spectrogram to compute local surface normal which are in turn used to frontalize the texture these frontalized texture patch are then subjected to a region growing algorithm based on similarity in the local frequency domain and a minimum description length criterion we show result of our algorithm on real texture image taken in the lab and outdoors 
current approach for detecting periodic motionassume a stationary camera and place limit on an object s motion these approach rely on the assumptionthat a periodic motion project to a set of periodicimage curve an assumption that fails in general using affine invariance we derive necessary and sufficientconditions for an image sequence to be the projectionof a periodic motion no restriction are placedon either the motion of the camera or the object ouralgorithm is shown to 
we address the recovery of segmented d description of an object from intensity image we use three view of an object from slightly different viewpoint a our input for each image we extract a hierarchy of group based on proximity parallelism and symmetry in a robust manner the group in the three image are matched by computing the epipolar geometry for each set of matched group from the three image we then label the contour of the group a true or limb edge using the information about group the label associated with their contour and projective property of subclass of generalized cylinder we infer the d structure of these group the proposed method not only allows robust shape recovery but also produce segmented part our approach can also deal with group generated a a result of texture or shadow on the object we present result on real image of moderately complex object 
we present a class of region growing algorithmsbased on an analogy to a mass suspended in a field offorces the mass represents the growing region andthe field represents the degree of concordance betweenlocal pixel value and the color characteristic of theregion the algorithm are particularly well suited tosystems that are looking for specific simply connectedshapes in local area of interest for example arectangle of unknown size elongation or orientation comparing 
a shape recognition approach is presented uncertainty handling combining and propagation form the heart of the method multiple knowledge source extract information from the segmented image and increase knowledge about undefined shape knowledge source have to be tuned to discriminate shape class and a critical number of independent knowledge source guarantee the classification information provided by the knowledge source is stored in the shafer form of probability mass assignment dempster s rule is used to update belief in class a brief theoretical overview is given combined with a heuristic this method achieves interesting result a well a a short execution time an example derived from an application in the prometheus project consisting of traffic sign recognition on a motorway illustrates this method 
tracking elementary feature and coherently grouping them is an important problem in computer vision and a real challenging feature extraction problem perceptual grouping technique can be applied to some feature tracking problem such an approach is presented in this paper moreover we show how a perceptual grouping problem can be expressed a a global optimization problem in order to solve it we devise an original neural network called pulsed neural network the specific application concerned here is particle tracking velocimetry in fluid mechanic 
a computational framework is introduced for matching a pair of stereo image which in contrast to existing algorithm feature a self contained local matching module cascaded with a global matching module local matching output a d grey scale image in which each and every point ha an intensity measuring the goodness of a possible match global matching reduces to surface detection in this image to detect the surface it is first enhanced employing a hyperpyramid data structure unlike traditional multiresolution approach which are based on the coarse to fine continuation method the author multilevel method emphasizes a fine to coarse process in which local support is accumulated the algorithm is concise efficient and above all give good result for complex scene 
a given overcomplete discrete oriented pymmid may be converted into a steemble pyramid by interpolation we present a technique for deriving the optimal interpolation function otherwise called steering coeficients the proposed scheme is demonstmted on a computationally efficient oriented pyramid which is a variation on the burt and adelson pyramid we apply the generated steerable pyramid to orientation invarianttexture analysis to demonstrate it excellent rotational isotropy high classijcation rate and precise rotation identification are demonstrated 
this paper describes the application of a new spatial domain convolution deconvolution transform s transform for determining distance of object and rapid autofocusing of camera system usingimage defocus the method known a stmap involves simple local operation on only two imagestaken with dierent aperture diameter and can be easily implemented in parallel both image canbe arbitrarily blurred and neither of them need to be a focused image taken with a pin hole camera stmap ha 
we present a novel motion based approach for the part determination and shape estimation of a human s body part the novelty of the technique is that neither a prior model of the human body is employed nor prior body part segmentation is assumed we present a human body part identification strategy hbpis that recovers all the body part of a moving human based on the spatiotemporal analysis of it deforming silhouette we formalize the process of simultaneous part determination and d shape estimation by employing the supervisory control theory of discrete event system in addition in order to acquire the d shape of the body part we present a new algorithm which selectively integrates the segmented by the hbpis apparent contour from three mutually orthogonal view the effectiveness of the approach is demonstrated through a series of experiment where a subject performs a set of movement according to a protocol that reveals the structure of the human body 
discus the basic role of the trifocal tensor in scene reconstruction this spl time spl time tensor play a role in the analysis of scene from three view analogous to the role played by the fundamental matrix in the two view case in particular the trifocal tensor maybe computed by a linear algorithm from a set of line correspondence in three view it is further shown in this paper to be essentially identical to a set of coefficient introduced by shashua to effect point transfer in the three view case this observation mean that the line algorithm may be extended to allow for the computation of the trifocal tensor given any mixture of sufficiently many line and point correspondence from the trifocal tensor the camera image matrix may be computed and the scene may be reconstructed for unrelated uncalibrated camera this reconstruction is unique up to projectivity thus projective reconstruction of a set of line and point may be reconstructed linearly from three view 
we address the problem of scene segmentation and shape recovery from a single real intensity image solving this problem is central to obtaining d scene description in realistic application where perfect data cannot be obtained and only one image is available the method we propose address a large class of generic shape namely straight homogeneous generalized cylinder shgcs it consists of the derivation and use of their geometric projective property in a multi level grouping approach we describe an implemented and working system that detects and recovers full shgc description in the presence of image imperfection such a broken contour surface marking shadow and occlusion we demonstrate our method on complex real image 
this paper proposes an effective next view planning strategy for the object recognition and localization task in a model based robot vision system a set of rule are designed to automatically predict new feature and calculate the next optimal placement of the sensor so that the most useful information can be gathered from multi view a state vector i r t is defined to describe the current state of the vision system and each possible state corresponds to a subset of rule to deal with it the recognition and location task can be described a a process of rule calling and state conversion the most suitable rule is selected at each step to try to acquire more useful information a soon a possible experiment are shown in the paper 
implementation result for projective invariant description of planar curve are presented the paper outline method for the generation of projectively invariant representation of curve segment between bitangent point a well a and this for the first time segment between inflection their usefulness for recognition is illustrated the semi local nature of the invariant description allows recognition of object irrespective of overlap and other image degradation 
this work describes a statistical approach to deal with learning and recognition problem in the field of computer vision an abstract theoretical framework is provided which is suitable for automatic model generation from example identification and localization of object both the learning and localization stage are formalized a parameter estimation task the statistical learning phase is unsupervised with respect to the matching of model and scene feature the general mathematical description yield algorithm which can even treat parameter estimation problem from projected data the experiment show that this probabilistic approach is suitable for solving d and d object recognition problem using grey level image the method can also be applied to d image processing issue using range image i e d input data 
the scale space representation and wavelet transform theory have provided u with good singularity detection framework thanks to such method image understanding process have become more and more powerful some computer vision task also require a knowledge on the nature of detected singularity we propose in this paper to take into account these requirement and we present a singularity detection method based on fractional calculus argument 
this work investigates visual characteristic of specular surface during rotation and give approach to qualitatively identify and quantitatively recover shape of these surface continuous image are taken when an object rotates we look at specularly reflected pattern on the surface and their motion in the epi parallel to the rotation plane from which estimation of each surface point and construction of the object model are carried out we find very simple and direct method to fulfill this objective linear equation for multiple light illumination and a st order differential equation for single light illumination the motion of specular reflection ha nice global characteristic in epi the surface type range from very shiny metal surface to surface with only week specular reflectance we give both simulation and experiment on real object 
an algorithm is described which rapidly verifies the potential rigidity of three dimensional point correspondence from a pair of two dimensional view under perspective projection the output of the algorithm is a simple yes or no answer to the question could these corresponding point from two view be the projection of a rigid configuration potential application include d object recognition from a single previous view and correspondence matching for stereo or motion over widely separated view the rigidity checking problem is different from the structure from motion problem because it is often the case that two view cannot provide an accurate structure from motion estimate due to ambiguity and ill conditioning whereas it is still possible to give an accurate yes no answer to the rigidity question rigidity checking verifies point correspondence using d recovery equation a a matching condition the proposed algorithm improves upon other method that fall under this approach because it work with a few a six corresponding point under full perspective projection handle correspondence from widely separated view make full use of the disparity of the correspondence and is integrated with a linear algorithm for d recovery due to kontsevich result are given for experiment with synthetic and real image data a complete implementation of this algorithm is being made publicly available 
present a new approach for fixing two camera at a single location in a d scene fixation requires the detection of binocular disparity for a single point of interest in the scene so that vergence control can reduce that disparity to zero most existing system use area based matching since feature based matching is computationally prohibitive unfortunately the area based approach doe not perform well when confronted with steeply inclined surface occlusion repeating pattern or featureless image region the method presented in this paper utilizes attentional shift and affine resampling to combat these problem these are integrated with adaptive window size control and coarse to fine correlation based searching the effectiveness of the approach for complex scene is demonstrated with several stereo image pair 
this paper present a novel parameter free techniquefor the segmentation and local description of linestructures on multiple scale both in d and d the algorithm is based on a nonlinear combinationof linear filter and search for elongated symmetricline structure while suppressing the response toedges the filtering process creates one sharp maximumacross the line feature profile and across scalespace the multiscale response reflects local contrastand is independent of the 
this paper present a model based object recognition approach that us a hierarchical gabor wavelet representation the key idea is to use magnitude phase and frequency measure of gabor wavelet representation in an innovative flexible matching approach that can provide robust recognition a gabor grid a topology preserving map efficiently encodes both signal energy and structural information of an object in a sparse multi resolution representation the gabor grid subsamples the gabor wavelet decomposition of an object model and is deformed to allow the indexed object model match with the image data flexible matching between the model and the image minimizes a cost function based on local similarity and geometric distortion of the gabor grid grid erosion and repairing is performed whenever a collapsed grid due to object occlusion is detected the result on infrared imagery are presented where object undergo rotation translation scale occlusion and aspect variation under changing environmental condition 
we present a new method for analyzing the d motion of the heart s left ventricle lv from tagged magnetic resonance imaging mri data our technique is based on the development of a new class of volumetric physic based deformable model whose parameter are function and can capture the local shape variation of an object these parameter require no complex post processing in order to be used by a physician these volumetric model allow the accurate estimation of the shape and motion of the inner and outer wall of the lv a well a within the wall we also present a new technique for calculating force exerted by tagged mri data to material point of the deformable model furthermore by plotting the variation over time of the extracted lv model parameter from normal heart data we are able to quantitatively analyze and compare the epicardial and endocardial motion 
the paper proposes a statistical framework that enables d structure and motion to be computed optimally from an image sequence on the assumption that feature measurement error are independent and gaussian distributed the analysis and result demonstrate that computing both camera scene motion and d structure is essential to computing either with any accuracy having computed optimal estimate of structure and motion over a small number of initial image a recursive version of the algorithm previously reported recomputes sub optimal estimate given new image data the algorithm is designed explicitly for real time implementation and the complexity is proportional to the number of tracked feature d projective affine and euclidean model of structure and motion recovery have been implemented incorporating both point and line feature into the computation the framework can handle any feature type and camera model that may be encapsulated a a projection equation from scene to image 
symmetry is usually viewed a a discrete feature anobject is either symmetric or non symmetric followingthe view that symmetry is a continuous feature acontinuous symmetry measure csm ha been developedto evaluate symmetry of shape and object inthis paper we extend the symmetry measure to evaluatethe symmetry of occluded shape additionally usingthe symmetry measure we reconstruct occluded shapesby locating the center of symmetry of the shape proc cvpr new york 
the problem of tracking a moving object having marking on it surface in front of a static camera is addressed in this case the motion analysis reduces to the problem of tracking these marking from frame to frame the marking are modeled by b spline the problem of establishing the correspondence between the image marking point in the various frame is bypassed by relating the b spline parameter of the same marking viewed at different frame implicit in this relationship are the motion parameter the complexity of the problem is significantly reduced by first acquiring the d object curve structure before the usual motion estimation 
recently there ha been a growing interest in the use of mosaic image to represent the information contained in video sequence the paper systematically investigates how to go beyond thinking of the mosaic simply a a visualization device but rather a a basis for efficient representation of video sequence we describe two different type of mosaic called the static and the dynamic mosaic that are suitable for different need and scenario we discus a series of extension to these basic mosaic to provide representation at multiple spatial and temporal resolution and to handle d scene information we describe technique for the basic element of the mosaic construction process namely alignment integration and residual analysis we describe several application of mosaic representation including video compression enhancement enhanced visualization and other application in video indexing search and manipulation 
we present a practical pattern recognition system that is invariant with respect to translation scale and rotation of object the system is also insensitive to large variation of the threshold used a feature vector zernike moment are used and we compare them with hu s seven moment invariant for a practical machine vision system three key issue are discussed pattern normalization fast computation of zernike moment and classification using k nn rule a testing result the system recognizes a set of alphanumeric machine printed character with different size at arbitrary orientation and with different threshold where the size of the character varies from to pixel 
the author present a hand model that simultaneously satisfies both the synthesis and analysis requirement of model based compression the model can be fitted to any person s hand and can be done using a single camera once the model is fitted to a real human hand it is then used in several tracking scenario in order to verify it effectiveness with successful tracking achieved the model is ready to be incorporated into a virtual environment or model based compression scheme such a sign language communication over telephone line or virtual teleconference over computer network at very low bit rate and at very high image quality 
deformable model have been widely used to approximate object from collected data point but most algorithm based on the deformable model can only handle geometrically and topologically simple object they are inadequate for object with deep cavity or multi part object furthermore they always assume there is only one underlying object for the collected data which mean the segmentation ha been done ahead of time unlike most deformable algorithm which approximate one object at a time our proposed approach can apply simultaneously more than one curve to approximate multiple object using the residual data point the bad part of the fitting curve and appropriate boolean operation our approach is able to detect pattern with hole or cavity and can perform segmentation by itself for more than one underlying object we currently present experiment mainly on d data these d algorithm can be extended to d without theoretical difficulty an experiment on d data composed of two genus i torus is also presented also a new method for defining the external energy is presented which help capture the shape more accurately with low time and reasonable space complexity and a method to prevent self intersection of the curve during evolution is also introduced 
in this work we describe experiment with eigenfaces for recognition and interactive search ina large scale face database accurate visualrecognition is demonstrated using a database ofo face the problem of recognition undergeneral viewing orientation is also examined a view based multiple observer eigenspacetechnique is proposed for use in face recognitionunder variable pose in addition a modulareigenspace description technique is used whichincorporates salient feature 
estimating d motion parameter from three dimensional point correspondence is considered a minimum error in variable formulation of the motion estimation problem is developed to obtain stable and accurate solution and is connected with the ordinary least square formulation of the problem when covariance matrix of d point are known a closed form matrix weighted solution is derived for estimating the motion parameter in the presence of independent and identically distributed i i d gaussian noise in a general case a closed form approximate solution is presented the experimental result demonstrate that the author solution are accurate and reliable in the presence of noise with different deviation 
this paper describes a new approach to the integration and control of continuously operating visual process visual process are expressed a transformation which map signal from virtual sensor into command for device these transformation define reactive process which tightly couple perception and action such transformation may be used to control robotic device including fixation an active binocular head a well a the to select and control the process which interpret visual data this method take inspiration from so called behavioural approach to mobility and manipulation however unlike most previous work we define reactive transformation at the level of virtual sensor and device controller this permit a system to integrate a large number of perceptual process and to dynamically compose sequence of such process to perform visual task the transition between visual process is mediated by signal from a supervisory controller a well a signal obtained from perception this method offer the possibility of constructing vision system with large number of visual ability in a manner which is both scalable and learnable after a review of related work in mobility and manipulation we adapt the reactive process framework to computer vision we define reactive visual process which map information from virtual sensor to device command we discus the selection and control of reactive visual process to accomplish visual task we then illustrate this approach with a system which detects and fixates on different class of moving object 
this article present a new algorithm for segmenting d image it is based on a dynamic triangulated surface and on a pyramidal representation the triangulated surface which can a well modify it geometry a it topology segment image into their component by altering it shape according to internal and external constraint in order to speed up the whole process the surface performs a coarse to fine approach by evolving in a specifically designed pyramid of d image 
address the problem of pose estimation and tracking of vehicle in image sequence from traffic scene recorded by a stationary camera in a new algorithm the vehicle pose is estimated by directly fitting image gradient to polyhedral vehicle model without an edge segment extraction process the new approach is significantly more robust than approach that rely on feature extraction because the new approach exploit more information from the image data we can track vehicle that are partially occluded by textured object e g foliage where classical approach based on edge segment extraction fail result from various experiment with real world traffic scene are presented 
this paper present an efficient biologically inspired early vision architecture the dynamicretina that is well suited to highly active and responsive vision platform the dynamic retina exploitsnormally undesirable camera motion a a necessary step in detecting image contrast by using dynamicreceptive field instead of traditional spatial neighborhood operator we analyze the continuous miniature quot noise quot movement made by active imaging system and show that they can be exploited 
a new algorithm is described for refining the pose of a model of a rigid object to conform more accurately to the image structure elemental d force are considered to act on the model these are derived from directional derivative of the image local to the projected model feature the convergence property of the algorithm is investigated and compared to a previous technique it use in a video sequence of a cluttered outdoor traffic scene is also illustrated and assessed 
a family of qualitative method is described that determinestructure of curve in a scene from their imageprojections in two or more view for example planecurves are distinguished from space curve and spacecurves from contour generator the novelty of theapproach is first it is unaffected by camera intrinsic parameter so calibration is not required second is it also unaffected by camera motion extrinsic parameter so viewer motion or epipolar geometry forstereo need not 
we explore the geometric and algebraic relation that exist between correspondence of point and line in an arbitrary number of image we propose to use the formalism of the grassmann cayley algebra a the simplest way to make both geometric and algebraic statement in a very synthetic and effective way i e allowing actual computation if needed we have a fairly complete picture of the situation in the case of point there are only three type of algebraic relation which are satisfied by the coordinate of the image of a d point bilinear relation arising when we consider pair of image among the n and which are the well known epipolar constraint trilinear relation arising when we consider triple of image among the n and quadrilinear relation arising when we consider four tuples of image among the n in the case of line we show how the traditional perspective projection equation can be suitably generalized and that in the case of three image there exist two independent trilinear relation between the coordinate of the image of a d line 
vista is a software environment supporting the modular implementation and execution of computer vision algorithm because it is extensible portable and freely available vista is an appropriate medium for the exchange of standard implementation of algorithm this paper an overview of vista describes it file format it data abstraction it c onventions for unix filter program and library routine and it user interface toolkit unlike system that are designe d principally to support image processing vista provides fo r the easy creation and use of arbitrary data type such a are needed for many area of computer vision research 
we present an approach for building an affine representation of an unknown curved object viewed under orthographic projection from image of it occluding contour it is based on the observation that the projection of a point on a curved featureless surface can be computed along a special viewing direction that doe not belong to the point s tangent plane we show that by circumnavigating the object on the tangent plane of selected surface point we can compute two orthogonal projection of every point projecting to the occluding contour during this motion and compute the affine coordinate of these point our approach demonstrates that affine shape of curved object can be computed directly i e without euclidean calibration or image velocity and acceleration measurement 
the problem of automatically constructing algebraic surface model from set of d and d image and using these model in pose computation motion and deformation estimation and object recognition are addressed it is proposed that a combination of constrained optimization and nonlinear least square estimation technique be used to minimize the mean squared geometric distance between a set of point or ray and a parameterized surface in modeling task the unknown parameter are the surface coefficient while in pose and deformation estimation task they represent the transformation mapping the observer s coordinate system onto the modeled surface s own coordinate system this approach is applied to a variety of real range computerized tomography ct and video image 
simple constraint on the set of possible surface reflectance and illuminant are exploited in a new color constancy algorithm that build upon forsyth s theory of color constancy the goal defined for a color constancy algorithm is to discount variation in the color and intensity of the incident illumination and thereby extract illumination independent descriptor of surface color from image forsyth s method is based on two constraint first the surface color under a canonical illuminant all fall within an established maximal convex gamut of possible color and second that a diagonal matrix accurately map color between illuminant these constraint taken together turn out to be very effective in solving for color constancy however other strong assumption about the scene are required for the method to work the illumination must be uniform the surface must be planar and there can be no specularities we show that these restriction are necessary only because forsyth set out to recover the intensity of descriptor at the outset we abandon dimensional descriptor recovery in favor of recovering only orientation i e dimension intensity information is factored out of the problem by mapping dimensional r g b camera response onto dimensional chromaticity specifically r b g b we show that this diagonal chromaticity space ha two important property first gamut convexity is preserved and second illumination change is still described by a diagonal matrix it follows that forsyth s algorithm can be directly applied to the recover chromaticity descriptor and from these the d descriptor orientation can be derived the basic algorithm is then extended to include a maximal gamut constraint on the set of illuminant that is analogous to the gamut constraint on surface color the diagonal chromaticity space facilitates the expression of the illumination constraint in the algorithm test on real image show that the algorithm provides good color constancy 
this paper concern the pose determination and recognition of vehicle in traffic scene which under normal condition stand on the ground plane novel linear and closed form algorithm are described for pose determination from an arbitrary number of known line match a form of the generalised hough transform is used in conjuction with explicit probability based voting model to find consistent match the algorithm are fast and robust they cope well with complex outdoor scene 
the paper study the geometry of multi image perspective projection and the matching constraint that this induces on image measurement the combined image projection define a d joint image subspace of the space of combined homogeneous image coordinate this is a complete projective replica of the d world in image coordinate it location encodes the imaging geometry and is captured by the index joint image grassmannian tensor projective reconstruction in the joint image is a canonical process requiring only a simple rescaling of image coordinate reconstruction in world coordinate amount to a choice of basis in the joint image the matching constraint are multilinear tensorial equation in image coordinate that tell whether token in different image could be the projection of a single world token for d image of d point there are exactly three basic type the epipolar constraint a shashua s trilinear one and a new quadrilinear image one for image of line r hartley s trilinear constraint is the only type the coefficient of the matching constraint are tensor built directly from the joint image grassmannian their complex algebraic interdependency is captured by quadratic structural simplicity constraint on the grassmannian 
in this paper a robust method for detecting and recognizing road sign by vision is presented the detection step is based on a geometrical analysis of the edge extracted from monochromatic image and is able to identify triangular and circular road sign from image of city street country road and highway a simple recognition system which validates and classifies the detected road sign greatly improves the reliability and the robustness of the whole system extensive experimentation on real image show that road sign are usually correctly identified even in cluttered image 
we quantify the observation by kender and freudenstein that degenerate view occupy a significant fraction of the viewing sphere surrounding an object this demonstrates that system for recognition must explicitly account for the possibility of view degeneracy we show that view degeneracy cannot be detected from a single camera viewpoint a a result system designed to recognize object from a single arbitrary viewpoint must be able to function in spite of possible undetected degeneracy or else operate with imaging parameter that cause acceptably low probability of degeneracy to address this need we give a prescription for active control of focal length that allows a principled tradeoff between the camera field of view and probability of view degeneracy 
a framework for tracking pointwise periodic non rigid motion of the heart s left ventricular lv wall is presented which incorporates information from two different magnetic resonance imaging mri technique new development in phase contrast cine mr imaging have produced spatial map of instantaneous velocity that heave proven accuracy within the myocardium or wall of the heart this information is combined with shape based matching technique to provide improved estimate of trajectory especially in region where shape information is limited these raw trajectory act a input to a recursive least square rls filter which applies the constraint of temporal periodicity and spatial smoothness for the final estimate the result of the rls filter are compared with the motion of actual implanted marker comparison are also made between exclusively shape based filtered and phase contrast enhanced trajectory estimate using both phantom and actual canine heart mr image 
in any object recognition system a major and primary task is to associate those image feature within an image of a complex scene that arise from an individual object the key idea here is that a geometric class defined in d induces relationship in the image which must hold between point on the image outline the perspective projection of the object the resulting image constraint enable both identification and grouping of image feature belonging to object of that class the class include surface of revolution canal surface pipe and polyhedron recognition proceeds by first recognising an object a belonging to one of the class for example a surface of revolution and subsequently identifying the object for example a a particular vase this differs from conventional object recognition system where recognition is generally targetted at particular object these class also support the computation of d invariant description including symmetry ax canonical coordinate frame and projective signature the constraint and grouping method are viewpoint invariant and proceed with no information on object pose we demonstrate the effectiveness of this class based grouping on real cluttered scene using grouping algorithm developed for rotationally symmetric surface canal surface and polyhedron 
this paper introduces a sensor placement measure called resolvability the measure provides a technique for estimating the relative ability of various visual sensor including monocular system stereo pair multi baseline stereo system and d rangefinder to accurately control visually manipulated object the resolvability ellipsoid illustrates the directional nature of resolvability and can be used to direct camera motion and adjust camera intrinsic parameter in real time so that the servoing accuracy of the visual servoing system improves with camera lens motion the jacobian mapping from task space to sensor space is derived for a monocular system a stereo pair with parallel optical ax and a stereo pair with perpendicular optical ax resolvability ellipsoid based on these mapping for various sensor configuration are presented visual servoing experiment demonstrate that resolvability can be used to direct camera lens motion in order to increase the ability of a visually servoed manipulator to precisely servo object 
we present an approach for identifying the occludingcontour and determining it sidedness using an active i e moving observer it is based on the non stationarity property of the visible rim when the observer s viewpoint ischanged the visible rim is a collection of curve that quot slide quot rigidly or non rigidly over the surface we show that theobserver can deterministically choose three view on thetangent plane of selected surface point to distinguish suchcurves from stationary 
most of the work achieved thus far on aspect graph ha concentrated on the design of algorithm for computing the representation after reviewing how the space of viewpoint can be partitioned in view equivalent cell we work in this paper on a more theoretical level to give enumerative property of the different entity entering in the construction of aspect graph of object bounded by smooth algebraic surface we show how tool from algebraic geometry can be used to compute their 
an approach to labeling the component of human face from range image is proposed the component of interest are those human usually find significant for recognition to cope with the nonrigidity of face a qualitative approach is used the preprocessing stage employ a multi stage diffusion process to identify convexity and concavity point these point are grouped into component and qualitative reasoning about possible interpretation of the component is performed consistency of hypothesized interpretation is carried out using context based reasoning experimental result on real image of several face are provided 
introductiondocument image understanding encompasses thetechnology required to make paper document equivalentto other computer exchange medium like floppy tape and cdroms the physical reader of the paperdocument is the scanner just like the physical reader ofthe floppy is the floppy drive and the physical readerof the tape cartridge is the tape cartridge drive andthe physical reader of the cdrom is the cdrom drive but document image understanding can involvemore than just 
we address the problem to recover the d shape of an unfolded book surface from the shading information in a scanner image from a technical point of view this shape from shading problem in real world environment is characterized by proximal light source interreflection moving light source specular reflection and nonuniform albedo distribution taking all these factor into account we first formulate the problem based on an iterative nonlinear optimization scheme then we introduce piecewise polynomial model of the d shape image restoration experiment for a real book surface demonstrated that geometric and photometric distortion are almost completely removed by the proposed method 
we present a novel approach to reliable and efficient recovery of part description from range image we show that a set of superquadric model can be directly recovered from unsegmented range data a opposed to method which attempt the recovery of volumetric model only after the data ha been pre segmented using extensive pre processing the approach is based on the recover and select paradigm which consists of two intertwined stage model recovery and model selection at the model recovery stage a redundant set of superquadrics is initiated in the image and allowed to grow which involves an iterative procedure combining data classification and parameter estimation all the recovered model are passed to the model selection procedure where only the model resulting in the simplest overall description are selected 
an optical flow determination method is proposed which derives at a location more than two gradient constraint equation with a set of orientation selective spatial gaussian filter the uncertainty measure of an optical flow is also obtained from the equation 
introductionwe have derived a novel approach to the detectionand recognition of human gait in gait detection we find a spatiotemporal pattern thatsignals the presence of a walking person in gaitrecognition we seek to identify the individualwho is walking it is known that human candetect and recognize gait with reduce spatiotemporalsequences such a moving light display and we would like to give similar capabilitiesto machine any reasonable approach to the 
abstract introductionwehave derived a novel approach to the detectionand recognition of human gait in gait detection we nd a spatiotemporal pattern thatsignals the presence of a walking person in gaitrecognition we seek to identify the individualwho is walking it is known that human candetect and recognize gait with reduce spatiotemporalsequences suchasmoving light display and wewould like to give similar capabilitiesto machine any reasonable approach to the interpretation 
in this paper we propose a new statistical framework formodeling and extracting d moving deformable object fromimage sequence the object representation relies on a hierarchicaldescription of the deformation applied to a template global deformation are modeled using a karhunenloeve expansion of the distorsions observed on a representativepopulation local deformation are modeled bya first order markov process the optimal bayesian estimateof the global and local deformation is 
new method are reported for the detection of multiple solution degeneracy when estimating the fundamental matrix with specific emphasis on robustness in the presence of data contamination outlier the fundamental matrix can be used a a first step in the recovery of structure from motion if the set of correspondence is degenerate then this structure cannot be accurately recovered and many solution will explain the data equally well it is essential that we are alerted to such eventuality however current feature matcher are very prone to mismatching giving a high rate of contamination within the data such contamination can make a degenerate data set appear non degenerate thus the need for robust method becomes apparent the paper present such method with a particular emphasis on providing a method that will work on real imagery and with an automated non perfect feature detector and matcher it is demonstrated that proper modelling of degeneracy in the presence of outlier enables the detection of outlier which would otherwise be missed result using real image sequence are presented all processing point matching degeneracy detection and outlier detection is automatic 
a new method to locate human face in a complex background is proposed this system utilizes a hierarchical knowledge based method and consists of three level the higher two level are based on mosaic image at different resolution in the lower level an improved edge detection method is proposed the problem of scale is solved and the system is made more practical so that it can locate unknown human face spanning a wide range of size in a complex black white picture 
we propose a new method for acquiring time sequential range image that provide dense range data in our approach stereo pair of thermal and intensity image are synchronously acquired and are mutually registered the thermal image are segmented into isotemperature region contour based matching is done for the isotemperature region in the thermal image independently at each time instant and by temporal correspondence possible matching pair of contour are generated by evaluating the similarity of the pair consistent and likely pair are chosen to get dense range data intensity profile within the isotemperature region are matched by dynamic programming experiment on real scene including a sequence showing a moving human being show promising result 
a geometric criterion is developed for establishing shape based non rigid correspondence between plane curve unlike previous effort the criterion doe not use rigid invariant of shape instead shape are compared non rigidly from the vantage point of the correspondence geometric invariant are proposed for curve whose shape can be exactly matched by a non rigid correspondence the invariant are based on angular deviation of convex and concave segment of the curve example of correspondence between curve obtained from medical image are provided 
in vision guided robotic operation vision is used for extracting necessary information for achieving the task since visual sensing is usually performed with limited resource visual sensing strategy should be planned so that only necessary information is obtained efficiently this paper describes a method of systematically generating visual sensing strategy based on knowledge of the task to be performed the generation of the appropriate visual sensing strategy entail knowing what information to extract where to get it and how to get it this is facilitated by the knowledge of the task which describes what object are involved in the operation and how they are assembled our method ha been implemented using a laser range finder a the sensor experimental result show the feasibility of the method and point out the importance of task oriented evaluation of visual sensing strategy 
this report discus the problem of recovering d motion and structure for rigid curve for this purpose we use long monocular sequence of image of the curve and compute some set of derivative up to the second order that are dened on the so called spatio temporal surface generated by the curve for general d rigid curve there is exactly one constraint for each image point that relates these derivative to the kinematic screw and it first order time derivative these equation derive 
it ha been established that certain trilinear form of three perspective view give rise to a tensor of intrinsic coefficient we show in this paper that a permutation of the the trilinear coefficient produce three homography matrix projective transformation of plane of three distinct intrinsic plane respectively this in turn yield the result that d invariant are recovered directly simply by appropriate arrangement of the tensor s coefficient on a secondary level we show new relation between fundamental matrix epipoles euclidean structure and the trilinear tensor on the practical side the new result extend the existing envelope of method of d recovery from d view for example new linear method that cut through the epipolar geometry and new method for computing epipolar geometry using redundancy available across many view 
indexing is an efficient method of recovering matchhypotheses in model based object recognition unlikeother method which search for viewpoint invariantshape descriptor to use a index we use a learningmethod to model the smooth variation in appearance oflocal feature set lf indexing from lf effectivelydeals with the problem of occlusion and missing feature the indexing function generated by the learningmethod are probability distribution describing thepossible 
orientation based representation are well suited to vision task including viewpoint independent object recognition and d attitude determination the key property that orientation based representation share is that they rotate in the same way a the object rotates combination of orientation based representation of a model and of a sensed object determine inequality that become equality if and only if the object and model match both in identity and in attitude this result in optimization problem that can be solved by standard numerical method the paper unifies and extends previous work based on the extended gaussian image egi representation it provides the theoretical basis for new approach to object recognition and attitude determination using dense surface data it extends result on convex polyhedron to the domain of smooth strictly convex surface the class of shape covered also is extended to include starshaped set the theoretical result lead to feasible algorithm that are both accurate and robust a proof of concept system ha been implemented and experiment conducted both on synthesized data and on data obtained from real object 
in this paper we present a meth od for reconstructing the three dimensional scene geometry i e depth surface orientation occluding contour and surface crease from a pair of stereo image this reconstruclion is not done a a post processing step but rather of the above quantity are estimated simultaneously a part of the matching algorith m we argue for an energy functional in which each of the quantity in i he scene geometry is ezplicitly represented for this energy functional we use a smooth ness prior which an addition to it ability to detect surface discontinuity and the accompanying half occluded region is able to reconsiruct steeply sloping surface with sharp crease ezperimental result are pmsented demonstrating the effectiveness of the algorithm 
d shape modeling ha been a very prominent part of computer vision over thepast decade several shape modeling technique have been proposed in literature someare local distributed parameter while others are global lumped parameter in termsof the parameter required to describe the shape hybrid model that combine bothends of this parameter spectrum have been in vogue only recently however they donot allow a smooth transition between the two extreme of this parameter 
a new method for acquiring time sequential range image is proposed stereo pair of thermal and intensity image are synchronously acquired and are mutually registered stereo thermal image are segmented into isotemperature region contour based matching is done for the isotemperature region to supplement sparse range data obtained from the contour matching dynamic programming matching is performed for either intensity profile or edge in the stereo intensity image by corresponding pixel pair obtained from the matching process the d coordinate of the point can be calculated experiment with real scene having moving human being show promising result 
people need to calibrate camera system in order to determine the relationship between the position of feature in object space and their corresponding position in the image part of camera calibration is the determination of image center but what is the image center ideally the image center is considered to be the point of intersection of the camera s optical axis with the camera s sensing plane in fact there are many possible definition of image center and in real lens most do not have the same coordinate in addition the image center move a lens parameter are changed in this paper we examine why image center are not necessarily the same for different image property and why they vary with lens parameter we then provide a taxonomy of different image center and describe procedure for measuring them finally we examine the calibration of image center for a variable parameter lens several technique are applied to a precision automated zoom lens and experimental result are shown we conclude that the accuracy of the image center can be an important factor in the accuracy of the overall camera calibration and that the large variation in the position of the image center across different definition and different lens setting make the calibration problem much more complex than is conventionally believed with proper modeling by using correct definition for all image center in a system we can improve the accuracy of our camera calibration 
weak perspective represents a simplified projection model that approximates the imaging process when the scene is viewed under a small viewing angle and it depth relief is small relative to it distance from the viewer we study how to generate dynamic model for estimating rigid d motion from weak perspective a crucial feature in dynamic visual motion estimation is to decouple structure from motion in the estimation model the reason are both geometric to achieve global observability of the model and practical for a structure independent motion estimator allows u to deal with occlusion and appearance of new feature in a principled way it is also possible to push the decoupling even further and isolate the motion parameter that are affected by the so called ba relief ambiguity from the one that are not we present a novel method for reducing the order of the estimator by decoupling portion of the state space from the time evolution of the measurement constraint we use this method to construct an estimator of full rigid motion modulo a scaling factor on a six dimensional state space an approximate estimator for a four dimensional subset of the motion space and a reduced filter with only two state the latter two are immune to the ba relief ambiguity we compare strength and weakness of each of the scheme on real and synthetic image sequence 
the frontier of a curved surface is the envelope of contour generator showing the boundary at least locally of the visible region swept out under viewer motion in general the outline of curved surface apparent contour from different viewpoint are generated by different contour generator on the surface and hence do not provide a constraint on viewer motion we show that frontier point however have projection which correspond to a real point on the surface and can be used to constrain viewer motion by the epipolar constraint we show how to recover viewer motion from frontier point for both continuous and discrete motion calibrated and uncalibrated camera we present preliminary result of an iterative scheme to recover the epipolar line structure from real image sequence using only the outline of curved surface a statistical evaluation a also performed to estimate the stability of the solution 
a stereoscopic scene analysis system for d modeling of object from stereoscopic image sequence is described a dense map of d surface point is obtained by image correspondence object segmentation interpolation and triangulation emphasis is put on the accurate measur ement of image correspondence from grey level image the surface geometry of each scene object is approximated by a triangular wire frame which store the surface texture in texture map sequence processing serf to track camera motion and to fuse surface from different view point into a consistent d surface model from the textured d model highly realistic image sequence from arbitrary view point can be synthesized using computer graphic technique 
discus a nonparametric approach for calibrating a ccd camera a constrained topological mapping ctm approach to analyze the systematic imaging error of an image system and compare it with parametric approach which are based on optimization and have been discussed by many other author this nonparametric approach ha several distinct feature in this approach some distortion surface are derived directly from the training sample because no analytical form of these surface is assumed when we modeled the distortion by a nonparametric model the systematic imaging error instead of mere lens distortion are considered this give an new approach to analyze the imaging error of a particular imaging system experimental result are given in detail which indicate that both in image projection and in d reconstruction the accuracy is much improved when the nonparametric approach is employed for calibrating a camera 
this paper describes an algorithm for stereo tracking using d affine transfer of a body centred fixation point transfer is based on corner detected in the image and matched over time and in stereo the paper present a method of basing the transfer on all the available data providing immunity to noise and poor conditioning the paper also show an implementation at video rate on a four axis active camera platform graceful degradation in the presence of insufficient data and fixed latency tracking in parallel with the structure calculation provide robust performance recovered trajectory are shown in an approximately euclidean frame while structure transfer is demonstrated by the evolution of the target s convex hull 
while researcher in computer vision and pattern recognition have worked on automatic technique for recognizing face for the last year most system specialize on frontal view of the face we present a face recognizer that work under varying pose the difficult part of which is to handle face rotation in depth building on successful template based system our basic approach is to represent face with template from multiple model view that cover different pose from the viewing sphere our system ha achieved a recognition rate of on a data base of people containing testing and modelling view per person 
this paper defines a temporal continuity constraint that express assumption about the evolution of d image velocity or optical flow over a sequence of image temporal continuity is exploited to develop an incremental minimization framework that extends the minimization of a non convex objective function over time within this framework this paper describes an incremental continuation method for recursive non linear estimation that robustly and adaptively recovers optical flow with motion 
the fundamental matrix is a basic tool in the analysis of scene taken with two uncalibrated camera and the point algorithm is a frequently cited method for computing the fundamental matrix from a set of or more point match it ha the advantage of simplicity of implementation the prevailing view is however that it is extremely susceptible to noise and hence virtually useless for most purpose the paper challenge that view by showing that by preceding the algorithm with a very simple normalization translation and scaling of the coordinate of the matched point result are obtained comparable with the best iterative algorithm this improved performance is justified by theory and verified by extensive experiment on real image 
term of feature and their qualitative geometric relationship we propose to detect group using perceptual organization criterion such a proximity symmetry parallelism and closure the detection of these feature is performed in an efficient way using proximity indexing since many group are created we also perform selection of relevant group by organizing them into set of similar perceptual content finally we present an initial implementation of a recognition system using these set a primitive it is an efficient colored graph matching algorithm using the adjacency matrix representation of a graph using indexing we retrieve matching hypothesis which are verified against each other with respect to topological constraint group of consistent hypothesis represent detected model instance in a scene the complete system is illustrated on real image we also discus further extension most object recognition system today address the problem of finding the location and orientation of an exactly known rigid object in a scene grimson s book give a lucid treatment for the geometric constraint used in these approach the presence of a model is inferred by the verification that such a model could indeed produce some of the observed data under an appropriate geometric transform however this approach cannot be extended to more general scenario containing object which may be very similar while being geometrically different consider for instance two different airplane which have similar feature but different geometry in other word generic recognition obviates the use of method based purely on the exact geometric structure of the object it is clear that the only way to solve this difficult problem is to reason about part and their arrangement this argument is supported by biederman s theory which state the sufficiency of a limited number of volumetric component or geons for the task of recognition recovery of part and their arrangement can help fast recognition of object even if they are occluded novel rotated in depth or extensively degraded we therefore have three problem to solve the extraction of primitive the description of scene in term of these primitive and the actual recognition of object in this paper we propose the use of perceptual grouping to approach the problem of generic recognition use of perceptual group is not new a it wa proposed in the s 
the paper address the problem of computing the fundamental matrix which describes a geometric relationship between a pair of stereo image the epipolar geometry we propose a novel method based on virtual parallax instead of computing directly the spl time fundamental matrix we compute a homography with one epipole position and show that this is equivalent to computing the fundamental matrix simple equation are derived by reducing the number of parameter to estimate a a consequence we obtain an accurate fundamental matrix of rank two with a stable linear computation experiment with simulated and real image validate our method and clearly show the improvement over existing method 
we describe a method for computing visual correspondence which employ a formal model of the probability of a false match this model estimate the chance that the best match for each point could have occurred at random the model is effective at identifying point in one image for which there is no corresponding point in the other image a occurs at depth boundary in stereo and at motion boundary in optical flow more generally the model can be used to identify point where the best match is of poor quality a occurs in region of uniform texture we describe the similarity measure used in the method and present the formal model of a false match we also show example of using the method to compute stereo disparity 
this paper present a physic based algorithm for hierarchical shape representation using deformable model with locally adaptive finite element our new adaptive finite element algorithm ensures that during subdivision the desirable finite element mesh generation property of conformity non degeneracy and smoothness are maintained through our algorithm we locally subdivide the triangular finite element based on the distance between the given datapoints and the model in this way we can very efficiently and accurately represent the shape of an object with a resulting small number of model node furthermore using our locally adaptive subdivision algorithm in conjunction with our model s global deformation we construct a hierarchical representation of the given d data 
we address the problem of estimating the position and motion of a human arm in d without any constraint on it behavior and without the use of special marker we model the arm a two truncated right circular cone connected with spherical joint we propose to use a recursive estimator for arm position and to provide the estimator with error signal obtained by comparing the projected estimated arm position with that of the actual arm in the image the system is demonstrated and tested on a real image sequence 
the paper unifies most of the current literature on d geometric invariant from point correspondence across multiple d view by using the tool of elimination from algebraic geometry the technique allows one to predict result by counting parameter and reduces many complicated result obtained in the past reconstructuon from two and three view epipolar geometry from seven point trilinearity of three view the use of a priori d information such a bilateral symmetry shading and color constancy and more into a few line of reasoning each the tool of grobner base computation is used in the elimination process in the process we obtain several result on n view geometry and obtain a general result on invariant function of view and it corresponding quadlinear tensor view admit minimal set of invariant function of quadlinear form with distinct coefficient that can be solved linearly from corresponding point across view this result ha non trivial implication to the understanding of n view geometry we show a new result on single view invariant based on point and show that certain relationship are impossible one of the appealing feature of the elimination approach is that it is simple to apply and doe not require any understanding of the underlying d from d geometry and algebra 
this paper describes the design and implementation ofa single instruction multiple data simd depth frommotionalgorithm on the image understanding architecturesimulator correspondence are established in parallelfor two temporally separated image through correlation the correspondence are used to determine thetranslational and rotational motion parameter of the camerathrough a parallel motion algorithm this is done byfirst determining the approximate translational parametersand 
we present an efficient and geometrically intuitive algorithm to reliably interpret the image velocity of moving object in d it is well known that under weak perspective the image motion of point on a plane can be characterised by an affinetransformation we show that the relative image motion of a nearby noncoplanar point and it projection on the plane is equivalent to motion parallax and because it is independent of viewer rotation it is a reliable geometric cue to d shape and viewer object motion in particular we show how to interpret the motion parallax vector of non coplanar point and contour and the curl divergence and deformation component of the affine transformation defined by the three point or a closed contour of the plane in order to recover the projection of the axis of rotation of a moving object the change in relative position of the object the rotation about the ray the tilt of the surface and a one parameter family of solution for the slant a a function of the magnitude of the rotation of the object the latter is a manifestation of the ba relief ambiguity these measurement although representing an incomplete solution to structure from motion are the only subset of structure and motion parameter which can be reliably extracted from two view when perspective effect are small we present a real time example in which the d visual interpretation of hand gesture or a hand held object is used a part of a man machine interface this is an alternative to the polhemus coil instrumented dataglove commonly used in sensing manual gesture 
in this work we present result from a new formulation fordetermining image velocity from a time sequence of x ray projectionimages of flowing fluid starting with the conservation of mass principle and physic of x ray projection we derive a motion constraint equationfor projection imaging a practical special case of which is shown to bethe horn and schunck s optical flow constraint we are interested in thestudy of non rigid motion of blood which is an incompressible fluid and 
face image are difficult to interpret because they are highly variable source of variability include individual appearance d pose facial expression and lighting we describe a compact parametrised model of facial appearance which take into account all these source of variability the model represents both shape and grey level appearance and is created by performing a statistical analysis over a training set of face image a robust multi resolution search algorithm is used to fit the model to face in new image this allows the main facial feature to be located and a set of shape and grey level appearance parameter to be recovered a good approximation to a given face can be reconstructed using le than of these parameter this representation can be used for task such a image coding person identification pose recovery gender recognition and expression recognition the system performs well on all the task listed above 
we present result using a markov random field color texture model for the unsupervised segmentation of image of outdoor scene the color random field model describes textured region in term of spatial interaction within color band and between different color band the model is used by a segmentation algorithm based on agglomerative hierarchical clustering at the heart of the clustering is a step wise optimal merging process that at each iteration maximizes a global performance functional the test for stopping the clustering is based on change in the likelihood of the image we provide experimental result that demonstrate the performance of the segmentation algorithm on color image of natural scene most of the processing during segmentation is local making the algorithm amenable to high performance parallel implementation 
this paper describes a hierarchical estimation framework for the computation of diverse representation of motion information the key feature of the resulting framework or family of algorithm are a global model that constrains the overall structure of the motion estimated a local model that is used in the estimation process and a coarse fine refinement strategy four specific motion model affine flow planar surface flow rigid body motion and general optical flow are described along with their application to specific example 
unlike existing global shape from shading algorithm which involve the brightness constraint in their formulation we propose a new algorithm which replaces the brightness constraint by an intensity gradient constraint this is a global approach which obtains the solution by the minimization of an error function over the entire image through the linearization of the reflectance map and the discretization of the surface gradient the intensity gradient can be expressed a a linear function of the surface height a quadratic error function which involves the intensity gradient constraint and the traditional smoothness constraint is minimized efficiently by solving a sparse linear system using the multigrid technique neither the information at singular point nor the information at occluding boundary is needed for the initialization 
the computation of optical flow relies on merging information available over an image patch to form an estimate of d image velocity at a point this merging process raise a host of issue which include the treatment of outlier in component velocity measurement and the modeling of multiple motion within a patch which arise from occlusion boundary or transparency we present a new approach for dealing with these issuesm which s based on the use of a probabilistic mixture model to 
previous effort at facial expression recognition have been based on the facial action coding system facs a representation developed in order to allow human psychologist to code expression from static facial mugshot we develop new more accurate representation for facial expression by building a video database of facial expression and then probabilistically characterizing the facial muscle activation associated with each expression using a detailed physical model of the skin and muscle this produce a muscle based representation of facial motion which is then used to recognize facial expression in two different way the first method us the physic based model directly by recognizing expression through comparison of estimated muscle activation the second method us the physic based model to generate spatio temporal motion energy template of the whole face for each different expression these simple biologically plausible motion energy template are then used for recognition both method show substantially greater accuracy at expression recognition than ha been previously achieved 
we present an active object recognition strategy which combine the use of an attentionmechanism for focusing the search for a d object in a d image with a viewpoint controlstrategy for disambiguating recovered object feature the attention mechanism consists of aprobabilistic search through a hierarchy of predicted feature observation taking object into aset of region classified according to the shape of their bounding contour we motivate the useof image region a a 
the problem of d shape description particularly with contour partitioning grouping and classification in term of straight and curved based on the minimum description length mdl criterion and shape fitting technique is discussed the mdl criterion is used to detect outlier in connection with shape fitting using the mdl criterion it is possible to derive for a given data set and a class of model a description which best explains the data a new algorithm for fitting d point to an ellipse is presented 
for a number of computational purpose including visualization of scientific data and registration of multimodal medical data smooth curve must be approximated by polygonal curve and surface by polyhedral surface an inherent problem of these approximation algorithm is that the resulting curve and surface appear faceted boundary following and iso surface construction algorithm are typical example to reduce the apparent faceting smoothing method are used in this paper we introduce a new method for smoothing piecewise linear shape of arbitrary dimension and topology this new method is in fact a linear low pas filter that remove high curvature variation and doe not produce shrinkage it computational complexity is linear in the number of edge or face of the shape and the required storage is linear in the number of vertex 
to alleviate the problem of overwhelming complexity in grasp synthesis and path planning associated with robot task planning we adopt the approach of teaching the robot by demonstrating in front of it the system ha four component the observation system the grasping task recognition module the task translator and the robot system the observation system comprises an active multibaseline stereo system and a dataglove the data stream recorded is then used to track object motion this paper illustrates how complimentary sensory data can be used for this purpose the data stream is also interpreted by the grasping task recognition module which produce higher level of abstraction to describe both the motion and action taken in the task the resulting information are provided to the task translator which creates command for the robot system to replicate the observed task in this paper we describe how these component work with special emphasis on the observation system the robot system that we use to perform the grasping task comprises the puma arm and the utah mit hand 
the paper describes a novel approach to relational matching problem in machine vision rather than matching static scene description the approach adopts an active representation of the data to be matched this representation is iteratively reconfigured to increase it degree of topological congruency with the model relational structure in a reconstructive matching process the active reconfiguration of relational structure is controlled by a map update process the final restored graph representation is optimal in the sense that it ha maximum a posteriori probability with respect to the available attribute for the object under match the benefit of the technique are demonstrated experimentally on the matching of cluttered synthetic aperture radar data to a model in the form of a digital map the operational limit of the method are established in a simulation study 
this paper present a framework for implicit deformable model and a pair of new algorithm for solving the nonlinear partial differential equation that result from this framework implicit model offer a useful alternative to parametric model particularly when dealing with the deformation of higher dimensional object the basic expression for the evolution of implicit model are relatively straightforward they follow a a direct consequence of the chain rule for differentiation more challenging however is the development of algorithm that are stable and efficient the first algorithm is a viscosity approximation which give solution over a dense set in the range providing a mean of calculating the solution of embedded family of contour simultaneously the second algorithm incorporates sparse solution for a discrete set of contour this sparse field method requires a fraction of the computation compared to the first but offer solution only for a finite number of contour result from d medical data a well a video image are shown 
we have built a high speed physically robust stereo ranging system we describe our experience with this system on several autonomous robot vehicle we use a custom built trinocular stereo jig and three specially modified ccd camera stereo matching is per ormed using the sum ofsum of squared difference technique 
this paper describes a comparative study of reconstruction algorithm from sequence of image comparing algorithm which make the weak perspective assumption also called scaled orthography or para perspective to algorithm assuming perspective projection the weak perspective assumption is usually employed to simplify the computation using three sequence of real image taken under condition corresponding to small medium and large field of view we compare two algorithm that compute invariant shape from motion one assumes scaled orthography and one assumes perspective projection 
we present a mathematical formulation for curve and surface reconstruction algorithm by introduction of auxiliary variable for deformable model and template two step iterative algorithm have been often used where at each iteration the model is first locally deformed according to the potential data attraction and then globally smoothed we show how these approach can be interpreted a the introduction of auxiliary variable and the minimization of a two variable energy this permit u to transform an implicit data constraint defined by a non convex potential into an explicit convex reconstruction problem we show some mathematical property and result on this new auxiliary problem in particular when the potential is a function of the distance to the closest feature point we then illustrate our approach for some deformable model and template and image restoration 
we propose a shape representation scheme which allows two shape to be combined into a single model the desired region of the two shape are selected and then merged together forming a blended shape for reconstruction blending is incorporated into a deformable model framework the model automatically adapts to the data blending when necessary hierarchical blending allows multiple blend of a shape to occur forming an evolution from the initial shape of a sphere to the final shape blending also allows the insertion of a hole between arbitrary location the model used are globally defined making the recovered shape a natural symbolic description we present reconstruction experiment involving shape of various topology 
a model based approach to on line cursive handwriting analysis and recognition is presented and evaluated in this model on line handwriting is considered a a modulation of a simple cycloidal pen motion described by two coupled oscillation with a constant linear drift along the line of the writing by slow modulation of the amplitude and phase lag of the two oscillator a general pen trajectory can be efficiently encoded these parameter are then quantized into a small number of value without altering the writing intelligibility a general procedure for the estimation and quantization of these cycloidal motion parameter for arbitrary handwriting is presented the result is a discrete motor control representation of the continuous pen motion via the quantized level of the model parameter this motor control representation enables successful word spotting and matching of cursive script our experiment clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition 
this paper study the problem of obtaining depth information from focusing anddefocusing which have long been noticed a important source of depth informationfor human and machine vision in depth from focusing we try to eliminate the localmaxima problem which is the main source of inaccuracy in focusing in depth fromdefocusing a new computational model is proposed to achieve higher accuracy the major contribution of this paper are in depth from focusing instead ofthe popular 
image displacement field optical flow field stereo disparity field normal flow field due to rigid motion posse a global geometric structure which is independent of the scene in view motion vector of certain length and direction are constrained to lie on the imaging surface at particular locus whose location and form depends solely on the d motion parameter if optical flow field or stereo disparity field are considered then equal vector are shown to lie on conic section similarly for normal motion field equal vector lie within region whose boundary also constitute conic by studying various property of these curve and region and their relationship a characterization of the structure of rigid motion field is given the goal of this paper is to introduce a concept underlying the global structure of image displacement field this concept give rise to various constraint that could form the basis of algorithm for the recovery of visual information from multiple view 
this paper give a practical algorithm for the selfcalibration of a camera from several view the method involves non iterative method for finding an initial calibration for the camera followed by leastsquares iteration to an optimum solution at the same time a scaled euclidean reconstruction of the scene appearing in the image is computed 
wet surface are ubiquitous in our visual experience autonomous machine with vision system will need to identify wet surface from dry wet surface especially rough absorbent one appear darker when wet this paper present the lekner and dorf model for describing the darkening caused by wetting we explain how to use this optic model to transform intensity value of a region of an image to make that region appear wet we also show how the model can be reversed in order to make a wet part of an image appear dry it is also shown that this technique can be used to identify wet region this identification is contrasted with darkening caused by shadow comparison of the gray level histogram of these real image show the validity of this approach for distinguishing wet surface from dry 
the paper describes an approach to detect face whose size and position are unknown in an image with a complex background the candidate of face are detected by finding out face like region in the input image using the fuzzy pattern matching method the perceptually uniform color space is used in our research in order to obtain reliable result the skin color that is used to detect face like region is represented by a model developed by u called skin color distribution function the skin color region are then extracted by estimating a measure that describes how well the color of a pixel look like the skin color for each pixel in the input image the face which appear in image are modeled a several dimensional pattern the face like region are extracted by a fuzzy pattern matching approach using these face model the face candidate are then verified by estimating how well the extracted facial feature fit a face model which describes the geometrical relation among facial feature 
it is possible to recover the three dimensional structure of a scene using image taken with uncalibrated camera and pixel correspondence betweeen these image but such reconstruction can only be performed up to a projective transformation of the d space therefore constraint have to be put on the reconstructed data to get the reconstruction in the euclidean space such constraint arise from knowledge of the scene such a the location of point geometrical constraint on line etc the kind of constraint that have to be added are discussed and it is shown how they can be fed in a general framework experimental result on real data prove the feasibility and experiment on simulated data address the accuracy of the result 
the joint invariant of a pair of coplanar conic ha been widely used in recent vision literature in this paper the algebraic invariant of a pair of non coplanar conic in space is concerned the algebraic invariant of a pair of non coplanar conic is first derived from the invariant algebra of a pair of quaternary quadratic form by using the dual representation of space conic then this algebraic invariant is geometrically interpreted in term of cross ratio finally an analytical procedure for projective reconstruction of a space conic from two uncalibrated image is developed and the correspondence condition of the conic between two view are also explicited 
the ability to control egomotion using low resolutionperipheral vision is crucial for enablinga small high resolution fovea to attend to featuresthat require detailed examination the beebotdemonstrates the ability to use low resolutionmotion vision over large field of view to steer betweenobstacles the system us the maximumflow observed in left and right peripheral visualfields to indicate obstacle proximity each peripheralfield constitutes one third of a wide anglelens the 
from sphere image we have developed a new method for camera calibration in order to calculate with accuracy it intrinsic parameter we prove an interesting geometric propriety about ellipsis extracted from sphere image taking into account the lens geometrical distortion introduced by the optical system and searching a precise point detection for sphere image permit to obtain satisfactory result 
illumination is rarely constant in intensity or color throughout a scene multiple light source with different spectrum sun and sky direct and interreflected light are the norm nonetheless almost all color constancy algorithm assume that the spectrum of the incident illumination remains constant across the scene we assume the converse that illumination doe vary in developing a new algorithm for color constancy rather than creating difficulty varying illumination is in fact a very powerful constraint indeed test of our algorithm using real image of an office scene show excellent result 
the fundamental matrix is a key concept when working withuncalibrated image and multiple viewpoint it contains all the availablegeometric information and enables to recover the epipolar geometry fromuncalibrated perspective view this paper is about a stability analysisfor the fundamental matrix we first present a probabilistic approachwhich work well this approch however doe not give insight into thecauses of unstability two complementary explanation for unstabilityare the 
in this paper we present modeling analysis and synthesisof visual behavior of agent engaged in navigationaltasks we consider situation in which twoagents can navigate independently or in cooperation for the purpose of modeling the behavior we haveadopted a formalism from the discrete event system de theory suitable for investigating controltheoreticissues of a system the focus of this paperis on the identification of elementary behavior andtheir composition leading to more 
the optical flow constitutes one of the most widely adopted representation to define and characterize the evolution of image feature over time in order to compute the velocity field it is necessary to define a set of constraint on the temporal change of image feature we consider the implication in using multiple constraint arising from multiple data point the first step is the analysis of differential constraint and how they can be applied locally to compute the image velocity this analysis allows to relate each constraint to a particular gray level pattern this approach is extended to multiple image point allowing also the characterization of the temporal behaviour of the image feature and to detect erroneous measurement due to occlusion depth discontinuity or shadow several experiment are presented from real image sequence 
we present an algorithm based on mrf modelling for motion detection in image sequence and give a modified version for implementation on analog resistive network energy minimization is realized by a network relaxing to it state of minimal power dissipation it take a few nanosecond and replaces advantageously time consuming stochastic or suboptimal deterministic relaxation algorithm the elementary cell of the network is presented along with the environment needed to feed it with the required input two network architecture are proposed derived from ccd camera principle software simulation of a network demonstrate the good behaviour of the modified algorithm on real sequence electrical simulation of a network with ideal component give promising result implementation of the cmos circuit with vlsi technology is under study at our laboratory 
this paper considers the problem of modeling and extracting arbitrary deformable contour from noisy image we propose a global contour model based on a stable and regenerative shape matrix which is invariant and unique under rigid motion combined with markov random field to model local deformation this yield prior distribution that exerts influence over a global model while allowing for deformation we then cast the problem of extraction into posterior estimation and show it equivalence to energy minimization of a generalized active contour model we discus pertinent issue in shape training energy minimization line search strategy minimax regularization and initialization by generalized hough transform finally we present experimental result and compare it performance to rigid template matching 
a unified differential geometric framework for estimation of local surface shape and orientation from projective texture distortion is proposed based on a differential version of the texture stationarity assumption introduced by malik and rosenholtz this framework allows the information content of the gradient of any texture descriptor defined in a local coordinate frame to be characterized in a very compact form the analysis encompasses both full affine texture descriptor and the classical texture gradient for estimation of local surface orientation and curvature from uncertain observation of affine texture distortion the proposed framework allows the dimensionality of the search space to be reduced from five to one 
motion based recognition deal with the recognition of object or motion directly from the motion information extracted from a sequence of image there are two main step in this approach the first consists of finding an appropriate representation for the object or motion from the motion cue of the sequence and then organize them into useful representation the second step consists of the matching of some unknown input with a model this paper provides a review of recent development in motion based recognition 
in this paper we analyze the geometric active contour model discussed previously from a curve evolution point of view and propose some modification based on gradient flow relative to certain new feature based riemannian metric this lead to a novel snake paradigm in which the feature of interest may be considered to lie at the bottom of a potential well thus the snake is attracted very naturally and efficiently to the desired feature moreover we consider some d active surface model based on these idea 
the standard method for extracting range data from optical triangulation scanner are accurate only for planar object of uniform reflectance illuminated by an incoherent source using these method curved surface discontinuous surface and surface of varying reflectance cause systematic distortion of the range data coherent light source such a laser introduce speckle artifact that further degrade the data we present a new ranging method based on analyzing the time evolution of the structured light reflection using our spacetime analysis we can correct for each of these artifact thereby attaining significantly higher accuracy using existing technology we present result that demonstrate the validity of our method using a commercial laser stripe triangulation scanner 
shadow are a frequent occurrence but they cannot be infallibly recognized until a scene s geometry and lighting are known we present a number of cue which together strongly suggest the identification of a shadow and which can be examined with low cost the technique are a color image segmentation method that recovers single material surface a single image region irregardless of the surface partially in shadow a method to recover the penumbra and umbra of shadow a method for determining whether some object could be obstructing a light source the last cue requires the examination of well understood shadow in the scene our observer is equipped with an extendable probe for casting it own shadow actively obtained shadow allow the observer to experimentally determine the location of the light source in the scene the system ha been tested both indoors and out 
present a new approach to rendering arbitrary view of real world d object of complex shape we propose to represent an object by a sparse set of corresponding d view and to construct any other view a a combination of these reference view we show that this combination can be linear assuming proximity of the view and we suggest how the visibility of constructed point can be determined our approach make it possible to avoid difficult d reconstruction assuming only rendering is required moreover almost no calibration of view is needed we present preliminary result on real object indicating that the approach is feasible 
this paper present a method for localization of modeled object that is general enough to cover articulated and other type of constrained model the flexibility between component of the model are expressed a spatial constraint which are fused into the pose estimation process the constraint fusion assist in obtaining a precise and stable pose of each object s component and in finding the correct interpretation the proposed method can handle any constraint including inequality between any number of different component of the model the framework is based on kalman filtering 
this paper explores the use of local parametrized model of image motion for recovering and recognizing the non rigid and articulated motion of human face parametric flow model for example affine are popular for estimating motion in rigid scene we observe that within local region in space and time such model not only accurately model non rigid facial motion but also provide a concise description of the motion in term of a small number of parameter these parameter are intuitively related to the motion of facial feature during facial expression and we show how expression such a anger happiness surprise fear disgust and sadness can be recognized from the local parametric motion in the presence of significant head motion the motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiment involving subject a well a in television and movie sequence 
we present a self organizing framework called the shoslif m for learning and recognizing spatiotemporal event or pattern from intensity image sequence the proposed framework consists of a multiclass multivariate discriminant analysis to automatically select the most discriminating feature mdf a space partition tree to achieve a logarithmic retrieval time complexity for a database of n item and a general interpolation scheme to do view inference and generalization in the mdf space based on a small number of training sample the system is tested to recognize different hand sign the experimental result show that the learned system can achieve a recognition rate for test sequence that have not been used in the training phase 
edge corner and vertex are strong and useful feature in computervision this paper deal with the development of an efficient modelbased approach in order to detect and characterize precisely these importantfeatures the key of our approach is first to propose some efficient modelsassociated to each of these feature and second to efficiently extract and characterizethese feature directly from the image the model associated to eachfeature include a large number of intrinsic 
this paper present a new algorithm for structure from motion from an arbitrary number of tracked feature over an arbitrary number of image which posse several advantage over previous formulation first it is recursive so the time complexity is independent of the number of image the complexity is linear with the number of tracked feature the algorithm allows newly appeared feature to be included stale feature to be discarded and missing data to be handled naturally dynamic outlier elimination is achieved without recourse to heuristic segmentation strategy lastly the algorithm can employ different kind of tracked feature e g edge and corner in the same framework the actual structure from motion recovered is affine which assumes limited depth variation within the field of view but the recovery is based on a more general recursive estimation algorithm known a the variable state dimension filter vsdf which we devised and applied earlier to active camera calibration result are presented for real image sequence and timing for the algorithm demonstrate the feasibility for real time implementation 
a method for matching d curve under euclideanmotions is presented our approach us a semidifferentialinvariant description requiring only firstderivatives and one reference point thus avoidingthe computation of high order derivative a novelcurve similarity measure building on the notion offfl reciprocal correspondence is proposed it is shownthat by combining ffl reciprocal correspondence with therobust least median of square motion estimation theregistration of partially 
this paper present a new method of recognizing facial expression using a two dimensional physical model named potential net the advantage of the method is not to need extracting facial feature from an image so that it is robust for variation of illumination and facial individuality potential net is a physical model which consists of node connected by spring in two dimensional grid configuration this net is set on a facial image and is deformed by image force which move the node to position near to facial feature recognition is executed by analyzing the similarity between model net prepared previously and a net deformed by an input image 
the paper describes an approach to the tracking of complex shape through image sequence that combine deformable region model and deformable contour a deformable region model is presented it optimisation is based on texture correlation and is constrained by the use of a motion model such a rigid affine or homographic the use of texture information versus edge information noticeably improves the tracking performance of deformable model in the presence of texture then the region contour is refined using an edge based deformable model in order to better deal with specularities non planar object and occlusion the method is illustrated and validated by experimental result on real image 
this paper discus the problem of predicting image feature in an image from image feature in two other image and the epipolar geometry between the three image we adopt the most general camera model of perpective projection and show that a point can be predicted in the third image a a bilinear function of it image in the first two camera that the tangent to three corresponding curve are related by a trilinear function and that the curvature of a curve in the third image is a linear function of the curvature at the corresponding point in the other two image we thus answer completely the following question given two view of an object what would a third view look like we show that in the special case of orthographic projection our result for point reduce to those of ullman and basri we demonstrate on synthetic a well a on real data the applicability of our theory 
focus on approximating object part shape by distinctive type of volumetric primitive shape approximation is accomplished by fitting volumetric model called parametric geons to multiview range data of single part object and classifying the fitting residual parametric geons are seven qualitative shape type defined by parameterized equation which control the size and degree of tapering and bending model fitting is performed by minimizing an objective function which measure the similarity in both size and shape between model and object multiple view data global shape constraint and global optimization are employed to obtain unique model and to compensate for noise and minor variation in object shape this approach ha been studied in experiment with both synthetic d data and actual rangefinder data of perfect and imperfect geon like object 
we suggest an approach to describing and tracking the deformation of facial feature we concentrate on the mouth since it shape is important in detecting emotion however we believe that our system could be extended to deal with other facial feature in our system the mouth is described by a valley contour which is based between the lip this contour is shown to exist independently of illumination viewpoint identity and expression we present a real time mouth tracking system that follows this valley it is shown to be robust to change in identity illumination and viewpoint a simple classification algorithm wa found to be sufficient to discriminate between different mouth shape with a recognition rate 
from the publisher markov random field mrf theory provides a basis for modeling contextual constraint in visual processing and interpretation it enables u to develop optimal vision algorithm systematically when used with optimization principle this book present a comprehensive study on the use of mrfs for solving computer vision problem the book cover the following part essential to the subject introduction to fundamental theory formulation of mrf vision model mrf parameter estimation and optimization algorithm various vision model are presented in a unified framework including image restoration and reconstruction edge and region segmentation texture stereo and motion object matching and recognition and pose estimation this book is an excellent reference for researcher working in computer vision image processing statistical pattern recognition and application of mrfs it is also suitable a a text for advanced course in these area 
the problem of accurate depth estimation using stereo in the presence of specular reflection is addressed specular reflection a fundamental and ubiquitous reflection mechanism is viewpoint dependent and can cause large intensity difference at corresponding point resulting in significant depth error we analyze the physic of specular reflection and the geometry of stereopsis which led u to a relationship between stereo vergence surface roughness and the likelihood of a correct match given a lower bound on surface roughness an optimal binocular stereo configuration can be determined which maximizes precision in depth estimation despite specular reflection however surface roughness is difficult to estimate in unstructured environment therefore trinocular configuration independent of surface roughness are determined such that at each scene point visible to all sensor at least one stereo pair can compute produce depth we have developed a simple algorithm to reconstruct depth from the multiple stereo pair 
this paper deal with the recovery of d information using a single mobile camera in the context of active vision we propose a general revisited formulation of the structure from motion issue and we determine adequate camera configuration and motion which lead to a robust and accurate estimation of the d structure parameter we apply the visual servoing approach to perform these camera motion real time experiment dealing with the d structure estimation of point and cylinder are reported and demonstrate that this active vision strategy can very significantly improve the estimation accuracy 
the author describe a framework for establishing correspondence computing canonical description and recognizing object that is based on the idea of describing object by their generalized symmetry a defined by the object s free vibration mode a technique given by a pentland and s scarloff described object in term of the mode of some prototype shape in contrast this new method computes the object s mode directly from available image information this result in greater generality and accuracy and is applicable to data of any dimensionality for the purpose of illustration a detailed mathematical formulation of the method is given for d problem and it is demonstrated on gray scale image and contour data 
when a plane undergoes a deformation that can be represented by a planar linear vector field the projected vector field on the image plane of an optical device is at most quadratic this d motion field ha one singular point with eigenvalue identical to those of the singular point describing the deformation a a consequence the nature of the singular point of the deformation is a projective invariant when the plane move and experience a linear deformation at the same time the associated d motion field is still quadratic with at most singular point in the case of a normal rototranslation i e when the angular velocity is normal to the plane and of a linear deformation the d motion field ha at most one singular point and substantial information on the rigid motion and on the deformation can be recovered from it experiment with simulated deformation and real deformable object show that the proposed analysis can provide accurate result and information on more general d deformation 
individual cue from visual module are fallible and oftenambiguous a a result only integrated vision systemscan be expected to give a reliable performance in practice the design of such system is challenging since eachvision module work under different and possibly conflictingsets of assumption we have proposed and implementeda multiresolution system which integrates perceptualgrouping segmentation stereo shape from shading and line labelling module the output of the 
this paper present a new algorithm for locatingthe boundary of textured region both step changesand outlier using a robust estimator previous robustimage filter perform poorly on binary image blur edge round corner and run slowly i avoidartifacts on binary image by modelling them a continuousand interpolating value information is combineddirectly between non adjacent location to preventblurring corner are sharpened by relabellingmis classified pixel the 
we consider the problem of robustly estimating optical flow from a pair of image using a new framework based on robust estimation which address violation of the brightness constancy and spatial smoothness assumption we also show the relationship between the robust estimation framework and line process approach for coping with spatial discontinuity in doing so we generalize the notion of a line process to that of an outlier process that can account for violation in both the 
researcher in computer vision have primarily studied the problem of visual reconstruction of environmental structure that is plainly visible in this thesis the conventional goal of visual reconstruction are generalized to include both visible and occluded forward facing surface this larger fraction of the environment is termed the it anterior surface because multiple anterior surface neighborhood project onto a single image neighborhood wherever surface overlap surface neighborhood and image neighborhood are not guaranteed to be in one to one correspondence a conventional shape from method assume the result is that the topology of three dimensional scene structure can no longer be taken for granted but must be inferred from evidence provided by image contour where boundary are not occluded and where surface reflectance is distinct from that of the background boundary will be marked by image contour however where boundary are occluded or where surface reflectance match background reflectance there will be no detectable luminance change in the image deducing the complete image trace of the boundary of the anterior surface under these circumstance is called the it figural completion problem in this thesis we show that the boundary of the anterior surface can be represented in viewer centered coordinate a a it labeled knot diagram the interior neighborhood of the anterior surface are explicitly represented by a combinatorial model called a it paneling which is produced from a labeled knot diagram by mean of a straightforward construction conventional shape from method formulated a variational problem and defined over image neighborhood can be applied to the neighborhood of the paneling equally well the labeling scheme and paneling construction provide a solid theoretical foundation for a working experimental system which computes surface representation from illusory contour display including well known figure from the visual psychology literature the experimental system employ a two stage process of completion hypothesis and combinatorial optimization the labeling scheme is enforced by a system of integer linear inequality so that the final organization is the optimal feasible solution of an integer linear program 
the paper describes a new approach to image segmentation it accepts the inherent deficiency occuring when extracting low level feature and when dealing with the complexity of real scene image segmentation therefore is understood a deriving a rich symbolic description useful for task such a stereo or object recognition in outdoor scene the approach is based on a polymorphic scheme for simultaneously extracting point line and segment in a topologically consistent manner together with their mutual relation derived from the feature adjacency graph fag thereby performing several grouping step which gradually use more and more specific domain knowledge to achieve an optimal image description the heart of the approach is a detailed analysis of the fag and a robust estimation for validating the found geometric hypothesis the analysis of the fag derived from the exoskeleton of the feature allows to detect inconsistency of the extracted feature with the ideal image model a cell complex the fag is used for finding hypothesis about incidence relation and geometric hypothesis such a collinearity or parallelity also between non neighbored point and line the m type robust estimation is used for simultaneously eliminating wrong hypothesis on geometric relationship it us a new argument for the weighting function 
the paper give a practical rapid algorithm for doing projective reconstruction of a scene consisting of a set of line seen in three or more image with uncalibrated camera the algorithm is evaluated on real and ideal data to determine it performance in the presence of varying degree of noise by carefully consideration of source of error it is possible to get accurate reconstruction with realistic level of noise the algorithm can be applied to image from different camera or the same camera for image with the same camera with unknown calibration it is possible to do a complete euclidean reconstruction of the image this extends to the case of uncalibrated camera previous result of spetsakis and aloimonos on scene reconstruction from line 
visual motion estimation can be regarded a estimation of the state of a system of differenceequations with unknown input defined on a manifold such a system happens to be quot linear quot but it is defined on a space the so called quot essential manifold quot which is not a linear vector space in this paper we will introduce a novel perspective for viewing the motion estimation problemwhich result in three original scheme for solving it the first consists in quot flattening the space quot and 
we propose and demonstrate a new paradigm for active vision research that draw upon recent advance in the field of artificial life and computer graphic a software alternative to the prevailing hardware vision mindset animat vision prescribes artificial animal or animats situated in physic based virtual world a autonomous virtual robot possessing active perception system to be operative in it world an animat must autonomously control it eye and muscle actuated body applying computer vision algorithm to continuously analyze the retinal image stream acquired by it eye in order to locomote purposefully through it world we describe an initial animat vision implementation within lifelike artificial fish inhabiting a physic based virtual marine world emulating the appearance motion and behavior of real fish in their natural habitat these animats are capable of spatially nonuniform retinal imaging foveation retinal image stabilization color object recognition and perceptually guided navigation these capability allow them to pursue moving target such a fellow artificial fish animat vision offer a fertile approach to the development implementation and evaluation of computational theory that profess sensorimotor competence for animal or robotic situated agent 
pinta is a system for segmentation and visualization ofanatomical structure obtained from serial section reconstructedfrom magnetic resonance imaging the systemapproaches the segmentation problem by assigning eachvolumetric region to an anatomical structure this is accomplishedby satisfying constraint at the pixel level slicelevel and volumetric level each slice is represented by anattributed graph where node correspond to region andlinks correspond to the relation between 
we consider the problem of image segmentation and describe an algorithm that is based on the minimum description length mdl principle is fast is applicable to multi band image and guarantee closed region we construct an objective unction that when minimized yield a partitioning of the image into region where the pixel value in each band of each region are described by a polynomial surface plus noise the polynomial order and their coefficient are determined by the algorithm the minimization is difficult because it involves a search over a very large space and there is extensive computation required at each stage of the search to address the first of these problem we use a region merging minimization algorithm to address the second we use an incremental polynomial regression that us computation from the previous stage to compute result in the current stage resulting in a significant speed up over the non incremental technique the segmentation result obtained is suboptimal in general but of high quality result on real image are shown 
abstract we present a method for partitioning a set of surfaceestimates obtained with a laser range finding systeminto subset corresponding to part of an object ourstrategy us two complementary representation forsurfaces one that describes local structure in termsof differential property e g edge line contour and the other that represents the surface a a collectionof smooth patch at different scale by enforcing aconsistent interpretation between these two representation 
the computation of the optical flow field from an image sequence requires the definition of constraint on the temporal change of image feature in general these constraint limit the motion of the body in space and or of the feature on the image plane 
a subpart of the following problem is considered it is assumed that a set of known three dimensional line with an unknown pose and orientation are observed with a camera the problem is to recover the position and orientation of the camera from the observed image line assuming that a correspondence ha been established between the d and the d line it is shown that there exist infinite set of three dimensional line such that no matter how many line are observed in these set the solution to the orientation or pose determination problem is not unique the maximum number of possible solution is given these result clearly define the domain of validity of algorithm which solve the orientation or pose determination problem 
standard approach to motion analysis assumethat the optic flow is smooth such technique havetrouble dealing with occlusion boundary the mostpopular solution is to allow discontinuity in the flowfield imposing the smoothness constraint in a piecewisefashion but there is a sense in which the discontinuitiesin flow are artifactual resulting from theattempt to capture the motion of multiple overlappingobjects in a single flow field instead we can decomposethe image sequence 
in this work we address the problem of occlusion in tracking multiple d object in a known environment and propose a new approach for tracking vehicle in road traffic scene using an explicit occlusion reasoning step we employ a contour tracker based on intensity and motion boundary the motion of the contour of the vehicle in the image is assumed to be well describable by an affine motion model with a translation and a change in scale a vehicle contour is represented by closed cubic spline the position and motion of which is estimated along the image sequence in order to employ linear kalman filter we decompose the estimation process into two filter one for estimating the affine motion parameter and one for estimating the shape of the contour of the vehicle occlusion detection is performed by intersecting the depth ordered region associated to the object the intersection part is then excluded in the motion and shape estimation this procedure also improves the shape estimation in case of adjacent object since occlusion detection is performed on slightly enlarged region in this way we obtain robust motion estimate and trajectory for vehicle even in the case of occlusion a we show in some experiment with real world traffic scene 
we present an approach for recognizing and classifying moving vehicle in monocularimages sequence of traffic scene recorded by a stationary camera a generic vehicle model represented by a d polyhedral model described by length parameter is used to coverthe different shape of road vehicle the object recognition process is initialized by formulatinga model hypothesis using a reference model and initial value provided by a motionsegmentation step from a model based tracking 
the recognition of object from their projected two dimensional shape is a challengingproblem owing to the spectrum of possible variation reflected in the image domain e g those causedby movement of part change in viewing geometry occlusion etc this motivates a need for quantitativeas well a qualitative description of shape in term of structural relation between component the latter remain largely invariant under the above change in this paper we confront the theoretical 
pose clustering is a method of object recognition that determines the transformation that align hypothesized match of group of image and model feature an object that appears in an image corresponds to a large cluster of transformation in pose space close to the correct pose of the object if there are m model feature and n image feature then there are o m n transformation to consider for the case of recognition of three dimensional object from feature point in two dimensional image i show that clustering can be equally accurate when examining only o mn match due to correlation between the transformation if we are given two correct match this property is used with randomization to decompose the pose clustering problem into o n problem each of which cluster o mn match for a total complexity of o mn besides reducing the time necessary to perform pose clustering this method requires much le memory and make the use of accurate clustering algorithm le costly further time reduction can be gained by using grouping or indexing to determine the initial match 
digital video is rapidly becoming an important source for information entertainment and a host of multimedia application with the size of these collection growing to thousand of hour technology is needed to effectively browse segment in a short time without losing the content of the video we propose a method to extract the significant audio and video information and create a skim video which represents a short synopsis of the original the extraction of significant information such a specific object audio keywords and relevant video structure is made possible through the integration of technique in image and language understanding the resulting skim is much smaller and retains the essential content of the original segment 
abstract in this paper it is shown how false operator response due to missing or uncertain data can be signiflcantly reduced or eliminated perhaps the most well knownofsuchefiectsarethevarious edgeefiects which invariably occur at the edge of the input data set further itisshownhowoperatorshavingahigher degreeofselectivityandhighertoleranceagainstnoise can be constructed using simple combination of appropriately chosen convolution the theory is based on linear operation and is general in that it allows for both data and operator to be scalar vector or tensor of higher order threenewmethodsarepresented normalized convolution difierential convolutionand normalized differential convolution all three method are example of the power of the signal certainty philosophy i e the separation of both data and operator into a signal part and a certainty part missing data is simply handled by setting the certainty to zero in the case of uncertain data an estimate of the certainty must accompany the data localization or windowing of operator is done using an applicability function the operator equivalent to certainty not by changing the actual operator coe cients spatially or temporally limited operator are handled by setting the applicability function to zero outside the window consistentwiththephilosophyofthispaperallalgorithms produce a certainty estimate to be used if fur 
we analyze the amount of information needed to carry out various model based recognition task in the context of a probabilistic data collection model we focus on object that may be described a semi algebraic subset of a euclidean space and on a wide class of object transformation including perspective and affine transformation of d object and perspective projection of d object our approach borrows from computational learning theory we draw close relation between recognition task and a certain learnability framework we then apply basic technique of learnability theory to derive upper bound on the number of data feature that provably suffice for drawing reliable conclusion the bound are based on a quantitative analysis of the complexity of the hypothesis class that one ha to choose from our central tool is the vc dimension which is a well studied parameter measuring the combinatorial complexity of family of set it turn out that these bound grow linearly with the task complexity measured via the vc dimension of the class of object one deal with 
in order to recover camera motion and d structurefrom a sequence of image we must first relate pointsin the image plane to direction in space this paperdescribes a least square algorithm for computingcamera calibration from a series of motion sequencesfor which the translational direction of the camera isknown the method doe not require special calibrationobjects or scene structure it only requires theability to move the camera in a given direction andto track feature in the 
we present a framework for d surface reconstruction that can be used to model fully dimensional scene from an arbitrary number of stereo view taken from vastly different viewpoint this is a key step toward producing d world description of complex scene using stereo and is a very challenging problem real world scene tend to contain many d object they do not usually conform to the d assumption made by traditional algorithm and one cannot take it for granted that the computed d point can easily be clustered into separate group by combining a particle based representation robust fitting and optimization of an image based objective function we have been able to reconstruct surface without any a priori knowledge of their topology and in spite of the noisiness of the stereo data our current implementation go through three step initializing a set of particle from the input d data optimizing their location and finally grouping them into global surface using several complex scene containing multiple object we demonstrate it competence and ability to merge information and thus to go beyond what can be done with conventional stereo alone 
this report discus the well known problem of structure from motionfor the special case of rigid curve it is already known that it is theoretically possibleto recover the motion and then the structure of a moving d rigid curve observed cina monocular image sequence a soon a some set of derivative that are defined onthe so called spatio temporal surface can be computed this is true under the mostgeneral camera model of perspective projection we give here a new simplificationof 
we concentrate on nonrigid motion analysis in d imagesusing modal dynamic borrowing the solid state physic formulation we develop the equation of motion and the analytical expression of vibrationmodes of a multidimensional elastically deformable model thus nonrigid motion of a d deformable object can be recovered in closedformin real time the power of the approach is demonstrated by a setof experimental result on d medical data backgroundfollowing the theory of 
this paper present a new method for extracting the d shape and texture of an object undergoing translational motion from image sequence captured through a monocular extra wide picture viewing angle the feature of this work is extracting this information from image sequence without requiring rigid environmental condition in this method the relative position between target and view position are estimated based on spatio temporal image analysis and shape is reconstructed from the multiple silhouette information after reconstructing the d shape the voxel value of a surface point is determined by statistically analyzing those image that contain the surface point the proposed method can extract d shape and surface texture at a stroke from outdoor scene an experiment using real outdoor scene confirms the effectiveness of the method 
we describe a computer vision system for observing the action unit of a face using video sequence a input the visual observation sensing is achieved by using an optimal estimation optical flow method coupled with a geometric and a physical muscle model describing the facial structure this modeling result in a time varying spatial patterning of facial shape and a parametric representation of the independent muscle action group responsible for the observed facial motion these muscle action pattern may then be used for analysis interpretation and synthesi s thus by interpreting facial motion within a physic base d optimal estimation framework a new control model of facial movement is developed the newly extracted action unit which we name facs are both physic and geometry based and extend the well known facs parameter for facial expression by adding temporal informatio n and non local spatial patterning of facial motion 
learning can often be viewed a the problem of mapping from an input space to an output space example of these mapping are used to construct a continuous function that approximates given data and generalizes for intermediate instance generalized radial basis function grbf network are used to formulate this approximating function a novel method is introduced to construct an optimal grbf network for a given mapping and error bound using the integral wavelet transform simple one dimensional example are used to demonstrate how the optimal network is superior to one constructed using standard ad hoc optimization technique the paper concludes with an application of optimal grbf network to object recognition and pose estimation the result of this application are favorable 
using low order global motion hypothesis and the assumption that there are no more than two motion at a single point it is possible to successfully decompose motion stimulus that contain additively combined transparent layer it is assumed that the space of flow field is sufficiently smooth that a relatively coarse sampling of the flow parameter s will produce a set of vector field that can be combined to reasonably approximate the actual motion in the scene the definition of support from an exclusively spatial notion is extended to include the spatio temporal energy domain the key insight is that when processing transparent motion display the support of a motion hypothesis should exist over both a region of space and velocity so that it can be isolated both spatially and in term of local velocity 
vision should provide an explanation of the scenein term of a causal semantics what affect what andwhy an important part of the causal explanation ofstatic scene is what support what or counterfactually why aren t thing moving we use simple naivephysical knowledge a the basis of a vertically integratedvision system that explains arbitrarily complexstacked block structure the semantics provides a basis for controlling theapplication of visual attention and form a 
based on flat ground assumption a correhtion method is veloprd to estimate orientation of vehicle relative to it run ning environment a weight finclion u introduced to account for figure varirrtion caused by d dynamic scene and perspective efect caused by the camera system the estimated parameter can be qualitatively wed in visual navigation promising result indicate that robust esthation can be achieved in real time by wing powerfil image processing system pipe pipelined image processing engine 
rotationally symmetric operation in the image domain may give rise to shape distortion this article describes a way of reducing this effect for a general class of method for deriving d shape cue from d image data which are based on the estimation of locally linearized distortion of brightness pattern by extending the linear scale space concept into an affine scale space representation and performing affine shape adaption of the smoothing kernel the accuracy of surface 
the structure from motion problem ha been extensively studied in the field of computer vision yet the bulk of the existing work assumes that the scene contains only a single moving object the more realistic case where an unknown number of object move in the scene ha received little attention especially for it theoretical treatment we present a new method for separating and recovering the motion and shape of multiple independently moving object in a sequence of image the method doe not require prior knowledge of the number of object nor is dependent on any grouping of feature into an object at the image level for this purpose we introduce a mathematical construct of object shape called the shape interaction matrix which is invariant to both the object motion and the selection of coordinate system this invariant structure is computable solely from the observed trajectory of image feature without grouping them into individual object once the structure is computed it allows for segmenting feature into object by the process of transforming it into a canonical form a well a recovering the shape and motion of each object 
knowledge about the imaging geometry and acquisition parameter provides useful geometric constraint for the analysis and extraction of man made feature in aerial imagery particularly in oblique view in this paper we discus the identification of horizontal and vertical line in the scene using image orientation information and vanishing point calculation and the calculation of their dimension the vertical and horizontal attribution are used to constrain the set of possible building hypothesis vertical line are extracted at corner to estimate structure height and permit the generation of three dimensional building model from monocular view result of these technique are presented for nadir and oblique imagery and evaluated against manually generated d ground truth building model 
in this paper we investigate algorithm for evaluating surface orientation from pair of stereo image using limited calibration information and without reconstructing an explicit metric representation of the observed scene 
the paper show how technique from computational vision can be deployed to support interactive sketch editing while conventional computer supported drawing tool give user access to visible mark or image object at a single level of abstraction a human user s visual system rapidly construct complex grouping and association among image element according to his or her immediate purpose we have been exploring perceptually supported sketch editor in which computer vision algorithm run continuously behind the scene to afford user efficient access to emergent visual object in a drawing we employ a flexible image interpretation architecture based on token grouping in a multiscale blackboard data structure this organization support multiple perceptual interpretation of line drawing data domain specific knowledge base for interpreting visual structure and natural gesture based selection of visual object 
this contribution investigates local differential technique for estimating optical flow and it derivative based on the brightness change constraint by using the tensor calculus representation we build the taylor expansion of the gray value derivative a well a of the optical flow in a spatiotemporal neighborhood such a formulation simplifies a unifying framework for all existing local differential approach and allows to derive new system of equation to estimate the optical flow and it derivative we also tested various optical flow estimation approach on real image sequence recorded by a calibrated camera fixed on the arm of a robot by moving the arm of the robot along a precisely defined trajectory we can determine the true displacement rate of scene surface element projected into the image plane and compare it quantitatively with the result of different optical flow estimator 
present a vision system for autonomous navigation based on stereo perception without d reconstruction this approach us weakly calibrated stereo image i e image for which only the epipolar geometry is known the vision system first rectifies the image match selected point between the two image and then computes the relative elevation of the point relative to a reference plane a well a the image of their projection on this plane we have integrated this vision module into a complete navigation system in this system the relative elevation is used a a shape indicator in order to compute appropriate steering direction everytime a new stereo pair is processed we have conducted initial experiment in unstructured outdoor environment with an wheeled rover 
a key issue in managing today s large amount of genetic data is the availability of efficient accurate and selective technique for detecting homology similarity between newly discovered and already stored sequence a common characteristic of today s most advanced algorithm such a fasta blast and blaze is the need to scan the content of the entire database in order to find one or more match this design decision result in either excessively long search time or a is the case of blast in a sharp trade off between the achieved accuracy and the required amount of computation the homology detection algorithm presented in this paper on the other hand is based on a probabilistic indexing framework the algorithm requires minimal access to the database in order to determine match this minimal requirement is achieved by using the sequence of interest to generate a highly redundant number of very descriptive tuples these tuples are subsequently used a index in a table look up paradigm in addition to the description of the algorithm theoretical and experimental result on the sensitivity and accuracy of the suggested approach are provided the storage and computational requirement are described and the probability of correct match and false alarm is derived sensitivity and accuracy are shown to be close to those of dynamic programming technique a prototype system ha been implemented using the described idea it contains the full swiss prot database rel mr and the genome of e coli mr the system is currently being expanded to include the complete genbank database abstract truncated at word 
proposes a new approach for vision based longitudinal and lateral vehicle control the novel feature of this approach is the use of binocular vision we integrate two module consisting of a new domain specific efficient binocular stereo algorithm and a lane marker detection algorithm and show that the integration result in a improved performance for each of the module longitudinal control is supported by detecting and measuring the distance to leading vehicle using binocular stereo the knowledge of the camera geometry with respect to the locally planar road is used to map the image of the road plane in the two camera view into alignment this allows u to separate image feature into those lying in the road plane e g lane marker and those due to other object which are dynamically integrated into an obstacle map therefore in contrast with the previous work we can cope with the difficulty arising from occlusion of lane marker by other vehicle the detection and measurement of the lane marker provides u with the positional parameter and the road curvature which are needed for lateral vehicle control moreover this information is also used to update the camera geometry with respect to the road therefore allowing u to cope with the problem of vibration and road inclination to obtain consistent result from binocular stereo 
we previously presented sarkar and boyer the perceptual inference network pin a formalism based on bayesian network to reason among a set of object or feature hypothesis and to integrate multiple source of information in the context of perceptual organization the design of a pin requires knowledge of the dependency structure among the organization of interest and the specification of the conditional probability this design wa done manually with large dos of tedium and guesswork in this paper we present an algorithm based on structural entropic measure and random parametric structural description rpsds to design a pin automatically and in a more theoretically sound fashion experimental result present evidence of the robustness of the algorithm and make performance comparison on real image data with a manually structured pin since pin are a form of bayesian network we hope that this work will also prove useful towards structuring bayesian network in other computer vision context 
an algorithm for camera calibration is presented it is a significant improvement in mathematical simplicity accuracy and computational efficiency in the solution of all extrinsic external camera geometric and intrinsic internal camera geometric and camera optic parameter the method involves a direct transformation from the three dimensional d object world to the two dimensional d image or sensor plane in term of homogeneous vector form for both coplanar and noncoplanar distribution of object point a strong robust property of the proposed algorithm is demonstrated by proving that if the camera is calibrated with image data not compensated for image center displacement and scale factor the proposed algorithm yield parameter that cause no error in the computation of both image and world coordinate 
a nonlinear clustering filter is derived using the maximum entropy principle this filter is governed by a single scale parameter and us local characteristic in the data to determine the scale parameter in the output space it provides a mechanism for removing impulsive noise preserving edge and improving smoothing of nonimpulsive noise it also present a scheme for nonlinear scale space filtering comparison with gaussian scale space filtering are made using real image it is demonstrated that the clustering filter give much better result 
to create a pose invariant face recognizer one strategy is the view based approach which us a set of real example view at different pose but what if we only have one real view available such a a scanned passport photo can we still recognize face under different pose given one real view at a known pose it is still possible to use the view based approach by exploiting prior knowledge of face to generate virtual view or view of the face a seen from different pose to represent prior knowledge we use d example view of prototype face under different rotation we develop example based technique for applying the rotation seen in the prototype to essentially rotate the single real view which is available next the combined set of one real and multiple virtual view is used a example view for a view based pose invariant face recognizer oar experiment suggest that among the technique for expressing prior knowledge of face d example based approach should be considered alongside the more standard d modeling technique 
in previous application bilateral symmetry of object wa used either a a descriptivefeature in domain such a recognition and grasping or a a way to reduce the complexity ofstructure from motion in this paper we propose a novel application using the symmetry propertyto quot symmetrize quot data before and after reconstruction we first show how to compute theclosest symmetric d and d configuration given noisy data this give u a symmetrizationprocedure which we apply to image 
the image segmentation problem may be considered a the search for a way to subdivide an image domain into region which represent the projection of visible part of object in a real scene the author analyze the problem of image segmentation in the framework of the approximation theory a defined by d mumford and j shah they show that for real image the problem of the choice of the energy functional is dictated by the model of the world and they propose a method to optimize it based on a deterministic algorithm processed at multiple level of resolution problem encountered in dealing with real scene lead to several modification of the algorithm and the energy functional image are shown on which the algorithm wa tested 
representing and modeling the motion and spatial support of multiple object and surface from motion video sequence is an important intermediate step towards dynamic image understanding one such representation called layered representation ha recently been proposed although a number of algorithm have been developed for computing these representation there ha not been a consolidated effort into developing a precise mathematical formulation of the problem this paper present one such formulation based on maximum likelihood estimation mle of mixture model and the minimum description length mdl encoding principle the three major issue in layered motion representation are i how many motion model adequately describe image motion ii what are the motion model parameter and iii what is the spatial support layer for each motion model 
color histogram matching ha been shown to be apromising way of quickly indexing into a large imagedatabase yet few experiment have been done to testthe method on truly large database and even if theywere performed they would give little guidance to auser wondering if the technique would be useful withhis or her database in this paper we define and analyzea measure relevant to extending color histogramindexing to large database capacity how many distinguishablehistograms can 
we propose an algorithm for the determination of three dimensional shape and perspective based on the response of the human visual system to change in visual texture current computer vision algorithm are computationally intensive and show inherent difficulty in integrating additional cue for the determination of shape such a shading contour or motion in order to develop a fast and simple mechanism le constrained for integrating other cue we incorporated aspect of the physiological property of cortical cell in vi into a network model we provide psychophysical evidence that the local spatial frequency spectrum is represented by the spatially averaged peak frequency apf after normalization this apf measure texture compression and lead to estimate of d shape and depth simulation of the model show good agreement with human response to a range of textured image 
this paper address the problem of accurately and automaticallyrecovering the epipolar geometry from an uncalibrated stereorig and it application to the image matching problem a robust correlationbased approach that eliminates outlier is developped to produce areliable set of corresponding high curvature point these point are usedto estimate the so called fundamental matrix which is closely related tothe epipolar geometry of the uncalibrated stereo rig we show that an 
demonstrates a method of using nonmetric visual information derived from an uncalibrated active vision system to navigate an autonomous vehicle through free space region detected in a cluttered environment the structure of space is recovered modulo an affine transformation using an uncalibrated active stereo head carried by the vehicle the plane at infinity necessary for recovering affine structure from projective structure is found in a novel manner by making controlled rotation of the head the structure is composed of d point obtained by detecting and matching image corner through the stereo image sequence considerable care ha been taken to ensure that the processing is reliable robust and automatic driveable region are determined from the projection of the affine structure onto a plane parallel to the ground determined using projective construct two method of negotiating the region are explored the first introduces metric information to allow control of a euclidean vehicle the second us visual servoing of the active head to navigate in the affinely described free space region 
we ass the usefulness of monocular recursive motion estimation technique for vehicle navigation in the absence of a model for the environment for this purpose we extend a recently proposed recursive motion estimator the essential filter to handle scale estimation we examine experimentally the accuracy with which the motion and position of the vehicle may be computed on an frame indoors sequence the issue of sampling time frequency and number of necessary feature in the environment are addressed systematically 
in the general case a trilinear relationship between three perspective view is shown to exist the trilinearity result is shown to be of much practical use in visual recognition by alignment yielding a direct method superior to the conventional epipolar line intersection method the proof of the central result may be of further interest a it demonstrates certain regularity across homographies of the plane 
the issue of recognizing d elongated object from d intensity image is addressed a tube model locally similar to generalized cone is developed for the class of elongated object a recognition strategy that combine d contour property and surface shading information is used to exploit the power of the d model reliable contour provide constraint for localizing the object of interest the theory of optimal filter is adopted in verifying the shading of hypothesized object object recognition is achieved through optimizing the signal to noise response with respect to model parameter a sweeping operation is proposed a a further stage of identifying object so that the overall performance of the system doe not heavily rely on the quality of local feature detection 
we present a method based on kalman filtering for image motion estimation within kalman formalism a motion boundary can be modelled a a jump in the evolution equation of the filter the detection of such a jump relies on a statistical test applied to the innovation signal the optimal estimation of the jump parameter and the compensation of the current estimate are performed using a general likelihood ratio glr algorithm to exploit the spatial redundancy inherent to a motion boundary the original glr algorithm is reformulated by integrating spatiotemporal motion information this result in a significant decrease of the compensation delay 
an automatic ego motion compensation based feature detection and correspondence algorithm is presented for image sequence taken from a moving camera feature displacement over consecutive frame can be approximately decomposed into two component the displacement due to camera motion which can be compensated for by image rotation scaling and translation and the displacement due to object motion and or perspective projection the author introduce a two step approach first the motion of the camera is compensated for by using a computational vision based image registration algorithm then consecutive frame are transformed to the same coordinate system and the feature correspondence problem is solved a though for a stationary camera feature point are detected using a gabor wavelet decomposition and a local interaction based algorithm method for subpixel accuracy feature matching and tracking are introduced experimental result on a real image sequence are presented 
we represent arbitrary smooth curved dshapes by a discrete set of hot curve where a surfaceadmits high order tangent these curve determinethe structure of the image contour and it catastrophicchanges and there is a natural correspondence betweensome of them and monocular contour feature such a inflectionsand bitangents we present a method for automaticallyconstructing the hot curve from continuoussequences of video image and describe an approach to objectrecognition 
this paper describes an adaptive method for the recovery of d shape model from sequence of image a d surface model initialised to be spherical is progressively deformed under the action of simulated external force arising from the profile of the target object in successive image obtained using a low level motion segmentation algorithm intrinsic constraint encourage the model to deform smoothly and to remain symmetrical about a vertical plane parallel to the direction of motion 
recognizing face is a difficult problem due to the generally similar shape of face combined with the considerable variability in image of the same face under different viewing condition in this report we consider image variation due to mainly illumination condition 
in this paper we present a system for detection trackingand representation of tubular object in image theuniqueness of the proposed system is twofold at the macrolevel the novelty of the system lie in the integration ofobject localization and tracking using geometric property at the micro level in the use of high and low levelconstraints to model the detection and tracking subsystem the underlying philosophy for object detection isto extract perceptually significant feature 
the paper present a novel method for measuring a discontinuityin range image the discontinuity basically the qualitativesurface characteristic is assigned a quantitative value called measureof the surface discontinuity strength theoretical emphasis is put on estimationof c crease discontinuity three principal advantage areachieved first the discontinuity strength is computed locally second the d problem of the surface discontinuity strength estimation is 
this paper present a method for doing motion segmentation for autonomous vehicle which drive on planar surface there are two distinct type of independent motion that may occur within an image sequence taken from a moving vehicle the first generic type of independent motion is when the projected motion of point on the independent object violate the epipolar constraint the second case is where the epipolar constraint is not violated this paper demonstrates that it is possible to detect this second type of independent motion by looking for progressive dis occlusion of the road a novel collision prediction method is also given the method predicts the projection of a corridor down which the agv will travel this prediction may be used for time to contact collision prediction and the corridor width embodies an estimate of the vehicle size 
we propose an affine framework for perspective view captured by a single extremely simple equation basedon a viewer centered invariant we call relative affinestructure via a number of corollary of our mainresults we show that our framework unifies previouswork including euclidean projective and affine in a natural and simple way finally the main resultswere applied to a real image sequence for purpose of d reconstruction from d view introductionthe introduction of 
the reconstruction of noise corrupted surface can be inferred by methodology such a bayesian estimation and minimum description length both of these imply a formulation where the reconstruction minimizes a functional often this functional is non convex and the minimum cannot be found by simple gradient method the paper concern functionals with quadratic data term criterion for such functionals to be convex and the variational approach of minimizing non convex functionals initial convexity of the approximating functional is considered to be a critical point two fully automatic method of generating convex functionals are presented they are based on gaussian convolution and are compared to the blake zisserman graduated non convexity gnc a blake a zisserman and g l bilbro et al and d geiger and f girosi s mean field annealing mfa of the weak membrane 
a method for automatically evaluating the quality of document page segmentation algorithm is introduced many d ifferent zoning technique are now available but there exists no robust method to benchmark and evaluate them reliably our proposed strategy is a region based approach in which segmentation result are compared with manually generated ground truth file describing all possible correct segmentation a segmentation ground truthing scheme wa already proposed the evaluation of segmentation quality is achieved by testing the overlap between the two set of region in fact the region are defined a being the valued pixel contained in the extracted polygon an explicit specification of segmentation error and a numerical evaluation are derived the algorithm is simple and fast and provides a multi level output for each segmentation 
this article deal with the problem of estimating deformation of brightness pattern using visual front end operation estimating such deformation constitutes an important subtask in several computer vision problem relating to image correspondence and shape estimation the following subject are treated the problem of decomposing affine flow field into simpler component is analysed in detail a canonical parametrization is presented based on singular value decomposition which naturally separate the rotationally invariant component of the flow field from the rotationally variant one a novel mechanism is presented for automatic selection of scale level when estimating local affine deformation this mechanism is expressed within a multiscale framework where disparity estimate are computed in a hierarchical coarse to fine manner and corrected using iterative technique then deformation estimate are selected from the scale that minimize a certain normalized residual over scale finally the descriptor so obtained serve a initial data for computing refined estimate of the local deformation 
we present a binocular active vision system that can attend to and fixate a moving target our system ha an open and expandable design and it form the first step of a long term effort towards developing an active observer using vision to interact with the environment in particular capable of figure ground segmentation we also present partial real time implementation of this system and show their performance in real world situation together with motor control in pursuit we particularly focus on occlusion of other target both stationary and moving and integrate three cue ego motion target motion and target disparity to obtain an overall robust behavior an active vision system must be open expandable and operate with whatever data are available momentarily it must also be equipped with mean and method to direct and change it attention this system is therefore equipped with motion detection for changing attention and pursuit for maintaining attention both of which run concurrently 
an efficient graph matching approach is proposed for finding region correspondence between two image of the same scene but taken from different viewpoint region and their relation in an image are represented with region adjacency graph rag which is a kind of attributed planar graph the problem to find an optimal region correspondence which match the region in two image with maximal similarity in region feature and region relation is formulated into the problem to find the optimal inexact matching between two rag the property specific to planar graph and that of the region adjacency relation are utilized to invent an efficient algorithm to solve the problem experimental result on various kind of image show the effectiveness of the method 
range data offer a direct way to produce shape descriptionsof surface typically single range imageshave the form of a graph surface z g x y and thussuffer from occlusion one can reduce this problemby taking several image from different location andmerging them together the result is a real d descriptionof the object s surface in this paper we addressseveral problem that result from the d to dtransition we present an algorithm which is able tomerge depth image of 
this paper describes the analysis of image sequence takenby a t v camera mounted on a car moving in usual outdoor scenery because of the presence of shock and vibration during the image acquisition the numerical computation of temporal derivative is very noisyand therefore differential technique to compute the optical flow do notprovide adequate result by using correlation based technique and bycorrecting the optical flow for shock and vibration it is possible to 
describes a simple and accurate method for internal camera calibration based on tracking image feature through a sequence of image while the camera undergoes pure rotation a special calibration object is not required and the method can therefore be used both for laboratory calibration and for self calibration in autonomous robot experimental result with real image show that focal length and aspect ratio can be found to within percent and lens distortion error can be reduced to a fraction of a pixel the location of the principal point and the location of the center of radial distortion can each be found to within a few pixel we perform a simple analysis to show to what extent the various technical detail affect the accuracy of the result we show that having pure rotation is important if the feature are derived from object close to the camera in the basic method accurate angle measurement is important the need to accurately measure the angle can be eliminated by rotating the camera through a complete circle while taking an overlapping sequence of image and using the constraint that the sum of the angle must equal degree 
in this paper we propose a new method for solving the handeye calibration problem and we show how this method can be used in conjunction with a reconstruction technique in order to estimate on line the relationship between the frame in which the scene ha been reconstructed or calibration frame and the frame attached to the robot hand the method is particularly well suited for calibrating stereo head with respect to the robot on which they are mounted we discus the advantage of on line self versus off line hand eye and camera calibration we develop two solution for solving for the hand eye calibration problem a closed form solution and a non linear least square solution finally we report on some experiment performed with a stereo head mounted onto a degree of freedom robot arm 
much of the previous work on hand eye coordination ha emphasized the reconstructive aspect of vision recently technique that avoid explicit reconstruction by placing visual feedback into a control loop have been developed when properly defined these method lead to calibration insensitive hand eye coordination recent work on projective geometry a applied to vision is used to extend this paradigm in two way first it is shown how result from projective geometry can be used to perform online calibration second result on projective invariance are used to define setpoints for visual control that are independent of viewing location these idea are illustrated through a number of example and have been tested on an implemented system 
in this paper we preseni scalable data parallel algorithm for geometric hashing we perform implementation of the proposed algorithm on maspar mp l mp in earlier parallel implementation the number of processor employed a independent of the sire of the scene but depends on the size of the model database which is usually very large we destgn new parallel algorithm and map them onto mp i mp these technique significantly improve apon the nuii ber of processor employed while achieving superzor time performance our tmplementatzons run on a p processor machine such that p s where s is the number of feature point in the scene our result show that a probe of the recognztion phase for a scene consisting of feature point take le thaii msec on a k processor mp l mp background object recognition a high level vision task is a key step in an integrated vision system in object recognition using geometric hashing given a set of model and their feature point for each model all possible pair of the feature point are designated a a basis set the coordinate of the feature point of a model are computed relative to each member of it basis set these coordinate are then used a index into a hash table the record in the hash table comprise of model basis pair in the recognition phase an arbitrary pair of feature point in the scene is chosen a a basis and the coordinate of the feature point in the scene are computed the new coordinate are used to hash into the hash table and the corresponding entry of the hashed bin are accessed vote are accumulated tor the model basis pair stored in the hashed location the pair winning the maximumnumber of vote is chosen a a candidate for matching there have been two prior effort in paralleliziiig the geometric hashing algorithm l both implementation have been performed on simd liyper 
d f dementhon and l s davis proposed a method for determining the pose of a d object with respect to a camera from d to d point correspondence the method consists of iteratively improving the pose computed with a weak perspective camera model to converge at the limit to a pose estimation computed with a perspective camera model we show that the method of dementhon and davis can be extended to paraperspective the iterative paraperspective pose algorithm that we describe in detail ha interesting property both in term of speed and rate of convergence moreover we introduce a simple way of taking into account the orthogonality constraint associated with the rotation matrix and we define the optimal experimental setup to be used in the presence of camera calibration error 
information measure with respect to spatial location and scale of object in an image are important to image processing and interpretation it allows u to focus attention on relevant data saving effort and reducing false positive in particular the information content of a man made scene is typically confined to a small set of scale we devise a scale space based measure of image information kullback contrast between successive resolution length give the differential information gain experiment show that this measure give a clear indication of characteristic length in a variety of real world image and is superior to power spectrum based measurement decomposing the expected information gain into spatial coordinate give u a saliency map for use by an attention selector we combine the scale and spatial decomposition into a single information measure giving both the spatial extent and scale range of interest the information measure ha an efficient implementation and thus can be used routinely in early vision processing 
the fundamental matrix is a key concept when working with uncalibrated imagesand multiple viewpoint it contains all the available geometric information and enablesto recover the epipolar geometry from uncalibrated perspective view this paper isabout the problem of it determination from point which lie in several plane in thatcase there is an homography between coordinate of point in the two image we firstinvestigate the use of different criterion to compute the homography a 
estimating principal curvature and principal direction of a surface from a polyhedral approximation with a large number of small face such a those produced by iso surface construction algorithm ha become a basic step in many computer vision algorithm particularly in those targeted at medical application we describe a method to estimate the tensor of curvature of a surface at the vertex of a polyhedral approximation principal curvature and principal direction are obtained by computing in closed form the eigenvalue and eigenvectors of certain spl time symmetric matrix defined by integral formula and closely related to the matrix representation of the tensor of curvature the resulting algorithm is linear both in time and in space a a function of the number of vertex and face of the polyhedral surface 
this report present a new framework for the computation of shape and motion from a sequence of image taken under perspective projection the framework is based on two abstraction the picture and trail locus that represent respectively the set of all picture of the same scene and the set of all trail that a point in the world can leave on the image for a given camera trajectory these abstraction lead to a remarkably clean relation between perspective and orthography furthermore image motion is described in term of angle between projection ray thereby eliminating the need to model camera rotation and leading to more stable result a numerically sound global minimization method is developed based on this framework for the case of a two dimensional world but all concept also hold in three dimension experiment show that the method is rather immune to noise but critically dependent on camera calibration 
in this paper we show how both geometry driven diffusion and optimization of the mumford shah functional can be used to develop a type of curve evolution that is able to preserve salient feature of closed curve such a corner and straight line segment while simultaneously suppressing noise and irrelevant detail the idea is to characterize the curve by mean of it angle function i e the angle between the tangent and a fixed axis and to apply the appropriate dynamic to this one dimensional representation we show how constrained evolution equation can be used to keep the corresponding curve closed at all time 
a system ha been developed to acquire extend and refine d geometric site model from aerial imagery this system hypothesizes potential building roof in an image automatically locates supporting geometric evidence in other image and determines the precise shape and position of the new building via multiimage triangulation model to image registration technique are applied to align new incoming image against the site model model extension and refinement procedure are then performed to add previously unseen building and to improve the geometric accuracy of the existing d building model 
a fundamental problem of determining the position and orientation of a d object using a single perspective image view is defined and investigated the technique is based on the interpretation of trihedral angle constraint information a new closed form solution to the problem is proposed the method also provides a general analytic technique for dealing with a class of problem of shape from inverse perspective projection by using angle to angle correspondence information simulation experiment show that the author method is effective and robust for real application 
vision algorithm are often developed in a bayesian framework two estimator are commonly used maximum a posteriori map and minimum mean squared error mmse we argue that neither is appropriate for perception problem the map estimator make insufficient use of structure in the posterior probability the squared error penalty of the mmse estimator doe not reflect typical penalty we describe a new estimator which we call maximum local mass mlm which integrates the local probability density the mlm method is sensitive to local structure of the posterior probability which map is not the new method us an optimality criterion that is appropriate for perception task it find the most probable approximately correct answer for the case of low observation noise we provide an efficient approximation we apply this new estimator to color constancy an unknown illuminant fall on surface of unknown color we seek to estimate both the illuminant spectrum and the surface spectrum from photosensor response which depend on the product of the unknown spectrum in simulation we show that the mlm method performs better than the map estimator and better than two standard color constancy algorithm the mlm method may prove useful in other vision problem a well 
we show how a special decomposition of general projection matrix called canonic enables u to build geometric description for a system of camera which are invariant with respect to a given group of transformation these representation are minimal and capture completely the property of each level of description considered euclidean in the context of calibration and in the context of structure from motion which we distinguish clearly affine and projective that we also relate to each other in the last case a new decomposition of the well known fundamental matrix is obtained dependency which appear when three or more view are available are studied in the context of the canonic decomposition and new composition formula are established a well a the link between local ie for pair of view representation and global ie for a sequence of image representation 
we describe our implementation of a parallel depth recovery scheme for a four camera multibaseline stereo in a convergent configuration our system is capable of image capture at video rate this is critical in application that require three dimensional tracking we obtain dense stereo depth data by projecting a light pattern of frequency modulated sinusoidally varying intensity onto the scene thus increasing the local discriminability at each pixel and facilitating match in addition we make most of the camera view area by converging them at a volume of interest result show that we are able to extract stereo depth data that are on the average le than mm in error at distance between to m away from the camera 
the use of a multistage diffusion process in the early processing of range data is examined the input range data are interpreted a occupying a volume in d space each diffusion stage simulates the process of diffusing part of the boundary of the volume into the volume the outcome of the process can be used for both discontinuity detection and segmentation into shape homogeneous region the process is applied to synthetic noise free and noisy step roof and valley edge a well a to real range image 
we consider the following problem how should an observerchange viewpoint in order to generate a dense imagesequence of an arbitrary smooth surface so that it can be incrementallyreconstructedusing the occluding contour and theepipolar parameterization we present a collection of qualitativebehaviors that when integrated appropriately purposefullycontrol viewpoint based on the appearance of the surfacein order to provably solve this problem 
a qualitative approach to visually guided navigationbased on the computation of optical flow field is presented the approach is based on the use of two camerasmounted on a mobile robot and with the optical axisdirected in opposite direction such that the two visualfields do not overlap divergent stereo range computationis based on the computation of the apparentimage speed on image acquired during robot s motion an example of reflex type control of motion drivenby differential 
we introduce a spatial representation s map for an indoor navigation robot the s map represents the location of obstacle in a planar domain where obstacle are defined a any object that can block movement of the robot in building the s map the viewing triangle constraint and the stability constraint are introduced for efficient verification of vertical surface these verified vertical surface and d segment of obstacle smaller than a robot are mapped to the s map by simply dropping height information thus the s map is made directly from d segment with simple verification and represents obstacle in a planar domain so that it becomes a navigable map for the robot without further processing in addition to efficient map building the s map represents the environment more realistically and completely furthermore the s map convert many navigation problem in d such a map fusion and path planning into d one we present the analysis of the s map in term of complexity and reliability and discus it pro and con moreover we show the result of the s map for indoor environment 
in extracting a polynomial surface patch near an intensity or range discontinuity a robust estimator must tolerate not only the truly random bad data random outlier but also the coherently structured point pseudo outlier that belong to a different surface to characterize the performance of least median of square m estimator hough transforms ransac and minpran on data containing both random and pseudo outlier we develop two analytical measure pseudo outlier bias and pseudo outlier breakdown using these measure we find that each robust estimator ha surprisingly poor performance even under the best possible circumstance implying that present estimator should be used with care and new estimator should be developed 
simplex mesh are simply connected mesh thatare topologically dual of triangulation in a previouswork we have introduced the simplex meshrepresentation for performing recognition of partiallyoccluded smooth object in this paper wepresent a physically based approach for recoveringthree dimensional object based on the geometry ofsimplex mesh elastic behavior is modelled by localstabilizing functionals controlling the mean curvaturethrough the simplex angle extracted at 
this paper s main result is to show that under the condition imposed by the maloneywandell color constancy algorithm color constancy can in fact he expressed in term of a simple independent adjustment of the sensor response in other word a a uon kries adaptation type of coeficient rule algorithm so long a the sensor space is first transformed to a new hasis our overall goal is to present a theoretical analysis connecting many established theory of color constancy for the case where surface refiectances are dimensional and illuminant are dimensional we prove that perfect color constancy can always be solved for by an independent adjustment of sensor response which mean that the color constancy transform can he expressed a a diagonal matrix this result requires a prior transformation of the sensor basis and to support it we show in particular that there exists n transformation of the original sensor basis under which the non diagonal meth od of maloneywandell forsyth s mwext and funt and drew s lightness algorithm all reduce to simpler diagonal matrix theones of color constancy our result are strong in the sense that no constraint is placed on the initial sensor spectral sensitzuities in addition to purely theoretical argument the paper contains result from simulation of diagonal matrix based color constancy in which the spectrum of real illuminant and refiectances along with the human cone sensitivity function are used the simulation demonstrate that when the cone sensor space is transformed to it new basis in the appropriate manner a diagonal matrix support close to optimal color constancy 
we present a method for navigating a robot from an initial position to a specified landmark in it visual field using a sequence of monocular image the location of the landmark with respect to the robot is determined using the change in size and location of the landmark in the image a a function of the motion of the robot the landmark location is estimated after the first three image are taken and this estimate is refined a the robot move the method can correct for error in the robot motion a well a navigate around obstacle the obstacle avoidance is done using bump sensor sonar and dead reckoning rather than visual servoing the method doe not require prior calibration of the camera we show some example of the operation of the system 
a sensory system consisting of a camera and several laser beam is described it is designed for estimating the parameter of a planar surface with respect to the camera estimation is possible when the beam position and direction are known a well a the image of the beam spot on a planar surface the system is readily applicable in an industrial environment for automation if it is attached to a robot arm and is connected to a computer 
a fast simulated annealing algorithm is developed for automatic object recognition the object recognition problem is addressed a the problem of best describing a match between a hypothesized object and an image the normalized correlation coefficient is used a a measure of the match template are generated on line during the search by transforming model image simulated annealing reduces the search time by order of magnitude with respect to an exhaustive search the algorithm is applied to the problem of how landmark e g traffic sign can be recognized by a navigating robot we illustrate the performance of our algorithm with real world image of complicated scene with traffic sign false positive match occur only for template with very small information content to avoid false positive match we propose a method to select model image for robust object recognition by measuring the information content of the model image the algorithm work well in noisy image for model image with high information content 
the author investigate the computational time complexity of the labeling problem for line drawing of polyhedral scene it is found that line drawing can be labeled in time proportional to the number of segment once the vanishing point associated to the possible direction for the edge are known the vanishing point can be given a priori otherwise they can in many case be detected by standard technique from the line drawing itself the np completeness of the labeling problem for line drawing of trihedral scene kirousis and papadimitriou is then due to the lack of knowledge about the vanishing point which is equivalent to the knowledge of the possible direction for the edge these result help draw a more accurate boundary between the problem in the interpretation of line drawing that are polynomially solvable and those that are np complete 
figure ground segmentation is a fundamental problem in computer vision the main difficulty is the integration of low level pixel based local image feature to obtain global object based description active contour in the form of snake balloon and level set modeling technique have been proposed that satisfactorily address this question for certain application however these method require manual initialization do not always perform well near sharp protrusion or indentation or often cross gap we propose an approach inspired by these method and a shock based representation of shape in term of part protrusion and bend since initially it is not clear where the object or their part are part are hypothesized in the form of fourth order shock randomly initialized in homogeneous area of image these shock then form evolving contour or bubble which grow shrink merge split and disappear to capture the object in the image in the homogeneous area of the image bubble deform by a reaction diffusion process in the inhomogeneous area indicated by differential property computed from low level process such a edge detection texture optical flow and stereo etc bubble do not deform a such the randomly initialized bubble integrate low level information and in the process segment the figure from the ground 
we present a new approach to relative stereo and motion reconstruction from a discrete set of point correspondence in completely uncalibrated pair of image this approach also yield new projective invariant and we present some application to object recognition finally we introduce a new approach to camera self calibration from two image which allows full metric reconstruction up to some unknown scale factor we have implemented the proposed method and present example using real image 
abstract most stereo algorithm do not take into ac count discontinuity in disparity and the fact that there are half occlusion consisting of area seen by one eye but not the other at the same time very few of them are formulated using the framework of energy functionals which are so succesfully used in other area of computer vision such a image segmentation and surface represen tation in this paper a formulation is presented within such a framework taking into account the discontinuity and half occlusion the formulation follows directly from the assumption that when matching the left and right im age the order of point must be preserved a model is derived consisting of two coupled energy functionals cor responding to the two eye they are coupled in the sense that the discontinuity locus determined by one eye also determines the occluded area in the image seen by the other eye a nonlinear system of diffusion equation is de rived by simultaneously applying gradient descent to these functionals the diffusion equation are implemented by a straight forward finite difference scheme 
it is known that rotationally symmetric surface canbe recognized from their outline alone using crossratio s of bitangent intersection this paper demonstratesa successful implementation of this technique using a novel bitangent finder that work on imagesof real scene we report on the stability of the crossratios and compare this to affine invariant therecognition technique is shown to extend to the caseof straight homogeneous generalised cylinder introductionthis paper 
this paper describes a method of pattern recognitiontargeted for recognizing complex annotationsfound in paper document our investigation is motivatedby the high reliability required for accomplishingautonomous interpretation of map and engineeringdrawings our approach includes a strategy basedon multiscale representation obtained by hexagonalwavelet analysis a feasibility study is described in which more than pattern were recognized with an error rate of by a neural 
ambiguity in the solution of inverse problem arises when data are insufficient to define a unique solution i e the problem is ill posed data fusion ha the potential to reduce this ambiguity by using other sensory data that complement the original data this paper examines the application of data fusion to limited angle computed tomography ct to resolve ambiguity while ct in it conventional form is ill posed with a small null space limited angle ct ha a much larger null space structure that lie primarily in the null space of the limited angle radon transform are particularly prone to ambiguity we describe a novel constraint based data fusion system that fuse spatial support and ultrasound measurement with x ray data the ensuing problem is le ambiguous ha a reduced null space and permit accurate reconstruction of a sandwich structure where otherwise impossible 
we present a novel statistical and variational approach to image segmentation based on a new algorithm named region competition this algorithm is derived by minimizing a generalized bayes mdl minimum description length criterion using the variational principle we show that existing technique in early vision such a snake balloon model region growing and bayes mdl are addressing different aspect of the same problem and they can be unified within a common statistical framework which combine their advantage we analyze how to optimize the precision of the resulting boundary location by studying the statistical property of the region competition algorithm and discus what are good initial condition for the algorithm our method is generalized to color and texture segmentation and is demonstrated on grey level image color image and texture image 
we consider the problem of matching perspective view of coplanar structure composed of line segment both model to image and image to image correspondence matching are given a consistent treatment these matching scenario generally require discovery of an eight parameter projective mapping however when the horizon line of the object plane can be found in the image done here using vanishing point analysis these problem reduce to a simpler six parameter affine matching problem when the intrinsic lens parameter of the camera are known the problem further reduces to four parameter affine similarity matching 
abstract flexible operation of a robotic agent in an uncalibratedenvironment requires the ability to recover unknown or partiallyknown parameter of the workspace through sensing ofthe sensor available to a robotic agent visual sensor provideinformation that is richer and more complete than othersensors in this paper we present robust technique for thederivation of depth from feature point on a target s surfaceand for the accurate and high speed tracking of moving target we use these 
in differential geometry curve are characterized a mapping from an interval to the plane in topology curve are characterized a a hausdorff space with certain countability property neither of these definition capture the role that curve play in vision however in which curve can denote simple object such a a straight line or complicated object such a a jumble of string the difference between these situation is in part a measure of their complexity and in part a measure of their dimensionality note that the map defining such curve is unknown a is the proper way to represent them we propose a formal complexity theory of curve appropriate for computational vision in general and for problem like separating straight line from jumble in particular the theory is applied to the problem of perceptual grouping 
we present a novel robust integrated approach to segmentationshape and motion estimation of articulated object initially we assume the object consists of a singlepart and we fit a deformable model to the given data usingour physic based framework a the object attains newpostures we decide based on certain criterion if and whento replace the initial model with two new model thesecriteria are based on the model s state and the given data we then fit the model to the data using 
in this paper we present method and technique for calibrating camera of a head eye system which ha computer controlled focusing zooming and iris the idea is to build up look up table for intrinsic parameter so we can index them extensive experiment were carried out and result are reported here 
a multiscale extension to the medial axis transform mat or skeleton can be obtained by combining information derived from a scale space hierarchy of boundary representation w ith region information provided by the mat the skeleton space is constructed by attributing each skeleton component with a hierarchically ordered sequence of residual value each e xpressing the saliency of the component at a distinct resolut ion level since our method amount to a rather symbolic than iconic computation of a multiscale mat it doe not introduce the correspondence problem between distinct level of detail in contrast to other commonly proposed technique our multiscale mat is capable of describing complex shape characterized by significantly jagged boundary furthermore tracking the evolution of prominent locus of the mat such a node across scale permit to ass the most significant skeleton constituent and to automatically determine pruning parameter a salient subset of the mat first order skeleton can be extracted without the need of manual threshold adjustment 
explores the reconstruction of object surface from viewed change in surface texture pattern our approach differs from those in the past in that instead of simply producing local estimate of the surface orientation our algorithm recovers complete surface past approach only found the surface orientation locally and therefore did not take advantage of the surface integrability constraint our algorithm doe not assume that the surface texture pattern is isotropic and it doe not assume that the viewed surface is at some point fronto parallel furthermore our algorithm ha mechanism for handling texture boundary and consequently doe not produce erratic result in the region abutting these boundary result on real image are presented demonstrating the potential of our approach 
in this report we present method and technique for calibrating camera of thekth head eye system in particular intrinsic parameter the intention is to buildup look up table for them so that we can index them and no on the job calibrationis needed extension experiment were carried out and result are reported here m x li camera calibration of the kth head eye system introduction and backgroundcamera calibration is useful if not necessary in many computer vision 
it is known that the deformation of the apparent contour of a surface under perspective projection and viewer motion enable the recovery of the geometry of the surface for example by utilising the epipolar parametrization these method break down with apparent contour that are singular i e with cusp in this paper we study this situation in detail and show how nevertheless the surface geometry including the gauss curvature and mean curvature of the surface can be recovered by following the cusp indeed the formula are much simpler in this case and require lower spatio temporal derivative than in the general case of nonsingular apparent contour we give a simulated example and also show that following cusp doe not by itself provide u with information on ego motion 
in the present paper we address the problem of computing structure and motion given a set point correspondence in a monocular image sequence considering small motion when the camera is not calibrated we first set the equation defining the calibration rigid motion and scene structure we then review the motion equation the structure from equation and the depth evolution equation including the particular case of planar structure considering a discrete displacement between two frame a step further we develop the first order expansion of these equation and analyse the observability of the related infinitesimal quantity it is shown that we obtain a complete correspondence between these equation and the equation derived in the discrete case however in the case of infinitesimal displacement the projection of the translation focus of expansion or epipole is clearly separated from the rotational component of the motion this is an important advantage of the present approach using this last property we propose a mechanism of image stabilization in which the rotational disparity is iteratively canceled this allows a better estimation of the focus of expansion and simplifies different aspect of the analysis of the equation structure from motion equation analysis of ambiguity geometrical interpretation of the motion equation 
this paper present a framework for analyzing salient pattern vortex structure in the velocity field of turbulent fluid flow vortex are modeled a rotational motion in the velocity field and concentration in the corresponding vorticity field a pointwise linear model is then built to approximate the kinematics of the flow field locally the vector field are analyzed in term of fluid motion and singular pattern the region of vortex structure are then extracted by identifying those dominated by rotational motion or those of focus type singularity in addition to this d vortex a a special case are detected by searching region of vorticity concentration the algorithm is applied to both d and d experimental and computational turbulent flow 
this paper present a markov random field mrf model for object recognition in high level vision thelabeling state of a scene in term of a model object isconsidered a an mrf or couple mrfs within thebayesian framework the optimal solution is definedas the maximum a posteriori map estimate of themrf the posterior distribution is derived based onsound mathematical principle from theory of mrfand probability which is in contrast to heuristic formulation an experimental 
the tracking of moving object in the d space for long term image sequence must be very robust with respect to noise and computational error thus for example autoregressive and newtonian model have been adopted mainly with least square kalman filter and other technique the parameter measured are predicted corrected on the basis of the model adopted which can be adaptive or not in this paper a new method for tracking object in the d space belonging to the class of matching based algorithm with an adaptive prediction correction mechanism is presented the prediction correction is based on d and d motion estimation and both these correction are used for measuring the displacement on the image plane the mechanism proposed is very robust with respect to the accumulation error and thus it is suitable for very long term object tracking 
more and more low level vision algorithm are being carried out in the spatialfrequency domain using gabor filter there are two basic problem concerned withgabor filterings we will address in this paper one is the window size problem inwhich we will adopt a set of d variable window gabor filter and compare it performancewith those of fixed window filter we will show that the variable windowscheme is more adaptive to image content while fixed window scheme may suffereither 
the paper present a new idea for detecting an unknown human face in input imagery and recognizing his her facial expression represented in the deformation of the two dimensional net called potential net the method deal with the facial information faceness and expression a an overall pattern of the net activated by edge in a single input image of face rather than from change in the shape of the facial organ or their geometrical relationship we build model of facial expression from the deformation pattern in the potential net for face image in the training set of different expression and then project them into emotion space expression of an unknown subject can be recognized from the projection of the net for the image into the emotion space the potential net is further used to model the common human face the mosaic method representing energy in the net is used a a template for finding candidate for the face area and the candidate are verified their faceness by projecting them into emotion space in order to select the finalist precise location of the face is determined by the histogram analysis of vertical and horizontal projection of edge 
despite the promising result of numerous application the hitherto proposed snake technique share some common problem snake attraction by spurious edge point snake degeneration shrinking and flattening convergence and stability of the deformation process snake initialization and local determination of the parameter of elasticity we argue here that these problem can be solved only when all the snake aspect are considered the snake proposed here implement a new potential field and external force in order to provide a deformation convergence attraction by both near and far edge a well a snake behaviour selective according to the edge orientation furthermore we conclude that in the case of model based segmentation the internal force should include structural information about the expected snake shape experiment using this kind of snake for segmenting bone in complex hand radiograph show a significant improvement 
two new method are presented for recovering the focused image of an object from only two blurred image recorded with different camera parameter setting the camera parameter include lens position focal length and aperture diameter first a blur parameter sigma is estimated using one of our proposed depth from defocus method then one of the two blurred image is deconvolved to recover the focused image the first method is based on a spatial domain convolution deconvolution transform this method requires only the knowledge of sigma of the camera s point spread function psf it doe not require information about the actual form of the camera s psf the second method in contrast to the first requires full knowledge of the form of the psf a part of the second method we present a calibration procedure for estimating the camera s psf for different value of the blur parameter sigma in the second method the focused image is obtained through deconvolution in the fourier domain using a wiener filter for both method the result of experiment on actual defocused image recorded by a ccd camera are given the first method requires much le computation than the second method the first method give satisfactory result for up to medium level of blur and the second method give good result for up to relatively high level of blur 
the paper deal with the problem of unsupervised classification of image modeled by markov random field mrf if the model parameter are known then we have various method to solve the segmentation problem simulated annealing icm etc however when they are not known the problem becomes more difficult one ha to estimate the hidden label field parameter from the only observable image our approach consists of extending a recent iterative method of estimation called iterative conditional estimation ice to a hierarchical markovian model the idea resembles the estimation maximization em algorithm a we recursively look at the maximum a posteriori map estimate of the label field given the estimated parameter then we look at the maximum likelihood ml estimate of the parameter given a tentative labeling obtained at the previous step we propose unsupervised image classification algorithm using a hierarchical model the only parameter supposed to be known is the number of region all the other parameter are estimated the presented algorithm have been implemented on a connection machine cm comparative test have been done on noisy synthetic and real image remote sensing 
the best known algorithm for symbolic model matching incomputer vision is the interpretation tree search algorithm this algorithmhas a high computational complexity when applied to matchingproblems with large number of feature this paper examines ten variationsof this algorithm in a search for improved performance and concludesthat the non wildcard and hierarchical algorithm have reducedtheoretical complexity and run faster than the standard algorithm introductionthe most 
statistical modeling and evaluation of the performance of obstacle detection system for unmanned ground vehicle ugv s is essential for the desig n evaluation and comparison of sensor system in this report we address this issue for ima ging range sensor by dividing the evaluation problem into two level quality of the range dat a itself and quality of the obstacle detection algorithm applied to the range data we review existing model of the quality of range data from stereo vision and am cw ladar then use these to derive a new model for the quality of a simple obstacle detection algorithm this model predicts the probability of detecting obstacle and the probability of false alarm a a function of the size and distance of the obstacle the resolution of the sensor and the level of n oise in the range data we evaluate these model experimentally using range data from stereo image pair of a gravel road with known obstacle at several distance the result show that the approach is a promising tool for predicting and evaluating the performance of obstacle detection with imaging range sensor 
we are considering the problem of recovering the three dimensional geometry of a scene from binoculor stereo disparity once a dense disparity map ha been computed from a stereo pair of image one often need to calculate some local diferential property of the cowesponding surface such a orientation or curvature the wual approach is to build a reconstruction of the surface s from which all shape property will then be derived without ever going back to the original image in this paper we depart from this paradigm and propose to we the image directly to compute the shape property we thus propose a new method extending the classical cowelation method to estimate accurately both the disparity and it derivative directly from the image data we then relate those derivative to diferential property of the surface such a orientation and curvature 
in binocular visual system vergence is the process of directing the gaze so that the optical ax intersect at a surface point correlation based method of disparity analysis provide fast estimate of the vergence errol unfortunately most correlation technique do not provide mechanism to determine which image location contributed to q given correlation peak the result is that large correlation peak may have contribution from image area not relevant to the vergence task this paper present a vergence system that applies a cepstral filter to multiscale image obtained from a dominant eye binocular sensol a used by this system the cepstral filter ha two main advantage it enhances target through narrow band signal suppression and it support a back projection operation to determine the image location associated with particular correlation peak the use of multiscale image allows the system to have both high resolution for precision in the final vergence and a large field of view for a wide range of initial camera orientation without undue computational cost 
this paper is devoted to an analytical study of extremum curvature evolution through scale space our analytical study allows to get result which show that from a qualitative point of view corner evolution in scale space ha the same behavior for planar curve or surface in particular this analysis performed with different corner shape model show that for a two corner shape two curvature maximum exist and merge at a certain scale depending on the shape for a two corner grey level surface the evolution of the determinant of hessian det show a merging point for a certain independently of contrast and the evolution of gaussian curvature present the same characteristic but this point evolves with contrast 
this paper introduces a new general purpose algorithm that allows the optimal geometric match between contour to be determined that is the transformation yielding a minimal deformation is obtained the algorithm relies only on the geometric property of the contour and doe not call for any other constraint so that it is particularly suitable when no parameterization of title deformation is available or desirable contour deformation is explicitly incorporated in the computation allowing for a thorough use of all geometric information available moreover no discretization is involved in the computation resulting in two main advantage first the algorithm is robust to difference in the segmentation of contour and allows the matching of polygonal approximation of contour with very little loss of precision second subpixel precision matching can be achieved 
a new method for representing and recognizing human body movement is presented the basic idea is to identify set of constraint that are diagnostic of a movement expressed using body centered coordinate such a joint angle and in force only during a particular movement assuming the availability of cartesian tracking data we develop technique for a representation of movement defined by space curve in subspace of a phase space the phase space ha ax of joint angle and torso location and attitude and the ax of the subspace are subset of the ax of the phase space using this representation we develop a system for learning new movement from ground truth data by searching for constraint we then use the learned representation for recognizing movement in unsegmented data we train and test the system on nine fundamental step from classical ballet performed by two dancer the system accurately recognizes the movement in the unsegmented stream of motion 
computer sensing of hand and limb motion is an important problem for application in human computer interaction and computer graphic we describe a framework for local trading of self occluding motion in which one part of an object obstructs the visibility of another our approach us a kinematic model to predict occlusion and windowed template to track partially occluded object we present offline d tracking result for hand motion with significant self occlusion 
we report a novel application of polarization based vision addressing the robustness of laser triangulation range sensor such sensor are based on the accurate detection of a pattern of laser light projected onto a scene usually a point or line typical problem arise with highly specularly reflective surface which can generate visible reflection of the light in various part of the image this can confuse the detection algorithm and lead to wrong range measurement this paper demonstrates experimentally the feasibility of polarization based vision for disambiguating multiple specular inter reflection of the laser light we concentrate on metal component a they have high interest for inspection in manufacturing and show positive result with situation of various complexity 
this paper present a system for large vocabularyrecognition of on line handwritten cursive word thesystem first us a filtering module based on simpleletter feature to quickly reduce a large reference dictionaryto a smaller number of candidate the reducedlexicon along with the original input is subsequently fedto a recognition module in order to exploit the sequentialnature of the temporal data we employ a tdnnstylenetwork architecture which ha been successfullyused in the 
present a method for calibrating intrinsic and extrinsic camera parameter this algorithm can easily be modified by other user to suit their particular calibration need without requiring a high precision calibration target or complicated linear algebra the algorithm us controlled motion and a single light source to simulate calibration target in convenient d location these convenient calibration target enable u to simplify the calibration algorithm and gather dense data for lens distortion dense data make the distortion correction more accurate than traditional low order polynomial fit and allows u to calibrate wide angle lens 
shape from texture is best analyzed in two stage analogous to stereopsis and structure from motion a computing the texture distortion and b interpreting the texture distortion to infer the orientation and shape of the surface we model the texture distortion for a given point and direction on the image plane a an affine transformation and derive the relationship between the parameter of this transformation and the shape parameter we use non linear minimization of a least square error criterion to estimate the shape parameter from the affine transformation using a simple linear algorithm to obtain an initial guess under the assumption that the measurement error in the affine parameter are independent and normally distributed we can find error bound on the shape parameter estimate we present result on image of planar and curved surface under perspective projection we find all five local shape and orientation parameter with no a priori assumption about the shape of the surface 
our long term goal is to develop a trainable tool for locating pattern of interest in large image database toward this goal we have developed a prototype system based on classical filteringand statistical pattern recognition technique for automatically locating volcano in the magellan sar database of venus training for the specificvolcano detectiontask is obtained by synthesizing feature template via normalizationand principal component analysis from a small number of example provided by expert candidateregions identifiedby a focus of attention foa algorithm are classifiedbased on correlation with the feature template preliminary test show performance comparableto trained human observer 
this paper address the problem of computing cue to thethree dimensional structure of surface in the world directly from thelocal structure of the brightness pattern of a binocular image pair thegeometric information content of the gradient of binocular disparity isanalyzed for the general case of a fixating system with symmetric orasymmetric vergence and with either known or unknown viewing geometry a computationally inexpensive technique which exploit thisanalysis is proposed 
this paper present a novel framework for shape modeling and shape recovery based on idea developed by osher sethian for interface motion in this framework shape are represented by propagating front whose motion is governed by a hamilton jacobi type equation this equation is written for a function in which the interface is a particular level set unknown shape are modeled by making the front adhere to the object boundary of interest under the influence of a synthesized halting criterion the resulting equation of motion is solved using a narrow band algorithm designed for rapid front advancement our technique can be applied to model arbitrarily complex shape which include shape with significant protrusion and to situation where no a priori assumption about the object s topology can be made we demonstrate the scheme via example of shape recovery in d and d from synthetic and low contrast medical image data 
an image of a scene with occlusion can yield only partial knowledge about disconnected fragment of the scene if this were the only knowledge available program attempting to interpret the scene would have to conclude that the scene fragment would collapse in a jumble but they won t we describe a program that exploit commonsense knowledge of naive physic to make sense of scene with occlusion our causal analysis focus on the static stability of structure what support what occluded connection in a link and junction scene are inferred by determining the stability of each subassembly in the scene and connecting part when they are unstable the causal explanation that is generated reflects a deeper understanding of the scene than mere model matching it allows the seeing agent to predict what will happen next in the scene and determine how to interact with it 
a newpractical method is given for the self calibration of a camera in this method at least three image are taken from the same point in space with different orientation of the camera and calibration is computed from an analysis of point match between the image the method requires no knowledge of the orientation of the camera calibration is based on the image correspondence only this method differs fundamentally from previous result by maybank and faugeras on selfcalibration using the epipolar structure of image pair in the method of this paper there is no epipolar structure since all image are taken from the same point in space since the image are all taken from the same point in space determination of point match is considerably easier than for image taken with a moving camera since problem of occlusion or change of aspect or illumination do not occur the calibration method is evaluated on several set of synthetic and real image data 
binocular stereo vision process estimate d surfacesusing a pair of image taken from different pointsof view d surface characteristic are estimated bymatching d image area or feature corresponding tothe projection of same d point the most classicarea based method used cross correlation with a fixedwindow size but this technique present a major drawback the computation of depth is generally prone toerrors close to surface discontinuity in this paper we present our 
it is fairly common in video sequence that a mostly fixed background scene is imaged with or without object the dominant background change in the image plane mostly due to camera operation and motion zoom pan tilt track etc we address the problem of computation of the dominant image transformation over time and demonstrate how this can be effectively used for efficient video representation through video mosaicing and image registration we formulate the problem of dominant component estimation a that of model based robust estimation using m estimator with direct multi resolution method in addition to d affine and plane projective model that have been used in the past for describing image motion using direct method we also employ a true d model of motion and scene structure imaged with uncalibrated camera this model parameterizes the image motion a that due to a planar component and a parallax component for rigid d scene imaged under camera motion only least square l method with the plane and parallax parameterization are also presented furthermore in the context of robust estimation in contrast with previous approach for similar problem our algorithm employ an automatic computation of a scale parameter that is crucial in rejecting the non dominant component a outlier 
the brodatz album ha become the de facto standardfor evaluating texture algorithm with hundredsof study having been applied to small set of it image this paper compare two powerful recognition algorithm principal component analysis and multiscaleautoregressive model by evaluating them on a imagedatabase derived from the entire brodatz album the variety of homogeneous and non homogeneous imagesstudied is thus nearly an order of magnitude largerthan ha been compared 
an algorithm that performs recursive estimation of ego motion and ambient structure from a stream of monocular perspective image of a number of feature point is presented the algorithm is based on an extended kalman filter ekf that integrates over time the instantaneous motion and structure measurement computed by a two perspective view step the key feature of the author filter are global observability of the model and complete online characterization of the uncertainty of the measurement provided by the two view step the filter is thus guaranteed to be well behaved regardless of the particular motion undergone by the observer region of motion space that do not allow recovery of structure e g pure rotation may be crossed while maintaining good estimate of structure and motion whenever reliable measurement are available they are exploited the algorithm work well for arbitrary motion with minimal smoothness assumption and no ad hoc tuning simulation are presented that illustrate these characteristic 
the hough transform is a class of medium level vision technique generally recognised a a robust way to detect geometric feature from a d image this paper present two related technique first a new hough function is proposed based on a mahalanobis distance measure that incorporates a formal stochastic model for measurement and model noise thus the effect of image and parameter space quantisation can be incorporated directly given a resolution of the parameter space the method provides better result than the standard hough transform sht including under high geometric feature density secondly extended kalman filtering is used a a further refinement process which achieves not only higher accuracy but also better performance than the sht the algorithm are compared with the sht theoretically and experimentally 
present a closed form solution for the determination of d displacement and rotation parameter given a set of d point correspondence the method applies to the general case of arbitrary displacement and rotation with respect to an arbitrary stationary scene the approach is based on the linear subspace method which allows separate linear equation to be extracted for the displacement and rotation this lead to a simple algorithm suitable for real time implementation for the determination of both the d transformation and error estimate for the estimated d displacement preliminary experimental result with range data are presented 
we describe a technique for finding pixelwise correspondence between two image by using model of object of the same class to guide the search the object model are learned from example image also called prototype of an object class the model consist of a linear combination of prototype the flow field giving pixelwise correspondence between a base prototype and each of the other prototype must be given a novel image of an object of the same class is matched to a model by minimizing an error between the novel image and the current guess for the closest model image currently the algorithm applies to line drawing of object an extension to real grey level image is discussed 
the author propose to replace a set of connected d point or line segment with a d formable curve using weighted least square approximation the parameter of the d energy minimizing curve are updated so that it d projection on two or three stereoscopic image converge toward the corresponding image edge thus a more realistic representation of the real non polygonal world is obtained the case where no initial d information is provided is also considered a novel approach is proposed to match a given d curve in the first image to it corresponding position in the second image the curve is tracked between the two image by a deformable curve constrained by a d motion model the position of the d curve in the second image is then refined by relaxing the motion constraint a a result the correspondence between the curve of both image are known an initial estimate of the d curve can be recovered using the calibration parameter of the stereoscopic system these approach are illustrated by experimental result 
this paper is concerned with three dimensional d analysis of image showing d motion of an observer relative to a scene it present an approach to recovering d motion and structure parameter from multiple feature present in a monocular image sequence such a point region line texture gradient and vanishing line for concreteness the paper focus on flight image of a planar textured surface in this paper a linear integrated estimation method using two view is developed then for robust estimation a nonlinear integrated estimation method using multiple frame is presented the integration of information in these diverse feature is carried out using minimization of image error to reduce computation a sequential batch method is used to compute motion and structure performance is evaluated through simulation and experiment with a real image sequence digitized from a commercially available laserdisc of film taken from flying aircraft 
in this paper it is shown how false operator response due to missing or uncertain data can be signiflcantly reduced or eliminated perhaps the most well knownofsuchefiectsarethevarious edgeefiects which invariably occur at the edge of the input data set further itisshownhowoperatorshavingahigher degreeofselectivityandhighertoleranceagainstnoise can be constructed using simple combination of appropriately chosen convolution the theory is based on linear operation and is general in that it allows for both data and operator to be scalar vector or tensor of higher order threenewmethodsarepresented normalized convolution difierential convolutionand normalized differential convolution all three method are example of the power of the signal certainty philosophy i e the separation of both data and operator into a signal part and a certainty part missing data is simply handled by setting the certainty to zero in the case of uncertain data an estimate of the certainty must accompany the data localization or windowing of operator is done using an applicability function the operator equivalent to certainty not by changing the actual operator coe cients spatially or temporally limited operator are handled by setting the applicability function to zero outside the window consistentwiththephilosophyofthispaperallalgorithms produce a certainty estimate to be used if further processing is needed spectrum analysis is discussed and example of the performance of gradient divergence and curl operator are given 
a general purpose object indexing technique is described that combine the virtue of principal component analysis with the favorable matching property of high dimensional space to achieve high precision recognition an object is represented by a set of high dimensional iconic feature vector comprised of the response of derivative of gaussian filter at a range of orientation and scale since these filter can be shown to form the eigenvectors of arbitrary image containing both natural and man made structure they are well suited for indexing in disparate domain the indexing algorithm us an active vision system in conjunction with a modified form of kanerva s sparse distributed memory which facilitates interpolation between view and provides a convenient platform for learning the association between an object s appearance and it identity the robustness of the indexing method wa experimentally confirmed by subjecting the method to a range of viewing condition and the accuracy wa verified using a well known model database containing a number of complex d object under varying pose 
edge detector which use a quadratic nonlinearity in the filtering stage are attracting interest in machine vision application because of several advantage they enjoy over linear edge detector however many important property of these quadratic or energy edge detector remain unknown in this paper we investigate the behavior of quadratic edge detector under scaling we consider two case important in practice quadratic detector with constituent filter related by the hilbert transform and with constituent filter related by the first spatial derivative we prove that in one dimension hilbert pair detector with gaussian scaling permit the creation of new feature a scale is increased but such causality failure cannot generically occur with derivative pair detector in addition we report experiment that show the effect of these property in practice thus at least one class of quadratic edge detector can have the same desirable scaling property a detector based on linear differential filtering 
specular reflection and interreflection produce strong highlight in brightness image these highlight can cause vision algorithm such a segmentation shape from shading binocular stereo and motion detection to produce erroneous result we present an algorithm for separating the specular and difise component of reflection from image the method iis color and polarization simultaneously to obtain strong constraint on the reflection component at each image point polarization is used to locally determine the color oj the specular component constraining the difsuse color at a pixel to a one dimensional linear subspace this subspact is used to find neighboring pixel whose color is consistent with the pixel diffuse color information from consistent neighbor is used to determine the diffuse color of the pixel in contrast to previous separation algorithm the proposed method can handle highlight that have a varying diffuse component a well a highlight that include region with diffkrent reflectance and material property we present several txperimental result obtained by applying the algorithm to complex scene with textured object and strong interrejtrtions 
in this paper we discus a nonparametric approach for calibrating a ccd camera a constrained topological mapping ctm approach to analyze the systematic imaging error of an image system and compare it with the parametric approach which are based on optimalization and have been discussed by many other author this nonparametric approach ha several distinct feature in this approach some distortion surface are derived directly from the training sample because no analytical form of these surface is assumed when we modeled the distortion by a nonparametric model the systematic imaging error instead of mere lens distortion are considered this give an new approach to analyze the imaging error of a particular imaging system experimental result are given in detail which indicate that both in image projection and in d reconstruction the accuracy is much improved when the nonparametric approach is employed for calibrating a camera 
a method is presented for identifying the view in an engineering drawing along with their associated view point in preparation for d interpretation of the object shape a formal procedure is developed for constructing a set of view based coordinate system that act a intermediate d coordinate to relate the d drawing based coordinate to the d object based coordinate the method can accommodate auxiliary view in addition to the standard orthogonal set and the number of view and their layout in the drawing need not be known a priori moderate error in line placement and view alignment can also be accommodated 
