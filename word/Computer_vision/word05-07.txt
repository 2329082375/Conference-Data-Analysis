component baseddetection method have demonstrated their promise by integrating a set of part detector to deal with large appearance variation of the target however an essential and critical issue i e how to handle the imperfectness of part detector in the integration is not well addressed in the literature this paper proposes a detector ensemble model that consists of a set of substructuredetectors each of which is composed of several partdetectors two important issue are studied both in theory and in practice finding an optimal detector ensemble and detecting target based on an ensemble based on some theoretical analysis a new model selection strategy is proposed to learn an optimal detector ensemble that ha a minimum number of false positive and satisfies the design requirement on the capacity of tolerating missing part in addition this paper also link ensemble based detection to the inference in markov random field and show that the target detection can be done by a max product belief propagation algorithm 
in this paper we propose a method to restore a single image affected by space varying blur the main novelty of our method is the use of recurring pattern a regularization during the restoration process we postulate that restored pattern in the deblurred image should resemble other sharp detail in the input image to this purpose we establish the correspondence of region that are similar up to gaussian blur when two region are in correspondence one can perform deblurring by using the sharpest of the two a a proposal our solution consists of two step first estimate correspondence of similar patch and their relative amount of blurring second restore the input image by imposing the similarity of such recurring pattern a a prior our approach ha been successfully tested on both real and synthetic data 
in this paper we introduce background cut a high quality and realtime foreground layer extraction algorithm from a single video sequence with a moving foreground object and stationary background our algorithm combine background subtraction color and contrast cue to extract a foreground layer accurately and efficiently the key idea in background cut is background contrast attenuation which adaptively attenuates the contrast in the background while preserving the contrast across foreground background boundary our algorithm build upon a key observation that the contrast or more precisely color image gradient in the background is dissimilar to the contrast across foreground background boundary in most case using background cut the layer extraction errorscaused by background cluttercan be substantially reduced moreover we present an adaptive mixture model of global and per pixel background color toimprove the robustnessofour systemundervarious background change experimental result of high quality composite video demonstrate the effectiveness of our background cut algorithm 
we present confocal stereo a new method for computing d shape by controlling the focus and aperture of a lens the method is specifically designed for reconstructing scene with high geometric complexity or fine scale texture to achieve this we introduce the confocal constancy property which state that a the lens aperture varies the pixel intensity of a visible in focus scene point will vary in a sceneindependent way that can be predicted by prior radiometric lens calibration the only requirement is that incoming radiance within the cone subtended by the largest aperture is nearly constant first we develop a detailed lens model that factor out the distortion in high resolution slr camera mp or more with large aperture lens e g f this allows u to assemble an a f aperture focus image afi for each pixel that collect the undistorted measurement over all a aperture and f focus setting in the afi representation confocal constancy reduces to color comparison within region of the afi and lead to focus metric that can be evaluated separately for each pixel we propose two such metric and present initial reconstruction result for complex scene 
manifold learning ha become a vital tool in data driven method for interpretation of video motion capture and handwritten character data when they lie on a low dimensional non linear manifold this work extends manifold learning to classify and parameterize unlabeled data which lie on multiple intersecting manifold this approach significantly increase the domain to which manifold learning method can be applied allowing parameterization of example manifold such a figure eight and intersecting path which are quite common in natural data set this approach introduces several technical contribution which may be of broader interest including node weighted multi dimensional scaling and a fast algorithm for weighted low rank approximation for rank one weight matrix we show example for intersecting manifold of mixed topology and dimension and demonstration on human motion capture data 
in this paper we propose a new definition of curvature called visual curvature it is based on statistic of the extreme point of the height function computed over all direction by gradually ignoring relatively small height a single parameter multi scale curvature is obtained it doe not modify the original contour and the scale parameter ha an obvious geometric meaning the theoretical property and the experiment presented demonstrate that multi scale visual curvature is stable even in the presence of significant noise in particular it can deal with contour with significant gap we also show a relation between multi scale visual curvature and convexity of simple closed curve to our best knowledge the proposed definition of visual curvature is the first ever that applies to regular curve a defined in differential geometry a well a to turn angle of polygonal curve moreover it yield stable curvature estimate of curve in digital image even under sever distortion 
since their debut in snake active contour model have become a standard image analysis technique with several variant now in common use we present a framework called united snake which ha two key feature first it unifies the most popular snake variant including finite difference b spline and hermite polynomial snake in a consistent finite element formulation thus expanding the range of object modeling capability within a uniform snake construction process second it embodies the idea that the heretofore presumed competing technique known a live wire or intelligent scissors is in fact complementary to snake and that the two technique can advantageously be combined by introducing an effective hard constraint mechanism the united snake framework amplifies the efficiency and reproducibility of the component technique and it offer more flexible interactive control while further minimizing user interaction we apply united snake to several different medical image analysis task including the segmentation of neuronal dendrite in em image dynamic chest image analysis the quantification of growth plate in mr image and the isolation of the breast region in mammogram demonstrating the generality accuracy and robustness of the tool 
a variational approach for the background foreground segmentation of multiple view of the same scene is presented the main novelty is the introduction of cost function based on pairwise similarity between pixel across different image these cost function are minimized within a level set framework in addition a warping model rigid or non rigid between the emerging foreground in the different view is imposed thus avoiding the introduction of a specific shape term in the cost function to handle occlusion the thin plate spline tps warping is for the first time employed within the level set framework to model nonrigid deformation the minimization of these cost function lead to simultaneous segmentation and registration of the different view example of segmentation of a variety of object are shown and possible application are proposed 
in this paper we study the possibility of removing aliasing in a scene from a single observation by designing an alias free upsampling scheme we generate the unknown high frequency component of the given partially aliased low resolution image by minimizing the total variation of the interpolant subject to the constraint that part of unaliased spectral component in the low resolution observation are known precisely and under the assumption of sparsity in the data this provides a mathematical basis for exact reproduction of high frequency component with probability approaching one from their aliased observation the primary application of the given approach would be in super resolution imaging 
the fieldof view of a traditionalcamera ha afixed shape this severely restricts how scene element can be composed into an image we present a novel imaging system that us a flexible mirror in conjunctionwith a camerato overcome this limitation by deforming the mirror our system can produce field of view with a wide range of shape and size a captured image is typically a multi perspective view of the scene with spatially varying resolution a a result scene object appear distorted to minimize these distortion we have developed an efficient algorithm that map a captured image to one with almost uniform resolution to determine this mapping we need to know the shape of the mirror for this we have developed a simple calibration method that automatically estimate the mirror shape from it boundary which is visible in the captured image we present a number of example that demonstrate that a flexible field of view imaging system can be used to compose scene in way that have not been possible before this flexibility can be exploited in application such a video surveillance and monitoring 
we present an algorithm for detecting multiple rotational symmetry in natural image given an image it gradient magnitude field is computed and information from the gradient is spread using a diffusion process in the form of a gradient vector flow gvf field we construct a graph whose node correspond to pixel in the image connecting point that are likely to be rotated version of one another the n cycle present in the graph are made to vote for c n symmetry their vote being weighted by the error in transformation between gvf in the neighborhood of the voting point and the irregularity of the n sided polygon formed by the voter the vote are accumulated at the centroid of possible rotational symmetry generating a confidence map for each order of symmetry we tested the method with several natural image 
in this paper we consider the problem of reconstructing the d position and surface normal of point on an unknown arbitrarily shaped refractive surface we show that two viewpoint are sufficient to solve this problem in the general case even if the refractive index is unknown the key requirement are knowledge of a function that map each point on the two image plane to a known d point that refracts to it and light is refracted only once we apply this result to the problem of reconstructing the time varying surface of a liquid from pattern placed below it to do this we introduce a novel stereo matching criterion called refractive disparity appropriate for refractive scene and develop an optimization based algorithm for individually reconstructing the position and normal of each point projecting to a pixel in the input view result on reconstructing a variety of complex deforming liquid surface suggest that our technique can yield detailed reconstruction that capture the dynamic behavior of free flowing liquid 
illumination change cause object appearance to change drastically and many existing tracking algorithm lack the capability to handle this problem the earth mover s distance emd is a similarity measure that is more robust against illumination change however emd is computationally expensive and we therefore propose the differential emd demd algorithm which computes the derivative of the emd with respect to the object location so that the emd doe not need to be computed for every location in the tracking window the fast differential formula is derived based on the sensitivity analysis of the simplex method a applied to the emd formula to further reduce the computation signature i e variable size description of distribution are employed a an object representation the new algorithm model local background scene a well a foreground object to handle scale change in a principled way extensive quantitative evaluation of the proposed algorithm ha been carried out using benchmark sequence and the improvement over the standard mean shift tracker is demonstrated 
this paper describes a new robust regular polygon detector the regular polygon transform is posed a a mixture of regular polygon in a five dimensional space given the edge structure of an image we derive the a posteriori probability for a mixture of regular polygon and thus the probability density function for the appearance of a mixture of regular polygon likely regular polygon can be isolated quickly by discretising and collapsing the search space into three dimension the remaining dimension may be efficiently recovered subsequently using maximum likelihood at the location of the most likely polygon in the subspace this lead to an efficient algorithm also the a posteriori formulation facilitates inclusion of additional a priori information leading to real time application to road sign detection the use of gradient information also reduces noise compared to existing approach such a the generalised hough transform result are presented for image with noise to show stability the detector is also applied to two separate application real time road sign detection for on line driver assistance and feature detection recovering stable feature in rectilinear environment 
we approach mosaicing a a camera tracking problem within a known parameterized surface from a video of a camera moving within a surface we compute a mosaic representing the texture of that surface flattened onto a planar image our approach work by defining a warp between image a a function of surface geometry and camera pose globally optimizing this warp to maximize alignment across all frame determines the camera trajectory and the corresponding flattened mosaic image in contrast to previous mosaicing method which assume planar or distant scene or controlled camera motion our approach enables mosaicing in case where the camera move unpredictably through proximal surface such a in medical endoscopy application 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in contrast to traditional markov random field mrf model we develop a steerable random field srf in which the field potential are defined in term of filter response that are steered to the local image structure in particular we use the structure tensor to obtain derivative response that are either aligned with or orthogonal to the predominant local image structure and analyze the statistic of these steered filter response in natural image clique potential are defined over steered filter response using a gaussian scale mixture model and are learned from training data the srf model connects random field model with anisotropic regularization and provides a statistical motivation for the latter we demonstrate that steering the random field to the local image structure improves image denoising and inpainting performance compared with traditional pairwise mrfs 
object detection can be challenging when the object class exhibit large variation one commonly used strategy is to first partition the space of possible object variation and then train separate classifier for each portion however with continuous space the partition tend to be arbitrary since there are no natural boundary for example consider the continuous range of human body pose in this paper a new formulation is proposed where the detector themselves are associated with continuous parameter and reside in a parameterized function space there are two advantage of this strategy first a priori partitioning of the parameter space is not needed the detector themselves are in a parameterized space second the underlying parameter for object variation can be learned from training data in an unsupervised manner in profile face detection experiment at a fixed false alarm number of our method attains a detection rate of v for the method of viola jones in hand shape detection at a false positive rate of our method achieves a detection rate of v for partition based method in pedestrian detection our method reduces the miss detection rate by a factor of three at a false positive rate of compared with the method of dalal triggs 
nonnegative tensor factorization ntf is a recent multiway multilinear extension of nonnegative matrix factorization nmf where nonnegativity constraint are imposed on the candecomp parafac model in this paper we consider the tucker model with nonnegativity constraint and develop a new tensor factorization method referred to a nonnegative tucker decomposition ntd the main contribution of this paper include multiplicative updating algorithm for ntd an initialization method for speeding up convergence a sparseness control method in tensor factorization through several computer vision example we show the useful behavior of the ntd over existing ntf and nmf method 
recently there ha been a lot of interest in geometrically motivated approach to data analysis in high dimensional space we consider the case where data is drawn from sampling a probability distribution that ha support on or near a submanifold of euclidean space in this paper we propose a novel subspace learning algorithm called neighborhood preserving embedding npe different from principal component analysis pca which aim at preserving the global euclidean structure npe aim at preserving the local neighborhood structure on the data manifold therefore npe is le sensitive to outlier than pca also comparing to the recently proposed manifold learning algorithm such a isomap and locally linear embedding npe is defined everywhere rather than only on the training data point furthermore npe may be conducted in the original space or in the reproducing kernel hilbert space into which data point are mapped this give rise to kernel npe several experiment on face database demonstrate the effectiveness of our algorithm 
in the task of visual object categorization semantic context can play the very important role of reducing ambiguity in object visual appearance in this work we propose to incorporate semantic object context a a post processing step into any off the shelf object categorization model using a conditional random field crf framework our approach maximizes object label agreement according to contextual relevance we compare two source of context one learned from training data and another queried from google set the overall performance of the proposed framework is evaluated on the pascal and msrc datasets our finding conclude that incorporating context into object categorization greatly improves categorization accuracy 
representation for interactive photorealistic visualiz ation of scene range from compact d panorama to dataintensive d light field in this paper we propose a technique for creating a layered representation from a sparse se t of image taken with a hand held camera this representation which we call a layered depth panorama ldp allows the user to experience d by off axis panning it combine the compelling experience of panorama with limited d navigation our choice of representation is motivated by ease of capture and compactness we formulate the problem of constructing the ldp a the recovery of color and geometry in a multi perspective cylindrical disparity space w e leverage a graph cut approach to sequentially determine the disparity and color of each layer using multi view stereo geometry visible through the crack at depth discontinuiti e in a frontmost layer is determined and assigned to layer behind the frontmost layer all layer are then used to render novel panoramic view with parallax we demonstrate our approach on a variety of complex outdoor and indoor scene 
in this paper we present a learning procedure called probabilistic boosting network pbn for joint real time object detection and pose estimation grounded on the law of total probability pbn integrates evidence from two building block namely a multiclass boosting classifier for pose estimation and a boosted detection cascade for object detection by inferring the pose parameter we avoid the exhaustive scanning for the pose which hamper real time requirement in addition we only need one integral image volume with no need of image volume rotation we implement pbn using a graph structured network that alternate the two task of foreground background discrimination and pose estimation for rejecting negative a quickly a possible compared with previous approach we gain accuracy in object localization and pose estimation while noticeably reducing the computation we invoke pbn to detect the left ventricle from a d ultrasound volume processing about volume per second and the left atrium from d image in real time 
we study and compare two novel embedding method for segmenting feature point of piece wise planar structure from two uncalibrated perspective image we show that a set of different homographies can be embedded in different way to a higher dimensional real or complex space so that each homography corresponds to either a complex bilinear form or a real quadratic form each embedding reveals different algebraic property and relation of homographies we give a closed form segmentation solution for each case by utilizing these property based on subspace segmentation method these theoretical result show that one can intrinsically segment a piece wise planar scene from d image without explicitly performing any d reconstruction the resulting segmentation may make subsequent d reconstruction much better conditioned we demonstrate the proposed method with some convincing experimental result 
many source of information relevant to computer vision and machine learning task are often underused one example is the similarity between the element from a novel source such a a speaker writer or printed font by comparing instance emitted by a source we help ensure that similar instance are given the same label previous approach have clustered instance prior to recognition we propose a probabilistic framework that unifies similarity with prior identity and contextual information by fusing information source in a single model we eliminate unrecoverable error that result from processing the information in separate stage and improve overall accuracy the framework also naturally integrates dissimilarity information which ha previously been ignored we demonstrate with an application in printed character recognition from image of sign in natural scene 
we study the challenging problem of maneuvering object tracking with unknown dynamic i e force or torque we investigate the underlying cause of object kinematics and propose a generative model approach that encodes the newtonian dynamic for a rigid body by relating force and torque with object s kinematics in a graphical model this model also accommodates the physical constraint between maneuvering dynamic and object kinematics in a probabilistic form allowing more accurate and efcient object tracking additionally we develop a sequential monte carlo inference algorithm that is embedded with markov chain monte carlo mcmc step to rejuvenate the path of particle the proposed algorithm can estimate both maneuvering dynamic and object kinematics simultaneously the experiment performed on both simulated and real world data of ground vehicle show the robustness and effectiveness of the proposed graphical model based approach along with the sampling based inference algorithm 
we propose a novel approach for determining if a pair of image match each other under the effect of a highdistortion transformation or non structural relation the co occurrence statistic between feature across a pair of image are learned from a training set comprising matched and mismatched image pair these are expresssed in the form of a cross feature ratio table the proposed method doe not require feature to feature correspondence but instead identifies and exploit feature co occurrence that are able to provide discriminative result from the transformation the method not only allows for the matching of test image pair that have substantially different visual content a compared to those present in the training set but also caters for transformation and relation that do not preserve image structure 
abstract this paper present a method for scene flow estimation from a calibrated stereo image sequence the scene flow contains the d displacement field of scene point so that the d optical flow can be seen a a projection of the scene flow onto the image we propose to recover the scene flow by coupling the opticalflow estimation in both camera with dense stereo matching between the image thus reducing the number of unknown per image point the use of a variational framework allows u to properly handle discontinuity in the observed surface and in the d displacement field moreover our approach handle occlusion both for the optical flow and the stereo we obtain a partial differential equation system coupling both the optical flow and the stereo which is numerically solved using an original multiresolution algorithm whereas previous variational method were estimating the d reconstruction at time t and the scene flow separately our method jointly estimate both in a single optimization we present numerical result on synthetic data with ground truth information and we also compare the accuracy of the scene flow projected in one camera with a state of the art single camera optical flow computation method result are also presented on a real stereo sequence with large motion and stereo discontinuity source code and sample data are available for the evaluation of the algorithm 
an ideal shape model should be both invariant to global transformation and robust to local distortion in this paper we present a new shape modeling framework that achieves both efficiently a shape instance is described by a curvature based shape descriptor a profile hidden markov model phmm is then built on such descriptor to represent a class of similar shape phmms are a particular type of hidden markov model hmms with special state and architecture that can tolerate considerable shape contour perturbation including rigid and non rigid deformation occlusion and missing part the sparseness of the phmm structure provides efficient inference and learning algorithm for shape modeling and analysis to capture the global characteristic of a class of shape the phmm parameter are further embedded into a subspace that model long term spatial dependency the new framework can be applied to a wide range of problem such a shape matching registration classification recognition etc our experimental result demonstrate the effectiveness and robustness of this new model in these different setting 
the success of tensor based subspace learning depends heavily on reducing correlation along the column vector of the mode k flattened matrix in this work we study the problem of rearranging element within a tensor in order to maximize these correlation so that information redundancy in tensor data can be more extensively removed by existing tensor based dimensionality reduction algorithm an efficient iterative algorithm is proposed to tackle this essentially integer optimization problem in each step the tensor structure is refined with a spatially constrained earth mover s distance procedure that incrementally rearranges tensor to become more similar to their low rank approximation which have high correlation among feature along certain tensor dimension monotonic convergence of the algorithm is proven using an auxiliary function analogous to that used for proving convergence of the expectation maximization algorithm in addition we present an extension of the algorithm for conducting supervised subspace learning with tensor data experiment in both unsupervised and supervised subspace learning demonstrate the effectiveness of our proposed algorithm in improving data compression performance and classification accuracy 
detection of object of a known class is a fundamental problem of computer vision the appearance of object can change greatly due to illumination view point and articulation for object class with large intra class variation some divide and conquer strategy is necessary tree structured classifier model have been used for multi view multipose object detection in previous work this paper proposes a boosting based learning method called cluster boosted tree cbt to automatically construct tree structured object detector instead of using predefined intra class subcategorization based on domain knowledge we divide the sample space by unsupervised clustering based on discriminative image feature selected by boosting algorithm the sub categorization information of the leaf node is sent back to refine their ancestor classification function we compare our approach with previous related method on several public data set the result show that our approach outperforms the state of the art method 
viola and jones vj demonstrate that cascade classification method can successfully detect object belonging to a single class such a face detecting and identifying object that belong to any of a set of class many class detection is a much more challenging problem we show that object from each class can form a cluster in a classifier space and illustrate example of such cluster using image of real world object our detection algorithm us a decision tree classifier whose internal node each correspond to a vj classifier to propose a class label for every sub image w of a test image or reject it a a negative instance if this w reach a leaf of this tree we then pas w through a subsequent vj cascade of classifier specific to the identified class to determine whether w is truly an instance of the proposed class we perform several empirical study to compare our system for detecting object of any of m class to the obvious approach of running a set of m learned vj cascade classifier one for each class of object on the same image we found that the detection rate are comparable and our many class detection system is about a fast a running a single vj cascade and scale up well a the number of class increase 
the dynamic texture is a stochastic video model that treat the video a a sample from a linear dynamical system the simple model ha been shown to be surprisingly useful in domain such a video synthesis video segmentation and video classification however one major disadvantage of the dynamic texture is that it can only model video where the motion is smooth i e video texture where the pixel value change smoothly in this work we propose an extension of the dynamic texture to address this issue instead of learning a linear observation function with pca we learn a non linear observation function using kernelpca the resulting kernel dynamic texture is capable of modeling a wider range of video motion such a chaotic motion e g turbulent water or camera motion e g panning we derive the necessary step to compute the martin distance between kernel dynamic texture and then validat e the new model through classification experiment on video containing camera motion 
in this paper we propose a robust multi layer background subtraction technique which take advantage of local texture feature represented by local binary pattern s lbp and photometric invariant color measurement in rgb color space lbp can work robustly with respective to light variation on rich texture region but not so efficiently on uniform region in the latter case color information should overcome lbp s limitation due to the illumination invariance of both the lbp feature and the selected color feature the method is able to handle local illumination change such a cast shadow from moving object due to the use of a simple layer based strategy the approach can model moving background pixel with quasiperiodic flickering a well a background scene which may vary over time due to the addition and removal of long time stationary object finally the use of a cross bilateral filter allows to implicitly smooth detection result over regionsof similar intensity and preserve object boundary numerical and qualitative experimental result on both simulated and real data demonstrate the robustness of the proposed method 
video retargeting is the process of transforming an existing video to fit the dimension of an arbitrary display a compelling retargeting aim at preserving the viewer experience by maintaining the information content of important region in the frame whilst keeping their aspect ratio an efficient algorithm for video retargeting is introduced it consists of two stage first the frame is analyzed to detect the importance of each region in the frame then a transformation that respect the analysis shrink le important region more than important one our analysis is fully automatic and based on local saliency motion detection and object detector the performance of the proposed algorithm is demonstrated on a variety of video sequence and compared to the state of the art in image retargeting 
we analyze the least square error for structure from motion with a single infinitesimal motion structure from optical flow we present asymptotic approximation to the noiseless error over two complementary region of motion estimate roughly forward and non forward translation our approximation are powerful tool for understanding the error experiment show that they capture it detailed behavior over the entire range of motion we illustrate the use of our approximation by deriving new property of the least square error we generalize the earlier result of jepson heeger maybank on the ba relief ambiguity and of oliensis on the reflected minimum we explain the error s complexity and it multiple local minimum for roughly forward translation estimate epipoles within the field of view and identify the factor that make this complexity likely for planar scene we clarify the effect of the two fold ambiguity show the existence of a new double ba relief ambiguity and analyze the error s local minimum for nonplanar scene we derive simplified error approximation for reasonable assumption on the image and scene for example we show that the error tends to have a simpler form when many point are tracked we show experimentally that our analysis for zero image noise give a good model of the error for large noise we show theoretically and experimentally that the error for projective structure from motion is simpler but flatter than the error for calibrated image 
many current face recognition algorithm perform badly when the lighting or pose of the probe and gallery image differ in this paper we present a novel algorithm designed for these condition we describe face data a resulting from a generative model which incorporates both withinindividual and between individual variation in recognition we calculate the likelihood that the difference between face image are entirely due to within individual variability we extend this to the non linear case where an arbitrary face manifold can be described and noise is position dependent we also develop a tied version of the algorithm that allows explicit comparison across quite different viewing condition we demonstrate that our model produce state of the art result for i frontal face recognition ii face recognition under varying pose 
abstract d object reconstruction from a single d line drawing is an important problem in both computer vision and graphic manymethods havebeen putforward to solvethis problem but they usually fail when the geometric structure of a dobjectbecomescomplex in this paper a novelapproach based on a divide and conquer strategy is proposed to handle d reconstruction of complex manifold object from single d line drawing the approach consists of three step dividing a complex line drawing into multiple simpler line drawing based on the result of face identification reconstructing the d shape from these simpler line drawing and merging the d shape into one complete object represented by the original line drawing a number of example are given to show that our approach can handle d reconstruction of more complex object than previous method 
this paper present a novel unsupervised color segmentation scheme named roi seg which is based on the main idea of combining a set of different sub segmentation result we propose an efficient algorithm to compute subsegmentations by an integral image approach for calculating bhattacharyya distance and a modified version of the maximally stable extremal region mser detector the sub segmentation algorithm get a region of interest roi a input and detects connected region having similar color appearance a the roi we further introduce a method to identify roi representing the predominant color and texture region of an image passing each of the identified roi to the sub segmentation algorithm provides a set of different segmentation which are then combined by analyzing a local quality criterion the entire approach is fully unsupervised and doe not need a priori information about the image scene the method is compared to state of the art algorithm on the berkeley image database where it show competitive result at reduced computational cost 
two major limitation of real time visual slam algorithm are the restricted range of view over which they can operate and their lack of robustness when faced with erratic camera motion or severe visual occlusion in this paper we describe a visual slam algorithm which address both of these problem the key component is a novel feature description method which is both fast and capable of repeatable correspondence matching over a wide range of viewing angle and scale this is achieved in real time by using a sift like spatial gradient descriptor in conjunction with efficient scale prediction and exemplar based feature representation result are presented illustrating robust realtime slam operation within an office environment 
in this paper we propose a novel region based active contour model for image segmentation with a variational level set formulation by introducing a local binary fitting energy the proposed method is able to utilize accurate local image information for accurate recovery of desired object boundary our method is able to segment image with intensity inhomogeneity weak object boundary and vessel like structure comparison with typical region based active contour model such a piecewise constant model and piecewise smooth model show the advantage of our method in term of computational efficiency and accuracy in addition the proposed method ha promising application for image denoising our method ha been successfully applied to synthetic and real image in different modality 
this paper proposes a novel framework for offline signature verification different from previous method our approach make use of online handwriting instead of handwritten image for registration the online registration enable robust recovery of the writing trajectory from an input offline signature and thus allow effective shape matching between registration and verification signature in addition we propose several new technique to improve the performance of the new signature verification system we formulate and solve the recovery of writing trajectory within the framework of conditional random field we propose a new shape descriptor online context for aligning signature we develop a verification criterion which combine the duration and amplitude variance of handwriting experiment on a benchmark database show that the proposed method significantly outperforms the wellknown offline signature verification method and achieve comparable performance with online signature verification method 
we present a recording scheme image formation model and reconstruction method that enables image based modeling of flowing body of water from multivideo input data the recorded water is dyed with a fluorescent chemical to measure the thickness of a column of water which lead to an image formation model based on integrated emissivities along a viewing ray this model allows for a photo consistency based error measure for a weighted minimal surface which is recovered using a pde obtained from the euler lagrangian formulation of the problem the resulting equation is solved using the level set method 
reliable wide field detection of human activity is an unsolved problem the main difficulty is that low resolution and the unconstrained nature of realistic environment and human behaviour make form cue unreliable here we argue that reliability in faror wide field detection can still be achieved by probabilistic combination of multiple weak but complementary visual cue that do not depend on detailed form analysis to demonstrate we describe a real time bayesian algorithm for localizing human activity in relatively unconstrained scene using motion background subtraction and skin colour cue fast sampling of scale space is achieved using integral image and a flexible norm that can handle sparse cue without loss of statistical power we show that the probabilistic approach far outperforms a representative logical approach in which skin and background subtraction classifier are combined conjunctively our method is currently used in a pre attentive human activity sensor generating saccadic target for an attentive foveated vision system that reliably fixates face over a deg field of view allowing high resolution capture of facial image over a large dynamic scene 
robust integration of range image is an important task for building high quality d model since range image and in particular range map from stereo vision may have a substantial amount of outlier any integration approach aiming at high quality model need an increased level of robustness additionally a certain level of regularization is required to obtain smooth surface computational efficiency and global convergence are further preferable property the contribution of this paper is a unified framework to solve all these issue our method is based on minimizing an energy functionalconsisting of a totalvariation tv regularization force and an l data fidelity term we present a novel and efficient numerical scheme which combine the duality principle for the tv term with a point wise optimization step we demonstrate the superior performance of our algorithm on the well known middlebury multi view database and additionally on real world multi view image 
abstract we present a new formulation to multi view stereo that treat the problem a probabilistic d segmentation previous work ha used the stereo photo consistency criterion a a detector of the boundary between the d scene and the surrounding empty space here we show how the same criterion can also provide a foreground background model that can predict if a d location is inside or outside the scene this model replaces the commonly used naive foreground model based on ballooning which is known to perform poorly in concavity we demonstrate how the probabilistic visibility is linked to previous work on depth ma p fusion and we present a multi resolution graph cut implementation using the new ballooning term that is very efficient both in term of computation time and memory requirement 
we present a multi view stereo algorithm that address the extreme change in lighting scale clutter and other effect in large online community photo collection our idea is to intelligently choose image to match both at a per view and per pixel level we show that such adaptive view selection enables robust performance even with dramatic appearance variability the stereo matching technique take a input sparse d point reconstructed from structure from motion method and iteratively grows surface from these point optimizing for surface normal within a photoconsistency measure significantly improves the matching result while the focus of our approach is to estimate high quality depth map we also show example of merging the resulting depth map into compelling scene reconstruction we demonstrate our algorithm on standard multi view stereo datasets and on casually acquired photo collection of famous scene gathered from the internet 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present an efficient probabilistic method for identity recognition in personal photo album personal photo are usually taken under uncontrolled condition the captured face exhibit significant variation in pose expression and illumination that limit the success of traditional face recognition algorithm we show how to improve recognition rate by incorporating additional cue present in personal photo collection such a clothing appearance and information about when the photo wa taken this is done by constructing a markov random field mrf that effectively combine all available contextual cue in a principled recognition framework performing inference in the mrf produce markedly improved recognition result in a challenging dataset consisting of the personal photo collection of multiple people at the same time the computational cost of our approach remains comparable to that of standard face recognition approach 
in this paper we present a tracking framework for capturing articulated human motion in real time without the need for attaching marker onto the subject s body this is achieved by first obtaining a low dimensional representation of the training motion data using a nonlinear dimensionality reduction technique called back constrained gplvm a prior dynamic model is then learnt from this low dimensional representation by partitioning the motion sequence into elementary movement using an unsupervised em clustering algorithm the temporal dependency between these elementary movement are efficiently captured by a variable length markov model the learnt dynamic model is used to bias the propagation of candidate pose feature vector in the low dimensional space by combining this with an efficient volumetric reconstruction algorithm our framework can quickly evaluate each candidate pose against image evidence captured from multiple view we present result that show our system can accurately track complex structured activity such a ballet dancing in real time 
accurate feature point track through long sequence are a valuable substrate for many computer vision application e g non rigid body tracking video segmentation video matching and even object recognition existing algorithm may be arranged along an axis indicating how global the motion model used to constrain track is local method such a the klt tracker depend on local model of feature appearance and are easily distracted by occlusion repeated structure and image noise this lead to short track many of which are incorrect alone these require considerable postprocessing to obtain a useful result in restricted scene for example a rigid scene through which a camera is moving such postprocessing can make use of global motion model to allow guided matching which yield long high quality feature track however many scene of interest contain multiple motion or significant non rigid deformation which mean that guided matching cannot be applied in this paper we propose a general amalgam of local and global model to improve tracking even in these difficult case by viewing rank constrained tracking a a probabilistic model of d track rather than d motion we obtain a strong robust motion prior derived from the global motion in the scene the result is a simple and powerful prior whose strength is easily tuned enabling it use in any existing tracking algorithm 
relevant component analysis rca ha been proposed for learning distance metric with contextual constraint for image retrieval however rca ha two important disadvantage one is the lack of exploiting negative constraint which can also be informative and the other is it incapability of capturing complex nonlinear relationship between data instance with the contextual information in this paper we propose two algorithm to overcome these two disadvantage i e discriminative component analysis dca and kernel dca compared with other complicated method for distance metric learning our algorithm are rather simple to understand and very easy to solve we evaluate the performance of our algorithm on image retrieval in which experimental result show that our algorithm are effective and promising in learning good quality distance metric for image retrieval 
we consider the problem of rendering high resolution image on a display composed of multiple superimposed lower resolution projector a theoretical analysis of this problem in the literature previously concluded that the multi projector superimposition of low resolution projector cannot produce high resolution image in our recent work we showed to the contrary that super resolution via multiple superimposed projector is indeed theoretically achievable this paper derives practical algorithm for real multi projector system that account for the intraand inter projector variation and that render high quality high resolution content at real time interactive frame rate a camera is used to estimate the geometric photometric and color property of each component projector in a calibration step given this parameter information we demonstrate novel method for efficiently generating optimal subframes so that the resulting projected image is a close a possible to the given high resolution image 
visual surveillance is an important computer vision research problem a more and more surveillance camera appear around u the demand for automatic method for video analysis is increasing such method have broad application including surveillance for safety in public transportation public area and in school and hospital automatic surveillance is also essential in the ght against terrorism in this light the pet data corpus contains seven left luggage scenario with increasing scene complexity the challenge is to automatically determine when piece of luggage have been abandoned by their owner using video data and set an alarm in this paper we present a solution to this problem using a two tiered approach the r st step is to track object in the scene using a trans dimensional markov chain monte carlo tracking model suited for use in generic blob tracking task the tracker us a single camera view and it doe not differentiate between people and luggage the problem of determining if a luggage item is left unattended is solved by analyzing the output of the tracking system in a detection process our model wa evaluated over the entire data set and successfully detected the left luggage in all but one of the seven scenario 
this paper present a novel formulation for the multiview scene reconstruction problem while this formulation benefit from a volumetric scene representation it is amenable to a computationally tractable global optimisation using graph cut the algorithm proposed us the visual hull of the scene to infer occlusion and a a constraint on the topology of the scene a photo consistency based surface cost functional is defined and discretised with a weighted graph the optimal surface under this discretised functional is obtained a the minimum cut solution of the weighted graph our method provides a viewpoint independent surface regularisation approximate handling of occlusion and a tractable optimisation scheme promising experimental result on real scene a well a a quantitative evaluation on a synthetic scene are presented 
this paper present a top down approach to d data analysis by tting a morphable model to scan of face in a unied framework the algorithm optimizes shape texture pose and illumination simultaneously the algorithm can be used a a core component in face recognition from scan in an analysis by synthesis approach raw scan are transformed into a pca based representation that is robust with respect to change in pose and illumination illumination condition are estimated in an explicit simulation that involves specular and diffuse component the algorithm inverts the effect of shading in order to obtain the diffuse reectance in each point of the facial surface our result include illumination correction surface completion and face recognition on the frgc database of scan 
the wide availability of gps sensor is changing the landscape in the application of structure from motion technique for localization in this paper we study the problem of estimating camera orientation from multiple view given the position of the viewpoint in a world coordinate system and a set of point correspondence across the view given three or more view the above problem ha a finite number of solution for three or more point correspondence given six or more view the problem ha a finite number of solution for just two or more point in the three view case we show the necessary and sufficient condition for the three essential matrix to be consistent with a set of known baseline we also introduce a method to recover the absolute orientation of three view in world coordinate from their essential matrix to refine these estimate we perform a least square minimization on the group cross product so so so we report experiment on synthetic data and on data from the iccv computer vision contest 
we present a technique to generate an illumination subspace for arbitrary d face based on the statistic of measured illumination under variable lighting condition from many subject a bilinear model based on the higher order singular value decomposition is used to create a compact illumination subspace given arbitrary shape parameter from a parametric d face model using a fitting procedure based on minimizing the distance of the input image to the dynamically changing illumination subspace we reconstruct a shape specific illumination subspace from a single photograph we use the reconstructed illumination subspace in various face recognition experiment with variable lighting condition and obtain accuracy which are very competitive with previous method that require specific training session or multiple image of the subject 
we present a framework for extracting image contour based on geometric and structural consistency among edge element location and orientation the paper present two contribution first we observe that while the traditiona l edge orientation operator are based on first order derivative orientation a tangent of a localized curve requires third order derivative we derive a numerically stable third order edge operator and show that it outperforms current technique second we consider all discrete n tuplesof edge in a local neighborhood x and retain those that are geometrically consistent with a third order local curv e model this result in a number of ordered discrete combination of edge each represented by a bundle of curve the resulting curve bundle map is a representation of all possible local grouping from which longer contour fragment are constructed we validate our result and show that our framework outperforms traditional approach to contour extraction 
we present a novel model for measurement of the arterial pulse from the supercial temporal artery sta using passive thermal infra red ir sensor the proposed approach ha a physical and physiological basis and a such is of fundamental nature thermal ir camera is used to capture the heat pattern from supercial artery and a blood vessel model is used to describe the pulsatile nature of the blood ow a multresolution wavelet based signal analysis approach is used to extract the arterial pulse waveform which lends itself to various physiological measurement we validate the result using a traditional contact vital sign monitor a a ground truth eight people of different age race and gender have been tested in our study consistent with irb approval the resultant arterial pulse waveform exactly matched the ground truth reading the essence of our approach is the automatic detection of region of arterial pulse measurement rom from which the arterial pulse waveform is extracted to the best of our knowledge the correspondence between non contact thermal ir imaging based measurement of the arterial pulse in the time domain and traditional contact approach ha never been reported in the literature 
projection system can be used to implement augmented reality a well a to create both display and interface on ordinary surface ordinary surface have varying reflectance color and geometry these variation can be accounted for by integrating a camera into the projection system and applying method from computer vision the method currently applied are fundamentally limited since they assume the camera projector and scene are static in this paper we describe a technique for photometrically adaptive projection that make it possible to handle a dynamic environment we begin by presenting a co axial projector camera system whose geometric correspondence is independent of change in the environment to handle photometric change our method us the error between the desired and measured appearance of the projected image a key novel aspect of our algorithm is that we combine a physic based model with dynamic feedback to achieve real time adaptation to the changing environment we verify our algorithm through a wide variety of experiment we show that it is accurate and run in real time our algorithm can be applied broadly to assist hci visualization shape recovery and entertainment application 
we propose an algorithm for estimating disparity and occlusion in stereo video sequence the algorithm defines a prior on sequence of disparity map using a d markov random field and approximately computes the map estimate for the disparity sequence using loopy belief propagation in contrast to previous work on temporal stereo the algorithm i correctly model half occlusion scene point visible in one camera but not the other and ii enforces the so called monotonicity constraint on the boundary of half occluded region the algorithm is also able to exploit temporal coherence more appropriately than many previous approach to temporal stereo by employing additional state in the markov random field these additional state permit rudimentary motion estimation to be performed a part of the belief propagation thus improving the quality of temporal inference parameter of the algorithm are learned from the ground truth disparity of a real stereo sequence qualitative result are shown on real sequence including comparison with competing approach and the performance of the algorithm is assessed quantitatively using the ground truth data 
in cross modal inference we estimate complete field from noisy and missing observation of one sensory modality using structure found in another sensory modality this inference problem occurs in several area including texture reconstruction and reconstruction of geophysical field we propose a method for cross modal inference that simultaneously learns shape recipe between two modality and estimate missing information by using a prior on image structure gleaned from the alternate modality in the absence of a physical basis for representing image prior we use a statistical one that represents correlation in differential feature this is done efficiently using a perturbation sampling scheme using just one example of the alternate modality we produce a factorized ensemble representation of feature correlation that yield efficient solution to large sized spatial inference problem we demonstrate the utility of this approach on cross modal inference with depth and spectral data 
in many vision problem instead of having fully labeled training data it is easier to obtain the input in small group s where the data in each group is constrained to be from the same class but the actual class label is not known such constraint give rise to partial equivalence relation th e absence of class label prevents the use of standard discriminative method in this scenario on the other hand the state of the art technique that use partial equivale nce relation e g relevant component analysis learn proje ctions that are optimal for data representation but not discrimination we show that this lead to poor performance in several real world application especially those with hi ghdimensional data in this paper we present a novel discriminative technique for the classification of weakly labeled data which exploit the null space of data scatter matrix to achieve good classification accuracy we demonstrate the superior performance of both linear and nonlinear version of our approach on face recognition clustering and image retrieval task result are reported on standard datasetsas well a real world image and video from the web 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present a method for automatically learning discriminative image patch for the recognition of given object class the approach applies discriminative training of log linear model to image patch histogram we show that it work well on three task and performs significantly better than other method using the same feature for example the method decides that patch containing an eye are most important for distinguishing face from background image the recognition performance is very competitive with error rate presented in other publication in particular a new best error rate for the caltech motorbike data of is achieved 
this paper describes how facial shape can be modelled using a statistical model that capture variation in surface normal direction to construct this model we make use of the azimuthal equidistant projection to map surface normal from the unit sphere to point on a local tangent plane the variation in surface normal direction are captured using the covariance matrix for the projected point position this allows u to model variation in face shape using a standard point distribution model we train the model on field of surface normal extracted from range data and show how to fit the model to intensity data using constraint on the surface normal direction provided by lambert s law we demonstrate that this process yield accurate facial shape recovery and allows an estimate of the albedo map to be made from single real world face image 
in patch based object recognition there are two important issue on the codebook generation resolution a coarse codebook lack sufcient discriminative power and an over ne one is sensitive to noise codeword selection non discriminative codewords not only increase the codebook size but also can hurt the recognition performance to achieve a discriminative codebook for better recognition this paper argues that these two issue are strongly related and should be solved a a whole in this paper a multi resolution codebook is r st designed via hierarchical clustering with a reasonable size it includes all of the codewords which cross a large number of resolution level more importantly it form a diverse candidate codeword set that is critical to codeword selection a boosting feature selection approach is modied to select the discriminative codewords from this multi resolution codebook by doing so the obtained codebook is composed of the most discriminative codewords culled from different level of resolution experimental study demonstrates the better recognition performance attained by this codebook 
in this paper we measure the response of image patch used a filter on different image ensemble and examine how the response are affected by reducing the resolution of the image ensemble by comparing the set of response obtained at high and reduced resolution we find that for the ensemble of natural and object image car there is a limit resolution of about x and x pixel respectively beyond which the filter response are sig nificantly affected by resolution reduction we support the result by a simple theoretical analysis based on image ensemble statistic there are two consequence to this result first it provides a natural working resolution determined solely from the image ensemble statistic to which higher resolution template can be reduced without losing a significant amount of information this can be used in particular to reduce the search space for useful visual feature i n many application secondly in contrast to many study it suggests that feature that are more complex than gabor patch can be effectively used a first layer filter and combined in order to represent more complex shape and appearance 
path modeling for video surveillance is an active area of research we address the issue of euclidean path modeling in a single camera for activity monitoring in a multicamera video surveillance system the paper proposes i a novel linear solution to auto calibrate any camera observing pedestrian and ii to use these calibrated camera to detect unusual object behavior during the unsupervised training phase after auto calibrating a camera and metric rectifying the input trajectory the input sequence are registered to the satellite imagery and prototype path model are constructed this allows u to estimate metric information directly from the video sequence during the testing phase using our simple yet efficient similarity measure we seek a relation between the input trajectory derived from a sequence and the prototype path model we test the proposed method on synthetic a well a on real world pedestrian sequence 
this paper proposes a new approach to learning a discriminative model of object class incorporating appearance shape and context information efficiently the learned model is used for automatic visual recognition and semantic segmentation of photograph our discriminative model exploit novel feature based on textons which jointly model shape and texture unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of class accurate image segmentation is achieved by incorporating these classifier in a conditional random field efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training method high classification and segmentation accuracy are demonstrated on three different database i our own object class database of photograph of real object viewed under general lighting condition pose and viewpoint ii the class corel subset and iii the class sowerby database used in the proposed algorithm give competitive result both for highly textured e g grass tree highly structured e g car face bike aeroplane and articulated object e g body cow 
component baseddetection method have demonstrated their promise by integrating a set of part detector to deal with large appearance variation of the target however an essential and critical issue i e how to handle the imperfectness of part detector in the integration is not well addressed in the literature this paper proposes a detector ensemble model that consists of a set of substructuredetectors each of which is composed of several partdetectors two important issue are studied both in theory and in practice finding an optimal detector ensemble and detecting target based on an ensemble based on some theoretical analysis a new model selection strategy is proposed to learn an optimal detector ensemble that ha a minimum number of false positive and satisfies the design requirement on the capacity of tolerating missing part in addition this paper also link ensemble based detection to the inference in markov random field and show that the target detection can be done by a max product belief propagation algorithm 
in this paper we propose a method to restore a single image affected by space varying blur the main novelty of our method is the use of recurring pattern a regularization during the restoration process we postulate that restored pattern in the deblurred image should resemble other sharp detail in the input image to this purpose we establish the correspondence of region that are similar up to gaussian blur when two region are in correspondence one can perform deblurring by using the sharpest of the two a a proposal our solution consists of two step first estimate correspondence of similar patch and their relative amount of blurring second restore the input image by imposing the similarity of such recurring pattern a a prior our approach ha been successfully tested on both real and synthetic data 
in this paper we introduce background cut a high quality and realtime foreground layer extraction algorithm from a single video sequence with a moving foreground object and stationary background our algorithm combine background subtraction color and contrast cue to extract a foreground layer accurately and efficiently the key idea in background cut is background contrast attenuation which adaptively attenuates the contrast in the background while preserving the contrast across foreground background boundary our algorithm build upon a key observation that the contrast or more precisely color image gradient in the background is dissimilar to the contrast across foreground background boundary in most case using background cut the layer extraction errorscaused by background cluttercan be substantially reduced moreover we present an adaptive mixture model of global and per pixel background color toimprove the robustnessofour systemundervarious background change experimental result of high quality composite video demonstrate the effectiveness of our background cut algorithm 
we present confocal stereo a new method for computing d shape by controlling the focus and aperture of a lens the method is specifically designed for reconstructing scene with high geometric complexity or fine scale texture to achieve this we introduce the confocal constancy property which state that a the lens aperture varies the pixel intensity of a visible in focus scene point will vary in a sceneindependent way that can be predicted by prior radiometric lens calibration the only requirement is that incoming radiance within the cone subtended by the largest aperture is nearly constant first we develop a detailed lens model that factor out the distortion in high resolution slr camera mp or more with large aperture lens e g f this allows u to assemble an a f aperture focus image afi for each pixel that collect the undistorted measurement over all a aperture and f focus setting in the afi representation confocal constancy reduces to color comparison within region of the afi and lead to focus metric that can be evaluated separately for each pixel we propose two such metric and present initial reconstruction result for complex scene 
manifold learning ha become a vital tool in data driven method for interpretation of video motion capture and handwritten character data when they lie on a low dimensional non linear manifold this work extends manifold learning to classify and parameterize unlabeled data which lie on multiple intersecting manifold this approach significantly increase the domain to which manifold learning method can be applied allowing parameterization of example manifold such a figure eight and intersecting path which are quite common in natural data set this approach introduces several technical contribution which may be of broader interest including node weighted multi dimensional scaling and a fast algorithm for weighted low rank approximation for rank one weight matrix we show example for intersecting manifold of mixed topology and dimension and demonstration on human motion capture data 
in this paper we propose a new definition of curvature called visual curvature it is based on statistic of the extreme point of the height function computed over all direction by gradually ignoring relatively small height a single parameter multi scale curvature is obtained it doe not modify the original contour and the scale parameter ha an obvious geometric meaning the theoretical property and the experiment presented demonstrate that multi scale visual curvature is stable even in the presence of significant noise in particular it can deal with contour with significant gap we also show a relation between multi scale visual curvature and convexity of simple closed curve to our best knowledge the proposed definition of visual curvature is the first ever that applies to regular curve a defined in differential geometry a well a to turn angle of polygonal curve moreover it yield stable curvature estimate of curve in digital image even under sever distortion 
since their debut in snake active contour model have become a standard image analysis technique with several variant now in common use we present a framework called united snake which ha two key feature first it unifies the most popular snake variant including finite difference b spline and hermite polynomial snake in a consistent finite element formulation thus expanding the range of object modeling capability within a uniform snake construction process second it embodies the idea that the heretofore presumed competing technique known a live wire or intelligent scissors is in fact complementary to snake and that the two technique can advantageously be combined by introducing an effective hard constraint mechanism the united snake framework amplifies the efficiency and reproducibility of the component technique and it offer more flexible interactive control while further minimizing user interaction we apply united snake to several different medical image analysis task including the segmentation of neuronal dendrite in em image dynamic chest image analysis the quantification of growth plate in mr image and the isolation of the breast region in mammogram demonstrating the generality accuracy and robustness of the tool 
a variational approach for the background foreground segmentation of multiple view of the same scene is presented the main novelty is the introduction of cost function based on pairwise similarity between pixel across different image these cost function are minimized within a level set framework in addition a warping model rigid or non rigid between the emerging foreground in the different view is imposed thus avoiding the introduction of a specific shape term in the cost function to handle occlusion the thin plate spline tps warping is for the first time employed within the level set framework to model nonrigid deformation the minimization of these cost function lead to simultaneous segmentation and registration of the different view example of segmentation of a variety of object are shown and possible application are proposed 
in this paper we study the possibility of removing aliasing in a scene from a single observation by designing an alias free upsampling scheme we generate the unknown high frequency component of the given partially aliased low resolution image by minimizing the total variation of the interpolant subject to the constraint that part of unaliased spectral component in the low resolution observation are known precisely and under the assumption of sparsity in the data this provides a mathematical basis for exact reproduction of high frequency component with probability approaching one from their aliased observation the primary application of the given approach would be in super resolution imaging 
the fieldof view of a traditionalcamera ha afixed shape this severely restricts how scene element can be composed into an image we present a novel imaging system that us a flexible mirror in conjunctionwith a camerato overcome this limitation by deforming the mirror our system can produce field of view with a wide range of shape and size a captured image is typically a multi perspective view of the scene with spatially varying resolution a a result scene object appear distorted to minimize these distortion we have developed an efficient algorithm that map a captured image to one with almost uniform resolution to determine this mapping we need to know the shape of the mirror for this we have developed a simple calibration method that automatically estimate the mirror shape from it boundary which is visible in the captured image we present a number of example that demonstrate that a flexible field of view imaging system can be used to compose scene in way that have not been possible before this flexibility can be exploited in application such a video surveillance and monitoring 
we present an algorithm for detecting multiple rotational symmetry in natural image given an image it gradient magnitude field is computed and information from the gradient is spread using a diffusion process in the form of a gradient vector flow gvf field we construct a graph whose node correspond to pixel in the image connecting point that are likely to be rotated version of one another the n cycle present in the graph are made to vote for c n symmetry their vote being weighted by the error in transformation between gvf in the neighborhood of the voting point and the irregularity of the n sided polygon formed by the voter the vote are accumulated at the centroid of possible rotational symmetry generating a confidence map for each order of symmetry we tested the method with several natural image 
in this paper we consider the problem of reconstructing the d position and surface normal of point on an unknown arbitrarily shaped refractive surface we show that two viewpoint are sufficient to solve this problem in the general case even if the refractive index is unknown the key requirement are knowledge of a function that map each point on the two image plane to a known d point that refracts to it and light is refracted only once we apply this result to the problem of reconstructing the time varying surface of a liquid from pattern placed below it to do this we introduce a novel stereo matching criterion called refractive disparity appropriate for refractive scene and develop an optimization based algorithm for individually reconstructing the position and normal of each point projecting to a pixel in the input view result on reconstructing a variety of complex deforming liquid surface suggest that our technique can yield detailed reconstruction that capture the dynamic behavior of free flowing liquid 
illumination change cause object appearance to change drastically and many existing tracking algorithm lack the capability to handle this problem the earth mover s distance emd is a similarity measure that is more robust against illumination change however emd is computationally expensive and we therefore propose the differential emd demd algorithm which computes the derivative of the emd with respect to the object location so that the emd doe not need to be computed for every location in the tracking window the fast differential formula is derived based on the sensitivity analysis of the simplex method a applied to the emd formula to further reduce the computation signature i e variable size description of distribution are employed a an object representation the new algorithm model local background scene a well a foreground object to handle scale change in a principled way extensive quantitative evaluation of the proposed algorithm ha been carried out using benchmark sequence and the improvement over the standard mean shift tracker is demonstrated 
this paper describes a new robust regular polygon detector the regular polygon transform is posed a a mixture of regular polygon in a five dimensional space given the edge structure of an image we derive the a posteriori probability for a mixture of regular polygon and thus the probability density function for the appearance of a mixture of regular polygon likely regular polygon can be isolated quickly by discretising and collapsing the search space into three dimension the remaining dimension may be efficiently recovered subsequently using maximum likelihood at the location of the most likely polygon in the subspace this lead to an efficient algorithm also the a posteriori formulation facilitates inclusion of additional a priori information leading to real time application to road sign detection the use of gradient information also reduces noise compared to existing approach such a the generalised hough transform result are presented for image with noise to show stability the detector is also applied to two separate application real time road sign detection for on line driver assistance and feature detection recovering stable feature in rectilinear environment 
we approach mosaicing a a camera tracking problem within a known parameterized surface from a video of a camera moving within a surface we compute a mosaic representing the texture of that surface flattened onto a planar image our approach work by defining a warp between image a a function of surface geometry and camera pose globally optimizing this warp to maximize alignment across all frame determines the camera trajectory and the corresponding flattened mosaic image in contrast to previous mosaicing method which assume planar or distant scene or controlled camera motion our approach enables mosaicing in case where the camera move unpredictably through proximal surface such a in medical endoscopy application 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in contrast to traditional markov random field mrf model we develop a steerable random field srf in which the field potential are defined in term of filter response that are steered to the local image structure in particular we use the structure tensor to obtain derivative response that are either aligned with or orthogonal to the predominant local image structure and analyze the statistic of these steered filter response in natural image clique potential are defined over steered filter response using a gaussian scale mixture model and are learned from training data the srf model connects random field model with anisotropic regularization and provides a statistical motivation for the latter we demonstrate that steering the random field to the local image structure improves image denoising and inpainting performance compared with traditional pairwise mrfs 
object detection can be challenging when the object class exhibit large variation one commonly used strategy is to first partition the space of possible object variation and then train separate classifier for each portion however with continuous space the partition tend to be arbitrary since there are no natural boundary for example consider the continuous range of human body pose in this paper a new formulation is proposed where the detector themselves are associated with continuous parameter and reside in a parameterized function space there are two advantage of this strategy first a priori partitioning of the parameter space is not needed the detector themselves are in a parameterized space second the underlying parameter for object variation can be learned from training data in an unsupervised manner in profile face detection experiment at a fixed false alarm number of our method attains a detection rate of v for the method of viola jones in hand shape detection at a false positive rate of our method achieves a detection rate of v for partition based method in pedestrian detection our method reduces the miss detection rate by a factor of three at a false positive rate of compared with the method of dalal triggs 
nonnegative tensor factorization ntf is a recent multiway multilinear extension of nonnegative matrix factorization nmf where nonnegativity constraint are imposed on the candecomp parafac model in this paper we consider the tucker model with nonnegativity constraint and develop a new tensor factorization method referred to a nonnegative tucker decomposition ntd the main contribution of this paper include multiplicative updating algorithm for ntd an initialization method for speeding up convergence a sparseness control method in tensor factorization through several computer vision example we show the useful behavior of the ntd over existing ntf and nmf method 
recently there ha been a lot of interest in geometrically motivated approach to data analysis in high dimensional space we consider the case where data is drawn from sampling a probability distribution that ha support on or near a submanifold of euclidean space in this paper we propose a novel subspace learning algorithm called neighborhood preserving embedding npe different from principal component analysis pca which aim at preserving the global euclidean structure npe aim at preserving the local neighborhood structure on the data manifold therefore npe is le sensitive to outlier than pca also comparing to the recently proposed manifold learning algorithm such a isomap and locally linear embedding npe is defined everywhere rather than only on the training data point furthermore npe may be conducted in the original space or in the reproducing kernel hilbert space into which data point are mapped this give rise to kernel npe several experiment on face database demonstrate the effectiveness of our algorithm 
in the task of visual object categorization semantic context can play the very important role of reducing ambiguity in object visual appearance in this work we propose to incorporate semantic object context a a post processing step into any off the shelf object categorization model using a conditional random field crf framework our approach maximizes object label agreement according to contextual relevance we compare two source of context one learned from training data and another queried from google set the overall performance of the proposed framework is evaluated on the pascal and msrc datasets our finding conclude that incorporating context into object categorization greatly improves categorization accuracy 
representation for interactive photorealistic visualiz ation of scene range from compact d panorama to dataintensive d light field in this paper we propose a technique for creating a layered representation from a sparse se t of image taken with a hand held camera this representation which we call a layered depth panorama ldp allows the user to experience d by off axis panning it combine the compelling experience of panorama with limited d navigation our choice of representation is motivated by ease of capture and compactness we formulate the problem of constructing the ldp a the recovery of color and geometry in a multi perspective cylindrical disparity space w e leverage a graph cut approach to sequentially determine the disparity and color of each layer using multi view stereo geometry visible through the crack at depth discontinuiti e in a frontmost layer is determined and assigned to layer behind the frontmost layer all layer are then used to render novel panoramic view with parallax we demonstrate our approach on a variety of complex outdoor and indoor scene 
in this paper we present a learning procedure called probabilistic boosting network pbn for joint real time object detection and pose estimation grounded on the law of total probability pbn integrates evidence from two building block namely a multiclass boosting classifier for pose estimation and a boosted detection cascade for object detection by inferring the pose parameter we avoid the exhaustive scanning for the pose which hamper real time requirement in addition we only need one integral image volume with no need of image volume rotation we implement pbn using a graph structured network that alternate the two task of foreground background discrimination and pose estimation for rejecting negative a quickly a possible compared with previous approach we gain accuracy in object localization and pose estimation while noticeably reducing the computation we invoke pbn to detect the left ventricle from a d ultrasound volume processing about volume per second and the left atrium from d image in real time 
we study and compare two novel embedding method for segmenting feature point of piece wise planar structure from two uncalibrated perspective image we show that a set of different homographies can be embedded in different way to a higher dimensional real or complex space so that each homography corresponds to either a complex bilinear form or a real quadratic form each embedding reveals different algebraic property and relation of homographies we give a closed form segmentation solution for each case by utilizing these property based on subspace segmentation method these theoretical result show that one can intrinsically segment a piece wise planar scene from d image without explicitly performing any d reconstruction the resulting segmentation may make subsequent d reconstruction much better conditioned we demonstrate the proposed method with some convincing experimental result 
many source of information relevant to computer vision and machine learning task are often underused one example is the similarity between the element from a novel source such a a speaker writer or printed font by comparing instance emitted by a source we help ensure that similar instance are given the same label previous approach have clustered instance prior to recognition we propose a probabilistic framework that unifies similarity with prior identity and contextual information by fusing information source in a single model we eliminate unrecoverable error that result from processing the information in separate stage and improve overall accuracy the framework also naturally integrates dissimilarity information which ha previously been ignored we demonstrate with an application in printed character recognition from image of sign in natural scene 
we study the challenging problem of maneuvering object tracking with unknown dynamic i e force or torque we investigate the underlying cause of object kinematics and propose a generative model approach that encodes the newtonian dynamic for a rigid body by relating force and torque with object s kinematics in a graphical model this model also accommodates the physical constraint between maneuvering dynamic and object kinematics in a probabilistic form allowing more accurate and efcient object tracking additionally we develop a sequential monte carlo inference algorithm that is embedded with markov chain monte carlo mcmc step to rejuvenate the path of particle the proposed algorithm can estimate both maneuvering dynamic and object kinematics simultaneously the experiment performed on both simulated and real world data of ground vehicle show the robustness and effectiveness of the proposed graphical model based approach along with the sampling based inference algorithm 
we propose a novel approach for determining if a pair of image match each other under the effect of a highdistortion transformation or non structural relation the co occurrence statistic between feature across a pair of image are learned from a training set comprising matched and mismatched image pair these are expresssed in the form of a cross feature ratio table the proposed method doe not require feature to feature correspondence but instead identifies and exploit feature co occurrence that are able to provide discriminative result from the transformation the method not only allows for the matching of test image pair that have substantially different visual content a compared to those present in the training set but also caters for transformation and relation that do not preserve image structure 
abstract this paper present a method for scene flow estimation from a calibrated stereo image sequence the scene flow contains the d displacement field of scene point so that the d optical flow can be seen a a projection of the scene flow onto the image we propose to recover the scene flow by coupling the opticalflow estimation in both camera with dense stereo matching between the image thus reducing the number of unknown per image point the use of a variational framework allows u to properly handle discontinuity in the observed surface and in the d displacement field moreover our approach handle occlusion both for the optical flow and the stereo we obtain a partial differential equation system coupling both the optical flow and the stereo which is numerically solved using an original multiresolution algorithm whereas previous variational method were estimating the d reconstruction at time t and the scene flow separately our method jointly estimate both in a single optimization we present numerical result on synthetic data with ground truth information and we also compare the accuracy of the scene flow projected in one camera with a state of the art single camera optical flow computation method result are also presented on a real stereo sequence with large motion and stereo discontinuity source code and sample data are available for the evaluation of the algorithm 
an ideal shape model should be both invariant to global transformation and robust to local distortion in this paper we present a new shape modeling framework that achieves both efficiently a shape instance is described by a curvature based shape descriptor a profile hidden markov model phmm is then built on such descriptor to represent a class of similar shape phmms are a particular type of hidden markov model hmms with special state and architecture that can tolerate considerable shape contour perturbation including rigid and non rigid deformation occlusion and missing part the sparseness of the phmm structure provides efficient inference and learning algorithm for shape modeling and analysis to capture the global characteristic of a class of shape the phmm parameter are further embedded into a subspace that model long term spatial dependency the new framework can be applied to a wide range of problem such a shape matching registration classification recognition etc our experimental result demonstrate the effectiveness and robustness of this new model in these different setting 
the success of tensor based subspace learning depends heavily on reducing correlation along the column vector of the mode k flattened matrix in this work we study the problem of rearranging element within a tensor in order to maximize these correlation so that information redundancy in tensor data can be more extensively removed by existing tensor based dimensionality reduction algorithm an efficient iterative algorithm is proposed to tackle this essentially integer optimization problem in each step the tensor structure is refined with a spatially constrained earth mover s distance procedure that incrementally rearranges tensor to become more similar to their low rank approximation which have high correlation among feature along certain tensor dimension monotonic convergence of the algorithm is proven using an auxiliary function analogous to that used for proving convergence of the expectation maximization algorithm in addition we present an extension of the algorithm for conducting supervised subspace learning with tensor data experiment in both unsupervised and supervised subspace learning demonstrate the effectiveness of our proposed algorithm in improving data compression performance and classification accuracy 
detection of object of a known class is a fundamental problem of computer vision the appearance of object can change greatly due to illumination view point and articulation for object class with large intra class variation some divide and conquer strategy is necessary tree structured classifier model have been used for multi view multipose object detection in previous work this paper proposes a boosting based learning method called cluster boosted tree cbt to automatically construct tree structured object detector instead of using predefined intra class subcategorization based on domain knowledge we divide the sample space by unsupervised clustering based on discriminative image feature selected by boosting algorithm the sub categorization information of the leaf node is sent back to refine their ancestor classification function we compare our approach with previous related method on several public data set the result show that our approach outperforms the state of the art method 
viola and jones vj demonstrate that cascade classification method can successfully detect object belonging to a single class such a face detecting and identifying object that belong to any of a set of class many class detection is a much more challenging problem we show that object from each class can form a cluster in a classifier space and illustrate example of such cluster using image of real world object our detection algorithm us a decision tree classifier whose internal node each correspond to a vj classifier to propose a class label for every sub image w of a test image or reject it a a negative instance if this w reach a leaf of this tree we then pas w through a subsequent vj cascade of classifier specific to the identified class to determine whether w is truly an instance of the proposed class we perform several empirical study to compare our system for detecting object of any of m class to the obvious approach of running a set of m learned vj cascade classifier one for each class of object on the same image we found that the detection rate are comparable and our many class detection system is about a fast a running a single vj cascade and scale up well a the number of class increase 
the dynamic texture is a stochastic video model that treat the video a a sample from a linear dynamical system the simple model ha been shown to be surprisingly useful in domain such a video synthesis video segmentation and video classification however one major disadvantage of the dynamic texture is that it can only model video where the motion is smooth i e video texture where the pixel value change smoothly in this work we propose an extension of the dynamic texture to address this issue instead of learning a linear observation function with pca we learn a non linear observation function using kernelpca the resulting kernel dynamic texture is capable of modeling a wider range of video motion such a chaotic motion e g turbulent water or camera motion e g panning we derive the necessary step to compute the martin distance between kernel dynamic texture and then validat e the new model through classification experiment on video containing camera motion 
in this paper we propose a robust multi layer background subtraction technique which take advantage of local texture feature represented by local binary pattern s lbp and photometric invariant color measurement in rgb color space lbp can work robustly with respective to light variation on rich texture region but not so efficiently on uniform region in the latter case color information should overcome lbp s limitation due to the illumination invariance of both the lbp feature and the selected color feature the method is able to handle local illumination change such a cast shadow from moving object due to the use of a simple layer based strategy the approach can model moving background pixel with quasiperiodic flickering a well a background scene which may vary over time due to the addition and removal of long time stationary object finally the use of a cross bilateral filter allows to implicitly smooth detection result over regionsof similar intensity and preserve object boundary numerical and qualitative experimental result on both simulated and real data demonstrate the robustness of the proposed method 
video retargeting is the process of transforming an existing video to fit the dimension of an arbitrary display a compelling retargeting aim at preserving the viewer experience by maintaining the information content of important region in the frame whilst keeping their aspect ratio an efficient algorithm for video retargeting is introduced it consists of two stage first the frame is analyzed to detect the importance of each region in the frame then a transformation that respect the analysis shrink le important region more than important one our analysis is fully automatic and based on local saliency motion detection and object detector the performance of the proposed algorithm is demonstrated on a variety of video sequence and compared to the state of the art in image retargeting 
we analyze the least square error for structure from motion with a single infinitesimal motion structure from optical flow we present asymptotic approximation to the noiseless error over two complementary region of motion estimate roughly forward and non forward translation our approximation are powerful tool for understanding the error experiment show that they capture it detailed behavior over the entire range of motion we illustrate the use of our approximation by deriving new property of the least square error we generalize the earlier result of jepson heeger maybank on the ba relief ambiguity and of oliensis on the reflected minimum we explain the error s complexity and it multiple local minimum for roughly forward translation estimate epipoles within the field of view and identify the factor that make this complexity likely for planar scene we clarify the effect of the two fold ambiguity show the existence of a new double ba relief ambiguity and analyze the error s local minimum for nonplanar scene we derive simplified error approximation for reasonable assumption on the image and scene for example we show that the error tends to have a simpler form when many point are tracked we show experimentally that our analysis for zero image noise give a good model of the error for large noise we show theoretically and experimentally that the error for projective structure from motion is simpler but flatter than the error for calibrated image 
many current face recognition algorithm perform badly when the lighting or pose of the probe and gallery image differ in this paper we present a novel algorithm designed for these condition we describe face data a resulting from a generative model which incorporates both withinindividual and between individual variation in recognition we calculate the likelihood that the difference between face image are entirely due to within individual variability we extend this to the non linear case where an arbitrary face manifold can be described and noise is position dependent we also develop a tied version of the algorithm that allows explicit comparison across quite different viewing condition we demonstrate that our model produce state of the art result for i frontal face recognition ii face recognition under varying pose 
abstract d object reconstruction from a single d line drawing is an important problem in both computer vision and graphic manymethods havebeen putforward to solvethis problem but they usually fail when the geometric structure of a dobjectbecomescomplex in this paper a novelapproach based on a divide and conquer strategy is proposed to handle d reconstruction of complex manifold object from single d line drawing the approach consists of three step dividing a complex line drawing into multiple simpler line drawing based on the result of face identification reconstructing the d shape from these simpler line drawing and merging the d shape into one complete object represented by the original line drawing a number of example are given to show that our approach can handle d reconstruction of more complex object than previous method 
this paper present a novel unsupervised color segmentation scheme named roi seg which is based on the main idea of combining a set of different sub segmentation result we propose an efficient algorithm to compute subsegmentations by an integral image approach for calculating bhattacharyya distance and a modified version of the maximally stable extremal region mser detector the sub segmentation algorithm get a region of interest roi a input and detects connected region having similar color appearance a the roi we further introduce a method to identify roi representing the predominant color and texture region of an image passing each of the identified roi to the sub segmentation algorithm provides a set of different segmentation which are then combined by analyzing a local quality criterion the entire approach is fully unsupervised and doe not need a priori information about the image scene the method is compared to state of the art algorithm on the berkeley image database where it show competitive result at reduced computational cost 
two major limitation of real time visual slam algorithm are the restricted range of view over which they can operate and their lack of robustness when faced with erratic camera motion or severe visual occlusion in this paper we describe a visual slam algorithm which address both of these problem the key component is a novel feature description method which is both fast and capable of repeatable correspondence matching over a wide range of viewing angle and scale this is achieved in real time by using a sift like spatial gradient descriptor in conjunction with efficient scale prediction and exemplar based feature representation result are presented illustrating robust realtime slam operation within an office environment 
in this paper we propose a novel region based active contour model for image segmentation with a variational level set formulation by introducing a local binary fitting energy the proposed method is able to utilize accurate local image information for accurate recovery of desired object boundary our method is able to segment image with intensity inhomogeneity weak object boundary and vessel like structure comparison with typical region based active contour model such a piecewise constant model and piecewise smooth model show the advantage of our method in term of computational efficiency and accuracy in addition the proposed method ha promising application for image denoising our method ha been successfully applied to synthetic and real image in different modality 
this paper proposes a novel framework for offline signature verification different from previous method our approach make use of online handwriting instead of handwritten image for registration the online registration enable robust recovery of the writing trajectory from an input offline signature and thus allow effective shape matching between registration and verification signature in addition we propose several new technique to improve the performance of the new signature verification system we formulate and solve the recovery of writing trajectory within the framework of conditional random field we propose a new shape descriptor online context for aligning signature we develop a verification criterion which combine the duration and amplitude variance of handwriting experiment on a benchmark database show that the proposed method significantly outperforms the wellknown offline signature verification method and achieve comparable performance with online signature verification method 
we present a recording scheme image formation model and reconstruction method that enables image based modeling of flowing body of water from multivideo input data the recorded water is dyed with a fluorescent chemical to measure the thickness of a column of water which lead to an image formation model based on integrated emissivities along a viewing ray this model allows for a photo consistency based error measure for a weighted minimal surface which is recovered using a pde obtained from the euler lagrangian formulation of the problem the resulting equation is solved using the level set method 
reliable wide field detection of human activity is an unsolved problem the main difficulty is that low resolution and the unconstrained nature of realistic environment and human behaviour make form cue unreliable here we argue that reliability in faror wide field detection can still be achieved by probabilistic combination of multiple weak but complementary visual cue that do not depend on detailed form analysis to demonstrate we describe a real time bayesian algorithm for localizing human activity in relatively unconstrained scene using motion background subtraction and skin colour cue fast sampling of scale space is achieved using integral image and a flexible norm that can handle sparse cue without loss of statistical power we show that the probabilistic approach far outperforms a representative logical approach in which skin and background subtraction classifier are combined conjunctively our method is currently used in a pre attentive human activity sensor generating saccadic target for an attentive foveated vision system that reliably fixates face over a deg field of view allowing high resolution capture of facial image over a large dynamic scene 
robust integration of range image is an important task for building high quality d model since range image and in particular range map from stereo vision may have a substantial amount of outlier any integration approach aiming at high quality model need an increased level of robustness additionally a certain level of regularization is required to obtain smooth surface computational efficiency and global convergence are further preferable property the contribution of this paper is a unified framework to solve all these issue our method is based on minimizing an energy functionalconsisting of a totalvariation tv regularization force and an l data fidelity term we present a novel and efficient numerical scheme which combine the duality principle for the tv term with a point wise optimization step we demonstrate the superior performance of our algorithm on the well known middlebury multi view database and additionally on real world multi view image 
abstract we present a new formulation to multi view stereo that treat the problem a probabilistic d segmentation previous work ha used the stereo photo consistency criterion a a detector of the boundary between the d scene and the surrounding empty space here we show how the same criterion can also provide a foreground background model that can predict if a d location is inside or outside the scene this model replaces the commonly used naive foreground model based on ballooning which is known to perform poorly in concavity we demonstrate how the probabilistic visibility is linked to previous work on depth ma p fusion and we present a multi resolution graph cut implementation using the new ballooning term that is very efficient both in term of computation time and memory requirement 
we present a multi view stereo algorithm that address the extreme change in lighting scale clutter and other effect in large online community photo collection our idea is to intelligently choose image to match both at a per view and per pixel level we show that such adaptive view selection enables robust performance even with dramatic appearance variability the stereo matching technique take a input sparse d point reconstructed from structure from motion method and iteratively grows surface from these point optimizing for surface normal within a photoconsistency measure significantly improves the matching result while the focus of our approach is to estimate high quality depth map we also show example of merging the resulting depth map into compelling scene reconstruction we demonstrate our algorithm on standard multi view stereo datasets and on casually acquired photo collection of famous scene gathered from the internet 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present an efficient probabilistic method for identity recognition in personal photo album personal photo are usually taken under uncontrolled condition the captured face exhibit significant variation in pose expression and illumination that limit the success of traditional face recognition algorithm we show how to improve recognition rate by incorporating additional cue present in personal photo collection such a clothing appearance and information about when the photo wa taken this is done by constructing a markov random field mrf that effectively combine all available contextual cue in a principled recognition framework performing inference in the mrf produce markedly improved recognition result in a challenging dataset consisting of the personal photo collection of multiple people at the same time the computational cost of our approach remains comparable to that of standard face recognition approach 
in this paper we present a tracking framework for capturing articulated human motion in real time without the need for attaching marker onto the subject s body this is achieved by first obtaining a low dimensional representation of the training motion data using a nonlinear dimensionality reduction technique called back constrained gplvm a prior dynamic model is then learnt from this low dimensional representation by partitioning the motion sequence into elementary movement using an unsupervised em clustering algorithm the temporal dependency between these elementary movement are efficiently captured by a variable length markov model the learnt dynamic model is used to bias the propagation of candidate pose feature vector in the low dimensional space by combining this with an efficient volumetric reconstruction algorithm our framework can quickly evaluate each candidate pose against image evidence captured from multiple view we present result that show our system can accurately track complex structured activity such a ballet dancing in real time 
accurate feature point track through long sequence are a valuable substrate for many computer vision application e g non rigid body tracking video segmentation video matching and even object recognition existing algorithm may be arranged along an axis indicating how global the motion model used to constrain track is local method such a the klt tracker depend on local model of feature appearance and are easily distracted by occlusion repeated structure and image noise this lead to short track many of which are incorrect alone these require considerable postprocessing to obtain a useful result in restricted scene for example a rigid scene through which a camera is moving such postprocessing can make use of global motion model to allow guided matching which yield long high quality feature track however many scene of interest contain multiple motion or significant non rigid deformation which mean that guided matching cannot be applied in this paper we propose a general amalgam of local and global model to improve tracking even in these difficult case by viewing rank constrained tracking a a probabilistic model of d track rather than d motion we obtain a strong robust motion prior derived from the global motion in the scene the result is a simple and powerful prior whose strength is easily tuned enabling it use in any existing tracking algorithm 
relevant component analysis rca ha been proposed for learning distance metric with contextual constraint for image retrieval however rca ha two important disadvantage one is the lack of exploiting negative constraint which can also be informative and the other is it incapability of capturing complex nonlinear relationship between data instance with the contextual information in this paper we propose two algorithm to overcome these two disadvantage i e discriminative component analysis dca and kernel dca compared with other complicated method for distance metric learning our algorithm are rather simple to understand and very easy to solve we evaluate the performance of our algorithm on image retrieval in which experimental result show that our algorithm are effective and promising in learning good quality distance metric for image retrieval 
we consider the problem of rendering high resolution image on a display composed of multiple superimposed lower resolution projector a theoretical analysis of this problem in the literature previously concluded that the multi projector superimposition of low resolution projector cannot produce high resolution image in our recent work we showed to the contrary that super resolution via multiple superimposed projector is indeed theoretically achievable this paper derives practical algorithm for real multi projector system that account for the intraand inter projector variation and that render high quality high resolution content at real time interactive frame rate a camera is used to estimate the geometric photometric and color property of each component projector in a calibration step given this parameter information we demonstrate novel method for efficiently generating optimal subframes so that the resulting projected image is a close a possible to the given high resolution image 
visual surveillance is an important computer vision research problem a more and more surveillance camera appear around u the demand for automatic method for video analysis is increasing such method have broad application including surveillance for safety in public transportation public area and in school and hospital automatic surveillance is also essential in the ght against terrorism in this light the pet data corpus contains seven left luggage scenario with increasing scene complexity the challenge is to automatically determine when piece of luggage have been abandoned by their owner using video data and set an alarm in this paper we present a solution to this problem using a two tiered approach the r st step is to track object in the scene using a trans dimensional markov chain monte carlo tracking model suited for use in generic blob tracking task the tracker us a single camera view and it doe not differentiate between people and luggage the problem of determining if a luggage item is left unattended is solved by analyzing the output of the tracking system in a detection process our model wa evaluated over the entire data set and successfully detected the left luggage in all but one of the seven scenario 
this paper present a novel formulation for the multiview scene reconstruction problem while this formulation benefit from a volumetric scene representation it is amenable to a computationally tractable global optimisation using graph cut the algorithm proposed us the visual hull of the scene to infer occlusion and a a constraint on the topology of the scene a photo consistency based surface cost functional is defined and discretised with a weighted graph the optimal surface under this discretised functional is obtained a the minimum cut solution of the weighted graph our method provides a viewpoint independent surface regularisation approximate handling of occlusion and a tractable optimisation scheme promising experimental result on real scene a well a a quantitative evaluation on a synthetic scene are presented 
this paper present a top down approach to d data analysis by tting a morphable model to scan of face in a unied framework the algorithm optimizes shape texture pose and illumination simultaneously the algorithm can be used a a core component in face recognition from scan in an analysis by synthesis approach raw scan are transformed into a pca based representation that is robust with respect to change in pose and illumination illumination condition are estimated in an explicit simulation that involves specular and diffuse component the algorithm inverts the effect of shading in order to obtain the diffuse reectance in each point of the facial surface our result include illumination correction surface completion and face recognition on the frgc database of scan 
the wide availability of gps sensor is changing the landscape in the application of structure from motion technique for localization in this paper we study the problem of estimating camera orientation from multiple view given the position of the viewpoint in a world coordinate system and a set of point correspondence across the view given three or more view the above problem ha a finite number of solution for three or more point correspondence given six or more view the problem ha a finite number of solution for just two or more point in the three view case we show the necessary and sufficient condition for the three essential matrix to be consistent with a set of known baseline we also introduce a method to recover the absolute orientation of three view in world coordinate from their essential matrix to refine these estimate we perform a least square minimization on the group cross product so so so we report experiment on synthetic data and on data from the iccv computer vision contest 
we present a technique to generate an illumination subspace for arbitrary d face based on the statistic of measured illumination under variable lighting condition from many subject a bilinear model based on the higher order singular value decomposition is used to create a compact illumination subspace given arbitrary shape parameter from a parametric d face model using a fitting procedure based on minimizing the distance of the input image to the dynamically changing illumination subspace we reconstruct a shape specific illumination subspace from a single photograph we use the reconstructed illumination subspace in various face recognition experiment with variable lighting condition and obtain accuracy which are very competitive with previous method that require specific training session or multiple image of the subject 
we present a framework for extracting image contour based on geometric and structural consistency among edge element location and orientation the paper present two contribution first we observe that while the traditiona l edge orientation operator are based on first order derivative orientation a tangent of a localized curve requires third order derivative we derive a numerically stable third order edge operator and show that it outperforms current technique second we consider all discrete n tuplesof edge in a local neighborhood x and retain those that are geometrically consistent with a third order local curv e model this result in a number of ordered discrete combination of edge each represented by a bundle of curve the resulting curve bundle map is a representation of all possible local grouping from which longer contour fragment are constructed we validate our result and show that our framework outperforms traditional approach to contour extraction 
we present a novel model for measurement of the arterial pulse from the supercial temporal artery sta using passive thermal infra red ir sensor the proposed approach ha a physical and physiological basis and a such is of fundamental nature thermal ir camera is used to capture the heat pattern from supercial artery and a blood vessel model is used to describe the pulsatile nature of the blood ow a multresolution wavelet based signal analysis approach is used to extract the arterial pulse waveform which lends itself to various physiological measurement we validate the result using a traditional contact vital sign monitor a a ground truth eight people of different age race and gender have been tested in our study consistent with irb approval the resultant arterial pulse waveform exactly matched the ground truth reading the essence of our approach is the automatic detection of region of arterial pulse measurement rom from which the arterial pulse waveform is extracted to the best of our knowledge the correspondence between non contact thermal ir imaging based measurement of the arterial pulse in the time domain and traditional contact approach ha never been reported in the literature 
projection system can be used to implement augmented reality a well a to create both display and interface on ordinary surface ordinary surface have varying reflectance color and geometry these variation can be accounted for by integrating a camera into the projection system and applying method from computer vision the method currently applied are fundamentally limited since they assume the camera projector and scene are static in this paper we describe a technique for photometrically adaptive projection that make it possible to handle a dynamic environment we begin by presenting a co axial projector camera system whose geometric correspondence is independent of change in the environment to handle photometric change our method us the error between the desired and measured appearance of the projected image a key novel aspect of our algorithm is that we combine a physic based model with dynamic feedback to achieve real time adaptation to the changing environment we verify our algorithm through a wide variety of experiment we show that it is accurate and run in real time our algorithm can be applied broadly to assist hci visualization shape recovery and entertainment application 
we propose an algorithm for estimating disparity and occlusion in stereo video sequence the algorithm defines a prior on sequence of disparity map using a d markov random field and approximately computes the map estimate for the disparity sequence using loopy belief propagation in contrast to previous work on temporal stereo the algorithm i correctly model half occlusion scene point visible in one camera but not the other and ii enforces the so called monotonicity constraint on the boundary of half occluded region the algorithm is also able to exploit temporal coherence more appropriately than many previous approach to temporal stereo by employing additional state in the markov random field these additional state permit rudimentary motion estimation to be performed a part of the belief propagation thus improving the quality of temporal inference parameter of the algorithm are learned from the ground truth disparity of a real stereo sequence qualitative result are shown on real sequence including comparison with competing approach and the performance of the algorithm is assessed quantitatively using the ground truth data 
in cross modal inference we estimate complete field from noisy and missing observation of one sensory modality using structure found in another sensory modality this inference problem occurs in several area including texture reconstruction and reconstruction of geophysical field we propose a method for cross modal inference that simultaneously learns shape recipe between two modality and estimate missing information by using a prior on image structure gleaned from the alternate modality in the absence of a physical basis for representing image prior we use a statistical one that represents correlation in differential feature this is done efficiently using a perturbation sampling scheme using just one example of the alternate modality we produce a factorized ensemble representation of feature correlation that yield efficient solution to large sized spatial inference problem we demonstrate the utility of this approach on cross modal inference with depth and spectral data 
in many vision problem instead of having fully labeled training data it is easier to obtain the input in small group s where the data in each group is constrained to be from the same class but the actual class label is not known such constraint give rise to partial equivalence relation th e absence of class label prevents the use of standard discriminative method in this scenario on the other hand the state of the art technique that use partial equivale nce relation e g relevant component analysis learn proje ctions that are optimal for data representation but not discrimination we show that this lead to poor performance in several real world application especially those with hi ghdimensional data in this paper we present a novel discriminative technique for the classification of weakly labeled data which exploit the null space of data scatter matrix to achieve good classification accuracy we demonstrate the superior performance of both linear and nonlinear version of our approach on face recognition clustering and image retrieval task result are reported on standard datasetsas well a real world image and video from the web 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present a method for automatically learning discriminative image patch for the recognition of given object class the approach applies discriminative training of log linear model to image patch histogram we show that it work well on three task and performs significantly better than other method using the same feature for example the method decides that patch containing an eye are most important for distinguishing face from background image the recognition performance is very competitive with error rate presented in other publication in particular a new best error rate for the caltech motorbike data of is achieved 
this paper describes how facial shape can be modelled using a statistical model that capture variation in surface normal direction to construct this model we make use of the azimuthal equidistant projection to map surface normal from the unit sphere to point on a local tangent plane the variation in surface normal direction are captured using the covariance matrix for the projected point position this allows u to model variation in face shape using a standard point distribution model we train the model on field of surface normal extracted from range data and show how to fit the model to intensity data using constraint on the surface normal direction provided by lambert s law we demonstrate that this process yield accurate facial shape recovery and allows an estimate of the albedo map to be made from single real world face image 
in patch based object recognition there are two important issue on the codebook generation resolution a coarse codebook lack sufcient discriminative power and an over ne one is sensitive to noise codeword selection non discriminative codewords not only increase the codebook size but also can hurt the recognition performance to achieve a discriminative codebook for better recognition this paper argues that these two issue are strongly related and should be solved a a whole in this paper a multi resolution codebook is r st designed via hierarchical clustering with a reasonable size it includes all of the codewords which cross a large number of resolution level more importantly it form a diverse candidate codeword set that is critical to codeword selection a boosting feature selection approach is modied to select the discriminative codewords from this multi resolution codebook by doing so the obtained codebook is composed of the most discriminative codewords culled from different level of resolution experimental study demonstrates the better recognition performance attained by this codebook 
in this paper we measure the response of image patch used a filter on different image ensemble and examine how the response are affected by reducing the resolution of the image ensemble by comparing the set of response obtained at high and reduced resolution we find that for the ensemble of natural and object image car there is a limit resolution of about x and x pixel respectively beyond which the filter response are sig nificantly affected by resolution reduction we support the result by a simple theoretical analysis based on image ensemble statistic there are two consequence to this result first it provides a natural working resolution determined solely from the image ensemble statistic to which higher resolution template can be reduced without losing a significant amount of information this can be used in particular to reduce the search space for useful visual feature i n many application secondly in contrast to many study it suggests that feature that are more complex than gabor patch can be effectively used a first layer filter and combined in order to represent more complex shape and appearance 
path modeling for video surveillance is an active area of research we address the issue of euclidean path modeling in a single camera for activity monitoring in a multicamera video surveillance system the paper proposes i a novel linear solution to auto calibrate any camera observing pedestrian and ii to use these calibrated camera to detect unusual object behavior during the unsupervised training phase after auto calibrating a camera and metric rectifying the input trajectory the input sequence are registered to the satellite imagery and prototype path model are constructed this allows u to estimate metric information directly from the video sequence during the testing phase using our simple yet efficient similarity measure we seek a relation between the input trajectory derived from a sequence and the prototype path model we test the proposed method on synthetic a well a on real world pedestrian sequence 
this paper proposes a new approach to learning a discriminative model of object class incorporating appearance shape and context information efficiently the learned model is used for automatic visual recognition and semantic segmentation of photograph our discriminative model exploit novel feature based on textons which jointly model shape and texture unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of class accurate image segmentation is achieved by incorporating these classifier in a conditional random field efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training method high classification and segmentation accuracy are demonstrated on three different database i our own object class database of photograph of real object viewed under general lighting condition pose and viewpoint ii the class corel subset and iii the class sowerby database used in the proposed algorithm give competitive result both for highly textured e g grass tree highly structured e g car face bike aeroplane and articulated object e g body cow 
we look at the problem of location recognition in a large image dataset using a vocabulary tree this entail finding the location of a query image in a large dataset containing streetside image of a city we investigate how the traditional invariant feature matching approach fall down a the size of the database grows in particular we show that by carefully selecting the vocabulary using the most informative feature retrieval performance is significantly improved allowing u to increase the number of database image by a factor of we also introduce a generalization of the traditional vocabulary tree search algorithm which improves performance by effectively increasing the branching factor of a fixed vocabulary tree 
although a considerable amount of work ha been published on material classification relatively little of it study situation with considerable variation within each class many experiment use the exact same sample or different patch from the same image for training and test set thus such study are vulnerable to effectively recognising one particular sample of a material a opposed to the material category in contrast this paper place firm emphasis on the capability to generalise to previously unseen instance of material we adopt an appearance based strategy and conduct experiment on a new database which contains several sample of each of eleven material category imaged under a variety of pose illumination and scale condition together these source of intra class variation provide a stern challenge indeed for recognition somewhat surprisingly the difference in performance between various state of the art texture descriptor prof rather small in this task on the other hand we clearly demonstrate that very significant gain can be achieved via different svm based classification technique selecting appropriate kernel parameter prof crucial this motivates a novel recognition scheme based on a decision tree each node contains an svm to split one class from all others with a kernel parameter optimal for that particular node hence each decision is made using a different optimal class specific metric experiment show the superiority of this approach over several state of the art classifier 
we describe a new theoretical approach to image processing and vision expressed in mathemetical terminology in our formalism image space is a fibre bundle and the image itself is the graph of a section on it this mathematical model ha advantage to the conventional view of the image a a function on the plane based on the new method we are able to do image processing of the image a viewed by the human visual system which includes adaptation and perceptual correctness of the result our formalism is invariant to relighting and handle seamlessly illumination change it also explains simultaneous contrast visual illusion which are intrinsically related to the new covariant approach example include poisson image editing inpainting gradient domain hdr compression and others 
appearance model have been applied to model the space of human face over the last two decade in particular active appearance model aams have been successfully used for face tracking synthesis and recognition and they are one of the state of the art approach due to it efficiency and representational power although widely employed aams suffer from a few drawback such a the inability to isolate pose identity and expression change this paper proposes bilinear active appearance model baams an extension of aams that effectively decouple change due to pose and expression identity we derive a gradient descent algorithm to efficiently fit baams to new image experimental result show how baams improve generalization and convergence with respect to the linear model in addition we illustrate decoupling benefit of baams in face recognition across pose we show how the pose normalization provided by baams increase the recognition performance of commercial system 
in the context of visual surveillance of human activity knowledge about a camera s internal and external parameter is useful a it allows for the establishment of a connection between image and world measurement unfortunately calibration information is rarely available and difficult to obtain after a surveillance system ha been installed in this paper a method for camera autocalibration based on information gathered by tracking people is developed it brings two main contribution first we show how a foot to head plane homology can be used to obtain the calibration parameter and then we show an approach how to efficiently estimate initial parameter estimate from measurement second we present a bayesian solution to the calibration problem that can elegantly handle measurement uncertainty outlier a well a prior information it is shown how the full posterior distribution of calibration parameter given the measurement can be estimated which allows making statement about the accuracy of both the calibration parameter and the measurement involving them 
we study from a theoretical standpoint the ambiguity that occur when tracking a generic deformable surface under monocular perspective projection given d to d correspondence we show that additionally to the known scale ambiguity a set of potential ambiguity can be clearly identied from this we deduce a minimal set of constraint required to disambiguate the problem and incorporate them into a working algorithm that run on real noisy data 
in this paper we present a surprisingly simple yet powerful method for detecting illumination determining which pixel are lit by different light in image our method is based on the chromagenic camera which take two picture of each scene one is captured a normal and the other through a coloured filter previous research ha shown that the relationship between the colour the rgbs in the filtered and unfiltered image depends strongly on the colour of the light and this can be used to estimate the colour of the illuminant while chromagenic illuminant estimation often work well it can and doe fail and so is not itself a direct solution to the illuminant detection problem in this paper we dispense with the goal of illumination estimation and seek only to use the chromagenic effect to find out which part of a scene are illuminated by the same light the simplest implementation of our idea involves a combinatorial search we precompute a dictionary of possible illuminant relation that might map rgbs to filtered counterpart from which we select a small number m corresponding to the number of distinct light we think might be present each pixel or region is assigned the relation from this m set that best map filtered to unfiltered rgb all m set are tried in turn and the one that ha the minimum prediction error over all is found at the end of this search process each pixel or region is assigned an integer between and m indicating which of the m light are thought to have illuminated the region our simple search algorithm is possible when m and m and for this case we present experiment that show our method doe a remarkable job in detecting illumination in image if the light are shadow and nonshadow we find the shadow almost effortlessly compared to ground truth data our method delivers close to optimal performance 
we propose a novel framework to build descriptor of local intensity that are invariant to general deformation in this framework an image is embedded a a d surface in d space with intensity weighted relative to distance in x y we show that a this weight increase geodesic distance on the embedded surface are le affected by image deformation in the limit distance are deformation invariant we use geodesic sampling to get neighborhood sample for interest point and then use a geodesic intensity histogram gih a a deformation invariant local descriptor in addition to it invariance the new descriptor automatically find it support region this mean it can safely gather information from a large neighborhood to improve discriminability furthermore we propose a matching method for this descriptor that is invariant to affine lighting change we have tested this new descriptor on interest point matching for two data set one with synthetic deformation and lighting change and another with real non affine deformation our method show promising matching result compared to several other approach 
volume intersection is a frequently used technique to solve the shape from silhouette problem which construct a d object estimate from a set of silhouette taken with calibrated camera it is natural to develop an efficient algorithm to determine the consistency of a set of silhouette before performing time consuming reconstruction so that inaccurate silhouette can be omitted in this paper we first present a fast algorithm to determine the consistency of three silhouette from known but arbitrary viewing direction assuming the projection is scaled orthographic the temporal complexity of the algorithm is linear in the number of point of the silhouette boundary we further prove that a set of more than three convex silhouette are consistent if and only if any three of them are consistent another possible application of our approach is to determine the miscalibrated camera in a large camera system a consistent subset of camera can be determined on the fly and miscalibrated camera can also be recalibrated at a coarse scale real and synthesized data are used to demonstrate our result 
for fitting an ellipse to a point sequence ml maximum likelihood ha been regarded a having the highest accuracy in this paper we demonstrate the existence of a hyperaccurate method which outperforms ml this is made possible by error analysis of ml followed by subtraction of high order bias term since ml nearly achieves the theoretical accuracy bound the kcr lower bound the resulting improvement is very small nevertheless our analysis ha theoretical significance illuminating the relationship between ml and the kcr lower bound 
image smoothing segmentation and registration are three key processing step in many computer vision application in this paper we present a novel framework for achieving all three seemingly disparate goal simultaneously across multiple image in a unified framework via a single variational principle the proposed method ensures that the estimated registration is unbiased and all composition of registration map are compatible the solution to the variational problem is achieved efficiently by solving a coupled system of partial differential equation over the common domain on which the registration map are defined the effectiveness of the proposed framework is demonstrated on set of real image 
this paper address the problem of efficient visual d template tracking in image sequence we adopt a discriminative approach in which the observation at each frame yield direct prediction of a parametrisation of the state e g position scale rotation of the tracked target to this end a bayesian mixture of expert bme is trained on a dataset of image patch that are generated by applying artificial transformation to the template at the first frame in contrast to other method in the literature we explicitly address the problem that the prediction accuracy can deteriorate drastically for observation that are not similar to the one in the training set such observation are common in case of partial occlusion or of fast motion to do so we couple the bme with a probabilistic kernel based classifier which when trained can determine the probability that a new unseen observation can accurately predict the state of the target the relevance of the observation in question in addition in the particle filtering framework we derive a recursive scheme for maintaining an approximation of the posterior probability of the target s state in which the probabilistic prediction of multiple observationsare moderated bytheircorrespondingrelevance we applythealgorithmin the problem of d template tracking and demonstrate that the proposed scheme outperformsclassical methodsfor discriminative tracking in case of motion large in magnitude and of partial occlusion 
pose and illumination variation remain a persistent problem in face recognition algorithm in this paper we present a method for accurately estimating the pose and illumination condition and use it for registration and trac king in video based face recognition algorithm this is achieved by using a joint motion illumination and shape model that is bilinear in the motion and illumination variable the motion is represented in term of translation and rotation of the object centroid and the illumination is rep resented using a spherical harmonic linear basis we start by estimating a rough pose by projecting the image onto the spherical harmonic basis function this pose estimate is used to initialize the registration algorithm which worksby minimizing a square error criterion in the bilinear model thereafter d tracking proceeds by alternately estimatin g motion and illumination parameter the method doe not assume any model for the variation of the illumination condition lighting can change slowly or drastically and can originate from combination of point and extended source we demonstrate the effectiveness of our method on several real world video sequence under severe change of lighting condition contribution of the paper in this paper we present a method for accurately estimating the pose and illumination condition and use it for registration and tracking for vid eobased face recognition algorithm the method relies on learning joint motion and illumination model of object from video we focus on video based recognitionwhere our proposed strategy can automatically and accurately register a d model to the face image in the first frame and track it in subsequent frame we can handle a variety of lighting condition including the presence of multiple an d extended light source which is natural in outdoor environment this is achieved using the spherical harmonic based representation of illumination and previous work that integrates motion and illumination model for video analysis in the reflectance image wa represented using a linear combination of spherical harmonic basis function for lambertian object a ninth order expansion wa deemed sufficient to capture most of the energy in the signal while non lambertian object required higher order coefficient in the author showed that the appearance of a moving object under arbitrary lighting could be represented a bilinear combination of d motion and the spherical harmonic coefficient for illumination 
abstract we address the problem of model based recognition our aim is to localize and recognize road vehicle from monocular image in calibrated scene a deformable d geometric vehicle model with parameter is set up a prior information and bayesian classification error is adopted for evaluation of fitness between the model and image using a novel evolutionary computing method called eda estimation of distribution algorithm we can not only determine the d pose of the vehicle but also obtain a dimensional vector which corresponds to the shape parameter of the model by clustering obtained vector in the parameter space we can recognize different type of vehicle experimental result demonstrate the effectiveness of the approach to vehicle of different type and pose thanks to eda we can not only localize and recognize vehicle but also show the whole evolution procedure of the deformable model which gradually fit the image better and better 
this paper present a passive depth map computation algorithm which run entirely on programmable d graphic hardware at real time speed previous implementation relied on the use of either mipmapping or correlation window to increase the robustness of the calculated depth map these method however are inherently unable to compute the depth for fine d structure to overcome this obstacle we introduce a pixel based method which incorporates connectivity information between neighboring pixel while maintaining the performance boost gained by implementing the algorithm on a highly parallelized architecture such a graphic hardware 
in this paper we present a system that integrates fully automatic scene geometry estimation d object detection d localization trajectory estimation and tracking for dynamic scene interpretation from a moving vehicle our sole input are two video stream from a calibrated stereo rig on top of a car from these stream we estimate structurefrom motion sfm and scene geometry in real time in parallel we perform multi view multi category object recognition to detect car and pedestrian in both camera image using the sfm self localization d object detection are converted to d observation which are accumulated in a world coordinate frame a subsequent tracking module analyzes the resulting d observation to find physically plausible spacetime trajectory finally a global optimization criterion take object objectinteractions into accountto arrive at accurate d localization and trajectory estimate for both car and pedestrian we demonstrate the performance of our integrated system on challenging real world data showing car passage through crowded city area 
abstract we present a nonparametric mode seeking algorithm called medoidshift based on approximating the local gradient using a weighted estimate of medoids like meanshift medoidshift clustering automatically computes the number of cluster and the data doe not have to be linearly separable unlike meanshift the proposed algorithm doe not require the definitionof a mean this property allows medoidshift to find mode even when only a distance measure between sample is defined in this sense the relationship between the medoidshift algorithm and the meanshift algorithm is similar to the relationship between the k medoids andthek meansalgorithms we showthatmedoidshiftscan also be used for incremental clustering of growing datasets by recycling previous computation we present experimental result using medoidshift for image segmentation incremental clustering for shot segmentation and clustering on nonlinearly separable data 
for the first time we perform normalized correlation template tracking in the modulation domain for each frame of the video sequence we compute a multi component am fm image model that characterizes the local texture structure of object and background tracking is carried out by formulating a modulation domain correlation function in the derived feature space using visible and longwave infrared sequence a illustrative example we study the performance of this new approach relative to two basic pixel domain correlation template tracker we also present preliminary result from a new dual domain tracker that operates simultaneously in both the pixel and modulation domain 
we present a novel discriminative generative hybrid approach in this paper with emphasis on application in multiview object detection our method includes a novel generative model called random attributed relational graph rarg which is able to capture the structural and appearance characteristic of part extracted from object we develop new variational learning method to compute the approximation of the detection likelihood ratio function the variaitonal likelihood ratio function can be shown to be a linear combination of the individual generative classifier defined at node and edge of the rarg such insight inspires u to replace the generative classifier at node and edge with discriminative classifier such a support vector machine to further improve the detection performance our experiment have shown the robustness of the hybrid approach the combined detection method incorporating the svm based discriminative classifier yield superior detection performance compared to prior work in multiview object detection 
we present theory of multiperspective projection and collineation given an arbitrary multiperspective imaging system that capture smoothly varying set of ray we show how to map the ray onto a d ray manifold embedded in a d linear vector space the characteristic of this imaging system such a it projection collineation and image distortion can be analyzed by studying the d tangent plane of this ray manifold these tangent plane correspond to the recently proposed general linear camera glc model in this paper we study the imaging process of the glcs we show the glc imaging process can be broken down into two separate stage the mapping of d geometry to ray and the sampling of those ray over an image plane we derive a closed form solution to projecting d point in a scene to ray in a glc a glc image is created by sampling these ray over an image plane we develop a notion of glc collineation analogous to pinhole camera glc collineation describes the transformation between the image of a single glc due to change in sampling and image plane selection we show that general glc collineations can be characterized by a quartic th order rational function glc projection and collineation provides a basis for developing new computer vision algorithm suitable for analyzing a wider range of imaging system than current method based on simple pinhole projection model permit 
a dynamic texture is a linear dynamical system used to model a single video a a sample from a spatio temporal stochastic process in this work we introduce the mixture of dynamic texture which model a collection of video consisting of different visual process a sample from a set of dynamic texture we derive the em algorithm for learning a mixture of dynamic texture and relate the learning algorithm and the dynamic texture mixture model to previous work finally we demonstrate the applicability of the proposed model to problem that have traditionally been challenging for computer vision 
abstract thispaper aimsto introducetherobustnessagainstnoise into the spectral clustering algorithm first we propose a warping model to map the data into a new space on the basis of regularization during the warping each point spread smoothly it spatial information to other point after the warping empirical study show that the cluster become relatively compact and well separated including the noise cluster that is formed by the noise point in this new space the number of cluster can be estimated by eigenvalue analysis we further apply the spectral mapping to the data to obtain a low dimensional data representation finally the k mean algorithm is used to perform clustering the proposed method is superior to previous spectral clustering method in that i it is robust against noise because the noise point are grouped into one new cluster ii the number of cluster and the parameter of the algorithm are determined automatically experimental result on synthetic and real data have demonstrated this superiority 
in this paper we develop a theory of non parametric self calibration recently scheme have been devised for non parametric laboratory calibration but not for self calibration we allow an arbitrary warp to model the intrinsic mapping with the only restriction that the camera is central and that the intrinsic mapping ha a well defined non singular matrix derivative at a finite number of point under study we give a number of theoretical result both forinfinitesimal motion and finite motion for a finite number of observation and when observing motion over a dense image for rotation and translation our main result is that through observing the flow induced by three instantaneous rotation at a finite number of point of the distorted image we can perform projective reconstruction of those image point on the undistorted image we present some result with synthetic and real data 
this paper considers the objective of accurate stereo matching especially at object boundary robustness against recording or illumination change and efficiency of the calculation these objective lead to the proposedsemi global matching method that performs pixelwise matching based on mutual information and the approximation of a global smoothness constraint occlusion are detected and disparity determined with sub pixel accuracy additionally an extension for multi baseline stereo image is presented there are two novel contribution firstly a hierarchical calculation of mutual information based matching is shown which is almost a fast a intensity based matching secondly an approximation of a global cost calculation is proposed that can be performed in a time that is linear to the number of pixel and disparity the implementation requires just second on typical image 
we present a computer vision system for robust object tracking in d by combining evidence from multiple calibrated camera this kernel based d tracker is automatically bootstrapped by constructing d point cloud these point cloud are then clustered and used to initialize the tracker and validate their performance the framework describes a complete tracking system that fuse appearance feature from all available camera sensor and is capable of automatic initialization and drift detection it elegance resides in it inherent ability to handle problem encountered byvarious dtrackers includingscaleselection occlusion view dependence and correspondence across view tracking result for an indoor smart room and a multi camera outdoor surveillance scenario are presented we demonstrate the effectiveness of this unified approach by comparing it performance to a baseline d tracker that fuse result of independent d tracker a well a comparing the re initialization result to known ground truth 
in many application it is necessary to track a moving and deforming boundary on the plane from infrequent sparse measurement for instance each of a set of mobile observer may be able to tell the position of a point on the boundary often boundary component split merge appear and disappear over time data are typically sparse and noisy and the underlying dynamic is uncertain to address these issue we use a particle filter to represent a distribution in the large space of all plane curve and propose a full fledged combination of level set and particle filter our main contribution is in controlling the potentially high expense of multiplying the cost of a level set representation of boundary by the number of particle needed experiment on tracking the boundary of a colon in tomographic imagery from sparse edge measurement show the promise of the approach 
this contribution proposes a compositional approach to visual object categorization of scene composition are learned from the caltech database and form intermediate abstraction of image that are semantically situated between low level representation and the highlevel categorization salient region which are described by localized feature histogram are detected a image part subsequently composition are formed a bag of part with a locality constraint after performing a spatial binding of composition by mean of a shape model coupled probabilistic kernel classifier are applied thereupon to establish the final image categorization in contrast to the discriminative training of the categorizer intermediate composition are learned in a generative manner yielding relevant part agglomeration i e grouping which are frequently appearing in the dataset while simultaneously supporting the discrimination between set of category consequently compositionality simplifies the learning of a complex categorization model for complete scene by splitting it up into simpler sharable composition the architecture is evaluated on the highly challenging caltech database which exhibit large intra category variation our compositional approach show competitive retrieval rate in the range of or with a multi scale feature set rate of 
active appearance model aams provide a framework for modeling the joint shape and texture of an image an aam is a compact representation of both factor in a conditionally linear model however the standard aam framework doe not handle image which have missing feature or allow modification of certain structure in the image while leaving neighboring one undeformed we introduce the layered active appearance model laam which allows for missing feature occlusion substantial spatial rearrangement of feature and which provides a more general representation that extends the applicability of the active appearance model 
we present light fall off stereo lf a new method for computing depth from scene beyond lambertian reflectance and texture lf take a number of image from a stationary camera a the illumination source move away from the scene based on the inverse square law for light intensity the ratio image are directly related to scene depth from the perspective of the light source using this a the invariant we developed both local and global method for depth recovery compared to previous reconstruction method for non lamebrain scene lf need a few a two image doe not require calibrated camera or light source or reference object in the scene we demonstrated the effectiveness of lf with a variety of real world scene 
we treat tracking a a matching problem of detected keypoints between successive frame the novelty of this paper is to learn classifier based keypoint description allowing to incorporate background information contrary to existing approach we are able to start tracking of the object from scratch requiring no off line training phase before tracking the tracker is initialized by a region of interest in the first frame afterwards an on line boosting technique is used for learning description of detected keypoints lying within the region of interest new frame provide new sample for updating the classifier which increase their stability a simple mechanism incorporates temporal information for selecting stable feature in order to ensure correct update a verification step based on estimating homographies using ransac is performed the approach can be used for real time application since on line updating and evaluating classifier can be done efficiently 
in this paper we study interest point descriptor for image matching and d reconstruction we examine the building block of descriptor algorithm and evaluate numerous combination of component various published descriptor such a sift gloh and spin image can be cast into our framework for each candidate algorithm we learn good choice for parameter using a training set consisting of patch from a multi image d reconstruction where accurate ground truth match are known the best descriptor were those with log polar histogramming region and feature vector constructed from rectified output of steerable quadrature filter at a detection rate these gave one third of the incorrect match produced by sift 
calculating a reliable similarity measure between pixel feature is essential for many computer vision and image processing application we propose a similarity measure affinity between pixel feature which depends on the feature space histogram of the image we use the observation that cluster in the feature space histogram are typically smooth and roughly convex given two feature point we adjust their similarity according to the bottleneck in the histogram value on the straight line between them we call our new similarity bottleneck affinity these measure are computed efficiently we demonstrate superior segmentation result compared to the use of the euclidean metric 
recently the wide deployment of practical face recognition system give rise to the emergence of the inter modality face recognition problem in this problem the face image in the database and the query image captured on spot are acquired under quite different condition or even using different equipment conventional approach either treat the sample in a uniform model or introduce an intermediate conversion stage both of which would lead to severe performance degradation due to the great discrepancy between different modality in this paper we propose a novel algorithm called common discriminant feature extraction specially tailored to the inter modality problem in the algorithm two transforms are simultaneously learned to transform the sample in both modality respectively to the common feature space we formulate the learning objective by incorporating both the empirical discriminative power and the local smoothness of the feature transformation by explicitly controlling the model complexity through the smoothness constraint we can effectively reduce the risk of overfitting and enhance the generalization capability furthermore to cope with the nongaussian distribution and diverse variation in the sample space we develop two nonlinear extension of the algorithm one is based on kernelization while the other is a multi mode framework these extension substantially improve the recognition performance in complex situation extensive experiment are conducted to test our algorithm in two application scenario optical image infrared image recognition and photo sketch recognition our algorithm show excellent performance in the experiment 
when we take a picture through transparent glass the image we obtain is often a linear superposition of two image the image of the scene beyond the glass plus the image of the scene reflected by the glass decomposing the single input image into two image is a massively ill posed problem in the absence of additional knowledge about the scene being viewed there are an infinite number of valid decomposition in this paper we focus on an easier problem user assisted separation in which the user interactively label a small number of gradient a belonging to one of the layer even given label on part of the gradient the problem is still ill posed and additional prior knowledge is needed following recent result on the statistic of natural image we use a sparsity prior over derivative filter this sparsity prior is optimized using the terative reweighted least square irls approach our result show that using a prior derived from the statistic of natural image give a far superior performance compared to a gaussian prior and it enables good separation from a modest number of labeled gradient 
the problem of block noise removal is considered it is assumed that the original image is on or close to a sub space of admissible image in the form of a low dimensional nonlinear manifold we propose to use a close variant of the total variation regularizer for measuring block noise based on this noise measure we present an effective approach that reconstructs the original image in the presence of block noise our main computational task is the solution of a quadratic programming problem for which we propose a very efficient interior point method the effectiveness and efficiency of our approach is demonstrated by an example 
vision system for various task are increasingly being deployed although significant effort ha gone into improving the algorithm for such task there ha been relatively little work on determining optimal sensor configuration this paper address this need we specifically address and enhance the state of the art in the analysis of scenario where there are dynamically occuring object capable of occluding each other the visibility constraint for such scenario are analyzed in a multi camera setting also analyzed are other static constraint such a image resolution and field of view and algorithmic requirement such a stereo reconstruction face detection and background appearance theoretical analysis with the proper integration of such visibility and static constraint lead to a generic framework for sensor planning which can then be customized for a particular task our analysis can be applied to a variety of application especially those involving randomly occuring object and include surveillance and industrial automation several example illustrate the wide applicability of the approach 
abstract the scale invariant property of an ensemble of natural im age is examined which motivates a new early visual representation termed the higher order pyramid the representation is a non linear gen eralization of the laplacian pyramid and is tuned to the type of scale invariance exhibited by natural imagery a opposed to other scale invari ant image such a f correlated noise and the step edge the trans formation of an image to a higher order pyramid is simple to compute and straightforward to invert because the representation is invertible it is shown that the higher order pyramid can be truncated and quan tized with little loss of visual quality image coded in this representation have much le redundancy than the raw image pixel and decorrelating transformation such a the laplacian pyramid this is demonstrated by showing statistical independence between pair of coe cients because the representation is tuned to the ensemble redundancy the coe cients of the higher order pyramid are more e cient at capturing the variation within the ensemble which lead too improved matching result this is demonstrated on two recognition task face recognition with illumina tion change and object recognition which viewpoint change 
convolutional network have achieved a great deal of success in high level vision problem such a object recognition here we show that they can also be used a a general method for low level image processing a an example of our approach convolutional network are trained using gradient learning to solve the problem of restoring noisy or degraded image for our training data we have used electron microscopic image of neural circuitry with ground truth restoration provided by human expert on this dataset markov random field mrf conditional random field crf and anisotropic diffusion algorithm perform about the same a simple thresholding but superior performance is obtained with a convolutional network containing over adjustable parameter when restored by this convolutional network the image are clean enough to be used for segmentation whereas the other approach fail in this respect we do not believe that convolutional network are fundamentally superior to mrfs a a representation for image processing algorithm on the contrary the two approach are closely related but in practice it is possible to train complex convolutional network while even simple mrf model are hindered by problem with bayesian learning and inference procedure our result suggest that high model complexity is the single most important factor for good performance and this is possible with convolutional network 
thin plate spline warp have been shown to be very effective a a parameterized model of the optic flow field between image of various deforming surface example include a sheet of paper being manually handled recent work ha used such warp for image of smooth rigid surface standard thin plate spline warp are not rigid in the sense that they do not satisfy the epipolar geometry constraint and are intrinsically affine in the sense of the affine camera model we propose three type of warp based on the thin plate spline the first one is a flexible rigid warp it describes the optic flow field induced by a smooth rigid surface and satisfies the affine epipolar geometry constraint the second and third one extend the standard thin plate spline and the proposed rigid flexible warp to the perspective camera model the property of these warp are studied in detail and a hierarchy is defined experimental result on simulated and real data are reported showing that the proposed warp outperform the standard one in several case of interest 
in the summer of using an interactive intelligent tool over researcher in video understanding annotated from the nist trecvid database over hour of news video spanning six month of these k shot with k label from over visual concept category comprise the largest publicly available ground truth for this domain our analysis of this data combining the tool of statistical natural language processing machine learning and computer vision find significant novel statistical pattern that can be exploited for the accurate tracking of the episode of a given news story over time by using semantic label that are solely visual we find that the ground truth is very muddy but by using the feature selection tool of information gain we extract reliable visual concept with mid frequency use all but one are visual concept that refer to setting rather than actor object or event we discover that the probability of another episode of a named story to recur after a gap of d day is proportional to d wedefine a novel similarity measure incorporating both semantic and temporal property between episode i and j a dice i j gap i j we exploit a low level computer vision technique normalized cut laplacian eigenmaps for clustering these episode into story and in the process document a weakness of this popular technique we use these empirical result to make specific recommendation on how better visual semantic ontology for news story and how better video annotation tool should be designed 
we introduce a theoretical framework and practical algorithm for replacing time coded structured light pattern with viewpoint code in the form of additional camera location current structured light method typically use log n light pattern encoded over time to unambiguously reconstruct n unique depth we demonstrate that each additional camera location may replace one frame in a temporal binary code our theoretical viewpoint coding analysis show that by using a high frequency stripe pattern and placing camera in carefully selected location the epipolar projection in each camera can be made to mimic the binary encoding pattern normally projected over time result from our practical implementation demonstrate reliable depth reconstruction that make neither temporal nor spatial continuity assumption about the scene being captured 
we propose a novel fast and robust technique for the computation of anatomical connectivity in the brain our approach exploit the information provided by diffusion tensor magnetic resonance imaging or dti and model the white matter by using riemannian geometry and control theory we show that it is possible from a region of interest to compute the geodesic distance to any other point and the associated optimal vector field the latter can be used to trace shortest path coinciding with neural fiber bundle we also demonstrate that no explicit computation of those d curve is necessary to ass the degree of connectivity of the region of interest with the rest of the brain we finally introduce a general local connectivity measure whose statistic along the optimal path may be used to evaluate the degree of connectivity of any pair of voxels all those quantity can be computed simultaneously in a fast marching framework directly yielding the connectivity map apart from being extremely fast this method ha other advantage such a the strict respect of the convoluted geometry of white matter the fact that it is parameter free and it robustness to noise we illustrate our technique by showing result on real and synthetic datasets ourgcm geodesic connectivity mapping algorithm is implemented in c and will be soon available on the web 
the space of image is known to be a non linear sub space that is difficult to model this paper derives an algorithm that walk within this space we seek a manifold through the video volume that is constrained to lie locally in this space every local neighborhood within the manifold resembles some image patch we call this the scene manifold because the solution trace the scene outline for a broad class of input the problem can be posed a finding the shortest path in a graph and can thus be solved efficiently to produce the globally optimal solution constraining appearance rather than geometry give rise to numerous new capability here we demonstrate the usefulness of this approach by posing the well studied problem of mosaicing in a new way instead of treating it a geometrical alignment we pose it a an appearance optimization since the manifold is constrained to lie in the space of valid image patch the resulting mosaic is guaranteed to have the least distortion possible any small part of it can be seen in some image even though the manifold span the whole video thus it can deal seamlessly with both static and dynamic scene with or without d parallax essentially the method simultaneously solves two problem that have been solved only separately until now alignment and mosaicing 
linear discriminant analysis lda ha been a popular method for extracting feature which preserve class separability the projection vector are commonly obtained by maximizing the between class covariance and simultaneously minimizing the within class covariance in practice when there is no sufficient training sample the covariance matrix of each class may not be accurately estimated in this paper we propose a novel method called semisupervised discriminant analysis sda which make use of both labeled and unlabeled sample the labeled data point are used to maximize the separability between different class and the unlabeled data point are used to estimate the intrinsic geometric structure of the data specifically we aim to learn a discriminant function which is a smooth a possible on the data manifold experimental result on single training image face recognition and relevance feedback image retrieval demonstrate the effectiveness of our algorithm 
just a optical flow is the two dimensional motion of point in an image scene flow is the three dimensional motion of point in the world the fundamental difficulty with optical flow is that only the normal flow can be computed directly from the image measurement without some form of smoothing or regularization in this paper we begin by showing that the same fundamental limitation applies to scene flow however many camera are used to image the scene there are then two choice when computing scene flow perform the regularization in the image or perform the regularization on the surface of the object in the scene in this paper we choose to compute scene flow using regularization in the image we describe three algorithm the first two for computing scene flow from optical flow and the third for constraining scene tructure from the inconsistency in multiple optical flow 
this paper contributes a new boosting paradigm to achieve detection of event in video previous boosting paradigm in vision focus on single frame detection and do not scale to video event thus new concept need to be introduced to address question such a determining if an event ha occurred localizing the event handling same action performed at different speed incorporating previous classifier response into current decision using temporal consistency of data to aid detection and recognition the proposed method ha the capability to improve weak classifier by allowing them to use previous history in evaluating the current frame a learning mechanism built into the boosting paradigm is also given which allows event level decision to be made this is contrasted with previous work in boosting which us limited higher level temporal reasoning and essentially make object detection decision at the frame level our approach make extensive use of temporal continuity of video at the classifier and detector level we also introduce a relevant set of activity feature feature are evaluated at multiple zoom level to improve detection we show result for a system that is able to recognize action 
this paper proposes an approach for object class localization which go beyond bounding box a it also determines the outline of the object unlike most current localization method our approach doe not require any hypothesis parameter space to be dened instead it directly generates evaluates and cluster shape mask thus the presented framework produce more informative result for object class localization for example it easily learns and detects possible object viewpoint and articulation which are often well characterized by the object outline we evaluate the proposed approach on the challenging natural scene graz object class dataset the result demonstrate the extended localization capability of our method 
we address recognition and localization of human action in realistic scenario in contrast to the previous work studying human action in controlled setting here we train and test algorithm on real movie with substantial variation of action in term of subject appearance motion surrounding scene viewing angle and spatio temporal extent we introduce a new annotated human action dataset and use it to evaluate several existing method we in particular focus on boosted space time window classifier and introduce keyframe priming that combine discriminative model of human motion and shape within an action keyframe priming is shown to significantly improve the performance of action detection we present detection result for the action class drinking evaluated on two episode of the movie coffee and cigarette 
monocular slam ha the potential to turn inexpensive camera into powerful pose sensor for application such a robotics and augmented reality however current implementation lack the robustness required to be useful outside laboratory condition blur sudden motion and occlusion all cause tracking to fail and corrupt the map here we present a system which automatically detects and recovers from tracking failure while preserving map integrity by extending recent advance in keypoint recognition the system can quickly resume tracking i e within a single frame time of m using any of the feature previously stored in the map extensive test show that the system can reliably generate map for long sequence even in the presence of frequent tracking failure 
the proliferation of low cost infrared camera give u a new angle for attacking many unsolved vision problem by leveraging a larger range of the electromagnetic spectrum a first step to utilizing these image is to explore the statistic of infrared image and compare them to the corresponding statistic in the visible spectrum in this paper we analyze the power spectrum a well a the marginal and joint wavelet coefficient distribution of datasets of indoor and outdoor image we note that infrared image have noticeably le texture indoors where temperature are more homogenous the joint wavelet statistic also show strong correlation between object boundary in ir and visible image leading to high potential for vision application using a combined statistical model 
recent work in matting hole filling and compositing allows image element to be mixed in a new composite image previous algorithm for matting foreground element have assumed that the new background for compositing is unknown we show that if the new background is known the matting algorithm ha more freedom to create a successful matte by simultaneously optimizing the matting and compositing operation we propose a new algorithm that integrates matting and compositing into a single optimization process the system is able to compose foreground element onto a new background more efficiently and with le artifact compared with previous approach in our example we show how one can enlarge the foreground while maintaining the wide angle view of the background we also demonstrate composing a foreground element on top of similar background to help remove unwanted portion of the background or to re scale or re arrange the composite we compare and contrast our method with a number of previous matting and compositing system 
most pose robust face verification algorithm which employ d appearance rely heavily on statistic gathered from offline database containing ample facial appearance variation across many view due to the high dimensionality of the face image being employed the validity of the assumption employed in obtaining these statistic are essential for good performance in this paper we ass three common approach in d appearance pose mismatched face recognition literature in our experiment we demonstrate where these approach work and fail a a result of this analysis we additionally propose a new algorithm that attempt to learn the statistical dependency between gallery patch i e local region of pixel and the whole appearance of the probe image we demonstrate improved performance over a number of leading d appearance face recognition algorithm 
given a set of image of scene containing multiple object category e g grass road building our objective is to discover these object in each image in an unsupervised manner and to use this object distribution to perform scene classification we achieve this discovery using probabilistic latent semantic analysis plsa a generative model from the statistical text literature here applied to a bag of visual word representation for each image the scene classification on the object distribution is carried out by a k nearest neighbour classifier we investigate the classification performance under change in the visual vocabulary and number of latent topic learnt and develop a novel vocabulary using colour sift descriptor classification performance is compared to the supervised approach of vogel schiele and oliva torralba and the semi supervised approach of fei fei perona using their own datasets and testing protocol in all case the combination of unsupervised plsa followed by supervised nearest neighbour classification achieves superior result we show application of this method to image retrieval with relevance feedback and to scene classification in video 
we extend the successful d robust feature concept into the third dimension in that we produce a descriptor for a reconstructed d surface region the descriptor is perspectively invariant if the region can locally be approximated well by a plane we exploit depth and texture information which is nowadays available in real time from video of moving camera from stereo system or pmd camera photonic mixer device by computing a normal view onto the surface we still keep the descriptiveness of similarity invariant feature like sift while achieving invariance against perspective distortion while descriptiveness typically suffers when using affine invariant feature our approach can be exploited for structure from motion for stereo or pmd camera alignment of large scale reconstruction or improved video registration 
linear dimensionality reduction method such a lda are often used in object recognition for feature extraction but do not address the problem of how to use these feature for recognition in this paper we propose probabilistic lda a generative probability model with which we can both extract the feature and combine them for recognition the latent variable of plda represent both the class of the object and the view of the object within a class by making example of the same class share the class variable we show how to train plda and use it for recognition on previously unseen class the usual lda feature are derived a a result of training plda but in addition have a probability model attached to them which automatically give more weight to the more discriminative feature with plda we can build a model of a previously unseen class from a single example and can combine multiple example for a better representation of the class we show application to classification hypothesis testing class inference and clustering on class not observed during training 
this paper present a general discriminant model gdm for color face recognition the gdm model involves two set of variable a set of color component combination coefficient for color image representation and a set of projection basis vector for image discrimination an iterative whitening maximization iwm algorithm is designed to find the optimal solution of the model the proposed algorithm is further extended to generate three color component like the three color component of rgb color image for further improving the face recognition performance experiment using the face recognition grand challenge frgc database and the biometric experimentation environment bee system show the effectiveness of the proposed model and algorithm in particular for the most challenging frgc version experiment which contains training image controlled target image and uncontrolled query image the proposed method achieves the face verification rate roc iii of at the false accept rate of 
why because human and primate outperform in almost any measure the best machine vision system building a system that emulates object recognition in cortex ha always been an attractive idea while mainstream computer vision ha always been inspired and challenged by human vision it seems to never have advanced past the very first stage of processing in the simple cell of i e gabor filter and no real attention wa given to biologically plausible feature of higher complexity moreover model of biological vision have not been extended to deal with real world object recognition task and tested on them how our system follows the standard modelof object recognition inprimate cortex the model itself attempt to summarize in a quantitative way what most visual neuroscientist generally agree on the first few hundred millisecond of visual processing in primate cortex follows a mostly feed forward hierarchy at each stage the receptive field of the neuron i e the part of the visual field that could potentially elicit a neuron s response tends to get larger along with the complexity of their optimal stimulus i e the set of stimulus that are susceptible to elicit a neuron s response in it simplest version the standard model consists of four layer of computational unit where simple s unit alternate with complex c unit the s unit combine their input with gaussian like tuning to increase object selectivity the c unit pool their input through a maximum operation thereby introducing invariance to scale and translation the standard model ha been able to duplicate quantitively the generalization property exhibited by neuron in inferotemporal monkey cortex the so called viewtuned unit that remain highly selective for particular object a face a hand a toilet brush while being invariant to range of scale and position the standard model in it simplest version used a very simple static dictionary of feature it wa suggested already that feature from the third and higher layer in the model should instead be learned from visual experience we have extended the standard model by showing how to learn a vocabulary of visual feature from image progress our system motivated by a quantitative model of visual cortex outperforms state of theart system on a variety of object image datasets from different group we also show that our system is able to learn from very few example with no prior category knowledge the success of the approach is also a suggestive plausibility proof for a class of feed forward model of object recognition in cortex finally we conjecture the existence of a universal overcomplete dictionary of feature that could handle the recognition of all object category 
occlusion reasoning necessary for task such a navigation and object search is an important aspect of everyday life and a fundamental problem in computer vision we believe that the amazing ability of human to reason about occlusion from one image is based on an intrinsically d interpretation in this paper our goal is to recover the occlusion boundary and depth ordering of free standing structure in the scene our approach is to learn to identify and label occlusion boundary using the traditional edge and region cue together with d surface and depth cue since some of these cue require good spatial support i e a segmentation we gradually create larger region and use them to improve inference over the boundary our experiment demonstrate the power of a scene based approach to occlusion reasoning 
we present a unified framework for separating specular and diffuse reflection component in image and video of textured scene this can be used for specularity removal and for independently processing filtering and recombining the two component beginning with a partial separation provided by an illumination dependent color space the challenge is to complete the separation using spatio temporal information this is accomplished by evolving a partial differential equation pde that iteratively erodes the specular component at each pixel a family of pdes appropriate for differing image source still image v video differing prior information e g highly v lightly textured scene or differing prior computation e g optical flow is introduced in contrast to many other method explicit segmentation and or manual intervention are not required we present result on high quality image and video acquired in the laboratory in addition to image taken from the internet result on the latter demonstrate robustness to low dynamic range jpeg artifact and lack of knowledge of illuminant color empirical comparison to physical removal of specularities using polarization is provided finally an application termed dichromatic editing is presented in which the diffuse and the specular component are processed independently to produce a variety of visual effect 
we consider the problem of detecting and accounting for the presence of occluders in a d scene based on silhouette cue in video stream obtained from multiple calibrated view while well studied and robust in controlled environment silhouette based reconstruction of dynamic object fails in general environment where uncontrolled occlusion are commonplace due to inherent silhouette corruption by occluders we show that occluders in the interaction space of dynamic object can be detected and their d shape fully recovered a a byproduct of shape from silhouette analysis we provide a bayesian sensor fusion formulation to process all occlusion cue occurring in a multi view sequence result show that the shape of static occluders can be robustly recovered from pure dynamic object motion and that this information can be used for online self correction and consolidation of dynamic object shape reconstruction 
most current local feature detector descriptor implicitly assume that the scene is locally planar an assumption that is violated at surface discontinuity we show that this restriction is at least in theory unnecessary a one can construct local feature that are viewpoint invariant for generic non planar scene however we show that any such feature necessarily sacrifice shape information in the sense of being non shape discriminative finally we show that if viewpoint is factored out a part of the matching process rather than explicitly in the representation then shape is discriminative indeed we illustrate our theoretical result empirically by showing that even for simple scene current affine descriptor fail where even a naive d viewpoint invariant succeeds in matching 
this paper is about mapping image to continuous output space using powerful bayesian learning technique a sparse semi supervised gaussian process regression model s gp is introduced which learns a mapping using only partially labelled training data we show that sparsity bestows efficiency on the s gp which requires minimal cpu utilization for real time operation the prediction of uncertainty made by the s gp are more accurate than those of other model leading to considerable performance improvement when combined with a probabilistic filter and the ability to learn from semi supervised data simplifies the process of collecting training data the s gp us a mixture of different image feature this is also shown to improve the accuracy and consistency of the mapping a major application of this work is it use a a gaze tracking system in which image of a human eye are mapped to screen coordinate in this capacity our approach is efficient accurate and versatile 
this paper introduces an affine invariant shape descriptor formaximallystableextremalregions mser affineinvariant feature descriptor are normally computed by sampling the original grey scale image in an invariant frame defined from each detected feature but we instead use only the shape of the detected mser itself this ha the advantage that feature can be reliably matched regardless of the appearance of the surroundings of the actual region the descriptor is computed using the scale invariant feature transform sift with the resampled mser binary mask a input we also show that the original mser detector can be modified to achieve better scale invariance by detecting msers in a scale pyramid we make extensive comparison of the proposed feature against a sift descriptor computed on grey scale patch and also explore the possibility of grouping the shape descriptor into pair to incorporate more context while the descriptor doe not perform a well on planar scene we demonstrate various category of full d scene where it outperforms the sift descriptor computed on grey scale patch the shape descriptor is also shown to be more robust to change in illumination we show that a system can achieve the best performance under a range of imaging condition by matching both the texture and shape descriptor 
we present a real time liveness detection approach against photograph spoofing in face recognition by recognizing spontaneous eyeblinks which is a non intrusive manner the approach requires no extra hardware except for a generic webcamera eyeblink sequence often have a complex underlying structure we formulate blink detection a inference in an undirected conditional graphical framework and are able to learn a compact and efficient observation and transition potential from data for purpose of quick and accurate recognition of the blink behavior eye closity an easily computed discriminative measure derived from the adaptive boosting algorithm is developed and then smoothly embedded into the conditional model an extensive set of experiment are presented to show effectiveness of our approach and how it outperforms the cascaded adaboost and hmm in task of eyeblink detection 
we present an approach to detecting and recognizing spoken isolated phrase based solely on visual input we adopt an architecture that first employ discriminative detection of visual speech and articulatory feature and then performs recognition using a model that account for the loose synchronization of the feature stream discriminative classifier detect the subclass of lip appearance corresponding to the presence of speech and further decompose it into feature corresponding to the physical component of articulatory production these component often evolve in a semi independent fashion and conventional viseme based approach to recognition fail to capture the resulting co articulation effect we present a novel dynamic bayesian network with a multi stream structure and observation consisting of articulatory feature classifier score which can model varying degree of co articulation in a principled way we evaluate our visual only recognition system on a command utterance task we show comparative result on lip detection and speech nonspeech classification a well a recognition performance against several baseline system 
determining the correspondence of image patch is one of the most important problem in computer vision when the intensity space is variant due to several factor such a the camera gain or gamma correction one need method that are robust to such transformation while the most common assumption is that of a linear transformation a more general assumption is that the change is monotonic therefore method have been developed previously that work on the ranking between different pixel a opposed to the intensity themselves in this paper we develop a new matching method that improves upon existing method by using a combination of intensity and rank information the method considers the difference in the intensity of the changed pixel in order to achieve greater robustness to gaussian noise furthermore only uncorrelated order change are considered which make the method robust to change in a single or a few pixel these property make the algorithm quite robust to different type of noise and other artifact such a camera shake or image compression experiment illustrate the potential of the approach in several different application such a change detection and feature matching 
we propose a simple model of human motion a a switching linear dynamical system where the switch correspond to contact force with the ground this significantly improves the modeling performance when compared to simpler linear system with only marginal increase in complexity we introduce a novel closed form non iterative algorithm to estimate the switch and learn the model parameter in between switch we validate our model qualitatively by running simulation and quantitatively by computing prediction error that show significant improvement over previous approach using linear model 
given an unstructured collection of captioned image of cluttered scene featuring a variety of object our goal isto learn both the name and appearance of the object only a small number of local feature within any given image are associated with a particular caption word we describe a connected graph appearance model where vertex represent local feature and edge encode spatial relationship we use the repetition of feature neighborhood across train ing image and a measure of correspondence with caption word to guide the search for meaningful feature configuration we demonstrate improved result on a dataset to which an unstructured object model wa previously applied we also apply the new method to a more challenging collection of captioned image from the web detecting and annotating object within highly cluttered realistic scene 
an iterative segmentation estimation framework for segmentation of planar surface in the disparity space is implemented on a digital signal processor dsp disparity of a scene is modeled by approximating various surface in the scene to be planar the surface label are estimated during the segmentation phase of the framework with help of the underlying plane parameter after segmentation planar surface are separated into spatially continuous region the largest of these region is used to compute the estimate for the plane parameter the iterative process is continued till convergence the algorithm wa optimized and implemented on tm dm based embedded system that operates at to frame per second on image of size 
unsupervised categorization of image or image part is often needed for image and video summarization or a a preprocessing step in supervised method for classification tracking and segmentation while many metric based technique have been applied to this problem in the vision community often the most natural measure of similarity e g number of matching sift feature between pair of image or image part is non metric unsupervised categorization by identifying a subset of representative exemplar can be efficiently performed with the recently proposed affinity propagation algorithm in contrast to k center clustering which iteratively refines an initial randomly chosen set of exemplar affinity propagation simultaneously considers all data point a potential exemplar and iteratively exchange message between data point until a good solution emerges when applied to the olivetti face data set using a translation invariant non metric similarity affinity propagation achieves a much lower reconstruction error and nearly half the classification error rate compared to state of the art technique for the more challenging problem of unsupervised categorization of image from the caltech data set we derived non metric similarity between pair of image by matching sift feature affinity propagation successfully identifies meaningful category which provide a natural summarization of the training image and can be used to classify new input image 
event can be considered a obvious change of important property with semantic meaning usually all these property are measurable and continual in complex format and higher dimension it is hard to define and measure semantic event on the original observed data however according to the perception process of human being these spatial temporal continuous data can be mapped onto corresponding smooth manifold and different appearance on manifold can indicate different semantic meaning in this paper we propose a semi supervised learning method which is based on partially labeled data to map original observed data onto semantic manifold for event definition and analysis in dynamic scene furthermore we also perform semantic representation for various event in real world scene finally we present experimental result to evaluate the performance of our method 
we propose a probabilistic hierarchical and discriminant phd framework for fast and accurate detection of deformable anatomic structure from medical image the phd framework ha three characteristic first it integrates distinctive primitive of the anatomic structure at global segmental and landmark level in a probabilistic manner second since the configuration of the anatomic structure lie in a high dimensional parameter space it seek the best configuration via a hierarchical evaluation of the detection probability that quickly prune the search space finally to separate the primitive from the background it adopts a discriminative boosting learning implementation we apply the phd framework for accurately detecting various deformable anatomic structure from mmode and doppler echocardiogram in about a second in clinical practice to ass the functionality of anatomic structure inside the heart such a left ventricle and aortic root a it high image quality allows accurate measurement and capture subtle motion the doppler echocardiograhy which is widely used to ass cardiovascular functionality such a valvular regurgitation and stenosis employ the doppler effect to determine whether structure usually blood are moving towards or away from the ultrasound probe and it relative velocity the acquired doppler echocardiogram is a velocity time image 
this paper show that structure from motion is np hard for most sensible cost function when missing data is allowed the result provides a fundamental limitation of what is possible to achieve with any structure from motion algorithm even though there are recent promising attempt to compute globally optimal solution there is no hope of obtaining a polynomial time algorithm unless p np the proof proceeds by encoding an arbitrary boolean formula a a structure from motion problem of polynomial size such that the structure from motion problem ha a zero cost solution if and only if the boolean formula is satisfiable hence if there wa a guaranteed way to minimize the error of the relevant family of structure from motion problem in polynomial time the np complete problem sat could be solved in polynomial time which would imply that p np the proof relies heavily on result from both structure from motion and complexity theory 
this article introduces the absolute quadratic complex formed by all line that intersect the absolute conic if denotes the symmetric matrix representing the image of that conic under the action of a camera with projection matrix rm p it is shown that omega approx overline rm p underline omega overline rm p rm t where rm p is the line projection matrix associated with rm p and underline omegais a symmetric matrix of rank representing the absolute quadratic complex this simple relation between a camera s intrinsic parameter it projection matrix expressed in a projective coordinate frame and the metric upgrade separating this frame from a metric one a respectively captured by the matrix overline rm p and underline omega provides a new framework for autocalibration particularly well suited to typical digital camera with rectangular or square pixel since the skew and aspect ratio are decoupled from the other intrinsic parameter in 
we present algorithm for recognizing human motion in monocular video sequence based on discriminative conditional random field crf and maximum entropy markov model memm existing approach to this problem typically use generative joint structure like the hidden markov model hmm therefore they have to make simplifying often unrealistic assumption on the conditional independence of observation given the motion class label and cannot accommodate overlapping feature or long term contextual dependency in the observation sequence in contrast conditional model like the crfs seamlessly represent contextual dependency support efficient exact inference using dynamic programming and their parameter can be trained using convex optimization we introduce conditional graphical model a complementary tool for human motion recognition and present an extensive set of experiment that show how these typically outperform hmms in classifying not only diverse human activity like walking jumping running picking or dancing but also for discriminating among subtle motion style like normal walk and wander walk 
we investigated the computational property of natural object hierarchy in the context of constellation object class model and it utility for object class recognition we first observed an interesting computational property of the object hierarchy comparing the recognition rate when using model of object at different level the higher more inclusive level e g closed frame vehicle or vehicle exhibit higher recall but lower precision when compared with the class specific level e g bus these inherent difference suggest that combining object classifier from different hierarchical level into a single classifier may improve classification a it appears like these model capture different aspect of the object we describe a method to combine these classifier and analyze the condition under which improvement can be guaranteed when given a small sample of a new object class we describe a method to transfer knowledge across the tree hierarchy between related object finally we describe extensive experiment using object hierarchy obtained from publicly available datasets and show that the combined classifier significantly improve recognition result 
within a computer vision context color naming is the action of assigning linguistic color label to image pixel in general research on color naming applies the following paradigm a collection of color chip is labelled with color name within a well defined experimental setup by multiple test subject the collected data set is subsequently used to label rgb value in real world image with a color name apart from the fact that this collection process is time consuming it is unclear to what extent color naming within a controlled setup is representative for color naming in realworld image therefore we propose to learn color name from real world image furthermore we avoid test subject by using google image to collect a data set due to limitation of google image this data set contains a substantial quantity of wrongly labelled data the color name are learned using a plsa model adapted to this task experimental result show that color name learned from realworld image significantly outperform color name learned from labelled color chip on retrieval and classification 
abstract reliable segmentation of the left ventricle is a long sought objective in medical imaging for automatic retrieval of anatomical and pathological measurement and detection of malfunction in this paper we propose a novel model constrained approach to address this task the method is based on an implicit representation of the shape model used in a shape registration framework with a thin plate spline transform to retrieve possible deformation the main innovation of our approach resides in the use of uncertainty defined on the registered shape to augment the training set and improve the robustness of the statistical deformable model we use ica to reduce the dimensionality of the space of deformation and provide a good separation of the different deformable part of the heart furthermore the estimation of uncertainty is also introduced in the segmentation process which is addressed in a variational framework where prior knowledge and visual support are considered the method lead to very promising qualitative and quantitative experimental result in ct 
an interactive human segmentation approach is described given region of interest provided by user the approach iteratively estimate segmentation via a generalized em algorithm specifically it encodes both spatial and color information in a nonparametric kernel density estimator and incorporates local mrf constraint and global pose inference to propagate belief over image space iteratively to determine a coherent segmentation this ensures the segmented human resemble the shape of human pose additionally a layered occlusion model and a probabilistic occlusion reasoning method are proposed to handle segmentation of multiple human in occlusion the approach is tested on a wide variety of image containing single or multiple occluded human and the segmentation performance is evaluated quantitatively 
image restoration is a keen problem of low level vision in this paper we propose a novel assumption free on the noise model technique based on random walk for image enhancement our method explores multiple neighbor set or hypothesis that can be used for pixel denoising through a particle filtering approach this technique associate weight for each hypothesis according to it relevance and it contribution in the denoising process towards accounting for the image structure we introduce perturbation based on local statistical property of the image in other word particle evolution are controlled by the image structure leading to a filtering window adapted to the image content promising experimental result demonstrate the potential of such an approach 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
classic method for bayesian inference effectively constrain search to lie within region of significant probability of the temporal prior this is efficient with an accurate dynamic model but otherwise is prone to ignore significant peak in the true posterior a more accurate posterior estimate can be obtained by explicitly finding mode of the likelihood function and combining them with a weak temporal prior in our approach mode are found using efficient example based matching followed by local refinement to find peak and estimate peak bandwidth by reweighting these peak according to the temporal prior we obtain an estimate of the full posterior model we show comparative result on real and synthetic image in a high degree of freedom articulated tracking task 
we address the problem of registering a sequence of image in a moving dynamic texture video this involves optimization with respect to camera motion the average image and the dynamic texture model this problem is highly illposed and almost impossible to have good solution without prior in this paper we introduce powerful prior for this problem based on two simple observation registration should simplify the dynamic texture model while preserving all useful information it motivates u to compute a prior for the dynamic texture by marginalizing over specific dynamic in the space of all stable auto regressive sequence the statistic of derivative filter response in the average image can be significantly changed by registration and better registration should lead to a sharper average image this offer u the prior of requiring the derivative distribution of the estimated average image to be close to that learned from the input image sequence with these prior a new registration approach is proposed by marginalizing over the nuisance variable under a bayesian framework and superior motion estimation result are obtained by jointly optimizing over the registration parameter the average image and the dynamic texture model experimental result on real video sequence of moving dynamic texture show convincing performance of the proposed approach 
this paper proposes a method for detecting shape of variable structure in image with clutter the term variable structure mean that some shape part can be repeated an arbitrary number of time some part can be optional and some part can have several alternative appearance the particular variation of the shape structure that occurs in a given image is not known a priori existing computer vision method including deformable model method were not designed to detect shape of variable structure they may only be used to detect shape that can be decomposed into a fixed a priori known number of part the proposed method can handle both variation in shape structure and variation in the appearance of individual shape part a new class of shape model is introduced called hidden state shape model that can naturally represent shape of variable structure a detection algorithm is described that find instance of such shape in image with large amount of clutter by finding globally optimal correspondence between image feature and shape model experiment with real image demonstrate that our method can localize plant branch that consist of an a priori unknown number of leaf and can detect hand more accurately than a hand detector based on the chamfer distance 
we present a generative model approach to explore intrinsic semantic structure in sport video e g the camera view in american football game we will invoke the concept of semantic space to explicitly dene the semantic structure in the video in term of latent state a dynamic model is used to govern the transition between state and an observation model is developed to characterize visual feature pertaining to different state then the problem is formulated a a statistical inference process where we want to infer latent state i e camera view from observation i e visual feature two generative model the hidden markov model hmm and the segmental hmm shmm are involved in this research in the hmm both latent state and visual feature are shot based and in the shmm latent state and visual feature are dened for shot and frame respectively both model provide promising performance for view based shot classication and the shmm outperforms the hmm by involving a two layer observation model to accommodate the variability of visual feature this approach is also applicable to other video mining task 
in this paper we consider region based variational segmentation of twoand three dimensional image by the minimization of functionals whose fidelity term is the quotient of two integral user often refrain from quotient functionals even when they seem to be the most natural choice probably because the corresponding gradient descent pdes are nonlocal and hence require the computation of global property here it is shown how this problem may be overcome by employing the structure of the euler lagrange equation of the fidelity term to construct a good initialization for the gradient descent pde which will then converge rapidly to the desired local minimum the initializer is found by making a one dimensional search among the level set of a function related to the fidelity term picking the level set which minimizes the segmentation functional this partial extremal initialization is tested on a medical segmentation problem with velocityand intensity data from mr image in this particular application the partial extremal initialization speed up the segmentation by two order of magnitude compared to straight forward gradient descent 
fingerprint individuality study deal with the crucial problem of the discriminative power of fingerprint for recognizing people in this paper we present a novel fingerprint individuality model based on minutia the most commonly used fingerprint feature the probability of the false correspondence among fingerprint from different finger is calculated by combining the distinctiveness of the spatial location and direction of the minutia to validate our model experiment were performed using different fingerprint database the matching score distribution predicted by our model actually fit the observed experimental result satisfactorily comparing to most previous fingerprint individuality model our model make more reasonably conservative estimate of the fingerprint discriminative power making it a powerful tool for studying the fingerprint individuality a well a the performance evaluation of fingerprint verification system 
this paper present a method for recognizing scene category based on approximate global geometric correspondence this technique work by partitioning the image into increasingly fine sub region and computing histogram of local feature found inside each sub region the resulting spatial pyramid is a simple and computationally efficient extension of an orderless bag of feature image representation and it show significantly improved performance on challenging scene categorization task specifically our proposed method exceeds the state of the art on the caltech database and achieves high accuracy on a large database of fifteen natural scene category the spatial pyramid framework also offer insight into the success of several recently proposed image description including torralba s gist and lowe s sift descriptor 
we present a novel object specic segmentation method which can be used in view based object recognition system previous object segmentation approach generate inexact result especially in partially occluded and cluttered environment because their top down strategy fail to explain the detail of various specic object on the contrary our segmentation method efciently exploit the information of the matched model view in view based recognition because the aligned model view to the input image can serve a the best top down cue for object segmentation in this paper we cast the problem of partially occluded object segmentation a that of labelling displacement and foreground status simultaneously for each pixel between the aligned model view and an input image the problem is formulated by a maximum a posteriori markov random eld map mrf model which minimizes a particular energy function our method overcomes complex occlusion and clutter and provides accurate segmentation boundary by combining a bottom up segmentation cue together we demonstrate the efciency and robustness of it by experimental result on various object under occluded and cluttered environment 
we use a hierarchical partition of unity finite element method h pufem to represent and analyse the non rigid deformation field involved in multidimensional image registration we make use of the ritz galerkin direct variational method to solve non rigid image registration problem with various deformation constraint in this method we directly seek a set of parameter that minimizes the objective function we thereby avoid the loss of information that may occur when an euler lagrange formulation is used experiment are conducted to demonstrate the advantage of our approach when registering synthetic image having little of or no localizing feature a a special case conformal mapping problem can be accurately solved in this manner we also illustrate our approach with an application to cardiac magnetic resonance temporal sequence 
we propose a new measure the method noise to evaluate and compare the performance of digital image denoising method we first compute and analyze this method noise for a wide class of denoising algorithm namely the local smoothing filter second we propose a new algorithm the non local mean nl mean based on a non local averaging of all pixel in the image finally we present some experiment comparing the nl mean algorithm and the local smoothing filter 
many low level vision algorithm assume a prior probability over image and there ha been great interest in trying to learn this prior from example since image are very non gaussian high dimensional continuous signal learning their distribution present a tremendous computational challenge perhaps the most successful recent algorithm is the field of expert foe model which ha shown impressive performance by modeling image statistic with a product of potential dened on lter output however a in previous model of image based on lter output calculating the probability of an image given the model requires evaluating an intractable partition function this make learning very slow requires monte carlo sampling at every step and make it virtually impossible to compare the likelihood of two different model given this computational difculty it is hard to say whether nonintuitive feature learned by such model represent a true property of natural image or an artifact of the approximation used during learning in this paper we present tractable lower and upper bound on the partition function of model based on lter output and efcient learning algorithm that do not require any sampling our result are based on recent result in machine learning that deal with gaussian potential we extend these result to non gaussian potential and derive a novel basis rotation algorithm for approximating the maximum likelihood lter s our result allow u to rigorously compare the likelihood of different model and calculate high likelihood model of natural image statistic in a matter of minute applying our result to previous model show that the nonintuitive feature are not an artifact of the learning process but rather are capturing robust property of natural image 
we propose a framework for detecting and tracking multiple interacting object while explicitly handling the dual problem of fragmentation an object may be broken into several blob and grouping multiple object may appear a a single blob we use foreground blob obtained by background subtraction from a stationary camera a measurement the main challenge is to associate blob measurement with object given the fragment object group ambiguity when the number of object is variable and unknown and object class specific model are not available we first track foreground blob till they merge or split we then build an inference graph representing merge split relation between the tracked blob using this graph and a generic object model based on spatial connectedness and coherent motion we label the tracked blob a whole object fragment of object or group of interacting object the output of our algorithm are entire track of object which may include corresponding track from group during interaction experimental result on multiple video sequence are shown 
in this paper we investigate a new method of learning part based model for visual object recognition from training data that only provides information about class membership and not object location or configuration this method learns both a model of local part appearance and a model of the spatial relation between those part in contrast other work using such a weakly supervised learning paradigm ha not considered the problem of simultaneously learning appearance and spatial model some of these method use a bag model where only part appearance is considered whereas other method learn spatial model but only given the output of a particular feature detector previous technique for learning both part appearance and spatial relation have instead used a highly supervised learning process that provides substantial information about object part location we show that our weakly supervised technique produce better result than these previous highly supervised method moreover we investigate the degree to which both richer spatial model and richer appearance model are helpful in improving recognition performance our result show that while both spatial and appearance information can be useful the effect on performance depends substantially on the particular object class and on the difficulty of the test dataset 
we address the problem of estimating human pose in video sequence where rough location ha been determined we exploit both appearance and motion information by defining suitable feature of an image and it temporal neighbor and learning a regression map to the parameter of a model of the human body using boosting technique our algorithm can be viewed a a fast initialization step for human body tracker or a a tracker itself we extend gradient boosting technique to learn a multi dimensional map from rotated and scaled haar feature to the entire set of joint angle representing the full body pose we test our approach by learning a map from image patch to body joint angle from synchronized video and motion capture walking data we show how our technique enables learning an efficient real time pose estimator validated on publicly available datasets 
abstract we investigate the problem of finding the metric structure of a general d scene viewed by a moving camera with square pixel and constant unknown focal length while the problem ha a concise and well understood formulation in the stratified framework thanks to the absolute dual quadric two open issue remain the first issue concern the generic critical motion sequence i e camera motion for which self calibration is ambiguous most of the previous work focus on the varying focal length case we provide a thorough study of the constant focal length case the second issue is to solve the nonlinear set of equation in four unknown arising from the dual quadric formulation most of the previous work either doe local nonlinear optimization thereby requiring an initial solution or linearizes the problem which introduces artificial degeneracy most of which likely to arise in practice we use interval analysis to solve this problem the resulting algorithm is guaranteed to find the solution and is not subject to artificial degeneracy directly using interval analysis usually result in computationally expensive algorithm we propose a carefully chosen set of inclusion function making it possible to find the solution within few second comparison of the proposed algorithm with existing one are reported for simulated and real data 
this paper treat tracking a a foreground background classification problem and proposes an online semisupervised learning framework initialized with a small number of labeled sample semi supervised learning treat each new sample a unlabeled data classification of new data and updating of the classifier are achieved simultaneously in a co training framework the object is represented using independent feature and an online support vector machine svm is built for each feature the prediction from different feature are fused by combining the confidence map from each classifier using a classifier weighting method which creates a final classifier that performs better than any classifier based on a single feature the semi supervised learning approach then us the output of the combined confidence map to generate new sample and update the svms online with this approach the tracker gain increasing knowledge of the object and background and continually improves itself over time compared to other discriminative tracker the online semi supervised learning approach improves each individual classifier using the information from other feature thus leading to a more robust tracker experiment show that this framework performs better than state of the art tracking algorithm on challenging sequence 
we propose a generalized equation to represent a continuum of surface reconstruction solution of a given non integrable gradient field we show that common approach such a poisson solver and frankot chellappa algorithm are special case of this generalized equation for a n n pixel grid the subspace of all integrable gradient field is of dimension n our framework can be applied to derive a range of meaningful surface reconstruction from this high dimensional space the key observation is that the range of solution is related to the degree of anisotropy in applying weight to the gradient in the integration process while common approach use isotropic weight we show that by using a progression of spatially varying anisotropic weight we can achieve significant improvement in reconstruction we propose a surface using binary weight where the parameter allows trade off between smoothness and robustness b m estimator and edge preserving regularization using continuous weight and c diffusion using affine transformation of gradient we provide result on photometric stereo compare with previous approach and show that anisotropic treatment discount noise while recovering salient feature in reconstruction 
we develop nonparametric bayesian model for multiscale representation of image depicting natural scene category individual feature or wavelet coefficient are marginally described by dirichlet process dp mixture yielding the heavy tailed marginal distribution characteristic of natural image dependency between feature are then captured with a hidden markov tree and markov chain monte carlo method used to learn model whose latent state space grows in complexity a more image are observed by truncating the potentially infinite set of hidden state we are able to exploit efficient belief propagation method when learning these hierarchical dirichlet process hidden markov tree hdp hmts from data we show that our generative model capture interesting qualitative structure in natural scene and more accurately categorize novel image than model which ignore spatial relationship among feature 
image can be represented a the composition of multiple intrinsic component image such a shading albedo and noise image in this paper we present a method for estimating intrinsic component image from a single image which we apply to the problem of estimating shading and albedo image and image denoising our method is based on learning estimator that predict filtered version of the desired image unlike previous approach our method doe not require unnatural discretizations of the problem we also demonstrate how to learn a weighting function that properly weight the local estimate when constructing the estimated image for shading estimation we introduce a new training set of real world image the accuracy of our method is measured both qualitatively and quantitatively showing better performance on the shading albedo separation problem than previous approach the performance on denoising is competitive with the current state of the art 
abstract image segmentation play an important role in computer vision and image analysis in this paper the segmentation problem is formulated a a labeling problem under a probability maximization framework to estimate the label configuration an iterative optimization scheme is proposed to alternately carry out the maximum a posteriori map estimation and the maximum likelihood ml estimation the map estimation problem is modeled with markov random field mrfs a graph cut algorithm is used to find the solution to the map mrf estimation the ml estimation is achieved by finding the mean of region feature our algorithm can automatically segment an image into region with relevant texture or color without the need to know the number of region in advance in addition under the same framework it can be extended to another algorithm that extract object of a particular class from a group of image extensive experiment have shown the effectiveness of our approach 
this paper proposes a new registration algorithm covariance driven correspondence cdc that depends fundamentally on the estimation of uncertainty in point correspondence this uncertainty is derived from the covariance matrix of the individual point location and from the covariance matrix of the estimated transformation parameter based on this uncertainty cdc us a robust objective function and an em like algorithm to simultaneously estimate the transformation parameter their covariance matrix and the likely correspondence unlike the robust point matching rpm algorithm cdc requires neither an annealing schedule nor an explicit outlier process experiment on synthetic and real image using a polynomial transformation model in d and in d show that cdc ha a broader domain of convergence than the well known iterative closest point icp algorithm and is more robust to missing or extraneous structure in the data than rpm 
we address the problem of seeking the global mode of a density function using the mean shift algorithm mean shift like other gradient ascent optimisation method is susceptible to local maximum and hence often fails to find the desired global maximum in this work we propose a multi bandwidth mean shift procedure that alleviates this problem which we term annealed mean shift a it share similarity with the annealed importance sampling procedure the bandwidth of the algorithm play the same role a the temperature in annealing we observe that the over smoothed density function with a sufficiently large bandwidth is uni modal using a continuation principle the influence of the global peak in the density function is introduced gradually in this way the global maximum is more reliably located generally the price of this annealing like procedure is that more iteration are required since it is imperative that the computation complexity is minimal in real time application such a visual tracking we propose an accelerated version of the mean shift algorithm compared with the conventional mean shift algorithm the accelerated mean shift can significantly decrease the number of iteration required for convergence the proposed algorithm is applied to the problem of visual tracking and object localisation we empirically show on various data set that the proposed algorithm can reliably find the true object location when the starting position of mean shift is far away from the global maximum in contrast with the conventional mean shift algorithm that will usually get trapped in a spurious local maximum 
this paper extends the set of problem for which a global solution can be found using modern optimization method in particular the method is applied to estimation of the essential matrix giving the first guaranteed optimal algorithm for estimating the relative pose under a geometric cost function in this case the l infinity cost function convex optimization technique ha been shown to provide optimal solution to many of the common problem in stucture from motion however they do not apply to problem involving rotation in this paper we introduce a search method that allows such problem to be solved optimally apart from the essential matrix the algorithm is applied to the camera pose problem providing an optimal algorithm 
one problem with the adaptive tracking is that the data that are used to train the new target model often contain error and these error will affect the quality of the new target model a time pass by these error will accumulate and eventually lead the tracker to drift away in this paper we propose a new method based on online data fusion to alleviate this tracking drift problem based on combining the spatial and temporal data through a dynamic bayesian network the proposed method can improve the quality of online data labeling therefore minimizing the error associated with model updating and alleviating the tracking drift problem experiment show the proposed method significantly improves the performance of an existing adaptive tracking method 
the problem of dense optical flow computation is addressed from a variational viewpoint a new geometric framework is introduced it unifies previous art and yield new efficient method along with the framework a new alignment criterion suggests itself it is shown that the alignment between the gradient of the optical flow component and between the latter and the intensity gradient is an important measure of the flow s quality adding this criterion a a requirement in the optimization process improves the resulting flow this is demonstrated in synthetic and real sequence 
our goal is to detect and track moving vehicle on a road observed from camera placed on pole or building inter vehicle occlusion is significant under these condition and traditional blob tracking method is unable to separate the vehicle in the merged blob we use vehicle shape model in addition to camera calibration and ground plane knowledge to detect track and classify moving vehicle in presence of occlusion we use a stage approach in the first stage hypothesis for vehicle type position and orientation are formed by a coarse search which is then refined by a data driven markov chain monte carlo ddmcmc process we show result and evaluation on some real urban traffic video sequence using three type of vehicle model 
the crossed slit x slit projection can be used to generate new view of a scene from a sequence of perspective image compared with other image based rendering ibr technique x slit image generation is simple and requires a relatively small number of input image which make it suitable for realtime ibr in this paper we extend this model to omnidirectional camera and a circular slit we show how it can be used for realtime image based rendering of omnidirectional image and how to optimize it for speed and quality we analyze the inherent geometric distortion of the circular x slit projection and describe a normalization mechanism to reduce distortion creating a realistic virtual environment essentially the same mechanism is used to augment the x slit image with artificial object when using standard graphic tool which assume perspective projection 
in this paper we investigate the mathematical problem underlying segmentation of hybrid motion given a series of tracked feature correspondence between two perspective image we seek to segment and estimate multiple motion possibly of different type e g affine epipolar and homography in order to accomplish this task we cast the problem into a more general mathematical framework of segmenting data sample drawn from a mixture of linear subspace and quadratic surface the result is a novel algorithm called hybrid quadratic surface analysis hqsa hqsa us both the derivative and hessian of fitting poly nomials for the data to separate linear data sample from quadratic data sample these derivative and hessian also lead to important necessary condition based on the so called mutual contraction subspace to separate data sample on different quadratic surface the algebraic solution we derive is non iterative and numerically stable it tolerates moderate noise and can be used in conjunction with outlier removal technique we show how to solve the hybrid motion segmentation problem using hqsa and demonstrate it performance on simulated data with noise and on real perspective image 
we present a new algorithm to detect human in still image utilizing covariance matrix a object descriptor since these descriptor do not lie on a vector space well known machine learning technique are not adequate to learn the classifier the space of d dimensional nonsingular covariance matrix can be represented a a connected riemannian manifold we present a novel approach for classifying point lying on a riemannian manifold by incorporating the a priori information about the geometry of the space the algorithm is tested on inria human database where superior detection rate are observed over the previous approach 
in this paper we present a compositional boosting algorithm for detecting and recognizing common image structure in low middle level vision task these structure called graphlets are the most frequently occurring primitive junction and composite junction in natural image and are arranged in a layer and or graph representation in this hierarchic model larger graphlets are decomposed in and node into smaller graphlets in multiple alternative way at or node and part are shared and re used between graphlets then we present a compositional boosting algorithm for computing the graphlets category collectively in the bayesian framework the algorithm run recursively for each node a in the and or graph and iterates between two step bottom up proposal and top down validation the bottom up step includes two type of boosting method i detecting instance of a often in low resolution using adaboosting method through a sequence of test weak classifier image feature ii proposing instance of a often in high resolution by binding existing child node of a through a sequence of compatibility test on their attribute e g angle relative size etc the adaboosting and binding method generate a number of candidate for node a which are verified by a top down process in a way similar to data driven markov chain monte carlo both the adaboosting and binding method are trained off line for each graphlet category and the compositional nature of the model mean the algorithm is recursive and can be learned from a small training set we apply this algorithm to a wide range of indoor and outdoor image with satisfactory result 
shape from shading is known to be an ill posed problem we show in this paper that if we model the problem in a different way than it is usually done more precisely by taking into account the r attenuation term of the illumination shape from shading becomes completely well posed thus the shading allows to recover almost any surface from only one image of this surface without any additional data in particular without the knowledge of the height of the solution at the local intensity minimum contrary to and without regularity assumption contrary to for example more precisely we formulate the problem a that of solving a new partial differential equation pde we develop a complete mathematical study of this equation and we design a new provably convergent numerical method finally we present result of our new shape from shading method on various synthetic and real image 
while feature point recognition is a key component of modernapproachesto object detection existing approach require computationally expensive patch preprocessing to handle perspective distortion in this paper we show that formulating the problem in a naive bayesian classification framework make such preprocessing unnecessary and producesan algorithm that is simple efficient and robust furthermore it scale well to handle large number of class to recognize the patch surrounding keypoints our classifier us hundred of simple binary feature and model class posterior probability we make the problem computationally tractable by assuming independence between arbitrary set of feature even though this is not strictly true we demonstrate that our classifier nevertheless performs remarkably well on image datasets containing very significant perspective change 
the performance of a face identification system varies with it enrollment size however most experiment evaluated the performance of algorithm at only one enrollment size with the rank identification rate the current practice doe not demonstrate the usability of algorithm thoroughly but the problem is in order to measure identification performance at different size experimenter have to repeat the evaluation with sample of those size which is almost impossible when they are large approach using the binomial theorem with match and non match score have been proposed to estimate performance at different size but a a separate process from the evaluation itself this paper present a new way of evaluating identification algorithm that allows the estimating and comparing of performance at different size using the regression analysis of misidentification risk 
abstract in many image classification application input feature space is often high dimensional and dimensionality reduction is necessary to alleviate the curse of dimensionality or to reduce the cost of computation in this paper we extract discriminant feature for image classification by learning a low dimensional embedding from finite labeled sample in the new feature space intra class compactness and extraclass separability are achieved simultaneously target dimensionality of the embedding is selected by spectral analysis our method is designed suitable for data with both uniand multi modal class distribution we also develop it two dimensional variant which make use of the matrix representation of image experimental result on three real image datasets demonstrate the efficacy of our method compared to the state of the art 
we propose to use high level visual information to improve illuminant estimation several illuminant estimation approach are applied to compute a set of possible illuminant for each of them an illuminant color corrected image is evaluated on the likelihood of it semantic content is the grass green the road grey and the sky blue in correspondence with our prior knowledge of the world the illuminant resulting in the most likely semantic composition of the image is selected a the illuminant color to evaluate the likelihood of the semantic content we apply probabilistic latent semantic analysis the image is modelled a a mixture of semantic class such a sky grass road and building the class description is based on texture position and color information experiment show that the use of high level information improves illuminant estimation over a purely bottom up approach furthermore the proposed method is shown to significantly improve semantic class recognition performance 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper we investigate a possibility of using the face expression information for person biometrics the idea of this research is that person s emotional face expression are repeatable and face expression feature can be used for person identification in order to avoid using person specific geometric or textural feature traditionally used in face biometrics we restrict ourselves to the tracker displacement feature only in contrast to previous research in facial expression biometrics we extract feature only from the pair of face image neutral and the apex of emotion expression instead of using the sequence of image from the video the experiment performed on two facial expression database confirm that proposed feature can indeed be used for biometrics purpose 
our objective is to model the visual manifold of object appearance corresponding to geometric transformation we learn a generative model for object appearance where the appearance of the object at each new frame is a function that map from a conceptual representation of the geometric transformation space into the visual manifold by learning such generative model we can infer the geometric transformation track directly from the tracked object appearance a a result tracking can be achieved in a closed form and therefore can be done very efficiently 
many application require the ability to track the d motion of the subject we build a particle filter based framework for multimodal tracking using multiple camera and multiple microphone array in order to calibrate the resulting system we propose a method to determine the location of all microphone using at least five loudspeaker and under assumption that for each loudspeaker there exists a microphone very close to it we derive the maximum likelihood ml estimator which reduces to the solution of the non linear least square problem we verify the correctness and robustness of the multimodal tracker and of the self calibration algorithm both with monte carlo simulation and on real data from three experimental setup 
in this paper a novel algorithm for the fundamental matrix estimation called factorized point algorithm is presented the factorized point algorithm is composed of three step the measurement matrix in the traditional point algorithm is decomposed into two factor matrix by introducing some auxiliary variable a new linear minimization problem is formed where every element of it associated measurement matrix is simply either a measurement datum or a constant the fundamental matrix is determined by solving this minimization problem by a least square method like the traditional point algorithm and hartley s normalized point algorithm the factorized point algorithm is also completely linear but unlike the normalized point algorithm the factorized point algorithm doe not need any pre normalization step since every element of the measurement matrix in the factorized point algorithm is a measurement datum or a constant no amplification of measurement error is involved the factorized point algorithm can boost effectively the robustness of the estimation large number of experiment show that the factorized point algorithm consistently outperforms the traditional point algorithm in addition although the factorized point algorithm is specially designed for fundamental matrix estimation it basic principle can be generalized to other estimation problem in computer vision such a camera projection matrix estimation homography estimation focus of expansion estimation and trifocal tensor estimation 
an integrated framework mainly focusing on stereo matching ha been presented in this paper to obtain dense depth map for a mobile robot that is equipped with a novel omnidirectional stereo vision sensor that is designed to obtain height information the vision sensor is composed of a common perspective camera and two hyperbolic mirror which are separately fixed inside a glass cylinder a the separation between the two mirror provides much enlarged baseline the precision of the system ha improved correspondingly nevertheless the large disparity space and image particularity that are different from general stereo vision system result in poor performance using common method to satisfy the reliability requirement by mobile robot navigation we use improved graph cut method in which more appropriate three variable smootheness model is proposed for general prior corresponding to more reasonable piecewise smoothness assumption since the well known swap move algorithm can be applied to a wider class of function we also show the necessary modification to handle panoramic image including deformed matching template adaptable template scale experiment show that this proposed vision system is feasible a a practical stereo sensor for accurate depth map generation 
in scene containing specular object the image motion observed by a moving camera may be an intermixed combination of optical flow resulting from diffuse reflectance diffuse flow and specular reflection specular flow here with few assumption we formalize the notion of specular flow show how it relates to the d structure of the world and develop an algorithm for estimating scene structure from d image motion unlike previous work on isolated specular highlight we use two image frame and estimate the semi dense flow arising from the specular reflection of textured scene we parametrically model the image motion of a quadratic surface patch viewed from a moving camera the flow is modeled a a probabilistic mixture of diffuse and specular component and the d shape is recovered using an expectation maximization algorithm rather than treating specular reflection a noise to be removed or ignored we show that the specular flow provides additional constraint on scene geometry that improve estimation of d structure when compared with reconstruction from diffuse flow alone we demonstrate this for a set of synthetic and real sequence of mixed specular diffuse object 
this paper present a novel statistical shape model that can be used to detect and localise feature point of a class of object in image the shape model is inspired from the d morphable model dmm and ha the property to be viewpoint invariant this shape model is used to estimate the probability of the position of a feature point given the position of reference feature point accounting for the uncertainty of the position of the reference point and of the intrinsic variability of the class of object the viewpoint invariant detection algorithm maximises a foreground background likelihood ratio of the relative position of the feature point their appearance scale orientation and occlusion state computational efficiency is obtained by using the bellman principle and an early rejection rule based on d to d projection constraint evaluation of the detection algorithm on the cmu pie face image and on a large set of non face image show high level of accuracy zero false alarm for more than detection rate a well a locating feature point the detection algorithm also estimate the pose of the object and a few shape parameter it is shown that it can be used to initialise a dmm fitting algorithm and thus enables a fully automatic viewpoint and lighting invariant image analysis solution 
we demonstrate an attentional event selection tracking and classification system for processing video stream from remotely operated underwater vehicle rovs that enables automated annotation of underwater video transects for quantitative study of ocean ecology the system identifies and track potentially interesting visual event spanning multiple frame based on low level property of salient object interesting event are passed to a bayesian classifier utilizing a gaussian mixture model to determine the abundance and distribution of a representative benthic specie presented data detail the comparison between automated detection of organism and program classification of deep sea ocean bottom echinoderm sea star rathbunaster californicus in video footage with professional annotation 
we present a technique for clustering measurement such that high dimensional parameter estimation problem can be simplified the key idea is to find row of the measurement jacobian whose rank is significantly le than it width such a set of row give a cluster of measurement which is affected only by a subset of the parameter space this cluster can be used independently from other measurement to isolate parameter decision unlike static partitioning technique the method presented dynamically generates cluster at each step of the estimation this achieves substantial computational reduction even for problem which cannot be partitioned in the traditional sense the technique is applied to the task of tracking camera motion in real time and video sequence are used to compare the resulting system to previous method 
the inverse gradient problem finding a scalar field f with a gradient near a given vector field g on some bounded and connected domain rn can be solved by mean of a poisson equation with inhomogeneous neumann boundary condition we present an elementary derivation of this partial differential equation and an efficient multigridbased method to numerically compute the inverse gradient on non rectangular domain the utility of the method is demonstrated by a range of important medical application such a phase unwrapping pressure computation inverse deformation field and fiber bundle tracking 
we consider the important challenge of recognizing a variety of deformable object class in image of fundamental importance and particular difficulty in this setting is the problem of outlining an object rather than simply deciding on it presence or absence a major obstacle in learning a model that will allow u to address this task is the need for hand segmented training image in this paper we present a novel landmark based piecewise linear model of the shape of an object class we then formulate a learning approach that allows u to learn this model with minimal user supervision we circumvent the need for hand segmentation by transferring the shape essence of an object from drawing to complex image we show that our method is able to automatically and effectively learn and localize a variety of object class 
we propose a homography estimation method from the contour of planar region standard projective invariant such a cross ratio or canonical frame based on hot point obtained from local differential property are extremely unstable in real image suffering from pixelization thresholding artifact and other noise source we explore alternative construction based on global convexity property of the contour such a discrete tangent and concavity we show that a projective frame can be robustly extracted from arbitrary shape with at least one appreciable concavity algorithmic complexity and stability are theoretically discussed and experimentally evaluated in a number of real application including projective shape matching alignment and pose estimation we conclude that the procedure is computationally efficient and notably robust given the ill conditioned nature of the problem 
this paper address the reconstruction of canal surface from single image a canal surface is obtained a the envelope of a family of sphere of constant radius whose center is swept along a space curve called axis previous study either used approximate relationship quasi invariant or they addressed the recognition based on a geometric model in this paper we show that under broad condition canal surface can be reconstructed from single image under exact perspective in particular canal surface with planar axis can even be reconstructed from a single fully uncalibrated image an automatic reconstruction method ha been implemented simulation and experimental result on real image are also presented 
the way catadioptric image are acquired implies that they present radial distortion therefore classical processing may not be suitable this statement will be illustrated by considering edge detection matter classical edge detector usually consist in three step gradient computation maximization and thresholding the two last step use pixel neighborhood concept on the opposite of perspective image where pixel neighborhood is intuitive catadioptric image present radial resolution change then the size and shape of pixel neighborhood have to be depending on pixel location this article present a new gradient estimation approach based on non additive kernel this technique is adapted to catadioptric image and also provides a natural threshold discarding the arbitrary thresholding step 
we present a new method for summarizing image for the purpose of matching and registration we take the point of view that large coherent region in the image provide a concise and stable basis for image description we develop a new algorithm for image segmentation that operates on several projection feature space of the image using kernel based optimization technique to locate local extremum of a continuous scale space of image region descriptor of these image region and their relative geometry then form the basis of an image description we present experimental result of these method applied to the problem of image retrieval on a moderate sized database we find that our method performs comparably to two published technique blobworld and sift feature however compared to these technique two significant advantage of our method are it stability under large change in the image and it representationalefficiency a a result we argue our proposed method will scale well with larger image set 
work on photometric stereo ha shown how to recover the shape and reflectance property of an object using multiple image taken with a fixed viewpoint and variable lighting condition this work ha primarily relied on known lighting condition or the presence of a single point source of light in each image in this paper we show how to perform photometric stereo assuming that all light in a scene are distant from the object but otherwise unconstrained lighting in each image may be an unknown and may include arbitrary combination of diffuse point and extended source our work is based on recent result showing that for lambertian object general lighting condition can be represented using low order spherical harmonic using this representation we can recover shape by performing a simple optimization in a low dimensional space we also analyze the shape ambiguity that arise in such a representation we demonstrate our method by reconstructing the shape of object from image obtained under a variety of lighting we further compare the reconstructed shape against shape obtained with a laser scanner 
a new approach to template tracking is presented incorporating three distinct contribution firstly an explicit definition for a feature track is given secondly the advantage of an image preprocessing stage are demonstrated and in particular the effectiveness of highly compressed image patch data stored in k d tree for fast and discriminatory image patch search thirdly the k d tree are used to generate multiple track hypothesis which are efficiently merged to give the optimal solution using dynamic programming the explicit separation of feature detection and trajectory determination creates the basis for the novel use of k d tree and dynamic programming multiple appearance and occlusion handling are seamlessly integrated into this framework appearance variation through the sequence is robustly handled in an iterative process the work presented is a significant foundation for a powerful off line feature tracking system particularly in the context of interactive application 
color constancy is almost exclusively modeled with diagonal transforms however the choice of basis under which diagonal transforms are taken is traditionally ad hoc attempt to remedy the situation have been hindered by the fact that no joint characterization of the condition for sensor illuminant reflectance to support diagonal color constancy ha previously been achieved in this work we observe that the von kries compatibility condition are imposition only on the sensor measurement not the physical spectrum this allows u to formulate the von kries compatibility condition succinctly a rank constraint on an order measurement tensor given this we propose an algorithm that computes a locally optimal choice of color basis for diagonal color constancy and compare the result against other proposed choice 
the advance in image video editing technique ha facilitated people in synthesizing realistic imageshideos that may hard to be distinguished from real one by visual examination this pose a problem how to differentiate real imageshideosfrom doctored one this is a serious problembecause some legal issue may occur if there is no reliable way for doctored image video detection when human inspection fails digital watermarking cannot solve this problem completely wepropose an approach that computes the response function of the camera by selecting appropriate patch in different way an image may be doctored if the response function are abnormal or inconsistent to each other the normality of the response function is classified by a trained support vector machine svm experiment show that our method is effective for high contrast image with many textureless edge 
the capability to learn from experience and update incrementally it internal representation is a key property for a visual recognition algorithm aiming to work in real world scenario this paper present a novel svm based algorithm for visual object recognition capable of learning model representation incrementally we combine an incremental extension of svms with a method which reduces the number of support vector needed to build the decision function without any loss in performance the resulting algorithm is guaranteed to achieve the same recognition performance a the original incremental method while reducing the memory requirement we then introduce a parameter which permit a user set trade off between performance and memory reduction this property is potentially useful in application where the memory size of the visual model must be kept under control result show that it is possible to achieve a consistent reduction of the memory requirement with only a moderate loss in performance for example experiment show that when the user accepts a reduction in recognition rate of this yield a memory reduction of up to 
this paper develops a new mathematical framework for studying the subspace segmentation problem we examine some important algebraic property of subspace arrangement that are closely related to the subspace segmentation problem more specifically we introduce an important class of invariant given by the hilbert function we show that there exist rich relation between subspace arrangement and their corresponding hilbert function we propose a new subspace segmentation algorithm and showcase two application to demonstrate how the new theoretical revelation may solve subspace segmentation and model selection problem under le restrictive condition with improved result 
this paper introduces a variational formulation for image denoising based on a quadratic function over kernel of variable bandwidth these kernel are scale adaptive and reflect spatial and photometric similarity between pixel the bandwidth of the kernel is observation dependent towards improving the accuracy of the reconstruction process andis constrainedto be locally smooth we analyzethe evolution of the noise model form the raw space to the rgb one by propagating it over the image formation process the experimental result demonstrate that the use of a variable bandwidth approach and an image intensity dependent noise variance ensures better restoration quality 
in this paper we introduce the semantic network model snm a generalization of the hidden markov model hmm that us factorization of state transition probability to reduce training requirement increase the efficiency of gesture recognition and on line learning and allow more precision in gesture modeling we demonstrate the advantage both formally and experimentally using example such a full body multimodal gesture recognition via optical motion capture and a pressure sensitive floor a well a mouse pen gesture recognition our result show that our algorithm performs much better than the traditional approach in situation where training sample are limited and or the precision of the gesture model is high 
an approach for fast tracking of arbitrary image feature with no prior model and no offline learning stage is presented fast tracking is achieved using bank of linear displacement predictor learnt online a multi modal appearance model is also learnt on the fly that facilitates the selection of subset of predictor suitable for prediction in the next frame the approach is demonstrated in real time on a number of challenging video sequence and experimentally compared to other simultaneous modeling and tracking approach with favourable result 
online camera recalibration is necessary for long term deploymentof computervision system existing algorithm assume that the source of recalibration information is a set of feature in a general d scene and that enough feature are observed that the calibration problem is wellconstrained however these assumption are frequently invalid outside the laboratory real world scene often lack texture contain repeated texture or are mostly planar making calibration difficult or impossible in this paper we consider the calibration of family of stereo camera where each camera is assumed to have parameter drawn from a common but unknown prior distribution we show how estimation of this prior using a small number of offline calibrated camera e g from the same production line allows online calibration of additional camera using a small number of point correspondence and that using the estimated prior significantly increase the accuracy and robustness of stereo camera calibration 
this paper present a novel method to solve multi view face detection problem by error correcting output code ecoc the motivation is that face pattern can be divided into separated class across view and ecoc multi class method can improve the robustness of multi view face detection compared with the view based method because of it inherent error tolerant ability one key issue with ecoc based multi class classifier is how to construct effective binary classifier besides applying ecoc to multi view face detection this paper emphasizes on designing efficient binary classifier by learning informative feature through minimizing the error rate of the ensemble ecoc multi class classifier aiming at designing efficient binary classifier we employ spatial histogram a the representation which provide an over complete set of optional feature that can be efficiently computed from the original image in addition the binary classifier is constructed a a coarse to fine procedure using fast histogram matching followed by accurate support vector machine svm the experimental result show that the proposed method is robust to multi view face and achieves performance comparable to that of state of the art approach to multi view face detection 
while crowd of various subject may offer applicationspecific cue to detect individual we demonstrate that for the general case motion itself contains more information than previously exploited this paper describes an unsupervised data driven bayesian clustering algorithm which ha detection of individual entity a it primary goal we track simple image feature and probabilistically group them into cluster representing independently moving entity the number of cluster and the grouping of constituent feature are determined without supervised learning or any subject specific model the new approach is instead that space time proximity and trajectory coherence through image space are used a the only probabilistic criterion for clustering an important contribution of this work is how these criterion are used to perform a one shot data association without iterating through combinatorial hypothesis of cluster assignment our proposed general detection algorithm can be augmented with subject specific filtering but is shown to already be effective at detecting individual entity in crowd of people insect and animal this paper and the associated video examine the implementation and experiment of our motion clustering framework 
recent work show that recovering pose and velocity from a single view of a moving rigid object is possible with a rolling shutter camera based on feature point correspondence we extend this method to line correspondence owing to the combined effect of rolling shutter and object motion straight line are distorted to curve a they get imaged with a rolling shutter camera line thus capture more information than point which is not the case with standard projection model for which both point and line give two constraint we extend the standard line reprojection error and proposeanonlinearmethodforretrievingasolutionto thepose and velocity computation problem a careful inspection of the design matrix in the normal equation reveals that it is highly sparse and patterned we propose a blockwise solution procedure based on bundle adjustment like sparse inversion this make nonlinearoptimization fast and numerically stable the method is validated using real data 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
this paper proposes a feature based method for recovering the relative position of the viewpoint of a set of panoramic image for which no a priori order information is available along with certain structure information regarding the imaged environment the proposed approach operates incrementally employing the levenshtein distance to deduce the spatial proximity of image viewpoint and thus determine the order in which image should be processed the levenshtein distance also provides match between image from which their underlying environment point can be recovered recovered point that are visible in multiple view permit the localization of more view which in turn allow the recovery of more point the process repeat until all view have been localized periodic refinement of the reconstruction with the aid of bundle adjustment distributes the reconstruction error among image the method is demonstrated on several unordered set of panoramic image obtained in an indoor environment 
the aim of this work is to learn generative model of object deformation in an unsupervised manner initially we introduce an expectation maximization approach to estimate a linear basis for deformation by maximizing the likelihood of the training set under an active appearance model aam this approach is shown to successfully capture the global shape variation of object like face car and hand however the aam representation cannot deal with articulated object like cow and horse we therefore extend our approach to a representation that allows for multiple part with the relationship between them modeled by a markov random field mrf finally we propose an algorithm for efficiently performing inference on part based mrf object model by speeding up the estimation of observation potential we use manually collected landmark to compare the alternative model and quantify learning performance 
in this paper we introduce a new image descriptor for broad image categorization the progressive randomization pr that us perturbation on the value of the least significant bit lsb of image we show that different class of image have a distinct behavior under our methodology and that using statistical descriptor of lsb occurrence and enough training example the method already performs a well or better than comparable existing techniquesin the literature with few training example pr still ha good separability and it accuracy increase with the size of the training set we validate our method using four image database with different category 
recovering the shape of a class of object requires establishing correct correspondence between manually or automatically annotated landmark point in this study we utilise a novel approach to automatically recover the shape of hand outline from a series of d training image automated landmark extraction is accomplished through the use of the self organising model the growing neural gas gng network which is able to learn and preserve the topological relation of a given set of input pattern without requiring a priori knowledge of the structure of the input space to measure the quality of the mapping throughout the adaptation process we use the topographic product result are given for the training set of hand outline 
description camera matchmoving is an application involving synthesis of real scene and artificial object in which the goal is to insert computer generated graphical d object into liveaction footage depicting unmodeled arbitrary scene graphical object should be inserted in a way so that they appear to move a if they were a part of the real scene seamless convincing insertion of graphical object call for accurate d camera motion tracking i e pose estimation stable enough over extended sequence so a to avoid the problem of jitter and drift in the location and appearance of object with respect to the real scene in addition to it theoretical interest camera matchmoving find several important application in area such a augmented reality virtual studio shooting and the creation of special effect in the post production film making industry this work address the problem of tracking the d motion of a camera in space using only the image it acquires while moving freely in unmodeled arbitrary environment a novel feature based method for camera tracking ha been developed intended to facilitate tracking in on line time critical application such a video see through augmented reality and visionbased control in contrast to several existing technique which are designed to operate in a batch off line mode assuming that the whole video sequence to be tracked is available before tracking commences our method operates on image incrementally a they are being acquired furthermore it doe not rely upon the presence in the environment of fiducial marker or special calibration object a brief overview of our approach is given in the next section more detailed description can be found in and online at http www ic forth gr lourakis camtrack the approach 
this paper is an argument for two assertion first that by representing correspondence probabilistically d rastically more correspondence information can be extracted from image second that by increasing the amount of correspondence information used more accurate egomotion estimation is possible we present a novel approach illustrating these principle we first present a framework for using gabor filter to generate such correspondence probability distribution essentially different filter vote on the correct correspondence in a way giving their relative likelihood next we use the epipolar constraint to generate a probability distr ibution over the possible motion a the amount of correspondence information is increased the set of motion yielding significant probability is shown to shrink to the correct motion 
while face recognition technique have rapidly advanced in the last few year most of the work is in the domain of security application for consumer imaging application person recognition is an important tool that is useful for searching and retrieving image from a personal image collection it ha been shown that when recognizing a single person in an image a maximum likelihood classifier requires the prior probability for each candidate individual in this paper we extend this idea and describe the benefit of using a group prior for identifying people in consumer image with multiple people the group prior describes the probability of a group of individual appearing together in an image in our application we have a subset of ambiguously labeled image for a consumer image collection where we seek to identify all of the people in the collection we describe a simple algorithm for resolving the ambiguous label we show that despite error in resolving ambiguous label useful classifier can be trained with the resolved label recognition performance is further improved with a group prior learned from the ambiguous label in summary by modeling the relationship between the people with the group prior we improve classification performance 
the human vision system can interpret a single d line drawing a a d object without much difficulty even if the hidden line of the object are invisible several reconstruction approach have tried to emulate this ability but they cannot recover the complete object if the hidden line of the object are not shown this paper proposes a novel approach for reconstructing complete d object from line drawing without hidden line first we develop some constraint and property for the inference of the topology of the invisible edge and vertex of an object then we present a reconstruction method based on perceptual symmetry and planarity of the object we give a number of example to demonstrate the ability of our approach 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
the demosaicing process convert single ccd color representation of one color channel per pixel into full per pixel rgb we introduce a bayesian technique for demosaicing bayer color filter array pattern that is based on a statistically obtained two color per pixel image prior by modeling all local color behavior a a linear combination of two fully specified rgb triple we avoid color fringing artifact while preserving sharp edge our grid le floating point pixel location architecture can process both single image and multiple image from video within the same framework with multiple image providing denser color sample and therefore better color reproduction with reduced aliasing an initial clustering is performed to determine the underlying local two color model surrounding each pixel using a product of gaussians statistical model the underlying linear blending ratio of the two representative color at each pixel is estimated while simultaneously providing noise reduction finally we show that by sampling the image model at a finer resolution than the source image during reconstruction our continuous demosaicing technique can super resolve in a single step 
tracking the d pose of an object need correspondence between d feature in the image and their d counterpart in the object model a large variety of such feature ha been suggested in the literature all of them have drawback in one situation or the other since their extraction in the image and or the matching is prone to error in this paper we propose to use two complementary type of feature for pose tracking such that one type make up for the shortcoming of the other aside from the object contour which is matched to a free form object surface we suggest to employ the optic flow in order to compute additional point correspondence optic flow estimation is a mature research field with sophisticated algorithm available using here a high quality method ensures a reliable matching in our experiment we demonstrate the performance of our method and in particular the improvement due to the optic flow 
one of the classic problem in low level vision is image restoration an important contribution toward this effort ha been the development of shock filter by osher and rudin it performs image de blurring using hyperbolic partial differential equation in this paper we relate the notion of cluster separation from the field of pattern recognition to the shock filter formulation a kind of shock filter is proposed based on the idea of gradient based separation of cluster the proposed formulation is general enough a it can allow various model of density function in the cluster separation process the efficacy of the method is demonstrated through various example 
usually object detection is performed directly on normalized gray value or gray primitive like gradient or haar like feature in that case the learning of relationship between gray primitive that describe the structure of the object is the complete responsibility of theclassifier we propose to apply more knowledge about the image structure in the preprocessing step by computing local isophote direction and curvature in order to supply the classifier with much more informative image structure feature however a periodic feature space like orientation is unsuited for common classification method therefore we split orientation into two more suitable component experiment show that the isophote feature result in better detection performance than intensity gradient or haar like feature 
the bag of word representation ha attracted a lot of attention recently in the field of object recognition based on the bag of word representation topic model such a probabilistic latent semantic analysis plsa have been applied to unsupervised object discovery in still image in this paper we extend topic model from still image to motion video with the integration of a temporal model we propose a novel spatial temporal framework that us topic model for appearance modeling and the probabilistic data association pda filter for motion modeling the spatial and temporal model are tightly integrated so that motion ambiguity can be resolved by appearance and appearance ambiguity can be resolved by motion we show promising result that cannotbe achieved by appearanceor motion modeling alone 
in this paper we compare the performance of local detector and descriptor in the context of object class recognition recently many detector descriptor have been evaluated in the context of matching a well a invariance to viewpoint change however it is unclear if these result can be generalized to categorization problem which require different property of feature we evaluate state of the art scale invariant region detector and descriptor local feature are computed for object class and clustered using hierarchical agglomerative clustering we measure the quality of appearance cluster and location distribution using entropy a well a precision we also measure how the cluster generalize from training set to novel test data our result indicate that extended sift descriptor computed on hessian laplace region perform best second score is obtained by salient region the result also show that these two detector provide complementary feature the new detector descriptorssignificantly improve the performance of a state of the art recognition approach in pedestrian detection task 
although it ha been studied for several year by computer vision and machine learning community image annotation is still far from practical in this paper we present annosearch a novel way to annotate image using search and data mining technology leveraging the web scale image we solve this problem in two step searching for semantically and visually similar image on the web and mining annotation from them firstly at least one accurate keyword is required to enable text based search for a set of semantically similar image then content based search is performed on this set to retrieve visually similar image at last annotation are mined from the description title url and surrounding text of these image it worth highlighting that to ensure the efficiency high dimensional visual feature are mapped to hash code which significantly speed up the content based search process our proposed approach enables annotating with unlimited vocabulary which is impossible for all existing approach experimental result on real web image show the effectiveness and efficiency of the proposed algorithm 
random subspace are a popular ensemble construction technique that improves the accuracy of weakclassifiers it ha been shown in different domain that random subspace combined with weak classifier such a decision tree and nearest neighbor classifier can provide an improvement in accuracy in this paper we apply the random subspace methodology to the d face recognition task the main goal of the paper is to see if the random subspace methodology can do a well if not better than the single classifier constructed on the tuned face space we also propose the use of a validation set for tuning the face space to avoid bias in the accuracy estimation in addition we also compare the random subspace methodology to an ensemble of subsamples of image data this work show that a random subspace ensemble can outperform a well tuned single classifier for a typical d face recognition problem the random subspace approach ha the added advantage of requiring le careful tweaking 
the use of image patch to capture local correlation between pixel ha been growing in popularity for use in various low level vision task there is a trade off between using larger patch to obtain additional high order statistic and smaller patch to capture only the elemental feature of the image previous work ha leveraged shortrange correlation between patch that share pixel value for use in patch matching in this paper long range correlation between patch are introduced where relation between patch that do not necessarily share pixel are learnt such correlation arise a an inherent property of the data itself these long range patch correlation are shown to be particularly important for video sequence where the patch have an additional time dimension with correlation link in both space and time we illustrate the power of our model on task such a multiple object registration and detection and missing data interpolation including a difficult task of photograph relighting where a single photograph is assumed to be the only observed part of a d volume whose two coordinate are the image x and y coordinate and the third coordinate is the illumination angle we show that in some case the long range correlation observed among the mapping of different volume patch in a small training set are sufficient to infer the possible complex intensity change in a new photograph due to illumination angle variation figure the epitome of three car image learnt using longrange patch correlation the epitome end up being a merge of the three car with both the front and back of the car reaching a compromise between the different shape of the car also interesting to note is how the epitome merges the three background the patch indicated by si in the top left image is connected to several other randomly chosen patch in the image to which relative patch distance should be generally maintained during patch matching to the epitome the corresponding patch in the epitome is shown a ti and the matching is constrained by the match for the patch connected to si a video illustrating this patch correspondence during learning is available at http www psi toronto edu vincent patchcorr html 
the choice of a color space is of great importance for many computer vision algorithm e g edge detection and object recognition it induces the equivalence class to the actual algorithm however the problem is how to automatically select the color space that produce the best result for a particular task the subsequent difficulty then is how to obtain a proper weighting scheme for the algorithm so that the result are combined in an optimal setting to achieve proper color space selection and fusion of feature detector in this paper we propose a method that exploit non perfect correlation between the color model derived from the principle of diversification a a consequence the weighting scheme yield maximal color discrimination the method is verified experimentally for two different feature detector the experimental result show that the model provides feature detection result having a discriminative power of percent higher than the standard weighting scheme 
we present a discriminative shape based algorithm for object category localization and recognition our method learns object model in a weakly supervised fashion without requiring the specification of object location nor pixel mask in the training data we represent object model a clique of fully interconnected part exploiting only the pairwise geometric relationship between them the use of pairwise relationship enables our algorithm to successfully overcome several problem that are common to previously published method even though our algorithm can easily incorporate local appearance information from richer feature we purposefully do not use them in order to demonstrate that simple geometric relationship can match or exceed the performance of state of the art object recognition algorithm 
although variational method are among the most accurate technique for estimating the optical flow they have not yet entered the field of real time vision main reason is the great popularity of standard numerical scheme that are easy to implement however at the expense of being too slow for real time performance in our paper we address this problem in two way i we present an improved version of the highly accurate technique of brox et al thereby we show that a separate robustification of the constancy assumption is very useful in particular if the norm is used a penalizer a a result a method is obtained that yield the lowest angular error in the literature ii we develop an efficient numerical scheme for the proposed approach that allows real time performance for sequence of size to this end we combine two hierarchical strategy a coarse to fine warping strategy a implementation of a fixed point iteration for a non convex optimisation problem and a nonlinear full multigrid method a so called full approximation scheme fa for solving the highly nonlinear equation system at each warping level in the experimental section the advantage of the proposed approach becomes obvious outperforming standard numerical scheme by two order of magnitude frame rate of six high quality flow field per second are obtained on a ghz pentium pc 
this article describes a video surveillance system developed within the iscaps project thermal imaging provides a robust solution to visibility change illumination smoke and is a relevant technology for discriminating human in complex scene in this article we demonstrate it efficiency for posture analysis in dense group of people the objective is to automatically detect several person lying down in a very crowded area the presented method is based on the detection and segmentation of individual within group of people using a combination of several weak classifier the classification of extracted silhouette enables to detect abnormal situation this approach wa successfully applied to the detection of terrorist gas attack on railway platform and experimentally validated in the project some of the result are presented here 
in this paper we present a novel framework for constructing large deformation log unbiased image registration model that generate theoretically and intuitively correct deformation map such registration model do not rely on regridding and are inherently topology preserving we apply information theory to quantify the magnitude of deformation and examine the statistical distribution of jacobian map in the logarithmic space to demonstrate the power of the proposed framework we generalize the well known viscous fluid registration model to compute logunbiased deformation we tested the proposed method using a pair of binary corpus callosum image a pair of two dimensional serial mri image and a set of threedimensional serial mri brain image we compared our result to those computed using the viscous fluid registration method and demonstrated that the proposed method is advantageous when recovering voxel wise map of local tissue change 
in this paper we present a bayesian framework for the fully automatic tracking of a variable number of interacting target using a fixed camera this framework us a joint multi object state space formulation and a trans dimensional markov chain monte carlo mcmc particle filter to recursively estimate the multi object configuration and efficiently search the state space we alsodefine a global observation model comprised of color and binary measurement capable of discriminating between different number of object in the scene we present result which show that our method is capable of tracking varying number of people through several challenging real world tracking situation such a full partial occlusion andentering leaving the scene 
we present a quality assessment procedure for correspondence estimation based on geometric coherence rather than ground truth the procedure can be used for performance evaluation of correspondence extraction scheme developed by researcher a well a for online learning and adaptation aimed at better system performance a very important aspect of the proposed procedure is that it considers uncertainty in the correspondence extraction and encourages the evaluated method to deal correctly with uncertainty other important strength of the procedure are that it doe not use any manual work and that it doe not put any strong constraint on the scene but rather relies on geometric coherence in the motion thanks to these strength it can therefore be used with large amount of real potentially application specific data or even data acquired during system operation in the evaluation the correspondence extractor is handled a a black box producing a probability distribution for the local motion vector between a pair of image patch the procedure is therefore quite general we are making the evaluation procedure available for public use 
this paper present a new constraint connecting the signal in multiple view of a surface the constraint arises from a harmonic analysis of the geometry of the imaging process and it give rise to a new technique for multiple view image reconstruction given several view of a surface from different position fundamentally different information is present in each image owing to the fact that camera measure the incoming light only after the application of a low pas filter our analysis show how the geometry of the imaging is connected to this filtering this lead to a techniquefor constructing a single outputimage containing all the information present in the input image 
convexity is an important geometric property of many natural and man made structure prior research ha shown that it is imperative to many perceptual organization and image understanding task this paper present a new grouping method for detecting convex structure from noisy image in a globally optimal fashion particularly this method combine both region and boundary information the detected structural boundary is closed and well aligned with detected edge while the enclosed region ha good intensity homogeneity we introduce a ratio form cost function for measuring the structural desirability which avoids a possible bias to detect small structure a new fragment pruning algorithm is developed to achieve the structural convexity the proposed method can also be extended to detect open boundary which correspond to the structure that are partially cropped by the image perimeter and incorporate a human computer interaction for detecting a convex boundary around a specified point we test the proposed method on a set of real image and compare it with the jacob convex grouping method 
we propose a framework for general multiple target tracking where the input is a set of candidate region in each frame a obtained from a state of the art background learning and the goal is to recover trajectory of target over time from noisy observation due to occlusion by target and static object noisy segmentation and false alarm one foreground region may not correspond to one target faithfully therefore the one to one assumption used in most data association algorithm is not always satisfied our method overcomes the one to one assumption by formulating the visual tracking problem in term of finding the best spatial and temporal association of observation which maximizes the consistency of both motion and appearance of trajectory to avoid enumerating all possible solution we take a data driven markov chain monte carlo dd mcmc approach to sample the solution space efficiently the sampling is driven by an informed proposal scheme controlled by a joint probability model combining motion and appearance to make sure the markov chain to converge to a desired distribution we propose an automatic approach to determine the parameter in the target distribution comparative experiment with quantitative evaluation are provided 
a novel approach is proposed that extends the classical background subtraction method to extract silhouette from video in real time with dynamic viewpoint variation caused by camera movement first manifold learning is used to model the background under viewpoint variation then for each new frame the background image corresponding to the same viewpoint is synthesized on the fly by examining the local neighborhood on the manifold and the silhouette is extracted via background subtraction an extension is also presented to generate stabilized silhouette at any fixed viewpoint within the training range experiment show that our approach can efficiently extract accurate silhouette in complex situation while maintaining a low noise level 
to compare spatial pattern of gene expression one must analyze a large number of image a current method are only able to measure a small number of gene at a time bringing image of corresponding tissue into alignment is a critical first step in making a meaningful comparative analysis of these spatial pattern significant image noise and variability in the shape make it hard to pick a canonical shape model in this paper we address these problem by combining segmentation and unsupervised shape learning algorithm we first segment image to acquire structure of interest then jointly align the shape of these acquired structure using an unsupervised nonparametric maximum likelihood algorithm along the line of congealing while simultaneously learning the underlying shape model and associated transformation the learned transformation are applied to corresponding image to bring them into alignment in one step we demonstrate the result for image of various class of drosophila imaginal disc and discus the methodology used for a quantitative analysis of spatial gene expression pattern 
capacity scaling is a hierarchical approach to graph representation that can improve theoretical complexity and practical efficiency of max flow min cut algorithm introduced by edmonds karp and dinic in capacity scaling is well known in the combinatorial optimization community surprisingly this major performance improving technique is overlooked in computer vision where graph cut method typically solve energy minimization problem on huge n d grid and algorithm efficiency is a widely studied issue unlike some earlier hierarchical method addressing efficiency of graph cut in imaging e g capacity scaling preserve global optimality of the solution this is the main motivation for our work studying capacity scaling in the context of vision we show that capacity scaling significantly reduces non polynomial theoretical time complexity of the max flow algorithm in to weakly polynomial o m n log u where u is the largest edge weight while is the fastest method for many application in vision capacity scaling give several fold speed ups for problem with large number of local minimum the effect is particularly strong in d application with denser neighborhood in computer vision max flow min cut algorithm are largely seen a powerful global energy optimization technique for n d grid in this case capacity scaling for graph cut algorithm can be interpreted a a method for approximating energy function at different accuracy level at the coarsest scale the energy function is only roughly approximated but it can be quickly optimized moreover the coarse scale solution can be efficiently reused by max flow min cut algorithm when moving to a better approximation of the energy at the next successive finer scale at the finest scale one get an exact global minimum of the original energy our goal is to demonstrate that computation of the global minimum for energy in computer vision can often be accelerated using the standard capacity scaling approach from combinatorial optimization interestingly our test on application in image analysis show that even the coarsest scale solution is often very similar if not identical to a global minimum of the original energy the remaining part of the introduction outline wellknown connection between energy minimization and standard max flow min cut algorithm section review the standard capacity scaling framework for max flow min cut algorithm in section we discus the implication of capacity scaling for optimization on n d grid in the context of image analysis in particular we demonstrate an improvement of theoretical time complexity and practical efficiency for a widely used in vision max flow algorithm for grid we show that capacity scaling allows to generate good approximate solution with a known quality bound at a fraction of the time required to converge to the global minimum we also demonstrate how capacity scaling significantly improves performance in complicated example with a large number of local minimum finally detailed experimental evaluation of the algorithm in with and without capacity scaling are presented in section in particular we show that capacity scaling ha the strongest effect on running time efficiency for grid of larger neighborhood and for grid of higher dimension e g in d 
we present an autocalibration algorithm for upgrading a projective reconstruction to a metric reconstruction by estimating the absolute dual quadric the algorithm enforces the rank degeneracy and the positive semidefiniteness of the dual quadric a part of the estimation procedure rather than a a post processing step furthermore the method allows the user if he or she so desire to enforce condition on the plane at infinity so that the reconstruction satisfies the chirality constraint the algorithm work by constructing low degree polynomial optimization problem which are solved to their global optimum using a series of convex linear matrix inequality relaxation the algorithm is fast stable robust and ha time complexity independent of the number of view we show extensive result on synthetic a well a real datasets to validate our algorithm 
we address the problem of temporal unusual event detection unusual event are characterized by a number of feature rarity unexpectedness and relevance that limit the application of traditional supervised model based approach we propose a semi supervised adapted hidden markov model hmm framework in which usual event model are first learned from a large amount of commonly available training data while unusual event model are learned by bayesian adaptation in an unsupervised manner the proposed framework ha an iterative structure which adapts a new unusual event model at each iteration we show that such a framework can address problem due to the scarcity of training data and the difficulty in pre defining unusual event experiment on audio visual and audio visual data stream illustrate it effectiveness compared with both supervised and unsupervised baseline method 
in this paper we propose a method for matching articulated shape represented a large set of d point by aligning the corresponding embedded cloud generated by locally linear embedding in particular we show that the problem is equivalent to aligning two set of point under anorthogonaltransformation acting onto thed dimensional embeddings the method may well be viewed a belonging to the model based clustering framework and is implemented a an em algorithm that alternate between the estimation of correspondence between data point and the estimation of an optimal alignment transformation correspondence are initialized by embedding one set of datapoints onto the other one through out of sample extension result for pair of voxelsets representing moving person are presented empirical evidence on the influence of the dimension of the embedding space is provided suggesting that working with higher dimensional space help matching in challenging real world scenario without collateral effect on the convergence 
in this paper we present a detailed analysis of multimodal fusion for person identification in a smart environment the multi modal system consists of a videobased face recognition system and a speaker identification system we investigated different score normalization modality weighting and modality combination scheme during the fusion of the individual modality we introduced two new modality weighting scheme namely the cumulative ratio of correct match crcm and distance to second closest dt nd measure in addition we also assessed the effect of the well known score normalization and classifier combination method on the identification performance experimental result obtained on the clear evaluation corpus which contains audio visual recording from different smart room show that crcm based modality weighting improves the correct identification rate significantly 
class syntax can be used to model temporal or locational evolvement of class label of feature observation sequence correct classification error of static classifier if feature observation from different class overlap in feature space and eliminate redundant feature whose discriminative information is already represented in the class syntax in this paper we describe a novel method that combine static classifier with class syntax model for supervised feature subset selection and classification in unified algorithm posterior class probability given feature observation are first estimated from the output of static classifier and then integrated into a parsing algorithm to find an optimal class label sequence for the given feature observation sequence finally both static classifier and class syntax model are used to search for an optimal subset of feature an optimal feature subset associated static classifier and class syntax model are all learned from training data we apply this method to logical entity recognition in scanned historical u s food and drug administration fda document containing court case notice of judgment nj of different layout style and show that the use of class syntax model not only corrects most classification error of static classifier but also significantly reduces the dimensionality of feature observation with negligible impact on classification performance 
we derive a probabilistic similarity measure between two observed image intensity that is based on the noise property of the camera in many vision algorithm the effect of camera noise is either neglected or reduced in a preprocessing stage however noise reduction cannot be performed with high accuracy due to lack of knowledge about the true intensity signal our similarity metric specifically represents the likelihood that two intensity observation correspond to the same unknown noise free scene radiance by directly accounting for noise in the evaluation of similarity the proposed measure make noise reduction unnecessary and enhances many vision algorithm that involve matching of image intensity real world experiment demonstrate the effectiveness of the proposed similarity measure in comparison to the standard l norm 
the active appearance model aam is a powerful method for modeling deformable visual object one of the majordrawbacksoftheaamis thatitrequiresa trainingset of pseudo dense correspondence over the whole database in this work we investigate the utility of stereo constraint for automatic model building from video first we propose a new method for automaticcorrespondencefinding in monocular image which is based on an adaptive template tracking paradigm we then extend this method to take the scene geometry into account proposing three approach each accounting for the availability of the fundamental matrix andcalibrationparametersor the lack thereof the performance of the monocular method wa first evaluated on a pre annotateddatabaseofatalkingface wethencompared themonocularmethodagainstitsthreestereo extensionsusing a stereo database 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
while great stride have been made in detecting and localizing specific object in natural image the bottom up segmentation of unknown generic object remains a difficult challenge we believe that occlusion can provide a strong cue for object segmentation and pop out but detecting an object s occlusion boundary using appearance alone is a difficult problem in itself if the camera or the scene is moving however that motion provides an additional powerful indicator of occlusion thus we use standard appearance cue e g brightness color gradient in addition to motion cue that capture subtle difference in the relative surface motion i e parallax on either side of an occlusion boundary we describe a learned local classifier and global inference approach which provide a framework for combining and reasoning about these appearance and motion cue to estimate which region boundary of an initial over segmentation correspond to object occlus ion boundary in the scene through result on a dataset which contains short video with labeled boundary we demonstrate the effectiveness of motion cue for this task 
we formulate multi view d shape reconstruction a the computation of a minimum cut on the dual graph of a semiregular multi resolution tetrahedral mesh our method doe not assume that the surface lie within a finite band around the visual hull or any other base surface instead it us photo consistency to guide the adaptive subdivision of a coarse mesh of the bounding volume this generates a multi resolution volumetric mesh that is densely tesselated in the part likely to contain the unknown surface the graph cut on the dual graph of this tetrahedral mesh produce a minimum cut corresponding to a triangulated surface that minimizes a global surface cost functional our method make no assumption about topology and can recoverdeepconcavitieswhenenoughcamerasobservethem our formulation also allows silhouette constraint to be enforced during the graph cut step to counter it inherent bias for producing minimal surface local shape refinement via surface deformation is used to recover detail in the reconstructed surface reconstruction of the multiview stereo evaluation benchmark datasets and other real datasets show the effectiveness of our method 
in this paper we investigate the effect of substantial inter image intensity change and change in modality on the performance of keypoint detection description and matching algorithm in the context of image registration in doing so we modify widely used keypoint descriptor such a sift and shape context attempting to capture the insight that some structural information is indeed preserved between image despite dramatic appearance change these extension include a pairing opposite direction gradient in the formation of orientation histogram and b focusing on edge structure only we also compare the stability of mser laplacian of gaussian and harris corner keypoint location detection and the impact of detection error on matching result our experiment on multimodal image pair and on image pair with significant intensity difference show that indexing based on our modified descriptor produce more correct match on difficult pair than current technique at the cost of a small decrease in performance on easier pair this extends the applicability of image registration algorithm such a the dual bootstrap which rely on correctly matching only a small number of keypoints 
in this paper we present a new method for segmenting closed contour and surface our work build on a variant of the fast marching algorithm first an initial point on the desired contour is chosen by the user next new keypoints are detected automatically using a front propagation approach we assume that the desired object ha a closed boundary this a priori knowledge on the topology is used to devise a relevant criterion for stopping the keypoint detection and front propagation the final domain visited by the front will yield a band surrounding the object of interest linking pair of neighboring keypoints with minimal path allows u to extract a closed contour from a d image detection of a variety of object on real image is demonstrated using a similar same idea we can extract network of minimal path from a d image called geodesic meshing the proposed method is applied to d data with promising result 
we compare the practical performance of several recently proposed algorithm for active learning in the online classification setting we consider two active learning algorithm and their combined variant that are strongly online in that they access the data sequentially and do not store any previously labeled example and for which formal guarantee have recently been proven under various assumption we motivate an optical character recognition ocr applicationthat we argue to be appropriatelyserved by online active learning we compare the practical efficacy for this application of the algorithm variant and show significant reduction in label complexity over random sampling 
in this paper we present a hybrid probabilistic framework for d image segmentation using conditional random field crfs and implicit deformable model our d deformable model us voxel intensity and higher scale texture a data driven term while the shape is formulated implicitly using the euclidean distance transform the data driven term are used a observation in a d discriminative crf which drive the model evolution based on a simple graphical model in this way we solve the model evolution a a joint map estimation problem for the d label field of the crf and the d shape of the deformable model we demonstrate the performance of our approach in the estimation of the volume of the human tear meniscus from image obtained with optical coherence tomography 
diffusion process driven by anisotropic diffusion tensor are known to be well suited for structure preserving denoising however numerical implementation based on finite difference introduce unwanted blurring artifact that deteriorate these favourable filtering property in this paper we introduce a novel discretisation of a fairly general class of anisotropic diffusion process on a d grid it lead to a locally semi analytic scheme lsas that is absolutely stable simple to implement and offer an outstanding sharpness of filtered image by showing that this scheme can be translated into a d haar wavelet shrinkage procedure we establish a connection between tensor driven diffusion and anisotropic wavelet shrinkage for the first time this result lead to coupled shrinkage rule that allow to perform highly anisotropic filtering even with the simplest wavelet 
we introduce the use of over complete spherical wavelet for shape analysis of d closed surface bi orthogonal spherical wavelet have been shown to be powerful tool in the segmentation and shape analysis of d closed surface but unfortunately they suffer from aliasing problem and are therefore not invariant under rotation of the underlying surface parameterization in this paper we demonstrate the theoretical advantage of over complete wavelet over bi orthogonal wavelet and illustrate their utility on both synthetic and real data in particular we show that over complete spherical wavelet allow u to build more stable cortical folding development model and detect a wider array of region of folding development in a newborn dataset 
one of the fundamental challenge of recognizing action is accounting for the variability that arises when arbitrary camera capture human performing action in this paper we explicitly identify three important source of variability viewpoint execution rate and anthropometry of actor and propose a model of human action that allows u to investigate all three our hypothesis is that the variability associated with the execution of an action can be closely approximated by a linear combination of action base in joint spatio temporal space we demonstrate that such a model bound the rank of a matrix of image measurement and that this bound can be used to achieve recognition of action based only on imaged data a test employing principal angle between subspace that is robust to statistical fluctuation in measurement data is presented to find the membership of an instance of an action the algorithm is applied to recognize several action and promising result have been obtained 
a new framework is presented that us tool from duality theory of linear programming to derive graph cut based combinatorial algorithm for approximating np hard classification problem the derived algorithm include expansion graph cut technique merely a a special case have guaranteed optimality property even in case where expansion technique fail to do so and can provide very tight per instance suboptimality bound in all occasion 
the aim of this paper is to achieve seamless image stitching for eliminating obvious visual artifact caused by severe intensity discrepancy image distortion and structure misalignment given that the input image are globally registered our approach is based on structure deformation and propagation while maintaining the overall appearance affinity of the result to the input image this new approach is proven to be effective in solving the above problem and ha found application in mosaic deghosting image blending and intensity correction our new method consists of the following main process first salient feature or structure are robustly detected and aligned along the optimal partitioning boundary between the input image from these feature we derive sparse deformation vector to to uniformly encode the underlying structure and intensity misalignment these sparse deformation cue will then be propagated robustly and smoothly into the interior of the target image by solving the associated laplace equation in the image gradient domain we present convincing result to show that our method can handle significant structure and intensity misalignment in image stitching 
abstract we propose a new approach to compute non linear intrinsic shape statistic and to incorporate them into a shape prior for an image segmentation task given a sample set of contour we rst dene their mean shape a the one that realizes the inmum of the sum of the square of it distance to each of the sample we consider here the hausdorff distance between shape or more exactly a differentiable approximation of it the mean shape is then computed with a gradient descent framework we perform statistic on the instantaneous deformation eld that the mean shape should undergo to move towards each sample the application of principal component analysis pca to the deformation eld lead to sensible 
in this paper we apply state of the art approach to object detection and localisation by incorporating local descriptor and their spatial configuration into a generative probability model in contrast to the recent semisupervised method we do not utilise interest point detector but apply a supervised approach where local image feature landmark are annotated in a training set and therefore their appearance and spatial variation can be learnt our method enables working in purely probabilistic search space providing a map estimate of object location and in contrast to the recent method no background class need to be formed using the training set we can estimate pdfs for both spatial constellation and local feature appea rance by applying an inference bias that the largest pdf mode ha probability one we are able to combine prior information spatial configuration of the feature and obser vations image feature appearance into posterior distrib ution which can be generatively sampled e g using mcmc technique the mcmc method are sensitive to initialisation but a a solution we also propose a very efficient and accurate ransac based method for finding good initial hypothesis of object pose the complete method can robustly and accurately detect and localise object under any homography 
utilization of an acoustic camera for range measurement is a key advantage for d shape recovery of underwater target by opti acoustic stereo imaging where the associated epipolar geometry of optical and acoustic image correspondence can be described in term of conic section in this paper we propose method for system calibration and d scene reconstruction by maximum likelihood estimation from noisy image measurement the recursive d reconstruction method utilized a initial condition a closed form solution that integrates the advantage of so called range and azimuth solution synthetic data test are given to provide insight into the merit of the new target imaging and d reconstruction paradigm while experiment with real data confirm the finding based on computer simulation and demonstrate the merit of this novel d reconstruction paradigm 
many vision task are posed a either graph partitioning coloring or graph matching correspondence problem the former include segmentation and grouping and the latter include wide baseline stereo large motion object tracking and recognition in this paper we present an integrated solution for both graph matching and graph partition using an effective sampling algorithm in a bayesian framework given two image for matching we extract two graph using a primal sketch algorithm the graph node are linelets and primitive junction both graph are automatically partitioned into an unknown number of k layer of subgraphs so that k pair of subgraphs are matched and the remaining layer contains unmatched background each matched pair represent a moving object with a tps thin plate spline transform to account for it deformation and a set of graph operator to edit the pair of subgraphs to achieve perfect structural match the matching energy between two subgraphs includes geometric deformation appearance dissimilarity and the cost of graph editing operator we demonstrate it application on two task i large motion with occlusion and ii automatic detection and recognition of common object in a pair of image 
this paper describes a local ensemble kernel learning technique to recognize classify object from a large number of diverse category due to the possibly large intraclass feature variation using only a single unified kernel based classifier may not satisfactorily solve the problem our approach is to carry out the recognition task with adaptive ensemble kernel machine each of which is derived from proper localization and regularization specifically for each training sample we learn a distinct ensemble kernel constructed in a way to give good classification performance for data falling within the corresponding neighborhood we achieve this effect by aligning each ensemble kernel with a locally adapted target kernel followed by smoothing out the discrepancy among kernel of nearby data our experimental result on various image database manifest that the technique to optimize local ensemble kernel is effective and consistent for object recognition 
generative model learning is one of the key problem in machine learning and computer vision currently the use of generative model is limited due to the difficulty in effectively learning them a new learning framework is proposed in this paper which progressively learns a target generative distribution through discriminative approach this framework provides many interesting aspect to the literature from the generative model side a reference distribution is used to assist the learning process which remove the need for a sampling process in the early stage the classification power of discriminative approach e g boosting is directly utilized the ability to select explore feature from a large candidate pool allows u to make nearly no assumption about the training data from the discriminative model side this framework improves the modeling capability of discriminative model it can start with source training data only and gradually invent negative sample we show how sampling scheme can be introduced to discriminative model the learning procedure help to tighten the decision boundary for classification and therefore improves robustness in this paper we show a variety of application including texture modeling and classification non photorealistic rendering learning image statistic denoising and face modeling the framework handle both homogeneous pattern e g texture and inhomogeneous pattern e g face with nearly an identical parameter setting for all the task in the learning stage 
this paper present a new framework for solving geometric structure and motion problem based on l norm instead of using the common sum of square cost function that is thel norm the model fitting error are measured using the l norm unlike traditional method based on l our framework allows for efficient computation of global estimate we show that a variety of structure and motion problem for example triangulation camera resectioning and homography estimation can be recast a a quasi convex optimization problem within this framework these problem can be efficiently solved using second order cone programming socp which is a standard technique in convex optimization the proposed solution have been validated on real data in different setting with small and large dimension and with excellent performance 
we present a novel approach for multi object tracking which considers object detection and spacetime trajectory estimation a a coupled optimization problem it is formulated in a hypothesis selection framework and build upon a state of the art pedestrian detector at each time instant it search for the globally optimal set of spacetime trajectory which provides the best explanation for the current image andfor all evidencecollected so far while satisfying the constraint that no two object may occupy the same physical space nor explain the same image pixel at any point in time successful trajectory hypothesis are fed back to guide object detection in future frame the optimization procedure is kept efficient through incremental computation and conservative hypothesis pruning the resulting approach can initialize automatically and track a large and varying number of person over long period and through complex scene with clutter occlusion and large scale background change also the global optimization framework allows our system to recover from mismatch and temporarily lost track we demonstrate the feasibility of the proposed approach on several challenging video sequence 
image patch are fundamental element for object modeling and recognition however there ha not been a panoramic study of the structure of the whole ensemble of natural image patch in the literature in this article we study the structure of this ensemble by mapping natural image patch into two type of subspace which we call explicit manifold and implicit manifold respec tively on explicit manifold one find those simple and regular image primitive such a edge bar corner and junction on implicit manifold one find those complex and stochastic image patch such a texture and clutter on different type of manifold different perceptual metr ic are used we propose a method for learning a probabilistic distribution on the space of patch by pursuing both type of manifold using a common information theoretical criterion the connection between the two type of manifold is realized by image scaling which change the entropy of the image patch the explicit manifold live in low entropy regime while the implicit manifold live in high entropy regime we study the transition between the two type of manifold over scale and show that the complexity of the manifold peak in a middle entropy regime 
optimization with graph cut became very popular in recent year progress in problem such a stereo correspondence image segmentation etc can be attributed in part to the development of efficient graph cut based optimization recent evaluation of optimization technique show that the popular expansion and swap graph cut algorithm perform extremely well for energy where the underlying mrf ha the potts prior which corresponds to the assumption that the true labeling is piecewise constant for more general prior however such a corresponding to piecewise smoothness assumption both swap and expansion algorithm do not perform a well we develop several optimization algorithm for truncated convex prior which imply piecewise smoothness assumption both expansion and swap algorithm are based on move that give each pixel a choice of only two label our insight is that to obtain a good approximation under piecewise smoothness assumption a pixel should have a choice among more than two label we develop new range move which act on a larger set of label than the expansion and swap algorithm we evaluate our method on problem of image restoration inpainting and stereo correspondence our result show that we are able to get more accurate answer both in term of the energy which is the direct goal and in term of accuracy which is an indirect but more important goal 
we are interested in modeling the variability of different image of the same scene or class of object obtained by changing the imaging condition for instance the viewpoint or the illumination understanding of such a variability is key to reconstruction of object despite change in their appearance e g due to non lambertian reection or to recognizing class of object e g car or individual object seen from different vantage point we propose a model that can account for change in shape or viewpoint appearance and also occlusion of line of sight we learn a prior model of each factor shape motion and appearance from a collection of sample using principal component analysis akin a generalization of active appearance model to dense domain affected by occlusion the ultimate goal of this work is stereo reconstruction in d but r st we have developed the r st stage in this approach by addressing the simpler case of d shape radiance detection in single image we illustrate our model on a collection of image of different car and show how the learned prior can be used to improve segmentation and d stereo reconstruction 
in a low resolution range sensor wa investigated for an occupant classification system that distinguish person from child seat or an empty seat the optimal deployment of vehicle airbags for maximum protection moreover requires information about the occupant s size and positio n the detection of occupant s position involves the detectio n and localization of occupant s head this is a challenging problem a the approach based on local shape analysis in d or d alone are not robust enough a other part of the person s body like shoulder knee may have similar shape a the head this paper discus and investigate the potential of a reeb graph approach to describe the topology of vehicle occupant in term of a skeleton the essence of the proposed approach is that an occupant sitting in a vehicle ha a typical topology which lead to different branch of a reeb graph and the possible location of the occupant s head are thus the end point of the reeb graph the proposed method is applied on real d range image and is compared to ground truth information result show the feasibility of using topological information to identify t he position of occupant s head 
belief propagation bp ha been successfully used to approximate the solution of various markov random field mrf formulated energy minimization problem however large mrfs require a significant amount of memory to store the intermediate belief message we observe that these message have redundant information due to the imposed smoothness prior in this paper we study the feasibility of applying compression technique to the message in the min sum max product bp algorithm with d label to improve the memory efficiency and reduce the read write bandwidth we articulate property that an efficient message representation should satisfy we investigate two common compression scheme predictive coding and linear transform coding pca and then propose a novel envelope point transform ept method predictive coding is efficient and support linear operation directly in the compressed domain but it is only compatible with the l smoothness function pca ha the disadvantage that it doe not guarantee the preservation of the minimal label ept is not limited to l smoothness cost and allows a flexible quality v compression ratio tradeoff compared with predictive coding experiment on dense stereo reconstruction have shown that the predictive scheme and ept can achieve time or more compression without significant loss of depth accuracy 
non negative tensor factorization ntf ha recently been proposed a sparse and efficient image representation welling and weber patt rec let until now sparsity of the tensor factorization ha been empirically observed in many case but there wa no systematic way to control it in this work we show that a sparsity measure recently proposed for non negative matrix factorization hoyer j mach learn re applies to ntf and allows precise control over sparseness of the resulting factorization we devise an algorithm based on sequential conic programming and show improved performance over classical ntf code on artificial and on real world data set 
occlusion is a significant challenge for many tracking algorithm most current method can track through transient occlusion but cannot handle significant extended occlusion when the object s trajectory may change significantly we present a method to track a d object through significant occlusion using multiple nearby camera e g a camera array when an occluder and object are atdifferent depth different part of the object are visible or occluded in each view due to parallax by aggregating across these view the method can track even when any individual camera observes very little of the target object implementationwise the method are straightforward and build upon established single camera algorithm they do not require explicit modeling or reconstruction of the scene and enable tracking in complex dynamic scene with moving camera analysis of accuracy and robustness show that these method are successful when upwards of of the object is occluded in every camera view to the best of our knowledge this system is the first capable of tracking in the presence of such significant occlusion 
discriminant analysis da method have demonstrated their utility in countless application in computer vision and other area of research especially in the c class classification problem the most popular approach is linear da lda which provides the c dimensional bayes optimal solution but only when all the class covariance matrix are identical this is rarely the case in practice to alleviate this restriction kernel lda klda ha been proposed in this approach we first intrinsically map the original nonlinear problem to a linear one and then use lda to find the c dimensional bayes optimal subspace however the use of klda is hampered by it computational cost given by the number of training sample available and by the limitedness of lda in providing a c dimensional solution space in this paper we first extend the definition of lda to provide subspace of q c dimension where the bayes error is minimized then to reduce the computational burden of the derived solution we define a sparse kernel representation which is able to automatically select the most appropriate sample feature vector that represent the kernel we demonstrate the superiority of the proposed approach on several standard datasets comparison are drawn with a large number of known da algorithm 
histogram pyramid representation computed from a vocabulary tree of visual word have proven valuable for a range of image indexing and recognition task however they have only used a single fixed partition of feature space we present a new efficient algorithm to incrementally compute set of tree forest vocabulary representation and show they improve recognition and indexing performance in method which use histogram pyramid our algorithm incrementally adapts a vocabulary forest with an inverted filesystem at the leaf node and automatically keep existing histogram pyramid database entry up to date in a forward filesystem it is possible not only to apply vocabulary tree indexing algorithm directly but also to compute pyramid match kernel value efficiently on dynamic recognition task where category or object under consideration may change over time we show that adaptive vocabulary offer significant performance advantage when compared to a single fixed vocabulary 
kernel machine e g svm klda have shown state ofthe art performance in several visual classification task the classification performance of kernel machine greatly depends on the choice of kernel and it parameter in this paper we propose a method to search over a space of parameterized kernel using a gradient descent based method our method effectively learns a non linear representation of the data useful for classification and simultaneously performs dimensionality reduction in addition we suggest a new matrix formulation that simplifies and unifies previous approach the effectiveness and robustness of the proposed algorithm is demonstrated in both synthetic and real example of pedestrian and mouth detection in image 
in this paper we present a new single image camera response function crf estimation method using geometry invariant gi we derive mathematical property and geometric interpretation for gi which lend insight to addressing various algorithm implementation issue in a principled way in contrast to the previous single image crf estimation method our method provides a constraint equation for selecting the potential target data point comparing to the prior work our experiment is conducted over more extensive data and our method is flexible in that it estimation accuracy and stability can be improved whenever more than one image is available the geometry invariance theory is novel and may be of wide interest 
this paper address the problem of deducing the surface shape of an object given just the surface normal many shape measurement algorithm such a shape from shading and shape from texture only return the surface normal of an object often with an ambiguity of in the surface tilt the surface shape ha to be inferred from these normal typically via some integration process however reconstruction through the integration of surface gradient is sensitive to noise and the choice of integration path across the surface in addition existing technique cannot accommodate ambiguity in tilt this paper present a new approach to the reconstruction of surface from surface normal using basis function referred to here a shapelets the surface gradient of the shapelets are correlated with the gradient of the surface and the correlation summed to form the reconstruction this result in a simple reconstruction process that is very robust to noise where there is an ambiguity of in the surface tilt reconstruction of reduced quality are still possible up to a positive negative shape ambiguity intriguingly some form of reconstruction is also possible using just slant information 
a novel algorithm called average neighborhood margin maximization anmm is proposed for supervised linear feature extraction for each data point anmm aim at pulling the neighboring point with the same class label towards it a near a possible while simultaneously pushing the neighboring point with different label away from it a far a possible we will show that feature extracted from anmm can separate the data from different class well and it avoids the small sample size problem existed in traditional linear discriminant analysis lda the kernelized nonlinear counterpart of anmm is also established in this paper moreover a in many computer vision application the data are more naturally represented by higher order tensor e g image and video we develop a tensorized multilinear form of anmm which can directly extract feature from tensor the experimental result of applying anmm to face recognition are presented to show the effectiveness of our method 
we propose a hierarchical generative model for coding the geometry and appearance of visual object category the model is a collection of loosely connected part containing more rigid assembly of subpart it is optimized for domain where there are relatively large number of somewhat informative subpart such a the feature returned by local feature method from computer vision the model is learned quickly by an e m procedure some experiment on real image show the it ability to t complex natural object class 
we introduce parametric switching linear dynamic system p slds for learning and interpretation of parametrized motion i e motion that exhibit systematic temporal and spatial variation our motivating example is the honeybee dance bee communicate the orientation and distance to food source through the dance angle and waggle length of their stylized dance switching linear dynamic system slds are a compelling way to model such complex motion however slds doe not provide a mean to quantify systematic variation in the motion previously wilson bobick presented parametric hmms an extension to hmms with which they successfully interpreted human gesture inspired by their work we similarly extend the standard slds model to obtain parametric slds we introduce additional global parameter that represent systematic variation in the motion and present general expectation maximization em method for learning and inference in the learning phase p slds learns canonical slds model from data in the inference phase p slds simultaneously quantifies the global parameter and label the data we apply these method to the automatic interpretation of honey bee dance and present both qualitative and quantitative experimental result on actual bee track collected from noisy video data 
the ability to associate object across multiple view allows co operativeuse of an ensemble camera for scene understanding in this paper we present a principled solution to object association where both the scene and the object motion are modeled by making the motion model of each object with respect to time explicit we are able to solve the trajectory association problem in a unified framework for overlapping or non overlapping camera we recover the assignment of association while simultaneously computing the maximum likelihood estimate of the inter camera homographies and the trajectory parameter using the expectation maximization algorithm quantitative result on simulation are reported along with several result on real data 
we propose an efficient image registration strategy that is based on learned prior distribution of transformation parameter these prior are used to constrain a finitetime multi start optimization method motivation for this approach come from the fact that standard affine brain image registration method especially those based on gradient descent optimization alone are affected by the initial search position while global optimization method can resolve this problem they are are often very time consuming our goal is to build an explicit prior model of the gap between a typical registration solution and the solution gained by a global optimization method we use this learned prior model to restrict randomized search in the relevant parameter space surrounding the initial solution global optimization in this restricted parameter space provides in finite time result that are superior to both gradient descent and the general multi start strategy the performance of our method is illustrated on a data set of elderly and neurodegenerative brain our novel learning strategy and the associated registration method are shown to outperform other approach theoretical synthetic and real world example illustrate this improvement 
in this paper a novel object class detection method based on d object modeling is presented instead of using a complicated mechanism for relating multiple d training view the proposed method establishes spatial connection between these view by mapping them directly to the surface of d model the d shape of an object is reconstructed by using a homographic framework from a set of model view around the object and is represented by a volume consisting of binary slice feature are computed in each d model view and mapped to the d shape model using the same homographic framework to generalize the model for object class detection feature from supplemental view are also considered a codebook is constructed from all of these feature and then a d feature model is built given a d test image correspondence between the d feature model and the testing view are identified by matching the detected feature based on the d location of the corresponding feature several hypothesis of viewing plane can be made the one with the highest confidence is then used to detect the object using feature location matching performance of the proposed method ha been evaluated by using the pascal voc challenge dataset and promising result are demonstrated 
the standard pca wa always used a baseline algorithm to evaluate ica based face recognition system in the previous research in this paper we examine the two architecture of ica for image representation and find that ica architecture i involves a pca process by vertically centering pca i while ica architecture ii involves a whitened pca process by horizontally centering pca ii so it is reasonable to use these two pca version a baseline algorithm to revaluate the ica based face recognition system the experiment were performed on the feret face database the experimental result show there is no significant performance difference between ica architecture i ii and pca i ii although ica architecture ii significantly outperforms the standard pca it can be concluded that the performance of ica strongly depends on it involved pca process the pure ica projection ha little effect on the performance of face recognition 
a good distance metric is crucial for unsupervised learning from high dimensional data to learn a metric without any constraint or class label information most unsupervised metric learning algorithm appeal to projecting observed data onto a low dimensional manifold where geometric relationship such a local or global pairwise distance are preserved however the projection may not necessarily improve the separability of the data which is the desirable outcome of clustering in this paper we propose a novel unsupervised adaptive metric learning algorithm called aml which performs clustering and distance metric learning simultaneously aml project the data onto a low dimensional manifold where the separability of the data is maximized we show that the joint clustering and distance metric learning can be formulated a a trace maximization problem which can be solved via an iterative procedure in the em framework experimental result on a collection of benchmark data set demonstrated the effectiveness of the proposed algorithm 
in this paper we propose a method for jointly computing optical flow and segmentating video while accounting for mixed pixel matting our method is based on statistical modeling of an image pair using constraint on appearance and motion segment are viewed a overlapping region with fractional contribution bidirectional motion is estimated based on spatial coherence and similarity of segment color our model is extended to video by chaining the pairwise model to produce a joint probability distribution to be maximized to make the problem more tractable we factorize the posterior distribution and iteratively minimize it part we demonstrate our method on frame interpolation 
we consider the problem of estimating detailed d structure from a single still image of an unstructured environment our goal is to create d model which are both quantitatively accurate a well a visually pleasing for each small homogeneous patch in the image we use a markov random field mrf to infer a set of plane parameter that capture both the d location and d orientation of the patch the mrf trained via supervised learning model both image depth cue a well a the relationship between different part of the image inference in our model is tractable and requires only solving a convex optimization problem other than assuming that the environment is made up of a number of small plane our model make no explicit assumption about the structure of the scene this enables the algorithm to capture much more detailed d structure than doe prior art such a saxena et al delage et al and hoiem et el and also give a much richer experience in the d flythroughs created using image based rendering even for scene with significant non vertical structure using this approach we have created qualitatively correct d model for of image downloaded from the internet a compared to hoiem et al s performance of further our model are quantitatively more accurate than either saxena et al or hoiem et al 
face image of non frontal view under poor illumination resolution reduce dramatically face recognition accuracy this is evident most compellingly by the very low recognition rate of all existing face recognition system when applied to live cctv camera input in this paper we present a bayesian framework to perform multimodal such a variation in viewpoint and illumination face image super resolution for recognition in tensor space given a single modal low resolution face image we benefit from the multiple factor interaction of training sensor and super resolve it high resolution reconstruction across different modality for face recognition instead of performing pixel domain super resolution and recognition independently a two separate sequential process we integrate the task of super resolution and recognition by directly computing a maximum likelihood identity parameter vector in high resolution tensor space for recognition we show result from multi modal super resolution and face recognition experiment across different imaging modality using low resolution image a testing input and demonstrate improved recognition rate over standard tensorface and eigenface representation 
local part based human detector are capable of handling partial occlusion efficiently and modeling shape articulation flexibly while global shape template based human detector are capable of detecting and segmenting human shape simultaneously we describe a bayesian approach to human detection and segmentation combining local part based and global template based scheme the approach relies on the key idea of matching a part template tree to image hierarchically to generate a reliable set of detection hypothesis and optimizing it under a bayesian map framework through global likelihood re evaluation and fine occlusion analysis in addition to detection our approach is able to obtain human shape and pose simultaneously we applied the approach to human detection and segmentation in crowded scene with and without background subtraction experimental result show that our approach achieves good performance on image and video sequence with severe occlusion 
surface gradient are useful to surface reconstruction in single view modeling shape from shading and photometric stereo previous algorithm minimize a complex nonlinear energy functional or require dense surface gradient to perform integration to generate d location or require user input height to constrain the solution space or produce severe distortion and smooth out surface detail most single view algorithm output a monge patch height field which may introduce further surface distortion along object silhouette and surface orientation discontinuity our proposed algorithm operates on a single view of complete or incomplete data the data can be gradient without d location or d location without gradient the output surface which is not necessarily a height field preserve salient depth and orientation discontinuity experimental comparison on both simple and complex data show that our method produce better surface with significantly le distortion and more detail preserved the implementation of our closed form solution is very straightforward 
in normal imaging system the depth of field is inversely proportional to the lens aperture if we assume the system is diffraction limited then the maximum resolution i e pixel per mm is proportional to the lens aperture thus there is a tradeoff between depth of field and resolution this tradeoff creates an upper limit on the number of pixel that can be resolved on a non planar subject this paper present the theoretical limit on the number of pixel the derivation of the limit show that the limit is only a function of the subject size and depth the subject distance focal length and sensor size do not matter for small subject the limit is well below the capability of modern imaging system for example a subject cm wide and cm deep can only be imaged with pixel even though sensor with time that many pixel are readily available the resulting limit ha obvious application in machine vision particularly when specifying optic and imaging sensor experimental result are provided to validate the main result of the paper 
within the eld of pattern classication the fisher kernel is a powerful framework which combine the strength of generative and discriminative approach the idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classier we propose to apply this framework to image categorization where the input signal are image and where the underlying generative model is a visual vocabulary a gaussian mixture model which approximates the distribution of low level feature in image we show that fisher kernel can actually be understood a an extension of the popular bag of visterms our approach demonstrates excellent performance on two challenging database an in house database of object scene category and the recently released voc database it is also very practical it ha low computational need both at training and test time and vocabulary trained on one set of category can be applied to another set without any signicant loss in performance 
for many multi part object class the set of part can vary not only in location but also in type for example player formation in american football involve various subset of player type and the spatial constraint among player depend largely upon which subset of player type constitutes the formation in this work we study the problem of localizing and classifying the part of such object pictorial structure provide an efficient and robust mechanism for localizing object part unfortunately these model assume that each object instance involves the same set of part making it difficult to apply them directly in our setting with this motivation we introduce the mixture of part pictorial structure mopps model which is characterized by three component a set of available part a set of constraint that specify legal part subset and a function that return a pictorial structure for any legal part subset mopps inference corresponds to jointly computing the most likely subset of part and their position we propose a restricted but useful representation for mopps model that facilitates inference via branch and bound optimization which we show is efficient in practice experiment in the challenging domain of american football show the effectiveness of the model and inference procedure 
we present an unsupervised approach for learning a generative layered representation of a scene from a video for motion segmentation the learnt model is a composition of layer which consist of one or more segment included in the model are the effect of image projection lighting and motion blur the two main contribution of our method are i a novel algorithm for obtaining the initial estimate of the model using efficient loopy belief propagation ii using swap and expansion algorithm which guarantee a strong local minimum for refining the initial estimate result are presented on several class of object with different type of camera motion we compare our method with the state of the art and demonstrate significant improvement 
tree structured model have been widely used for determining the pose of a human body from either d or d data while such model can effectively represent the kinematic constraint of the skeletal structure they do not capture additional constraint such a coordination of the limb tree structured model thus miss an important source of information about human body pose a limb coordination is necessary for balance while standing walking or running a well a being evident in other activity such a dancing and throwing in this paper we consider the use of undirected graphical model that augment a tree structure with latent variable in order to account for coordination between limb we refer to these a common factor model since they are constructed by using factor analysis to identify additional correlation in limb position that are not accounted for by the kinematic tree structure these common factor model have an underlying tree structure and thus a variant of the standard viterbi algorithm for a tree can be applied for efficient estimation we present some experimental result contrasting common factor model with tree model and quantify the improvement in pose estimation for d image data 
in this paper we present a new learning framework for image style transforms considering that the image in different style representation constitute different vector space we propose a novel framework called coupled space learning to learn the relation between different space and use them to infer the image from one style to another style observing that for each style only the component correlated to the space of the target style are useful for inference we first develop the correlative component analysis to pursue the embedded hidden subspace that best preserve the inter space correlation information then we develop the coupled bidirectional transform algorithm to estimate the transforms between the two embedded space where the coupling between the forward transform and the backward transform is explicitly taken into account to enhance the capability of modelling complex data we further develop the coupled gaussian mixture model to generalize our framework to a mixture model architecture the effectiveness of the framework is demonstrated in the application including face super resolution and bidirectional portrait style transforms 
a novel framework is developed for automatic behaviour profiling and abnormality sampling detection without any manual labelling of the training dataset natural grouping of behaviour pattern is discovered through unsupervised model selection and feature selection on the eigenvectors of a normalised affinity matrix our experiment demonstrate that a behaviour model trained using an unlabelled dataset is superior to those trained using the same but labelled dataset in detecting abnormality from an unseen video 
we explore the problem of classifying image by the object category they contain in the case of a large number of object category to this end we combine three ingredient i shape and appearance representation that support spatial pyramid matching over a region of interest this generalizes the representation of lazebnik et al from an image to a region of interest roi and from appearance visual word alone to appearance and local shape edge distribution ii automatic selection of the region of interest in training this provides a method of inhibiting background clutter and adding invariance to the object instance s position and iii the use of random forest and random fern a a multi way classifier the advantage of such classifier over multi way svm for example is the ease of training and testing result are reported for classification of the caltech and caltech data set we compare the performance of the random forest fern classifier with a benchmark multiway svm classifier it is shown that selecting the roi add about to the performance and together with the other improvement the result is about a improvement over the state of the art for caltech 
many recognition algorithm depend on careful positioning of an object into a canonical pose so the position of feature relative to a xed coordinate system can be examined currently this positioning is done either manually or by training a class specialized learning algorithm with sample of the class that have been hand labeled with part or pose in this paper we describe a novel method to achieve this positioning using poorly aligned example of a class with no additional labeling given a set of unaligned examplars of a class such a face we automatically build an alignment mechanism without any additional labeling of part or pose in the data set using this alignment mechanism new member of the class such a face resulting from a face detector can be precisely aligned for the recognition process our alignment method improves performance on a face recognition task both over unaligned image and over image aligned with a face alignment algorithm specically developed for and trained on hand labeled face image we also demonstrate it use on an entirely different class of object car again without providing any information about part or pose to the learning algorithm 
a method for defecting and segmenting periodic motion is presented we exploit periodicity a a cite and detect periodic motion in complex scene where common method for rnotion segmentation are likely to fail we note that periodic motion detection can be seen a an approximate case of sequence alignment where an image sequence is matched to itself over one or more period of time to use this observation we first consider alignment of two video sequence obtained by independently moving camera under assumption of constant translation the fundamental matrix and the homographies are shown to be time linear matrix function these dynamic quantity can be estimated by matching corresponding space time point with similar local motion and shape for periodic motion we match corresponding point across period and develop a ransac procedure to simultaneously estimate the period and the dynamic geometric transformation between periodic view using this method we demonstrate detection and segmentation of human periodic motion in complex scene with non rigid background moving camera and motion parallax 
we present a new axis based shape representation scheme along with a matching framework to address the problem of generic shape recognition the main idea is to define the relative spatial arrangement of local symmetry ax and their metric property in a shape centered coordinate frame the resulting description are invariant to scale rotation small change in viewpoint and articulation symmetry point are extracted from a surface whose level curve roughly mimic the motion by curvature by increasing the amount of smoothing on the evolving curve only those symmetry ax that correspond to the most prominent part of a shape are extracted the representation doe not suffer from the common instability problem of the traditional connected skeleton it capture the perceptual quality of shape well therefore finding the similarity and the difference among shape becomes easier the matching process give highly successful result on a diverse database of d shape 
clustering video sequence in order to infer and extract activity from a single video stream is an extremely important problem and ha significant potential in video indexing surveillance activity discovery and event recognition clustering a video sequence into activity requires one to simultaneously recognize activity boundary activity consistent subsequence and cluster these activity subsequence in order to do this we build a generative model for activity in video using a cascade of dynamical system and show that this model is able to capture and represent a diverse class of activity we then derive algorithm to learn the model parameter from a video stream and also show how a single video sequence may be clustered into different cluster where each cluster represents an activity we also propose a novel technique to build affine view rate invariance of the activity into the distance metric for clustering experiment show that the cluster found by the algorithm correspond to semantically meaningful activity 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
this paper address one of the fundamental problem encountered in performance prediction for object recognition in particular we address the problem related to estimation of small gallery size that can give good error estimate and their confidence on large probe set and population we use a generalized two dimensional prediction model that integrates a hypergeometric probability distribution model with a binomial model explicitly and considers the distortion problem in large population we incorporate learning in the prediction process in order to find the optimal small gallery size and to improve it performance the chernoff and chebychev inequality are used a a guide to obtain the small gallery size during the prediction we use the expectation maximum em algorithm to learn the match score and the non match score distribution the number of component their weight mean and covariance that are represented a gaussian mixture by learning we find the optimal size of small gallery and at the same time provide the upper bound and the lower bound for the prediction on large population result are shown using real world database 
we present an evaluation methodology and data for large scale video based d reconstruction we evaluate the effect of several parameter and draw conclusion that can be useful for practical system operating in uncontrolled environment unlike the benchmark datasets used for the binocular stereo and multi view reconstruction evaluation which were collected under well controlled condition our datasets are captured outdoors using video camera mounted on a moving vehicle a a result the video are much more realistic and include phenomenon such a exposure change from viewing both bright and dim surface object at varying distance from the camera and object of varying size and degree of texture the dataset includes ground truth model and precise camera pose information we also present an evaluation methodology applicable to reconstruction of large scale environment we evaluate the accuracy and completeness of reconstruction obtained by two fast visibility based depth map fusion algorithm a parameter vary 
the ability of human visual system to detect visual saliency is extraordinarily fast and reliable however computational modeling of this basic intelligent behavior still remains a challenge this paper present a simple method for the visual saliency detection our model is independent of feature category or other form of prior knowledge of the object by analyzing the log spectrum of an input image we extract the spectral residual of an image in spectral domain and propose a fast method to construct the corresponding saliency map in spatial domain we test this model on both natural picture and artificial image such a psychological pattern the result indicate fast and robust saliency detection of our method 
we present digitable an experimental platform we hope lessen the gap between co present and distant interaction digitable is combining a multiuser tactile interactive tabletop a video communication system enabling eye contact with real size distant user visualization and a spatialized sound system for speech transmission based on a robust computer vision module it provides a fluid gesture visualization of each distant participant whether he she is moving virtual digital object or is intending to do so remote gesture visualization contributes to the efficiency of distant collaboration task because it enables the coordination among participant s action and talk our main contribution address the development and the integration of robust and real time projector camera processing technique in computer supported cooperative work 
this paper present a novel framework to localize in a photograph prominent irregularity in facial skin in particular nevus mole birthmark their characteristic configuration over a face is used to encode the person s identity independent of pose and illumination this approach extends conventional recognition method which usually disregard such small scale variation and thereby miss potentially highly discriminative feature our system detects potential nevus with a very sensitive multi scale template matching procedure the candidate point are filtered according to their discriminative potential using two complementary method one is a novel skin segmentation scheme based on gray scale texture analysis that we developed to perform outlier detection in the face unlike most other skin detection segmentation method it doe not require color input the second is a local saliency measure to express a point s uniqueness and confidence taking the neighborhood s texture characteristic into account we experimentally evaluate the suitability of the detected feature for identification under different pose and illumination on a subset of the feret face database 
analysis of video of human object interaction involves understanding human movement locating and recognizing object and observing the effect of human movement on those object while each of these can be conducted independently recognition improves when interaction between these element are considered motivated by psychological study of human perception we present a bayesian approach which unifies the inference process involved in object classification and localization action understanding and perception of object reaction traditional approach for object classification and action understanding have relied on shape feature and movement analysis respectively by placing object classification and localization in a video interpretation framework we can localize and classify object which are either hard to localize due to clutter or hard to recognize due to lack of discriminative feature similarly by applying context on human movement from the object on which these movement impinge and the effect of these movement we can segment and recognize action which are either too subtle to perceive or too hard to recognize using motion feature alone 
where feature point are used in real time frame rate application a high speed feature detector is necessary feature detector such a sift dog harris and susan are good method which yield high quality feature however they are too computationally intensive for use in real time application of any complexity here we show that machine learning can be used to derive a feature detector which can fully process live pal video using le than of the available processing time by comparison neither the harris detector nor the detection stage of sift can operate at full frame rate clearly a high speed detector is of limited use if the feature produced are unsuitable for downstream processing in particular the same scene viewed from two different position should yield feature which correspond to the same real world d location hence the second contribution of this paper is a comparison corner detector based on this criterion applied to d scene this comparison support a number of claim made elsewhere concerning existing corner detector further contrary to our initial expectation we show that despite being principally constructed for speed our detector significantly outperforms existing feature detector according to this criterion 
object boundary detection and segmentation is a central problem in computer vision the importance of combining low level mid level and high level cue ha been realized in recent literature however it is unclear how to efficiently and effectively engage and fuse different level of information in this paper we emphasize a learning based approach to explore different level of information both implicitly and explicitly first we learn low level cue for object boundary and interior region using a probabilistic boosting tree pbt second we learn short and long range context information based on the result from the first st age both stage implicitly contain object specific information such a texture and local geometry and it is shown that this implicit knowledge is extremely powerful third we use high level shape information explicitly to further refine the object segmentation and to parse the object into component the algorithm is trained and tested on a challenging dataset of horse and the result obtained are very encouraging compared with other approach in detailed experiment we show significantly better performance e g f value of compared to than the best comparable reported performance on this dataset furthermore the system only need minute for a typical image although our system is illustrated on horse image the approach can be directly applied to detecting segmentaing other type of object 
this paper present a method of learning and recognizing generic object category using part based spatial mod el the model are multiscale with a scene component that specifies relationship between the object and surrounding scene context and an object component that specifies relationship between part of the object the underlying graphical model form a tree structure with a star topology for both the contextual and object component a partially supervised paradigm is used for learning the model where each training image is labeled with bounding box indicating the overall location of object instance but part or region of the object and scene are not specified the part region and spatial relationship are learned au tomatically we demonstrate the method on the detection task on the pascal visual object class challenge dataset where object must be correctly localized our result demonstrate better overall performance than those of previously reported technique in term of the average pre cision measure used in the pascal detection evaluation our result also show that incorporating scene context into the model improves performance in comparison with not using such contextual information with the world such a navigation surveillance and visual user interface there are a number of reason for the recent focus on image classification instead of localization first a broa d range of machine learning technique are directly applicable to the classification problem but le so to the localization problem second large scale training and test set th at provide object location information have not been available the latter issue ha recently been addressed with the creation of the dataset for the pascal visual object class challenge voc we address the same task using the same data and scoring a in the comp portion of the competition however we use a slightly different terminology that we believe is le open to confusion referring to this task a localization rather than detection this is because the term detection is often used in the literature to refer to method that do not actually determine the location of object in image i e that perform what both we and the voc refer to a classification 
in recent year kernel principal component analysis kernel pca ha gained much attention because of it ability to capture nonlinear image feature which are particularly important for encoding image structure boosting ha been established a a powerful learning algorithm that can be used for feature selection in this paper we present a novel framework for object class detection that combine the feature reduction and feature selection ability of kernel pca and adaboost respectively the classifier obtained in this way is able to handle change in object appearance illumination condition and surrounding clutter a nonlinear subspace is learned for positive and negative object class using kernel pca feature are derived by projecting example image onto the learned subspace base learner are modeled using bayes classifier adaboost is then employed to discover the feature that are most relevant for the object detection task at hand the proposed method ha been successfully tested on wide range of object class car airplane pedestrian motorcycle etc using standard data set and ha shown remarkable performance using a small training set a classifier learned in this way wa able to generalize the intra class variation while still maintaining high detection rate in most object category we achieved detection rate of above with minimal false alarm rate we demonstrate the effectiveness of our approach in term of absolute performance parameter and comparative performance against current state of the art approach 
this paper break with the common practice of using a joint state space representation and performing the joint data association in multi object tracking instead we present an interactively distributed framework with linear complexity for real time application when object do not interact on each other our approach performs like multiple independent tracker when the object are in close proximity or present occlusion we propose a magnetic inertia potential model to handle the error merge and labelling problem in a particle filtering framework specifically we propose to model the interactive likelihood density by a gravitation and magnetic repulsion scheme and relax the common first order markov chain assumption by using an inertia markov chain our model represents the cumulative effect of virtual physical force that object undergo while interacting with others it implicitly handle the error merge and labelling problem and thus solves the difficult object occlusion and data association problem using an innovative scheme our preliminary work ha demonstrated that the proposed approach is far superior to existing method not only in robustness but also in speed 
recently nonrigid shape matching ha received more and more attention for nonrigid shape most neighboring point cannot move independently under deformation due to physical constraint furthermore the rough structure of a shape should be preserved under deformation otherwise even people cannot match shape reliably therefore though the absolute distance between two point may change significantly the neighborhood of a point is well preserved in general based on this observation we formulate point matching a a graph matching problem each point is a node in the graph and two node are connected by an edge if their euclidean distance is le than a threshold the optimal match between two graph is the one that maximizes the number of matched edge the shape context distance is used to initialize the graph matching followed by relaxation labeling for refinement nonrigid deformation is overcome by bringing one shape closer to the other in each iteration using deformation parameter estimated from the current point correspondence experiment demonstrate the effectiveness of our approach it outperforms the shape context and tps rpm algorithm under nonrigid deformation and noise on a public data set 
abstract facial activity are the most natural and powerful mean of human communication spontaneous facial activity is characterized by rigid head movement non rigid facial muscular movement and their interaction current research in facial activity analysis is limited to recognizing rigidor non rigidmotionseparately oftenignoringtheirinteractions furthermore although some of them analyze the temporal property of facial feature during facial feature extraction they often recognize the facial activity statically ignoring the dynamic of the facial activity in this paper we propose to explicitly exploit the prior knowledge about facial activity and systematically combine the prior knowledge with image measurement to achieve an accurate robust and consistent facial activity understanding specifically we propose a unified probabilistic framework based on the dynamic bayesian network dbn to simultaneously and coherently represent the rigid and non rigid facial motion their interaction and their image observation a well a to capture the temporal evolution of the facial activity robust computer vision method are employed to obtain measurement of both rigid and non rigid facial motion finally facial activity recognition is accomplished through a probabilistic inference by systemically integrating the visual measurement with the facial activity model 
we introduce a novel probabilistic approach for nonparametric nonrigid image registration using generalized elastic net a model previously used for topographic map the idea of the algorithm is to adapt an elastic net a constrained gaussian mixture in the spatial intensity space of one image to t the second image the resulting net directly represents the correspondence between image pixel in a probabilistic way and recovers the underlying image deformation we regularize the net with a differential prior and develop an efcient optimization algorithm using linear conjugate gradient the nonparametric formulation allows for complex transformation having local deformation the method is generally applicable to registering point set of arbitrary feature the accuracy and effectiveness of the method are demonstrated on different medical image and point set registration example with locally nonlinear underlying deformation 
in this paper we propose a novel learning based method for image hallucination with image super resolution being a specific application that we focus on here given a low resolution image it underlying higher resolution detail are synthesized based on a set of training image in order to build a compact yet descriptive training set we investigate the characteristic local structure contained in large volume of small image patch inspired by progress in manifold learning research we take the assumption that small image patch in the low resolution and high resolution image form manifold with similar local geometry in the corresponding image feature space this assumption lead to a super resolution approach which reconstructs the feature vector corresponding to an image patch by it neighbor in the feature space in addition the residual error associated with the reconstructed image patch are also estimated to compensate for the information loss in the local averaging process experimental result show that our hallucination method can synthesize higher quality image compared with other method 
an important goal of statistical shape analysis is the discrimination between population of object exploring group difference in morphology not explained by standard volumetric analysis certain application additionally require analysis of object in their embedding context by joint statistical analysis of set of interrelated object in this paper we present a framework for discriminant analysis of population of d multi object set in view of the driving medical application a skeletal object parametrization of shape is chosen since it naturally encodes thickening bending and twisting in a multi object setting we not only consider a joint analysis of set of shape but also must take into account difference in pose statistic on feature of medial description and pose parameter which include rotational frame and distance us a riemannian symmetric space instead of the standard euclidean metric our choice of discriminant method is the distance weighted discriminant dwd because of it generalization ability in high dimensional low sample size setting joint analysis of subcortical brain structure in a pediatric autism study demonstrates that multi object analysis of shape result in a better group discrimination than pose and that the combination of pose and shape performs better than shape alone finally given a discriminating axis of shape and pose we can visualize the difference between the population 
in this paper we present a two layer generative model that incorporates generic middle level visual knowledge for dense stereo reconstruction the visual knowledge is represented by a dictionary of surface primitive including various category of boundary discontinuity and junction in parametric form given a stereo pair we first compute a primal sketch representation which decomposes the image into a structural part for object boundary and high intensity contrast represented by a d sketch graph and a structureless part represented by markov random field on pixel then we label the sketch graph and compute the d sketch like a wire frame by fitting the primitive dictionary to the sketch graph the surface between the d sketch are filled in by computing the depth of the mrf model on the structureless part these two level interact closely since the mrf is used to propagate information between the primitive and at the same time the primitive act a boundary condition for the mrf the two process maximize a bayesian posterior probability jointly we propose anmcmc algorithm that simultaneously infers the d primitive type and parameter and estimate the depth of the scene our experiment show that this representation can infer the depth map with sharp boundary and junction for textureless image curve object and free form shape 
currently sharp discontinuity in depth and partial occlusion in multiview imaging system pose serious challenge for many dense correspondence algorithm however it is important for d reconstruction method to preserve depth edge a they correspond to important shape feature like silhouette which are critical for understanding the structure of a scene in this paper we show how active illumination algorithm can produce a rich set of feature map that are useful in dense d reconstruction we start by showing a method to compute a qualitative depth map from a single camera which encodes object relative distance and can be used a a prior for stereo in a multiview setup we show that along with depth edge binocular half occluded pixel can also be explicitly and reliably labeled to demonstrate the usefulness of these feature map we show how they can be used in two different algorithm for dense stereo correspondence our experimental result show that our enhanced stereo algorithm are able to extract high quality discontinuity preserving correspondence map from scene that are extremely challenging for conventional stereo method 
being the most broadly used tool for deceit measurement the polygraph is a limited method a it suffers from human operator subjectivity and the fact that target subject are aware of the measurement which invite the opportunity to alter their behavior or plan counter measure in advance the approach presented in this paper attempt to circumvent these problem by unobtrusively and automatically measuring several prior identified deceit indicator dis based upon involuntary so called reliable facial expression through computer vision analysis of image sequence in real time reliable expression are expression said by the psychology community to be impossible for a significant percentage of the population to convincingly simulate without feeling a true inner felt emotion the strategy is to detect the difference between those expression which arise from internal emotion implying verity and those expression which are simulated implying deceit first a group of facial action unit au related to the reliable expression are detected based on distance and texture based feature the dis then can be measured and finally a decision of deceit or verity will be made accordingly the performance of this proposed approach is evaluated by it real time implementation for deceit detection 
we present an algorithm for edge detection suitable for both natural a well a noisy image our method is based on efficient multiscale utilization of elongated filter measuring the difference of oriented mean of various length and orientation along with a theoretical estimation of the effect of noise on the response of such filter we use a scale adaptive threshold along with a recursive decision process to reveal the significant edge of all length and orientation and to localize them accurately even in lowcontrast and very noisy image we further use this algorithm for fiber detection and enhancement by utilizing stochastic completion like process from both side of a fiber our algorithm relies on an efficient multiscale algorithm for computing all significantly different oriented mean in an image in o n log where n is the number of pixel and is the length of the longest structure of interest experimental result on both natural and noisy image are presented 
we present a novel algorithm to detect and remove cast shadow in a video sequence by taking advantage of the statistical prevalence of the shadowed region over the object region we model shadow using multivariate gaussians we apply a weak classifier a a pre filter we project shadow model into a quantized color space to update a shadow flow function we use shadow flow background model and current frame to determine the shadow and object region this method ha several advantage it doe not require a color space transformation we pose the problem in the rgb color space and we can carry out the same analysis in other cartesian space a well it is data driven and adapts to the changing shadow condition in other word accuracy of our method is not limited by the preset value furthermore it doe not assume any d model for the target object or tracking of the cast shadow between frame our result show that the detection performance is superior than the benchmark method 
we present a novel fully automatic method for high resolution nonrigid dense d point tracking high quality dense point cloud of nonrigid geometry moving at video speed are acquired using a phase shifting structured light ranging technique to use such data for the temporal study of subtle motion such a those seen in facial expression an efficient nonrigid d motion tracking algorithm is needed to establish inter frame correspondence the novelty of this paper is the development of an algorithmic framework for d tracking that unifies tracking of intensity and geometric feature using harmonic map with added feature correspondence constraint while the previous us of harmonic map provided only global alignment the proposed introduction of interior feature constraint guarantee that nonrigid deformation are accurately tracked a well the harmonic map between two topological disk is a diffeomorphism with minimal stretching energy and bounded angle distortion the map is stable insensitive to resolution change and is robust to noise due to the strong implicit and explicit smoothness constraint imposed by the algorithm and the high resolution data the resulting registration deformation field is smooth continuous and give dense one to one inter frame correspondence our method is validated through a series of experiment demonstrating it accuracy and efficiency 
discriminant feature extraction play a fundamental role in pattern recognition in this paper we propose the linear laplacian discrimination lld algorithm or discriminant feature extraction lld is an extension of linear discriminant analysis lda our motivation is to address the issue that lda cannot work well in case where sample space are non euclidean specifically we define the within class scatter and the between class scatter using similarity which are based on pairwise distance in sample space thus the structural information of class is contained in the within class and the between class laplacian matrix which are free from metric of sample space the optimal discriminant subspace can be derived by controlling the structural evolution of laplacian matrix experiment are performed on the facial database for frgc version experimental result show that lld is effective in extracting discriminant feature 
we present a new approach for the incorporation of shape information into a segmentation algorithm unlike previous approach to the problem our method requires no initialization is non iterative and find a steady state i e global optimum solution in the present work we are specifically focused on the segmentation of rectilinear shape the key idea is to use the fact that certain shape class optimize the ratio of specific metric which can be expressed a graph laplacian matrix applied to indicator vector we show that a relaxation of the binary formulation of this problem allows a global solution via generalized eigenvectors the approach is tested on both synthetic example and natural image 
in this paper we present a method for learning a curve model for detection and segmentation by closely integrating a hierarchical curve representation using generative and discriminative model with a hierarchical inference algorithm we apply this method to the problem of automatic localization of the guidewire in fluoroscopic sequence in fluoroscopic sequence the guidewire appears a a hardly visible non rigid one dimensional curve our paper ha three main contribution firstly we present a novel method to learn the complex shape and appearance of a free form curve using a hierarchical model of curve of increasing degree of complexity and a database of manual annotation secondly we present a novel computational paradigm in the context of marginal space learning in which the algorithm is closely integrated with the hierarchical representation to obtain fast parameter inference thirdly to our knowledge this is the first full system which robustly localizes the whole guidewire and ha extensive validation on hundred of frame we present very good quantitative and qualitative result on real fluoroscopic video sequence obtained in just one second per frame 
development of multiple camera based vision system for analysis of dynamic object such a human is challenging due to occlusion and similarity in the appearance of a person with the background and other peoplevisual confusion since occlusion and confusion depends on the presence of other people in the scene it lead to a dependency structure where there are often loop in the resulting bayesian network while approach such a loopy belief propagation can be used for inference they are computationally expensive and convergence is not guaranteed in many situation we present a unified approach cost that reason about such dependency and yield an order for the inference of each person in a group of people and a set of camera to be used for inference for a person using the probabilistic distribution of the position and appearance of people cost performs visibility and confusion analysis for each part of each person and computes the amount of information that can be computed with and without more accurate estimation of the position of other people we present an optimization problem to select set of camera and inference dependency for each person which attempt to minimize the computational cost under given performance constraint result show the efficiency of cost in improving the performance of such system and reducing the computational resource required 
this paper present a perceptual grouping algorithm that performs boundary extraction on natural image our grouping method maintains and update a model of the appearance of the image region on either side of a growing contour this model is used to change grouping behaviour at run time so that in addition to following the traditional gestalt grouping principle of proximity and good continuation the grouping procedure favour the path that best separate two visually distinct part of the image the resulting algorithm is computationally efficient and robust to clutter and texture we present experimental result on natural image from the berkeley segmentation database and compare our result to those obtained with three alternate grouping method 
several author have noticed that the common representation of image a vector is sub optimal the process of vectorization eliminates spatial relation between some of the nearby image measurement and produce a vector of a dimension which is the product of the measurement dimension it seems that image may be better represented when taking into account their structure a a d or multid array our work bear similarity to recent work such a dpca or coupled subspace analysis in that we treat image a d array the main difference however is that unlike previous work which separated representation from the discriminative learning stage we achieve both by the same method our framework low rank separator study the use of a separating hyperplane which are constrained to have the structure of low rank matrix we first prove that the low rank constraint provides preferable generalization property we then define two low rank svm problem and propose algorithm to solve these finally we provide supporting experimental evidence for the framework 
we present a viewpoint based approach for the quick fusion of multiple stereo depth map our method selects depth estimate for each pixel that minimize violation of visibility constraint and thus remove error and inconsistency from the depth map to produce a consistent surface we advocate a two stage process in which the first stage generates potentially noisy overlapping depth map from a set of calibrated image and the second stage fuse these depth map to obtain an integrated surface with higher accuracy suppressed noise and reduced redundancy we show that by dividing the processing into two stage we are able to achieve a very high throughput because we are able to use a computationally cheap stereo algorithm and because this architecture is amenable to hardwareaccelerated gpu implementation a rigorous formulation based on the notion of stability of a depth estimate is presented first it aim to determine the validity of a depth estimate by rendering multiple depth map into the reference view a well a rendering the reference depth map into the other view in order to detect occlusion and freespace violation we also present an approximate alternative formulation that selects and validates only one hypothesis based on confidence both formulation enable u to perform video based reconstruction at up to frame per second we show result on the multi view stereo evaluation benchmark datasets and several outdoors video sequence extensive quantitative analysis is performed using an accurately surveyed model of a real building a ground truth 
a set of image of a lambertian surface under varying lighting direction defines it shape up to a three parameter generalized ba relief gbr ambiguity in this paper we examine this ambiguity in the context of surface having an additive non lambertian reflectance component and we show that the gbr ambiguity is resolved by any non lambertian reflectance function that is isotropic and spatially invariant the key observation is that each point on a curved surface under directional illumination is a member of a family of point that are in isotropic or reciprocal configuration we show that the gbr can be resolved in closed form by identifying member of these family in two or more image based on this idea we present an algorithm for recovering full euclidean geometry from a set of uncalibrated photometric stereo image and we evaluate it empirically on a number of example 
abstract detection of object of a given class is important for many application however it is difficult to learn a general detector with high detection rate a well a low false alarm rate especially the labor needed for manually labeling a huge training sample set is usually not affordable we propose an unsupervised incremental learning approach based on online boosting to improve the performance on special application of a set of general part detector which are learned from a small amount of labeled data and have moderate accuracy our oracle for unsupervised learning which ha high precision is based on a combination of a set of shape based part detector learned by off line boosting our online boosting algorithm which is designed for cascade structure detector is able to adapt the simple feature the base classifier the cascade decision strategy and the complexity of the cascade automatically to the special application we integrate two noise restraining strategy in both the oracle and the online learner the system is evaluated on two public video corpus 
recognizing human estimating their pose and segmenting their body part are key to high level image understanding because human are highly articulated the range of deformation they undergo make this task extremely challenging previous method have focused largely on heuristic or pairwise part model in approaching this problem we propose a bottom up parsing of increasingly more complete partial body mask guided by a parse tree at each level of the parsing process we evaluate the partial body mask directly via shape matching with exemplar without regard to how the par are formed the body is evaluated a a whole not the sum of it constituent par unlike previous approach multiple image segmentation are included at each of the level of the parsing to augment existing par or to introduce one our method yield both a pose estimate a well a a segmentation of the human we demonstrate competitive result on this challenging task with relatively few training example on a dataset of baseball player with wide pose variation our method is comparatively simple and could be easily extended to other object 
the fundamental matrix is a central construct in the analysis of image captured from a pair of camera and many feature based method have been proposed for it computation in this paper we propose a direct method for estimating the fundamental matrix where the motion between the frame is small e g between successive frame of a video to achieve this a warping function is presented for the fundamental matrix by using the brightness constancy constraintin conjunctionwith geometric constraint using this warping function an iterative hierarchical algorithm is described to recover accurate estimate of the fundamental matrix we present result of experimentation to evaluate the performance of the proposed approach and demonstrate improved accuracy in the computation of the fundamental matrix 
abstract a simple stereo matching algorithm is proposed that visit only a small fraction of disparity space in order to find a semi dense disparity map it work by growing from a small set of correspondence seed unlike in known seedgrowing algorithm it guarantee matching accuracy and correctness even in the presence of repetitive pattern this success is based on the fact it solves a global optimization task the algorithm can recover from wrong initial seed to the extent they can even be random the quality of correspondence seed influence computing time not the quality of the final disparity map we show that the proposed algorithm achieves similar result a an exhaustive disparity space search but it is two order of magnitude faster this is very unlike the existing growing algorithm which are fast but erroneous accurate matching on megapixel image of complex scene is routinely obtained in a few second on a common pc from a small number of seed without limiting the disparity search range 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
the recognition of facial gesture and expression in image sequence is an important and challenging problem most of the existing method adopt the following paradigm first facial action feature are retrieved from the image and then facial expression are recognized based on the retrieved temporal parameter unlike this main stream this paper introduces a new approach allowing the simultaneous recovery of facial action and expression using a particle filter adopting multi class dynamic that are conditioned on the expression for each frame in the video sequence our approach is split in two consecutive stage in the first stage the d head pose is recovered using a deterministic registration technique based on online appearance model in the second stage the facial action a well a the facial expression are simultaneously recovered using the stochastic framework with mixed state the proposed fast scheme is either a robust a existing one or more robust with respect to many regard experimental result show the feasibility and robustness of the proposed approach 
time varying phenomenon such a ripple on water tree waving in the wind and illumination change produce false motion which significantly compromise the performance of an outdoor surveillance system in this paper we propose a corner based background model to effectively detect moving object in challenging dynamic scene specifically the method follows a three step process first we detect feature point using a harris corner detector and represent them a sift like descriptor second we dynamically learn a background model and classify each extracted feature a either a background or a foreground feature last a lucas kanade feature tracker is integrated into this framework to differentiate motion consistent foreground object from background object with random or repetitive motion the key insight of our work is that a collection of sift like feature can effectively represent the environment and account for variation caused by natural effect with dynamic movement feature that do not correspond to the background must therefore correspond to foreground moving object our method is computational efficient and work in real time experiment on challenging video clip demonstrate that the proposed method achieves a higher accuracy in detecting the foreground object than the existing method 
acquiring d model of intricate object like tree branch bicycle and insect is a hard problem due to severe self occlusion repeated thin structure and surface discontinuity in theory a shape from silhouette sfs approach can overcome these difficulty and use many view to reconstruct visual hull that are close to the actual shape in practice however sfs is highly sensitive to error in silhouette contour and the calibration of the imaging system and therefore not suitable for obtaining reliable shape with a large number of view we present a practical approach to sfs using a novel technique called coplanar shadowgram imaging that allows u to use dozen to even hundred of view for visual hull reconstruction here a point light source is moved around an object and the shadow silhouette cast onto a single background plane are observed we characterize this imaging system in term of image projection reconstruction ambiguity epipolar geometry and shape and source recovery the coplanarity of the shadowgrams yield novel geometric property that are not possible in traditional multi view camerabased imaging system these property allow u to derive a robust and automatic algorithm to recover the visual hull of an object and the d position of light source simultaneously regardless of the complexity of the object we demonstrate the acquisition of several intricate shape with severe occlusion and thin structure using to view 
in this paper we study the relationship between multiview active appearance model aam fitting and camera calibration in the first part of the paper we propose an algorithm to calibrate the relative orientation of a set of n camera by fitting an aam to set of n image in essence we use the human face a a non rigid calibration grid our algorithm calibrates a set of weak perspective camera projection matrix projection of the world coordinate system origin into the image depth of the world coordinate system origin and focal length we demonstrate that the performance of this algorithm is comparable to a standard algorithm using a calibration grid in the second part of the paper we show how calibrating the camera improves the performance of multi view aam fitting 
in this paper we consider modeling data lying on multiple continuous manifold in particular we model the shape manifold of a person performing a motion observed from different view point along a view circle at fixed camera height we introduce a model that tie together the body configuration kinematics manifold and the visual manifold observation in a way that facilitates tracking the d configuration with continuous relative view variability the model exploit the low dimensionality nature of both the body configuration manifold and the view manifold where each of them are represented separately 
the goal of this work is to learn a parsimonious and informative representation for high dimensional time series conceptually this comprises two distinct yet tightly coupled task learning a low dimensional manifold and modeling the dynamical process these two task have a complementary relationship a the temporal constraint provide valuable neighborhood information for dimensionality reduction and conversely the low dimensional space allows dynamic to be learnt efficiently solving these two task simultaneously allows important information to be exchanged mutually if nonlinear model are required to capture the rich complexity of time series then the learning problem becomes harder a the nonlinearities in both task are coupled the proposed solution approximates the nonlinear manifold and dynamic using piecewise linear model the interaction among the linear model are captured in a graphical model by exploiting the model structure efficient inference and learning algorithm are obtained without oversimplifying the model of the underlying dynamical process evaluation of the proposed framework with competing approach is conducted in three set of experiment dimensionality reduction and reconstruction using synthetic time series video synthesis using a dynamic texture database and human motion synthesis classification and tracking on a benchmark data set in all experiment the proposed approach provides superior performance 
in many computer vision application such a face recognition and hand pose estimation we need system that can recognize a very large number of class large margin classication method such a adaboost and svms often provide competitive accuracy rate but at the cost of evaluating a large number of binary classier s we propose an embedding based method for efcient multiclass recognition in our method pattern and class are mapped to vector in such a way that pattern and their associated class tend to get mapped close to each other this way given a test pattern a small set of candidate class can be identied efciently using simple vector comparison in experiment with d hand pose recognition class and face recognition class our method is between and time faster compared to evaluating all binary classier s with negligible or no loss in classication accuracy 
given a query image of an object our objective is to retrieve all instance of that object in a large m image database we adopt the bag of visual word architecture which ha proven successful in achieving high precision at low recall unfortunately feature detection and quantization are noisy process and this can result in variation in the particular visual word that appear in different image of the same object leading to missed result in the text retrieval literature a standard method for improving performance is query expansion a number of the highly ranked document from the original query are reissued a a new query in this way additional relevant term can be added to the query this is a form of blind relevance feedback and it can fail if outlier false positive document are included in the reissued query in this paper we bring query expansion into the visual domain via two novel contribution firstly strong spatial constraint between the query image and each result allow u to accurately verify each return suppressing the false positive which typically ruin text based query expansion secondly the verified image can be used to learn a latent feature model to enable the controlled construction of expanded query we illustrate these idea on the annotated image oxford building database together with more than m flickr image we show that the precision is substantially boosted achieving total recall in many case 
tracking object in low frame rate video or with abrupt motion pose two main difficulty which conventional tracking method can barely handle poor motion continuity and increased search space fast appearance variation of target and more background clutter due to increased search space in this paper we address the problem from a view which integrates conventional tracking and detection and present a temporal probabilistic combination of discriminative observer of different lifespan each observer is learned from different range of sample with different subset of feature to achieve varying level of discriminative power at varying cost an efficient fusion and temporal inference is then done by a cascade particle filter which consists of multiple stage of importance sampling experiment show significantly improved accuracy of the proposed approach in comparison with existing tracking method under the condition of low frame rate data and abrupt motion of both target and camera 
in this paper we develop a system for human behaviour recognition in video sequence human behaviour is modelled a a stochastic sequence of action action are described by a feature vector comprising both trajectory information position and velocity and a set of local motion descriptor action recognition is achieved via probabilistic search of image feature database representing previously seen action a hmm which encodes the rule of the scene is used to smooth sequence of action high level behaviour recognition is achieved by computing the likelihood that a set of predefined hidden markov model explains the current action sequence thus human action and behaviour are represented using a hierarchy of abstraction from simple action to action with spatio temporal context to action sequence and finally general behaviour while the upper level all use parametric bayes network and belief propagation the lowest level us non parametric sampling from a previously learned database of action the combined method represents a general framework for human behaviour modelling in this paper we demonstrate the result chiefly on broadcast tennis sequence for automated video annotation 
visual codebook based quantization of robust appearance descriptor extracted from local image patch is an effective mean of capturing image statistic for texture analysis and scene classification codebooks are usually constructed by using a method such a k mean to cluster the descriptor vector of patch sampled either densely textons or sparsely bag of feature based on key point or salience measure from a set of training image this work well for texture analysis in homogeneous image but the image that arise in natural object recognition task have far le uniform statistic we show that for dense sampling k mean over adapts to this clustering centre almost exclusively around the densest few region in descriptor space and thus failing to code other informative region this give suboptimal code that are no better than using randomly selected centre we describe a scalable acceptance radius based clusterer that generates better codebooks and study it performance on several image classification task we also show that dense representation outperform equivalent keypoint based one on these task and that svm or mutual information based feature selection starting from a dense codebook further improves the performance 
we describe a method for detecting and tracking human different from most of the previous work we focus on human with extensive pose articulation under situation where there is typically only a single camera multiple human are present and the image resolution is low in our method pose cluster are learned from an embedded silhouette manifold a set of object detector each of which corresponds to one pose cluster are trained based on a novel object weighted appearance model a probabilistic pose based transition model is used to track multiple object within a sliding window buffer making use of the detection response the track segment in the sliding window are connected sequentially into full trajectory experiment on a set of challenging surveillance video are presented these show good performance of our approach compared to standard pedestrian detector under difficult condition 
we present a new method for reconstructing the exterior surface of a complex transparent scene with inhomogeneous interior e g multiple interface reflective or painted interior etc our approach involves capturing image of the scene from one or more viewpoint while moving a proximal light source to a d or d set of position this give a d or d dataset per pixel called the scatter trace the key idea of our approach is that even though light transport within a transparent scene s interior can be exceedingly complex the scatter trace of each pixel ha a highlyconstrained geometry that reveals the contribution of direct surface reflection and lead to a simple scattertrace stereo algorithm for computing the local geometry of the exterior surface depth and surface normal we present d reconstruction result for a variety of scene that exhibit complex light transport phenomenon 
we employ d arrangement of curve to represent and analyze biological shape in particular the anatomy of the human brain the arrangement of curve may vary from fairly sparse such a a collection of sulcal line that coarsely approximates the global shape of the brain to very dense decomposition of the cortical surface into space curve a space of shape of such arrangement is constructed equipped with geodesic metric that can be used in conjunction with curve registration technique to quantify shape resemblance or dissimilarity a well a to identify the region where anatomical difference are most pronounced the metric is applied to the parcellation and labeling of configuration associated with the left and right hemisphere of the brain example are also given of geodesic interpolation between decomposition into space curve of surface representing the entire left hemisphere of the brain 
we propose a method for simultaneous detection localization and segmentation of object of a known category we show that this is possible by using segment a feature to this end we propose an object model in which the image is represented a a tree that capture containment relationship among the segment using segment a feature ha the advantage that object detection and segmentation is done simultaneously forgoing the need for a separate sophisticated model for object segmentation a generative model of an object category is estimated in a supervised mode in term of the characteristic of it constituent region their relative location and their mutual containment the novel aspect of this work lie in simplifying the description of the hierarchy in term of constraint that apply to only pair of node instead of all node in the tree we show that this indeed improves the speed of learning algorithm inference is done using graph cut we report the performance of the model on standard datasets mentation tree derived from prespecied example image of object segmentation tree contains the collection of all salient image region along with their associated gray level contrast arranged in a geometric tree that capture their mutual containment information the pairwise node constraint are captured in a topology feature vector which is extracted from the tree this representation transforms the complex structure of the tree into one in the simpler vector space which is easier to model we show that fast learning of object model can be performed in a supervised setting recognition in new image is done via alternating optimization between estimating a segmentation using graphcuts and estimating object conguration using fast hough transform voting the object are thus represented using region hierarchy in a probabilistic framework in this sense our approach combine statistical and structural object representation methodology the rest of the paper is organized a follows in sec we present a brief review of the existing literature on object category modelling in sec we describe the low level image representation we use sec describes the object model along with our learning and inference algorithm in sec we present experimental result and nally conclude the paper in sec related work 
a camera mounted on an aerial vehicle provides an excellent mean for monitoring large area of a scene utilizing several such camera on different aerial vehicle allows further flexibility in term of increased visual scope and in the pursuit of multiple target in this paper we address the problem of tracking object across multiple moving airborne camera since the camera are moving and often widely separated direct appearance based or proximity based constraint cannot be used instead we exploit geometric constraint on the relationship between the motion of each object across camera to test multiple correspondence hypothesis without assuming any prior calibration information we propose a statistically and geometrically meaningful mean of evaluating a hypothesized correspondence between two observation in different camera second since multiple camera exist ensuring coherency in correspondence i e transitive closure is maintained between more than two camera is an essential requirement to ensure such coherency we pose the problem of object tracking across camera a a k dimensional matching and use an approximation to find the maximum likelihood assignment of correspondence third we show that a a result of tracking object across the camera a concurrent visualization of multiple aerial video stream is possible result are shown on a number of real and controlled scenario with multiple object observed by multiple camera validating our qualitative model 
in this paper we describe a method for estimating curvature of elongated structure in image the curvature estimation is performed on an invertible orientation score which is a d entity obtained from a d image by convolution with a rotating kernel by considering the group structure we can define left invariant derivative which are essential to construct operation on the orientation score that amount to rotationally invariant operation on the corresponding image the problem of estimating curvature of an oriented structure is stated a a minimization problem which can be solved by eigenvector analysis of a matrix constructed from the non symmetric hessian matrix the experiment show the method performs well for a wide range of curvature and noise level the method clearly outperforms a related curvature estimation method by van ginkel et al that tends to give estimate that are too small we show how we can incorporate the curvature estimate in our method for coherence enhancing diffusion in orientation score this method ha superior performance in enhancing crossing contour which is demonstrated on medical image 
aiming at the problem when both positive and negative training set are enormous this paper proposes a novel matrix structural learning msl method a an extension to viola and jones cascade learning method for object detection briefly speaking unlike viola and jones method that learn linearly by bootstrapping only negative sample the proposed msl method bootstrap both positive and negative sample in a matrix like structure moreover an accumulative way is further presented to improve the training efficiency of msl by inheriting feature learned previously during training procedure the proposed method is evaluated on face detection problem on a positive set containing face sample only hour are needed on a common pc with a ghz pentium iv processor to learn a classifier with false alarm rate le than what s more the accuracy of the learned detector exceeds the state of the art result on the cmu mit frontal face test set 
in this work we present a common framework for seeded image segmentation algorithm that yield two of the leading method a special case the graph cut and the random walker algorithm the formulation of this common framework naturally suggests a new third algorithm that we develop here specifically the former algorithm may be shown to minimize a certain energy with respect to either an or an norm here we explore the segmentation algorithm defined by an norm provide a method for the optimization and show that the resulting algorithm produce an accurate segmentation that demonstrates greater stability with respect to the number of seed employed than either the graph cut or random walker method 
we describe a method for fully automatic object recognition and segmentation using a set of reference image to specify the appearance of each object our method us a generative model of image formation that take into account occlusion simple lighting change and object deformation we take advantage of local feature to identify locate and extract multiple object in the presence of large viewpoint change nonrigid motion with large number of degree of freedom occlusion and clutter we simultaneously compute an object level segmentation and a dense correspondence between the pixel of the appropriate reference image and the image to be segmented 
cascade of boosted ensemble have become popular in the object detection community following their highly successful introduction in the face detector of viola and jones in this paper we explore several aspect of this architecture that have not yet received adequate attention decision point of cascade stage faster ensemble learning and stronger weak hypothesis we present a novel strategy to determine the appropriate balance between false positive and detection rate in the individual stage of the cascade based on a probablistic model of the overall cascade s performance to improve the training time of individual stage we explore the use of feature filtering before the application of adaboost finally we show that the use of stronger weak hypothesis based on cart can significantly improve upon the standard face detection result on the cmu mit data set 
the representation and modelling of region is an important topic in computer vision in this paper we represent a region via a level set of a phase field function the function is not constrained e g to be a distance function nevertheless phase field energy equivalent to classical active contour energy can be defined they represent an advantageous alternative to other method a linear representation space ease of implementation a pde with no reinitialization neutral initialization greater topological freedom we extend the basic phase field model with term that reproduce higher order active contour energy a powerful way of including prior geometric knowledge in the active contour framework via nonlocal interaction between contour point in addition to the above advantage the phase field greatly simplifies the analysis and implementation of the higher order term we define a phase field model that favour region composed of thin arm meeting at junction combine this with image term and apply the model to the extraction of line network from remote sensing image 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
interactive image segmentation is important and ha widespread application in computer vision computer graphic and medical imaging a recent work ha shown that interactive figure ground segmentation can be achieved by computing a transparency image using an optimization framework where user interaction are used to supply constraint for solving a quadratic cost function with a unique global minimum which can be efficiently obtained using standard method in this paper we introduce statistical prior a constraint to solve the optimization problem we show that for some image the statistical prior can provide good enough constraint to automatically obtain satisfactory figure ground segmentation result for more difficult case we use the segmentation result of the statistical prior a a starting point for interactive figure ground segmentation we show that segmentation result obtained based on statistical prior can be effectively employed to guide user interaction thus helping to reduce user labor in the interaction process we also present a new effective adaptive thresholding method for making binary hard segmentation based on the computed continuous transparency image another contribution of this paper is the extension of the optimization based interactive figure ground segmentation framework to interactive multi class segmentation where user can provide multi class seed pixel instead of just foreground background class seed for segmenting the given image into the desired number of region by performing a one shot optimization operation which again ha a unique global minimum and can be obtained by solving a large system of linear equation we present various experimental result including segmentation error rate on an online image database with human labeled ground truth to show that our method work well and ha direct application in area such a interactive image editing 
in this paper we show that in a multi camera context we can effectively handle occlusion in real time at each frame independently even when the only available data come from the binary output of a simple blob detector and the number of present individual is a priori unknown we start from occupancy probability estimate in a top view and rely on a generative model to yield probability image to be compared with the actual input image we then refine the estimate so that the probability image match the binary input image a well a possible we demonstrate the quality of our result on several sequence involving complex occlusion 
we extend the sparse lda algorithm of with new sparsity bound on class separability and efcient partitioned matrix inverse technique leading to fold speed ups this mitigates the o n scaling that ha limited this algorithm s applicability to vision problem and also prioritizes the le myopic backward elimination stage by making it faster than forward selection experiment include sparse eigenfaces and gender classication on feret data a well a pixel part selection for ocr on mnist data using bayesian gp classication sparselda is an attractive alternative to the more demanding automatic relevance determination state of the art recognition is obtained while discarding the majority of pixel in all experiment our sparse model also show a better t to data in term of the evidence or marginal likelihood 
generic camera calibration is a non parametric calibration technique that is applicable to any typeof vision sensor however the standard generic calibration method wa developed with the goal of generality and it is therefore suboptimal for the common case of camera with a single centre of projection e g pinhole fisheye hyperboloidal catadioptric this paper proposes novel improvement to the standard generic calibration method for central camera that reduce it complexity and improve it accuracy and robustness improvement are achieved by taking advantage of the geometric constraint resulting from a single centre of projection input data for the algorithm is acquired using active grid the performance of which is characterised a new linear estimation stage to the generic algorithm is proposed incorporating classical pinhole calibration technique and it is shown to be significantly more accurate than the linear estimation stage of the standard method a linear method for pose estimation is also proposed and evaluated against the existing polynomial method distortion correction and motion reconstruction experiment are conducted with real data for a hyperboloidal catadioptric sensor for both the standard and proposed method result show the accuracy and robustness of the proposed method to be superior to those of the standard method 
abstract we present a segmentation method for live cell image using graph cut and learning method the image used here are particularly challenging because of the shared grey level distribution of cell and background which on ly differ by their texture and the local imprecision around cell border we use thep potts model we present the model and the learning method we used and compare our segmentation result with similar work in cytometry while our method performs similarly it requires little manual tuning and thus is straightforward to adapt to other image 
in many vision problem the appearance of the observed image e g the human facial image are often influenced by multiple underlying factor in this paper a kernel based factorization framework is proposed to analyze a multifactor dataset specifically we perform n mode singular value decomposition n mode svd in a higher dimensional feature space instead of the input space by using kernel approach given an input sample it specific underlying factor which may be all absent in the training set can be extracted and translated from one sample to another by using kernel based translation therefore our framework is suitable for task of new image synthesis and underlying factor recognition we demonstrate the capability of our framework on ensemble of facial image subjected to different person identity view point and illumination with high quality synthetic face and high face recognition accuracy 
in this study we propose an integrated approach to the problem of d pose estimation the main difference to the majority of known method is the usage of complementary image information including intensity and polarisation state of the light reflected from the object surface edge information and absolute depth value obtained based on a depth from defocus approach our method is based on the comparison of the input image to synthetic image generated by an opengl based renderer using model information about the object provided by cad data this comparison provides an error term which is minimised by an iterative optimisation algorithm although all six degree of freedom are estimated our method requires only a monocular camera circumventing disadvantage of multiocular camera system such a the need for external camera calibration our framework is open for the inclusion of independently acquired depth data we evaluate our method on a toy example a well a in two realistic scenario in the domain of industrial quality inspection our experiment regarding complex real world object located at a distance of about m to the camera show that the algorithm achieves typical accuracy of better than degree for the rotation angle image pixel for the lateral translation and several millimetre or about percent for the object distance 
the analysis of periodic or repetitive motion is useful in many application both in the natural and the man made world an important example is the recognition of human and animal activity existing method for the analysis of periodic motion first extract motion trajectory e g via correlation or feature point matching we present a new approach which take advantage of both the frequency and spatial information of the video the d spatial fourier transform is applied to each frame and time frequency distribution are then used to estimate the time varying object motion thus multiple periodic trajectory are extracted and their period are estimated the period information is finally used to segment the periodically moving object unlike existing method our approach estimate multiple periodicity simultaneously it is robust to deviation from strictly periodic motion and estimate periodicity superposed on translation experiment with synthetic and real sequence display the capability and limitation of this approach supplementary material is provided showing the video sequence used in the experiment 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
spherical object and vanish point are often used for camera calibration an occluding contour of a sphere is projected to a conic in the perspective image and using a moving active camera the trajectory of a vanishing point in the perspective image is also a conic when the camera is rotated about a fixed d axis whereas the translation of the camera is arbitrary in fact the problem of camera calibration using conic from sphere or vanishing point can be described by same mathematic representation two linear approach to the problem are proposed in this paper one based on the geometric interpretation of the relation between image conic and the image of the absolute conic and the other using the special structure of the problem in algebra only three such conic are needed for the two linear approach and the minimum number for previous nonlinear optimization method is also three all five intrinsic parameter are recovered linearly without making assumption such a zero skew or unitary aspect ratio which are often used in previous method the two linear algorithm have been tested in extensive experiment with respect to noise sensitivity and also made comparison with recent calibration technique 
lambertian photometric stereo with unknown light source parameter is ambiguous provided that the object imaged constitutes a surface the ambiguity is represented by the group of generalised ba relief gbr transformation we show that this ambiguity is resolved when specularreflection is present in two image taken under two different light source direction we identify all configuration of the two directional light which are singular and show that they can easily be tested for while previous work used optimisation algorithm to apply the constraint implied by the specular reflectance component we have developed a linear algorithm to achieve this goal our theory can be utilised to construct fast algorithm for automatic reconstruction of smooth glossy surface 
we present a new method to fit grammar based stochastic model for biological structure to stack of microscopic image captured at incremental focal length providing the ability to quantitatively represent structure and automatically fit it to image data enables important biological research we consider the case where individual can be represented a an instance of a stochastic grammar similar to l system used in graphic to produce realistic plant model in particular we construct a stochastic grammar of alternaria a genus of fungus and fit instance of it to microscopic image stack we express the image data a the result of a generative process composed of the underlying probabilistic structure model together with the parameter of the imaging system fitting the model then becomes probabilistic inference for this we create a reversible jump mcmc sampler to traverse the parameter space we observe that incorporating spatial structure help fit the model part and that simultaneously fitting the imaging system is also very helpful 
we revisit the problem of recovering d shape from the projection of planar curve on a surface this problem is strongly motivated by perception study application include single view modeling and fully uncalibrated structured light when the curve intersect the problem lead to a linear system for which a direct least square method is sensitive to noise we derive a more stable solution and show example where the same method produce plausible surface from the projection of parallel non intersecting planar cross section 
matching local feature across image is often useful when comparing or recognizing object or scene and efficient technique for obtaining image to image correspondence have been developed however given a query image searching a very large image database with such measure remains impractical we introduce a sublinear time randomized hashing algorithm for indexing set of feature vector under their partial correspondence we develop an efficient embedding function for the normalized partial matching similarity between set and show how to exploit random hyperplane property to construct hash function that satisfy locality sensitive constraint the result is a bounded approximate similarity search algorithm that find approximate nearest neighbor image in o n time for a database containing n image represented by varying number of local feature we demonstrate our approach applied to image retrieval for image represented by set of local appearance feature and show that searching over correspondence is now scalable to large image database 
in this paper we propose a general framework for fusing bottom up segmentation with top down object behavior classification over an image sequence this approach is beneficial for both task since it enables them to cooperate so that knowledge relevant to each can aid in the resolution of the other thus enhancing the final result in particular classification offer dynamic probabilistic prior to guide segmentation while segmentation supply it result to classification ensuring that they are consistent both with prior knowledge and with new image information we demonstratetheeffectivenessofourframeworkvia a particularimplementationfora handgesture recognitionapplication the prior model are learned from training data using principal component analysis and they adapt dynamically to the content of new image our experimental result illustrate the robustness of our joint approach to segmentation and behavior classification in challenging condition involving occlusion of the target object before a complex background 
in this paper we address the challenging problem of simultaneous pedestrian detection and ground plane estimation from video while walking through a busy pedestrian zone our proposed system integrates robust stereo depth cue ground plane estimation and appearance based object detection in a principled fashion using a graphical model object object occlusion lead to complex interaction in this model that make an exact solution computationally intractable we therefore propose a novel iterative approach that first infers scene geometry using belief propagation and then resolve interaction between object using a global optimization procedure this approach lead to a robust solution in few iteration while allowing object detection to benefit from geometry estimation and vice versa we quantitatively evaluate the performance of our proposed approach on several challenging test sequence showing stroll through busy shopping street comparison to various baseline system show that it outperforms both a system using no scene geometry and one just relying on structure from motion without dense stereo 
in this paper we study face recognition across age within a real passport photo verification task first we propose using the gradient orientation pyramid for this task discarding the gradient magnitude and utilizing hierarchical technique we found that the new descriptor yield a robust and discriminative representation with the proposed descriptor we model face verification a a two class problem and use a support vector machine a a classifier the approach is applied to two passport data set containing more than image pair from each person with large age difference although simple our approach outperforms previously tested bayesian technique and other descriptor including the intensity difference and gradient with magnitude in addition it work a well a two commercial system second for the first time we empirically study how age difference affect recognition performance our experiment show that although the aging process add difficulty to the recognition task it doe not surpass illumination or expression a a confounding factor 
in this paper we propose extension to the match propagation algorithm which is a technique for computing quasidense point correspondence between two view the extension make the match propagation applicable for wide baseline matching i e for case where the camera pose can vary a lot between the view our r st extension is to use a local afne model for the geometric transformation between the image the estimate of the local transformation is obtained from afne covariant interest region which are used a seed match the second extension is to use the second order intensity moment to adapt the current estimate of the local afne transformation during the propagation this allows a single seed match to propagate into region where the local transformation between the view differs from the initial one the experiment with real data show that the proposed technique improve both the quality and coverage of the quasi dense disparity map 
in this paper we present a novel segmentation insensitive approach for mining common pattern from image we develop an algorithm using the earth mover distance emd framework unary and adaptive neighborhood color similarity we then propose a novel local flow maximization approach to provide the best estimation of location and scale of the common pattern this is achieved by performing an iterative optimization in search of the most stable flow centroid common pattern discovery is difficult owing to the huge search space and problem domain we intend to solve this problem by reducing the search space through identifying the location and a reduced spatial space for common pattern discovery experimental result justify the effectiveness and the potential of the approach 
abstract reliable d tracking is still a difficult task most parametrized d deformable model rely on the accurate extraction of image feature for updating their parameter and are prone to failure when the underlying feature distribution assumption are invalid active shape model asms on the other hand are based on learning and thus require fewer reliable local image feature than parametrized d model but fail easily when they encounter a situation for which they were not trained in this paper we develop an integrated framework that combine the strength of both d deformable model and asms the d model governs the overall shape orientation and location and provides the basis for statistical inference on both the image feature and the parameter the asms in contrast provide the majority of reliable d image feature over time and aid in recovering from drift and total occlusion the framework dynamically selects among different asms to compensate for large viewpoint change due 
gene expression data provide information on the location where certain gene are active in order for this to be useful such a location must be registered to an anatomical atlas because gene expression map are considerably different from each other they display the expression of different gene and from the anatomical atlas this problem is currently addressed either manually by trained expert or by neglecting all image information and only using the pre segmented boundary in this manuscript we concentrate on data discrepancy measure that take into account image information when this is present in both the target and template image we exploit such bi lateral structure to drive the correspondence process in region where the intensity information is inconsistent analogously to a motion inpainting task although no ground truth can be established and prior information clearly play a key role we show that our model achieves desirable result on subjective test validated by expert subject 
this paper proposes a new approach to d reconstruction of piecewise planar object based on two image regularity connectivity and perspective symmetry first we formulate the whole shape of the object in an image a a shape vector consisting of the normal of all the face of the object then we impose several linear constraint on the shape vector using connectivity and perspective symmetry of the object finally we obtain a closed form solution to the d reconstruction problem we also develop an efficient algorithm to detect a face of perspective symmetry experimental result on real image are shown to demonstrate the effectiveness of our approach 
the u s army research laboratory arl ha a significant program involving the development of ugs unattended ground sensor that address a variety of military and government mission arl s program involves practically every aspect of sensor development including device detection and fusion algorithm communication and command and control one element of the arl ugs program involves the development of low cost sensing technique for the urban environment and one embodiment of this effort is the multi modal sensor mm 
in the author proposed the large deformation logunbiased diffeomorphic nonlinear image registration model which ha been successfully used to obtain theoretically and intuitively correct deformation map in this paper we extend this idea to simultaneously registering and tracking deforming object in a sequence of two or more image we generalize a level set based chan vese multiphase segmentation model to consider jacobian field while segmenting region of growth and shrinkage in deformation deforming object are thus classified based on magnitude of homogeneous deformation numerical experiment demonstrating our result include a pair of two dimensional synthetic image and pair of two dimensional and three dimensional serial mri image 
we present an unsupervised method for learning a hierarchy of sparse feature detector that are invariant to small shift and distortion the resulting feature extrac tor consists of multiple convolution filter followed by a feature pooling layer that computes the max of each filter output within adjacent window and a point wise sigmoid non linearity a second level of larger and more invariant feature is obtained by training the same algorithm on patch of feature from the first level training a supervised classifier on these feature yield error on mnist and average recognition rate on caltech with training sample per category while the resulting architecture is similar to convolutional network the layer wise unsupervised training procedure alleviates th e over parameterization problem that plague purely supervised learning procedure and yield good performance with very few labeled training sample 
we propose a novel algorithm for segmenting multiple motion of different type from point correspondence in multiple affine or perspective view since point trajectory associated with different motion live in different manifold traditional approach deal with only one manifold type linear subspace for affine view and homographic bilinear and trilinear variety for two and three perspective view a real motion sequence contain motion of different type we cast motion segmentation a a problem of clustering manifold of different type rather than explicitly modeling each manifold a a linear bilinear or multilinear variety we use nonlinear dimensionality reduction to learn a low dimensional representation of the union of all manifold we show that for a union of separated manifold the lle algorithm computes a matrix whose null space contains vector giving the segmentation of the data an analysis of the variance of these vector allows u to distinguish them from other vector in the null space this lead to a new algorithm for clustering both linear and nonlinear manifold although this algorithm is theoretically designed for separated manifold our experiment demonstrate it performance on real data where this assumption doe not hold we test our algorithm on the hopkins motion segmentation database and achieve an average classification error of which compare favorably against state of the art multiframe motion segmentation method 
although many color constancy method exist they are all based on specific assumption such a the set of possible light source or the spatial and spectral characteristic of image a a consequence no algorithm can be considered a universal however with the large variety of available method the question is how to select the method that induces equivalent class for different image characteristic furthermore the subsequent question is how to combine the different algorithm in a proper way to achieve selection and combining of color constancy algorithm in this paper natural image statistic are used to identify the most important characteristic of color image then based on these image characteristic the proper color constancy algorithm or best combination of algorithm is selected for a specific image to capture the image characteristic the weibull parameterization e g texture and contrast is used experiment show that on a large data set of image our approach outperforms current state of the art single algorithm a well a simple alternative for combining several algorithm 
topic model have recently emerged a powerful tool for modeling topical trend in document often the resulting topic are broad and generic associating large group of people and issue that are loosely related in many case it may be desirable to inuence the direction in which topic model develop in this paper we explore the idea of centering topic around people in particular given a large corpus of image featuring collection of people and associated caption it seems natural to extract topic specically focussed on each person what word are most associated with george bush which with condoleezza rice since people play such an important role in life it is natural to anchor one topic to each person in this paper we present people lda which us the coherence of face image in news caption to guide the development of topic in particular we show how topic can be rened to be more closely related to a single person like george bush rather than describing group of people in a related area like politics to do this we introduce a new graphical model that tightly couple image and caption through a modern face recognizer in addition to producing topic that are people specic using image a a guiding force the model also performs excellent soft clustering of face image using the language model to boost performance we present a variety of experiment comparing our method to recent development in topic modeling and joint image language modeling showing that our model ha lower perplexity for face identication than competing model and produce more rened topic 
conventional mutual information mi based registration using pixel intensity is time consuming and ignores spatial information which can lead to misalignment we propose a method to overcome these limitation by acquiring initial estimate of transformation parameter we introduce the concept of gradient intensity a a measure of spatial strength of an image in a given direction we determine the rotation parameter by maximizing the mi between gradient intensity histogram calculation of the gradient intensity mi function is extremely efficient our method is designed to be invariant to scale and translation between the image we then obtain estimate of scale and translation parameter using method based on the centroid of gradient image the estimated parameter are used to initialize an optimization algorithm which is designed to converge more quickly than the standard powell algorithm in close proximity of the minimum experiment show that our method significantly improves the performance of the registration task and reduces the overall computational complexity by an order of magnitude 
we propose a closely coupled object detection and segmentation algorithm for enhancing both process in a cooperative and iterative manner figure ground segmentation reduces the effect of background clutter on template matching the matched template provides shape constraint on segmentation more precisely we estimate the probability of each pixel belonging to the foreground by a weighted sum of the estimate based on shape and color alone the weight on the shape based estimate is related to the probability that a familiar object is present and is updated dynamically so that we enforce shape constraint only where the object is present experiment on detecting people in image of cluttered scene demonstrate that the proposed algorithm improves both segmentation and detection more accurate object boundary are extracted higher object detection rate and lower false alarm rate are achieved than performing the two process separately or sequentially 
face recognition and many medical imaging application require the computation of dense correspondence vector field that match one surface with another in brain imaging surface based registration is useful for tracking brain change and for creating statistical shape model of anatomy based on surface correspondence metric can also be designed to measure difference in facial geometry and expression to avoid the need for a large set of manually defined landmark to constrain these surface correspondence we developed an algorithm to automate the matching of surface feature it extends the mutual information method to automatically match general d surface including surface with a branching topology we use diffeomorphic flow to optimally align the riemann surface structure of two surface first we use holomorphic form to induce consistent conformal grid on both surface high genus surface are mapped to a set of rectangle in the euclidean plane and closed genus zero surface are mapped to the sphere next we compute stable geometric feature mean curvature and conformal factor and pull them back a scalar field onto the d parameter domain mutual information is used a a cost functional to drive a fluid flow in the parameter domain that optimally aligns these surface feature a diffeomorphic surface to surface mapping is then recovered that match surface in d lastly we present a spectral method that ensures that the grid induced on the target surface remain conformal when pulled through the correspondence field using the chain rule we express the gradient of the mutual information between surface in the conformal basis of the source surface this finite dimensional linear space generates all conformal reparameterizations of the surface illustrative experiment apply the method to face recognition and to the registration of brain structure such a the hippocampus in d mri scan a key step in understanding brain shape alteration in alzheimer s disease and schizophrenia 
this paper present an efficient algorithm for image segmentation and a framework for perceptual grouping it make an attempt to provide one way of combining bottom up and top down approach in image segmentation it generalizes the swendsen wang cut algorithm swc by barbu and zhu to make both way and m way cut and includes topology change process graph repartitioning and boundary diffusion the method directly work at a low temperature without using annealing we show that it is much faster than the ddmcmc approach tu and zhu and more robust than the swc method the result are demonstrated on the berkeley data set in perceptual grouping it integrates discriminative model learning computing a belief propagation algorithm bp by yedidia et al and swc into a three layer computing framework these method are realized a different level of approximation to an ideal generative model we demonstrate the algorithm on the problem of human body configuration 
a popular approach to problem in image classification is to represent the image a a bag of visual word and then employ a classifier to categorize the image unfortunately a significant shortcoming of this approach is that the clustering and classification are disconnected since the clustering into visual word is unsupervised the representation doe not necessarily capture the aspect of the data that are most useful for classification more seriously the semantic relationship between cluster is lost causing the overall classification performance to suffer we introduce discriminative cluster refinement dcr a method that explicitly model the pairwise relationship between different visual word by exploiting their co occurrence information the assigned class label are used to identify the co occurrence pattern that are most informative for object classification dcr employ a maximum margin approach to generate an optimal kernel matrix for classification one important benefit of dcr is that it integrates smoothly into existing bag of word information retrieval system by employing the set of visual word generated by any clustering method while dcr could improve a broad class of information retrieval system this paper focus on object category recognition we present a direct comparison with a state of the art method on the pascal database and show that cluster refinement result in a significant improvement in classification accuracy given a small number of training example 
we present a scalable approach to recognizing and describing complex activity in video sequence we are interested in long term sequential activity that may have several parallel stream of action our approach integrates temporal contextual and ordering constraint with output from low level visual detector to recognize complex long term activity we argue that a hierarchical objectoriented design lends our solution to be scalable in that higher level reasoning component are independent from the particular low level detector implementation and that recognition of additional activity and action can easily be added three major component to realize this design are a dynamic bayesian network structure for representing activity comprised of partially ordered sub action an object oriented action hierarchy for building arbitrarily complex action detector and an approximate viterbi like algorithm for inferring the most likely observed sequence of action additionally this study proposes the erlang distribution a a comprehensive model of idle time between action and frequency of observing new action we show result for our approach on real video sequence containing complex activity 
a visual word lexicon can be constructed by clustering primitive visual feature and a visual object can be described by a set of visual word such a bag of word representation ha led to many significant result in various vision task including object recognition and categorization however in practice the clustering of primitive visual feature tends to result in synonymous visual word that over represent visual pattern a well a polysemous visual word that bring large uncertainty and ambiguity in the representation this paper aim at generating a higher level lexicon i e visual phrase lexicon where a visual phrase is a meaningful spatially co occurrent pattern of visual word this higher level lexicon is much le ambiguous than the lower level one the contribution of this paper include a fast and principled solution to the discovery of significant spatial co occurrent pattern using frequent itemset mining a pattern summarization method that deal with the compositional uncertainty in visual phrase and a top down refinement scheme of the visual word lexicon by feeding back discovered phrase to tune the similarity measure through metric learning 
indisputably normalized cut is one of the most popular segmentation algorithm in computer vision it ha been applied to a wide range of segmentation task with great success a number of extension to this approach have also been proposed one that can deal with multiple class or that can incorporate a priori information in the form of grouping constraint however what is common for all these suggested method is that they are noticeably limited and can only address segmentation problem on a very specific form in this paper we present a reformulation of normalized cut segmentation that in a unified way can handle all type of linear equality constraint for an arbitrary number of class this is done by restating the problem and showing how linear constraint can be enforced exactly through duality this allows u to add group prior for example that certain pixel should belong to a given class in addition it provides a principled way to perform multiclass segmentation for task like interactive segmentation the method ha been tested on real data with convincing result 
abstract we propose a novel framework for consistent correspondence between arbitrary manifold mesh different from most existing method our approach directly map the connectivity of the source mesh onto the target mesh without needing to segment input mesh thus effectively avoids dealing with unstable extreme condition e g complex boundary or high genus in this paper firstly a novel mean value laplacian fitting scheme is proposed which aim at computing a shape preserving conformal correspondence directly in d to d space efficiently avoiding local optimum caused by the nearest point search and achieving good result even with only a few marker point secondly we introduce a vertex relocation and projection approach which refines the initial fitting result in the way of local conformity each vertex of the initial result is gradually projected onto the target model s surface to ensure a complete surface match furthermore we provide a fast and effective approach to automatically detect critic point in the context of consistent correspondence by fitting these critic point that capture the important feature of the target mesh theoutputcompatiblemesh matchesthetargetmesh s profile quite well compared with previous approach our scheme is robust fast and convenient thus suitable for common application 
the world is covered with million of webcam many transmit everything in their field of view over the internet hour a day a web search find public webcam in airport intersection classroom park shop ski resort and more even more private surveillance camera cover many private and public facility webcam are an endless resource but most of the video broadcast will be of little interest due to lack of activity we propose to generate a short video that will be a synopsis of an endless video stream generated by webcam or surveillance camera we would like to address query like i would like to watch in one minute the highlight of this camera broadcast during the past day the process includes two major phase i an online conversion of the video stream into a database of object and activity rather than frame ii a response phase generating the video synopsis a a response to the user s query to include maximum information in a short synopsis we simultaneously show activity that may have happened at different time the synopsis video can also be used a an index into the original video stream 
in foggy weather the contrast of image grabbed by invehicle camera in the visible light range is drastically degraded which make the current application very sensitive to weather condition an onboard vision system should take fog effect into account the effect of fog varies across the scene and are exponential with respect to the depth of scene point because it is not possible in this context to compute the road scene structure beforehand contrary to fixed camera surveillance a new scheme is proposed weather condition are first estimated and then used to restore the contrast according to a scene structure which is inferred a priori and refined during the restoration process based on the aimed application different algorithm with increasing complexity are proposed result are presented using sample road scene under foggy weather and assessed by computing the contrast before and after restoration 
this paper tackle the challenge of interactively retrieving visual scene within surveillance sequence acquired with fixed camera contrarily to today s solution we assume that no a priori knowledge is available so that the system must progressively learn the target scene thanks to interactive labelling of a few frame by the user the proposed method is based on very low cost feature extraction and integrates relevance feedback multiple instance svm classification and active learning each of these step run iteratively over the session and take advantage of the progressively increasing training set repeatable experiment on both simulated and real data demonstrate the efficiency of the approach and show how it allows reaching high retrieval performance 
a new technique for surface reconstruction is developed that us polarization information from two view one common problem arising from many multiple view technique is that of finding correspondence between pixel on each image in the new method these correspondence are found by exploiting the spontaneous polarization of light caused by reflection to recover surface normal these normal are then used to recover surface height the similarity between reconstructed surface region determines whether or not a pair of point correspond to each other the technique is thus able to overcome the convex concave ambiguity found in many single view technique because the technique relies on smooth surface region to detect correspondence rather than feature detection it is applicable to object normally inaccessible to stereo vision also due to this fact it is possible to remove noise without causing oversmoothing problem 
an interactive framework for soft segmentation and matting of natural image and video is presented in this paper the proposed technique is based on the optimal linear time computation of weighted geodesic distance to the user provided scribble from which the whole data is automatically segmented the weight are based on spatial and or temporal gradient without explicit optical flow or any advanced and often computationally expensive feature detector these could be naturally added to the proposed framework a well if desired in the form of weight in the geodesic distance a localized refinement step follows this fast segmentation in order to accurately compute the corresponding matte function additional constraint into the distance definition permit to efficiently handle occlusion such a people or object crossing each other in a video sequence the presentation of the framework is complemented with numerous and diverse example including extraction of moving foreground from dynamic background and comparison with the recent literature 
this paper present a practical method for finding the provably globally optimal solution to numerous problem in projective geometry including multiview triangulation camera resectioning and homography estimation unlike traditional method which may get trapped in local minimum due to the non convex nature of these problem this approach provides a theoretical guarantee of global optimality the formulation relies on recent development in fractional programming and the theory of convex underestimators and allows a unified framework for minimizing the standard l norm of reprojection error which is optimal under gaussian noise a well a the more robust l norm which is le sensitive to outlier the efficacy of our algorithm is empirically demonstrated by good performance on experiment for both synthetic and real data an open source matlab toolbox that implement the algorithm is also made available to facilitate further research 
so far global optimization technique have been developed independently for the task of shape matching and image segmentation in this paper we show that both task can in fact be solved simultaneously using global optimization by computing cycle of minimal ratio in a large graph spanned by the product of the input image and a shape template we are able to compute globally optimal segmentation of the image which are similar to a familiar shape and located in place of strong gradient the presented approach is translation invariant and robust to local and global scaling and rotation of the given shape we show how it can be extended to incorporate invariance to similarity transformation the particular structure of the graph allows for run time and memory efficient implementation highly parallel implementation on graphic card allow to produce globally optimal solution in a few second only 
this paper describes our work on classification of outdoor scene first image are partitioned into region using one class classification and patch based clustering algorithm where one class classifier model the region with relatively uniform color and texture property and clustering of patch aim to detect structure in the remaining region next the resulting region are clustered to obtain a codebook of region type and two model are constructed for scene representation a bag of individual region representation where each region is regarded separately and a bag of region pair representation where region with particular spatial relationship are considered together given theserepresentations sceneclassification is done using bayesian classifier we also propose a novel region selection algorithm that identifies region type that are frequently found in a particular class of scene but rarely exist in other class and also consistently occur together in the same class of scene experiment on the labelme data set showed that the proposed model significantly outperform a baseline global feature based approach 
this paper detail an empirical study of large image set taken by static camera these image have consistent correlation over the entire image and over time scale of day to month simple second order statistic of such image set show vastly more structure than exists in generic natural image or video from moving camera using a slight variant to pca we can decompose all camera into comparable component and annotate image with respect to surface orientation weather and seasonal change experiment are based on a data set from camera across the united state which have collected more than million image over the the last month 
the paper proposes an edge based multi object tracking framework which deal with tracking multiple object with occlusion using a variational particle filter object is modelled by a mixture of a non parametric contour model and a non parametric edge model using kernel density estimation visual tracking with a mixture model is formulated a a bayesian incomplete data problem where measurement in an image are associated with a generative model which is a mixture of mixture model including object model and a clutter model and unobservable association of measurement to density in the generative model are regarded a missing data a likelihood for tracking multiple object jointly with an exclusion principle is presented where it is assumed that one measurement can only be generated from one density and one density can generate multiple measurement and it significantly reduces the complexity of enumerating all feasible event to address the curse of dimensionality in tracking multiple object jointly a variational particle filter vpf is proposed for multi object tracking where the proposal distribution is based on the approximated posterior from variational inference rather than using the prior a the proposal distribution in sampling importance resampling sir particle filter with the variational particle filter the number of particle needed for multi object tracking can be significantly reduced experimental result in challenging sequence demonstrate the robust performance of the proposed method 
we present a novel categorical object detection scheme that us only local contour based feature a two stage partially supervised learning architecture is proposed a rudimentary detector is learned from a very small set of segmented image and applied to a larger training set of un segmented image the second stage bootstrap these detection to learn an improved classifier while explicitly training against clutter the detector are learned with a boosting algorithm which creates a location sensitive classifier using a discriminative set of feature from a randomly chosen dictionary of contour fragment we present result that are very competitive with other state of the art object detection scheme and show robustness to object articulation clutter and occlusion our major contribution are the application of boosted local contour based feature for object detection in a partially supervised learning framework and an efficient new boosting procedure for simultaneously selecting feature and estimating per feature parameter 
we propose a novel unsupervised learning framework for activity perception to understand activity in complicated scene from visual data we propose a hierarchical bayesian model to connect three element low level visual feature simple atomic activity and multi agent interaction atomic activity are modeled a distribution over low level visual feature and interaction are modeled a distribution over atomic activity our model improve existing language model such a latent dirichlet allocation lda and hierarchical dirichlet process hdp by modeling interaction without supervision our data set are challenging video sequence from crowded traffic scene with many kind of activity co occurring our approach provides a summary of typical atomic activity and interaction in the scene unusual activity and interaction are found with natural probabilistic explanation our method support flexible high level query on activity and interaction using atomic activity a component 
given point correspondence in multiple perspective view of a scene containing multiple rigid body motion we present an algorithm for segmenting the correspondence according to the multiple motion we exploit the fact that when the depth of the point are known the point trajectory associated with a single motion live in a subspace of dimension at most four thus motion segmentation with known depth can be achieved by method of subspace separation such a gpca or lsa when the depth are unknown we proceed iteratively given the segmentation we compute the depth using standard technique given the depth we use gpca or lsa to segment the scene into multiple motion experiment on thehopkins database show that our method outperforms existing affine method in term of segmentation error and execution time our method achieves an error of on sequence 
we present the first method to compute depth cue from image taken solely under uncalibrated near point lighting a stationary scene is illuminated by a point source that is moved approximately along a line or in a plane we observe the brightness profile at each pixel and demonstrate how to obtain three novel cue plane scene intersection depth ordering and mirror symmetry these cue are defined with respect to the line plane in which the light source move and not the camera viewpoint plane scene intersection are detected by finding those scene point that are closest to the light source path at some time instance depth ordering for scene with homogeneous brdfs is obtained by sorting pixel according to their shortest distance from a plane containing the light source mirror symmetry pair for scene with homogeneous brdfs are detected by reflecting scene point across a plane in which the light source move we show analytic result for lambertian object and demonstrate empirical evidence for a variety of other brdfs 
this poster describes our recently developed real time projector camera system for interaction with chinese inkand wash cartoon we implement a real time interactive water simulation under the acceleration of gpu together with a sensing subsystem using computer vision technique combined with chinese stylized fish rendered in process the system provides real time interaction with traditional chinese painting by stirring up the still water fish and other essential element of chinese painting we hope to present new interaction technique and more lively chinese painting scenery compared to those in traditional static setting 
we investigate the problem of learning optimal descriptor for a given classification task many hand crafted descriptor have been proposed in the literature for measuring visual similarity looking past initial difference what really distinguishes one descriptor from another is the tradeoff that it achieves between discriminative power and invariance since this trade off must vary from task to task no single descriptor can be optimal in all situation our focus in this paper is on learning the optimal tradeoff for classification given a particular training set and prior constraint the problem is posed in the kernel learning framework we learn the optimal domain specific kernel a a combination of base kernel corresponding to base feature which achieve different level of trade off such a no invariance rotation invariance scale invariance affine invariance etc this lead to a convex optimisation problem with a unique global optimum which can be solved for efficiently the method is shown to achieve state of the art performance on the uiuc texture oxford flower and caltech datasets 
we investigate the feasibility of reconstructing an arbitrarily shaped specular scene refractive or mirror like from one or more viewpoint by reducing shape recovery to the problem of reconstructing individual d light path that cross the image plane we obtain three key result first we show how to compute the depth map of a specular scene from a single viewpoint when the scene redirects incoming light just once second for scene where incoming light undergoes two refraction or reflection we show that three viewpoint are sufficient to enable reconstruction in the general case third we show that it is impossible to reconstruct individual light path when light is redirected more than twice our analysis assumes that for every point on the image plane we know at least one d point on it light path this lead to reconstruction algorithm that rely on an environment matting procedure to establish pixel to point correspondence along a light path preliminary result for a variety of scene mirror glass etc are also presented 
manuallabelingofobjectsinvideosis atedioustask we presentanapproachwhichautomaticallypropagatesthelabels from a single frame to the next one we tackle the challengingproblem of trackingsegmented region by combining keypoint tracking with an advanced multiple region matching strategy based on inclusion similarity and connected region we ran experiment on a frame driving video sequence for which we produced the corresponding handlabeled groundtruth we make this valuable dataset available for the research community we show our technique can accommodate variation in segmentation and correct them even in presence of multiple independent motion and partial occlusion result show that most of the labeled pixel can be correctly propagated even after a hundred frame the performance of this automatic propagation mechanism over many frame can greatly reduce the user effort in the task of video object labeling 
a wide range of low level vision problem have been formulated in term of finding the most probable assignment of a markov random field or equivalently the lowest energy configuration perhaps the most successful example is stereo vision for the stereo problem it ha been shown that finding the global optimum is np hard but good result have been obtained using a number of approximate optimization algorithm in this paper we show that for standard benchmark stereo pair the global optimum can be found in about minute using a variant of the belief propagation bp algorithm we extend previous theoretical result on reweighted belief propagation to account for possible tie in the belief and using these result we obtain easily checkable condition that guarantee that the bp disparity are the global optimum we verify experimentally that these condition are typically met for the standard benchmark stereo pair and discus the implication of our result for further progress in stereo 
in this paper we derive differential equation for evolving radial basis function rbfs to solve segmentation problem the differential equation result from applying variational calculus to energy functionals designed for image segmentation our methodology support evolution of all parameter of each rbf including it position weight orientation and anisotropy if present our framework is general and can be applied to numerous rbf interpolants the resulting approach retains some of the ideal feature of implicit active contour like topological adaptivity while requiring low storage overhead due to the sparsity of our representation which is an unstructured list of rbfs we present the theory behind our technique and demonstrate it usefulness for image segmentation 
this paper describes a photometric stereo method designed for surface with spatially varying brdfs including surface with both varying diffuse and specular property our method build on the observation that most object are composed of a small number of fundamental material this approach recovers not only the shape but also material brdfs and weight map yielding compelling result for a wide variety of object we also show example of interactive lighting and editing operation made possible by our method 
the k nearest neighbour knn rule is a simple and effective method for multi way classication that is much used in computer vision however it performance depends heavily on the distance metric being employed the recently proposed large margin nearest neighbour lmnn classier learns a distance metric for knn classication and thereby improves it accuracy learning involves optimizing a convex problem using semidenite programming sdp we extend the lmnn framework to incorporate knowledge about invariance of the data the main contribution of our work are three fold i invariance to multivariate polynomial transformation are incorporated without explicitly adding more training data during learning these can approximate common transformation such a rotation and afnities ii the incorporation of different regularizers on the parameter being learnt and iii for all these variation we show that the distance metric can still be obtained by solving a convex sdp problem we call the resulting formulation invariant lmnn ilmnn classier we test our approach to learn a metric for matching i feature vector from the standard iris dataset and ii face obtained from tv video an episode of buffy the vampire slayer we compare our method with the state of the art classier s and demonstrate improvement 
belief propagation over pairwise connected markov random field ha become a widely used approach and ha been successfully applied to several important computer vision problem however pairwise interaction are often insufficient to capture the full statistic of the problem higher order interaction are sometimes required unfortunately the complexity of belief propagation is exponential in the size of the largest clique in this paper we introduce a new technique to compute belief propagation message in time linear with respect to clique size for a large class of potential function over real valued variable we demonstrate this technique in two application first we perform efficient inference in graphical model where the spatial prior of natural image is captured by clique this approach show significant improvement over the commonly used pairwise connected model and may benefit a variety of application using belief propagation to infer image or range image finally we apply these technique to shape from shading and demonstrate significant improvement over previous method both in quality and in flexibility 
automatic evaluation of visual tracking algorithm in the absence of ground truth is a very challenging and important problem in the context of online appearance modeling there is an additional ambiguity involving the correctness of the appearance model in this paper we propose a novel performance evaluation strategy for tracking system based on particle filter using a time reversed markov chain starting from the latest observation the time reversed chain is propagated back till the starting time t of the tracking algorithm the posterior density of the time reversed chain is also computed the distance between the posterior density of the time reversed chain at t and the prior density used to initialize the tracking algorithm form the decision statistic for evaluation it is postulated that when the data is generated true to the underlying model the decision statistic take a low value we empirically demonstrate the performance of the algorithm against various common failure mode in the generic visual tracking problem finally we derive a small frame approximation that allows for very efficient computation of the decision statistic 
it is well known that forward motion induces a large number of local minimum in the instantaneous least square reprojection error this is caused in part by singularity in the error landscape around the forward direction and present a challenge in using existing algorithm for structure from motion in autonomous navigation application in this paper we prove that imposing a bound on the reconstructed depth of the scene make the least square reprojection error continuous this ha implication for autonomous navigation a it suggests simple modification for existing algorithm to minimize the effect of local minimum in forward translation 
abstract this paper proposes an approach to simultaneously detect and segment object of a known category edgelet feature are used to capture the local shape of the object for each feature a pair of base classifier for detection and segmentation is built the base segmentor is designed to predict the per pixel figure ground assignment around a neighborhood of the edgelet based on the feature response the neighborhood is represented a an effective field which is determined by the shape of the edgelet a boosting algorithm is used to learn the ensemble classifier with cascade decision strategy from the base classifier pool the simultaneousness is achieved for both training and testing the system is evaluated on a number of public image set and compared with several previous method 
the compositional nature of visual object significantly limit their representation complexity and render learning of structured object model tractable adopting this modeling strategy we both i automatically decompose object into a hierarchy of relevant composition and we ii learn such a compositional representation for each category without supervision the compositional structure support feature sharing already on the lowest level of small image patch composition are represented a probability distribution over their constituent part and the relation between them the global shape of object is captured by a graphical model which combine all composition inference based on the underlying statistical model is then employed to obtain a category level object recognition system experiment on large standard benchmark datasets underline the competitive recognition performance of this approach and they provide insight into the learned compositional structure of object 
due to it semi rigid shape and robustness against change over time the ear ha become an increasingly popular biometric feature it ha been shown that combining individual biometric method into multi biometric system improves recognition what feature should be used how they should be captured what algorithm should be used and how they should be combined are all open question in this paper we discus several existing method of combination and the recognition rate of each 
in this paper we consider the problem of compositing a scene from multiple image multiple image for example can be obtained by varying the exposure of the camera by changing the object at focus or by simply sampling a video sequence at arbitrary time instant we develop this problem in an optimization framework and then adopt a variational approach to derive a generalized algorithm which will be able to solve diverse application depending on the nature of the input image our approach ha distinct advantage over the existing digital compositing technique such a alpha matting and alpha blending which require an explicit preparation of the matte while there is no such requirement in the proposed technique we demonstrate the usefulness of our approach through result from diverse application in computer vision 
in order to achieve seamless imagery in a planar multiprojector display geometric distortion and misalignment of image within and across projector have to be removed camera based calibration method are popular for achieving this in an automated fashion previous method for geometric calibration fall into two category a method that model the geometric function relating the projector to camera using simple linear model like homography to calibrate the display these model assume perfect linear device and cannot address projector non linearity like lens distortion which are common in most commodity projector b method that use piecewise linear approximation to model the relationship between projector and camera these require a dense sampling of the function space to achieve good calibration in this paper we present a new closed form model that relates projector to camera in planar multi projector display using rational bezier patch this model overcomes the shortcoming of the previous method by allowing for projector with significant lens distortion it can be further used to develop an efficient and accurate geometric calibration method with a sparse sampling of the function 
this paper present a new structure based interest region detector called principal curvature based region pcbr which we use for object class recognition the pcbr interest operator detects stable watershed region within the multi scale principal curvature image to detect robust watershed region we clean a principal curvature image by combining a grayscale morphological close with our new eigenvector flow hysteresis threshold robustness across scale is achieved by selecting the maximally stable region across consecutive scale pcbr typically detects distinctive pattern distributed evenly on the object and it show significant robustness to local intensity perturbation and intra class variation we evaluate pcbr both qualitatively through visual inspection and quantitatively by measuring repeatability and classification accuracy in real world object classrecognitionproblems experiment on different benchmark datasets show that pcbr is comparable or superior to state of art detector for both feature matching and object recognition moreover we demonstrate the application of pcbr to symmetry detection 
ricci flow is a powerful curvature flow method in geometric analysis this work is the first application of surface ricci flow in computer vision we show that previous method based on conformal geometry such a harmonic map and least square conformal map which can only handle d shape with simple topology are subsumed by our ricci flow based method which can handle surface with arbitrary topology because the ricci flow method is intrinsic and depends on the surface metric only it is invariant to rigid motion scaling and isometric and conformal deformation the solution to ricci flow is unique and it computation is robust to noise our ricci flow based method can convert all d problem into d domain and offer a general framework for d surface analysis large non rigid deformation can be registered with feature constraint hence we introduce a method that constrains ricci flow computation using feature point and feature curve finally we demonstrate the applicability of this intrinsic shape representation through standard shape analysis problem such a d shape matching and registration 
we describe a method of representing human activity that allows a collection of motion to be queried without example using a simple and effective query language our approach is based on unit of activity at segment of the body that can be composed across space and across the body to produce complex query the presence of search unit is inferred automatically by tracking the body lifting the track to d and comparing to model trained using motion capture data we show result for a large range of query applied to a collection of complex motion and activity our model of short time scale limb behaviour are built using labelled motion capture set we compare with discriminative method applied to tracker data our method offer significantly improved performance we show experimental evidence that our method is robust to view direction and is unaffected by the change of clothing 
in this paper we propose a new framework to simultaneously segment and register lung and tumor in serial ct data our method assumes nonrigid transformation on lung deformation and rigid structure on the tumor we use the bspline based nonrigid transformation to model the lung deformation while imposing rigid transformation on the tumor to preserve the volume and the shape of the tumor in particular we set the control point within the tumor to form a control mesh and thus assume the tumor region follows the same rigid transformation a the control mesh for segmentation we apply a d graph cut algorithm on the d lung and tumor datasets by iteratively performing segmentation and registration our method achieves highly accurate segmentation and registration on serial ct data finally since our method eliminates the possible volume variation of the tumor during registration we can further estimate accurately the tumor growth an important evidence in lung cancer diagnosis initial experiment on five set of patient serial ct data show that our method is robust and reliable 
to implement a persistent tracker we build a set of viewdependent object appearance model adaptively and automatically while tracking an object under different viewing angle this collection of acquired model is indexed with respect to the view sphere the acquired model aid recovery from tracking failure due to occlusion and changing view angle in this paper view dependent object appearance is represented by intensity patch around detected harris corner the intensity patch from a model are matched to the current frame by solving a bipartite linear assignment problem with outlier exclusion and missed inlier recovery based on these reliable match the change in object rotation translation and scale is estimated between consecutive frame using procrustes analysis the experimental result show good performance using a collection of view specific patch based model for detection and tracking of vehicle in low resolution airborne video 
we present a new approach to learning image metric the main advantage of our method lie in a formulation that requires only a few pairwise example apparently based on the little amount of side information it would take a very effective learning scheme to yield a useful image metric our algorithm achieves this goal by addressing two key issue first we establish a global local glocal image representation that induces two structure meaningful vector space to respectively describe the global and the local image property second we develop a metric optimization framework that find an optimal bilinear transform to best explain the given side information we emphasize it is the glocal image representation that make the use of bilinear transform more powerful experimental result on classification of face image and visual tracking are included to demonstrate the contribution of the proposed method 
visually extracted d and d information have their own advantage and disadvantage that complement each other therefore it is important to be able to switch between the different dimension according to the requirement of the problem and use them together to combine the reliability of d information with the richness of d information in this article we use d and d information in a featurebased vision system and demonstrate their complementary property on different application namely depth prediction scene interpretation grasping from vision and object learning 
this paper proposes the problem of unsupervised extraction of texture element called texels which repeatedly o ccur in the image of a frontally viewed homogeneous d planar texture and present a solution d texture here mean that the physical texels are thin object lying along a surface that may partially occlude one another the image texture is represented by the segmentation tree whose struc ture capture the recursive embedding of region obtained from a multiscale image segmentation in the segmentation tree the texels appear a subtrees with similar structure with node having similar photometric and geometric property a new learning algorithm is proposed for fusing these similar subtrees into a tree union which register a ll visible texel part and thus represents a statistical gen erative model of the complete unoccluded texel the learning algorithm involves concurrent estimation of texel tree structure a well a the probability distribution of it n ode property texel detection and segmentation are achieved simultaneously by matching the segmentation tree of a new image with the texel model experiment conducted on a newly compiled dataset containing d natural texture demonstrate the validity of our approach 
in this paper we propose an approach to vehicle classification under a mid field surveillance framework we develop a repeatable and discriminative feature based on edge point and modified sift descriptor and introduce a rich representation for object class experimental result show the proposed approach is promising for vehicle classification in surveillance video despite great challenge such a limited image size and quality and large intra class variation comparison demonstrate the proposed approach outperforms other method 
we describe an unsupervised method to segment object detected in image using a novel variant of an interest point template which is very efficient to train and evaluate once an object ha been detected our method segment an image using a conditional random field crf model this model integrates image gradient the location and scale of the object the presence of object part and the tendency of these part to have characteristic pattern of edge nearby we enhance our method using multiple unsegmented image of object to learn the parameter of the crf in an iterative conditional maximization framework we show quantitative result on image of real scene that demonstrate the accuracy of segmentation 
we propose a method for reducing out of focus blur caused by projector projection in this method we estimate the point spread function psf of the out of focus blur in the image projected onto the screen by comparing thescreenimagecapturedbyacamerawiththeoriginalimage projected by the projector according to the estimated psf theprojectedimageispre corrected sothatthescreen imagecanbedeblurred experimentalresultsshowthatour method can reduce out of focus projection blur 
this paper describes a patch based approach for rapid image correlation or template matching by representing a template image with an ensemble of patch the method is robust with respect to variation such a local appearance variation partial occlusion and scale change rectangle filter are applied to each image patch for fast filtering based on the integral image representation a new method is developed for feature dimension reduction by detecting the salient image structure given a single image experiment on a variety image show the success of the method in dealing with different variation in the test image in term of computation time the approach is faster than traditional method by up to two order of magnitude and is at least three time faster than a fast implementation of normalized cross correlation 
in this paper we describe a pas iterative scheme to solve the generalpartialdifferentialequation pde related to the shape from shading sfs problem under both distant and close point light source in particular we discus it application in restoring warped document image that often appear in the daily snapshot the proposed method consists of two step first the image irradiance equation is formulated a a static hamilton jacobi hj equation and solved using a fast sweeping strategy with lax friedrichs hamiltonian however abrupt error may arise when applying to real document image due to noise in the approximated shading image to reduce the noise sensitivity a minimization method thus follows to smooth out the abrupt ridge in the initial result and produce a better reconstruction experiment on synthetic surface show promising result comparing to the ground truth data moreover a general framework is developed which demonstrates that the sfs method can help to remove both geometric and photometric distortion in warped document image for better visual appearance and higher recognition rate 
in this paper we propose a novel online learning method which can learn appearance model incrementally from a given video stream the data of each frame in the video can be discarded a soon a it ha been processed we only need to maintain a few linear eigenspace model and a transition matrix to approximately construct face appearance manifold it is convenient to use these learnt model for video based face recognition there are mainly two contribution in this paper first we propose an algorithm which can learn appearance model online without using a pre trained model second we propose a method for eigenspace splitting to prevent that most sample cluster into the same eigenspace this is useful for clustering and classification experimental result show that the proposed method can both learn appearance model online and achieve high recognition rate 
motion blur can degrade the quality of image and is considered a nuisance for computer vision problem in this paper we show that motion blur can in fact be used for increasing the resolution of a moving object our approach utilizes the information in a single motion blurred image without any image prior or training image a the blur size increase the resolution of the moving object can be enhanced by a larger factor albeit with a corresponding increase in reconstruction noise traditionally motion deblurring and super resolution have been ill posed problem using a coded exposure camera that preserve high spatial frequency in the blurred image we present a linear algorithm for the combined problem of deblurring and resolution enhancement and analyze the invertibility of the resulting linear system we also show a method to selectively enhance the resolution of a narrow region of high frequency feature when the resolution of the entire moving object cannot be increased due to small motion blur result on real image showing up to four time resolution enhancement are presented 
the paper introduces an action recognition framework that us concept from the theory of chaotic system to model and analyze nonlinear dynamic of human action trajectory of reference joint are used a the representation of the non linear dynamical system that is generating the action each trajectory is then used to reconstruct a phase space of appropriate dimension by employing a delay embedding scheme the property of the reconstructed phase space are captured in term of dynamical and metric invariant that include lyapunov exponent correlation integral and correlation dimension finally the action is represented by a feature vector which is a combination of these invariant over all the reference trajectory our contribution in this paper include investigation of the appropriateness of theory of chaotic system for human action modelling and recognition a new set of feature to characterize nonlinear dynamic of human action experimental validation of the feasibility and potential merit of carrying out action recognition using method from theory of chaotic system 
large scale d reconstruction ha recently received much attention from the computer vision community bundle adjustment is a key component of d reconstruction problem however traditional bundle adjustment algorithm require a considerable amount of memory and computational resource in this paper we present an extremely efficient inherently out of core bundle adjustment algorithm we decouple the original problem into several submaps that have their own local coordinate system and can be optimized in parallel a key contribution to our algorithm is making a much progress towards optimizing the global non linear cost function a possible using the fragment of the reconstruction that are currently in core memory this allows u to converge with very few global sweep often only two through the entire reconstruction we present experimental result on large scale d reconstruction datasets both synthetic and real 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper we consider the problem of solving geometric reconstruction problem with the l norm previous work ha shown that globally optimal solution can be computed reliably for a series of such problem the method for computing the solution have relied on the property of quasiconvexity for quasiconvex problem checking if there exists a solution below a certain objective value can be posed a a convex feasibility problem to solve the l problem one typically employ a bisection algorithm generating a sequence of convex problem in this paper we present more efficient way of computing the solution we derive necessary and sufficient condition for a global optimum a key property is that of pseudoconvexity which is a stronger condition than quasiconvexity the result open up the possibility of using local optimization method for more efficient computation we present two such algorithm the first one is an interior point method that us the kkt condition and the second one is similar to the bisection method in the sense it solves a sequence of socp problem result are presented and compared to the standard bisection algorithm on real data for various problem and scenario with improved performance 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper we propose a novel tree structured multi view face detector mvfd which adopts the coarse to fine strategy to divide the entire face space into smaller and smaller subspace for this purpose a newly extended boosting algorithm named vector boosting is developed to train the predictor for the branching node of the tree that have multi component output a vector our mvfd cover a large range of the face space say rotation in plane rip and rotation off plane rop and achieves high accuracy and amazing speed about m per frame on a video sequence compared with previous published work a a result by simply rotating the detector and a rotation invariant rip mvfd is implemented that achieves real time performance fps on a video sequence with high accuracy 
abstract introductionone of the main goal of computer vision research is to develop method for recognition of object and event asubclass of these problem is the recognition of human and their activity in this chapter we summarize someof the recent method developed for human recognition using face and gait gait recognition is related to the broader problem of human motion modeling which ha very important implicationsfor different area like surveillance medical diagnosis 
in this paper we focus on the design of markov chain monte carlo technique in a statistical registration frame work based on finite element basis fe due to the use of fe basis this framework ha specific feature the main feature is that displacement random field are markovian we construct two hybrid gibbs metropolis hasting algorithm which take fully advantage of this markovian property the second technique is defined in a coarse to fine way by introducing a penalization on the sampled posterior distribution we present some promising result suggestin g that both technique can accurately register image exper iments also show that the penalized technique is more robust to local maximum of the posterior distribution than the first technique this study is a preliminary step towards the esti mation of model parameter in complex image registration problem 
detecting and segmenting free form object from cluttered background is a challenging problem in computer vision signature detection in document image is one classic example and a of yet no reasonable solution have been presented in this paper we propose a novel multi scale approach to jointly detecting and segmenting signature from document with diverse layout and complex background rather than focusing on local feature that typically have large variation our approach aim to capture the structural saliency of a signature by searching over multiple scale this detection framework is general and computationally tractable we present a saliency measure based on a signature production model that effectively quantifies the dynamic curvature of d contour fragment our evaluation using large real world collection of handwritten and machine printed document demonstrates the effectiveness of this joint detection and segmentation approach 
wecombine detection andtracking technique to achieve robust d motion recovery of people seen from arbitrary viewpoint by a single and potentially moving camera we rely on detecting key posture which can be done reliably using a motion model to infer d pose between consecutive detection and finally refining them over the whole sequence using a generative model wedemonstrate our approach inthe case of peoplewalking against cluttered background and filmed using a moving camera which precludes the use of simple background subtraction technique in this case the easy to detect posture is the one that occurs at the end of each step when people have their leg furthest apart 
the estimation of head pose angle from face image is an integral component of face recognition system human computer interface and other human centered computing application to determine the head pose face image with varying pose angle can be considered to be lying on a smooth low dimensional manifold in high dimensional feature space while manifold learning technique capture the geometrical relationship between data point in the highdimensional image feature space the pose label information of the training data sample are neglected in the computation of these embeddings in this paper we propose a novel supervised approach to manifold based non linear dimensionality reduction for head pose estimation the biased manifold embedding bme framework is pivoted on the ideology of using the pose angle information of the face image to compute a biased neighborhood of each point in the feature space before determining the low dimensional embedding the proposed bme approach is formulated a an extensible framework and validated with the isomap locally linear embedding lle and laplacian eigenmaps technique a generalized regression neural network grnn is used to learn the non linear mapping and linear multi variate regression is finally applied on the lowdimensional space to obtain the pose angle we tested this approach on face image of individual with pose angle varying from to with a granularity of the result showed substantial reduction in the error of pose angle estimation and robustness to variation in feature space dimensionality of embedding and other parameter 
in this paper we present an empirical study of object category recognition using generalized sample and a set of sequential test we study category each consisting of a small data set of instance to increase the amount of training data we have we use a compositional object model to learn a representation for each category from which we select additional template with varied appearance from the training set these sample better span the appearance space and form an augmented training set t of training template to perform recognition on a testing image we use a set of sequential test to project t into different representation space to narrow the number of candidate match in t we use graphlets structural element a our local feature and model t at each stage using histogram of graphlets over category histogram of graphlets over object instance histogram of pair of graphlets over object shape context each test is increasingly computationally expensive and by the end of the cascade we have a small candidate set remaining to use with our most powerful test a top down graph matching algorithm we achieve an classification rate on classifying testing image in category more accurate than a method without generalized sample 
in this paper we address the problem of estimating the motion of fluid flow that are visualized through a schlieren system such a system is well known in fluid mechanic a it enables the visualization of unseeded flow a the resulting image exhibit very low photometric contrast classical motion estimation method based on the brightness consistency assumption correlation based approach optical flow method are completely inefficient this work aim at proposing a sound energy based estimator dedicated to these particular image the energy function to be minimized is composed of a a novel data term describing the fact that the observed luminance is linked to the gradient of the fluid density and b a specific div curl regularization term the relevance of our estimator is demonstrated on real world sequence 
the paper deal with grouping of edge to contour of shape using only local symmetry and continuity shape skeleton are used to generate the search space for a version of the markov chain monte carlo approach utilizing particle filter to find the most likely skeleton intuitively this mean that grouping of edge segment is performed by walking along the skeleton the particle search which is an adapted version of a successful algorithm in robot mapping is assisted by a reference model of a shape which is expressed a the sequence of sample point and radius of maximal skeleton disk this model is sufficiently flexible to represent non rigid deformation but restrictive enough to perform well on real noisy image data the order of skeleton point and their corresponding segment found by the particle defines the grouping 
abstract a recognition scheme that scale efficiently to a large number of object is presented the efficiency and quality is exhibited in a live demonstrationthat recognizescd cover from a database of image of popular music cd s the scheme build upon popular technique of indexing descriptor extracted from local region and is robust to background clutter and occlusion the local region descriptor are hierarchically quantized in a vocabulary tree the vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently which we show experimentally lead to a dramatic improvement in retrieval quality the most significant property of the scheme is that the tree directly definesthe quantization the quantization and the indexing are therefore fully integrated essentially being one and the same the recognition quality is evaluated through retrieval on a database with ground truth showing the power of the vocabulary tree approach going a high a million image 
we propose a new method to segment d structure with competitive level set driven by a shape model and fuzzy control to this end several contour evolve simultaneously toward previously defined target the main contribution of this paper is the original introduction of prior information provided by a shape model which is used a an anatomical atlas into a fuzzy decision system the shape information is combined with the intensity distribution of the image and the relative position of the contour this combination automatically determines the directional term of the evolution equation of each level set this lead to a local expansion or contraction of the contour in order to match the border of their respective target the shape model is produced with a principal component analysis and the resulting mean shape and variation are used to estimate the target location and the fuzzy state corresponding to the distance between the current contour and the target by combining shape analysis and fuzzy control we take advantage of both approach to improve the level set segmentation process with prior information experiment are shown for the d segmentation of deep brain structure from mri and a quantitative evaluation is performed on a volume dataset 
thenon negativityofcolorsignalsimplies thattheyspan a conical space with a hyperbolic geometry we use perspective projection to separate intensity from chromaticity and for d color descriptor the chromatic property are represented by point on the unit disk descriptor derived from the same object point but under different imaging condition can be joined by a hyperbolic geodesic the property of this model are investigated using multichannel image of natural scene and black body illuminant of different temperature we show over a series of static scene with different illuminant how illumination change influence the hyperbolic distance and the geodesic descriptor derived from conventional rgb image are also addressed function value this implies that these function are always located in the positive part of the corresponding function space these region in the function space have a special geometry and admissible transformation of these function can never move the resulting function outside these region based on this observation we argue that the function space of interest in color signal processing can be described by direct product of the positive axis representing intensity and the unit ball describing chromaticity related property the property related to intensity are investigated by gray value based image processing and here we 
determining the status of a runway prior to landing is essential for any aircraft whether manned or unmanned in this paper we present a method that can detect moving object on the runway from an onboard infrared camera prior to the landing phase since the runway is a planar surface we first locally stabilize the sequence to automatically selected reference frame using feature point in the neighborhood of the runway next we normalize the stabilized sequence to compensate for the global intensity variation caused by the gain control of the infrared camera we then create a background model to learn an appearance model of the runway finally we identify moving object by comparing the image sequence with the background model we have tested our system with both synthetic and real world data and show that it can detect distant moving object on the runway we also provide a quantitative analysis of the performance with respect to variation in size direction and speed of the target 
our problem is that of recovering in one view the d euclidean structure induced by the projection of n parallel circle this structure is a prerequisite for camera calibration and pose computation until now no general method ha been described for n the main contribution of this work is to state the problem in term of a system of linear equation to solve we give a closed form solution a well a bundle adjustment like refinement increasing the technical applicability and numerical stability our theoretical approach generalizes and extends all those described in existing work for n in several respect a we can treat simultaneously pair of orthogonal line and pair of circle within a unified framework the proposed algorithm may be easily implemented using well known numerical algorithm it performance is illustrated by simulation and experiment with real image 
we propose a method for removing non uniform motion blur from multiple blurry image traditional method focus on estimating a single motion blur kernel for the entire image in contrast we aim to restore image blurred by unknown spatially varying motion blur kernel caused by different relative motion between the camera and the scene our algorithm simultaneously estimate multiple motion motion blur kernel and the associated image segment we formulate the problem a a regularized energy function and solve it using an alternating optimization technique realworld experiment demonstrate the effectiveness of the proposed method 
non rigid object alignment is especially challenging when only a single appearance template is available and target and template image fail to match two source of discrepancy between target and template are change in illumination and non rigid motion because most existing method rely on a holistic representation for the alignment process they require multiple training image to capture appearance variance we developed a patch based method that requires only a single appearance template of the object specifically we fit the patch based face model to an unseen image using an exhaustive local search and constrain the local warp update within a global warping space our approach is not limited to intensity value or gradient and therefore offer a natural framework to integrate multiple local feature such a filter response to increase robustness to large initialization error illumination change and non rigid deformation this approach wa evaluated experimentally on more than subject for multiple illumination condition and facial expression in all the experiment our patch based method outperforms the holistic gradient descent method in term of accuracy and robustness of feature alignment and image registration 
this paper present a new technique to reduce the storage cost of high quality d video in d video a sequence of d object represents scene in motion every frame is composed by one or several accurate d mesh with attached high fidelity property such a color and texture each frame is acquired at video rate the entire video sequence requires a huge amount of free disk space to overcome this issue we propose an original approach using reeb graph which are well known topology based shape descriptor in particular we take advantage of the augmented multiresolution reeb graph property to store the relevant information of the d model of each frame this graph structure ha shown it efficiency a a motion descriptor being able to track similar node all along the d video sequence therefore we can describe and reconstruct the d model of all frame with a very low cost data size the algorithm ha been implemented a a fully automatic d video compression system our experiment show the robustness and accuracy of the proposed technique by comparing reconstructed sequence against challenging real one 
this paper present a model of spatiotemporal variation in a dynamic texture dt sequence most recent work on dt modelling represents image in a dt sequence a the response of a linear dynamical system lds to noise despite it merit this model ha limitation because it attempt to model temporal variation in pixel intensity which do not take advantage of global motion coherence we propose a model that relates texture dynamic to the variation of the fourier phase which capture the relationship among the motion of all pixel i e global motion within the texture a well a the appearance of the texture unlike lds our model doe not require segmentation or cropping during the training stage which allows it to handle dt sequence containing a static background we test the performance of this model on recognition and synthesis of dt s experiment with a dataset that we have compiled demonstrate that our phase based model outperforms lds 
model based d object tracking is fast and robust using d edge however traditional edge based approach have difficulty handling occluding contour of curved surface since they are not static model edge but change with the viewpoint in this paper we propose a unified approach to edge based tracking where d edge including occluding contour are utilized this is achieved through an analysis of local surface differential geometry which provides the foundation for incorporating occluding contour of curved surface into edge based tracking this approach us a simple parametrization of both type of model edge within the same framework the proposed method ha been tested within the context of an existing edge based tracking system the system can track both type of model edge in a very fast and robust manner experimental result on both synthetic and real scene are provided which confirm that occluding contour improve real time d tracking performance 
we present a bayesian framework for learning higherorder transition model in video surveillance network such higher order model describe object movement between camera in the network and have a greater predictive power for multi camera tracking than camera adjacency alone these model also provide inherent resilience to camera failure filling in gap left by single or even multiple non adjacent camera failure our approach to estimating higher order transition model relies on the accurate assignment of camera observation to the underlying trajectory of object moving through the network we address this data association problem by gathering the observation and evaluating alternative partition of the observation set into individual object trajectory searching the complete partition space is intractable so an incremental approach is taken iteratively adding observation and pruning unlikely partition partition likelihood is determined by the evaluation of a probabilistic graphical model when the algorithm ha considered all observation the most likely map partition is taken a the true object trajectory from these recovered trajectory the higher order statistic we seek can be derived and employed for tracking the partitioning algorithm we present is parallel in nature and can be readily extended to distributed computation in medium scale smart camera network 
we present a unified method for simultaneously acquiring both the location and the silhouette shape of people in outdoor scene the proposed algorithm integrates top down and bottom up process in a balanced manner employing both appearance and motion cue at different perceptual level without requiring manually segmented training data the algorithm employ a simple top down procedure to capture the high level cue of object familiarity motivated by regularity in the shape and motion characteristic of human interaction among low level contour feature are exploited to extract mid level perceptual cue such a smooth continuation common fate and closure a markov random field formulation is presented that effectively combine the various cue from the top down and bottom up process the algorithm is extensively evaluated on static and moving pedestrian datasets for both detection and segmentation 
we explore the performance of a number of popular feature detector and descriptor in matching d object feature across viewpoint and lighting condition to this end we design a method based on intersecting epipolar constraint for providing ground truth correspondence automatically we collect a database of object viewed from calibrated viewpoint under three different lighting condition we find that the combination of hessian affine feature finder and sift feature is most robust to viewpoint change harris affine combined with sift and hessian affine combined with shape context descriptor were best respectively for lighting change and scale change we also find that no detector descriptor combination performs well with viewpoint change of more than 
the objective of this work is to automatically generate a large number of image for a specified object class for example penguin a multi modal approach employing both text meta data and visual feature is used to gather many high quality image from the web candidate image are obtained by a text based web search querying on the object identifier the word penguin the web page and the image they contain are downloaded the task is then to remove irrelevant image and re rank the remainder first the image are re ranked using a bayes posterior estimator trained on the text surrounding the image and meta data feature such a the image alternative tag image title tag and image filename no visual information is used at this stage second the top ranked image are used a noisy training data and a svm visual classifier is learnt to improve the ranking further the principal novelty is in combining text meta data and visual feature in order to achieve a completely automatic ranking of the image example are given for a selection of animal e g camel shark penguin vehicle car airplane bike and other class guitar wristwatch totalling class the result are assessed by precision recall curve on ground truth annotated data and by comparison to previous approach including those of berg et al on an additional six class and fergus et al 
discriminative method for visual object category recognition are typically non probabilistic predicting class label but not directly providing an estimate of uncertainty gaussian process gps are powerful regression technique with explicit uncertainty model we show here how gaussian process with covariance function defined based on a pyramid match kernel pmk can be used for probabilistic object category recognition the uncertainty model provided by gps offer confidence estimate at test point and naturally allows for an active learning paradigm in which point are optimally selected for interactive labeling we derive a novel active category learning method based on our probabilistic regression model and show that a significant boost in classification performance is possible especially when the amount of training data for a category is ultimately very small 
in this paper a novel method for learning based image super resolution sr is presented the basic idea is to bridge the gap between a set of low resolution lr image and the corresponding high resolution hr image using both the sr reconstruction constraint and a patch based image synthesis constraint in a general probabilistic framework we show that in this framework the estimation of the lr image formation parameter is straightforward the whole framework is implemented via an annealed gibbs sampling method experiment on sr on both single image and image sequence input show that the proposed method provides an automatic and stable way to compute super resolution and the achieved result is encouraging for both synthetic and real lr image 
kernel machine have recently been considered a a promising solution for implicit surface modelling a key challenge of machine learning solution is how to fit implicit shape model from large scale set of point cloud sample efficiently in this paper we propose a fast solution for approximating implicit surface based on a multi scale tikhonov regularization scheme the optimization of our scheme is formulated into a sparse linear equation system which can be efficiently solved by factorization method different from traditional approach our scheme doe not employ auxiliary off surface point which not only save the computational cost but also avoids the problem of injected noise to further speedup our solution we present a multi scale surface fitting algorithm of coarse to fine modelling we conduct comprehensive experiment to evaluate the performance of our solution on a number of datasets of different scale the promising result show that our suggested scheme is considerably more efficient than the state of the art approach 
particle filter encode a time evolving probability density by maintaining a random sample from it level set represent closed curve a zero crossing of function of two variable the combination of level set and particle filter present many conceptual advantage when tracking uncertain evolving boundary over time but the cost of combining these two idea seems prima facie prohibitive a previous publication showed that a large number of virtual level set particle can be tracked with a logarithmic amount of work for propagation and update we now make levelset curve particle more efficient by borrowing idea from the finite element method fem this improves level set curve particle in both running time by a constant factor and accuracy of the result 
while the majority of competitive image segmentation method are based on energy minimization only few allow to efficiently determine globally optimal solution a graphtheoretic algorithm for finding globally optimal segmentation is given by the minimum ratio cycle first applied to segmentation in in this paper we show that the class of image segmentation problem solvable by minimum ratio cycle is significantly larger than previously considered in particular they allow for the introduction of higher orde r regularity of the region boundary the key idea is to introduce an extended graph representation where each node of the graph represents an image pixel a well a the orientation of the incoming line segment with each graph edge representing a pair of adjacent line segment edge weight can depend on the curvature this way arbitrary positive function of curvature can be introduced into globally optimal segmentation by minimum ratio cycle in numerous experiment we demonstrate that compared to length regularity the integration of curvatur eregularity will drastically improve segmentation result moreover we show an interesting relation to the snake functional minimum ratio cycle provide a way to find one of the few case where the snake functional ha a meaningful global minimum 
template matching is a fundamental operator in computer vision and is widely used in feature tracking motion estimation image alignment and mosaicing under a certain parameterized warping model the traditional template matching algorithm estimate the geometric warp parameter that minimize the ssd between the target and a warped template the performance of the template matching can be characterized by deriving the distribution of warp parameter estimate a a function of the ideal template the ideal warp parameter and a given noise or perturbation model in this paper we assume a discretization of the warp parameter space and derive the theoretical expression for the probability mass function pmf of the parameter estimate a the pmf is also a function of the template size we can optimize the choice of the template or block size by determining the template block size that give the estimate with minimum entropy experimental result illustrate the correctness of the theory an experiment involving feature point tracking in face video is shown to illustrate the robustness of the algorithm in a real world problem 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
the efficiency and robustness of a vision system is often largely determined by the quality of the image feature available to it in data mining one typically work with immense volume of raw data which demand effective algorithm to explore the data space in analogy to data mining the space of meaningful feature for image analysis is also quite vast recently the challenge associated with these problem area have become more tractable through progress made in machine learning and concerted research effort in manual feature design by domain expert in this paper we propose a feature mining paradigm for image classification and examine several feature mining strategy we also derive a principled approach for dealing with feature with varying computational demand our goal is to alleviate the burden of manual feature design which is a key problem in computer vision and machine learning we include an in depth empirical study on three typical data set and offer theoretical explanation for the performance of various feature mining strategy a a final confirmation of our idea we show result of a system that utilizing feature mining strategy match or outperforms the best reported result on pedestrian classification where considerable effort ha been devoted to expert feature design 
spectral clustering and path based clustering are two recently developed clustering approach that have delivered impressive result in a number of challenging clustering task however they are not robust enough against noise and outlier in the data in this paper based on m estimation from robust statistic we develop a robust path based spectral clustering method by defining a robust path based similarity measure for spectral clustering our method is significantly more robust than spectral clustering and path based clustering we have performed experiment based on both synthetic and real world data comparing our method with some other method in particular color image from the berkeley segmentation dataset and benchmark are used in the image segmentation experiment experimental result show that our method consistently outperforms other method due to it higher robustness 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper we show how a segmentation a preprocessing paradigm can be used to improve the efficiency and accuracy of model search in an image we operationalize this idea using an over segmentation of an image into superpixels the problem domain we explore is human body pose estimation from still image the superpixels prove useful in two way first we restrict the joint position in our human body model to lie at center of superpixels which reduces the size of the model search space in addition accurate support mask for computing feature on half limb of the body model are obtained by using agglomeration of superpixels a half limb segment we present result on a challenging dataset of people in sport news image 
epipolar geometry and relative camera pose computation for uncalibrated camera with radial distortion ha recently been formulated a a minimal problem and successfully solved in floating point arithmetic the singularity of the fundamental matrix ha been used to reduce the minimal number of point to eight it wa assumed that the camera were not calibrated but had same distortion in this paper we formulate two new minimal problem for estimating epipolar geometry of camera with radial distortion first we presenta minimalalgorithmforpartiallycalibratedcameras with same radial distortion using the trace constraint which hold for the epipolar geometry of calibrated camera to reduce the number of necessary point from eight to six we demonstrate that the problem is solvable in exact rational arithmetic secondly we present a minimal algorithm for uncalibrated camera with different radial distortion we show that the problem can be solved using nine point in two view by manipulatingpolynomials by a sequence of gauss jordan elimination in exact rationalarithmetics we demonstratethe algorithmsonsynthetic and real data 
we propose a global optimization framework for d shape reconstruction from sparse noisy d measurement frequently encountered in range scanning sparse featurebased stereo and shape from x in contrast to earlier local or banded optimization method for shape fitting we compute global optimum in the whole volume removing dependence on initial guess and sensitivity to numerous local minimum our global method is based on two main idea first we suggest a new regularization functional with a data alignment term that maximizes the number of weaklyoriented data point contained by a surface while allowing for some measurement error second we propose a touchexpand algorithm for finding a minimum cut on a huge d grid using an automatically adjusted band this overcomes prohibitively high memory cost of graph cut when computing globally optimal surface at high resolution our result for sparse or incomplete d data from laser scanning and passive multi view stereo are robust to noise outlier missing part and varying sampling density 
we present a novel calibration method for off axis catadioptric camera i e standard perspective camera placed in a generic position w r t an axial symmetric mirror of un known shape the proposed method estimate the intrinsic parameter of the natural perspective camera the d shape of the mirror and it pose w r t the camera the peculiarity of our approach is that unlike several other calibration method we do not require any cross section of the mirror to be visible in the image instead we require that the catadioptric image contains at least the im age of one generic space line we then derive some constraint that combined with the harmonic homology relating the apparent contour of the mirror allow u to calibrate the off axis camera we provide experimental result both on synthetic and camera image that prove the validity of the technique 
recently the author developed nir based face recognition for highly accurate face recognition under illumination variation in this paper we present a part based method for improving it robustness with respect to pose variation an nir face is decomposed into part a part classifier is built for each part using the most discriminative lbp histogram feature selected by adaboost learning the output of part classifier are fused to give the final score experiment show that the present method outperforms the whole face based method by 
we present a new approach to reconstruct the shape of a d object or scene from a set of calibrated image the central idea of our method is to combine the topological flexibility of a point based geometry representation with the robust reconstruction property of scene aligned planar primitive this can be achieved by approximating the shape with a set of surface element surfels in the form of planar disk which are independently fitted such that their footprint in the input image match instead of using an artificial energy functional to promote the smoothness of the recovered surface during fitting we use the smoothness assumption only to initialize planar primitive and to check the feasibility of the fitting result after an initial disk ha been found the recovered region is iteratively expanded by growing further disk in tangent direction the expansion stop when a disk rotates by more than a given threshold during the fitting step a global sampling strategy guarantee that eventually the whole surface is covered our technique doe not depend on a shape prior or silhouette information for the initialization and it can automatically and simultaneously recover the geometry topology and visibility information which make it superior to other state of theart technique we demonstrate with several high quality reconstruction example that our algorithm performs highly robustly and is tolerant to a wide range of image capture modality 
in this paper we present two contribution to improve accuracy and speed of an image search system based on bag of feature a contextual dissimilarity measure cdm and an efficient search structure for visual word vector our measure cdm take into account the local distribution of the vector and iteratively estimate distance correcting term these term are subsequently used to update an existing distance thereby modifying the neighborhood structure experimental result on the nist er stew enius dataset show that our approach significantly outperforms the state of the art in term of accuracy our efficient search structure for visual word vector is a two level scheme using inverted file the first level partition the image set into cluster of image at query time only a subset of cluster of the second level ha to be searched this method allows fast querying in large set of image we evaluate the gain in speed and the loss in accuracy on large datasets up to million image 
we propose statistical data association technique for visual tracking of enormously large number of object we do not assume any prior knowledge about the number involved and the object may appear or disappear anywhere in the image frame and at any time in the sequence our approach combine the technique of multitarget track initiation recursive bayesian tracking clutter modeling event analysis and multiple hypothesis ltering the original multiple hypothesis lter address an np hard problem and is thus not practical we propose two cluster based data association approach that are linear in the number of detection and tracked object we applied the method to track wildlife in infrared video we have successfully tracked hundred of thousand of bat which were ying at high speed and in dense formation 
over the past few year several method for segmenting a scene containing multiple rigidly moving object have been proposed however most existing method have been tested on a handful of sequence only and each method ha been often tested on a different set of sequence therefore the comparison of different method ha been fairly limited in this paper we compare four d motion segmentation algorithm for affine camera on a benchmark of motion sequence of checkerboard traffic and articulated scene 
unimodal analysis of palmprint and palm vein ha been investigated for person recognition however they are not robust to noise and spoof attack in this paper we present a multimodal personal identification system using palmprint and palm vein image with fusion applied at the image level the palmprint and palm vein image are fused by a novel integrated line preserving and contrast enhancing fusion method based on our proposed fusion rule the modified multiscale edge of palmprint and palm vein image are combined a well a the image contrast and the interaction point ip of the palmprints and vein line are enhanced the ip are novel feature obtained in our fused image a novel palm representation called laplacianpalm feature is extracted from the fused image by locality preserving projection lpp we compare the recognition performance using the unimodal and the proposed fused image we also compared the proposed laplacianpalm approach with the fisherpalm and eigenpalm on a large dataset experimental result show that the proposed multimodal approach provides a better representation and achieves lower error rate in palm recognition 
we introduce the tsallis divergence error measure in the context of plsa matrix and tensor decomposition showing much improved performance in the presence of noise the focus of our approach is on one hand to provide an optimization framework which extends in the sense of a one parameter family the maximum likelihood framework and on the other hand is theoretically guaranteed to provide robustness under clutter noise and outlier in the measurement matrix under certain condition specifically the condition under which our approach excels is when the measurement array co occurrence is sparse which happens in the application domain of bag of visual word 
the existing method for offline training of cascade classifier take a greedy search to optimize individual classifier in the cascade leading inefficient overall performance we propose a new design of the cascaded classifier where all classifier are optimized for the final objective function the key contribution of this paper is the and or framework for learning the classifier in the cascade in earlier work each classifier is trained independently using the example labeled a positive by the previous classifier in the cascade and optimized to have the best performance for that specific local stage the proposed approach take into account the fact that an example is classified a positive by the cascade if it is labeled a positive by all the stage and it is classified a negative if it is rejected at any stage in the cascade an offline training scheme is introduced based on the joint optimization of the classifier in the cascade to minimize an overall objective function we apply the proposed approach to the problem of automatically detecting polyp from multi slice ct image our approach significantly speed up the execution of the computer aided detection cad system while yielding comparable performance with the current state of the art and also demonstrates favorable result over cascade adaboost both in term of performance and online execution speed 
we propose a cord distance in the space of dynamical model that take into account their dynamic including transient output map and input distribution in data analysis application a opposed to control the input is often not known and is inferred a part of the blind identification so it is an integral part of the model that should be considered when comparing different time series previous work on kernel distance between dynamical model assumed either identical or independent input we extend it to arbitrary distribution highlighting connection with system identification independent component analysis and optimal transport the increased modeling power is demonstrated empirically on gait classification from simple visual feature 
we present a novel framework for tracking of a long sequence of human activity including the time instance of change from one activity to the next using a closed loop non linear dynamical feedback system a composite feature vector describing the shape color and motion of the object and a non linear piecewise stationary stochasticdynamical model describing it spatio temporal evolution a re used for tracking the tracking error or expected log likeli hood which serf a a feedback signal is used to automatically detect change and switch between activity happen ing one after another in a long video sequence whenever a change is detected the tracker is reinitialized automatic ally by comparing the input image with learned model of the activity unlike some other approach that can track a sequence of activity we do not need to know the transition probability between the activity which can be difficult to estimate in many application scenario we demonstrate the effectiveness of the method on multiple indoor and outdoor real life video and analyze it performance 
we propose a solution to the problem of robust subspace estimation using the projection based m estimator the new method handle more outlier than inliers doe not require a user defined scale of the noise affecting the inliers handle noncentered data and nonorthogonal subspace other robust method like ransac use an input for the scale while method for subspace segmentation like gpca are not robust synthetic data and three real case of multibody factorization show the superiority of our method in spite of user independence 
we introduce an epitomic representation for modeling human activity in video sequence a video sequence is divided into segment within which the dynamic of object is assumed to be linear and modeled using linear dynamical system the tuple consisting of the estimated system matrix statistic of the input signal and the initial state value is said to form an epitome the system matrix are decomposed using the iwasawa matrix decomposition to isolate the effect of rotation scaling and projective action on the state vector we demonstrate the usefulness of the proposed representation and decomposition for activity recognition using the tsa airport surveillance dataset and the ucf indoor human action dataset 
markov random field mrfs are ubiquitous in lowlevel computer vision in this paper we propose a new approach to the optimization of multi labeled mrfs similarly to expansion it is based on iterative application of binary graph cut however the number of binary graph cut required to compute a labelling grows only logarithmically with the size of label space instead of linearly we demonstrate that for application such a optical flow image restoration and high resolution stereo this give an order of magnitude speed up for comparable energy iteration are performed by fusion of solution done with qpbo which is related to graph cut but can deal with nonsubmodularity at convergence the method achieves optimum on a par with the best competitor and sometimes even exceeds them 
we describe a method to recover the surface reflectance and the d shape of a non lambertian object a well a illumination from a collection of image it is based on the so called frontier point which are extracted from the outline of an object frontier point provide d location on the object surface where the surface normal is known this information is exploited to infer the surface reflectance of the object and the light distribution of the scene both under varying illumination and fixed vantage point and under varying vantage point and fixed illumination we also show how to apply frontier point for shape recovery in photometric stereo the effectiveness of frontier point for recovering reflectance illumination and shape is confirmed by a number of experiment on both real and synthetic data 
we present a novel approach to inferring d volumetric shape of both moving object and static background from video sequence shot by a moving camera with the assumption that the object move rigidly on a ground plane the d scene is divided into a set of volume element termed a voxels organized in an adaptive octree structure each voxel is assigned a label at each time instant either a empty or belonging to background structure or a moving object the task of shape inference is then formulated a assigning each voxel a dynamic label which minimizes photo and motion variance between voxels and the original sequence we propose a three step voxel labeling method based on a robust photo motion variance measure first a sparse set of surface point are utilized to initialize a subset of voxels then a deterministic voxel coloring scheme carves away the voxels with large variance finally the labeling result are refined by a graph cut based optimization method to enforce global smoothness experimental result on both indoor and outdoor sequence demonstrate the effectiveness and robustness of our method 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
this paper proposes a method for human detection in crowded scene from static image an individual human is modeled a an assembly of natural body part we introduce edgelet feature which are a new type of silhouette oriented feature part detector based on these feature are learned by a boosting method response of part detector are combined to form a joint likelihood model that includes case of multiple possibly inter occluded human the human detection problem is formulated a maximum a posteriori map estimation we show result on a commonly used previous dataset a well a new data set that could not be processed by earlier method 
abstract automatic detection of dynamic event in video sequence ha a variety of application including visual surveillance and monitoring video highlight extraction intelligent transportation system video summarization and many more learning an accurate description of the various event in real world scene is challenging owing to the limited user labeled data a well a the large variation in the pattern of the event pattern difference arise either due to the nature of the event themselves such a the spatio temporal event or due to missing or ambiguous data interpretation using computer vision method in this work we introduce a novel method for representing and classifying event in video sequence using reversible context free grammar the grammar are learned using a semi supervised learning method more concretely by using the classification entropy a a heuristic cost function the grammar are iteratively learned using a search method experimental result demonstrating the efficacy of the learning algorithm and the event detection method applied to traffic video sequence are presented 
the paper describes a method for automatically extracting informative feature hierarchy for object classification and show the advantage of the feature constructed hierarchically over previous method the extraction process proceeds in a top down manner informative top level fragment are extracted first and by a repeated application of the same feature extraction process the classification fragment are broken down successively into their own optimal component the hierarchical decomposition terminates with atomic feature that cannot be usefully decomposed into simpler feature the entire hierarchy the different feature and sub feature and their optimal parameter are learned during a training phase using training example experimental comparison show that these feature hierarchy are significantly more informative and better for classification compared with similar non hierarchical feature a well a previous method for using feature hierarchy 
previous pixel level change detection method either contain a background updating step that is costly for moving camera background subtraction or can not locate object position and shape accurately frame differencing in this paper we present a belief propagation approach for moving object detection using a d markov random field mrf model each hidden state in the d mrf model represents a pixel s motion likelihood and is estimated using message passing in a connected spatio temporal neighborhood this approach deal effectively with difficult moving object detection problem like object camouflaged by similar appearance to the background or object with uniform color that frame difference method can only partially detect three example are presented where moving object are detected and tracked successfully while handling appearance change shape change varied moving speed direction scale change and occlusion clutter 
tracking of speckle in echocardiography enables the study of myocardium deformation and thus can provide insight about heart structure and function most of the current method are based on d speckle tracking which suffers from error due to through plane decorrelation speckle tracking in d overcomes such limitation however d speckle tracking is a challenging problem due to relatively low spatial and temporal resolution of d echocardiography to ensure accurate and robust tracking high level spatial and temporal constraint need to be incorporated in this paper we introduce a novel method for speckle tracking in d echocardiography instead of tracking each speckle independently we enforce a motion coherence constraint in conjunction with a dynamic model for the speckle this method is validated on in vivo porcine heart and is proved to be accurate and robust 
face recognition under varying illumination remains a challenging problem much progress ha been made toward a solution through method that require multiple gallery image of each subject under varying illumination yet for many application this requirement is too severe in this paper we propose a novel method that requires only a single gallery image per subject taken under unknown lighting the method build upon two contribution we first estimate the lighting from it reflection in the eye this allows u to explicitly recover the illumination in the single gallery image a well a the probe image next we exploit the local linearity of face appearance variation across different people we represent the gallery image a locally linear montage of image of many different face taken under the same lighting bootstrap image then we transfer the estimated combination of bootstrap image to synthesize each subject s face under the probe lighting to accomplish recognition finally we show through test on the cmu pie database that we can achieve better recognition result using our lighting estimation method and locally linear montage than the current state of the art 
most of the online multimedia collection such a picture gallery or video archive are categorized in a fully manual process which is very expensive and may soon be infeasible with the rapid growth of multimedia repository in this paper we present an effective method for automating this process within the unsupervised learning framework we exploit the truly multi modal nature of multimedia collection they have multiple view ormodalities each of which contributes it own perspective to the collection s organization for example in picture gallery image caption are often provided that form a separate view on the collection color histogram or any other set of global feature form another view additional view are blob interest point and other set of local feature our model called comraf pronounced comraf star efficiently incorporates various view in multi modal clustering by which it allows great modeling flexibility comraf is a light weight version of the recently introducedcombinatorial markov random field comraf we show how to translate an arbitrary comraf into a series of comraf model and give an empirical evidence for comparable effectiveness of the two comraf demonstrates excellent result on two real world image gallery it obtains time higher accuracy compared with a uni modalk mean 
many computer vision application rely on the efficient optimization of challenging so called non submodular b inary pairwise mrfs a promising graph cut based approach for optimizing such mrfs known a roof duality wa recently introduced into computer vision we study two method which extend this approach first we discus an efficient implementation of the probing technique introduced recently by boros et al it simplifies the mrf while preserving the global optimum our code is faster on some graph than the implementation of second we present a new technique which take an arbitrary input labeling and try to improve it energy we give theoretical characterization of local minimum of this procedur e we applied both technique to many application including image segmentation new view synthesis superresolution diagram recognition parameter learning tex ture restoration and image deconvolution for several application we see that we are able to find the global minimum very efficiently and considerably outperform the original roof duality approach in comparison to existing technique such a graph cut trw bp icm and simulated annealing we nearly always find a lower energy 
the standard graph cut technique is a robust method for globally optimal image segmentation however because of it global nature it is prone to capture outlying area similar to the object of interest this paper proposes a novel method to constrain the standard graph cut technique for tracking anywhere from one to several object in region of interest for each object we introduce a pixel penalty based upon distance from a region of interest and so segmentation is biased to remain in this area also we employ a filter predicting the location of the object the distance penalty is then centered at this location and adaptively scaled based on prediction confidence this method is capable of tracking multiple interacting object of different intensity profile in both gray scale and color imagery 
this paper proposes a novel algorithm for calibrated multi view stereopsis that output a quasi dense set of rectangular patch covering the surface visible in the input image this algorithm doe not require any initialization in the form of a bounding volume and it detects and discard automatically outlier and obstacle it doe not perform any smoothing across nearby feature yet is currently the top performer in term of both coverage and accuracy for four of the six benchmarkdatasets presented in the key to it performance are effective technique for enforcing local photometric consistency and global visibility constraint stereopsis is implemented a a match expand and filter procedure starting from a sparse set of matched keypoints and repeatedly expanding these to nearby pixel correspondence before using visibility constraint to filter away false match a simple but effective method for turning the resulting patch model into a mesh appropriate for image based modeling is also presented the proposed approach is demonstrated on various datasets including object with fine surface detail deep concavity and thin structure outdoor scene observed from a restricted set of viewpoint and crowded scene where moving obstacle appear in different place in multiple image of a static structure of interest 
we present a novel stochastic adaptive strategy for tracking multiple people in a large network of video camera similarity between feature appearance and biometrics observed at different camera are continuously adapted and the stochastically optimal path for each person computed the following are the major contribution of the proposed approach first we consider situation where the feature similarity are uncertain and treat them a random variable we show how the distribution of these random variable can be learned and how to compute the track in a stochastically optimal manner second we consider the possibility of long term interdependence of the feature over space and time this allows u to adoptively evolve the feature correspondence by observing the system performance over a time window and correct for error in the similarity computation third we show that the above two condition can be addressed by treating the issue of tracking in a camera network a an optimization problem in a stochastic adaptive system we show result on data collected by a large camera network the proposed approach is particularly suitable for distributed processing over the entire network 
object detection in aerial imagery ha been well studied in computer vision for year however given the complexity of large variation of the appearance of the object and the background in a typical aerial image a robust and efficient detection is still considered a an open and challenging problem in this paper we present the enhanced semi supervised learning esl framework and apply this framework to revising an object detection methodology we have developed in a previous effort theoretic analysis and experimental evaluation using the uci machine learning repository clearly indicate the superiority of the esl framework the performance evaluation of the revised object detection methodology against the original one clearly demonstrate the promise and superiority of this approach 
this paper present a method of imaging the coloration pattern in the fingernail and surrounding skin to infer fingertip force direction during planar contact nail image from subject were registered to reference image with ransac and then warped to an atlas with elastic registration recognition of fingertip force direction based on lineardiscriminantanalysis showsthatthere arecommon colorpattern featuresin thefingernailand surroundingskin for different subject based on the common feature the overall recognition accuracy is 
this paper address robust recovery of structure and motion for rigid body in video sequence for small interframe motion feature appearance is commonly estimated according to the previous frame however in the case of occlusion or corrupt frame the small inter frame motion model fails in this paper we propose to use robustidentification technique to estimate the motion dynamic based on a set of previous frame these dynamic are then recursively used to robustly estimate object structure and motion and to predict the object appearance in future frame result are tested for d reconstruction of rigid body in real and synthetic image sequence 
markov random field mrf model are a popular tool for vision and image processing gaussian mrf model are particularly convenient to work with because they can be implemented using matrix and linear algebra routine however recent research ha focused on on discrete valued and non convex mrf model because gaussian model tend to over smooth image and blur edge in this paper we show how to train a gaussian conditional random field gcrf model that overcomes this weakness and can outperform the non convex field of expert model on the task of denoising image a key advantage of the gcrf model is that the parameter of the model can be optimized efficiently on relatively large image the competitive performance of the gcrf model and the ease of optimizing it parameter make the gcrf model an attractive option for vision and image processing application 
combination of microphone and camera allow the joint audio visual sensing of a scene such arrangement of sensor are common in biological organism and in application such a meeting recording and surveillance where both modality are necessary to provide scene understanding microphone array provide geometrical information on the source location and allow the sound source in the scene to be separated and the noise suppressed while camera allow the scene geometry and the location and motion of people and other object to be estimated in most previous work the fusion of the audio visual information occurs at a relatively late stage in contrast we take the viewpoint that both camera and microphone array are geometry sensor and treat the microphone array a generalized camera we employ computer vision inspired algorithm to treat the combined system of array and camera in particular we consider the geometry introduced by a general microphone array and spherical microphone array the latter show a geometry that is very close to central projection camera and we show how standard vision based calibration algorithm can be profitably applied to them experiment are presented that demonstrate the usefulness of the considered approach 
we consider the use of top point for object retrieval these point are based on scale space and catastrophe theory and are invariant under gray value scaling and offset a well a scale euclidean transformation the differential property and noise characteristic of these point are mathematically well understood it is possible to retrieve the exact location of a top point from any coarse estimation through a closed form vector equation which only depends on local derivative in the estimated point all these property make top point highly suitable a anchor point for invariant matching scheme by mean of a set of repeatability experiment and receiver operator curve we demonstrate the performance of top point and differential invariant feature a image descriptor 
linear fitting of implicit algebraic model to data usually suffers from global stability problem complicated object structure can accurately be modeled by closed bounded surface of higher degree using ridge regression this paper derives an explicit formula for computing a euclidean invariant d ridge regression matrix and applies it for the global stabilization of a particular linear fitting method experiment show that the proposed approach improves global stability of resulting surface significantly 
considerable advance have been made in learning to recognize and localize visual object class simple bag offeature approach label each pixel or patch independently more advanced model attempt to improve the coherence of the labellings by introducing some form of inter patch coupling traditional spatial model such a mrf s provide crisper local labellings by exploiting neighbourhoodlevel coupling while aspect model such a plsa and lda use global relevance estimate global mixing proportion for the class appearing in the image to shape the local choice we point out that the two approach are complementary combining them to produce aspect based spatial field model that outperform both approach we study two spatial model one based on averaging over forest of minimal spanning tree linking neighboring image region the other on an efficient chain based expectation propagation method for regular neighbor markov random field the model can be trained using either patch level label or image level keywords a input feature they use factored observation model combining texture color and position cue experimental result on the msr cambridge data set show that combining spatial and aspect model significantly improves the region level classification accuracy in fact our model trained with image level label outperform plsa trained with pixel level one 
smoothly bent paper like surface are developable they are however difficult to minimally parameterize since the number of meaningful parameter is intrinsically dependent on the actual deformation previous generative model are either incomplete i e limited to subset of developable surface or depend on huge parameter set we propose a generative model governed by a quasiminimal set of intuitive parameter namely rule and angle more precisely a flat mesh is bent along guiding rule while a number of extra rule control the level of smoothness the generated surface is guaranteed to be developable a fully automatic multi camera threedimensional reconstruction algorithm including model based bundleadjustment demonstrates our model on real image 
in this paper we propose a novel learned visual code book lvc for d face recognition in our method we first extract intrinsic discriminative information embedded in d face using gabor filter then k mean clustering is adopted to learn the center from the filter response vector we construct lvc by these learned center finally we represent d face based on lvc and achieve recognition using a nearest neighbor nn classifier the novelty of this paper come from we first apply textons based method into d face recognition we encompass the efficiency of gabor feature for face recognition and the robustness of texton strategy for texture classification simultaneously our experiment are based on two challenging database casia d face database and frgc d face database experimental result show lvc performs better than many commonly used method 
this paper present a new method to detect and accurately extract the moving object from a video sequence taken by a hand held camera in order to extract the high quality moving foreground previous approach usually assume that the background is static or through only planar perspective transformation in our method based on the robust motion estimation we are capable of handling challenging video where the background contains complex depth and the camera undergoes unknown motion we propose the appearance and structure consistency constraint in d warping to robustly model the background which greatly improves the foreground separation even on the object boundary the estimated dense motion eld and the bilayer segmentation result are iteratively rened where continuous and discrete optimization are alternatively used experimental result of high quality moving object extraction from challenging video demonstrate the effectiveness of our method 
this paper describes a novel approach for reconstructing a closed continuous surface of an object from multiple calibrated color image and silhouette any accurate reconstruction must satisfy photo consistency and silhouette consistency constraint most existing technique treat these cue identically in optimization framework where silhouette constraint are traded off against photo consistency and smoothness prior our approach strictly enforces silhouette constraint while optimizing photo consistency and smoothness in a global graph cut framework we transform the reconstruction problem into computing max flow mincut in a geometric graph where any cut corresponds to a surface satisfying exact silhouette constraint it silhouette should exactly coincide with those of the visual hull a minimum cut is the most photo consistent surface amongst them our graph cut formulation is based on the rim mesh the combinatorial arrangement of rim or contour generator from many view which can be computed directly from the silhouette unlike other method our approach enforces silhouette constraint without introducing a bias near the visual hull boundary and also recovers the rim curve result are presented for synthetic and real datasets 
taking a sequence of photograph using multiple illumination source or setting is central to many computer vision and graphic problem a growing number of recent method use multiple source rather than single point source in each frame of the sequence potential benefit include increased signal to noise ratio and accommodation of scene dynamic range however existing multiplexing scheme including hadamard based code are inhibited by fundamental limit set by poisson distributed photon noise and by sensor saturation the prior scheme may actually be counterproductive due to these effect we derive multiplexing code that are optimal under these fundamental effect thus the novel code generalize the prior scheme and have a much broader applicability our approach is based on formulating the problem a a constrained optimization we further suggest an algorithm to solve this optimization problem the superiority and effectiveness of the method is demonstrated in experiment involving object illumination 
this paper present an automatic system for the monitoring of indoor environment using pan tilt zoomable camera a combination of haar feature classifier based detection and color histogram filtering is used to achieve reliable initialization of person track even in the presence of camera movement a combination of adaptive color and klt feature tracker for face and upper body allows for robust tracking and track recovery in the presence of occlusion or interference the continuous recomputation of camera parameter coupled with a fuzzy controlling scheme allow for smooth tracking of moving target a well a acquisition of stable facial closeup similar to the natural behavior of a human cameraman the system is tested on a series of natural indoor monitoring scenario and show a high degree of naturalness flexibility and robustness 
the photorealistic modeling of large scale object such a urban scene requires the combination of range sensing technology and digital photography in this paper we attack the key problem of camera pose estimation in an automatic and efficient way first the camera orientation is recovered by matching vanishing point extracted from d image with d direction derived from a d range model then a hypothesis and test algorithm computes the camera position with respect to the d range model by matching corresponding d and d linear feature the camera position are further optimized by minimizing a line to line distance the advantage of our method over earlier work ha to do with the fact we do not need to rely on extracted planar facade or other higher order feature we are utilizing lowlevel linear feature that make this method more general robust and efficient our method can also be enhanced by the incorporation of traditional structure from motion algorithm we have also developed a user interface for allowing user to accurately texture map d image onto d range model at interactive rate we have tested our system in a large variety of urban scene 
in this paper we present a method using pixel level information local region level information and global level information to remove shadow at the pixel level we employ gmm to model the behavior of cast shadow for every pixel in the hsv color space a it can deal with complex illumination condition however unlike the gmm for background which can obtain sample every frame this model for shadow need more frame to get the same number of sample because shadow may not appear at the same pixel for each frame therefore it will take a long time to converge to overcome this drawback we use the local region level information to get more sample and global level information to improve a preclassifier and then by using it we get sample which are more likely to be shadow also at the local region level we use markov random field to represent dependency between the label of single pixel and label of it neighborhood moreover to make global level information more robust tracking information is used experimental result show that proposed method is efficient and robust 
we argue that registration should be thought of a a mean to an end and not a a goal by itself in particular we consider the problem of predicting the location of hidden label of a test image using observable feature given a training set with both the hidden label and observable feature for example the hidden label could be segmentation label or activation region in fmri while the observable feature could be sulcal geometry or mr intensity we analyze a probabilistic framework for computing an optimal atlas and the subsequent registration of a new subject using only the observable feature to optimize the hidden label alignment to the training set we compare two approach for co registering training image for the atlas construction the traditional approach of only using observable feature and a novel approach of only using hidden label we argue that the alternative approach is superior particularly when the relationship between the hidden label and observable feature is complex and unknown a an application we consider the task of registering cortical fold to optimize brodmann area localization we show that the alignment of the brodmann area improves by up to when using the alternative atlas compared with the traditional atlas to the best of our knowledge these are the most accurate brodmann area localization result achieved via cortical fold registration reported to date 
several approach to shadow removal in color image have been introduced in recent year yet these method fail in removing shadow that are cast on curved surface a well a retaining the original texture of the image in shadow boundary known a penumbra region in this paper we propose a novel approach which effectively remove shadow from curved surface while retaining the textural information in the penumbra yielding high quality shadowfree image our approach aim at finding scale factor to cancel the effect of shadow including penumbra region where illumination change gradually due to the fact that surface geometry is also taken into account when computing the scale factor our method can handle a wider range of shadow image than current state of the art method a demonstrated by several example 
video based multiple target tracking mtt is a challenging task when similar target are present in close vicinity because their visual observation are mixed and difficult to segment their motion have to be estimated jointly most existing approach perform this joint motion estimation in a centralized fashion and involve searching a rather high dimensional space and thus leading to quite complicated joint tracker this paper brings a new view to mtt from a game theoretic perspective bridging the joint motion estimation and the nash equilibrium of a game instead of designing a centralized tracker mtt is decentralized and a set of individual tracker is used each of which try to maximize it visual evidence for explaining it motion a well a generates interference to others modelling this competition behavior a special game is designed so that the difficult joint motion estimation is achieved at the nash equilibrium of this game where no individual tracker ha incentive to change it motion estimate this paper substantializes this novel idea in a solid case study where individual tracker are kernel based tracker an efficient best response updating procedure is designed to find the nash equilibrium the powerfulness of this game theoretic mtt is shown by promising result on difficult real video 
in this paper we present a method for the tracking of fluid flow velocity field the technique we propose is formalized within sequential bayesian filter framework the filter we propose here combine an it diffusion process coming from a stochastic formulation of the vorticity velocity form of navier stokes equation and discrete measurement extracted from an image sequence the resulting tracker provides robust and consistent estimation of instantaneous motion field along the whole image sequence in order to handle a state space of reasonable dimension for the stochastic filtering problem we represent the motion field a a combination of adapted basis function the used basis function ensue from a mollification of biot savart integral and a discretization of the vorticity and divergence map of the fluid vector field the efficiency of the method is demonstrated on a long real world sequence showing a vortex launch at tip of airplane wing 
in recent year many powerful computer vision algorithm have been invented making automatic or semiautomatic solution to many popular vision task such a visual object recognition or camera calibration possible on the other hand embedded vision platform and solution such a smart camera have successfully emerged however only offering limited computational and memory resource the first contribution of this paper is the investigation of a set of robust local feature detector and descriptor for application on embedded system we briefly describe the method involved i e the dog difference of gaussian and mser maximally stable extremal region detector a well a the pca sift descriptor and discus their suitability for smart system and their qualification for given task the second contribution of this work is the experimental evaluation of these method on two challenging task namely fully embedded object recognition on a moderate size database and on the task of robust camera calibration our approach is fortified by encouraging result we present at length 
a jigsaw is a recently proposed generative model that describes an image a a composition of non overlapping patch of varying shape extracted from a latent image by learning the latent jigsaw image which best explains a set of image it is possible to discover the shape size and appearance of repeated structure in the image a challenge when learning this model is the very large space of possible jigsaw pixel which can potentially be used to explain each image pixel the previous method of inference for this model scale linearly with the number of jigsaw pixel making it unusable for learning the large jigsaw needed for many practical application in this paper we make three contribution that enable the learning of large jigsaw a novel sparse belief propagation algorithm a hybrid method which significantly improves the sparseness of this algorithm and a method that us these technique to makelearningof largejigsawsfeasible we providedetailed analysisof how our hybrid inference method lead to significant saving in memory and computation time to demonstrate the success of our method we present experimental result applying large jigsaw to an object recognition task 
we describe a new hierarchical representation for twodimensional object that capture shape information at mul tiple level of resolution this representation is based ona hierarchical description of an object s boundary and can be used in an elastic matching framework both for comparing pair of object and for detecting object in cluttered image in contrast to classical elastic model our representation explicitly capture global shape information t his lead to richer geometric model and more accurate recognition result our experiment demonstrate classificatio n result that are significantly better than the current stateof the art in several shape datasets we also show initial experiment in matching shape to cluttered image 
we introduce hsos hierarchical semantics of object an hso is learnt from a collection of image taken from a particular scene category the hso capture the interaction between the object that tend to co occur in the scene and hence are potentially semantically related such relationship are typically hierarchical for example in a collection of image taken in a living room scene the tv dvd player and coffee table co occur frequently the tv and the dvd player are more closely related to each other than the coffee table and this can be learnt from the fact that the two are located at similar relative location across image while the coffee table is somewhat arbitrarily placed the goal of this paper is to learn this hierarchy that characterizes the scene the proposed approach being entirely unsupervised can detect the part of the image that belong to the foreground object cluster these part to represent object and provide an understanding of the scene by hierarchically clustering these object in a semantically meaningful way all from a collection of unlabeled image of a particular scene category in addition to providing the semantic layout of the scene learnt hsos can have several useful application such a compact scene representation for scene category classification and providing context for enhanced object detection 
image artifact that result from sensor dust are a common but annoying problem for many photographer to reduce the appearance of dust in an image we first formulate a model of artifact formation due to sensor dust with this artifact formation model we make use of contextual information in the image and a color consistency constraint on dust to remove these artifact when multiple image are available from the same camera even under different camera setting this approach can also be used to reliably detect dust region on the sensor in contrast to image inpainting or other hole filling method the proposed technique utilizes image information within a dust region to guide the use of contextual data joint use of these multiple cue lead to image recovery result that are not only visually pleasing but also faithful to the actual scene the effectiveness of this method is demonstrated in experiment with various camera 
most shapematchingmethodsare either fast but toosimplistic to give the desired performance or promising a far a performance is concerned but computationally demanding in this paper we present a very simple and efficient approachthatnotonly performsalmost asgoodasmanystateof the art technique but also scale up to large database in the proposed approach each shape is indexed based on a variety of simple and easily computable feature which are invariant to articulation and rigid transformation the feature characterize pairwise geometric relationship between interest point on the shape thereby providing robustness to the approach shape are retrieved using an efficient scheme which doe not involve costly operation like shape wise alignment or establishing correspondence even for a moderate size database of shape the retrieval process is several time faster than most technique with similar performance extensive experimental result are presented to illustrate the advantage of our approach a compared to the best in the field 
we present a novel approach for contextual segmentation of complex visual scene based on the use of bag of local invariant feature visterms and probabilistic aspect mo dels our approach us context in two way by using the fact that specific learned aspect correlate with the semant ic class which resolve some case of visual polysemy and by formalizing the notion that scene context is imagespecific what an individual visterm represents depends on what the rest of the visterms in the same bag represent too we demonstrate the validity of our approach on a man made v natural visterm classification problem experiment on an image collection of complex scene show that the approach improves region discrimination producing satisfa ctory result and outperforming a non contextual method furthermore through the later use of a markov random field model we also show that co occurrence and spatial contextual information can be conveniently integrated for improved visterm classification 
classifying moving object to semantically meaningful category is important for automatic visual surveillance however this is a challenging problem due to the factor related to the limited object size large intra class variation of object in a same class owing to different viewing angle and lighting and real time performance requirement in real world application this paper describes an appearance based method to achieve real time and robust object classification in diverse camera viewing angle a new descriptor i e the multi block local binary pattern mb lbp is proposed to capture the large scale structure in object appearance based on mb lbp feature an adaboost algorithm is introduced to select a subset of discriminative feature a well a construct the strong two class classifier to deal with the non metric feature value of mb lbp feature a multi branch regression tree is developed a the weak classifier of the boosting finally the error correcting output code ecoc is introduced to achieve robust multi class classification performance experimental result show that our approach can achieve real time and robust object classification in diverse scene 
this paper address the problem of shadow extraction from a single image of a complex natural scene no simplifying assumption on the camera and the light source other than the lambertian assumption is used our method is unique because it is capable of translating very rough user supplied hint into the effective likelihood and prior function for our bayesian optimization the likelihood function requires a decent estimation of the shadowless image which is obtained by solving the associated poisson equation our bayesian framework allows for the optimal extraction of smooth shadow while preserving texture appearance under the extracted shadow thus our technique can be applied to shadow removal producing some best result to date compared with the current state of the art technique using a single input image we propose related application in shadow compositing and image repair using our bayesian technique 
this paper present technique for improving the numerical stability of gr obner basis solver for polynomial equation recently gr obner basis method have been used succesfully to solve polynomial equation arising in global optimization e g three view triangulation and in many important minimal case of structure from motion such method work extremely well for problem of reasonably low degree involving a few variable currently the limiting factor in using these method for larger and more demanding problem is numerical difficulty in the paper we i show how to change basis in the quotient space r x i and propose a strategy for selecting a basis which improves the conditioning of a crucial elimination step ii use this technique to devise a gr obner basis with improved precision and iii show how solving for the eigenvalue instead of eigenvectors can be used to improve precision further while retaining the same speed we study these method on some of the latest reported us of gr obner basis method and demonstrate dramatically improved numerical precision using these new technique making it possible to solve a larger class of problem than previously 
abstract in stereo literature there is no standard method for evaluating algorithm for semi dense stereo matching moreover existing evaluation for dense method require a fixed parameter setting for the tested algorithm in this paper we propose a method that overcomes these drawback and still is able to compare algorithm based on a simple numerical value so that reporting result doe not take up much space in a paper we propose evaluation of stereo algorithm based on receiver operating characteristic roc which capture both error and sparsity by comparing roc curve of all tested algorithm we obtain the feasibility boundary the best possible performance achieved by a set of tested stereo algorithm which allows stereo algorithm user to select the proper method and parameter setting for a required application 
a new strategy is proposed for the design of cascaded object detector of high detection rate the problem of jointly minimizing the false positive rate and classification complexity of a cascade given a constraint on it detection rate is considered it is shown that it reduces to the problem of minimizing false positive rate given detection rate and is therefore an instance of the classic problem of cost sensitive learning a cost sensitive extension of bo osting denoted by asymmetric boosting is introduced it maintains a high detection rate across the boosting iteration and allows the design of cascaded detector of high overall detection rate experimental evaluation show th at when compared to previous cascade design algorithm the cascade produced by asymmetric boosting achieve significantly higher detection rate at the cost of a marginal in crease in computation 
this paper proposes an effective method for compensating inter reflection in immersive projection display ipds because ipds project image onto a screen which surround a viewer we have perform out both geometric and photometric correction our method compensates interreflection on the screen it requires no special device and approximates both diffuse and specular reflection on the screen using block based photometric calibration 
matching of high dimensional feature using nearest neighbor search is an important part of image matching method which are based on local invariant feature in this work we highlight effect pertinent to high dimensional space that are significant for matching yet have not been explicitly accounted for in previous work in our approach we require every nearest neighbor to be meaningful that is sufficiently close to a query feature such that it is an outlier to a background feature distribution we estimate the background feature distribution from the extended neighborhood of a query feature given by itsk nearest neighbor based on the concept of meaningful nearest neighbor we develop a novel high dimensional feature matching method and evaluate it performance by conducting image matching on two challenging image data set a superior performance in term of accuracy is shown in comparison to several state of the art approach additionally to make search for k nearest neighbor more efficient we develop a novel approximate nearest neighbor search method based on sparse coding with an overcomplete basis set that provides a ten fold speed up over an exhaustive search even for high dimensional space and retains excellent approximation to an exact nearest neighbor search 
in object tracking occlusion significantly undermine the performance of tracking algorithm unlike the existing method that solely depend on the observed target appearance to detect occluders we propose an algorithm that progressively analyzes the occlusion situation by exploiting the spatiotemporal context information which is further double checked by the reference target and motion constraint this strategy enables our proposed algorithm to make a clearer distinction between the target and occluders than existing approach to further improve the tracking performance we rectify the occlusion interfered erroneous target location by employing a variant mask template matching operation a a result correct target location can always be obtained regardless of the occlusion situation using these technique the robustness of tracking under occlusion is significantly promoted experimental result have confirmed the effectiveness of our proposed algorithm 
in this paper we introduce two new method for solving binary quadraticproblems while spectral relaxation method have been the workhorse subroutine for a wide variety of computer vision problem segmentation clustering image restoration to name a few it ha recently been challenged by semidefinite programming sdp relaxation in fact it can be shown that sdp relaxation produce better lower bound than spectral relaxation on binary problem with a quadratic objective function on the other hand the computational complexity for sdp increase rapidly a the number of decision variable grows making them inapplicable to large scale problem our method combine the merit of both spectral and sdp relaxation better lower bound than traditional spectral method and considerably faster execution time than sdp the first method is based on spectral subgradients and can be applied to large scale sdps with binary decision variable and the second one is based on the trust region problem both algorithm have been applied to several large scale vision problem with good performance relaxation produce better estimate than spectral method however a the number of variable grows the execution timesofthe semidefiniteprogramsincreaserapidly inpractice one is limited to a few hundred decision variable spectral and sdp relaxation method can be regarded a two point on an axis of increasing relaxation performance we introduce two alternative method that lie somewhere in betweenthese two relaxation unlikestandardsdp solver that suffer from bad time complexity they can still handle large scale problem the two method are based on a subgradient optimization scheme we show good performance on a number of experimental problem our main contribution are an efficient algorithm for solving binary sdp problem with quadratic objective function based on subgradient optimization is developed in addition we show how to incorporate linear constraint in the same program 
we present a motion exemplar approach for finding body configuration in monocular video a motion correlation technique is employed to measure the motion similarity at various space time location between the input video and stored video template these observation are used to predict the conditional state distribution of exemplar and joint position exemplar sequence selection and joint position estimation are then solved with approximate inference using gibbs sampling and gradient ascent the presented approach is able tofind joint position accurately for people with textured clothing result are presented on a dataset containing slow fast and incline walk video of various people from different view angle the result demonstrate an overall improvement compared to previous method 
we describe a new framework for globally solving the d d registration problem with unknown point correspondence this problem is significant a it is frequently encountered in many application existing method are not fully satisfactory mainly due to the risk of local minimum our framework is grounded on the lipschitz global optimization theory it achieves a guaranteed global optimality without any initialization by exploiting the special structure of the problem itself and of the d rotation space so we propose a box and ball algorithm which solves the problem efficiently the main idea of the work can be applied to many other problem a well 
most work in action recognition deal with sequence acquired by stationary camera with fixed viewpoint due to the camera motion the trajectory of the body part contain not only the motion of the performing actor but also the motion of the camera in addition to the camera motion different viewpoint of the same action in different environment result in different trajectory which can not be matched using standard approach in order to handle these problem we propose to use the multi view geometry between two action however well known epipolar geometry of the static scene where the camera are stationary is not suitable for our task thus we propose to extend the standard epipolar geometry to the geometry of dynamic scene where the camera are moving we demonstrate the versatility of the proposed geometric approach for recognition of action in a number of challenging sequence 
we introduce a new framework namely tensor canonical correlation analysis tcca which is an extension of classical canonical correlation analysis cca to multidimensional data array or tensor and apply this for action gesture classification in video by tensor cca joint space time linear relationship of two video volume are inspected to yield flexible and descriptive similarity feature of the two video the tcca feature are combined with a discriminative feature selection scheme and a nearest neighbor classifier for action classification in addition we propose a time efficient action detection method based on dynamic learning of subspace for tensor cca for the case that action are not aligned in the space time domain the proposed method delivered significantly better accuracy and comparable detection speed over state of the art method on the kth action data set a well a self recorded hand gesture data set 
we present a novel approach to automatically find spatial configuration of local feature occurring frequently on instance of a given object class and rarely on the background the approach is based on computationally efficient data mining technique and can find frequent configuration among ten of thousand of candidate within second based on the mined configuration we develop a method to select feature which have high probability of lying on previously unseen instance of the object class the technique is meant a an intermediate processing layer to filter the large amount of clutter feature returned by lowlevel feature extraction and hence to facilitate the task of higher level processing stage such a object detection 
we propose a multi resolution framework inspired by human visual search for general object detection different resolution are represented using a coarse to fine feature hierarchy during detection the lower resolution feature are initially used to reject the majority of negative window at relatively low cost leaving a relatively small number of window to be processed in higher resolution this enables the use of computationally more expensive higher resolution feature to achieve high detection accuracy we applied this framework on histogram of oriented gradient hog feature for object detection our multi resolution detector produced better performance for pedestrian detection than state of the art method dalal and triggs and wa faster during both training and testing testing our method on motorbike and car from the voc database revealed similar improvement in both speed and accuracy suggesting that our approach is suitable for realtime general object detection application 
in this paper we introduce a novel real time tracker based on color texture and motion information rgb color histogramand correlogram autocorrelogram are exploited a color cue and texture property are represented by local binary pattern lbp object s motion is taken into account through location and trajectory after extraction these feature are used to build a unifying distance measure the measure is utilized in tracking and in the classification event in which an object is leaving a group the initial object detection is done by a texture based background subtraction algorithm the experiment on indoor and outdoor surveillance video show that a unified system work better than the version based on single feature it also cope well with low illumination condition and low frame rate which are common in large scale surveillance system 
histogram of orientation and the statistic derived from them have proven to be effective image representation for various recognition task in this work we attempt to improve the accuracy of object detection system by including new feature that explicitly capture mid level gestalt con cepts four new image feature are proposed inspired by the gestalt principle of continuity symmetry closure and repetition the resulting image representation are used jointly with existing state of the art feature and together enable be tter detector for challenging real world data set a base line feature we use riesenhuber and poggio s c feature and dalan and triggs histogram of oriented gradient feature given that both of these baseline feature have already shown state of the art performance in multiple object detection benchmark that our new midlevel representation can further improve detection resul t warrant special consideration we evaluate the performance of these detection system on the publicly available streetscenes and caltech database among others 
use of ir image is advantageous for many surveillance application where the system must operate around the clock and external illumination is not always available we investigate the method derived from visible spectrum analysis for the task of human detection two feature class edgelets and hog feature and two classification model adaboost and svm cascade are extended to ir image we find out that it is possible to get detection performance in ir image that is comparable to state of the art result for visible spectrum image it is also shown that the two domain share many feature likely originating from the silhouette in spite of the starkly different appearance of the two modality 
we propose an approach to activity recognition based on detecting and analyzing the sequence of object that are being manipulated by the user in domain such a cooking where many activity involve similar action object use information can be a valuable cue in order for this approach to scale to many activity and object however it is necessary to minimize the amount of human labeled data that is required for modeling we describe a method for automatically acquiring object model from video without any explicit human supervision our approach leverage sparse and noisy reading from rfid tagged object along with common sense knowledge about which object are likely to be used during a given activity to bootstrap the learning process we present a dynamic bayesian network model which combine rfid and video data to jointly infer the most likely activity and object label we demonstrate that our approach can achieve activity recognition rate of more than on a real world dataset consisting of household activity involving object with significant background clutter we show that the combination of visual object recognition with rfid data is significantly more effective than the rfid sensor alone our work demonstrates that it is possible to automatically learn object model from video of household activity and employ these model for activity recognition without requiring any explicit human labeling 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
biometric identification ha numerous advantage over conventional id and password system however the lack of anonymity and revocability of biometric template is of concern several method have been proposed to address these problem many of the approach require a precise registration before matching in the anonymous domain we introduce binary string representation of fingerprint that obviates the need for registration and can be directly matched we describe several technique for creating anonymous and revocable representation using these binary string representation the match performance of these representation is evaluated using a large database of fingerprint image we prove that given an anonymous representation it is computationally infeasible to invert it to the original fingerprint thereby preserving privacy to the best of our knowledge this is the first linear anonymous and revocable fingerprint representation that is implicitly registered 
we propose a unified framework based on a general definition of geometric transform get for modeling appearance get represents the appearance by applying designed functionals over certain geometric set we show that image warping radon transform trace transform etc are special case of our definition moreover three different type of get are designed to handle deformation articulation and occlusion and applied to fingerprinting the appearance inside a contour they include the contour driven get the feature curve based get and selecting functionals to model the appearance inside the convex hull of the contour a multi resolution representation that combine both shape and appearance information is also proposed we apply our approach to image synthesis and object recognition the proposed approach produce promising result when applied to fingerprinting the appearance of human and body part despite the challenge due to articulated motion and deformation 
we propose a linear programming relaxation scheme for the class of multiple object tracking problem where the inter object interaction metric is convex and the intra object term quantifying object state continuity may use any metric the proposed scheme model object tracking a a multi path searching problem it explicitly model track interaction such a object spatial layout consistency or mutual occlusion and optimizes multiple object track simultaneously the proposed scheme doe not rely on track initialization and complex heuristic it ha much le average complexity than previous efficient exhaustive search method such a extended dynamic programming and is found to be able to find the global optimum with high probability we have successfully applied the proposed method to multiple object tracking in video stream 
it s often important to analyze shape a made up of part but there are two way to think of how part fit together we can characterize the remainder of a shape after a part is removed here we want to cut the shape so what remains ha the simplest possible structure alternatively we can cut out the part so that the part itself take on a simple shape these cut do not directly give rise to a segmentation of the shape a point inside the shape may associate with the part the remainder neither or both we present a new model for reconstructing these cut based on the differential geometry of smoothed local symmetry the model take into account relatability which characterizes clean cut to determine part boundary our approach complement and unifies existing work on partbased segmentation of shape and can be used to construct interesting simplification of shape 
we propose a new method to estimate multiple rigid motion from noisy d point correspondence in the presence of outlier the method doe not require prior specification of number of motion group and estimate all the motion parameter simultaneously we start with generating sample from the rigid motion distribution the motion parameter are then estimated via mode finding operation on the sampled distribution since rigid motion do not lie on a vector space classical statistical method can not be used for mode finding we develop a mean shift algorithm which estimate mode of the sampled distribution using the lie group structure of the rigid motion we also show that proposed mean shift algorithm is general and can be applied to any distribution having a matrix lie group structure experimental result on synthetic and real image data demonstrate the superior performance of the algorithm 
we propose a novel mrf based model for deformable image matching also known a registration the deformation is described by a field of discrete variable representing displacement of block of pixel discontinuity in the deformation are prohibited by imposing hard pairwise constraint in the model exact maximum a posteriori inference is intractable and we apply a linear programming relaxation technique we show that when reformulated in the form of two coupled field of xand y displacement the problem lead to a simpler relaxation to which we apply the sequential tree reweighted message passing trw s algorithm wainwright kolmogorov this enables image registration with large displacement at a single scale we employ fast message update for a special type of interaction a wa proposed felzenszwalb and huttenlocher for the max product belief propagation bp and introduce a few independent speedup in contrast to bp the trw s allows u to compute per instance approximation ratio and thus to evaluate the quality of the optimization the performance of our technique is demonstrated on both synthetic and real world experiment 
the concept of the bayesian optimal single threshold is a well established and widely used classification technique in this paper we prove that when spatial cohesion is assumed for target a better classification result than the optimal single threshold classification can be achieved under the assumption of spatial cohesion and certain prior knowledge about the target and background the method can be further simplified a dual threshold classification in core dual threshold classification spatial cohesion within the target core allows continuation linking value to fall between the two threshold to the target core classical bayesian classification is employed beyond the dual threshold the core dual threshold algorithm can be built into a markov random field model mrf from this mrf model the dual threshold can be obtained and optimal classification can be achieved in some practical application a simple method called symmetric subtraction may be employed to determine effective dual threshold in real time given dual threshold the quasi connected component algorithm is shown to be a deterministic implementation of the mrf core dual threshold model combining the dual threshold extended neighborhood and efficient connected component computation 
creating uniform lighting for archival quality document acquisition remains a non trivial problem we propose a novel method for automatic photometric correction of nonplanar document by estimating a single point light source using a simple light probe by adding a simple piece of folded white paper with a known d surface to a scene we are able to extract the d position of a light source automatically perform white balance correction and determine area of poor illumination furthermore this method is designed with the purpose of adding it to an already implemented document digitization pipeline to justify our claim we provide an accuracy analysis of our correction technique using simulated ground truth data which allows individual source of error to be determined and compared these technique are then applied on real document that have been acquired using a d scanner 
this paper present a fast accurate and novel method for the problem of estimating the number of human and their position from background differenced image obtained from a single camera where inter human occlusion is significant the problem is challenging firstly because the state space formed by the number position and articulation of people is large secondly in spite of many advance in background maintenance and change detection background differencing remains a noisy and imprecise process anditsoutput is far from ideal hole fill in irregular boundary etc pose additional challenge for our midlevel problem of segmenting it to localize human we propose a novel example based algorithm which map the global shape feature by fourier descriptor to various configuration of human directly we use locally weighted averaging to interpolate for the best possible candidate configuration the inherent ambiguity resulting from the lack of depth and layer information in the background difference image is mitigated by the use of dynamic programming which find the trajectory in state space that best explains the evolution of the projected shape the key component of our solution are simple and fast we demonstrate the accuracy and speed of our approach on real image sequence 
we present variable aperture photography a new method for analyzing set of image captured with different aperture setting with all other camera parameter fixed we show that by casting the problem in an image restoration framework we can simultaneously account for defocus high dynamic range exposure hdr and noise all of which are confounded according to aperture our formulation is based on a layered decomposition of the scene that model occlusion effect in detail recovering such a scene representation allows u to adjust the camera parameter in post capture to achieve change in focus setting or depthof field with all result available in hdr our method is designed to work with very few input image we demonstrate result from real sequence obtained using the threeimage aperture bracketing mode found on consumer digital slr camera 
line localization from a single image of a central camera is an ill posed problem unless other constraint or apriori knowledge are exploited recently it ha been proved that noncentral catadioptric camera allow space line to be localized from a single image in this paper we propose two novel localization algorithm the first method exploit a pair of coplanar viewing ray to localize the space line the second method follows a constrained non linear minimization procedure using a suitable parametrization to represent space line we compare the accuracy of the proposed method w r t the classical line localization algorithm and two robust variant of it we carried out both synthetic and real experiment and evaluated the performance in localizing a set of space line we also propose a quality index for the viewing surface associated to space line in order to better evalua te the quality of the localization the experimental result showed the effectiveness and the accuracy of both proposed method 
recently method for estimating d scene geometry or absolute scene depth information from d image content have been proposed however general applicability of these method in depth estimation may not be realizable a inconsistency may be introduced due to a large variety of possible pictorial content we identify scene categorization a the r st step towards efcient and robust depth estimation from single image to that end we describe a limited number of typical d scene geometry called stage each having a unique depth pattern and thus providing a specic context for stage object this type of scene information narrow down the possibility with respect to individual object location scale and identity we show how these stage type can be efciently learned and how they can lead to robust extraction of depth information our result indicate that stage without much variation and object clutter can be detected robustly with up to success rate 
a study of the performance of recently introduced discriminant method for interest point detection is presented it ha been previously shown that the resulting interest point are more informative for object recognitio n than those produced by the detector currently used in computer vision little is however known about the propertie s of discriminant point with respect to the metric such a repeatability that have been traditionally used to evalua te interest point detection a thorough experimental evaluation of the stability of discriminant point is presented a nd this stability compared to those of four popular method in particular we consider image correspondence under geometric and photometric transformation and extend the experimental protocol proposed by mikolajczyk et al for the evaluation of stability with respect to such transfo rmations the extended protocol is suitable for the evaluation of both bottom up and top down learned detector it is shown that the stability of discriminant interest poin t is comparable and frequently superior to those of interes t point produced by various currently popular technique 
the use of video sequence for face recognition ha been relatively le studied than image based approach in th is paper we present a framework for face recognition from video sequence that is robust to large change in facial pose and lighting condition our method is based on a recently obtained theoretical result that can integrate th e effect of motion lighting and shape in generating an image using a perspective camera this result can be used to estimate the pose and illumination condition for each frame of the probe sequence then using a d face model we synthesize image corresponding to the pose and illumination condition estimated in the probe sequence similarity between the synthesized image and the probe video is computed by integrating over the entire sequence the method can handle situation where the pose and lighting condition in the training and testing data are completely disjoint it is believed by many that video based face recognition system hold promise in certain application where motion can be used a a cue for face segmentation and tracking and the presence of more spatio temporally coherent data can increase recognition performance however these system have their own challenge such a tracking the face over time d modeling change of pose and lighting over the sequence duration and developing efficient measure for integrating information over the entire sequence in th is paper we present a novel framework for video based face recognition that is based on learning joint illumination and motion model from video synthesizing novel view based on the learned parameter and using a metric that can compare two time sequence while being robust to outlier we show experimentally that our method achieves high identification rate under extreme change of pose and illumination 
the invariance of the similarity measure in photometric distortion a well a it capability in producing sub pixel accuracy are two desired and often required feature in most stereo vision application in this paper we propose a new correlation based measure which incorporates both mentioned requirement specifically by using an appropriate interpolation scheme in the candidate window of the matching image and using the classical zero mean normalized cross correlation function we introduce a suitable measure although the proposed measure is a non linear function of the sub pixel displacement parameter it maximization result in a closed form solution resulting in reduced complexity for it use in matching technique application of the proposed measure in a number of benchmark stereo pair image reveals it superiority over existing correlation based technique used for sub pixel accuracy 
abstract geologist and planetary scientist will benefit from method for accurate segmentation of rock in natural scene however rock are poorly suited for current visual segmentation technique they exhibit diverse morphology and have no uniform property to distinguish them from background soil we address this challenge with a novel detection and segmentation method incorporating feature from multiple scale these feature include local attribute such a texture object attribute such a shading and twodimensional shape and scene attribute such a the direction of illumination our method us a superpixel segmentation followed by region merging to search for the most probable group of superpixels a learned model of rock appearance identifies whole rock by scoring candidate superpixel grouping we evaluate our method s performance on representative image from the mar exploration rover catalog 
we address the problem of detecting irregularity in visual data e g detecting suspicious behavior in video sequence or identifying salient pattern in image the term irregular depends on the context in which the regular or valid are defined yet it is not realistic to expect explicit definition of all possible valid configuration for a given context we pose the problem of determining the validity of visual data a a process of constructing a puzzle we try to compose a new observed image region or a new video segment the query using chunk of data piece of puzzle extracted from previous visual example the database region in the observed data which can be composed using large contiguous chunk of data from the database are considered very likely whereas region in the observed data which cannot be composed from the database or can be composed but only using small fragmented piece are regarded a unlikely suspicious the problem is posed a an inference process in a probabilistic graphical model we show application of this approach to identifying saliency in image and video and for suspicious behavior recognition 
in this work we introduce the usage of bilinear model a a mean of factorising the shape variation induced by subject variability and the contraction of the human heart we show that it is feasible to reconstruct the shape of the heart at a certain point in the cardiac cycle if we are given a small number of shape representing the same heart at different point in the same cycle using the bilinear model depending on pathology and the ratio between healthy and pathological heart in the training set rms reconstruction error measured between and millimetre with a median of and th percentile of millimetre 
this article proposes an active basis model and a shared pursuit algorithm for learning deformable template from image patch of various object category in our generative model a deformable template is in the form of an active basis which consists of a small number of gabor wavelet element at different location and orientation these el ements are allowed to slightly perturb their location and orientation before they are linearly combined to generate each individual training or testing example the active basis model can be learned from training image patch by the shared pursuit algorithm the algorithm selects the element of the active basis sequentially from a dictionary of gabor wavelet when an element is selected at each step the element is shared by all the training example in the sense that a perturbed version of this element is added to improve the encoding of each example our model and algorithm are developed within a probabilistic framework that naturally embrace wavelet sparse coding and random field 
this paper investigates the feasibility of using diffusion mri to measure axon cell dimension in the white matter of live subject a simple geometric model of white matter tissue provides an expression that relates the axon radius to the diffusion mri signal the aim is to determine the accuracy and precision with which we can estimate this potentially important new biomarker precision and accuracy depend critically on the acquisition protocol the paper proposes a general strategy to optimize the experiment design of in vivo diffusion mri experiment the applicability of the design optimization extends well beyond the current work to optimizing the acquisition for any model of the diffusion process simulation experiment and result suggest feasibility of measuring larger axon radius in vivo on modern mri scanner using the optimized acquisition scheme but that higher gradient strength are required to measure smaller axon 
this paper deal with region of interest roi tracking in video sequence the goal is to determine in successive frame the region which best match in term of a similarity measure an roi defined in a reference frame two aspect of a similarity measure between a reference region and a candidate region can be distinguished radiometry which check if the region have similar color and geometry which check if these color appear at the same location in the region measure based solely on radiometry include distance between probability density function pdf of color the absence of geometric constraint increase the number of potential match a soft geometric constraint can be added to a pdf based measure by enriching the color information with location thus increasing the dimension of the domain of definition of the pdfs however high dimensional pdf estimation is not trivial instead we propose to compute the kullback leibler distance between high dimensional pdfs without explicitly estimating the pdfs the distance is expressed directly from the sample using the k th nearest neighbor framework tracking experiment were performed on several standard sequence 
real world action occur often in crowded dynamic environment this pose a difficult challenge for current approach to video event detection because it is difficult to segment the actor from the background due to distracting motion from other object in the scene we propose a technique for event recognition in crowded video that reliably identifies action in the presence of partial occlusion and background clutter our approach is based on three key idea we efficiently match the volumetric representation of an event against oversegmented spatio temporal video volume we augment our shape based feature using flow rather than treating an event template a an atomic entity we separately match by part both in space and time enabling robustness against occlusion and actor variability our experiment on human action such a picking up a dropped object or waving in a crowd show reliable detection with few false positive 
this paper describes the construction and use of a novel representation for the recognition of object and their part the semantic hierarchy it advantage include improved classification performance accurate detection and localization of object part and sub part and explicitly identifying the different appearance of each object part the semantic hierarchy algorithm start by constructing a minimal feature hierarchy and proceeds by adding semantically equivalent representative to each node using the entire hierarchy a a context for determining the identity and location of added feature part detection is obtained by a bottom up top down cycle unlike previous approach the semantic hierarchy learns to represent the set of possible appearance of object part at all level and their statistical dependency the algorithm is fully automatic and is shown experimentally to substantially improve the recognition of object and their part 
given five motion vector observed in a calibrated camera what is the rotational and translational velocity of the camera this problem is the infinitesimal motion analogue tothefive pointrelativeorientationproblem whichhaspreviously been solved through the derivation of a tenth degree polynomial and extraction of it root here we present the first efficient solution to the infinitesimal version of the problem the solution is faster than it finite counterpart in our experiment we investigate over which range of motion and scene distance the infinitesimal approximation is valid and show that the infinitesimal approximation work well in application such a camera tracking 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
automatic image annotation ha been an active research topic due to it great importance in image retrieval and management however result of the state of the art image annotation method are often unsatisfactory despite continuous effort in inventing new annotation algorithm it would be advantageous to develop a dedicated approach that could refine imprecise annotation in this paper a novel approach to automatically refining the original annotation of image is proposed for a query image an existing image annotation method is first employed to obtain a set of candidate annotation then the candidate annotation are re ranked and only the top one are reserved a the final annotation by formulating the annotation refinement process a a markov process and defining the candidate annotation a the state of a markov chain a content based image annotation refinement ciar algorithm is proposed to re rank the candidate annotation it leverage both corpus information and the content feature of a query image experimental result on a typical corel dataset show not only the validity of the refinement but also the superiority of the proposed algorithm over existing one 
a video containing multiple object in rotational and translational motion is analyzed through a combination of spatial and frequency domain representation it is argued that the combined analysis can take advantage of the strength of both representation initial estimate of constant a well a time varying translation and rotation velocity are obtained from frequency analysis improved motion estimate and motion segmentation for the case of translation are achieved by integrating spatial and fourier domain information for combined rotational and translational motion the frequency representation is used for motion estimation but only spatial information can be used to separate and extract the independently moving object the proposed algorithm are tested on synthetic and real video 
we consider the problem of reconstructing the shape of a surface with an arbitrary spatially varying isotropic bidirectional reflectance distribution function brdf and introduce a novel stratified photometric stereo method by using a particular configuration of light it is possible to use symmetry in the image measurement resulting from brdf isotropy to estimate at each point a plane containing the surface normal for differentiable surface this allows u to recover the isocontours of the depth map but not the actual depth associated with each contour the isocontour structure provides topological information about the surface critical point reeb graph etc by using additional cue in the image data or imposing additional constraint on the surface e g shadow specular highlight helmholtz reciprocity uniform brdf the unknown height of each isocontour can be estimated and the metric structure is resolved we validate this technique on real and synthetic data by successfully recovering the isocontours of the depth map from image 
this work report on the advance and on the current status of a terrestrial city modeling approach which us image contributed by end user a input hence the wiki principle well known from textual knowledge database is transferred to the goal of incrementally building a virtual representation of the occupied habitat in order to achieve this objective many state of the art computer vision method must be applied and modified according to this task we describe the utilized d vision method and show initial result obtained from the current image database acquired by in house participant 
structural perception of data play a fundamental role in pattern analysis and machine learning in this paper we develop a new structural perception of data based on local context we first identify the contextual set of a point by finding it nearest neighbor then the contextual distance between the point and one of it neighbor is defined by the difference between their contribution to the integrity of the geometric structure of the contextual set which is depicted by a structural descriptor the centroid and the coding length are introduced a the example of descriptor of the contextual set furthermore a directed graph digraph is built to model the asymmetry of perception the edge of the digraph are weighted based on the contextual distance thus direction is brought to the undirected data and the structural perception of data can be performed by mining the property of the digraph we also present the method for deriving the global digraph laplacian from the alignment of the local digraph laplacians experimental result on clustering and ranking of toy problem and real data show the superiority of asymmetric perception 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
numerous technique were invented in computer vision and photogrammetry to obtain spatial information from digital image we intend to describe and improve the performance of these vision technique by providing test objective data metric and test protocol in this paper we propose a comprehensive benchmarking dataset for evaluating a variety of automatic surface reconstruction algorithm shape from x and a methodology for comparing their result 
we study retinal curvature estimation from multiple image that provides the fundamental geometry of human retina we use an afne camera model due to it simplicity linearity and robustness moreover the afne camera is suitable in this research because nih s retinal imaging protocol specify a narrow eld of vie w in each eye and each eld ha small depth variation a major challenge is that there is a series of optic involved in the imaging process including an actual fundus camera a digital camera and the human cornea all of which cause signicant non linear distortion in the retinal image in this work we develop a new constrained optimization procedure that considers both the geometric shape of human retina and lens distortion moreover the constrained optimization is implemented in the afne space because it is computationally efcient and robust to noise specically we amend the afne bundle adjustment algorithm by including a quadratic surface tting error and the lens distortion correction into the cost function for constrained optimization the experiment on both synthetic data and real retinal image show the effectiveness and robustness of the proposed algorithm 
this paper present reliable technique for detecting tracking and storing keyframes of people in surveillance video the first component of our system is a novel face detector algorithm which is based on first learning local adaptive feature for each training image and then using adaboost learning to select the most general feature for detection this method provides a powerful mechanism for combining multiple feature allowing faster training time and better detection rate the second component is a face tracking algorithm that interleaf multiple view based classifier along the temporal domain in a video sequence this interleaving technique combined with a correlation based tracker enables fast and robust face tracking over time finally the third component of our system is a keyframe selection method that combine a person classifier with a face classifier the basic idea is to generate a person keyframe in case the face is not visible in order to reduce the number of false negative we performed quantitatively evaluation of our technique on standard datasets and on surveillance video captured by a camera over several day 
abstract we propose a novel generative language for shape that is based on the shock graph given a shock graph topology we explore constraint on the geometry and dynamic of the shock graph branch at each point required to generate a valid shape i e with no self intersection cusp or crossover we model the shape boundary a a piecewise smooth circular arc spline which is dense in the space of piecewise smooth curve using this model we derive an independent set of parameter which generate a variety of shape and satisfy the reconstruction constraint we show simple example of using this generative model a an active deformable shape and for morphing between two shape the result illustrate that it is possible to generate any generic shape with relatively few parameter further reduced if prior knowledge of shape is available 
we propose a first attempt to classify event in static image by integrating scene and object categorization we define an event in a static image a a human activity taking place in a specific environment in this paper we use a number of sport game such a snow boarding rock climbing or badminton to demonstrate event classification our goal is to classify the event in the image a well a to provide a number of semantic label to the object and scene environment within the image for example given a rowing scene our algorithm recognizes the event a rowing by classifying the environment a a lake and recognizing the critical object in the image a athlete rowing boat water etc we achieve this integrative and holistic recognition through a generative graphical model we have assembled a highly challenging database of widely varied sport event we show that our system is capable of classifying these event class at accuracy while each component of the model contributes to the final recognition using scene or object alone cannot achieve this performance 
reconstructing large model from image is a significant challenge for computer vision computer graphic and related field in this paper we present an approach for simplifying the reconstruction process by mathematically eliminating external camera parameter this result in le parameter to estimate and in an overall significantly more robust and accurate reconstruction we reformulate the problem in such a manner a to be able to identify invariant eliminate superfluous parameter and measure the performance of our formulation under various condition we compare a two step camera orientation free method where the majority of the point are reconstructed using a linear equation set and a camera position andorientation free method using a degree two equation set both approach use a full perspective camera and are applied to synthetic and real world datasets 
minimizing l error norm for some geometric vision problem provides global optimization using the welldeveloped algorithm called socp second order cone programming because the error norm belongs to quasiconvex function bisection method is utilized to attain the global optimum it test the feasibility of the intersection of all the second order cone due to measurement repeatedly adjusting the global error level the computation time increase according to the size of measurement data since the number of second order cone for the feasibility test inflates correspondingly we observe in this paper that not all the data need be included for the feasibility test because we minimize the maximum of the error we may use only a subset of the measurement to obtain the optimal estimate and therefore we obtain a decreased computation time in addition by using l image error instead of l euclidean distance we show that the problem is still a quasi convex problem and can be solved by bisection method but with linear programming lp our algorithm and experimental result are provided 
bottom up approach which rely mainly on continuity principle are often insufficient to form accurate segment in natural image in order to improve performance recent method have begun to incorporate top down cue or object information into segmentation in this paper we propose an approach to utilizing category based information in segmentation through a formulation a an image labelling problem our approach exploit bottom up image cue to create an over segmented representation of an image the segment are then merged by assigning label that correspond to the object category the model is trained on a database of image and is designed to be modular it learns a number of image context which simplify training and extend the range of object class and image database size that the system can handle the learning method estimate model parameter by maximizing a lower bound of the data likelihood we examine performance on three real world image database and compare our system to a standard classifier and other conditional random field approach a well a a bottom up segmentation method 
in this paper we present a framework for dynamic consistent estimation of dense motion eld over a sequence of image the originality of the approach is to exploit recipe related to optimal control theory this setup allows performing the estimation of an unknown state function according to a given dynamical model and to noisy and incomplete measurement the overall process is formalized through the minimization of a global spatio temporal cost functional w r t the complete sequence of motion eld the minimization is handled considering an adjoint formulation the resulting scheme consists in iterating a forward integration of the evolution model and a backward integration of the adjoint evolution model guided by a discrepancy measurement between the state variable and the available noisy observation such an approach allows u to cope with several delicate situation such a the absence of data which are not well managed with usual estimator tionary local prior moreover strong artifact are managed with difculty such approach can not be used to enforce on the whole sequence a solution minimizing an image based discrepancy measure and in the same time that follows a given dynamical model this kind of tracking process is indeed very difcult to manage with stochastic technique a the variable s state space is of huge dimension theoretically innite and can not be efciently handled with usual recursive bayesian lters such a the particle lter in this paper we propose a variational technique which allows u to estimate a sequence of dense motion eld guided by a given dynamical law to that end we suggest to rely on recipe related to optimal control theory and variational data assimilation a bayesian smoothing such technique allow to estimate on the basis of noisy and possibly incomplete observation a feature trajectory a sequence of dense motion eld in our application respecting a specied evolution law the associated minimization process is efciently expressed considering an adjoint formulation the adjoint variable introduced enables to compute the gradient of the cost function from a forward backward integration of two coupled evolution model this efcient procedure authorizes coping with state space of very large dimension 
we study the beneficial effect of side information on the structure from motion sfm estimation problem the side informationthat we consider is measurementofa reference vector and distance from fixed plane perpendicular to that reference vector firstly we show that in the presence of this information the sfm equationscan be rewritten similar to a bilinear form in it unknown secondly we describe a fast iterative estimation procedure to recover the structure of both stationary scene and moving object that capitalizes on this information we also provide a refinement procedure in order to tackle incomplete or noisy side information we characterize the algorithm with respect to it reconstruction accuracy memory requirement and stability finally we describe two class of commonly occurring real world scenario in which this algorithm will be effective a presence of a dominant ground plane in the scene and b presence of an inertial measurement unit on board experiment using both real data and rigorous simulation show the efficacy of the algorithm 
the active appearance model aam is a powerful generative method for modeling and registering deformable visual object most method for aam fitting utilize a linear parameter update model in an iterative framework despite it popularity the scope of this approach is severely restricted both in fitting accuracy and capture range due to the simplicity of the linear update model used in this paper we present an new aam fitting formulation which utilizes a nonlinear update model to motivate our approach we compare it performance against two popular fitting method on two publicly available face database in which this formulation boast significant performance improvement 
this paper present a new method for the recognition and reconstruction of surface from d data line element geometry which generalizes both line geometry and the laguerre geometry of oriented plane enables u to recognize a wide class of surface spiral surface cone helical surface rotational surface cylinder etc by fitting linear subspace in an appropriate seven dimensional image space in combination with standard technique such a pca and ransac line element geometry is employed to effectively perform the segmentation of complex object according to surface type example show application in reverse engineering of cad model and testing mathematical hypothesis concerning the exponential growth of sea shell 
a method is presented for separating corneal reflection in an image of human iris to estimate illumination from the surrounding scene previous technique for reflection separation have demonstrated success in only limited case such a for uniform colored lighting and simple object texture so they are not applicable to iris which exhibit intricate texture and complicated reflection of the environment to make this problem feasible we present a method that capitalizes on physical characteristic of human iris to obtain an illumination estimate that encompasses the prominent light contributor in the scene result of this algorithm are presented for eye of different color including light colored eye for which reflection separation is necessary to determine a valid illumination estimate 
recent result on stereo indicate that an accurate segmentation is crucial for obtaining faithful depth map variational method have successfully been applied to both image segmentation and computational stereo in this paper we propose a combination in a unifiedframework in particular we use a mumford shah like functional to compute a piecewise smooth depth map of a stereo pair our approach ha two novel feature first the regularization term of the functional combine edge information obtained from the color segmentation with flow driven depth discontinuity emerging during the optimization procedure second we propose a robust data term which adaptively selects the best match obtained from different weak stereo algorithm we integrate these feature in a theoretically consistent framework the final depth map is the minimizer of the energy functional which can be solved by the associated functional derivative the underlying numerical scheme allows an efficient implementation on modern graphic hardware we illustrate the performance of our algorithm using the middlebury database a well a on real imagery 
a randomized model verification strategy for ransac is presented the proposed method find like ransac a solution that is optimal with user controllable probability n a provably optimal model verification strategy is designed for the situation when the contamination of data by outlier is known i e the algorithm is the fastest possible on average of all randomized ransac algorithm guaranteeing n confidence in the solution the derivation of the optimality property is based on wald s theory of sequential decision making the r ransac with sprt which doe not require the a priori knowledge of the fraction of outlier and ha result close to the optimal strategy is introduced we show experimentally that on standard test data the method is to time faster than the standard ransac and up to time faster than previously published method 
we introduce an approach to accurately detect and segment partially occluded object in various viewpoint and scale our main contribution is a novel framework for combining object level description such a position shape and color with pixel level appearance boundary and occlusion reasoning in training we exploit a rough d object model to learn physically localized part appearance to find and segment object in an image we generate proposal based on the appearance and layout of local part the proposal are then refined after incorporating object level information and overlapping object compete for pixel to produce a final description and segmentation of object in the scene a further contribution is a novel instance penalty which is handled very efficiently during inference we experimentally validate our approach on the challenging pascal car database 
dimensionality reduction and clustering on statistical manifold is presented statistical manifold is a d riemannian manifold which is statistically defined by map that transform a parameter domain onto a set of probability density function principal component analysis pca based dimensionality reduction is performed on the manifold and therefore estimation of a mean and a variance of the set of probability distribution are needed first the probability distribution are transformed by an isometric transform that map the distribution onto a surface of hyper sphere the sphere construct a riemannian manifold with a simple geodesic distance measure then a frechet mean is estimated on the riemannian manifold to perform the pca on a tangent plane to the mean experimental result show that clustering on the riemannian space produce more accurate and stable classification than the one on euclidean space 
abstract 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
this paper proposes a discriminative framework for efficiently aligning image although conventional active appearance model aam based approach have achieved some success they suffer from the generalization problem i e how to align any image with a generic model we treat the iterative image alignment problem a a process of maximizing the score of a trained two class classifier that is able to distinguish correct alignment positive class from incorrect alignment negative class during the modeling stage given a set of image with ground truth landmark we train a conventional point distribution model pdm and a boosting based classifier which we call boosted appearance model bam when tested on an image with the initial landmark location the proposed algorithm iteratively update the shape parameter of the pdm via the gradient ascent method such that the classification score of the warped image is maximized the proposed framework is applied to the face alignment problem using extensive experimentation we show that compared to the aam based approach this framework greatly improves the robustness accuracy and efficiency of face alignment by a large margin especially for unseen data 
this paper explores the use of volumetric feature for action recognition first we propose a novel method to correlate spatio temporal shape to video clip that have been automatically segmented our method work on over segmented video which mean that we do not require background subtraction for reliable object segmentation next we discus and demonstrate the complementary nature of shapeand flow based feature for action recognition our method when combined with a recent flow based correlation technique can detect a wide range of action in video a demonstrated by result on a long tennis video although not specifically designed for whole video classification we also show that our method s performance is competitive with current action classification technique on a standard video classification dataset 
matrix factorization is a key component for solving several computer vision problem it is particularly challenging in the presence of missing or erroneous data which often arise in structure from motion we propose batch algorithm for matrix factorization they are based on closure and basisconstraints that are used either on the camera or the structure leading to four possible algorithm the constraint are robustly computed from complete measurement sub matrix with e g random data sampling the camera and d structure are then recovered through linear least square prior information about the scene such a identical camera position or orientation smooth camera trajectory known d point and coplanarity of some d point can be directly incorporated we demonstrate our algorithm on challenging image sequence with tracking error and more than missing data 
photometric stereo is a fundamental approach in computer vision at it core lie a set of image irradiance equation each taken with a different illumination the vast majority of study in this field have assumed orthography a the projection model this paper re examines the basic set of equation of photometric stereo under an assumption of perspective projection we show that the resulting system is linear a is the case under the orthographic model nevertheless the unknown are different in the perspective case we then suggest a simple reconstruction algorithm based on the perspective formula and compare it to it orthographic counterpart on synthetic a well a real image this algorithm obtained lower error rate than the orthographic one in all of the error measure these finding strengthen the hypothesis that a more realistic set of assumption the perspective one improves reconstruction significantly 
this paper introduces a new method for simultaneous estimation of lens distortion and multi view geometry using only point correspondence the new technique ha significant advantage over the current state of the art in that it make more effective use of correspondence arising from any number of view multi view geometry in the presence of lens distortion can be expressed a a set of point correspondence constraint that are quadratic in the unknown distortion parameter previous work ha demonstrated how the system can be solved efficiently a a quadratic eigenvalue problem by operating on the normal equation of the system although this approach is appropriate for situation in which only a minimal set of matchpoints are available it doe not take full advantage of extra correspondence in overconstrained situation resulting in significant bias and many potential solution the new technique directly operates on the initial constraint equation and solves the quadratic eigenvalue problem in the case of rectangular matrix the method is shown to contain significantly le bias on both controlled and real world data and in the case of a moving camera where additional view serve to constrain the number of solution an accurate estimate of both geometry and distortion is achieved 
histogram of local appearance descriptor are a popular representation for visual recognition they are highly discriminant and have good resistance to local occlusion and to geometric and photometric variation but they are not able to exploit spatial co occurrence statistic at scale larger than their local input patch we present a new multilevel visual representation hyperfeatures that is designed to remedy this the starting point is the familiar notion that to detect object part in practice it often suffices to detect co occurrence of more local object fragment a process that can be formalized a comparison e g vector quantization of image patch against a codebook of known fragment followed by local aggregation of the resulting codebook membership vector to detect co occurrence this process convert local collection of image descriptor vector into somewhat le local histogram vector higher level but spatially coarser descriptor we observe that a the output is again a local descriptor vector the process can be iterated and that doing so capture and code ever larger assembly of object part and increasingly abstract or semantic image property we formulate the hyperfeatures model and study it performance under several different image coding method including clustering based vector quantization gaussian mixture and combination of these with latent dirichlet allocation we find that the resulting high level feature provide improved performance in several object image and texture image classification task 
object based segmentation is a challenging topic most of the previous algorithm focused on segmenting a single or a small set of object in this paper the multiple class object based segmentation is achieved using the appearance and bag of keypoints model integrated over mean shift patch we also propose a novel affine invariant descriptor to model the spatial relationship of keypoints and apply the elliptical fourier descriptor to describe the global shape the algorithm is computationally efficient and ha been tested for three real datasets using le training sample our algorithm provides better result than other study reported in the literature 
the state of the art object detection algorithm learns a binary classifier to differentiate the foreground object from the background since the detection algorithm exhaustively scan the input image for object instance by testing the classifier it computational complexity linearly depends on the image size and if say orientation and scale are scanned the number of configuration in orientation and scale we argue that exhaustive scanning is unnecessary when detecting medical anatomy because a medical image offer strong contextual information we then present an approach to effectively leveraging the medical context leading to a solution that need only one scan in theory or several sparse scan in practice and only one integral image even when the rotation is considered the core is to learn a regression function based on an annotated database that map the appearance observed in a scan window to a displacement vector which measure the difference between the configuration being scanned and that of the target object to achieve the learning task we propose an image based boosting ridge regression algorithm which exhibit good generalization capability and training efficiency coupled with a binary classifier a a confidence scorer the regression approach becomes an effective tool for detecting left ventricle in echocardiogram achieving improved accuracy over the state of the art object detection algorithm with significantly le computation 
invariant feature descriptor such a sift and gloh have been demonstrated to be very robust for image matching and visual recognition however such descriptor are generally parameterised in very high dimensional space e g dimension in the case of sift this limit the performance of feature matching technique in term of speed and scalability furthermore these descriptor have traditionally been carefully hand crafted by manually tuning many parameter in this paper we tackle both of these problem by formulating descriptor design a a nonparametric dimensionality reduction problem in contrast to previous approach that use only the global statistic of the input we adopt a discriminative approach starting from a large training set of labelled match non match pair we pursue lower dimensional embeddings that are optimised for their discriminative power extensive comparative experiment demonstrate that we can exceed the performance of the current state of the art technique such a sift with far fewer dimension and with virtually no parameter to be tuned by hand 
in this paper we investigate physic based plane beam model frequently used in mechanical and civil engineering to track large non linear deformation in image such model do not only contribute to robust and precise tracking in the presence of clutter and partial occlusion but also allow to compute the force that produce observed deformation we verify the correctness of the recovered force by using them in a simulation and compare the result to the original image displacement we apply this method to track deformation of the pole vault the rat whisker and the car antenna 
generalized cylinder gc ha played an important role in computer vision since it wa introduced in the s while studying gc model in human visual perception of shape from contour marr assumed that gc s limb are planar curve later koenderink and ponce pointed out that this assumption doe not hold in general by giving some example in this paper we show that straight homogeneous generalized cylinder shgcs and torus a kind of curved gc have planar limb when viewed from point on specific straight line this property lead u to the definition and investigation of a new class of gc with the help of the surface model proposed by degen for geometric modeling we call them degen generalized cylinder dgcs which include shgcs torus quadric cyclides and more other gc into one model our rigorous discussion is based on projective geometry and homogeneous coordinate we present some invariant property of dgcs that reveal the relation among the planar limb ax and contour of dgcs these property are useful for recovering dgc description from image contour a well a for some other task in computer vision 
this paper proposes a method of automated individualization of eye region model the eye region model ha been proposed in past research that parameterizes both the structure and the motion of the eye region without any prior knowledge one can never determine a given appearance of eye region to be either neutral to any expression i e the inherent structure of the eye region or the result of motion by a facial expression the past method manually individualized the model with respect to the structure parameter in the initial frame and track the motion parameter automatically across the rest of the image sequence assuming the initial frame contains only neutral face under the same assumption we automatically determine the structure parameter for the given eye region image we train active appearance model aams for parameterizing the variance of individuality the system project a given eye region image onto the low dimensional subspace spanned by the aam and retrieves the structure parameter of the nearest training sample and initializes the eye region model using them the aams are trained in the subregions i e the upper eyelid region the palpebral fissure the eye aparture region and the lower eyelid region respectively it enables each aam to effectively represent fine structure experimental result show the proposed method give a nice initialization a manual labor and allows comparative tracking result for a comprehensive set of eye motion 
good continuation is a fundamental principle of perceptual organization that guide the grouping of part based on how they should succeed one another within coherent whole despite the general language that wa used by the gestalt psychologist in phrasing this principle computational work ha focused almost exclusively on the study of curve like structure here we offer for the first time a rigorous generalization of good continuation to arbitrary visual structure that can be abstracted a scalar function over the image plane the differential geometry of these structure dictate that their good continuation should be based both on their value and on the geometry of their levelsets which yield a coupled system of equation solvable for a formal model we exhibit the resulting computation on shading and intensity function demonstrating how it eliminates spurious measurement while preserving both regular structure and singularity related implementation could be applied to color channel motion magnitude and disparity signal 
displaying small text on large multiprojector tiled display is challenging problem arise because text is badly affected by the image warping technique that these display apply to rectify projector misalignment a a consequence there ha been little progress with important largedisplay application that require small text such a collaborative tutoring or web browsing in this paper we present a new warping technique designed to preserve crisp text based on recent work by hereld and stevens our technique produce good result free of artifact when used in today s multiprojector display we evaluate the legibility of our technique against conventional interpolation based warping and find that user prefer our technique we describe an efficient and reusable implementation and show how the increased legibility ha allowed u to investigate two new application 
thanks to recent progress in category level object recognition we have now come to a point where these technique have gained sufficient maturity and accuracy to succesfully feed back their output to other process this is what we refer to a cognitive feedback in this paper we study one particular form of cognitive feedback where the ability to recognize object of a given category is exploited to infer meta data such a depth cue d point or object decomposition in image of previously unseen object instance our approach build on the implicit shape model of leibe and schiele and extends it to transfer annotation from training image to test image experimental result validate the viability of our approach 
we present a novel model for human action categorization a video sequence is represented a a collection of spatial and spatial temporal feature by extracting static and dynamic interest point we propose a hierarchical model that can be characterized a a constellation of bagsof feature and that is able to combine both spatial and spatial temporal feature given a novel video sequence the model is able to categorize human action in a frameby frame basis we test the model on a publicly available human action dataset and show that our new method performs well on the classification task we also conducted control experiment to show that the use of the proposed mixture of hierarchical model improves the classification performance over bag of feature model an additional experiment show that using both dynamic and static feature provides a richer representation of human action when compared to the use of a single feature type a demonstrated by our evaluation in the classification task 
in this paper we address two closely related visual tracking problem localizing a target s position in low or moderate resolution video and segmenting a target s image support in moderate to high resolution video both task are treated a an online binary classification problem using dynamic foreground background appearance model our major contribution is a novel nonparametric approach that successfully maintains a temporally changing appearance model for both foreground and background the appearance model are formulated a bag of image patch that approximate the true two class appearance distribution they are maintained using a temporaladaptive importance resampling procedure that is based on simple nonparametric statistic of the appearance patch bag the overall framework is independent of an specific foreground background classification process and thus offer the freedom to use different classifier we demonstrate the effectiveness of our approach with extensive comparative experimental result on sequence from previous visual tracking and video matting work a well a our own data 
face recognition in video is being actively studied a a covert method of human identification in surveillance system identifying human face in video is a difficult problem due to the presence of large variation in facial pose and lighting and poor image resolution however by taking advantage of the diversity of the information contained in video the performance of a face recognition system can be enhanced in this work we explore a the adaptive use of multiple face matcher in order to enhance the performance of face recognition in video and b the possibility of appropriately populating the database gallery in order to succinctly capture intra class variation to extract the dynamic information in video the facial pose in various frame are explicitly estimated using active appearance model aam and a factorization based d face reconstruction technique we also estimate the motion blur using discrete cosine transformation dct our experimental result on subject in cmu s face in action fia database show that the proposed recognition method provides consistent improvement in the matching performance using three different face matcher 
active shape model asm ha been shown to be a powerful tool to aid the interpretation of image especially in face alignment asm local appearance model parameter estimation is based on the assumption that residual between model fit and data have a gaussian distribution moreover to generate an allowable face shape asm truncates coefficient of shape principal component into the bound determined by eigenvalue in this paper an algorithm of modeling local appearance called adaboosted asm and a shape parameter optimization method are proposed in the algorithm of modeling the local appearance we describe our novel modeling method by using adaboosted histogram classifier in which the assumption of the gaussian distribution is not necessary in the shape parameter optimization we describe that there is an inadequacy on controlling shape parameter in asm and our novel method on how to solve it experimental result demonstrate that the adaboosted histogram classifier improve robustness of landmark displacement greatly and the shape parameter optimization solves the inadequacy problem of asm on shape constraint effectively 
we present a new approach to model visual scene in image collection based on local invariant feature and probabilistic latent space model our formulation provides answer to three open question whether the invariant local feature are suitable for scene rather than object classification whether unsupervised latent space model can be used for feature extraction in the classification task and whether the latent space formulation can discover visual co occurrence pattern motivating novel approach for image organization and segmentation using a image dataset our approach is validated on each of these issue first we show with extensive experiment on binary and multi class scene classification task that a bag of visterm representation derived from local invariant descriptor consistently outperforms state of the art approach second we show that probabilistic latent semantic analysis plsa generates a compact scene representation discriminative for accurate classification and significantly more robust when le training data are available third we have exploited the ability of plsa to automatically extract visually meaningful aspect to propose new algorithm for aspect based image ranking and context sensitive image segmentation 
in this paper the virtual restoration method of the art piece in the real world is proposed the correction pattern for restoration is generated from non damaged object s image scanned in advance a the method to recover the beauty the marker tracking is used to detect art piece position and the correction image is projected from calibrated lcd projector in the experiment the color restoration by a sample image wa performed from the experimental result the ability of restoration of the discoloring wa confirmed in the real world imaginary by the correction image projection 
nowadays robotic system are more and more equipped with catadioptric camera however several problem associated to catadioptric vision have been studied only slightly especially algorithm for detecting rectangle in catadioptric image have not yet been developed whereas it is required in diverse application such a building extraction in aerial image we show that working in the equivalent sphere provides an appropriate framework to detect line parallelism orthogonality and therefore rectangle finally we present experimental result on synthesized and real data 
the structure and motion problem of multiple onedimensional projection of a two dimensional environment is studied one dimensional camera have proven useful in several different application most prominently for autonomous guided vehicle but also in ordinary vision for analysing planar motion and the projection of line previous result on one dimensional vision are limited to classifying and solving minimal case bundle adjustment for finding local minimum to the structure and motion problem and linear algorithm based on algebraic cost function in this paper we present a method for finding the global minimumto the structure andmotionproblem usingthe max norm of reprojection error we show how the optimal solution can be computed efficiently using simple linear programming technique the algorithm have been tested on a variety of different scenario bothreal and synthetic with good performance in addition we show how to solve the multiview triangulation problem the camera pose problem and how to dualize the algorithm in the carlsson duality sense all within the same framework 
we present a novel approach to detect and track independently moving region in a d scene observed by a moving camera in the presence of strong parallax detected moving pixel are classified into independently moving region or parallax region by analyzing two geometric constraint the commonly used epipolar constraint and the structure consistency constraint the second constraint is implemented within a plane parallax framework and represented by a bilinear relationship which relates the image point to their relative depth this newly derived relationship is related to trilinear tensor but can be enforced into more than three frame it doe not assume a constant reference plane in the scene and therefore eliminates the need for manual selection of reference plane then a robust parallax filtering scheme is proposed to accumulate the geometric constraint error within a sliding window and estimate a likelihood map for pixel classification the likelihood map is integrated into our tracking framework based on the spatio temporal joint probability data association filter jpdaf this tracking approach infers the trajectory and bounding box of the moving object by searching the optimal path with maximum joint probability within a fixed size of buffer we demonstrate the performance of the proposed approach on real video sequence where parallax effect are significant 
in this paper we propose a new method to integrate multiview normal field using level set in contrast with conventional normal integration algorithm used in shape from shading and photometric stereo that reconstruct a d surface using a single view normal field our algorithm can combine multiview normal field simultaneously and recover the full d shape of a target object we formulate this multiview normal integration problem by an energy minimization framework and find an optimal solution in a least square sense using a variational technique a level set method is applied to solve the resultant geometric pde that minimizes the proposed error functional it is shown that the resultant flow is composed of the well known mean curvature and flux maximizing flow in particular we apply the proposed algorithm to the problem of d shape modelling in a multiview photometric stereo setting experimental result for various synthetic data show the validity of our approach 
a method is proposed for estimating radiometric response function from noise observation from the statistical property of noise source the noise distribution for each scene radiance value is shown to be symmetric for a radiometrically calibrated camera however due to the non linearity of camera response function the observed noise distribution become skewed in an uncalibrated camera in this paper we capitalize on these asymmetric profile of measured noise distribution to estimate radiometric response function unlike prior approach the proposed method is not sensitive to noise level and is therefore particularly useful when the noise level is high also the proposed method doe not require registered input image taken with different exposure only statistical noise distribution at multiple intensity level are used real world experiment demonstrate the effectiveness of the proposed approach in comparison to standard calibration technique 
we propose a family of kernel between image defined a kernel between their respective segmentation graph the kernel are based on soft matching of subtree pattern of the respective graph leveraging the natural structure of image while remaining robust to the associated segmentation process uncertainty indeed output from morphological segmentation is often represented by a labelled graph each vertex corresponding to a segmented region with edge joining neighboring region however such image representation have mostly remained underused for learning task partly because of the observed instability of the segmentation process and the inherent hardness of inexact graph matching with uncertain graph our kernel count common virtual substructure amongst image which enables to perform efficient supervised classification of natural image with a support vector machine moreover the kernel machinery allows u to take advantage of recent advance in kernel based learning i semi supervised learning reduces the required number of labelled image while ii multiple kernel learning algorithm efficiently select the most relevant similarity measure between image within our family 
to improve the accuracy of tissue structural and architectural characterization with diffusion tensor imaging an anisotropic smoothing algorithm is presented for reducing noise in diffusion tensor image efficiently and effectively the presented algorithm is based on previous anisotropic diffusion filtering which is implemented with a straightforward but inefficient explicit numerical scheme the main contribution of this paper is to improve the performance of the previous method considerably by using unconditionally stable and second order time accurate semi implicit scheme our new method need only few or even one iteration to achieve better smoothed image than what is generated by ten of iteration of the previous method which make it more attractive to practical use experiment with simulated and in vivo data have demonstrated the advantage of our new algorithm for denoising diffusion tensor image in term of efficiency and effectiveness 
this work proposes a way to use a priori knowledge on motion dynamic for markerless human motion capture mocap specifically we match tracked motion pattern to training pattern in order to predict state in successive frame thereby modelingthe motionbymeans oftwists allows for a proper scaling of the prior consequently there is no need for training data of different frame rate or velocity moreover the method allows to combine very different motion pattern experiment in indoor and outdoor scenario demonstrate the continuous tracking of familiar motion pattern in case of artificial frame drop or in situation insufficiently constrained by the image data 
this paper proposes a novel method for recognizing face in a cluster of moving people in this task there are two problem caused by motion which are occlusion and change in facial pose and illumination multiple camera are used to acquire near frontal face to avoid occlusion and profile face the hierarchical image set matching hism creates a distribution for each individual by integrating a set of face image of the same individualacquired from the multiple camera by adopting a method for comparing between test and training distribution in identification variation in pose and illumination is alleviated and good recognition accuracy can be obtained experimental result using video sequence containing people show that the proposed method achieves high recognition performance compared with conventional method which use frame by frame identification and a distribution obtained from a single camera 
various linear subspace method can be formulated in the notion of matrix factorization in which a cost function is minimized subject to some constraint among them constraint on sparseness have received much attention recently some popular constraint such a non negativity lasso penalty and plain orthogonality etc have been so far applied to extract sparse feature however little work ha been done to give theoretical and experimental analysis on the difference of the impact of different constraint within a framework in this paper we analyze the problem in a more general framework called constrained sparse matrix factorization csmf in csmf a particular case called csmf with non negative component csmfnc is further discussed unlike nmf csmfnc allows not only additive but also subtractive combination of non negative sparse component it is useful to produce much sparser feature than those produced by nmf and meanwhile have better reconstruction ability achieving a trade off between sparseness and low mse value moreover for optimization an alternating algorithm is developed and a gentle update strategy is further proposed for handling the alternating process experimental analysis are performed on the swimmer data set and cbclface database in particular csmf can successfully extract all the proper component without any ghost on swimmer gaining a significant improvement over the compared well known algorithm 
automatically determining facial similarity is a difficult and open question in computer vision the problem is complicated both because it is unclear what facial feature human use to determine facial similarity and because facial similarity is subjective in nature similarity judgement change from person to person in this work we suggest a system which place facial similarity on a solid computational footing first we describe method for acquiring facial similarity rating from human in an efficient manner next we show how to create feature vector representation for each face by extracted patch around facial keypoints finally we show how to use the acquired similarity rating to learn functional mapping which project facialfeature vector into face space which correspond to our notion of facial similarity we use different collection of image to both create and validate the face space including perceptual similarity data obtained from human morphed face between two different individual and the cmu pie collection which contains image of the same individual under different lighting condition we demonstrate that using our method we can effectively create face space which correspond to human notion of facial similarity 
it is well known in the photometric stereo literature that uncalibrated photometric stereo where light source strength and direction are unknown can recover the surface geometry of a lambertian object up to a parameter linear transform known a the generalized ba relief gbr ambiguity many technique have been proposed for resolving the gbr ambiguity typically by exploiting prior knowledge of the light source the object geometry or non lambertian effect such a specularities a le celebrated consequence of the gbr transformation is that the albedo at each surface point is transformed along with the geometry thus it should be possible to resolve the gbr ambiguity by exploiting prior on the albedo distribution to the best of our knowledge the only time the albedo distribution ha been used to resolve the gbr is in the case of uniform albedo we propose a new prior on the albedo distribution that the entropy of the distribution should be low this prior is justified by the fact that many object in the real world are composed of a small finite set of albedo value 
this paper present an algorithm for the automatic segmentation of monocular video into foreground and background layer correct segmentation are produced even in the presence of large background motion with nearly stationary foreground there are three key contribution the first is the introduction of a novel motion representation motons inspired by research in object recognition second we propose learning the segmentation likelihood from the spatial context of motion the learning is efficiently performed by random forest the third contribution is a general taxonomy of tree based classifier which facilitates theoretical and experimental comparison of several known classification algorithm a well a spawning new one diverse visual cue such a motion motion context colour contrast and spatial prior are fused together by mean of a conditional random field crf model segmentation is then achieved by binary min cut our algorithm requires no initialization experiment on many video chat type sequence demonstrate the effectiveness of our algorithm in a variety of scene the segmentation result are comparable to those obtained by stereo system 
this paper address the problem of estimating dense correspondence between arbitrary frame from captured sequence of shape and appearance for surface undergoing free form deformation previous technique require either a prior model limiting the range of surface deformation or frame to frame surface tracking which suffers from stabilisation problem over complete motion sequence and doe not provide correspondence between sequence the primary contribution of this paper is the introduction of a system for wide timeframe surface matching without the requirement for a prior model or tracking deformationinvariant surface matching is formulated a a locally isometric mapping at a discrete set of surface point a set of feature descriptor are presented that are invariant to isometric deformation and a novel map mrf framework is presented to label sparse to dense surface correspondence preserving the relative distribution of surface feature while allowing for change in surface topology performance is evaluated on challenging data from a moving person with loose clothing ground truth feature correspondence are manually marked and the recall accuracy characteristic is quantied in matching result demonstrate an improved performance compared to non rigid point pattern matching using robust matching and graph matching using relaxation labelling with successful matching achieved across wide variation in human body pose and surface topology 
image fusion a a way of combining multiple image signal into a single fused image ha in recent year been extensively researched for a variety of multisensor application choosing an optimal fusion approach for each application from the plethora of algorithm available however remains a largely open issue a small number of metric proposed so far provide only a rough numerical estimate of fusion performance with limited understanding of the relative merit of different fusion scheme this paper proposes a method for comprehensive objective image fusion performance characterisation using a fusion evaluation framework based on gradient information representation the method provides an in depth analysis of fusion performance by quantifying information contribution by each sensor fusion gain fusion information loss and fusion artifact artificial information created it is demonstrated on the evaluation of an extensive dataset of multisensor image fused with a wide range of established image fusion algorithm the result demonstrate and quantify a number of well known issue concerning the performance of these scheme and provide a useful insight into a number of more subtle yet important fusion performance effect not immediately accessible to an observer 
this paper present a purely image based approach to fusing foreground silhouette information from multiple arbitrary view our approach doe not require d construct like camera calibration to carve out d voxels or project visual cone in d space using planar homographies and foreground likelihood information from a set of arbitrary view we show that visual hull intersection can be performed in the image plane without requiring to go in d space this process delivers a d grid of object occupancy likelihood representing a cross sectional slice of the object subsequent slice of the object are obtained by extending the process to plane parallel to a reference plane in a direction along the body of the object we show that homographies of these new plane between view can be computed in the framework of plane to plane homology using the homography induced by a reference plane and the vanishing point of the reference direction occupancy grid are stacked on top of each other creating a three dimensional data structure that encapsulates the object shape and location object structure is finally segmented out by minimizing an energy functional over the surface of the object in a level set formulation we show the application of our method on complicated object shape a well a cluttered environment containing multiple object in this paper we present a novel approach to silhouette fusion that doe not require calibrated view the method delivers the affine structure of object which can be augmented with a metric measurement from the scene for full euclidean structure in many case though the affine structure would suffice for application like multi object localization object recognition generation of novel view motion capturing and activity recognition among others some of which we demonstrate in this paper our approach get it inspiration from body part reconstruction using cat computed axial tomography scan in medical imaging the basic method is quite simple the cat scanner us xrays that penetrate into the body of the object to capture a d cross sectional slice of the object by moving the scanner along the body of the object a series of successive slice are obtained that are stacked on top of each other to obtain the structure of the object in this spirit we consider object to be composed of an infinite number of cross sectional slice with the frequency at which we sample the slice being a variable determining the granularity of the reconstruction we state the problem of determining a slice of an object a finding the region on a hypothetical plane that is occupied by the object to this end we show that by homographic warping of silhouette information from multiple view to a reference view we can achieve visual hull intersection on a plane if foreground information is available in each view then this process delivers a d grid of space occupancy indeed a representation of a slice of the scene object cut out by the plane starting with homographies between view due to a reference plane in the scene usually the ground plane we show that homographies of successively parallel plane can be obtained in the framework of plane to plane homology using the vanishing point of the reference direction the direction not parallel to the reference plane this enables u to obtain an arbitrary number of occupancy grid slice along the body of the object each being a discrete sampling of d space of object occupancy finally the slice obtained are stacked up in the reference direction and the object structure segmented out by minimizing an energy functional over the surface of the object 
recent year have witnessed the rise of many effective text information retrieval system by treating local visual feature a term training image a document and input image a query we formulate the problem of object recognition into that of text retrieval our formulation open up the opportunity to integrate some powerful text retrieval tool with computer vision technique in this paper we propose to improve the efficiency of articulated object recognition by an okapi chamfer matching algorithm the algorithm is based on the inverted index technique the inverted index is a widely used way to effectively organize a collection of text document with the inverted index only document that contain query term are accessed and used for matching to enable inverted indexing in an image database we build a lexicon of local visual feature by clustering the feature extracted from the training image given a query image we extract visual feature and quantize them based on the lexicon and then look up the inverted index to identify the subset of training image with non zero matching score to evaluate the matching score in the subset we combined the modified okapi weighting formula with the chamfer distance the performance of the okapi chamfer matching algorithm is evaluated on a hand posture recognition system we test the system with both synthesized and real world image quantitative result demonstrate the accuracy and efficiency of our system 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
a very efficient and robust visual object tracking algorithm based on the particle filter is presented the method characterizes the tracked object using color and edge orientation histogram feature while the use of more feature and sample can improve the robustness the computational load required by the particle filter increase to accelerate the algorithm while retaining robustness we adopt several enhancement in the algorithm the first is the use of integral image for efficiently computing the color feature and edge orientation histogram which allows a large amount of particle and a better description of the target next the observation likelihood based on multiple feature is computed in a coarse to fine manner which allows the computation to quickly focus on the more promising region quasi random sampling of the particle allows the filter to achieve a higher convergence rate the resulting tracking algorithm maintains multiple hypothesis and offer robustness against clutter or short period occlusion experimental result demonstrate the efficiency and effectiveness of the algorithm for single and multiple object tracking 
we propose a simple probabilistic generative model for image segmentation like other probabilistic algorithm such a em on a mixture of gaussians the proposed model is principled provides both hard and probabilistic cluster assignment a well a the ability to naturally incorporate prior knowledge while previous probabilistic approach are restricted to parametric model of cluster e g gaussians we eliminate this limitation the suggested approach doe not make heavy assumption on the shape of the cluster and can thus handle complex structure our experiment show that the suggested approach outperforms previous work on a variety of image segmentation task 
diffusion tensor imaging dti is widely used to characterize white matter in health and disease previous approach to the estimation of diffusion tensor have either been statistically suboptimal or have used gaussian approximation of the underlying noise structure which is rician in reality this can cause quantity derived from these tensor e g fractional anisotropy and apparent diffusion coefficient to diverge from their true value potentially leading to artifactual change that confound clinically significant one this paper present a novel maximum likelihood approach to tensor estimation denoted diffusion tensor estimation by maximizing rician likelihood dtemrl in contrast to previous approach dtemrl considers the joint distribution of all observed data in the context of an augmented tensor model to account for variable level of rician noise to improve numeric stability and prevent non physical solution dtemrl incorporates a robust characterization of positive definite tensor and a new estimator of underlying noise variance in simulated and clinical data mean squared error metric show consistent and significant improvement from low clinical snr to high snr dtemrl may be readily supplemented with spatial regularization or a priori tensor distribution for bayesian tensor estimation 
in this paper a new framework for the tracking of closed curve is described the proposed approach formalized through an optimal control technique enables a continuous tracking along an image sequence of a deformable curve the associated minimization process consists in a forward integration of a dynamical model followed by a backward integration of an adjoint dynamic this latter pde includes a term related to the discrepancy between the state variable evolution law and discrete noisy measurement of the system the closed curve are represented through an implicit surface 
a nonparametric bayesian model for histogram clustering is proposed to automatically determine the number of segment when markov random field constraint enforce smooth class assignment the nonparametric nature of this model is implemented by a dirichlet process prior to control the number of cluster the resulting posterior can be sampled by a modification of a conjugate case sampling algorithm for dirichlet process mixture model this sampling procedure estimate segmentation a efficiently a clustering procedure in the strictly conjugate case the sampling algorithm can process both single channel and multi channel image data experimental result are presented for real world synthetic aperture radar and magnetic resonance imaging data 
firstname lastna me sophia inria fr abstract in this paper we investigate how to improve the robustness of visual tracking method with respect to generic lighting change we propose a new approach to the direct image alignment of either lambertian or non lambertian object under shadow inter reflection s glint a well a ambient diffuse and specular reflection which may vary in power type number and space the method is based on a proposed model of illumination change together with an appropriate geometric model of image motion the parameter related to these model are obtained through an efficient second order optimization technique which minimizes directly the intensity discrepancy comparison result with existing direct method show significant improvement in the tracking performance extensive experiment confirm the robustness and reliability of our method 
in this paper we present a new method to change the illumination condition of a face image with unknown face geometry and albedo information this problem is particularly difficult when there is only one single image of the subject available and it wa taken under a harsh lighting condition recent research demonstrates that the set of image of a convex lambertian object obtained under a wide variety of lighting condition can be approximated accurately by a low dimensional linear subspace using spherical harmonic representation however the approximation error can be large under harsh lighting condition thus making it difficult to recover albedo information in order to address this problem we propose a subregion based framework that us a markov random field to model the statistical distribution and spatial coherence of face texture which make our approach not only robust to harsh lighting condition but insensitive to partial occlusion a well the performance of our framework is demonstrated through various experimental result including the improvement to the face recognition rate under harsh lighting condition 
we present a general algorithm of image based regression that is applicable to many vision problem the proposed regressor that target a multiple output setting is learned using boosting method we formulate a multiple output regression problem in such a way that overfitting is decreased and an analytic solution is admitted because we represent the image via a set of highly redundant haar like feature that can be evaluated very quickly and select relevant feature through boosting to absorb the knowledge of the training data during testing we require no storage of the training data and evaluate the regression function almost in no time we also propose an efficient training algorithm that break the computational bottleneck in the greedy feature selection process we validate the efficiency of the proposed regressor using three challenging task of age estimation tumor detection and endocardial wall localization and achieve the best performance with a dramatic speed e g more than time faster than conventional data driven technique such a support vector regressor in the experiment of endo cardial wall localization 
abstract in proc ieee int l conf on computer vision iccv october traditional bayesian restoration method depend heavily on the accuracy of underlying generative model for the challenging streak noise generated in the procedure of reconstruction from projection bayesian method do not generalize well because accurate signal noise model are not readily available in this paper we reformulate the reconstruction problem into a multi image based restoration task and demonstrate that multiple image and mutual independence analysis can be utilized to significantly improve the generalization capability of traditional bayesian framework in challenging scenario an efficient mutual independence analysis term is designed based on the property of independent random variable to enforce the independent noise constraint between multiple image in an energy optimization framework which can effectively detect and correct restoration error due to inaccurate generative model quantitative comparison on phantom image and experiment on clinical scan both show significant improvement in accuracy and robustness of the proposed method 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in order to analyze shape of continuous curve in we parameterize them by arc length and represent them a curve on a unit two sphere we identify the subset denoting the closed curve and study it differential geometry to compute geodesic between any two such curve we connect them with an arbitrary path and then iteratively straighten this path using the gradient of an energy associated with this path the limiting path of this path straightening approach is a geodesic next we consider the shape space of these curve by removing shape preserving transformation such a rotation and re parametrization to construct a geodesic in this shape space we construct the shortest geodesic between the all possible transformation of the two end shape this is accomplished using an iterative procedure we provide step by step description of all the procedure and demonstrate them with simple example 
we introduce an iterative algorithm for shape reconstruction from multiple image of a moving lambertian object illuminated by distant and possibly time varying lighting starting with an initial piecewise linear surface the algorithm iteratively estimate a new surface based on the previous surface estimate and the photometric information available from the input image sequence during each iteration standard photometric stereo technique are applied to estimate the surface normal up to an unknown generalized ba relief transform and a new surface is computed by integrating the estimated normal the algorithm essentially consists of a sequence of matrix factorization of intensity value followed by minimization using gradient descent integration of the normal conceptually the algorithm admits a clear geometric interpretation which is used to provide a qualitative analysis of the algorithm s convergence implementation wise it is straightforward being based on several established photometric stereo and structure from motion algorithm we demonstrate experimentally the effectiveness of our algorithm using several video of hand held object moving in front of a fixed light and camera 
abstract this paper introduces a novel colour based affine covariantregiondetector ouralgorithmisanextension ofthe maximally stable extremal region mser to colour the extension to colour is done by looking at successive time step of an agglomerative clustering of image pixel the selection of time step is stabilised against intensity scaling and image blur by modelling the distribution of edge magnitude the algorithm contains a novel edge significance measure based on a poisson image noise model which we show performs better than the commonly used euclidean distance we compare our algorithm to the original mser detector and a competing colour based blob feature detector and show through a repeatability test that our detector performs better we also extend the state of the art in feature repeatability test by using scene consisting of two plane where one is piecewise transparent this new test is able to evaluate how stable a feature is against changing background 
we propose a new multiple instance learning mil algorithm to learn image category unlike existing mil algorithm in which the individual instance in a bag are assumed to be independent with each other we develop concurrent tensor to explicitly model the inter dependency between the instance to better capture image s inherent semantics rank tensor factorization is then applied to obtain the label of each instance furthermore we formulate the classification problem in the reproducing kernel hilbert space rkhs to extend instance label prediction to the whole feature space finally a regularizer is introduced which avoids overfitting and significantly improves learning machine s generalization capability similar to that in svms we report superior categorization performance compared with key existing approach on both the corel and the caltech datasets 
strong lighting is common in natural scene yet is often viewed a a nuisance for object pose estimation and tracking in human shape and pose estimation cast shadow can be confused with foreground structure while self shadowing and shading variation on the body cause the appearance of the person to change with pose rather than attempt to minimize the effect of lighting and shadow we show that strong lighting in a scene actually make pose and shape estimation more robust additionally by recovering multiple body pose we are able to automatically estimate the lighting in the scene and the albedo of the body our approach make use of a detailed d body model the parameter of which are directly recovered from image data we provide a thorough exploration of human pose estimation under strong lighting condition and show the estimation of the light source from cast shadow the estimation of the light source and the albedo of the body from multiple body pose that a point light and cast shadow on the ground plane can be treated a an additional shadow camera that improves pose and shape recovery particularly in monocular scene additionally we introduce the notion of albedo constancy which employ lighting normalized image data for matching our experiment with multiple subject show that rather than causing problem strong lighting improves human pose and shape estimation 
in this paper we present a large scale object retrieval system the user supply a query object by selecting a region of a query image and the system return a ranked list of image that contain the same object retrieved from a large corpus we demonstrate the scalability and performance of our system on a dataset of over million image crawled from the photo sharing site flickr using oxford landmark a query building an image feature vocabulary is a major time and performance bottleneck due to the size of our dataset to address this problem we compare different scalable method for building a vocabulary and introduce a novel quantization method based on randomized tree which we show outperforms the current state of the art on an extensive ground truth our experiment show that the quantization ha a major effect on retrieval quality to further improve query performance we add an efficient spatial verification stage to re rank the result returned from our bag of word model and show that this consistently improves search quality though by le of a margin when the visual vocabulary is large we view this work a a promising step towards much larger web scale image corpus 
this article proposes an original method to estimate a continuous transformation that map one n dimensional distribution to another the method is iterative non linear and is shown to converge only d marginal distribution are used in the estimation process hence involving low computation cost a an illustration this mapping is applied to colour transfer between two image of different content the paper also serf a a central focal point for collecting together the research activity in this area and relating it to the important problem of automated colour grading 
object detection and segmentation can be facilitated by the availability of a reference object however accounting for possible transformation between the different object view a part of the segmentation process remains a challenge recent work address this problem by using comprehensive training data other approach are applicable only to limited object class or can only accommodate similarity transformation we suggest a novel variational approach to prior based segmentation which account for planar projective transformation using a single reference object the prior shape is registered concurrently with the segmentation process without point correspondence the algorithm detects the object of interest and correctly extract it boundary the homography between the two object view is accurately recovered a well extending the chan vese level set framework we propose a region based segmentation functional that includes explicit representation of the projective homography between the prior shape and the shape to segment the formulation is derived from two view geometry segmentation of a variety of object is demonstrated and the recovered transformation is verified 
this paper address automatic image annotation problem and it application to multi modal image retrieval the contribution of our work is three fold we propose a probabilistic semantic model in which the visual feature and the textual word are connected via a hidden layer which constitutes the semantic concept to be discovered to explicitly exploit the synergy among the modality the association of visual feature and textual word is determined in a bayesian framework such that the confidence of the association can be provided extensive evaluation on a large scale visually and semantically diverse image collection crawled from web is reported to evaluate the prototype system based on the model in the proposed probabilistic model a hidden concept layer which connects the visual feature and the word layer is discovered by fitting a generative model to the training image and annotation word through an expectation maximization em based iterative learning procedure the evaluation of the prototype system on image and automatically extracted annotation word from crawled web page for multi modal image retrieval ha indicated that the proposed semantic model and the developed bayesian framework are superior to a state of the art peer system in the literature 
fully automatic d modeling from a catadioptric image sequence ha rarely been addressed until now although this is a long standing problem for perspective image all previous catadioptric approach have been limited to dense reconstruction for a few view point and the majority of them require calibration of the camera this paper present a method which deal with hundred of image and doe not require precise calibration knowledge in this context the same d point of the scene may be visible and reconstructed in a large number of image at very different accuracy so the main part of this paper concern the selection of reconstructed point a problem largely ignored in previous work summary of the structure from motion and dense stereo step are also given experiment include the d model reconstruction of indoor and outdoor scene and a walkthrough in a city 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we develop computational model for measuring hair appearance for comparing different people the model and method developed have application to person recognition and face image indexing an automatic hair detection algorithm is described and result reported a multidimensional representation of hair appearance is presented and computational algorithm are described result on a dataset of subject are reported identification of people using hair attribute is compared to eigenface based recognition along with a joint eigenface hair based identification 
object tracking is viewed a a two class one versus rest classification problem in which the sample distribution of the target is approximately gaussian while the background sample are often multimodal based on these special property we propose a graph embedding based discriminative learning method in which the topology structure of graph are carefully designed to reflect the property of the sample distribution this method can simultaneously learn the subspace of the target and it local discriminative structure against the background moreover a heuristic negative sample selection scheme is adopted to make the classification more effective in tracking procedure the graph based learning is embedded into a bayesian inference framework cascaded with hierarchical motion estimation which significantly improves the accuracy and efficiency of the localization furthermore an incremental updating technique for the graph is developed to capture the change in both appearance and illumination experimental result demonstrate that compared with two state of the art method the proposed tracking algorithm is more efficient and effective especially in dynamically changing and clutter scene 
we study the influence of numerical conditioning on the accuracy of two closed form solution to the overconstrained relative orientation problem we consider the well known eight point algorithm and the recent five point algorithm and evaluate change in their performance due to hartley s normalization and muehlich s equilibration the need for numerical conditioning is introduced by explaining the known occurence of the bias of the eight point algorithm towards the forward motion then it is shown how conditioning can be used to improve the result of the recent five point algorithm this is not straightforward since the conditioning disturbs the calibration of the input data the conditioning therefore need to be reverted before enforcing the internal cubic constraint of the essential matrix the obtained improvement are le dramatic than in the case of the eight point algorithm for which we offer a plausible explanation the theoretical claim are backed up with extensive experimentation on noisy artificial datasets under a variety of geometric and imaging parameter 
parametric active contour have been used extensively in computer vision for different task like segmentation and tracking however all parametric contour are known to suffer from the problem of frequent bunching and spacing out of curve point locally during the curve evolution in a spline based implementation of active contour this lead to occasional formation of loop locally and subsequently the curve blow up due to instability it ha been shown earlier that in addition to usual evolution along the normal direction the curve should also be evolved in the tangential direction for stability purpose in this paper we provide a mathematical basis for selecting such a suitable tangential component for stabilisation we prove the boundedness of the evolved curve in this paper and provide the physical significance we demonstrate the usefulness of the proposed method with a number of experiment 
dimensionality reduction play a fundamental role in data processing for which principal component analysis pca is widely used in this paper we develop the laplacian pca lpca algorithm which is the extension of pca to a more general form by locally optimizing the weighted scatter in addition to the simplicity of pca the benefit broughtby lpca aretwofold thestrong robustness against noise and the weak metric dependence on sample space the lpca algorithm is based on the global alignment of locallygaussian or linear subspacesvia an alignmenttechnique borrowed from manifold learning based on the coding length of local sample the weight can be determined to capture the local principal structure of data we also give the exemplary application of lpca to manifold learning manifold unfolding non linear dimensionality reduction can be performed by the alignment of tangential map which are linear transformationsof tangentcoordinatesapproximated by lpca the superiority of lpca to pca and kernel pca is verified by the experiment on face recognition frgc version face database and manifold scherk surface unfolding 
recent work in object categorization often us local image descriptor such a sift to learn and detect object category such descriptor explicitly code local appearance and have shown impressive result on object with sufficient local appearance statistic however many important object class such a tool cup and other man made artifact seem to require feature that capture the respective shape and geometric layout of those object class therefore this paper compare on a novel data collection of geometric object class various shape based feature with appearance based descriptor such a sift the analysis includes a direct comparison of feature statistic a well a result within standard recognition framework which are partly intuitive but sometimes surprising 
the ground truth labeling of an image dataset is a task that often requires a large amount of human time and labor we present an infrastructure for distributed human labeling that can exploit the modularity of common vision problem involving segmentation and recognition we present the different element of this infrastructure in detail in particular the different vision human computational task hcts and machine computable task mcts we also discus the impact of such a system on internet security v the current state of the art finally we present our prototype implementation of such a system named soylent grid on typical problem 
mean shift is a popular method to segment image and video pixel are represented by feature point and the segmentation is driven by the point density in feature space in this paper we introduce the use of morse theory to interpret mean shift a a topological decomposition of the feature space into density mode this allows u to build on the watershed technique and design a new algorithm to compute mean shift segmentation of image and video in addition we introduce the use of topological persistence to create a segmentation hierarchy we validated our method by clustering image using color cue in this context our technique run faster than previous work especially on video and large image we evaluated accuracy with a classical benchmark which show result on par with existing low level technique i e we do not sacrifice accuracy for speed 
the paper present a fusion tracker and pedestrian classifier for color and thermal camera the tracker build a background model a a multi modal distribution of color and temperature it is constructed a a particle filter that make a number of informed reversible transformation to sample the model probability space in order to maximize posteriorprobabilityof thescene model observationlikelihoodsof moving object account their d locationswith respect to the camera and occlusion by other tracked object a well a static obstacle after capturing the coordinate and dimension of moving object we apply a pedestrian classifier based on periodic gait analysis to separate human from other moving object such a car we detect in human gait a symmetrical double helical pattern that can then be analyzed using the frieze group theory the result of tracking on color and thermal sequence demonstrate that our algorithm is robust to illumination noise and performs well in the outdoor environment 
in this paper we describe a method for segmenting fiber bundle from diffusion weighted magnetic resonance image using a locally constrained region based approach from a pre computed optimal path the algorithm propagates outward capturing only those voxels which are locally connected to the fiber bundle rather than attempting to find large number of open curve or single fiber which individually have questionable meaning this method segment the full fiber bundle region the strength of this approach include it ease of use computational speed and applicability to a wide range of fiber bundle in this work we show result for segmenting the cingulum bundle finally we explain how this approach and extension thereto overcome a major problem that typical region based flow experience when attempting to segment neural fiber bundle 
abstract detecting and segmenting moving object in dynamic scene is a hard but essential task in a number of application such a surveillance most existing method only give good result in the case of persistent or slowly changing background or if both the object and the background are rigid in this paper we propose a new method for direct detection and segmentation of foreground moving object in the absence of such constraint first group of pixel having similar motion and photometric feature are extracted for this r st step only a sub grid of image pixel is used to reduce computational cost and improve robustness to noise we introduce the use of p value to validate optical ow estimate and of automatic bandwidth selection in the mean shift clustering algorithm in a second stage segmentation of the object associated to a given cluster is performed in a map mrf framework our method is able to handle moving camera and several different motion in the background experiment on challenging sequence show the performance of the proposed method and it utility for video analysis in complex scene 
image registration is an important element in data processing for remote sensing with many application and a wide range of solution despite considerable investigation the field ha not settled on a definitive solution for most application and a number of question remain open this article look at selected research issue by surveying the experience of operational satellite team application specific requirement for earth science and our experiment in the evaluation of image registration algorithm with emphasis on the comparison of algorithm for subpixel accuracy we conclude that remote sensing application put particular demand on image registration algorithm to take into account domain specific knowledge of geometric transformation and image content 
this paper proposes a novel and robust approach to the point set registration problem in the presence of large amount of noise and outlier each of the point set is represented by a mixture of gaussians and the point set registration is treated a a problem of aligning the two mixture we derive a closed form expression for the l distance between two gaussian mixture which in turn lead to a computationally efficient registration algorithm this new algorithm ha an intuitive interpretation is simple to implement and exhibit inherent statistical robustness experimental result indicate that our algorithm achieves very good performance in term of both robustness and accuracy 
tracking over a long period of time is challenging a the appearance shape and scale of the object in question may vary we propose a paradigm of tracking by repeatedly segmenting figure from background accurate spatial support obtained in segmentation provides rich information about the track and enables reliable tracking of non rigid object without drifting figure ground segmentation operates sequentially in each frame by utilizing both static image cue and temporal coherence cue which include an appearance model of brightness or color and a spatial model propagating figure ground mask through low level region correspondence a superpixel based conditional random field linearly combine cue and loopy belief propagation is used to estimate marginal posterior of figure v background we demonstrate our approach on long sequence of sport video including figure skating and football 
we show how to extend the icp framework to nonrigid registration while retaining the convergence property of the original algorithm the resulting optimal step nonrigid icp framework allows the use of different regularisation a long a they have an adjustable stiffness parameter the registration loop over a series of decreasing stiffness weight and incrementally deforms the template towards the target recovering the whole range of global and local deformation to find the optimal deformation for a given stiffness optimal iterative closest point step are used preliminary correspondence are estimated by a nearest point search then the optimal deformation of the template for these fixed correspondence and the active stiffness is calculated afterwards the process continues with new correspondence found by searching from the displaced template vertex we present an algorithm using a locally affine regularisation which assigns an affine transformation to each vertex and minimises the difference in the transformation of neighbouring vertex it is shown that for this regularisation the optimal deformation for fixed correspondence and fixed stiffness can be determined exactly and efficiently the method succeeds for a wide range of initial condition and handle missing data robustly it is compared qualitatively and quantitatively to other algorithm using synthetic example and real world data 
many variant of mi exist in the literature these vary primarily in how the joint histogram is populated this paper place the four main variant of mi standard sampling partial volume estimation pve in parzen windowing and post parzen windowing into a single mathematical framework jacobians and hessian are derived in each case a particular contribution is that the non linearity implicit to standard sampling and post parzen windowing are explicitly dealt with these non linearity are a barrier to their use in optimisation side by side comparison of the mi variant is made using eight diverse data set considering computational expense and convergence in the experiment pve wa generally the best performer although standard sampling often performed nearly a well if a higher sample rate wa used the widely used sum of squared difference metric performed a well a mi unless large occlusion and non linear intensity relationship occurred the binary and script used for testing are available online 
traditional method of object recognition are reliant on shape and so are very difficult to apply in cluttered wide angle and low detail view such a surveillance scene to address this a method of indirect object recognition is proposed where human activity is used to infer both the location and identity of object no shape analysis is necessary the concept is dubbed interaction signature since the premise is that a human interacts with object in way characteristic of the function of that object for example a person sits in a chair and drink from a cup the human centred approach mean that recognition is possible in low detail view and is largely invariant to the shape of object within the same functional class this paper implement a bayesian network for classifying region patch with object label building upon our previous work in automatically segmenting and recognising a human s interaction with the object experiment show that interaction signature can successfully find and label object in low detail view and are equally effective at recognising test object that differ markedly in appearance from the training object 
traditional method for creating classifier have two main disadvantage firstly it is time consuming to acquire or manually annotate the training collection secondly the data on which the classifier is trained may be over generalised or too specific this paper present our investigation into overcoming both of these drawback simultaneously by providing example application where two data source train each other this remove both the need for supervised annotation or feedback and allows rapid adaptation of the classifier to different data two application are presented one using thermal infrared and visual imagery to robustly learn changing skin model and another using change in saturation and luminance to learn shadow appearance parameter 
we present an approach for inferring the topology of a camera network by measuring statistical dependence between observation in different camera two camera are considered connected if object seen departing in one camera are seen arriving in the other this is captured by the degree of statistical dependence between the camera the nature of dependence is characterized by the distribution of observation transformation between camera such a departure to arrival transition time and color appearance we show how to measure statistical dependence when the correspondence between observation in different camera is unknown this is accomplished by non parametric estimate of statistical dependence and bayesian integration of the unknown correspondence our approach generalizes previous work which assumed restricted parametric transition distribution and only implicitly dealt with unknown correspondence result are shown on simulated and real data we also describe a technique for learning the absolute location of the camera with global positioning system gps side information 
in this paper we use motion and appearance context for persistent tracking of object in aerial imagery the motion context in a given environment is a collection of trajectory of object which are representative of the motion of the occluded or unobserved object it is learned using a clustering scheme based on the lyapunov characteristic exponent lce which measure the mean exponential rate of divergence of the nearby trajectory the learned motion context is then used in a regression framework to predict the location of the unobserved object the appearance context of an occluded target object consists of appearance information of object which are currently occluded or unobserved it is incorporated by learning a distribution of interclass variation for each target unobservable object pair in addition intra class variation distribution is constructed for each occluded object using all of it previous observation qualitative and quantitative result are reported on challenging aerial sequence 
this paper address the problem of correspondence establishment in binocular stereo vision we suggest a novel variational approach that considers both the discontinuity and occlusion it deal with color image a well a gray level the proposed method divide the image domain into the visible and occluded region where each region is handled differently the depth discontinuity in the visible domain are preserved by use of the total variation term in conjunction with the mumford shah framework in addition to the dense disparity and the occlusion map our method also provides a discontinuity function revealing the location of the boundary in the disparity map we evaluate our method on data set from middlebury site showing superior performance in comparison to the state of the art variational technique 
this paper present minimal solution for the geometric parameter of a camera rotating about it optical centre in particular we present new and point solution for the homography induced by a rotation with and unknown focal length parameter using test on real data we show that these algorithm outperform the standard point linear homography solution in term of accuracy of focal length estimation and image based projection error 
we address the problem of visual category recognition by learning an image to image distance function that attempt to satisfy the following property the distance between image from the same category should be le than the distance between image from different category we use patch based feature vector common in object recognition work a a basis for our image to image distance function our large margin formulation for learning the distance function is similar to formulation used in the machine learning literature on distance metric learning however we differ in that we learn local distance function a different parameterized function for every image of our training set whereas typically a single global distance function is learned this wa a novel approach first introduced in frome singer malik nip in that work we learned the local distance function independently and the output of these function could not be compared at test time without the use of additional heuristic or training here we introduce a different approach that ha the advantage that it learns distance function that are globally consistent in that they can be directly compared for purpose of retrieval and classification the output of the learning algorithm are weight assigned to the image feature which is intuitively appealing in the computer vision setting some feature are more salient than others and which are more salient depends on the category or image being considered we train and test using the caltech object recognition benchmark using fifteen training image per category we achieved a mean recognition rate of and using twenty image per category a rate of image j 
in this paper we present an attribute graph grammar for image parsing on scene with man made object such a building hallway kitchen and living mom we choose one class of primitive d planar rectangle projected on image and six graph grammar production rule each production rule not only expands a node into it component but also includes a number of equation that constrain the attribute of a parent node and those of it child thus our graph grammar is context sensitive the grammar rule are used recursively to produce a large number of object and pattern in image and thus the whole graph grammar is a type of generative model the inference algorithm integrates bottom up rectangle detection which activates top down prediction using the grammar rule the final result are validated in a bayesian framework the output of the inference is a hierarchical parsing graph with object surface rectangle and their spatial relation in the inference the acceptance of a grammar rule mean recognition of an object and action are taken to pas the attribute between a node and it parent through the constraint equation associated with this production rule when an attribute is passed from a child node to a parent node it is called bottom up and the opposite is called top down 
finding a good metric over the input space play a fundamental role in machine learning most existing technique use the mahalanobis metric without incorporating the geometry of positive matrix and experience difficulty in the optimization procedure in this paper we introduce the use of iwasawa decomposition a unique and effective parametrization of symmetric positive definite spd matrix for performing metric learning task unlike other previously employed factorization the use of the iwasawa decomposition is able to reformulate the semidefinite programming sdp problem a smooth convex nonlinear programming nlp problem with much simpler constraint we also introduce a modified iwasawa coordinate for rank deficient positive semidefinite psd matrix which enables the unifying of the metric learning and linear dimensionality reduction we show that the iwasawa decomposition can be easily used in most recent proposed metric learning algorithm and have applied it to the neighbourhood component analysis nca the experimental result on several public domain datasets are also presented 
many vision task such a scene segmentation or the recognition of material within a scene become considerably easier when it is possible to measure the spectral reflectance of scene surface in this paper we present an efficient and robust approach for recovering spectral reflectance in a scene that combine the advantage of using multiple spectral source and a multispectral camera we have implemented a system based on this approach using a cluster of light source with different spectrum to illuminate the scene and a conventional rgb camera to acquire image rather than sequentially activating the source we have developed a novel technique to determine the optimal multiplexing sequence of spectral source so a to minimize the number of acquired image we use our recovered spectral measurement to recover the continuous spectral reflectance for each scene point by using a linear model for spectral reflectance our imaging system can produce multispectral video of scene at fps we demonstrate the effectiveness of our system through extensive evaluation a a demonstration we present the result of applying data recovered by our system to material segmentation and spectral relighting 
linear and affine subspace are commonly used to describe appearance of object under different lighting viewpoint articulation and identity a natural problem arising from their use is given a query image portion represented a a point in some high dimensional space find a subspace near to the query this paper present an efficient solution to the approximate nearest subspace problem for both linear and affine subspace our method is based on a simple reduction to the problem of nearest point search and can thus employ tree based search or locality sensitive hashing to find a near subspace further speedup may be achieved by using random projection to lower the dimensionality of the problem we provide theoretical proof of correctness and error bound of our construction and demonstrate it capability on synthetic and real data our experiment demonstrate that an approximate nearest subspace can be located significantly faster than the exact nearest subspace while at the same time it can find better match compared to a similar search on point in the presence of variation due to viewpoint lighting etc 
human face are remarkably similar in global property including size aspect ratio and location of main feature but can vary considerably in detail across individual gender race or due to facial expression we propose a novel method for d shape recovery of a face from a single image using a single d reference model of a different person s face the method us the input image a a guide to mold the reference model to reach a desired reconstruction assuming lambertian reflectance and rough alignment of the input image and reference model we seek shape albedo and lighting that best fit the image while preserving the rough structure of the model we demonstrate our method by providing accurate reconstruction of novel face overcoming significant difference in shape due to gender race and facial expression 
for year researcher in face recognition area have been representing and recognizing face based on subspace discriminant analysis or statistical learning nevertheless these approach are always suffering from the generalizability problem this paper proposes a novel non statistic based face representation approach local gabor binary pattern histogram sequence lgbphs in which training procedure is unnecessary to construct the face model so that the generalizability problem is naturally avoided in this approach a face image is modeled a a histogram sequence by concatenating the histogram of all the local region of all the local gabor magnitude binary pattern map for recognition histogram intersection is used to measure the similarity of different lgbphses and the nearest neighborhood is exploited for final classification additionally we have further proposed to assign different weight for each histogram piece when measuring two lgbphses our experimental result on ar and feret face database show the validity of the proposed approach especially for partially occluded face image and more impressively we have achieved the best result on feret face database 
in this paper a new approach for object detection and pose estimation is introduced the contribution consists in the conception of entity permitting stable detection and reliable pose estimation of a given object thanks to a welldefined off line learning phase we design local and minimal subset of feature point that have at the same time distinctive photometric and geometric property we call these entity natural d marker n m constraint on the selection and the distribution of the subset coupled with a multi level validation approach result in a detection at high frame rate and allow u to determine the precise pose of the object the method is robust against noise partial occlusion background clutter and illumination change the experiment show it superiority to existing standard method the validation wa carried out using simulated ground truth data excellent result on real data demonstrated the usefulness of this approach for many computer vision application 
model learning and tracking are two important topic in computer vision while there are many application where one of them is used to support the other there are currently only few where both aid each other simultaneously in this work we seek to incrementally learn a graphical model from tracking and to simultaneously use whatever ha been learned to improve the tracking in the next frame the main problem encountered in this situation is that the current intermediate model may be inconsistent with future observation creating a bias in the tracking result we propose an uncertain model that explicitly account for such uncertainty by representing relation by an appropriately weighted sum of informative parametric and uninformative uniform component the method is completely unsupervised and operates in real time 
this paper study the use of volumetric feature a an alternative to popular local descriptor approach for event detection in video sequence motivated by the recent success of similar idea in object detection on static image we generalize the notion of d box feature to d spatio temporal volumetric feature this general framework enables u to do real time video analysis we construct a real time event detector for each action of interest by learning a cascade of filter based on volumetric feature thatefficiently scan video sequence in space and time this event detector recognizes action that are traditionally problematic for interest point method such a smooth motion where insufficient space time interest point are available our experiment demonstrate that the technique accurately detects action on real world sequence and is robust to change in viewpoint scale and action speed we also adapt our technique to the related task of human action classification and confirm that it achieves performance comparable to a current interest point based human activity recognizer on a standard database of human activity 
many computer vision and image processing task require the preservation of local discontinuity termination and bifurcation denoising with feature preservation is a challenging task and in this paper we present a novel technique for preserving complex oriented structure such a junction and corner present in image this is achieved in a two stage process namely all image data are pre processed to extract local orientation information using a steerable gabor filter bank the orientation distribution at each lattice point is then represented by a continuous mixture of gaussians the continuous mixture representation can be cast a the laplace transform of the mixing density over the space of positive definite covariance matrix this mixing density is assumed to be a parameterized distribution namely a mixture of wisharts whose laplace transform is evaluated in a closed form expression called the rigaut type function a scalar valued function of the parameter of the wishart distribution computation of the weight in the mixture wisharts is formulated a a sparse deconvolution problem the feature preserving denoising is then achieved via iterative convolution of the given image data with the rigaut type function we present experimental result on noisy data real d image and d mri data acquired from plant root depicting bifurcating root superior performance of our technique is depicted via comparison to the state of the art anisotropic diffusion filter 
this paper proposes a method for precise overlapping of projected image from multiple steerable projector when they are controlled simultaneously two problem are revealed even a slight positional error of the projected image which doe not matter in the case of a single projector cause misalignment of multiple projected image that can be perceived clearly when using multiple projector and a the projector usually do not have architecture fortheirsynchronizationitisimpossibleto displaya moving image that is by tiling or overlaying precisely the multiple projected image to overcome a method is proposed that measure preliminarily the misalignment through every plane in the environment and hence display the image without the misalignment for a consideration and a new proposal for the synchronization of multiple projector are also discussed 
we propose a discriminative feature selection method utilizing support vector machine for the challenging task of multi view face recognition according to the statistical relationship between the two task feature selection and multi class classification we integrate the two task into a single consistent framework and effectively realize the goal of discriminative feature selection the classification process can be made faster without degrading the generalization performance through this discriminative feature selection method on the umist multi view face database our experiment show that this discriminative feature selection method can speed up the multi view face recognition process without degrading the correct rate and outperform the traditional kernel subspace method 
subspace learning based face recognition method have attracted considerable interest in recent year including principal component analysis pca linear discriminant analysis lda locality preserving projection lpp neighborhood preserving embedding npe and marginal fisher analysis mfa however a disadvantage of all these approach is that their computation involve eigendecomposition of dense matrix which is expensive in both time and memory in this paper we propose a novel dimensionality reduction framework called spectral regression sr for efficient regularized subspace learning sr cast the problem of learning the projective function into a regression framework which avoids eigen decomposition of dense matrix also with the regression based framework different kind of regularizes can be naturally incorporated into our algorithm which make it more flexible computational analysis show that sr ha only linear time complexity which is a huge speed up comparing to the cubic time complexity of the ordinary approach experimental result on face recognition demonstrate the effectiveness and efficiency of our method 
the maximum flow algorithm for minimizing energy function of binary variable ha become a standard tool in computer vision in many case unary cost of the energy depend linearly on parameter in this paper we study vision application for which it is important to solve the maxflow problem for different s an example is a weighting between data and regularization term in image segmentation or stereo it is desirable to vary it both during training to learn from ground truth data and testing to select best using high knowledge constraint e g user input we review algorithmic aspect of this parametric maximum flow problem previously unknown in vision such a the ability to compute all breakpoints of and corresponding optimal configuration in finite time these result allow in particular to minimize the ratio of some geometric functionals such a flux of a vector field over length or area previously such functionals were tackled with shortest path technique applicable only in d we give theoretical improvement for pde cut we present experimental result for image segmentation d reconstruction and the cosegmentation problem 
we propose a new technique for fusing multiple cue to robustly segment an object from it background in video sequence that suffer from abrupt change of both illumination and position of the target robustness is achieved by the integration of appearance and geometric object feature and by their description using particle filter previous approach assume independence of the object cue or apply the particle filter formulation to only one of the feature and assume a smooth change in the rest which can prove is very limiting especially when the state of some feature need to be updated using other cue or when their dynamic follow non linear and unpredictable path our technique offer a general framework to model the probabilistic relationship between feature the proposed method is analytically justified and applied to develop a robust tracking system that adapts online and simultaneously the colorspace where the image point are represented the color distribution and the contour of the object result with synthetic data and real video sequence demonstrate the robustness and versatility of our method 
most dense stereo correspondence algorithm start by establishing discrete pixel match and later refine these match to sub pixel precision traditional sub pixel refinement method attempt to determine the precise location of point in the secondary image that correspond to discrete position in the reference image we show that this strategy can lead to a systematic bias associated with the violation of the general symmetry of matching cost function this bias produce random or coherent noise in the final reconstruction but can be avoided by refining both image coordinate simultaneously in a symmetric way we demonstrate that the symmetric sub pixel refinement strategy result in more accurate correspondence by avoiding bias while preserving detail 
in this paper we investigate how to scale a content based image retrieval approach beyond the ram limit of a single computer and to make use of it hard drive to store the feature database the feature vector describing the image in the database are binned in multiple independent way each bin contains image similar to a representative prototype each binning is considered through two stage of processing first the prototype closest to the query is found second the bin corresponding to the closest prototype is fetched from disk and searched completely the query process is repeatedly performing these two stage each time with a binning independent of the previous one the scheme cut down the hard drive access significantly and result in a major speed up an experimental comparison between the binning scheme and a raw search show competitive retrieval quality 
in this paper we present an approach for separating two transparent layer of complex non rigid scene dynamic the dynamic in one of the layer is assumed to be repetitive while the other can have any arbitrary dynamic such repetitive dynamic includes among other human action in video e g a walking person or a repetitive musical tune in audio signal we use a global to local space time alignment approach to detect and align the repetitive behavior once aligned a median operator applied to space time derivative is used to recover the intrinsic repeating behavior and separate it from the other transparent layer we show result on synthetic and real video sequence in addition we show the applicability of our approach to separating mixed audio signal from a single source 
in this paper we demonstrate an integrated registration and clustering algorithm to compute an atlas of fiberbundles from a set of multi subject diffusion weighted mr image we formulate a maximum likelihood problem which the proposed method solves using a generalized expectation maximization em framework additionally the algorithm employ an outlier rejection and denoising strategy to produce sharp probabilistic map of certain bundle of interest this map is potentially useful for making diffusion measurement in a common coordinate system to identify pathology related change or developmental trend 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
this paper demonstrates how to reduce the hand labeling effort considerably by d information in an object detection task in particular we demonstrate how an efficient car detector for aerial image with minimal hand labeling effort can be build we use an on line boosting algorithm to incrementally improve the detection result initially we train the classifier with a single positive car example randomly drawn from a fixed number of given sample when applying this detector to an image we obtain many false positive detection we use information from a stereo matcher to detect some of these false positive e g detected car on a facade and feed back this information to the classifier a negative update this improves the detector considerably thus reducing the number of false positive we show that we obtain similar result to hand labeling by iteratively applying this strategy the performance of our algorithm is demonstrated on digital aerial image of urban environment 
today s category level object recognition system largely focus on fronto parallel view of object with char acteristic texture pattern to overcome these limitation s we propose a novel framework for visual object recognition where object class are represented by assembly ofpartial surface model psms obeying loose local geometric constraint the psms themselves are formed of dense locally rigid assembly of image feature since our model only enforces local geometric consistency both at the level of model part and at the level of individual feature within the part it is robust to viewpoint change and intra class variability the proposed approach ha been implemented and it outperforms the state of the art algorithm for obj ect detection and localization recently compared in on the pascal voc challenge car test data 
occlusion is one of the challenging problem in stereo in this paper we solve the problem in a segment based style both image are segmented and we propose a novel patch based stereo algorithm that cut the segment of one image using the segment of the other and handle occlusion area in a proper way a symmetric graph cut optimization framework is used to find correspondence and occlusion simultaneously the experimental result show superior performance of the proposed algorithm especially on occlusion untextured area and discontinuity 
this paper proposes a novel approach for rank level fusion which give improved performance gain verified by experimental result in the absence of ranked feature and instead of using the entire template we propose using k partition of the template the approach proposed in the paper is useful for generating sequential rank and survivor list on partition of template to boost confidence level by incorporating information from partition the proposed algorithm iteratively generates rank for each partition of the user template rank from template partition are consolidated to estimate the fusion rank for the classification this paper investigates rank level fusion for palmprint biometric using two approach fixed threshold and resulting survivor list and iterative threshold and iteratively refined survivor list the above approach achieve similar performance a related manifestation of fusion architecture the experimental result support the proposition of high in template similarity of palmprint for a user and it relevance to the intra modal fusion framework experimental result using proposed approach on real palmprint data from user show superior performance with recognition accuracy of a compared to recognition accuracy of achieved with the conventional approach 
bayesian method have been extensively used in various application however there are two intrinsic issue rarely addressed namely generalization and validity in the context of multiple image restoration we show that traditional bayesian method are sensitive to model error and cannot guarantee valid result satisfying the underlying prior knowledge e g independent noise property to improve the bayesian framework s generalization we propose to explicitly enforce the validity of the result independent noise prior is very important but largely under utilized in previous literature in this paper we use mutual information mi to explicitly enforce the independence efficient approximation based on taylor expansion are proposed to adapt mi into standard energy form to regularize the bayesian method the new regularized bayesian framework effectively utilizes the traditional generative signal noise model but is much more robust to various model error a demonstrated in experiment on some demanding imaging application 
registering consecutive image from an airborne sensor into a mosaic is an essential tool for image analyst strictly local method tend to accumulate error resulting in distortion we propose here to use a reference image such a a high resolution map image to overcome this limitation in our approach we register a frame in an image sequence to the map using both frame to frame registration and frame to map registration iteratively in frame to frame registration a frame is registered to it previous frame with it previous frame been registered to the map in the previous iteration we can derive an estimated transformation from the frame to the map in frame to map registration we warp the frame to the map by this transformation to compensate for scale and rotation difference and then perform an area based matching using mutual information to find correspondence between this warped frame and the map these correspondence together with the correspondence in previous frame could be regarded a correspondence between the partial local mosaic and the map by registering the partial local mosaic to the map we derive a transformation from the frame to the map with this two step registration the error between each consecutive frame are not accumulated we then extend our approach to synchronize multiple image sequence by tracking moving object in each image sequence and aligning the frame based on the object s coordinate in the reference image 
we consider the task of creating a d model of a large novel environment given only a small number of image of the scene this is a difficult problem because if the image are taken from very different viewpoint or if they contain similar looking structure then most geometric reconstruction method will have great difficulty finding good correspondence further the reconstruction given by most algorithm include only point in d that were observed in two or more image a point observed only in a single image would not be reconstructed in this paper we show how monocular image cue can be combined with triangulation cue to build a photo realistic model of a scene given only a few image even one taken from very different viewpoint or with little overlap our approach begin by oversegmenting each image into small patch superpixels it then simultaneously try to infer the d position and orientation of every superpixel in every image this is done using a markov random field mrf which simultaneously reason about monocular cue and about the relation between multiple image patch both within the same image and across different image triangulation cue map inference in our model is efficiently approximated using a series of linear program and our algorithm scale well to a large number of image 
we propose an algorithm to perform causal inference of the state of a dynamical model when the measurement are corrupted by outlier while the optimal maximum likelihood solution ha doubly exponential complexity due to the combinatorial explosion of possible choice of inliers we exploit the structure of the problem to design a sampling based algorithm that ha constant complexity we derive our algorithm from the equation of the optimal filter which make our approximation explicit our work is motivated by real time tracking and the estimation of structure from motion sfm we test our algorithm for on line outlier rejection both for tracking and for sfm we show that our approach can tolerate a large proportion of outlier whereas previous causal robust statistical inference method failed with le than half a many our work can be thought of a the extension of random sample consensus algorithm to dynamic data or a the implementation of pseudo bayesian filtering algorithm in a sampling framework 
we present a d model based approach to localizing human body in image viewed from arbitrary and unknown angle the central component is a statistical shape representation of the nonrigid and articulated body contour where a nonlinear deformation is decomposed based on the concept of part several image cue are combined to relate the body configuration to the observed image with self occlusion explicitly treated to accommodate large viewpoint change a mixture of view dependent model is employed inference is done by direct sampling of the posterior mixture using sequential monte carlo smc simulation enhanced with annealing and kernel move the fitting method is independent of the number of mixture component and doe not require the preselection of a correct viewpoint the model were trained on a large number of interactively labeled gait image preliminary test demonstrated the feasibility of the proposed approach 
we describe a probabilistic framework for recognizing human activity in monocular video based on simple silhouette observation in this paper the methodology combine kernel principal component analysis kpca based feature extraction and factorial conditional random field fcrf based motion modeling silhouette data is represented more compactly by nonlinear dimensionality reduction that explores the underlying structure of the articulated action space and preserve explicit temporal order in projection trajectory of motion fcrf model temporal sequence in multiple interacting way thus increasing joint accuracy by information sharing with the ideal advantage of discriminative model over generative one e g relaxing independence assumption between observation and the ability to effectively incorporate both overlapping feature and long range dependency the experimental result on two recent datasets have shown that the proposed framework can not only accurately recognize human activity with temporal intraand inter person variation but also is considerably robust to noise and other factor such a partial occlusion and irregularity in motion style 
we propose a novel numerical approach for solving the free form deformable registration problem the central idea is to utilize the well understood technique from variational deformable registration problem we demonstrate that it is possible to formulate the free form deformable registration problem a the optimization of an energy functional a in the dense deformation case this energy functional posse image distance and regularization term which are both function of the free form deformation control point we then setup a semi backward implicit partial differential equation that optimizes the established energy functional in addition to being mathematically justified this approach provides both accuracy and speed our evaluation on synthetic real two dimensional and three dimensional data demonstrates accuracy and computational effectiveness 
this study address the problem of unsupervised visual learning it examines existing popular model order selection criterion before proposes two novel criterion for improving visual learning given sparse data and without any knowledge about model complexity in particular a rectified bayesian information criterion bicr and a completed likelihood akaike s information criterion cl aic are formulated to estimate the optimal model order complexity for learning the dynamic structure of a visual scene both criterion are designed to overcome poor model selection by existing popular criterion when the data sample size varies from very small to large extensive experiment on learning a dynamic scene structure are carried out to demonstrate the effectiveness of bicr and cl aic compared to that of bic schwarz aic akaike icl biernacki and a mml figueiredo and jain based criterion 
most algorithm for reconstructing shape from defocus assume that the image are obtained with a camera that ha been previously calibrated so that the aperture focal plane and focal length are known in this manuscript we characterize the set of scene that can be reconstructed from defocused image regardless of calibration parameter in lack of knowledge about the camera or about the scene reconstruction is possible only up to an equivalence class that is described analytically when weak knowledge about the scene is available however we show how it can be exploited in order to auto calibrate the imaging device this includes imaging a slanted plane or generic assumption on the restoration of the deblurred image 
abstract high dynamic range image hdris are needed for capturing scene that include drastic lighting change this paper present a method to improve the dynamic range of a camera by using a reflective liquid crystal the system consists of a camera and a reflective liquid crystal placed in front of the camera by controlling the attenuation rate of the liquid crystal the scene radiance for each pixel is adaptively controlled after the control the original scene radiance is derived from the attenuation rate of the liquid crystal and the radiance obtained by the camera a prototype system ha been developed and tested for a scene that includes drastic lighting change the radiance of each pixel wa independently controlled and the hdris were obtained by calculating the original scene radiance from these result 
gait is a promising biometric cue which can facilitate the recognition of human being particularly when other biometrics are unavailable existing work for gait recognition however lay more emphasis on the problem of daytime walker recognition and overlook the significance of walker recognition at night this paper deal with the problem of recognizing nighttime walker we take advantage of infrared gait pattern to accomplish this task walker detection is improved using intensity compensation based background subtraction pseudoshape based feature are proposed to describe gait pattern the dimension of gait feature is reduced through the principal component analysis pca and linear discriminant analysis lda technique temporal cue are exploited in the form of the relevant component analysis rca learning the nearest neighbor classifier is used to recognize unknown gait experimental result justify the effectiveness of our method and show that our method ha an encouraging potential for the application in surveillance system 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework the method depends on a set of training shape used to build a parametric shape model the color is taken into consideration besides the shape prior information the shape model is fitted to the image volume by registration through an energy minimization problem the approach overcomes the conventional method problem like point correspondence and weighing coefficient tuning of the partial differential equation pde s also it is suitable for multi dimensional data and computationally efficient result of extracting the d star fish and the brain ventricle in d demonstrate theefficiency of the approach 
many high resolution image exhibit chromatic aberration ca where the color channel appear shifted unfortunately merely compensating for these shift is sometimes inadequate because the intensity are modified by other effect such a spatially varying defocus and surprisingly in camera sharpening in this paper we start from the basic principle of image formation to characterize ca and show how it effect can be substantially reduced we also show result of ca correction on a number of high resolution image taken with different camera 
efficient incremental image alignment is a topic of renewed interest in the computer vision community because of it application in model fitting and model based object tracking successful compositional procedure for aligning d and d model under weak perspective imaging condition have already been proposed here we present a mixed compositional and additive algorithm which is applicable to the full projective camera case 
we present a biologically motivated system for the recognition of action from video sequence the approach build on recent work on object recognition based on hierarchical feedforward architecture and extends a neurobiological model of motion processing in the visual cortex the system consists of a hierarchy of spatio temporal feature detector of increasing complexity an input sequence is first analyzed by an array of motiondirection sensitive unit which through a hierarchy of processing stage lead to position invariant spatio temporal feature detector we experiment with different type of motion direction sensitive unit a well a different system architecture a in we find that sparse feature in intermediate stage outperform dense one and that using a simple feature selection approach lead to an efficient system that performs better with far fewer feature we test the approach on different publicly available action datasets in all case achieving the highest result reported to date 
conventional stereo matching algorithm assume color constancy on the corresponding opaque pixel in the stereo image however when the foreground object with fractional boundary are blended to the scene behind using unknown alpha value due to the spatially varying disparity for different layer the color constancy doe not hold any more in this paper we address the fractional stereo matching problem a probability framework is introduced to establish the correspondence of pixel color disparity and alpha value in different layer we propose an automatic optimization method to solve a maximum a posteriori map problem using expectation maximization em given the input of only a narrow band stereo image pair our method naturally encodes pixel occlusion in the formulation of layer blending without a special detection process we demonstrate the effectiveness of our method using difficult stereo image 
the capacity to robustly detect human in video is a critical component of automated visual surveillance system this paper describes a bilattice based logical reasoning approach that exploit contextual information and knowledge about interaction between human and augments it with the output of different low level detector for human detection detection from low level part based detector are treated a logical fact and used to reason explicitly about the presence or absence of human in the scene positive and negative information from different source a well a uncertainty from detection and logical rule are integrated within the bilattice framework this approach also generates proof or justification for each hypothesis it proposes these justification or lack thereof are further employed by the system to explain and validate or reject potential hypothesis this allows the system to explicitly reasonaboutcomplexinteractionsbetweenhumansandhandle occlusion these proof are also available to the end user a an explanation of why the system think a particular hypothesis is actually a human we employ a boosted cascade of gradient histogram based detector to detect individual body part we have applied this framework to analyze the presence of human in static image from different datasets 
topic model from the text understanding literature have shown promising result in unsupervised image categorization and object localization category are treated a topic and word are formed by vector quantizing local descriptor of image patch limitation of topic model include their weakness in localizing object and the requirement of a fairly large proportion of word coming from the object we present a new approach that employ correspondence between image to provide information about object configuration which in turn enhances the reliability of object localization and categorization this approach is efficient a it requires only a small number of correspondence we show improved categorization and localization performance on real and synthetic data moreover we can push the limit of topic model when the proportion of word coming from the object is very low 
although camera self calibration and metric reconstruction have been extensively studied during the past decade automatic metric reconstruction from long video sequence with varying focal length is still very challenging several critical issue in practical implementation are not adequately addressed for example how to select the initial frame for initializing the projective reconstruction what criterion should be used how to handle the large zooming problem how to choose an appropriate moment for upgrading the projective reconstruction to a metric one this paper give a careful investigation of all these issue practical and effective approach are proposed in particular we show that existing image based distance is not an adequate measurement for selecting the initial frame we propose a novel measurement to take into account the zoom degree the self calibration quality a well a image based distance we then introduce a new strategy to decide when to upgrade the projective reconstruction to a metric one finally to alleviate the heavy computational cost in the bundle adjustment a local on demand approach is proposed our method is also extensively compared with the state of the art commercial software to evidence it robustness and stability 
this paper present a new algorithm for the automatic recognition of object class from image categorization compact and yet discriminative appearance based object class model are automatically learned from a set of training image the method is simple and extremely fast making it suitable for many application such a semantic image retrieval web search and interactive image editing itclassifies a region according to the proportion of different visual word cluster in feature space the specific visual word and the typical proportion in each object are learned from a segmented training set the main contribution of this paper is two fold i an optimally compact visual dictionary is learned by pair wise merging of visual word from an initially large dictionary the final visual word are described by gmms ii a novel statistical measure of discrimination is proposed which is optimized by each merge operation high classification accuracy is demonstrated for nine object class on photograph of real object viewed under general lighting condition pose and viewpoint the set of test image used for validation comprise i photograph acquired by u ii image from the web and iii image from the recently released pascal dataset the proposed algorithm performs well on both texture rich object e g grass sky tree and structure rich one e g car bike plane 
traditional aspect graph are topology based and are impractical for articulated object in this work we learn a small number of aspect or prototypical view from video data groundtruth segmentation in video sequence are utilized for both training and testing aspect model that operate on static image we represent aspect of an articulated object a collection of line segment in learning aspect where object center are known a linear matching based on line location and orientation is used to measure similarity between view we use k medoid to find cluster center when using line aspect in recognition matching is based on pairwise cue of relative location relative orientation a well adjacency and parallelism matching with pairwise cue lead to a quadratic optimization that we solve with a spectral approximation we show that our line aspect matching is capable of locating people in a variety of pose line aspect matching performs significantly better than an alternative approach using hausdorff distance showing merit of the line representation 
we propose a method that dramatically improves the performance of template based matching in term of size of convergence region and computation time this is done by selecting a subset of the template that verifies the assumption made during optimization of linearity or quadraticity with respect to the motion parameter we call these subset linear or quadratic subset while subset selection approach have already been proposed they generally do not attempt to provide linear or quadratic subset and rely on heuristic such a texturedness because a naive search for the optimal subset would result in a combinatorial explosion for large template we propose a simple algorithm that doe not aim for the optimal subset but provides a very good linear or quadratic subset at low cost even for large template simulation result and experiment with real sequence show the superiority of the proposed method compared to existing subset selection approach 
given a set of image containing multiple object category we seek to discover those category and their image location without supervision we achieve this using generative model from the statistical text literature probabilistic latent semantic analysis plsa and latent dirichlet allocation lda in text analysis these are used to discover topic in a corpus using the bag of word document representation here we discover topic a object category so that an image containing instance of several category is modelled a a mixture of topic the model are applied to image by using a visual analogue of a word formed by vector quantizing sift like region descriptor we investigate a set of increasingly demanding scenario starting with image set containing only two object category through to set containing multiple category including airplane car face motorbike spotted cat and background clutter the object category sample both intra class and scale variation and both the category and their approximate spatial layout are found without supervision we also demonstrate classification of unseen image and image containing multiple object performance of the proposed unsupervised method is compared to the semisupervised approach of 
image based object modeling ha emerged a an impor tant computer vision application typically the process start with the acquisition of the image view of an ob ject these view are registered within the global coordinate system using structure and motion technique while on the next step the geometric shape of an object is recovered u ing stereo and or silhouette cue this paper considers the final step which creates the texture map for the recovered geometry model the approach proposed in the paper naturally start by backprojecting original view onto the obtained sur face a texture is then mosaiced from these backprojections whereas the quality of the mosaic is maximized within the process of markov random field energy optimization fi nally the residual seam between the mosaic component are removed via seam levelling procedure which is similar to gradient domain stitching technique recently proposed for image editing unlike previous approach to the same problem inten sity blending a well a image resampling are avoided on all stage of the process which ensures that the resolution of the produced texture is essentially the same a that of the original view importantly due to restriction to non greedy energy optimization technique good result are produced even in the presence of significant error on image registra tion and geometric estimation step 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
efficient direct solution for the determination of a cylinder from point are presented the solution range from the well known direct solution of a quadric to the minimal solution of a cylinder with five point in contrast to the approach of g roth and m d levine who used polynomial base for representing the geometric entity we use algebraic constraint on the quadric representing the cylinder the solution for six to eight point directly determine all the cylinder parameter in one step the eight point solution similar to the estimation of the fundamental matrix requires to solve for the root of a rd order polynomial the seven point solution similar to the six point solution for the relative orientation by j philip yield a linear equation system the six point solution similar to the five point solution for the relative orientation by d nister yield a ten by ten eigenvalue problem the new minimal five point solution first determines the direction and then the position and the radius of the cylinder the search for the zero of the resulting th order polynomial is efficiently realized using d bernstein polynomial also direct solution for the special case with the ax of the cylinder parallel to a coordinate plane or axis are given the method is used to find cylinder in range data of an industrial site 
we propose a method for learning using a set of feature representation which retrieve different amount of information at different cost the goal is to create a more efficient terrain classification algorithm which can be used in real time onboard an autonomous vehicle instead of building a monolithic classifier with uniformly complex representation for each class the main idea here is to actively consider the label or misclassification cost while constructing the classifier for example some terrain class might be easily separable from the rest so very simple representation will be sufficient to learn and detect these class this is taken advantage of during learning so the algorithm automatically build a variable length visual representation which varies according to the complexity of the classification task this enables fast recognition of different terrain type during testing we also show how to select a set of feature representation so that the desired terrain classification task is accomplished with high accuracy and is at the same time efficient the proposed approach achieves a good trade off between recognition performance and speedup on data collected by an autonomous robot 
where am i and what am i seeing this is a classical vision problem and this paper present a solution based on efficient use of a combination of d and d feature given a model of a scene the objective is to find the relative camera location of a new input image unlike traditional hypothesize and test method that try to estimate the unknown camera position based on d model feature only or alternatively based on d model feature only we show that using a mixture of such feature that is a hybrid correspondence set may improve performance we use minimal case of structure from motion for hypothesis generation in a ransac engine for this purpose several new and useful minimal case are derived for calibrated semi calibratedanduncalibratedsettings basedon algebraic geometry method we show how these minimal hybrid case can be solved efficiently the whole approach ha been validated on both synthetic and real data and we demonstrate improvement compared to previous work 
we derive the clustering problem from first principle showing that the goal of achieving a probabilistic or hard multi class clustering result is equivalent to the algebraic problem of a completely positive factorization under a doubly stochastic constraint we show that spectral clustering normalized cut kernel k mean and the various normalization of the associated affinity matrix are particular instance and approximation of this general principle we propose an efficient algorithm for achieving a completely positive factorization and extend the basic clustering scheme to situation where partial label information is available 
we present a monocularslam system that avoidsinconsistency by coalescing observation into independent local coordinateframes buildinga graphof the local frame and optimizing the resulting graph we choose coordinate that minimize the nonlinearity of the update in the node and suggest a heuristic measure of such nonlinearity using it to guide our traversal of the graph the system operates in real time on sequence with several hundred of landmark while performing global graph optimization yielding accurate and nearly consistent estimation relative to offline bundle adjustment and considerably better consistency than ekf slam and fastslam 
in this paper an easy calibration method for projector is proposed the calibration handled in this paper is projective relation between d space and d pattern and is not correction of trapezoid distortion in projected pattern in projector camera system especially for d measurement such calibration is the basis of process the projection from projector can be modeled a inverse projection of the pinhole camera which is generally considered a perspective projection in the existing system some special object or device are often used to calibrate projector so that d d projection map can be measured for typical camera calibration method the proposed method utilizes projective geometry between camera and projector so that it requires only pre calibrated camera and a plane it is easy to practice easy to calculate and reasonably accurate 
in this paper we address the problem of detecting pedestrian in still image we introduce an algorithm for learning shapelet feature a set of mid level feature these feature are focused on local region of the image and are built from low level gradient information that discriminates between pedestrian and non pedestrian class using adaboost these shapelet feature are created a a combination of oriented gradient response to train the final classifier we use adaboost for a second time to select a subset of our learned shapelets by first focusing locally on smaller feature set our algorithm attempt to harvest more useful information than by examining all the low level feature together we present quantitative result demonstrating the effectiveness of our algorithm in particular we obtain an error rate percentage point lower at fppw than the previous state of the art detector of dalal and triggs on the inria dataset 
discontinuity preserving filtering of image is an important low level vision task with the development of new imaging technique like diffusion tensor imaging dti where the data doe not lie in a vector space previous method like the original mean shift are not applicable in this paper we use the nonlinear mean shift algorithm to develop filtering method for data lying on analytic manifold we work out the computational detail of using mean shift on sym n the manifold of n n symmetric positive definite matrix we apply our algorithm to chromatic noise filtering whichrequiresmeanshiftoverthegrassmannmanifold g and obtain better result then standard mean shift filtering we also use our method for dti filtering which requires smoothing over sym 
target based positioning and d target reconstruction are critical capability in deploying submersible platform for a range of underwater application e g search and inspection mission while optical camera provide highresolution and target detail they are constrained by limited visibility range in highly turbid water target at up to distance of s of meter can be recorded by high frequency mhz d sonar imaging system that have become introduced to the commercial market in recent year because of lower resolution and snr level and inferior target detail compared to optical camera in favorable visibility condition the integration of both sensing modality can enable operation in a wider range of condition with generally better performance compared to deploying either system alone in this paper estimate of the d motion of the integrated system and the d reconstruction of scene feature are addressed we do not require establishing match between optical and sonar feature referred to a opti acoustic correspondence but rather match in either the sonar or optical motion sequence in addition to improving the motion estimation accuracy advantage of the system comprise overcoming certain inherent ambiguity of monocular vision e g the scale factor ambiguity and dual interpretation of planar scene we discus how the proposed solution provides an effective strategy to address the rather complex opti acoustic stereo matching problem experiment with real data demonstrate our technical contribution 
closing the semantic gap in content based image retrieval cbir basically requires the knowledge of the user s intention which is usually translated into a sequence of question and answer q a the user s feedback to these question provides a cbir system with a partial labeling of the data and make it possible to iteratively rene a decision rule on the unlabeled data training of this decision rule is referred to a transductive learning this work is an original approach to relevance feedback rf based on graph cut training consists in implicitly modeling the manifold enclosing both the labeled and unlabeled dataset and nding a partition of this manifold using a min cut the contribution of this work is two fold i this is the r st comprehensive study of relevance feedback using graph cut and ii our rf model exploit the structure of the data manifold by considering also the structure of the unlabeled data experiment conducted on generic a well a specic database show that our graph cut based approach is very effective outperforms other existing method and make it possible to converge to almost all the image of the user s class of interest with a very small labeling effort a demo is available through our image retrieval tool kit irtk 
abstract the registration problem for image of a deforming surface ha been well studied external occlusion are usually well handled in d image based registration self occlusion are more challenging consequently the surface is usually assumed to be only slightly self occluding this paper is about image based non rigid registration with self occlusion reasoning a specific framework explicitly modeling self occlusion is proposed it is combined with an intensity based direct data term for registration self occlusion are detected a shrinkage area in the d warp experimental result on several challenging datasets show that our approach successfully register image with self occlusion while effectively detecting the self occluded region 
in this paper we present novel ridge regression rr and kernel ridge regression krr technique for multivariate label and apply the method to the problem efface recognition motivated by the fact that the regular simplex vertex are separate point with highest degree of symmetry we choose such vertex a the target for the distinct individual in recognition and apply rr or krr to map the training face image into a face subspace where the training image from each individual will locate near their individual target we identify the new face image by mapping it into this face subspace and comparing it distance to all individual target an efficient cross validation algorithm is also provided for selecting the regularization and kernel parameter experiment were conducted on two face database and the result demonstrate that the proposed algorithm significantly outperforms the three popular linear face recognition technique eigenfaces fisher face and laplacian face and also performs comparably with the recently developed orthogonal laplacian face with the advantage of computational speed experimental result also demonstrate that krr outperforms rr a expected since krr can utilize the nonlinear structure of the face image although we concentrate on face recognition in this paper the proposed method is general and may be applied for general multi category classification problem 
this paper present a framework to automatically detect and recover the occluded facial region we first derive a bayesian formulation unifying the occlusion detection and recovery stage then a quality assessment model is developed to drive both the detection and recovery process which capture the face prior in both global correlation and local pattern based on this formulation we further propose graphcut based detection and confidence oriented sampling to attain optimal detection and recovery respectively compared to traditional work in image repairing our approach is distinct in three aspect it free the user from marking the occlusion area by incorporating an automatic occlusion detector it learns a face quality model a a criterion to guide the whole procedure it couple the detection and occlusion stage to simultaneously achieve two goal accurate occlusion detection and high quality recovery the comparative experiment show that our method can recover the occluded face with both the global coherence and local detail well preserved 
this paper describes an online learning based method to detect flame in video by processing the data generated by an ordinary camera monitoring a scene our fire detection method consists of weak classifier based on temporal and spatial modeling of flame markov model representing the flame and flame colored ordinary moving object are used to distinguish temporal flame flicker process from motion of flame colored moving object boundary of flame are represented in wavelet domain and high frequency nature of the boundary of fire region is also used a a clue to model the flame flicker spatially result from temporal and spatial weak classifier based on flame flicker and irregularity of the flame region boundary are updated online to reach a final decision false alarm due to ordinary and periodic motion of flame colored moving object are greatly reduced when compared to the existing video based fire detection system 
we propose a method of simultaneously calibrating the radial distortion function of a camera and the other internal calibration parameter the method relies on the use of a planar or alternatively nonplanar calibration grid which is captured in several image in this way the determination of the radial distortion is an easy add on to the popular calibration method proposed by zhang the method is entirely noniterative and hence is extremely rapid and immune to the problem of local minimum our method determines the radial distortion in a parameter free way not relying on any particular radial distortion model this make it applicable to a large range of camera from narrow angle to fish eye lens the method also computes the center of radial distortion which we argue is important in obtaining optimal result experiment show that this point may be significantly displaced from the center of the image or the principal point of the camera 
in this paper we address the problem of learning compact view independent realistic d model of human action recorded with multiple camera for the purpose of recognizing those same action from a single or few camera without prior knowledge about the relative orientation between the camera and the subject to this aim we propose a new framework where we model action using three dimensional occupancy grid built from multiple viewpoint in an exemplar based hmm the novelty is that a d reconstruction is not required during the recognition phase instead learned d exemplar are used to produce d image information that is compared to the observation parameter that describe image projection are added a latent variable in the recognition process in addition the temporal markov dependency applied to view parameter allows them to evolve during recognition a with a smoothly moving camera the effectiveness of the framework is demonstrated with experiment on real datasets and with challenging recognition scenario 
in this paper we present a novel boosting algorithm for supervised learning that incorporates invariance to data transformation and ha high generalization capability while one can incorporate invariance by adding virtual sample to the data e g by jittering we adopt a much more efficient strategy and work along the line of vicinal risk minimization and tangent distance method a in vicinal risk minimization we incorporate invariance to data by applying anisotropic smoothing along the direction of invariance moreover a in tangent distance method we provide a simple local approximation to such direction thus obtaining an efficient computational scheme we also show that it is possible to automatically design optimal weak classifier by using gradient descent to increase efficiency at run time such optimal weak classifier are projected on a haar basis this result in designing strong classifier that are more computationally efficient than in the case of exhaustive search for illustration and validation purpose we demonstrate the novel algorithm both on synthetic and on real data set that are publicly available 
image matting is the problem of determining for each pixel in an image whether it is foreground background or the mixing parameter alpha for those pixel that are a mixture of foreground and background matting is inherently an ill posed problem previous matting approach either use naive color sampling method to estimate foreground and background color for unknown pixel or use propagation based method to avoid color sampling under weak assumption about image statistic we argue that neither method itself is enough to generate good result for complex natural image we analyze the weakness of previous matting approach and propose a new robust matting algorithm in our approach we also sample foreground and background color for unknown pixel but more importantly analyze the confidence of these sample only high confidence sample are chosen to contribute to the matting energy function which is minimized by a random walk the energy function we define also contains a neighborhood term to enforce the smoothness of the matte to validate the approach we present an extensive and quantitative comparison between our algorithm and a number of previous approach in hope of providing a benchmark for future matting research 
we propose using the proximity distribution of vectorquantized local feature descriptor for object and category recognition to this end we introduce a novel proximity distribution kernel that naturally combine local geometric a well a photometric information from image it satisfies mercer s condition and can therefore be readily combined with a support vector machine to perform visual categorization in a way that is insensitive to photometric and geometric variation while retaining significant discriminative power in particular it improves on the result obtained both with geometrically unconstrained bag of feature approach a well a with over constrained affine procrustes indeed we test this approach on several challenging data set including graz graz and the pascal challenge we registered the average performance at on graz on graz and on pascal our approach is designed to enforce and exploit geometric consistency among object in the same category therefore it doe not improve the performance of existing algorithm on datasets where the data is already roughly aligned and scaled our method ha the potential to be extended to more complex geometric relationship among local feature a we illustrate in the experiment 
we present a novel algorithm to jointly capture the motion and the dynamic shape of human from multiple video stream without using optical marker instead of relying on kinematic skeleton a traditional motion capture method our approach us a deformable high quality mesh of a human a scene representation it jointly us an imagebased d correspondence estimation algorithm and a fast laplacian mesh deformation scheme to capture both motion and surface deformation of the actor from the input video footage a opposed to many related method our algorithm can track people wearing wide apparel it can straightforwardly be applied to any type of subject e g animal and it preserve the connectivity of the mesh over time we demonstrate the performance of our approach using synthetic and captured real world video sequence and validate it accuracy by comparison to the ground truth 
abstract we propose a non iterative solution to the pnp problem the estimation of the pose of a calibrated camera from n d to d point correspondence whose computational complexity grows linearly with n this is in contrast to state of the art method that are o n without being more accurate our method is applicable for all n and handle properly both planar and non planar configuration our central idea is to express the n d point a a weighted sum of four virtual control point the problem then reduces to estimating the coordinate of these control point in the camera referential which can be done in o n time by expressing these coordinate a weighted sum of the eigenvectors of a matrix and solving a small constant number of quadratic equation to pick the right weight the advantage of our method are demonstrated by thorough testing on both synthetic and real data 
we address the problem of developing discriminative yet invariant feature for texture classification texture variation due to change in scale are amongst the hardest to handle one of the most successful method of dealing with such variation is based on choosing interest point and selecting their characteristic scale lazebnik et al pami however selecting a characteristic scale can be unstable for many texture furthermore the reliance on an interest point detector and the inability to evaluate feature densely can be serious limitation fractal present a mathematically well founded alternative to dealing with the problem of scale however they have not become popular a texture feature due to their lack of discriminative power this is primarily because a fractal based classification method have avoided statistical characterisation of texture which is essential for accurate analysis by using global feature and b fractal dimension feature are unable to distinguish between key texture primitive such a edge corner and uniform region in this paper we overcome these drawback and develop local fractal feature that are evaluated densely the feature are robust a they do not depend on choosing interest point or characteristic scale furthermore it is shown that the local fractal dimension is invariant to local bi lipschitz transformation whereas it extension is able to correctly distinguish between fundamental texture primitive texture are characterised statistically by modelling the full joint pdf of these feature this allows u to develop a texture classification framework which is discriminative robust and achieves state of the art performance a compared to affine invariant and fractal based method 
a novel method is introduced to recognize and estimate the scale of time varying human gesture it exploit the change in contour along spatio temporal direction each contour is first parameterized a a d function of radius v cumulative contour length and a d surface is composed from a sequence of such function in a two phase recognition process dynamic timewarping is employed to rule out significantly different gesture model and then mutual information mi is applied for matching the remaining model the system ha been tested on gesture performed by subject with varied time scale the two phase process is compared against exhaustively testing three similarity measure based upon mi correlation and nonparametric kernel density estimation experimental result demonstrate that the exhaustive application of mi is the most robust with a recognition rate of however the two phase approach is much more computationally efficient with a comparable recognition rate of 
d human pose recovery is considered a a fundamental step in view invariant human action recognition however inferring d pose from a single view usually is slow due to the large number of parameter that need to be estimated and recovered pose are often ambiguous due to the perspective projection we present an approach that doe not explicitly infer d pose at each frame instead from existing action model we search for a series of action that best match the input sequence in our approach each action is modeled a a series of synthetic d human pose rendered from a wide range of viewpoint the constraint on transition of the synthetic pose is represented by a graph model called action net given the input silhouette matching between the input frame and the key pose is performed first using an enhanced pyramid match kernel algorithm the best matched sequence of action is then tracked using the viterbi algorithm we demonstrate this approach on a challenging video set consisting of complex action class 
we propose using stereo matching for d face recognition across pose we match one d query image to one d gallery image without performing d reconstruction then the cost of this matching is used to evaluate the similarity of the two image we show that this cost is robust to pose variation to illustrate this idea we built a face recognit ion system on top of a dynamic programming stereo matching algorithm the method work well even when the epipolar line we use do not exactly fit the viewpoint we have tested our approach on the pie dataset in all the experiment our method demonstrates effective performance compared with other algorithm 
in this paper we propose to transform an image descriptor so that nearest neighbor nn search for correspondence becomes the optimal matching strategy under the assumption that inter image deviation of corresponding descriptor have gaussian distribution the euclidean nn in the transformed domain corresponds to the nn according to a truncated mahalanobis metric in the original descriptor space we provide theoretical justification for the propose d approach and show experimentally that the transformation allows a significant dimensionality reduction and improves matching performance of a state of the artsift descriptor we observe consistent improvement in precision recal l and speed of fast matching in tree structure at the expense of little overhead for projecting the descriptor into tran sformed space in the context of sift v transformed msift comparison tree search structure are evaluated according to different criterion and query type all search tr ee experiment confirm that transformedm sift performs better than the original sift 
in this paper we present the classification sub system of a real time video based face identification system which recognizes people entering through the door of a laboratory since the subject are not asked to cooperate with the system but are allowed to behave naturally this application scenario pose many challenge continuous uncontrolled variation of facial appearance due to illumination pose expression and occlusion need to be handled to allow for successful recognition face are classified by a local appearance based face recognition algorithm the obtained confidence score from each classification are progressively combined to provide the identity estimate of the entire sequence we introduce three different measure to weight the contribution of each individual frame to the overall classification decision they are distanceto model dtm distance to second closest dt nd and their combination both a k nearest neighbor approach and a set of gaussian mixture are evaluated to produce individual frame score we have conducted closed set and open set identification experiment on a database of subject the experimental result show that the proposed system is able to reach high correct recognition rate in a difficult scenario 
many computer vision task may be expressed a the problem of learning a mapping between image space and a parameter space for example in human body pose estimation recent research ha directly modelled the mapping from image feature z to joint angle fitting such model requires training data in the form of labelled z pair from which are learned the conditional density p z inference is then simple given test image feature z the conditional p z is immediately computed however large amount of training data are required to fit the model particularly in the case where the space are high dimensional we show how the use of unlabelled data sample from the marginal distribution p z and p may be used to improve fitting this is valuable because it is often significantly easier to obtain unlabelled than labelled sample we use a gaussian process latent variable model to learn the mapping from a shared latent low dimensional manifold to the feature and parameter space this extends existing approach to a use unlabelled data and b represent one to many mapping experiment on synthetic and real problem demonstrate how the use of unlabelled data improves over existing technique in our comparison we include existing approach that are explicitly semi supervised a well a those which implicitly make use of unlabelled example 
the presence of noise render the classical factorization method almost impractical for real world multi body motion tracking problem the main problem stem from the effect of noise on the shape interaction matrix which loos it block diagonal structure and a a result the assignment of element to object becomes difficult the aim in this paper is to overcome this problem using graph spectral embedding and the k mean algorithm to this end we develop a representation based on the commute time between node on a graph the commute time i e the expected time taken for a random walk to travel between two node and return can be computed from the laplacian spectrum using the discrete green s function and is an important property of the random walk on a graph the commute time is a more robust measure of the proximity of data than the raw proximity matrix our embedding procedure preserve commute time and is closely akin to kernel pca the laplacian eigenmap and the diffusion map we illustrate the result both on the synthetic image sequence and real world video sequence and compare our result with several alternative method 
stereo correspondence method rely on matching cost for computing the similarity of image location in this paper we evaluate the insensitivity of different matching cost with respect to radiometric variation of the input image we consider both pixel based and window based variant and measure their performance in the presence of global intensity change e g due to gain and exposure difference local intensity change e g due to vignetting nonlambertian surface and varying lighting and noise using existing stereo datasets with ground truth disparity a well a six new datasets taken under controlled change of exposure and lighting we evaluate the different cost with a local a semi global and a global stereo method 
current method for learning visual category work well when a large amount of labeled data is available but can run into severe difficulty when the number of labeled example is small when labeled data is scarce it may be beneficial to use unlabeled data to learn an image representation that is low dimensional but nevertheless capture the information required to discriminate between image category this paper describes a method for learning representation from large quantity of unlabeled image which have associated caption the goal is to improve learning in future image classification problem experiment show that our method significantly outperforms a fully supervised baseline model a model that ignores the caption and learns a visual representation by performing pca on the unlabeled image alone and a model that us the output of word classifier trained using caption and unlabeled data our current work concentrate on caption a the source of meta data but more generally other type of meta data could be used 
outdoor face recognition is among the most challenging problem for face recognition in this paper we develop a discriminant mutual subspace learning algorithm for indoor and outdoor face recognition unlike traditional algorithm using one subspace to model both indoor and outdoor face image our algorithm simultaneously learn two related subspace for indoor and outdoor image respectively thus can better model both to further improve the recognition performance we develop a dmsl based multiclassifier fusion framework on gabor image using a new fusion method called adaptive informative fusion scheme experimental result clearly show that this framework can greatly enhance the recognition performance 
a bottom up visual saliency detector is proposed following a decision theoretic formulation of saliency previou sly developed for top down processing object recognition the saliency of a given location of the visual field is defined a the power of a gabor like feature set to discriminate between the visual appearance of a neighborhood centered at that location the center and a neighborhood that surround it the surround discrimination is defined in an information theoretic sense and the optimal saliency dete ctor derived for a class of stimulus that complies with known statistical property of natural image so a to achieve a computationally efficient solution the resulting saliency detector is shown to replicate the fundamental property o f the psychophysics of pre attentive vision including stim ulus pop out inability to detect feature conjunction asy mmetries with respect to feature presence v absence and compliance with weber s law it is also shown that the detector produce better prediction of human eye fixation than two previously proposed bottom up saliency detector 
in this paper we describe a technique to temporally sort a collection of photo that span many year by reasoning about persistence of visible structure we show how this sorting task can be formulated a a constraint satisfaction problem csp casting this problem a a csp allows u to efficiently find a suitable ordering of the image despite the large size of the solution space factorial in the number of image and the presence of occlusion we present experimental result for photograph of a city acquired over a one hundred year period 
multifocus fusion is the process of fusing focal information from a set of input image into one all in focus image here a versatile multifocus fusion algorithm is presented for application independent fusion a focally connected region is a region or a set of region in an input image that fall under the depth of field of the imaging system such region are segmented adaptively under the predicate of focal connectivity and fused by partition synthesis the fused image ha information from all focal plane while maintaining the visual verisimilitude of the scene in order to validate the fusion performance of our method we have compared our result with those of tiling and multiscale fusion technique in addition to performing a seamless fusion of the focally connected region our method out performs the competing method regarding overall sharpness in all our experiment several illustrative example of multifocus fusion are shown and objective comparison are provided 
we present an approach for camera calibration from the image of at least two circle arranged in a coaxial way such a geometric conflguration arises in static scene of object with rotational symmetry or in scene including generic object undergoing rotational motion around a flxed axis the approach is based on the automatic localization of a surface of revolution sor in the image and it use a a calibration artifact the sor can either be a real object in a static scene or a virtual surface obtained by frame superposition in a rotational sequence this provides a unifled framework for calibration from single image of sors or from turntable sequence both the internal and external calibration parameter square pixel model are obtained from two or more imaged cross section of the sor whose apparent contour is also exploited to obtain a better calibration accuracy experimental result show that this calibration approach is accurate enough for several vision application encompassing d realistic model acquisition from single image and desktop d object scanning 
in order to achieve natural proactive and non intrusive in teraction between human and robot the understanding of human action is a highly relevant task in this paper a vision based method for manipulative gesture recognition is proposed different from the traditional trajectory based approach the manipulative action are modeled not only based on the hand trajectory but also on the object con text this context based trajectory recognition is embedded in a hierarchical hidden markov model which represents the hierarchical structure in manipulation task for represen tation a lattice dynamic bayesian network is used and the inference is done by particle filtering the result of experi ments in an office environment show the applicability of this approach for recognizing manipulative gesture 
informative vector machine ivm is an efficient fast sparse gaussian process s gp method previously suggested for active learning it greatly reduces the computational cost of gp classification and make the gp learning close to real time we apply ivm for man made structure classification a two class problem our work includes the investigation of the performance of ivm with varied active data point a well a the effect of different choice of gp kernel satisfactory result have been obtained showing that the approach keep full gp classification performance and yet is significantly faster by virtue if using a subset of the whole training data point 
we present an integrated framework for learning asymmetric boosted classifier and online learning to address the problem of online learning asymmetric boosted classifier which is applicable to object detection problem in particular our method seek to balance the skewness of the label presented to the weak classifier allowing them to be trained more equally in online learning we introduce an extra constraint when propagating the weight of the data point from one weak classifier to another allowing the algorithm to converge faster in compared with the online boosting algorithm recently applied to object detection problem we observed about increase in accuracy and about gain in learning speed 
current approach to motion category recognition typically focus on either full spatiotemporal volume analysis holistic approach or analysis of the content of spatiotemporal interest point part based approach holistic approach tend to be more sensitive to noise e g geometric variation while part based approach usually ignore structural dependency between part this paper present a novel generativemodel which extendsprobabilistic latent semantic analysis plsa to capture both semantic content of part and structural connection between part information for motion category recognition the structural information learnt can also be used to infer the location of motion for the purpose of motion detection we test our algorithm on challenging datasets involving human action facial expression and hand gesture and show it performance is better than existing unsupervised method in both task of motion localisation and recognition 
abstract in this paper we present a full featured license plate detection and recognition system the system is implemented on an embedded dsp platform and process a video stream in real time it consists of a detection and a character recognition module the detector is based on the adaboost approach presented by viola and jones detected license plate are segmented into individual character by using a region based approach character classification is performed with support vector classification in order to speed up the detection process on the embedded device a kalman tracker is integrated into the system the search area of the detector is limited to location where the next location of a license plate is predicted furthermore classification result of subsequent frame are combined to improve the class accuracy the major advantage of our system are it real time capability and that it doe not require any additional sensor input e g from infrared sensor except a video stream we evaluate our system on a large number of vehicle and license plate using bad quality video and show that the low resolution can be partly compensated by combining classification result of subsequent frame 
application in computer vision involve statistically analyzing an important class of constrained nonnegative function including probability density function in texture analysis dynamic time warping function in activity analysis and re parametrization or non rigid registration function in shape analysis of curve for this one need to impose a riemannian structure on the space formed by these function we propose a spherical version of the fisher rao metric that provides closed form expression for geodesic and distance and allows fast computation of sample statistic to demonstrate this approach we present an application in planar shape classification 
the task of registering video frame with a static model is a common problem in many computer vision domain the standard approach to registration involves finding point correspondence between the video and the model and using those correspondence to numerically determine registration transforms current method locate video to model point correspondence by assembling a set of reference image to represent the model and then detecting and matching invariant local image feature between the video frame and the set of reference image these method work well when all video frame can be guaranteed to contain a sufficient number of distinctive visual feature however a we demonstrate these method are prone to severe misregistration error in domain where many video frame lack distinctive image feature to overcome these error we introduce a concept of local distinctiveness which allows u to find model match for nearly all video feature regardless of their distinctiveness on a global scale we present result from the american football domain where many video frame lack distinctive image feature which show a drastic improvement in registration accuracy over current method in addition we introduce a simple empirical stability test that allows our method to be fully automated finally we present a registration dataset from the american football domain we hope can be used a a benchmarking tool for registration method 
in this paper we present a method for photometric selfcalibration of a projector camera system in addition to the input transfer function commonly called gamma function we also reconstruct the spatial intensity fall off from the center to fringe commonly called the vignetting effect for both the projector and camera projector camera system are becoming more popular in a large number of application like scene capture d reconstruction and calibrating multi projector display our method enables the use of photometrically uncalibrated projector and camera in all such application 
kernel based tracker aggregate image feature within the support of a kernel a mask regardless of their spatial structure these tracker spatially fit the kernel usually in location and in scale such that a function of the aggregate is optimized we propose a kernel based visual tracker that exploit theconstancyofcolorandthepresenceofcoloredgesalong the target boundary the tracker estimate the best affinity of a spatially aligned pair of kernel one of which is colorrelated and the other of which is object boundary related in a sense this work extends previous kernel based tracker by incorporating the object boundary cue into the tracking process and by allowing the kernel to be affinely transformed instead of only translated and isotropically scaled these two extension make for more precise target localization moreover a more accurately localized target facilitates safer updating of it reference color model further enhancing the tracker s robustness the improved tracking is demonstrated for several challenging image sequence 
aerial imagery and ground level imagery are two complementary data source for architectural modeling how to integrate them is a critical issue in creating complete photo realistic and large scale urban model we describe a semiautomatic approach of detecting feature correspondence between ground level image and the building footprint in an orthorectified aerial image the ground level image are stitched into panorama in order to obtain a wide camera field of view line segment are extracted from ground level image their corresponding segment on the building footprint are automatically detected through a voting process meanwhile the camera pose of the groundlevel image is also obtained wrong correspondence are corrected through user interaction later the height value of the building roof corner are computed and a piece wise planar d model with photo realistic facade and roof texture is then created 
we present a novel d scanning system combining stereo and active illumination based on phase shift for robust and accurate scene reconstruction stereo overcomes the traditional phase discontinuity problem and allows for the reconstruction of complex scene containing multiple object due to the sequential recording of three pattern motion will introduce artifact in the reconstruction we develop a closed form expression for the motion error in order to apply motion compensation on a pixel level the resulting scanning system can capture accurate depth map of complex dynamic scene at fps and can cope with both rigid and deformable object 
reliable tracking of multiple moving object in video is an interesting challenge made difficult in real world video by various source of noise and uncertainty we propose a bayesian approach to find correspondence between moving object over frame by using color value and position information of the moving object a observation we probabilistically assign track to those object we allow for track to be lost and then recovered when they resurface the probabilistic assignment method along with the ability to recover lost track add robustness to the tracking system we present result that show that the bayesian method performs well in difficult tracking case and compare the probabilistic result to a euclidean distance based method 
one main challenge in augmented reality ar application is to keep track of video object with their movement orientation size and position accurately this pose a challenging task to recover non rigid shape and global pose in real time ar application this paper proposes a novel two stage scheme for online non rigid shape recovery toward ar application using active appearance model aams first we construct d shape model from aams offline which do not involve processing of the d scan data based on the computed d shape model we propose an efficient online algorithm to estimate both d pose and non rigid shape parameter via local bundle adjustment for building up point correspondence our approach without manual intervention can recover the d non rigid shape effectively from either real time video sequence or single image the recovered d pose parameter can be used for ar registration furthermore the facial feature can be tracked simultaneously which is critical for many face related application we evaluate our algorithm on several video sequence promising experimental result demonstrate our proposed scheme is effective and significant for real time ar application 
color appearance of an object is significantly influenced by the color of the illumination when the illumination color change the color appearance of the object will change accordingly causing it appearance to be inconsistent to arrive at color constancy we have developed a physic based method of estimating and removing the illumination color in this paper we focus on the use of this method to deal with outdoor scene since very few physic based method have successfully handled outdoor color constancy our method is principally based on shadowed and non shadowed region previously researcher have discovered that shadowed region are illuminated by sky light while non shadowed region are illuminated by a combination of sky light and sunlight based on this difference of illumination we estimate the illumination color both the sunlight and the sky light and then remove them to reliably estimate the illumination color in outdoor scene we include the analysis of noise since the presence of noise is inevitable in natural image a a result compared to existing method the proposed method is more effective and robust in handling outdoor scene in addition the proposed method requires only a single input image making it useful for many application of computer vision 
we describe a probabilistic model for learning rich distributed representation of image transformation the basic model is defined a a gated conditional random field that is trained to predict transformation of it input using a factorial set of latent variable inference in the model consists in extracting the transformation given a pair of image and can be performed exactly and efficiently we show that when trained on natural video the model develops domain specific motion feature in the form of field of locally transformed edge filter when trained on affine or more general transformation of still image the model develops code for these transformation and can subsequently perform recognition task that are invariant under these transformation it can also fantasize new transformation on previously unseen image we describe several variation of the basic model and provide experimental result that demonstrate it applicability to a variety of task 
we present a method for the simultaneous detection and segmentation of people from static image the proposed technique requires no manual segmentation during training and exploit top down and bottom up processing within a single framework for both object localization and d shape estimation first the coarse shape of the object is learned from a simple training phase utilizing low level edge feature motivated by the observation that most object category have regular shape and closed boundary relation between these feature are then exploited to derive mid level cue such a continuity and closure a novel markov random field defined on the edge feature is presented that integrates the coarse shape information with our expectation that object are likely to have boundary that are regular and closed the algorithm is evaluated on pedestrian datasets of varying difficulty including a wide range of camera viewpoint and person orientation quantitative result are presented for person detection and segmentation demonstrating the effectiveness of the proposed technique to simultaneously address both these task 
although it is usually assumed in many pattern recognition problem that different pattern are distinguishable some pattern may have inseparable overlap for example some facial expression involve subtle muscle movement and are difficult to separate from other expression or neutral face in this paper we consider such overlapped pattern a cluster and present a novel method to quantify cluster overlap based on the bayes error estimation on manifold our method first applies a manifold learning method isomap to discover the intrinsic structure of data and then measure the overlap of different cluster using the k nn bayes error estimation on the learned manifold due to the isomap s capability of preserving geodesic distance and k nn s localized estimation the method can provide an accurate measure of the overlap between cluster a demonstrated by our simulation experiment the method is further applied for an analysis of a specific type of facial expression impairment in schizophrenia i e flat effect which refers to a severe reduction in emotional expressiveness in this study we capture facial expression of individual and quantify their expression flatness by estimating overlap between different facial expression the experimental result show that the patient group ha much larger facial expression overlap than the control group and demonstrate that the flat affect is an important symptom in diagnosing schizophrenia patient 
in this paper we propose a new segmentation algorithm which combine patch based information with edge cue under a probabilistic framework we use a mixture of multiple gaussians for building the statistical model with color and spatial feature and we incorporate edge information based on texture color and brightness difference into the em algorithm we evaluate our result qualitatively and quantitatively on a large data set of natural image and compare our result to other state of the art method 
this paper present a component based deformable model for generalized face alignment in which a novel bi stage statistical framework is proposed to account for both local and global shape characteristic instead of using statistical analysis on the entire shape a in previous alignment work we build separate gaussian model for shape component to preserve more detailed local shape deformation in each model of component the markov network is integrated to provide simple geometry constraint for our search strategy in order to make a better description of the nonlinear interrelationship over the shape component the gaussian process latent variable model is adopted to obtain enough control of full range shape variation furthermore we propose an illumination robust feature to lead the local fitting of every shape point when light condition change dramatically based on this approach our system can generate optimal shape for image with exaggerated expression and under variable illumination a evidenced by extensive experimentation 
this paper present a new shape registration algorithm that establishes meaningful correspondence between object in that it preserve the local shape correspondence between the source and target object by observing that an object s skeleton corresponds to it local shape peak we use skeleton to characterize the local shape of the source and target object unlike traditional graph based skeleton matching algorithm that focus on matching skeleton alone and ignore the overall alignment of the boundary our algorithm is formulated in a variational framework which aligns local shape by registering two potential field that are associated with skeleton also we add a boundary constraint term to the energy functional such that our algorithm can be applied to match bulky object where skeleton and boundary are far away to each other to increase the robustness of our algorithm we incorporate m estimator and dynamic pruning algorithm to form a feedback system that eliminates local shape outlier caused by nonrigid deformation occlusion and missing part experiment on d binary shape and d cardiac sequence validate the accuracy and robustness of this algorithm 
local spatiotemporal feature or interest point provide compact but descriptive representation for efficient video analysis and motion recognition current local feature extraction approach involve either local filtering or entropy computation which ignore global information e g large blob of moving pixel in video input this paper present a novel extraction method which utilises global information from each video input so that moving part such a a moving hand can be identified and are used to select relevant interest point for a condensed representation the proposed method involves obtaining a small set of subspace image which can synthesise frame in the video input from their corresponding coefficient vector and then detecting interest point from the subspace and the coefficient vector experimental result indicate that the proposed method can yield a sparser set of interest point for motion recognition than existing method 
epipolar geometry and relative camera pose computation are example of task which can be formulated a minimal problem and solved from a minimal number of image point finding the solution lead to solving system of algebraic equation often these system are not trivial and therefore special algorithm have to be designed to achieve numerical robustness and computational efficiency in this paperwe provide a solution to the problem of estimating radial distortion and epipolargeometry from eight correspondence in two image unlike previous algorithm which were able to solve the problem from nine correspondence only we enforce the determinant of the fundamental matrix be zero this lead to a system of eight quadratic and one cubic equation in nine variable we simplify the system by eliminating six of these variable then we solve the system by finding eigenvectors of an action matrix of a suitably chosen polynomial we show how to construct the action matrix without computing complete gr obner basis which provides an efficient and robust solver the quality of the solver is demonstrated on synthetic and real data 
there is a need to restore color image that suffer from distance dependent degradation during acquisition this occurs for example when imaging through scattering medium there signal attenuation worsens with the distance of an object from the camera a naive restoration may attempt to restore the image by amplifying the signal in each pixel according to the distance of it corresponding object this however would amplify the noise in a nonuniform manner moreover standard space invariant denoising over blur close by object which have low noise or insufficiently smoothes distant object which are very noisy we present a variational method to overcome this problem it us a regularization operator which is distance dependent in addition to being edge preserving and colorchannel coupled minimizing this functional result in a scheme of reconstruction while denoising it preserve important feature such a the texture of close by object and edge of distant one a restoration algorithm is presented for reconstructing color image taken through haze the algorithm also restores the path radiance which is equivalent to the distance map we demonstrate the approach experimentally 
subspace learning based face recognition method have attracted considerable interest in recently year including principal component analysis pca linear discriminant analysis lda locality preserving projection lpp neighborhood preserving embedding npe marginal fisher analysis mfa and local discriminant embedding lde these method consider an n timesn image a a vector in rn timesn and the pixel of each image are considered a independent while an image represented in the plane is intrinsically a matrix the pixel spatially close to each other may be correlated even though we have n xn pixel per image this spatial correlation suggests the real number of freedom is far le in this paper we introduce a regularized subspace learning model using a laplacian penalty to constrain the coefficient to be spatially smooth all these existing subspace learning algorithm can fit into this model and produce a spatially smooth subspace which is better for image representation than their original version recognition clustering and retrieval can be then performed in the image subspace experimental result on face recognition demonstrate the effectiveness of our method 
in this paper we investigate what can be inferred from several silhouette probability map in multi camera environment to this aim we propose a new framework for multi view silhouette cue fusion this framework us a space occupancy grid a a probabilistic d representation of scene content such a representation is of great interest for various computer vision application in perception or localization for instance our main contribution is to introduce the occupancy grid concept popular in the robotics community for multi camera environment the idea is to consider each camera pixel a a statistical occupancy sensor all pixel observation are then used jointly to infer where and how likely matter is present in the scene a our result illustrate this simple model ha various advantage most source of uncertainty are explicitly modeled and no premature decision about pixel labeling occur thus preserving pixel knowledge consequently optimal scene object localization and robust volume reconstruction can be achieved with no constraint on camera placement and object visibility in addition this representation allows to improve silhouette extraction in image 
since biometric data cannot be easily replaced or revoked it is important that biometric template used in biometric application should be constructed and stored in a secure way such that attacker would not be able to forge biometric data easily even when the template are compromised this is a challenging goal since biometric data are noisy by nature and the matching algorithm are often complex which make it difficult to apply traditional cryptographic technique especially when multiple modality are considered in this paper we consider a fusion of a minutia based fingerprint authentication scheme and an svd based face authentication scheme and show that by employing a recently proposed cryptographic primitive called secure sketch and a known geometric transformation on minutia we can make it easier to combine different modality and at the same time make it computationally infeasible to forge an original combination of fingerprint and face image that pass the authentication we evaluate the effectiveness of our scheme using real fingerprint and face image from publicly available source 
camera calibration with one dimensional object is based on an algebraic constraint on the image of the absolute conic we will give an alternative derivation to this constraint allowing a geometrical interpretation from this we derive the degenerate case or critical motion where the calibration algorithm will fail we also show that constraint on the intrinsic parameter lead to simplified closed form solution and a reduced set of critical motion a simulation and a real data experiment is performed to evaluate the accuracy of the calibration result for motion close to being critical 
the image of a curved specular mirror like surface is a distorted reflection of the environment the goal of our work is to develop a framework for recovering general shape from such distortion when the environment is neither calibrated nor known to achieve this goal we consider far field illumination where the object environment distance is relatively large and we examine the dense specular flow that is induced on the image plane through relative object environment motion we show that under these very practical condition the observed specular flow can be related to surface shape through a pair of coupled nonlinear partial differential equation importantly this relationship depends only on the environment s relative motion and not it content we examine the qualitative property of these equation present analytic method for recovery of the shape in several special case and empirically validate our result using captured data we also discus the relevance to both computer vision and human perception 
aligning a pair of blurred and non blurred image is a prerequisite for many image and video restoration and graphic application the traditional alignment method such a direct and feature based approach cannot be used due to the presence of motion blur in one image of the pair in this paper we present an effective and accurate alignment approach for a blurred non blurred image pair we exploit a statistical characteristic of the real blur kernel the marginal distribution of kernel value is sparse using this sparseness prior we can search the best alignment which produce the sparsest blur kernel the search is carried out in scale space with a coarse to fine strategy for efficiency finally we demonstrate the effectiveness of our algorithm for image deblurring video restoration and image matting 
a framework for the regularized estimation of nonuniform dimensionality and density in high dimensional data is introduced in this work this lead to learning stratification that is mixture of manifold representing different characteristic and complexity in the data set the basic idea relies on modeling the high dimensional sample point a a process of poisson mixture with regularizing restriction and spatial continuity constraint theoretical asymptotic result for the model are presented a well the presentation of the framework is complemented with artificial and real example showing the importance of regularized stratification learning in computer vision application 
recently more and more research focus on the concept extraction from unstructured video data to bridge the semantic gap between the low level feature and the high level video concept a mid level understanding of the video content i e salient object is detected based on the technique of image segmentation and machine learning specifically salient object detector are developed and tested on trecvid development video corpus in addition a boosting method is proposed to select the most representative feature to achieve a higher performance than only using single modality and lower complexity than taking all feature into account 
we present a novel method to reconstruct the d shape of a scene from several calibrated image our motivation is that most existing multi view stereovision approach require some knowledge of the scene extent and often even of it approximate geometry e g visual hull this make these approach mainly suited to compact object admitting a tight enclosing box imaged on a simple or a known background in contrast our approach focus on largescale cluttered scene under uncontrolled imaging condition it first generates a quasi dense d point cloud of the scene by matching keypoints across image in a lenient manner thus possibly retaining many false match then it build an adaptive tetrahedral decomposition of space by computing the d delaunay triangulation of the d point set finally it reconstructs the scene by labeling delaunay tetrahedron a empty or occupied thus generating a triangular mesh of the scene a globally optimal label assignment a regard photo consistency of the output mesh and compatibility with the visibility of keypoints in input image is efficiently found a a minimum cut solution in a graph 
multi body structure and motion msam is the problem to establish the multiple view geometry of an image sequence of a d scene where the scene consists of multiple rigid object moving relative to each other so far solution have been proposed for several restricted setting such a only two view affine projection and perspective projection of linearly moving point we give a solution for sequence of several image full perspective projection and general rigid motion it can deal with the fact that the set of correspondence change over time and is robust to outlier the proposed solution is based on monte carlo sampling and clustering of two view motion linking them through the sequence and model selection to yield the best explanation for the entire sequence 
to capture the full brightness range of natural scene camera automatically adjust the exposure value which cause the brightness of scene point to change from frame to frame given such a video sequence we introduce a new method for tracking feature and estimating the radiometric response function of the camera and the exposure difference between frame simultaneously we model the global and nonlinear process that is responsible for the change in image brightness rather than adapting to the change locally and linearly which make our tracking more robust to the change in brightness the radiometric response function and the exposure difference between frame are also estimated in the process which enables further video processing algorithm to deal with the varying brightness 
in recent year nonlinear dimensionality reduction nldr technique have attracted much attention in visual perception and many other area of science we propose an efficient algorithm called riemannian manifold learning rml a riemannian manifold can be constructed in the form of a simplicial complex and thus it intrinsic dimension can be reliably estimated then the nldr problem is solved by constructing riemannian normal coordinate rnc experimental result demonstrate that our algorithm can learn the data s intrinsic geometric structure yielding uniformly distributed and well organized low dimensional embedding data 
in this paper we introduce the skellam distribution a a sensor noise model for ccd or cmos camera this is derived from the poisson distribution of photon that determine the sensor response we show that the skellam distribution can be used to measure the intensity difference of pixel in the spatial domain a well a in the temporal domain in addition we show that skellam parameter are linearly related to the intensity of the pixel this property mean that the brighter pixel tolerate greater variation of intensity than the darker pixel this enables u to decide automatically whether two pixel have different color we apply this modeling to detect the edge in color image the resulting algorithm requires only a confidence interval for a hypothesis test because it us the distribution of image noise directly more importantly we demonstrate that without conventional gaussian smoothing the noise modelbased approach can automatically extract the fine detail of image structure such a edge and corner independent of camera setting 
most work in computer vision ha concentrated on studying the individual effect of motion and illumination on a d object in this paper we present a theory for combining the effect of motion illumination d structure albedo and camera parameter in a sequence of image obtained by a perspective camera we show that the set of all lambertian reflectance function of a moving object illuminated by arbitrarily distant light source lie close to a bilinear subspace consisting of nine illumination variable and six motion variable this result implies that given an arbitrary video sequence it is possible to recover the d structure motion and illumination condition simultaneously using the bilinear subspace formulation the derivation is based on the intuitive notion that given an illumination direction the image of a moving surface cannot change suddenly over a short time period we experimentally compare the image obtained using our theory with ground truth data and show that the difference is small and acceptable we also provide experimental result on real data by synthesizing video sequence of a d face with various combination of motion and illumination direction 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
virtually all structured light method assume that the scene and the source are immersed in pure air and that light is neither scattered nor absorbed recently however structured lighting ha found growing application in underwater and aerial imaging where scattering effect cannot be ignored in this paper we present a comprehensive analysis of two representative method light stripe range scanning and photometric stereo in the presence of scattering for both method we derive physical model for the appearance of a surface immersed in a scattering medium based on these model we present result on a the condition for object detectability in light striping and b the number of source required for photometric stereo in both case we demonstrate that while traditional method fail when scattering issignificant our method accurately recover the scene depth normal albedo a well a the property of the medium these result are in turn used to restore the appearance of scene a if they were captured in clear air although we have focused on light striping and photometric stereo our approach can also be extended to other method such a grid coding gated and active polarization imaging 
this paper proposes a novel model guided segmentation framework utilizing a statistical surface wavelet model a a shape prior in the model building process a set of training shape are decomposed through the subdivision surface wavelet scheme by interpreting the resultant wavelet coefficient a random variable we compute prior probability distribution of the wavelet coefficient to model the shape variation of the training set at different scale and spatial location with this statistical shape model the segmentation task is formulated a an optimization problem to best fit the statistical shape model with an input image due to the localization property of the wavelet shape representation both in scale and space this multi dimensional optimization problem can be efficiently solved in a multiscale and spatial localized manner we have applied our method to segment cerebral caudate nucleus from mri image the experimental result have been validated with segmentation obtained through human expert these show that our method is robust computationally efficient and achieves a high degree of segmentation accuracy 
in this paper we propose a novel approach for scene modeling the proposed method is able to automatically discover the intermediate semantic concept we utilize maximization of mutual information mmi co clustering approach to discover cluster of semantic concept which we call intermediate concept each intermediate concept corresponds to a cluster of visterms in the bag of visterms bov paradigm for scene classification mmi coclustering result in fewer but meaningful cluster unlike k mean which is used to cluster image patch based on their appearance in bov mmi co clustering can group the visterms which are highly correlated to some concept unlike probabilistic latent semantic analysis plsa which can be considered a one sided soft clustering mmi coclustering simultaneously cluster visterms and image so it is able to boost both clustering in addition the mmi coclustering is an unsupervised method we have extensively tested our proposed approach on two challenging datasets the fifteen scene category and the lscom dataset and promising result are obtained 
we present an algorithm and the associated capture methodology to acquire and track the detailed d shape bend and wrinkle of deforming surface moving d data ha been difficult to obtain by method that rely on known surface feature structured light or silhouette multi spectral photometric stereo is an attractive alternative becau se it can recover a dense normal field from an un textured surface we show how to capture such data and register it over time to generate a single deforming surface experiment were performed on video sequence of untextured cloth filmed under spatially separated red green and blue light source our first finding is that using zerodepth silhouette a the initial boundary condition alrea dy produce rather smoothly varying per frame reconstruction with high detail second when these d reconstruction are augmented with d optical flow one can register the first frame s reconstruction to every subsequent frame 
we develop a method for learning the spatial statistic of optical flow field from a novel training database training flow field are constructed using range image of natural scene and d camera motion recovered from hand held and car mounted video sequence a detailed analysis of optical flow statistic in natural scene is presented and machine learning method are developed to learn a markov random field model of optical flow the prior probability of a flow field is formulated a a field of expert model that capture the higher order spatial statistic in overlapping patch and is trained using contrastive divergence this new optical flow prior is compared with previous robust prior and is incorporated into a recent accurate algorithm for dense optical flow computation experiment with natural and synthetic sequence illustrate how the learned optical flow prior quantitatively improves flow accuracy and how it capture the rich spatial structure found in natural scene motion 
fitting parameterized d shape and general reflectance model to d image data is challenging due to the high dimensionality of the problem the proposed method combine the capability of classical and photometric stereo allowing for accurate reconstruction of both textured and non textured surface in particular we present a variational method implemented a a pde driven surface evolution interleaved with reflectance estimation the surface is represented on an adaptive mesh allowing topological change to provide the input data we have designed a capture setup that simultaneously acquires both viewpoint and light variation while minimizing self shadowing our capture method is feasible for real world application a it requires a moderate amount of input data and processing time in experiment model of people and everyday object were captured from a few dozen image taken with a consumer digital camera the capture process recovers a photo consistent model of spatially varying lambertian and specular reflectance and a highly accurate geometry 
in this work we develop appearance model for computing the similarity between image region containing deformable object of a given class in realtime we introduce the concept of shape and appearance context the main idea is to model the spatial distribution of the appearance relative to each of the object part estimating the model entail computing occurrence matrix we introduce a generalization of the integral image and integral histogram framework and prove that it can be used to dramatically speed up occurrence computation we demonstrate the ability of this framework to recognize an individual walking across a network of camera finally we show that the proposed approach outperforms several other method 
gait is an attractive biometric for vision based human identification previous work on existing public data set ha shown that shape cue yield improved recognition rate compared to pure motion cue however shape cue are fragile to gross appearance variation of an individual for example walking while carrying a ball or a backpack we introduce a novel spatiotemporal shape variation based frieze pattern svb frieze pattern representation for gait which capture motion information over time the svb frieze pattern represents normalized frame difference over gait cycle row column of the vertical horizontal svb frieze pattern contain motion variation information augmented by key frame information with body shape a temporal symmetry map of gait pattern is also constructed and combined with vertical horizontal svb frieze pattern for measuring the dissimilarity between gait sequence experimental result show that our algorithm improves gait recognition performance on sequence with and without gross difference in silhouette shape we demonstrate superior performance of this computational framework over previous algorithm using shape cue alone on both cmu mobo and uos humanid gait database in this paper we propose a new spatiotemporal pattern that represents gait shape variation information and the relation between temporally separated gait motion based on sequence of body silhouette our algorithm show robust and improved test result over previous algorithm using shape cue on test sequence containing significant change in an individual s body shape 
this paper summarizes a method for extracting d information and index of refraction from a scene by mean of a pair of polarimetric passive imaging sensor each sensor provides the stokes vector at each sensor pixel location from which degree and angle of linear polarization are computed angle of linear polarization provides the azimuth angle of the surface normal vector two case are considered for the special case when the two sensor have a common azimuth plane the index of refraction can be find analytically in term of the degree of polarization and the angle between the line of sight from the two sensor from which the depression angle of the surface normal can be computed for the second and more general case the surface normal is estimated from the cross product of the azimuth vector from the two sensor and the inner product of the line of sight vector and surface normal once the depresion angle are estimated the index of refraction can be computed result of the application of this approach on simulated infrared polarimetric data are provided 
model of activity structure for unconstrained environment are generally not available a priori recent representational approach to this end are limited by their computational complexity and ability to capture activity structure only up to some fixed temporal scale in this work we propose suffix tree a an activity representation to efficiently extract structure of activity by analyzing their constituent event subsequence over multiple temporal scale we empirically compare suffix tree with some of the previous approach in term of feature cardinality discriminative prowess noise sensitivity and activity class discovery finally exploiting property of suffix tree we present a novel perspective on anomalous subsequence of activity and propose an algorithm to detect them in linear time we present comparative result over experimental data collected from a kitchen environment to demonstrate the competence of our proposed framework 
a critical function in both machine vision and biological vision system is attentional selection of scene region worthy of further analysis by higher level process such a object recognition here we present the first model of spatial attention that can be applied to arbitrary static and dynamic image sequence with interactive task and combine a general computational implementation of both bottom up bu saliency and dynamic top down td task relevance the claimed novelty lie in the combination of these element and in the fully computational nature of the model the bu component computes a saliency map from low level multi scale visual feature the td component computes a low level signature of the entire image and learns to associate different class of signature with the different gaze pattern recorded from human subject performing a task of interest we measured the ability of this model to predict the eye movement of people playing contemporary video game we found that the td model alone predicts where human look about twice a well a doe the bu model alone in addition a combined bu td model performs significantly better than either individual component qualitatively the combined model predicts some easy to describe but hard to compute aspect of attentional selection such a shifting attention leftward when approaching a left turn along a racing track thus our study demonstrates the advantage of integrating bu factor derived from a saliency map and td factor learned from image and task context in predicting where human look while performing complex visually guided behavior 
the geometry of plane based calibration method is well understood but some user interaction is often needed in practice for feature detection this paper present a fully automatic calibration system that us pattern of pair of concentric circle the key observation is to introduce a geometric method that construct a sequence of point strictly convergent to the image of the circle center from an arbitrary point the method automatically detects the point of the pattern feature by the construction method and identify them by invariant it then take advantage of homological constraint to consistently and optimally estimate the feature in the image the experiment demonstrate the robustness and the accuracy of the new method 
most recent class level object recognition system work with visual word i e vector quantized local descriptor in this paper we examine the feasibility of a dataindependent approach to construct such a visual vocabulary where the feature space is discretized using a regular lattice using hashing technique only non empty bin are stored and fine grained grid become possible in spite of the high dimensionality of typical feature space based on this representation we can explore the structure of the feature space and obtain state of the art pixelwise classification result in the case of image classification we introduce a class specific feature selection step which take the spatial structure of sift like descriptor into account result are reported on the graz dataset 
we describe a novel variational segmentation algorithm designed to split an image in two region based on their intensity distribution a functional is proposed to integrate the unknown probability density function of both region within the optimization process the method simultaneously performs segmentation and non parametric density estimation it doe not make any assumption on the underlying distribution hence it is flexible and can be applied to a wide range of application although a boundary evolution scheme may be used to minimize the functional we choose to consider an alternative formulation with a membership function the latter ha the advantage of being convex in each variable so that the minimization is faster and le sensitive to initial condition finally to improve the accuracy and the robustness to low frequency artifact we present an extension for the more general case of local space varying probability density the approach readily extends to vectorial image and d volume and we show several result on synthetic and photographic image a well a on d medical data 
geometric reconstruction problem in computer vision are often solved by minimizing a cost function that combine the reprojection error in the d image in this paper we show that for various geometric reconstruction problem their reprojection error function share a common and quasiconvex formulation based on the quasiconvexity we present a novel quasiconvex optimization framework in which the geometric reconstruction problem are formulated a a small number of small scale convex program that are ready to solve our final reconstruction algorithm is simple and ha intuitive geometric interpretation in contrast to existing local minimization approach our algorithm is deterministic and guarantee a predefined accuracy of the minimization result the quasiconvexity also provides an intuitive method to handle directional uncertainty and outlier in measurement when there are outlier in the measurement our method provides a mechanism to locate the global minimum of a robust error function for large scale problem and when computational resource are constrained we provide an efficient approximation that give a good upper bound but not global minimum on the reconstruction error we demonstrate the effectiveness of our algorithm by experiment on both synthetic and real data 
we present an algorithm for performing lambertian photometric stereo in the presence of shadow the algorithm ha three novel feature first a fast graph cut based method is used to estimate per pixel light source visibility second it allows image to be acquired with multiple illuminant and there can be fewer image than light source this lead to better surface coverage and improves the reconstruction accuracy by enhancing the signal to noise ratio and the condition number of the light source matrix the ability to use fewer image than light source mean that the imaging effort grows sublinearly with the number of light source finally the recovered shadow map are combined with shading information to perform constrained surface normal integration this reduces the low frequency bias inherent to the normal integration process and ensures that the recovered surface is consistent with the shadowing configuration the algorithm work with a few a four light source and four image we report result for light source visibility detection and high quality surface reconstruction for synthetic and real datasets 
symmetry and self similarity is the cornerstone of nature exhibiting itself through the shape of natural creation and ubiquitous law of physic since many natural object are symmetric the absence of symmetry can often be an indication of some anomaly or abnormal behavior therefore detection of asymmetry is important in numerous practical application including crystallography medical imaging and face recognition to mention a few conversely the assumption of underlying shape symmetry can facilitate solution to many problem in shape reconstruction and analysis traditionally symmetry are described a extrinsic geometric property of the shape while being adequate for rigid shape such a description is inappropriate for non rigid one extrinsic symmetry can be broken a a result of shape deformation while it intrinsic symmetry is preserved in this paper we pose the problem of finding intrinsic symmetry of non rigid shape and propose an efficient method for their computation 
given any two image taken under different illumination condition there always exist a physically realizable object which is consistent with both the image even if the lighting ineachsceneisconstrainedto beaknownpointlightsource at infinity in this paper we show that image are much le ambiguous for the class of bilaterally symmetric lambertian object in fact the set of such object can be partitioned into equivalence class such that it is always possible to distinguish between two objectsbelongingto different equivalence class using just one image per object the condition required for two object to belong to the same equivalenceclass are very restrictive thereby leading to the conclusion that image of symmetric object are hardly ambiguous the observationleadsto an illumination invariant matching algorithm to compare image of bilaterally symmetric lambertian object experiment on real data are performed to show the implication of the theoretical result even when the symmetry and lambertian assumption are not strictly satisfied 
we address segmentation of an image into patch that have an underlying salient surface roughness three intrinsic image are derived reflectance shading and metatexture image a constructive approach is proposed for computing a meta texture image by preserving equalizing and enhancing the underlying surface roughness across color brightness and illumination variation we evaluate the performance on sample image and illustrate quantitatively that different patch of the same material in an image are normalized in their statistic despite variation in color brightness and illumination finally segmentation by line based boundary detection is proposed and result are provided and compared to known algorithm 
picture taken by a rotating camera cover the viewing sphere surrounding the center of rotation having a set of image registered and blended on the sphere what is left to be done in order to obtain a flat panorama is projecting the spherical image onto a picture plane this step is unfortunately not obvious the surface of the sphere may not be flattened onto a page without some form of distortion the objective of this paper is discussing the difficulty and opportunity that are connected to the projection from viewing sphere to image plane we first explore a number of alternative to the commonly used linear perspective projection these are global projection and do not depend on image content we then show that multiple projection may coexist successfully in the same mosaic these projection are chosen locally and depend on what is present in the picture we show that such multi view projection can produce more compelling result than the global projection 
in this paper we present a novel scaleand rotation invariant interest point detector and descriptor coined surf speeded up robust feature it approximates or even outperforms previously proposed scheme with respect to repeatability distinctiveness and robustness yet can be computed and compared much faster this is achieved by relying on integral image for image convolution by building on the strength of the leading existing detector and descriptor in casu using a hessian matrix based measure for the detector and a distribution based descriptor and by simplifying these method to the essential this lead to a combination of novel detection description and matching step the paper present experimental result on a standard evaluation set a well a on imagery obtained in the context of a real life object recognition application both show surf s strong performance 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper a new learning framework probabilistic boosting tree pbt is proposed for learning two class and multi class discriminative model in the learning stage the probabilistic boosting tree automatically construct a tree in which each node combine a number of weak classifier evidence knowledge into a strong classifier a conditional posterior probability it approach the target posterior distribution by data augmentation tree expansion through a divide and conquer strategy in the testing stage the conditional probability is computed at each tree node based on the learned classifier which guide the probability propagation in it sub tree the top node of the tree therefore output the overall posterior probability by integrating the probability gathered from it sub tree also clustering is naturally embedded in the learning phase and each sub tree represents a cluster of certain level the proposed framework is very general and it ha interesting connection to a number of existing method such a the a algorithm decision tree algorithm generative model and cascade approach in this paper we show the application of pbt for classification detection object recognition we have also applied the framework in segmentation 
we propose an efficient representation for studying shape of closed curve in rn this paper combine the strength of two important idea elastic shape metric and path straightening method and result in a very fast algorithm for finding geodesic in shape space the elastic metric allows for optimal matching of feature between the two curve while path straightening ensures that the algorithm result in geodesic path for the novel representation proposed here the elastic metric becomes the simple l metric in contrast to the past usage where more complex form were used we present the step by step algorithm for computing geodesic and demonstrate them with d a well a d example 
we present an algorithm for plane based self calibration of camera with radially symmetric distortion given a set of sparse feature match in at least two view the projection function of such camera can be seen a a projection with a pinhole camera followed by a non parametric displacement of the image point in the direction of the distortion center the displacement is a function of the point distance to the center thus the generated distortion is radially symmetric regular camera fish eye a well a the most popular central catadioptric device can be described by such a model our approach recovers a distortion function consistent with all the view or estimate one for each view if they are taken by different camera we consider a least square algebraic solution for computing the homography between two view that is valid for rectified undistorted point correspondence we observe that the term of the function are bilinear in the unknown of the homography and the distortion coefficient associated to each point our contribution is to approximate this non convex problem by a convex one to do so we replace the bilinear term by a set of new variable and obtain a linear least square problem we show that like the distortion coefficient these variable are subject to monotonicity constraint thus the approximate problem is a convex quadratic program we show that solving it is sufficient for accurately estimating the distortion parameter we validate our approach on simulated data a well a on fish eye and catadioptric camera we also compare our solution to three state of the art algorithm and show similar performance 
multi chamber heart segmentation is a prerequisite for global quantification of the cardiac function the complexity of cardiac anatomy poor contrast noise or motion artifact make this segmentation problem a challenging task in this paper we present an efficient robust and fully automatic segmentation method for d cardiac computed tomography ct volume our approach is based on recent advance in learning discriminative object model and we exploit a large database of annotated ct volume we formulate the segmentation a a two step learning problem anatomical structure localization and boundary delineation a novel algorithm marginal space learning msl is introduced to solve the dimensional similarity search problem for localizing the heart chamber msl reduces the number of testing hypothesis by about six order of magnitude we also propose to use steerable image feature which incorporate the orientation and scale information into the distribution of sampling point thus avoiding the time consuming volume data rotation operation after determining the similarity transformation of the heart chamber we estimate the d shape through learning based boundary delineation extensive experiment on multi chamber heart segmentation demonstrate the efficiency and robustness of the proposed approach comparing favorably to the state of the art this is the first study reporting stable result on a large cardiac ct dataset with volume in addition we achieve a speed of le than eight second for automatic segmentation of all four chamber 
we seek to discover the object category depicted in a set of unlabelled image we achieve this using a model developed in the statistical text literature probabilistic latent semantic analysis plsa in text analysis this is used to discover topic in a corpus using the bag of word document representation here we treat object category a topic so that an image containing instance of several category is modeled a a mixture of topic the model is applied to image by using a visual analogue of a word formed by vector quantizing sift like region descriptor the topic discovery approach successfully translates to the visual domain for a small set of object we show that both the object category and their approximate spatial layout are found without supervision performance of this unsupervised method is compared to the supervised approach of fergus et al on a set of unseen image containing only one object per image we also extend the bag of word vocabulary to include doublet which encode spatially local co occurring region it is demonstrated that this extended vocabulary give a cleaner image segmentation finally theclassification and segmentation method are applied to a set of image containing multiple object per image these result demonstrate that we can successfully build object class model from an unsupervised analysis of image 
learning model for detecting and classifying object category is a challenging problem in machine vision while discriminative approach to learning and classification have in principle superior performance generative approach provide many useful feature one of which is the ability to naturally establish explicit correspondence between model component and scene feature this in turn allows for the handling of missing data and unsupervised learning in clutter we explore a hybrid generative discriminativeapproach using fisher kernel which retains most of the desirable property of generative method while increasing the classification performance through a discriminative setting furthermore we demonstrate how this kernel framework can be used to combine different type of feature and model into a single classifier our experiment conducted on a number of popular benchmark show strong performance improvement over the corresponding generative approach and are competitive with the best result reported in the literature 
in the short time since publication of boykov and jolly s seminal paper graph cut have become well established a a leading method in d and d semi automated image segmentation although this approach is computationally feasible for many task the memory overhead and supralinear time complexity of leading algorithm result in an excessive computational burden for high resolution data in this paper we introduce a multilevel banded heuristic for computation of graph cut that is motivated by the well known narrow band algorithm in level set computation we perform a number of numerical experiment to show that this heuristic drastically reduces both the running time and the memory consumption of graph cut while producing nearly the same segmentation result a the conventional graph cut additionally we are able to characterize the type of segmentation target for which our multilevel banded heuristic will yield different result from the conventional graph cut the proposed method ha been applied to both d and d image with promising result 
manifold learning method are promising data analysis tool however if we locate a new test sample on the manifold we have to find it embedding by making use of the learned embedded representation of the training sample this process often involves accessing considerable volume of data for large sample set in this paper an approach of selecting landmark point from the given sample is proposed for hierarchical structuring of data on manifold th e selection is made such that if one use the voronoi diagram generated by the landmark point in the ambient space to partition the embeded manifold the topology of the manifold is preserved the landmark point then are used to recursively construct a hierarchical structure of the data thus it can speed up query in a manifold data set it is a general framework that can fit any manifold learning algorithm a long a it result of an input can be predicted by the result of the neighbor input compared to the existing technique of organizing data based on spatial partitionin g our method preserve the topology of the latent space of the data different from manifold learning algorithm that use landmark point to reduce complexity our approach is designed for fast retrieval of sample it may find it way in high dimensional data analysis such a indexing clusterin g and progressive compression more importantly it extends the manifold learning method to application in which they were previously considered to be not fast enough our algorithm is stable and fast and it validity is proved mathematically 
we introduce a novel topological formulation for contour grouping our grouping criterion called untangling cycle exploit the inherent topological d structure of salient contour to extract them from the otherwise d image clutter to define a measure for topological classification robust to clutter and broken edge we use a graph formulation instead of the standard computational topology the key insight is that a pronounced id contour should have a clear ordering of edge to which all graph edge adhere and no long range entanglement persist finding the contour grouping by optimizing these topological criterion is challenging we introduce a novel concept of circular embedding to encode this combinatorial task our solution lead to computing the dominant complex eigenvectors eigenvalue of the random walk matrix of the contour grouping graph we demonstrate major improvement over state of the art approach on challenging real image 
we suggest a variational method for the joint estimation of optic flow and the segmentation of the image into region of similar motion it make use of the level set framework following the idea of motion competition which is extended to non parametric motion moreover we automatically determine an appropriate initialization and the number of region by mean of recursive two phase split with higher order region model the method is further extended to the spatiotemporal setting and the use of additional cue like the gray value or color for the segmentation it need not fear a quantitative comparison to pure optic flow estimation technique for the popular yosemite sequence with cloud we obtain the currently most accurate result we further uncover a mistake in the ground truth coarsely correcting this we get an average angular error below degree 
many problem in computer vision require the knowledge of potential point correspondence between two image the usual approach for automatically determining correspondence begin by comparing small neighborhood of high saliency in both image since speed is of the essence most current approach for local region matching involve the computation of a feature vector that is invariant to various geometric and photometric transformation followed by fast distance computation using standard vector norm these algorithm include many parameter and choosing an algorithm and setting it parameter for a given problem is more an art than a science furthermore although invariance of the resulting feature space is in general desirable there is necessarily a tradeoff between invariance and descriptiveness for any given task in this paper we pose local region matching a a classification problem and use powerful machine learning technique to train a classifier that selects feature from a much larger pool our algorithm can be trained on specific domain or task and performs better than the state of the art in such case since our method is an application of boosting we refer to it a boosted region matching boom 
temporal segmentation of facial gesture in spontaneous facial behavior recorded in real world setting is an important unsolved and relatively unexplored problem in facial image analysis several issue contribute to the challenge of this task these include non frontal pose moderate to large out of plane head motion large variability in the temporal scale of facial gesture and the exponential nature of possible facial action combination to address these challenge we propose a two step approach to temporally segment facial behavior the first step us spectral graph technique to cluster shape and appearance feature invariant to some geometric transformation the second step group the cluster into temporally coherent facial gesture we evaluated this method in facial behavior recorded during face toface interaction the video data were originally collected to answer substantive question in psychology without concern for algorithm development the method achieved moderate convergent validity with manual facs facial action coding system annotation further when used to preprocess video for manual facs annotation the method significantly improves productivity thus addressing the need for ground truth data for facial image analysis moreover we were also able to detect unusual facial behavior 
in this paper a projection model is presented for camera moving at constant velocity which we refer to a galilean camera to that end we introduce the concept of spacetime projection and show that perspective imaging and linear pushbroom imaging are specialization of the proposed model the epipolar geometry between two such camera is developed and we derive the galilean fundamental matrix we show how six different fundamental matrix can be directly recovered from the galilean fundamental matrix including the classic fundamental matrix the linear pushbroom lp fundamental matrix and a fundamental matrix relating epipolar plane image epi to estimate the parameter of this fundamental matrix and the mapping between video in the case of planar scene we describe linear algorithm and report experimental performance of these algorithm 
the watershed partition of an image often result in oversegmentation this well known phenomenon is due to variation of intensity that do not correspond to object boundary and produce spurious local minimum in the image gradient magnitude filtering minimum or merging watershed region is then necessary to obtain a higher level description of the data in this paper we propose new solution to this problem by applying two interactive multilabel partitioning technique to the adjacency graph of the watershed region in our first approach the partition is derived from the probability that a random walker starting at an arbitrary node first reach a node with a pre assigned label in the second approach we compute a geodesic partition of the graph using competing wavefront starting at prescribed node both method are based on existing segmentation technique previously implemented on image lattice using a watershed adjacency graph greatly reduces their memory footprint and computational cost we demonstrate the practicality and versatility of this approach with several experiment on d and d datasets 
the problem of motion estimation and restoration of object in a blurred video sequence is addressed in this paper fast movement of the object together with the aperture time of the camera result in a motion blurred image the direct velocity estimation from this blurred video is inaccurate on the other hand an accurate estimation of the velocity of the moving object is critical for restoration of motion blurred video therefore restoration need accurate motion estimation and vice versa and a joint process is called for to address this problem we derive a novel model of the blurring process and propose a mumford shah type of variational framework acting on consecutive frame for joint object deblurring and velocity estimation the proposed procedure distinguishes between the moving object and the background and is accurate also close to the boundary of the moving object experimental result both on simulated and real data show the importance of this joint estimation and it superior performance when compared to the independent estimation of motion and restoration 
the goal of deconvolution is to recover an image x from it convolution with a known blurring function this is equivalent to inverting the linear system y hx in this paper we consider the generalized problem where the system matrix h is an arbitrary non negative matrix linear inverse problem can be solved by adding a regularization term to impose spatial smoothness to avoid oversmoothing the regularization term must preserve discontinuity this result in a particularly challenging energy minimization problem where h is diagonal a occurs in image denoising the energy function can be solved by technique such a graph cut which have proven to be very effective for problem in early vision when h is non diagonal however the data cost for a pixel to have a intensity depends on the hypothesized intensity of nearby pixel so existing graph cut method cannot be applied this paper show how to use graph cut to obtain a discontinuity preserving solution to a linear inverse system with an arbitrary non negative system matrix we use a dynamically chosen approximation to the energy which can be minimized by graph cut minimizing this approximation also decrease the original energy experimental result are shown for mri reconstruction from fourier data 
face annotation technology is important for a photo management system in this paper we propose a novel interactive face annotation framework combining unsupervised and interactive learning there are two main contribution in our framework in the unsupervised stage a partial clustering algorithm is proposed to find the most evident cluster instead of grouping all instance into cluster which lead to a good initial labeling for later user interaction in the interactive stage an efficient labeling procedure based on minimization of both global system uncertainty and estimated number of user operation is proposed to reduce user interaction a much a possible experimental result show that the proposed annotation framework can significantly reduce the face annotation workload and is superior to existing solution in the literature 
in this note we propose a method to perform segmentation on the tensor manifold that is the space of positive definite matrix of given dimension in this work we explicitly use the riemannian structure of the tensor space in designing our algorithm this structure ha already been utilized in severalapproachesbased on active contourmodelswhichseparatethemeanand orvarianceinsideandoutside the evolving contour we generalize these method by proposing a new technique for performing segmentation by separating the entire probabilitydistributions of the region insideandoutsidethecontourusingthebhattacharyyametric in particular this allows for segmenting object with multimodal probability distribution on the space of tensor we demonstrate the effectiveness of our algorithm by segmenting various textured image using the structure tensor a level set based scheme is proposed to implement the curve flow evolution equation 
abstract kernel method have been widely studied in the field of pattern recognition these method implicitly map the kernel trick the data into a space which is more appropriate for analysis many manifold learning and dimensionality reduction technique are simply kernel method for which the mapping is explicitly computed in such case two problem related with the mapping arise the out ofsample extension and the pre image computation in this paper we propose a new pre image method based on the nystr om formulation for the out of sample extension showing the connection between both problem we also address the importance of normalization in the feature space which ha been ignored by standard pre image algorithm a an example we apply these idea to the gaussian kernel and relate our approach to other popular pre image method finally we show the application of these technique in the study of dynamic shape 
one of the key problem of restoring a degraded image from motion blur is the estimation of the unknown shiftinvariant linear blur filter several algorithm have been proposed utilizing image intensity or gradient information in this paper we separate the image deblurring into filter estimation and image deconvolution process and propose a novel algorithm to estimate the motion blur filter from a perspective of alpha value the relationship between the object boundary transparency and the image motion blur is investigated we formulate the filter estimation a solving a maximum a posteriori map problem with the defined likelihood and prior on transparency our unified approach can be applied to handling both the camera motion blur and the object motion blur 
we consider clustering situation in which the pairwise affinity between data point depends on a latent context variable for example when clustering feature arising from multiple object class the affinity value between two image feature depends on the object class that generated those feature we show that clustering in the context of a latent variable can be represented a a special d hypergraph and introduce an algorithm for obtaining the cluster we use the latent clustering model for an unsupervised multiple object class recognition where feature fragment are shared among multiple cluster and those in turn are shared among multiple object class 
we present an approach for measuring similarity between visual entity image or video based on matching internal self similarity what is correlated across image or across video sequence is the internal layout of local self similarity up to some distortion even though the pattern generating those local self similarity are quite different in each of the image video these internal self similarity are efficiently captured by a compact local self similarity descriptor measured densely throughout the image video at multiple scale while accounting for local and global geometric distortion this give rise to matching capability of complex visual data including detection of object in real cluttered image using only rough hand sketch handling textured object with no clear boundary and detecting complex action in cluttered video data with no prior learning we compare our measure to commonly used image based and video based similarity measure and demonstrate it applicability to object detection retrieval and action detection 
we consider the problem of predicting a sequence of real valued multivariate state from a given measurement sequence it typical application in computer vision is the task of motion estimation state space model are widely used generative probabilistic model for the problem instead of jointly modeling state and measurement we propose a novel discriminative undirected graphical model which condition the state on the measurement while exploiting the sequential structure of the problem the major benefit of this approach are it focus on the ultimate prediction task while avoiding probably unnecessary effort in modeling the measurement density it relaxes generative model assumption that the measurement are independent given the state and the proposed inference algorithm take linear time in the measurement dimension a opposed to the cubic time for kalman filtering which allows u to incorporate large number of measurement feature we show that the parameter learning can be cast a an instance of convex optimization we also provide efficient convex optimization method based on theorem from linear algebra the performance of the proposed model is evaluated on both synthetic data and the human body pose estimation from silhouette video 
we present an approach for illumination and affineinvariant point matching using ordinal feature ordinal measure for matching only consider the order between pixel and not the absolute intensity value which enables them to be invariant to a monotonic change in intensity the utility of such measure ha been demonstrated in the past for point matching for some application such a background subtraction and stereo matching however invariance of such method to geometric transformation ha been limited leading to their inapplicability for more generic matching application such a object recognition wide baseline stereo matching mosaicing or tracking point on moving object in this paper we extend such method for use in such application the method is invariant to an affine transformation in the patch which make it applicable to a variety of application at the same time our method is robust to different type of noise process possible in a real scene experiment indicate favorable performance when compared to other state of the art method for affine invariant point matching 
the problem of using picture of object captured under ideal imaging condition here referred to a in vitro to recognize object in natural environment in situ is an emerging area of interest in computer vision and pattern recognition example of task in this vein include assistive vision system for the blind and object recognition for mobile robot the proliferation of image database on the web is bound to lead to more example in the near future despite it importance there is still a need for a freely available database to facilitate study of this kind of training testing dichotomy in this work one of our contribution is a new multimedia database of grocery product grozi for every product two different recording are available in vitro image extracted from the web and in situ image extracted from camcorder video collected inside a grocery store a an additional contribution we present the result of applying three commonly used object recognition detection algorithm color histogram matching sift matching and boosted haar like feature to the dataset finally we analyze the success and failure of these algorithm against product type and imaging condition both in term of recognition rate and localization accuracy in order to suggest way forward for further research in this domain 
recent research in visual inference from monocular image ha shown that discriminatively trained image based predictorscan provide fast automaticqualitative d reconstruction of human body pose or scene structure in realworld environment however the stability of existing image representation tends to be perturbed by deformation and misalignment in the training set which in turn degrade the quality of learning and generalization in this paper we advocate the semi supervised learning of hierarchical image description in order to better tolerate variability at multiple level of detail we combine multilevel encoding with improved stability to geometric transformation with metric learning and semi supervised manifold regularization method in order to further profile them for taskinvariance resistance to background clutter and within the same human pose class difference we quantitatively analyze the effectiveness of both descriptor and learning method and show that each one can contribute sometimes substantially to more reliable d human pose estimate in cluttered image 
this paper considers an application of scale invariant feature detection using scale space analysis suitable for use with wide field of view camera rather than obtain scalespace image via convolution with the gaussian function on the image plane we map the image to the sphere and obtain scale space image a the solution to the heat diffusion equation on the sphere which is implemented in the frequency domain using spherical harmonic the percentage correlation of scale invariant feature that may be matched between any two wide angle image subject to change in camera pose is then compared using each of these method we also present a mean by which the required sampling bandwidth may be determined and propose a suitable anti aliasing filter which may be used when this bandwidth exceeds the maximum permissible due to computational requirement the result show improved performance using scale space image obtained a the solution of the diffusion equation on the sphere with additional improvement observed using the anti aliasing filter 
in this study we present a y feature extraction method for registering color and fluorescein angiogram of the retina the registration of multimodal fluorescein imagery requires the identification of strong geometric feature in the retinal image that are invariant across modality and to temporal grey level variation due to the propagation of the dye in the vessel the most informative feature invariant across the considered modality are the location of vessel ramification the so called y feature we propose a y feature extraction method based on the local classification of image gradient information and an articulated model an appropriate cost function is proposed for fitting the model using a gradient based approach the fitted y feature are subsequently matched across the image for registering the color and fluorescein image experimental result obtained on a large database validate the proposed method 
in this paper we propose and evaluate an algorithm that learns a similarity measure for comparing never seen object the measure is learned from pair of training image labeled same or different this is far le informative than the commonly used individual image label e g car model x but it is cheaper to obtain the proposed algorithm learns the characteristic difference between local descriptor sampled from pair of same and different image these difference are vector quantized by an ensemble of extremely randomized binary tree and the similarity measure is computed from the quantized difference the extremely randomized tree are fast to learn robust due to the redundant information they carry and they have been proved to be very good clusterers furthermore the tree efciently combine different feature type sift and geometry we evaluate our innovative similarity measure on four very different datasets and consistantly outperform the state of the art competitive approach 
this paper proposes a novel approach to constructing a hierarchical representation of visual input that aim to enable recognition and detection of a large number of object category inspired by the principle of efficient indexing bottom up robust matching top down and idea of compositionality our approach learns a hierarchy of spatially flexible composition i e part in an unsupervised statistic driven manner starting with simple frequent feature we learn the statistically most significant composition part composed of part which consequently define the next layer part are learned sequentially layer after layer optimally adjusting to the visual data lower layer are learned in a category independent way to obtain complex yet sharable visual building block which is a crucial step towards a scalable representation higher layer of the hierarchy on the other hand are constructed by using specific category achieving a category representation with a small number of highly generalizable part that gained their structural flexibility through composition within the hierarchy built in this way new category can be efficiently and continuously added to the system by adding a small number of part only in the higher layer the approach is demonstrated on a large collection of image and a variety of object category detection result confirm the effectiveness and robustness of the learned part 
dimensionality reduction is an important issue when facing high dimensional data for supervised dimensionality reduction linear discriminant analysis lda is one of the most popular method and ha been successfully applied in many classification problem however there are several drawback in lda first it suffers from the singularity problem which make it hard to preform second lda ha the distribution assumption which may make it fail in application where the distribution is more complex than gaussian third lda can not determine the optimal dimensionality for discriminant analysis which is an important issue but ha often been neglected previously in this paper we propose a new algorithm and endeavor to solve all these three problem furthermore we present that our method can be extended to the two dimensional case in which the optimal dimensionality of the two projection matrix can be determined simultaneously experimental result show that our method are effective and demonstrate much higher performance in comparison to lda 
automated video surveillance application require accurate separation of foreground and background image content cost sensitive embedded platform place realtime performance and efficiency demand on technique to accomplish this task in this paper we evaluate pixel level foreground extraction technique for a low cost integrated surveillance system we introduce a new adaptive technique multimodal mean mm which balance accuracy performance and efficiency to meet embedded system requirement our evaluation compare several pixel level foreground extraction technique in term of their computation and storage requirement and functional accuracy for three representative video sequence the proposed mm algorithm delivers comparable accuracy of the best alternative mixture of gaussians with a x improvement in execution time and an reduction in required storage 
most previous motion deblurring method restore the degraded image assuming a shift invariant linear blur filter these method are not applicable if the blur is caused by spatially variant motion in this paper we model the physical property of a d rigid body movement and propose a practical framework to deblur rotational motion from a single image our main observation is that the transparency cue of a blurred object which represents the motion blur formation from an imaging perspective provides sufficient information in determining the object movement comparatively single image motion deblurring using pixel color gradient information ha large uncertainty in motion representation and computation our result are produced by minimizing a new energy function combining rotation possible translation and the transparency map using an iterative optimizing process the effectiveness of our method is demonstrated using challenging image example 
visual tracking is a very important front end to many vision application we present a new framework for robust visual tracking in this paper instead of just looking forward in the time domain we incorporate both forward and backward processing of video frame using a novel time reversibility constraint this lead to a new minimization criterion that combine the forward and backward similarity function and the distance of the state vector between the forward and backward state of the tracker the new framework reduces the possibility of the tracker getting stuck in local minimum and significantly improves the tracking robustness and accuracy our approach is general enough to be incorporated into most of the current tracking algorithm we illustrate the improvement due to the proposed approach for the popular klt tracker and a search based tracker the experimental result show that the improved klt tracker significantly outperforms the original klt tracker the time reversibility constraint used for tracking can be incorporated to improve the performance of optical flow mean shift tracking and other algorithm 
we propose an operational method to extract the left ventricle lv systole dynamic using harmonic phase harp image extracted from tagged cardiac mr sequence established technique to generate harp sequence provide independent evidence for motion extraction in the sense that the combined linear system for scalar brightness conservation applied to the harp image can be uniquely solved for a dense field of motion parameter without the need for regularization in contrast to some of the previously proposed popular method no segmentation or tracking of tag over time nor interpolation of a sparse motion field explicitly coupled to the tag pattern is required and the problem of tag fading is bypassed an important novelty is the incorporation of automatic local scale selection so a to obtain a robust solution which not only yield a stable but also a smoothly varying motion field of the healthy lv myocardial wall the scheme relies on an integer parameter representing order of approximation and allows one to simultaneously obtain a dense field of differential tensor capturing the low order differential structure of the motion field which is useful for the computation of relevant local quantity such a strain rate and material acceleration field 
when deploying a heterogeneous camera network or when we use cheap zoom camera like in cell phone it is not practical if not impossible to off line calibrate the radial distortion of each camera using reference object it is rather desirable to have an automatic procedure without strong assumption about the scene in this paper we present a new algorithm for estimating the epipolar geometry of two view where the two view can be radially distorted with different distortion factor it is the first algorithm in the literature solving the case of different distortion in the left and right view linearly and without assuming the existence of line in the scene point in the projective plane are lifted to a quadric in three dimensional projective space a radial distortion of the projective plane result to a matrix transformation in the space of lifted coordinate the new epipolar constraint depends linearly on a x radial fundamental matrix which ha degree of freedom a complete algorithm is presented and tested on real imagery 
in this paper we investigatedetection and localization of general d object class by relating local scale invariant feature to a viewpoint invariant reference frame this can generally be achievedby either a multi view representation where feature and reference frame are modeled a a collection of distinct view or by a viewpoint invariant representation where feature and reference frame are modeled independently of viewpoint we compare multi view and viewpoint invariant representation trained and tested on the same data where the viewpoint invariant approach result in fewer false positive detection and higher average precision we present a new iterative learning algorithm to determine an optimalviewpoint invariantreference frame from training image in a data driven manner the learned optimal reference frame is centrally located with respect to the d object class and to image feature in a given view thereby minimizing reference frame localization error a predicted by theory and maintaining a consistent geometrical interpretation with respect to the underlying object class modeling and detection based on the optimal reference frame improves detection performance for both multiview and viewpoint invariant representation experimentation is performed on the class of d face using the public color feret database for training the cmu profile database for testing and sift image feature 
abstract this work focus on a general framework for image categorization classification and retrieval that may be appro priate for medical image archive the proposed methodology is comprised of a continuous and probabilistic image representation scheme using gaussian mixture modeling mog along with information theoretic image matching measure kl a category model is obtained by learning a reduced model from all the image in the category we propose a novel algorithm for learning a reduced representation of a mog that is based on the unscented transform the superiority of the proposed method is validated on both simulation experiment and categorization of a real medica l image database 
in this paper we propose to use lexical semantic network to extend the state of the art object recognition technique we use the semantics of image label to integrate prior knowledge about inter class relationship into the visual appearance learning we show how to build and train a semantic hierarchy of discriminative classifier and how to use it to perform object detection we evaluate how our approach influence the classification accuracy and speed on the pascal voc challenge dataset a set of challenging real world image we also demonstrate additional feature that become available to object recognition due to the extension with semantic inference toolswe can classify high level category such a animal and we can train part detector for example a window detector by pure inference in the semantic network 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we introduce an algorithm for a non negative d tensor factorization for the purpose of establishing a local part feature decomposition from an object class of image in the past such a decomposition wa obtained using non negative matrix factorization nmf where image were vectorized before being factored by nmf a tensor factorization ntf on the other hand preserve the d representation of image and provides a unique factorization unlike nmf which is not unique the resulting factor from the ntf factorization are both sparse like with nmf but also separable allowing efficient convolution with the test image result show a superior decomposition to what an nmf can provide on all front degree of sparsity lack of ghost residue due to invariant part and efficiency of coding of around an order of magnitude better experiment on using the local part decomposition for face detection using svm and adaboost classifier demonstrate that the recovered feature are discriminatory and highly effective for classification 
in this paper we present a new mathematical framework for modeling texture image using independent basic gray level aura matrix bglams we prove that independent bglams are the basis of gray level aura matrix glams and that an image can be uniquely represented by it independent bglams we propose a new bglam distance measure for automatically evaluating synthesis result w r t input texture to determine if the output is a successful synthesis of the input for the application to texture synthesis we present a new algorithm to synthesize texture by sampling only the independent bglams of an input texture with respect to synthesis of texture and evaluation of the result the performance of our approach is extensively evaluated and compared with symmetric glams that are used in existing technique and with gray level cooccurrence matrix glcms experimental result have shown that our approach significantly outperforms both symmetric glams and glcms the new bglam distance measure ha the ability to evaluate synthesis result which can be used to automate the conventional visual inspection process for determining whether or not the output texture is a successful synthesis of the input and a broad range of texture can be faithfully synthesized using independent bglams and the synthesis result are comparable to existing technique 
we present a novel level set method for evolvingopen surface embedded in three dimensional volume we adapt the method for statistical detection and segmentation of cy toarchitectonic region of the cortical ribbon e g brodmann area in addition we incorporate an explicit interface appearance model which is oriented normal to the open surface allowing one to model characteristic beyond voxel intensity and high gradient we show that such model are well suited to detecting embedded cortical struc tures appearance model of the interface are used in two way firstly to evolve an open surface in the normal direction for the purpose of detecting the location of the surface and secondly to evolve the boundary of the surface in a direction tangential to the surface in order to delineate the e xtent of a specific brodmann area within the cortical ribbon the utility of the method is demonstrated on a challenging ex vivo structural mr dataset for detection of brodmann area 
several important problem in computer vision such a shape from shading sfs and photometric stereo p require reconstructing a surface from an estimated gradient field which is usually non integrable i e have non zero curl we propose a purely algebraic approach to enforce integrability in discrete domain we first show that enforcing integrability can be formulated a solving a single linear system ax b over the image in general this system is under determined we show condition under which the system can be solved and a method to get to those condition based on graph theory the proposed approach is non iterative ha the important property of local errorconfinement and can be applied to several problem result on sfs and p demonstrate the applicability of our method 
camera network are being used in more application a different type of sensor network are used to instrument large space here we show a method for localizing the camera in a camera network to recover the orientation and position up to scale of each camera even when camera are wide baseline or have different photometric property using moving object in the scene we use an intra camera step and an inter camera step in order to localize the intra camera step compare frame from a single camera to build the track of the object in the image plane of the camera the inter camera step us these object image track from each camera a feature for correspondence between camera we demonstrate this idea on both simulated and real data 
in this paper we propose a novel approach for foreground layer extraction using flash no flash image pair which we call flash cut flash cut is based on the simple observation that only the foreground is significantly brightened by the flash and the background appearance change is very small if the background is distant change due to flash motion and color information are fused in an mrf framework to produce high quality segmentation result flash cut handle some amount of camera shake and foreground motion which make it practical for anyone with a flash equipped camera to use we validate our approach on a variety of indoor and outdoor example 
this paper present a restoration framework for correcting both photometric and geometric distortion in camerabased image of non planar shaped document to facilitate human perception and machine recognition the photometric distortion usually perceived a shading artifact are corrected by separating the shading image from the reflectance image through digital inpainting and surface fitting technique meanwhile the extracted shading image is also used to recover the document s surface shape through a shape from shading sfs method with a generic formulation of the image irradiance under arbitrary illumination condition the recovered surface shape is then employed to correct the geometric distortion through a physicallybased flattening process result on real document image demonstrate the performance of each sub task and the functionality of the whole framework ocr result on restored image also show great improvement over the original distorted image 
a joint segmentation is a simultaneous segmentation of registered d image and d point reconstructed from the multiple view image it is fundamental in structuring the data for subsequent modeling application in this paper we treat this joint segmentation a a weighted graph labeling problem first we construct a d graph for the joint d and d point using a joint similarity measure then we propose a hierarchical sparse affinity propagation algorithm to automatically and jointly segment d image and group d point third a semi supervised affinity propagation algorithm is proposed to refine the automatic result with the user assistance finally intensive experiment demonstrate the effectiveness of the proposed approach 
we address the problem of reconstructing the d shape of a lambertian surface from multiple image acquired a an object rotates under distant and possibly varying illumination using camera projection matrix estimated from point correspondence across view the algorithm computes a dense correspondence map by minimizing a multi ocular photometric constraint once correspondence across view is established photometric stereo is applied to estimate a surface normal field and d surface conceptually the algorithm merges multi view stereo and photometric stereo and us aspect of both method to recover shape the method is straightforward to implement and relies on established principle from the two stereo method we empirically validate the method on image of a number of object and show that it outperforms previous method 
this paper present a novel motion segmentation algorithm on the basis of mixture of dirichlet process mdp model a kind of nonparametric bayesian framework in contrast to previous approach our method consider motion segmentation and it model selection regarding to the number of motion model a an indivisible problem the proposed algorithm can simultaneously infer the number of motion model estimate the cluster membership of correspondence point and identify the outlier of input data the keyidea is to use mdp modelsto fully exploit the epipolarconstraintsbeforemakingprematuredecisionsaboutthe number motion model to handle outlier efficiently we then incorporate ransac within the inference process of mdp model and make them take the advantage of each other in the experiment we compare the proposed algorithm with naive ransac gpca and schindler s method on both synthetic data and real image data the experimental result show that we can handle more motion and still have satisfactory performance in the presence of various level of noise and outlier 
automatic video surveillance in uncontrolled outdoor setting is a very challenging computer vision task nearly infinite variability of the environmental factor and the open ended goal of many surveillance problem conspire to create situation where even the most advanced detection tracking and recognition algorithm falter while the common academic response to such challenge is to develop new more powerful algorithm capable of handling a broader range of condition with acceptable performance this course of action is sometimes not appropriate from the industrial commercial point of view sometimes system must be deployed sooner than would allow for the development cycle of complex new algorithm and must be more robust than most such algorithm can be expected to be on short notice under those circumstance one may look toward better data quality a one mean of improving performance while remaining close to the existing state of the art in algorithmic technology this is often the motivation for deployment of multimodal surveillance system in the real 
in this paper we propose a novel metric learning method based on regularized moving least square unlike most previous metric learning method which learn a global mahalanobis distance we define locally smooth metric using local affine transformation which are more flexible the data set after metric learning can preserve the original topological structure moreover our method is fairly efficient and may be used a a preprocessing step for various subsequent learning task including classification clustering and nonlinear dimensionality reduction in particular we demonstrate that our method can boost the performance of content based image retrieval cbir task experimental result provide empirical evidence for the effectiveness of our approach 
lighting variation is commonly handled by method invariant to additive and multiplicative change in image intensity it ha been demonstrated that comparing image using the direction of the gradient can produce broader insensitivity to change in lighting condition even for d scene we analyze two common approach to image comparison that are invariant normalized correlation using small correlation window and comparison based on a large set of oriented difference of gaussian filter we show analytically that these method calculate a monotonic cosine function of the gradient direction difference and hence are equivalent to the direction of gradient method our analysis is supported with experiment on both synthetic and real scene 
it is well known that how to extract dynamical feature is a key issue for video based face analysis in this paper we present a novel approach of facial action unit au and expression recognition based on coded dynamical feature in order to capture the dynamical characteristic of facial event we design the dynamical haar like feature to represent the temporal variation of facial event inspired by the binary pattern coding we further encode the dynamic haar like feature into binary pattern feature which are useful to construct weak classifier for boosting learning finally the adaboost is performed to learn a set of discriminating coded dynamic feature for facial active unit and expression recognition experiment on the cmu expression database and our own facial au database show it encouraging performance 
much of the research on video based human motioncapture assumes the body shape is known a priori and is represented coarsely e g using cylinder or superquadrics to model limb these body model stand in sharp contrast to the richly detailed d body model used by the graphic community here we propose a method for recovering such model directly from image specifically we represent the body using a recently proposed triangulated mesh model called scape which employ a low dimensional but detailed parametric model of shape and pose dependent deformationsthatis learned from a databaseof rangescans of human body previous work showed that the parameter of the scape model could be estimated from marker based motion capture data here we go further to estimate the parameter directlyfrom imagedata wedefine a cost function between image observation and a hypothesized mesh and formulate the problem a optimization over the body shape and pose parameter using stochastic search our result show that such rich generative modelsenable the automatic recovery of detailed human shape and pose from image 
the seminal work of hubel and wiesel and the vast amount of work that followed it prove that hierarchy of increasingly complex cell play a central role in cortical computation computational model pioneered by fukushima suggest that these hierarchy contain feature building cell s cell and pooling cell ccells more recently riesenhuber poggio have developed the hmax model in which s cell perform linear combination while c cell perform a max operation we note that method for computing the connectivity of s cell abound since many algorithm for suggesting informative linear combination exist there are however only few published method that are suitable for the construction of c cell here we build a novel dimensionality reduction algorithm for learning the connectivity of c cell using the framework of the max plus tropical semiring 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present an algorithm hierarchical isometric self organizing map h isosom for a concise organized manifold representation of complex non linear large scale high dimensional input data in a low dimensional space the main contribution of our algorithm is threefold first we modify the previous isosom algorithm by a local linear interpolation lll technique which map the data sample from low dimensional space back to high dimensional space and make the complete mapping pseudo invertible the modified isosom m isosom follows the global geometric structure of the data and also preserve local geometric relation to reduce the nonlinear mapping distortion and make the learning more accurate second we propose the h isosom algorithm for the computational complexity problem of isomap som and lli and the nonlinear complexity problem of the highly twisted manifold h isosom learns an organized structure of a non convex large scale manifold and represents it by a set of hierarchical organized map the hierarchical structure follows a coarse to fine strategy according to the coarse global structure it unfolds the manifold at the coarse level and decomposes the sample data into small patch then iteratively learns the nonlinearity of each patch in finer level the algorithm simultaneously reorganizes and cluster the data sample in a low dimensional space to obtain the concise representation third we give quantitative comparison of the proposed method with similar method on standard data set finally we apply h isosom to the problem of appearance based hand pose estimation encouraging experimental result validate the effectiveness and efficiency of h isosom 
the appearance of a scene is a function of the scene content the lighting and the camera pose a set of n pixel image of a non degenerate scene captured from different perspective lie on a d nonlinear manifold in rn in general this nonlinear manifold is complicated and numerous sample are required to learn it globally in this paper we present a novel method and some preliminary result for incrementally tracking camera motion through sampling and linearizing the local appearance manifold at each frame time we use a cluster of calibrated and synchronized small baseline camera to capture scene appearance sample at different camera pose we compute a first order approximation of the appearance manifold around the current camera pose then a new cluster sample are captured at the next frame time we estimate the incremental camera motion using a linear solver by using intensity measurement and directly sampling the appearance manifold our method avoids the commonly used feature extraction and matching process and doe not require d correspondence across frame thus it can be used for scene with complicated surface material geometry and view dependent appearance property situation where many other camera tracking method would fail 
we present a general approach for the hierarchical segmentation and labeling of document layout structure this approach model document layout a a grammar and performs a global search for the optimal parse based on a grammatical cost function our contribution is to utilize machine learning to discriminatively select feature and set all parameter in the parsing process therefore and unlike many other approach for layout analysis ours can easily adapt itself to a variety of document analysis problem one need only specify the page grammar and provide a set of correctly labeled page we apply this technique to two document image analysis task page layout structure extraction and mathematical expression interpretation experiment demonstrate that the learned grammar can be used to extract the document structure in file from the uwiii document image database we also show that the same framework can be used to automatically interpret printed mathematical expression so a to recreate the original latex 
we present algorithm for estimating the epipole or direction of translation of a moving camera we use constraint arising from two point that are antipodal on the image sphere in order to decouple rotation from translation one pair of antipodal point constrains the epipole to lie on a plane and two such pair will correspondingly give two plane the intersection of these two plane is an estimate of the epipole this mean we require image motion measurement at two pair of antipodal point to obtain an estimate two class of algorithm are possible and we present two simple yet extremely robust algorithm representative of each class these are shown to have comparable accuracy with the state of the art when tested in simulation under noise and with real image sequence 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
effective image prior is necessary for image super resolution due to it severely under determined nature although the edge smoothness prior can be effective it is generally difficult to have analytical form to evaluate the edge smoothness especially for soft edge that exhibit gradual intensity transition this paper find the connection between the soft edge smoothness and a soft cut metric on an image grid by generalizing the geocuts method and prof that the soft edge smoothness measure approximates the average length of all level line in an intensity image this new finding not only lead to an analytical characterization of the soft edge smoothness prior but also give an intuitive geometric explanation regularizing the super resolution problem by this new form of prior can simultaneously minimize the length of all level line and thus resulting in visually appealing result in addition this paper present a novel combination of this soft edge smoothness priorandthe alphamattingtechniqueforcolorimage super resolution by normalizing edge segment with their alpha channel description to achieve a unified treatment of edge with different contrast and scale 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
a general methodology for noise reduction and contrast enhancement in very noisy image data with low dynamic range is presented video footage recorded in very dim light is especiallytargeted smoothingkernels that automatically adapt to the local spatio temporal intensity structure in the image sequence are constructed in order to preserve and enhancefine spatial detail and prevent motion blur in color image data the chromaticity is restored and demosaicing of raw rgb input data is performed simultaneously with the noise reduction the method is very general contains few user defined parameter and ha been developed for efficient parallel computation using a gpu the technique ha been applied to image sequence with various degree of darkness and noise level and result from some of these test andcomparisonsto other method are presented the presentwork ha beeninspired by researchon vision in nocturnal animal particularly the spatial and temporal visual summation that allows these animal to see in dim light 
in this paper we introduce the concept of intrinsic illumination subspace which is based on the intrinsic image this intrinsic illumination subspace enables an analytic generation of the illumination image under varying lighting condition when object of the same class are concerned our method allows a class based generic intrinsic illumination subspace to be constructed in advance we propose a lighting normalization method based on the generic intrinsic illumination subspace which is used a a bootstrap subspace for novel image face recognition experiment are performed to demonstrate the effectiveness of our method 
in this paper we take the human age and pose estimation problem a example to study automatic designing regressor from training sample with uncertain nonnegative label first the nonnegative label is predicted a the square norm of a matrix which is bilinearly transformed from the nonlinear mapping of the candidate kernel two transformation matrix are then learned for deriving such a matrix by solving a semi definite programming sdp problem in which the uncertain label of each sample is expressed a two inequality constraint the objective function of sdp control the rank of these two matrix and consequently automatically determines the structure of the regressor the whole framework for automatic designing regressor from sample with uncertain nonnegative label ha the following characteristic sdp formulation make full use of the uncertain label instead of using conventional fixed label regression with matrix norm naturally guarantee the nonnegativity of the label and greater prediction capability is achieved by integrating the square of the matrix element which act a weak regressors and the regressor structure is automatically determined by the pursuit of simplicity which potentially promotes the algorithmic generalization capability extensive experiment on two human age database fg net and yamaha a well a the pointing pose database demonstrate encouraging estimation accuracy improvement over conventional regression algorithm 
we present a new post processing step to enhance the resolution of range image using one or two registered and potentially high resolution color image a reference we iteratively refine the input low resolution range image in term of both it spatial resolution and depth precision evaluation using the middlebury benchmark show across the board improvement for sub pixel accuracy we also demonstrated it effectiveness for spatial resolution enhancement up to with a single reference image 
this paper address the problem of camera pose recovery from spherical image the d information is extracted from a set of panorama sparsely distributed over a scene of interest we present an algorithm to recover the position of omni directional camera in a scene using pair wise essential matrix first all rotation with respect to the world frame are found using an incremental bundle adjustment procedure thus achieving what we called cube alignment the structure of the scene is then computed using a full bundle adjustment during this step the previously computed panorama orientation used to feed the global optimization process are further refined result are shown for indoor and outdoor panorama set 
measuring system performance seems conceptually straightforward however the interpretation of the result and predicting future performance remain a exceptional challenge in system evaluation robust experimental design is critical in evaluation but there have been very few technique to check design for either overlooked association or weak assumption for biometric vision system evaluation the complexity of the system make a thorough exploration of the problem space impossible this lack of verifiability in experimental design is a serious issue in this paper we present a new evaluation methodology that improves the accuracy of variance estimator via the discovery of false assumption about the homogeneity of cofactor i e when the data is not well mixed the new methodology is then applied in the context of a biometric system evaluation with highly influential cofactor 
in order to obtain optimal d structure and viewing parameter estimate bundle adjustment is often used a the last step of feature based structure and motion estimation algorithm bundle adjustment involves the formulation of a large scale yet sparse minimization problem which is traditionally solved using a sparse variant of the levenbergmarquardt optimization algorithm that avoids storing and operating on zero entry this paper argues that considerable computational benefit can be gained by substituting the sparse levenberg marquardt algorithm in the implementation of bundle adjustment with a sparse variant of powell s dog leg non linear least square technique detailed comparative experimental result provide strong evidence supporting this claim 
over the past decade tremendous amount of research activity ha focused around the problem of localization in gps denied environment challenge with localization are highlighted in human wearable system where the operator can freely move through both indoors and outdoors in this paper we present a robust method that address these challenge using a human wearable system with two pair of backward and forward looking stereo camera together with an inertial measurement unit imu this algorithm can run in real time with hz update rate on a dual core ghz laptop pc and it is designed to be a highly accurate local relative pose estimation mechanism acting a the front end to a simultaneous localization and mapping slam type method capable of global correction through landmark matching extensive test of our prototype system so far reveal that without any global landmark matching we achieve between and accuracy in localizing a person over a meter travel indoors and outdoors to our knowledge such performance result with a real time system have not been reported before 
this paper proposes a method to match diffusion tensor magnetic resonance image dt mri through the large deformation diffeomorphic metric mapping of vector field focusing on the fiber orientation considered a unit vector field on the image volume we study a suitable action of diffeomorphisms on such vector field and provide an extension of the large deformation diffeomorphic metric mapping framework to this type of dataset resulting in optimizing for geodesic on the space of diffeomorphisms connecting two image two different distance function of vector field are considered existence of the minimizers under smoothness assumption on the compared vector field is proved and coarse to fine hierarchical strategy are detailed to reduce both ambiguity and computation load this is illustrated by numerical experiment on dt mri heart and brain image 
we present an approach for object recognition that combine detection and segmentation within a efficient hypothesize test framework scanning window template classifier are the current state of the art for many object class such a face car and pedestrian such approach though quite successful can be hindered by their lack of explicit encoding of object shape structure one might for example find face in tree we adopt the following strategy we first use these system a attention mechanism generating many possible object location by tuning them for low missed detection and high false positive at each hypothesized detection we compute a local figure ground segmentation using a window of slightly larger extent than that used by the classifier this segmentation task is guided by top down knowledge we learn offline from training data those segmentation that are consistent with true positive we then prune away those hypothesis with bad segmentation we show this strategy lead to significant improvement over established approach such a violajones and dalaltriggs on a variety of benchmark datasets including the pascal challenge labelme and the inriaperson dataset 
markov random field or mrf model are a powerful tool for modeling image while much progress ha been made in algorithm for inference in mrfs learning the parameter of an mrf is still a challenging problem in this paper we show how variational optimization can be used to learn the parameter of an mrf this method for learning which we refer to a variational mode learning find the mrf parameter by minimizing a loss function that penalizes the difference between ground truth image and an approximate variational solution to the mrf in particular we focus on learning parameter for the field of expert model of roth and black in addition to demonstrating the effectiveness of this method we show that a model based on derivative filter performs quite similarly to the field of expert model this suggests that the field of expert model which is difficult to interpret can be understood a imposing piecewise continuity on the image 
we propose non linear generative model referred to a sparse spectral latent variable model slvm that combine the advantage of spectral embeddings with the one of parametric latent variable model provide stable latent space that preserve global or local geometric property of the modeled data offer low dimensional generative model with probabilistic bi directional map ping between latent and ambient space are probabilistically consistent i e reflect the data distribution both jointly and marginally and efficient to learn and use we show that slvms compare favorably with competing method based on pca gplvm or gtm for the reconstruction of typical human motion like walking running pantomime or dancing in a benchmark dataset empirically we observe that slvms are effective for theautomatic d reconstruction of low dimensional human motion in movie 
this paper present a new incremental learning solution for linear discriminant analysis lda we apply the concept of the sufficient spanning set approximation in each update step i e for the between class scatter matrix the pr ojected data matrix a well a the total scatter matrix the algorithm yield a more general and efficient solution to incremental lda than previous method it also significantly reduces the computational complexity while providing a solution which closely agrees with the batch lda result the proposed algorithm ha a time complexity ofo nd and requires o nd space whered is the reduced subspace dimension and n the data dimension we show two application of incremental lda first the method is applied to semi supervised learning by integrating it into an em framework secondly we apply it to the task of merging large database which were collected during mpeg standardization for face image retrieval 
the goal of this paper is to present a weighted likelihood discriminant for minimum error shape classification different from traditional maximum likelihood ml method in which classification is based on probability from independent individual class model a is the case for general hidden markov model hmm method proposed method utilizes information from all class to minimize classification error the proposed approach us a hmm for shape curvature a it d shape descriptor in this contribution we introduce a weighted likelihood discriminant function and present a minimum error classification strategy based on generalized probabilistic descent gpd method we believe our sound theory based implementation reduces classification error by combining hmm with gpd theory we show comparative result obtained with our approach and classic ml classification alongwith fourier descriptor and zernike moment based classification for fighter plane and vehicle shape 
texture flow estimation is a valuable step in a variety of vision related task including texture analysis image segmentation shape from texture and texture remapping this paper describes a novel and effective technique to estimate texture flow in an image given a small example patch the key idea consists of extracting a dense set of feature from the example patch where discrete orientation are encapsulated into the feature vector such that rotation can be simulated a a linear shift of the vector this dense feature space is then compressed by pca and clustered using em to produce a set of small set of principal feature obtaining these principal feature at varying image scale we can compute the per pixel scale and orientation likelihood for the distorted texture the final texture flow estimation is formulated a the map solution of a labeling markov network which is solved using belief propagation experimental result on both synthetic and real image demonstrate good result even for highly distorted example 
we present a markov random field model for image binary segmentation that computes the probability that each pixel belongs to a given class we show that the computation of a real valued field ha noticeable computational and performance advantage with respect to the computation of binary valued field the proposed energy function is efficiently minimized with standard fast linear order algorithm a conjugate gradient or multigrid gauss seidel scheme by providing a good initial guess a starting point we avoid to construct from scratch a new solution accelerating the computational process and allow u to naturally implement efficient multigrid algorithm for application with limited computational time a good partial solution can be obtained by stopping the iteration even if the global optimum is not yet reached we present a meticulous comparison with state of the art method graph cut random walker and gmmf the algorithm performance are compared using a cross validation procedure and an automatic algorithm for learning the parameter set 
configuration of dense locally parallel d curve occur in medical imaging computer vision and graphic example include white matter fibre tract texture fur and hair we develop a differential geometric characterization of such structure by considering the local behaviour of the associated d frame field leading to the associated tangential normal and bi normal curvature function using result from the theory of generalized minimal surface we adopt a generalized helicoid model a an osculating object and develop the connection between it parameter and these curvature function these development allow for the construction of parametrized d vectorfields sampled osculating object to locally approximate these pattern we apply these result to the analysis of diffusion mri data via a type of d streamline flow experimental result on data from a human brain demonstrate the advantage of incorporating the full differential geometry 
the paper introduces a new framework for feature learning in classification motivated by information theory we first systematically study the information structure and present a novel perspective revealing the two key factor in information utilization class relevance and redundancy we derive a new information decomposition model where a novel concept called class relevant redundancy is introduced subsequently a new algorithm called conditional informative feature extraction is formulated which maximizes the joint class relevant information by explicitly reducing the class relevant redundancy among feature to address the computational difficulty in information based optimization we incorporate parzen window estimation into the discrete approximation of the objective function and propose a local active region method which substantially increase the optimization efficiency to effectively utilize the extracted feature set we propose a bayesian map formulation for feature fusion which unifies laplacian sparse prior and multivariate logistic regression to learn a fusion rule with good generalization capability realizing the inefficiency caused by separate treatment of the extraction stage and the fusion stage we further develop an improved design of the framework to coordinate the two stage by introducing a feedback from the fusion stage to the extraction stage which significantly enhances the learning efficiency the result of the comparative experiment show remarkable improvement achieved by our framework 
many problem in vision involve the prediction of a class label for each frame in an unsegmented sequence in this paper we develop a discriminative framework for simultaneous sequence segmentation and labeling which can capture both intrinsic and extrinsic class dynamic our approach incorporates hidden state variable which model the sub structure of a class sequence and learn dynamic between class label each class label ha a disjoint set of associated hidden state which enables efficient training and inference in our model we evaluated our method on the task of recognizing human gesture from unsegmented video stream and performed experiment on three different datasets of head and eye gesture our result demonstrate that our model compare favorably to support vector machine hidden markov model and conditional random field on visual gesture recognition task 
this paper proposes a novel matching method for realtime finding the correspondence among different image containing the same object the method utilizes an efficient kernel projection scheme to descript the image patch around a detected feature point in order to achieve invariance and tolerance to geometric distortion it combine a training stage based on generated synthetic view of the object the two reliable and efficient method cooperate together resulting the core part of our novel multiple view kernel projection method mvkp finally considering the property and distribution of the described feature vector we search for the best correspondence between two set of feature using a fast filtering vector approximation ffva algorithm which can be viewed a a fast lower bound rejection scheme extensive experimental result on both synthetic and real data have demonstrated the effectiveness of the proposed approach 
abstract the endovascular repair of a traumatic rupture of the thoracic aorta that would otherwise lead to the death of the patient is performed by delivering a stent graft into the vessel at the rupture location the age range of the affected patient is large and the stent graft will stay in the body for the remaining life the technique is relatively new and no experience with regard to long term effect and durability exists to predict long term complication such a rupture or destructive interaction with surrounding tissue during the life of the patient it is important to understand the rather intense and constant movement of the stentgraft during the cardiac cycle a computed tomography with heart gating gated ct acquires sequence that show the region of the stent graft at different time point we analyze the motion of stent graft with a model based approach stent graft are represented a sparse set of axis point extracted from the gated ct and motion pattern are captured by a minimum description length based group wise registration of the stent graft at different time point no parameterization or a priori definition of the topology is necessary and highly variable elasticity property in the data volume can by accounted for by the sparse statistical model that capture correlation and motion component of the stent graft we report result for deformation model 
we present a fully automated method for real time and marker free d human motion capture the system computes the d shape of the person filmed from a synchronized camera set we obtain a robust and real time system by using both a fast d shape analysis and a skin segmentation algorithm for human tracking a skeleton based approach facilitates the shape analysis we are able to track fast and complex human motion in very difficult case like self occlusion result on long video sequence with rapid and complex movement demonstrate our approach robustness 
abstract this paper address human activity recognition based on a new feature descriptor for a binary human silhouette an extended radon transform transform is employed to represent low level feature the advantage of the transform lie in it low computational complexity and geometric invariance then a set of hmms based on the extracted feature are trained to recognize activity compared with other commonly used feature descriptor transform is robust to frame loss in video disjoint silhouette and hole in the shape and thus achieves better performance in recognizing similar activity rich experiment have proved the efficiency of the proposed method 
linear discriminant analysis lda is a popular feature extraction technique in face recognition however it often suffers from the small sample size problem when dealing with the high dimensional data moreover while lda is guaranteed to find the best direction when each class ha a gaussian density with a common covariance matrix it can fail if the class density are more general in this paper a new nonparametric linear feature extraction method stepwise nonparametric margin maximum criterion snmmc is proposed to find the most discriminant direction which doe not assume that the class density belong to any particular parametric family and doe not depend on the nonsingularity of the within class scatter matrix neither on three datasets from att and feret face database our experimental result demonstrate that snmmc outperforms other method and is robust to variation of pose illumination and expression 
we propose a new approach to deal with the first and second order statistic of a set of image these statistic take into account the image characteristic deformation and their variation in intensity the central algorithm is based on non supervised diffeomorphic image matching without landmark or human intervention a they convey the notion of the mean shape and color of an object and the one of it common variation such statistic of set of image may be relevant in the context of object recognition both in the segmentation of any of it representation and in the classification of them the proposed approach ha been tested on a small database of face image to compute a mean face and second order statistic the result are very encouraging since wheras the algorithm doe not need any human intervention and is not specific to face image database the mean image look like a real face and the characteristic mode of variation deformation and intensity change are sensible 
we propose a pixel similarity based algorithm enabling accurate rigid registration between single and multimodal image presenting gross dissimilarity due to noise missing data or outlying measure the method relies on the partitioning of a reference image by a student s t mixture model smm this partition is then projected onto the image to be registered the main idea is that a t component in the reference image corresponds to a t component in the image to be registered if the image are correctly registered the weighted sum of distance between the corresponding component is minimized the use of smm component is justified by the property that they have heavier tail than standard gaussians thus providing robustness to outlier experimental result indicate that even in the case of image presenting low snr or important amount of dissimilarity due to temporal change the proposed algorithm compare favorably to the histogram based mutual information method that is widely used in a variety of application 
training a cascade based face detector using boosting and haar feature is computationally expensive often requiring week on single cpu machine the bottleneck is at training and selecting haar feature for a single weak classifier currently in minute traditional technique for training a weak classifier usually run in nt log n with n example approximately and t feature approximately we present a method to train a weak classifier in time nd t where d is the number of pixel of the probed image sub window usually from to by using only the statistic of the weighted input data experimental result revealed a significantly reduced training time of a weak classifier to the order of second in particular this method suffers very minimal immerse in training time with very large increase in member of haar feature enjoying a significant gain in accuracy even with reduced training time 
this paper address the problem of markerless tracking of a human in full d with a high dimensional d body model most work in this area ha been focused on achieving accurate tracking in order to replace marker based motion capture but do so at the cost of relying on relatively clean observing condition this paper take a different perspective proposing a body tracking model that is explicitly designed to handle real world condition such a occlusion by scene object failure recovery long term tracking auto initialisation generalisation to different people and integration with action recognition to achieve these goal an action s motion are modelled with a variant of the hierarchical hidden markov model the model is quantitatively evaluated with several test including comparison to the annealed particle filter tracking different people and tracking with a reduced resolution and frame rate 
many computer vision algorithm limit their performance by ignoring the underlying d geometric structure in the image we show that we can estimate the coarse geometric property of a scene by learning appearance based model of geometric class even in cluttered natural scene geometric class describe the d orientation of an image region with respect to the camera we provide a multiple hypothesis framework for robustly estimating scene structure from a single image and obtaining confidence for each geometric label these confidence can then be used to improve the performance of many other application we provide a thorough quantitative evaluation of our algorithm on a set of outdoor image and demonstrate it usefulness in two application object detection and automatic single view reconstruction 
we present a systematic procedure for selecting facial fiducial point associated with diverse structural characteristic of a human face we identify such characteristic from the existing literature on anthropometric facial proportion we also present three dimensional d face recognition algorithm which employ euclidean geodesic distance between these anthropometric fiducial point a feature along with linear discriminant analysis classifier furthermore we show that in our algorithm when anthropometric distance are replaced by distance between arbitrary regularly spaced facial point their performance decrease substantially this demonstrates that incorporating domain specific knowledge about the structural diversity of human face significantly improves the performance of d human face recognition algorithm 
we address the problem of learning object class model and object segmentation from unannotated image we introduce locus learning object class with unsupervised segmentation which us a generative probabilistic model to combine bottom up cue of color and edge with top down cue of shape and pose a key aspect of this model is that the object appearance is allowed to vary from image to image allowing for significant within class variation by iteratively updating the belief in the object s position size segmentation and pose locus avoids making hard decision about any of these quantity and so allows for each to be refined at any stage we show that locus successfully learns an object class model from unlabeled image whilst also giving segmentation accuracy that rival existing supervised method finally we demonstrate simultaneous recognition and segmentation in novel image using the learned model for a number of object class a well a unsupervised object discovery and tracking in video 
recognizing and localizing specular or mirror like surface from a single image is a great challenge to computer vision unlike other material the appearance of a specular surface change a function of the surrounding environment a well a the position of the observer even though the reflection on a specular surface ha an intrinsic ambiguity that might be resolved by high level reasoning we argue that we can take advantage of low level feature to recognize specular surface this intuition stem from the observation that the surrounding scene is highly distorted when reflected off region of high curvature or occluding contour we call these feature static specular flow ssf we show how to characterize ssf and use them for identifying specular surface to evaluate our result we collect a dataset of image containing specular surface our algorithm can achieve good performance on this challenging dataset particularly our result outperform other method that follow a more naive approach 
in this paper we investigate linear discriminant analysis lda method for multiclass classification problem in hyperspectral imaging we note that lda doe not consider pairwise relation between different class it rather assumes equal within and between class scatter matrix a a result we present a pairwise discriminant analysis algorithm for learning class category our pairwise linear discriminant analysis measure the separability of two class making use of the class centroid and variance our approach is based upon a novel cost function with unitary constraint based on the aggregation of pairwise cost for binary class we view the minimisation of this cost function a an unconstrained optimisation problem over a grassmann manifold and solve using a projected gradient method our approach doe not require matrix inversion operation and therefore doe not suffer of stability problem for small training set we demonstrate the utility of our algorithm for purpose of learning material catergories in hyperspectral image 
this paper present a simplified framework for the simultaneous treatment of missing data and motion in degraded video sequence using simple translational model of motion a joint solution for the detection and reconstruction of missing data is proposed the framework also incorporates the notion of dealing with occlusion and uncovering a it pertains to picture building the idea is to use mcmc to solve the resulting problem articulated under a bayesian framework but to deploy purely deterministic mechanism for dealing with the solution this result in a relatively fast implementation that unifies many of the pixelby pixel scheme previously described in the literature the novel contribution of this paper are i a new framework for incorporating occlusion jointly with missing data and motion ii a practical approach to the deployment of mcmcfor video manipulation 
recent approach to action classification in video have used sparse spatio temporal word encoding local appearance around interesting movement most of these approach use a histogram representation discarding the temporal order among feature but this ordering information can contain important information about the action itself e g consider the sport discipline of hurdle race and long jump where the global temporal order of motion running jumping is important to discriminate between the two in this work we propose to use a sequential representation which retains this temporal order further we introduce discriminative subsequence mining to find optimal discriminative subsequence pattern in combination with the lpboost classifier this amount to simultaneously learning a classification function and performing feature selection in the space of all possible feature sequence the resulting classifier linearly combine a small number of interpretable decision function each checking for the presence of a single discriminative pattern the classifier is benchmarked on the kth action classification data set and outperforms the best known result in the literature 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
abstract theoretical understanding and extension of mean shift procedure ha received much attention recently in this paper we present a theoretical exploration and an algorithm development on mean shift in the theory part we point out that convex profile based mean shift can be justified from the viewpoint of half quadratic hq optimization such analysis facilitates the convergence study and uni mode bandwidth selection for the latest variation annealed mean shift in the algorithm development part of this paper we extend annealed mean shift inside our hq framework to a novel method namely adaptive mean shift ada m to detect multiple data mode sequentially from an arbitrary starting point in linear running time to validate the performance we couple the investigation with two application image segmentation and color constancy extensive experiment show that the proposed method is time efficient and initialization invariant 
we boost the efficiency and robustness of distributionbased matching by random subsampling which result in the minimum number of sample required to achieve a specified probability that a candidate sampling distribution is a good approximation to the model distribution the improvement is demonstrated with application to object detection mean shift tracking using color distribution and tracking with improved robustness for low resolution video sequence the problem of minimizing the number of sample required for robust distribution matching is formulated a a constrained optimization problem with the specified probability a the objective function we show that surprisingly mean shift tracking using our method requires very few sample our experiment demonstrate that robust tracking can be achieved with even a few a random sample from the distribution of the target candidate this lead to a considerably reduced computational complexity that is also independent of object size we show that random subsampling speed up tracking by two order of magnitude for typical object size 
state of the art stereo vision algorithm utilize color change a important cue for object boundary most method impose heuristic restriction or prior on disparity for example by modulating local smoothness cost with intensity gradient in this paper we seek to replace such heuristic with explicit probabilistic model of disparity and intensity learned from real image we have constructed a large number of stereo datasets with ground truth disparity and we use a subset of these datasets to learn the parameter of conditional random field crfs we present experimental result illustrating the potential of our approach for automatically learning the parameter of model with richer structure than standard hand tuned mrf model 
this paper describes a novel hand based verification system based on palm finger segmentation and fusion the proposed system operates on d hand image acquired by placing the hand on a planar lighting table without any guidance peg the segmentation of the palm and the finger is performed without requiring the extraction of any landmark point on the hand first the hand is segmented from the forearm using a robust iterative methodology based on morphological operator then the hand is segmented into six region corresponding to the palm and the finger using morphological operator again the geometry of each component of the hand is represented using high order zernike moment which are computed using an efficient methodology finally verification is performed by fusing information from different part of the hand the proposed system ha been evaluated on a database of subject illustrating high accuracy and robustness comparison with competitive approach that use the whole hand illustrate the superiority of the proposed component based approach both in term of accuracy and robustness qualitative comparison with state of the art system illustrate that the proposed system ha comparable or better performance 
this paper introduces a method for building a readable image of an opaque rolled or folded text from a volumetric penetrating scan the problem is framed by localizing constructing and manipulating an image induced by a surface embedded in a d voxel space there are two central contribution that lead to the demonstrated result first is an energy based texture formation algorithm which is a function of voxel intensity and the geometry of the embedded surface second is a regularization algorithm based on a constrained mapping of the embedded surface to a regularized image plane the mapping preserve angle and length which minimizes the distortion of text in the image the experimental result show readable image derived from custom high resolution x ray based ct scan of rolled papyrus and ink sample these method are significant for scholar seeking to study inaccessible text and may lead to viable technique for scanning everyday opaque object book without opening them 
in this paper we propose a general framework to solve the articulated shape matching problem formulated a finding point to point correspondence between two shape represented by d or d point cloud the original pointsets are embedded in a spectral representation and the actual matching is carried out in the embedded space we analyze the advantage of this choice a well a the reason for which the task remains a difficult one in particular we show that although embedded space matching still ha intrinsic combinatorial difficulty it can be solved by searching for an optimal orthogonal transformation that aligns the two shape embeddings relying on the model based clustering formalism we propose a probabilistic formulation which cast the matching into an em algorithm outlier are properly handled by the algorithm and a simple strategy is adopted to initialize it experiment are performed with three embedding method isomap lle and laplacian embedding and with d voxelsets representing a human motion sequence 
the goal of this work is to recover human bodyconfigurations from static image without assuming a priori knowledge of scale pose or appearance this problem is extremely challenging and demand the use of all possible source of information we develop a framework which can incorporate arbitrary pairwise constraint between body part such a scale compatibility relative position symmetry of clothing and smooth contour connection between part we detect candidate body part from bottom up using parallelism and use various pairwise configuration constraint to assemble them together into body configuration to find the most probable configuration we solve an integer quadratic programming problem with a standard technique using linear approximation approximate iqp allows u to incorporate much more information than the traditional dynamic programming and remains computationally efficient hand labeled image are used to train the low level part detector and learn the pairwise constraint we show test result on a variety of image 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we propose a novel method for computing a fourdimensional d representation of the spatio temporal visual hull of a dynamic scene based on an extension of a recent provably correct delaunay meshing algorithm by considering time a an additional dimension our approach exploit seamlessly the time coherence between different frame to produce a compact and high quality d mesh representation of the visual hull the d visual hull at a given time instant is easily obtained by intersecting this d mesh with a temporal plane thus enabling interpolation of object shape between consecutive frame in addition our approach offer easy and extensive control over the size and quality of the output mesh a well a over it associated reprojection error our numerical experiment demonstrate the effectiveness and flexibility of our approach for generating compact high quality time coherent visual hull representation from real silhouette image data 
we present a practical stratified autocalibration algorithm with theoretical guarantee of global optimality given a projective reconstruction the first stage of the algorithm upgrade it to affine by estimating the position of the plane at infinity the plane at infinity is computed by globally minimizing a least square formulation of the modulus constraint in the second stage the algorithm upgrade this affine reconstruction to a metric one by globally minimizing the infinite homography relation to compute the dual image of the absolute conic diac the positive semidefiniteness of the diac is explicitly enforced a part of the optimization process rather than a a post processing step for each stage we construct and minimize tight convex relaxation of the highly non convex objective function in a branch and bound optimization framework we exploit the problem structure to restrict the search space for the diac and the plane at infinity to a small fixed number of branching dimension independent of the number of view the convex relaxation technique presented here are general enough that we expect them to be of use to computer vision researcher solving optimization problem in multiview geometry and elsewhere experimental evidence of the accuracy speed and scalability of our algorithm is presented on synthetic and real data matlab code for the implementation is made available to the community for facilitating further research 
object scene detection by discriminative kernel based classification ha gained great interest due to it promising performance and flexibility in this paper unlike traditional approach that independently build binary classifier to detect individual concept we proposed a new framework for multi class concept detection based on kernel sharing and joint learning by sharing good kernel among concept accuracy of individual weak detector can be greatly improved by joint learning of common detector among class the required kernel and the computational complexity for detecting each individual concept can be reduced we demonstrated our approach by developing an extended jointboost framework which wa used to choose the optimal kernel and subset of sharing class in an iterative boosting process in addition we constructed multi resolution visual vocabulary by hierarchical clustering and computed kernel based on spatial matching we tested our method in detecting concept object scene etc over hour of broadcast news video from the challenging trecvid corpus significant performance gain were achieved in mean average precision map and up to average precision ap for some concept like map building and boat ship extensive analysis of the result also revealed interesting and important underlying relation among concept 
diffusion tensor magnetic resonance imaging dt mri provides a comprehensive characterization of white matter wm in the brain and therefore play a crucial role in the investigation of disease in which wm is suspected to be compromised such a multiple sclerosis and neuropsychiatric disorder like schizophrenia however change induced by pathology may be subtle and affected region of the brain can only be revealed by a group based analysis of patient in comparison with healthy control this in turn requires voxel based statistical analysis of spatially normalized brain dt image a in the case of conventional mr image however this process is rendered extremely challenging in dt mri due to the high dimensionality of the data and it inherent non linearity that cause linear component analysis method to be inapplicable we therefore propose a novel framework for the statistical analysis of dt mri data using manifold based technique such a isomap and kernel pca that determine the underlying manifold structure of the data embed it to a manifold and help perform high dimensional statistic on the manifold to determine region of difference between the group of patient and control the framework ha been successfully applied to dt mri data from patient with schizophrenia a well a to study developmental change in small animal both of which identify regional change indicating the need for manifold based method for the statistical analysis of dti 
when an occluding object such a a person stand between a projector and a display surface a shadow result we can compensate by positioning multiple projector so they produce identical and overlapping image and by using a system to locate shadow existing system work by detecting either the shadow or the occluders shadow detection method cannot remove shadow before they appear and are sensitive to video projection while current occluder detection method require near infrared camera and illumination instead we propose using a camera based object tracker to locate the occluder and an algorithm to model the shadow the algorithm can adapt to other tracking technology a well despite imprecision in the calibration and tracking process we found that our system performs effective shadow removal with sufficiently low processing delay for interactive application with video projection 
abstract this paper address the problem of video inpainting that is seamlessly reconstructing missing portion in a set of video frame we propose to solve this problem proceeding a follows i finding a set of descriptor that encapsulate the information necessary to reconstruct a frame ii finding an optimal estimate of the value of these descriptor for the missing corrupted frame and iii using the estimated value to reconstruct the frame the main result of the paper show that the optimal descriptor estimate can be efficiently obtained by minimizing the rank of a matrix directly constructed from the available data leading to a simple computationally attractive dynamic inpainting algorithm that optimizes the use of spatio temporal information moreover contrary to most currently available technique the method can handle non periodic target motion non stationary background and moving camera these result are illustrated with several example including reconstructing dynamic texture and object disocclusion in case involving both moving target and camera 
we introduce an exemplar model that can learn and generate a region of interest around class instance in a training set given only a set of image containing the visual class the model is scale and translation invariant in the training phase image region that optimize an objective function are automatically located in the training image without requiring any user annotation such a bounding box the objective function measure visual similarity between training image pair using the spatial distribution of both appearance patch and edge the optimization is initialized using discriminative feature the model enables the detection localization of multiple instance of the object class in test image and can be used a a precursor to training other visual model that require bounding box annotation the detection performance of the model is assessed on the pascal visual object class challenge test set for a number of object class the performance far exceeds the current state of the art of fully supervised method 
kernel classifier based on support vector machine svm have recently achieved state of the art result on several popular datasets like caltech or pascal this wa possible by combining the advantage of svm convexity and the availability of efficient optimizers with hyperkernels linear combination of kernel computed at multiple level of image encoding the use of hyperkernels face the challenge of choosing the kernel weight the use of possibly irrelevant poorly performing kernel and an increased number of parameter that can lead to overfitting in this paper we advocate the transition from svms to support kernel machine skm model that estimate both the parameter of a sparse linear combination of kernel and the parameter of a discriminative classifier we exploit recent kernel learning technique not previously used in computer vision that show how learning skms can be formulated a a convex optimization problem which can be solved efficiently using sequential minimal optimization we study kernel learning for several multi level image encoding for supervised object recognition and report competitive result on several datasets including inria pedestrian caltech and the newly created caltech 
we present a new background estimation algorithm that construct the background of an image sequence with moving object by copying area from input frame the background estimation problem is formulated a an optimal labeling problem in which the label at an output pixel is the frame number from which to copy the background color the cost of assigning label encourage seamless copying from region that are stationary over a period of time in such a way that implied motion boundary occur at intensity edge this is accomplished without explicitly tracking the moving object or computing optical flow experiment demonstrate that our algorithm is effective in difficult area where the background is visible for only a small fraction of time and on input with both moving object that are not always in motion and moving object with textureless area 
we wish to endow the manifold m of smooth curve in with a riemannian metric that allows u to treat continuous morphs homotopies between two curve c and c a trajectory with computable length which are independent of the parameterization or representation of the two curve and the curve making up the morph between them we may then define the distance between the two curve using the trajectory of minimal length geodesic between them assuming such a minimizing trajectory exists at first we attempt to utilize the metric structure implied rather unanimously by the past twenty year or so of shape optimization literature in computer vision this metric arises a the unique metric which validates the common reference to a wide variety of contour evolution model in the literature a gradient flow to various formulated energy functionals surprisingly this implied metric yield a pathological and useless notion of distance between curve in this paper we show how this metric can be minimally modified using conformal factor the depend upon a curve s total arclength a nice property of these new conformal metric is that all active contour model that have been called gradient flow in the past will constitute true gradient flow with respect to these new metric under specfic time reparameterizations 
we introduce a physic based model for d person tracking based on a biomechanical characterization of lower body dynamic the model capture important physical property of bipedal locomotion such a balance and ground contact generalizes naturally to variation in style due to change in speed step length and mass and avoids common problem such a footskate that arise with existing tracker the model dynamic comprises a two degree offreedom representation of human locomotion with inelastic ground contact a stochastic controller generates impulsive force during the toe off stage of walking and spring like force between the leg a higher dimensional kinematic observation model is then conditioned on the underlying dynamic we use the model for tracking walking people from video including example with turning occlusion and varying gait 
in this paper we propose a variational method to segment image object which have a given parametric shape based on a level set formulation of the mumford shah functional and the shape parameter we define an energy functional composed by two complementary term the first one detects object boundary using a chan vese like method the second term constrains the contour to find a shape compatible with the parametric shape the segmentation of the object of interest is given by the minimum of our energy functional this minimum is computed with the calculus of variation and the gradient descent method that provide a system of evolution equation solved with the well known level set method we focus in this paper on the parametric category of image linear object application of the proposed model are presented on synthetic and real image 
most of current computer based facial expression analysis method focus on the recognition of perfectly posed expression and hence are incapable of handling the individual with expression impairment in particular patient with schizophrenia usually have impaired expression in the form of flat or inappropriate affect which make the quantification of their facial expression a challenging problem this paper present method to quantify the group difference between patient with schizophrenia and healthy control by extracting specialized feature and analyzing group difference on a feature manifold the feature include d and d geometric feature and the moment invariant combining both d geometry and d texture facial expression recognition experiment on actor demonstrate that our combined feature can better characterize facial expression than either d geometric or texture feature the feature are then embedded into an isomap manifold to quantify the group difference between control and patient experiment show that our result are strongly supported by the human rating result and clinical finding thus providing a framework that is able to quantify the abnormality in patient with schizophrenia 
many different shape from shading sfs algorithm have emerged during the last three decade most of these algorithm have been developed under the simplifying assumption of a lambertian surface an orthographic projection and a distant light source due to the difficulty of the sfs problem only a small number of algorithm have been proposed for surface with non lambertian reflectance and among those only very few algorithm are applicable for surface with specular and diffuse reflectance in this work a unified framework is proposed that is capable of solving the sfs problem under various setting of imaging condition i e lambertian or non lambertian orthographic or perspective projection and distant or nearby light source the proposed approach represents the image irradiance equation of each setting a an explicit partial differential equation pde these equation have been solved using a fast numerical algorithm based on lax friedrichs sweeping lf method several comparison with the state of the art of the sfs literature are given to evaluate the performance and the efficiency of the proposed approach 
we propose a novel classification approach for automatically detecting pulmonary embolism pe from computedtomography angiography image unlike most existing approach that require vessel segmentation to restrict the search space for pe our toboggan based candidate generator is capable of searching the entire lung for any suspicious region quickly and efficiently we then exploit the spatial information supplied in the vascular structure a a post candidate generation step by designing classifier with geodesic distance between candidate along the vascular tree moreover a pe represents a cluster of voxels in an image and thus multiple candidate can be associated with a single pe and the pe is identified if any of it candidate is correctly classified the proposed algorithm also provides an efficient solution to the problem of learning with multiple positive instance our clinical study with clinical case demonstrate that the proposed approach outperforms existing detection method achieving sensitivity on an independent test set at false positive per study 
this paper introduces a simple and efficient representation for natural image we partition an image into block and treat the block a vector in a high dimensional space we then fit a piece wise linear model i e a union of affine subspace to the vector at each down sampling scale we call this a multi scale hybrid linear model of the image the hybrid and hierarchical structure of this model allows u effectively to extract and exploit multi modal correlation among the imagery data at different scale it conceptually and computationally remedy limitation of many existing image representation method that are based on either a fixed linear transformation e g dct wavelet an adaptive uni modal linear transformation e g pca or a multi modal model at a single scale we will justify both analytically and experimentally why and how such a simple multi scale hybrid model is able to reduce simultaneously the model complexity and computational cost despite a small overhead for the model our result show that this new model give more compact representation for a wide variety of natural image under a wide range of signal to noise ratio than many existing method including wavelet 
we introduce a semi supervised method for building large labeleddatasetsoffacesbyleveragingarchival video specifically we have implemented a system for labeling year worth of archival footage from a television show we have compiled a dataset of face order of magnitude larger than existing collection it includes variation in appearance due to age weight gain change in hairstyle and other factor difficult to observe in smaller scale collection face recognition in an uncontrolled setting can be difficult we argue and demonstrate that there is much structure at varying timescales in the video data that make recognition much easier at local time scale one can use motion and tracking to group face image together we may not know the identity but we know a single label applies to all face in a track at medium time scale say within a scene one can use appearance feature such a hair and clothing to group track across shot boundary however at longer timescales say across episode one can no longer use clothing a a cue this suggests that one need to carefully encode representation of appearance depending on the timescale at which one intends to match we assemble our final dataset by classifying group of track in a nearest neighbor framework we use a face library obtained by labeling track cluster in a reference episode we show that this classification is significantly easier when exploiting the hierarchical structure naturally present in the video sequence from a data collection point of view tracking is vital because it add non frontal pose to our face collection this is important because we know of no other method for collecting image of non frontal face in the wild 
reconstruction of d structure from uncalibrated image sequence ha a wealthy history most work ha been focused on rigid object or static scene this paper study the problem of perspective reconstruction of deformable structure such a dynamic scene from an uncalibrated image sequence the task requires decomposing the image measurement into a composition of three factor d deformable structure rigid rotation and translation and intrinsic camera parameter we develop a factorization algorithm that consists of two step in the first step we recover the protective depth iteratively using the sub space constraint embedded in the image measurement of the deformable structure in the second step we scale the image measurement by the reconstructed projective depth we then extend the linear closed form solution for weak perspective reconstruction by j xiao et al to factorize the scaled measurement and simultaneously reconstruct the deformable shape and underlying shape model the rigid motion and the varying camera parameter such a focal length the accuracy and robustness of the proposed method is demonstrated quantitatively on synthetic data and qualitatively on real image sequence 
in this chapter we present two technology for sensing and surveillance audio assisted camera and acoustic doppler sensor for gait recognition 
in this work we deal with the problem of modelling and exploiting the interaction between the process of image segmentation and object categorization we propose a novel framework to address this problem that is based on the combination of the expectation maximization em algorithm and generative model for object category using a concise formulation of the interaction between these two process segmentation is interpreted a the e step assigning observation to model whereas object detection analysis is modelled a the m step fitting model to observation we present in detail the segmentation and detection process comprising the e and m step and demonstrate result on the joint detection and segmentation of the object category of face and car 
in computer vision application one usually ha to work with uncertain data it is therefore important to be able to deal with uncertain geometry and uncertain transformation in a uniform way the geometric algebra of conformal space offer a unifying framework to treat not only geometric entity like point line plane circle and sphere but also transformation like reflection inversion rotation and translation in this text we show how the uncertainty of all element of the geometric algebra of conformal space can be appropriately described by covariance matrix in particular it will be shown that it is advantageous to represent uncertain transformation in geometric algebra a compared to matrix other important result are a novel pose estimation approach a uniform framework for geometric entity fitting and triangulation the testing of uncertain tangentiality relation and the treatment of catadioptric camera with parabolic mirror within this framework this extends previous work by f rstner and heuel from point line and plane to non linear geometric entity and transformation while keeping the linearity of the estimation method we give a theoretical description of our approach and show exemplary application 
this paper present a practical method that estimate illumination distribution from shadow where the shadow are assumed to be cast on a textured lambertian surface previous method usually require that the reflectance property of the surface be constant or uniform or need an additional image to cancel out the effect of varying albedo of the textured surface we deal with an estimation problem for which surface albedo information is not available in this case the estimation problem corresponds to an underdetermined one we show that combination of regularization by correlation and some user specified information can be a practical method for solving the problem in addition a an optimization tool for solving the problem we develop a constrained nonnegative quadratic programming nnqp technique into which not only regularization but also user specified information are easily incorporated we test and validate our method on both synthetic and real image and present some experimental result 
this paper proposes a framework in which lagrangian particle dynamic is used for the segmentation of high density crowd flow and detection of flow instability for this purpose a flow field generated by a moving crowd is treated a an aperiodic dynamical system a grid of particle is overlaid on the flow field and is advected using a numerical integration scheme the evolution of particle through the flow is tracked using a flow map whose spatial gradient are subsequently used to setup a cauchy green deformation tensor for quantifying the amount by which the neighboring particle have diverged over the length of the integration the maximum eigenvalue of the tensor is used to construct a finite time lyapunov exponent ftle field which reveals the lagrangian coherent structure lcs present in the underlying flow the lcs divide flow into region of qualitatively different dynamic and are used to locate boundary of the flow segment in a normalized cut framework any change in the number of flow segment over time is regarded a an instability which is detected by establishing correspondence between flow segment over time the experiment are conducted on a challenging set of video taken from google video and a national geographic documentary 
robust egomotion recovery for extended camera excursion ha long been a challenge for machine vision researcher existing algorithm handle spatially limited environment and tend to consume prohibitive computational resource with increasing excursion time and distance we describe an egomotion estimation algorithm that take a input a coarse d model of an environment and an omnidirectional video sequence captured within the environment and produce a output a reconstruction of the camera s dof egomotion expressed in the coordinate of the input model the principal novelty of our method is a robust matching algorithm that associate d edge from the video with d line segment from the input model our system handle dof and dof camera excursion of hundred of meter within real cluttered environment it us a novel prior visibility analysis to speed initialization and dramatically accelerate image to model matching we demonstrate the method s operation and qualitatively and quantitatively evaluate it performance on both synthetic and real image sequence 
using the variational approach to estimate optical flow between two frame the flow discontinuity between different motion field are usually not distinguished even when an anisotropic diffusion operator is applied in this paper we propose a multi cue driven adaptive bilateral filter to regularize the flow computation which is able to achieve the smoothly varied optical flow field with highly desirable motion discontinuity first we separate the traditional one step variational updating model into a two step filtering based updating model then employing our occlusion detector we reformulate the energy functional of optical flow estimation by explicitly introducing an occlusion term to balance the energy loss due to the occlusion or mismatch furthermore based on the two step updating framework a novel multi cue driven bilateral filter is proposed to substitute the original anisotropic diffusion process and it is able to adaptively control the diffusion process according to the occlusion detection image intensity dissimilarity and motion dissimilarity after applying our approach on various video source movie and tv in the presence of occlusion motion blurring non rigid deformation and weak textureness we generate a spatial coherent flow field between each pair of input frame and detect more accurate flow discontinuity along the motion boundary 
abstract linear discriminant analysis lda is a popular statistical approach for dimensionality reduction lda capture the global geometric structure of the data by simultaneously maximizing the between class distance and minimizing the within class distance however local geometric structure ha recently been shown to be effective for dimensionality reduction in this paper a novel dimensionality reduction algorithm is proposed which integrates both global and local structure the main contribution of this paper include we present a least square formulation for dimensionality reduction which facility the integration of global and local structure we design an efficient model selection scheme for the optimal integration which balance the tradeoff between the global and local structure and we present a detailed theoretical analysis on the intrinsic relationship between the proposed framework and lda our extensive experimental study on benchmark data set show that the proposed integration framework is competitive with traditional dimensionality reduction algorithm which use global or local structure only 
in visual d reconstruction task with mobile camera one wish to move the camera so that they provide the view that lead to the best reconstruction result when the camera motion is adapted during the reconstruction the view of interest is the next best view for the current shape estimate we present such a next best view planning approach for visual d reconstruction the reconstruction is based on a probabilistic state estimation with sensor action the next best view is determined by a metric of the state estimation s uncertainty we compare three metric d optimality which is based on the entropy and corresponds to the d eterminant of the covariance matrix of a gaussian distribution e optimality and t optimality which are based on e igenvalues or on the t race of this matrix respectively we show the validity of our approach with a simulation a well a real world experiment and compare reconstruction accuracy and computation time for the optimality criterion 
recognition of d object from different viewpoint is a difficult problem in this paper we propose a new method to recognize d range image by matching local surface descriptor the input d surface are first converted into a set of local shape descriptor computed on surface patch defined by detected salient feature we compute the similarity between input d image by matching their descriptor with a pyramid kernel function the similarity matrix of the image is used to train for classification using svm and new image can be recognized by comparing with the training set the approach is evaluated on both synthetic and real d data with complex shape 
we propose a fast texture segmentation approach to the problem of d and d model based contour tracking which is suitable for real time or interactive application our approach relies on detecting texture boundary in the direction normal to the contour boundary and on using a hidden markov model to link these boundary point in the other direction the probability that appear in this computation closely relate to texture entropy and kullback leibler divergence a property we use to compute and update dynamic texture model we demonstrate result both in the context of interactive d delineation and fast d tracking 
we present a model of curvilinear grouping using piece wise linear representation of contour and a conditional random field to capture continuity and the frequency of different junction type potential completion are generated by building a constrained delaunay triangulation cdt over the set of contour found by a local edge detector maximum likelihood parameter for the model are learned from human labeled ground truth using held out test data we measure how the model by incorporating continuity structure improves boundary detection over the local edge detector we also compare performance with a baseline local classifier that operates on pair of edgels both algorithm consistently dominate the low level boundary detector at all threshold to our knowledge this is the first time that curvilinear continuity ha been shown quantitatively useful for a large variety of natural image better boundary detection ha immediate application in the problem of object detection and recognition 
we introduce the notion of co saliency for image matching our matching algorithm combine the discriminative power of feature correspondence with the descriptive power of matching segment co saliency matching score favor correspondence that are consistent with soft image segmentation a well a with local point feature matching we express the matching model via a joint image graph jig whose edge weight represent intraas well a inter image relation the dominant spectral component of this graph lead to simultaneous pixel wise alignment of the image and saliency based synchronization of soft image segmentation the co saliency score function which characterizes these spectral component can be directly used a a similarity metric a well a a positive feedback for updating and establishing new point correspondence we present experiment showing the extraction of matching region and pointwise correspondence and the utility of the global image similarity in the context of place recognition 
a major shortcoming of discriminative recognition and detection method is their noise sensitivity both during training and recognition this may lead to very sensitive and brittle recognition system focusing on irrelevant information this paper proposes a method that selects generative and discriminative feature in particular we boost classical haar like feature and use the same feature to approximate a generative model i e eigenimages a modified error function for boosting ensures that only feature are selected that show a good discrimination and reconstruction this allows a robust feature selection using boosting thus we can handle problem where discriminant classifier fail while still retaining the discriminative power our experiment show that we can significantly improve the recognition performance when learning from noisy data moreover the feature type used allows efficient recognition and reconstruction 
most multi camera vision application assume a single common color response for all camera however different camera even of the same type can exhibit radically different color response and the difference can cause significant error in scene interpretation to address this problem we have developed a robust system aimed at inter camera color consistency our method consists of two phase an iterative closed loop calibration phase that search for the per camera hardware register setting that best balance linearity and dynamic range followed by a refinement phase that computes the per camera parametric value for an additional software based color mapping 
for video summarization and retrieval one of the important module is to group temporal spatial coherent shot into high level semantic video clip namely scene segmentation in this paper we propose a novel scene segmentation and categorization approach using normalized graph cut ncuts starting from a set of shot we first calculate shot similarity from shot key frame then by modeling scene segmentation a a graph partition problem where each node is a shot and the weight of edge represents the similarity between two shot we employ ncuts to find the optimal scene segmentation and automatically decide the optimum scene number by q function to discover more useful information from scene we analyze the temporal layout pattern of shot and automatically categorize scene into two different type i e parallel event scene and serial event scene extensive experiment are tested on movie and tv series the promising result demonstrate that the proposed ncuts based scene segmentation and categorization method are effective in practice 
in this paper we consider the problem of computing and removing interreflection in photograph of real scene towards this end we introduce the problem of inverse light transport given a photograph of an unknown scene decompose it into a sum of n bounce image where each image record the contribution of light that bounce exactly n time before reaching the camera we prove the existence of a set of interreflection cancelation operator that enable computing each n bounce image by multiplying the photograph by a matrix this matrix is derived from a set of impulse image obtained by probing the scene with a narrow beam of light the operator work under unknown and arbitrary illumination and exist for scene that have arbitrary spatially varying brdfs we derive a closed form expression for these operator in the lambertian case and present experiment with textured and untextured lambertian scene that confirm our theory s prediction 
topology preserving geometric deformable model tgdms are used to segment object that have a known topology their accuracy is inherently limited however by the resolution of the underlying computational grid although this can be overcome by using fine resolution grid both the computational cost and the size of the resulting contour increase dramatically in order to maintain computational efficiency and to keep the contour size manageable we have developed a new framework termed qtgdms for topology preserving geometric deformable model on balanced quadtree grid bqgs in order to do this definition and concept from digital topology on regular grid were extended to bqgs so that characterization of simple point could be made other issue critical to the implementation of geometric deformable model are also addressed and a strategy for adapting a bqg during contour evolution is presented we demonstrate the performance of the qtgdm method using both mathematical phantom and real medical image 
mole pattern change are important cue in detecting melanoma at an early stage a a first step to automatically register mole pattern change from skin image this paper present a framework to detect and label mole on skin image in the presence of clutter occlusion and varying imaging condition the input image is processed with cascaded block to successively discard non mole pixel our method first search the entire input image for skin region using a non parametric skin detection scheme and the detected skin region are further processed using a difference of gaussian dog filter to find possible mole candidate of varying size mole candidate are classified a mole in the final stage using a trained support vector machine to increase the mole classification accuracy hair is removed if present on the skin image using steerable filter and a graphical model the performance of the designed system is evaluated with test image and the experimental result demonstrate the effectiveness of the proposed mole localization scheme 
accurately identifying corresponded landmark from a population of shape instance is the major challenge in constructing statistical shape model in this paper we address this landmark based shape correspondence problem for d case by developing a highly efcient landmark sliding algorithm this algorithm is able to quickly rene all the landmark in a parallel fashion by sliding them on the d shape surface we use d thin plate spline to model the shape correspondence error so that the proposed algorithm is invariant to afne transformation and more accurately reects the nonrigid biological shape deformation between different shape instance in addition the proposed algorithm can handle both openand closed surface shape while most of the current d shape correspondence method can only handle genus closed surface we conduct experiment on d hippocampus data and compare the performance of the proposed algorithm to the state of the art mdl and spharm method we nd that while the proposed algorithm produce a shape correspondence with a better or comparable quality to the other two it take substantially le cpu time we also apply the proposed algorithm to correspond d diaphragm data which have an open surface shape 
a successful representation of object in the literature is a a collection of patch or part with a certain appearance and position the relative location of the different part of an object are constrained by the geometry of the object going beyond the patch on a single object consider a collection of image of a particular class of scene containing multiple recurring object the part belonging to different object are not constrained by such a geometry however the object arguably due to their semantic relationship themselves demonstrate a pattern in their relative location which also propagates to their part analyzing the interaction between the part across the collection of image would reflect these pattern and the part can be grouped accordingly these grouping are typically hierarchical we introduce hso hierarchical semantics of object which is learnt from a collection of image of a particular scene and capture this hierarchical grouping we propose an approach for the unsupervised learning of the hso the hso simply hold object a cluster of patch at it node but it go much beyond that and also capture interaction between the object through it structure in addition to providing the semantic layout of the scene learnt hsos can have several useful application such a providing context for enhanced object detection and compact scene representation for scene category classification 
in this paper we present an interactive offline tracking system for generic color object the system achieves fps on a video the user can therefore easily refine the tracking result in an interactive way to fully exploit user input and reduce user interaction the tracking problem is addressed in a global optimization framework the optimization is efficiently performed through three step first from user s input we train a fast object detector that locates candidate object in the video based on proposed feature called boosted color bin second we exploit the temporal coherence to generate multiple object trajectory based on a global best first strategy last an optimal object path is found by dynamic programming 
our goal is to circumvent one of the roadblock to using existing approach for single view recognition for achieving multi view recognition namely the need for sufficient training data for many viewpoint we show how to construct virtual training example for multi view recognition using a simple model of object nearly planar facade centered at fixed d position we also show how the model can be learned from a few labeled image for each class 
recently real time active d range camera based on time of flight technology pmd have become available those camera can be considered a a competing technique for stereo vision based surface reconstruction since those system directly yield accurate d measurement they can be used for benchmarking vision based approach especially in highly dynamic environment therefore a comparative study of the two approach is relevant in this work the achievable accuracy of the two technique pmd and stereo is compared on the basis of patchlet estimation a patchlet we define an oriented small planar d patch with associated surface normal leastsquares estimation scheme for estimating patchlets from pmd range image a well a from a pair of stereo image are derived it is shown how the achivable accuracy can be estimated for both system experiment under optimal condition for both system are performed and the achievable accuracy are compared it ha been found that the pmd system outperformed the stereo system in term of achievable accuracy for distance measurement while the estimation of normal direction is comparable for both system 
measuring brdf bi directional reflectance distribution function requires huge amount of time because a target object must be illuminated from all incident angle and the reflected light must be measured from all reflected angle in this paper we present a high speed method to measure brdfs using an ellipsoidal mirror and a projector our method make it possible to changeincident angle without a mechanicaldrive moreover the omni directional reflected light from the object can be measured by one static camera atonce our prototyperequiresonlyfifty minute to measure anisotropic brdfs even if the lighting interval is one degree 
this paper present an approach that incorporates canonical correlation analysis cca for monocular d face pose and facial animation estimation the cca is used to find the dependency between texture residual and d face pose and facial gesture the texture residual are obtained from observed raw brightness shape free d image patch that we build by mean of a parameterized d geometric face model this method is used to correctly estimate the pose of the face and the model s animation parameter controlling the lip eyebrow and eye movement encoded in parameter extensive experiment on tracking face in long real video sequence show the effectiveness of the proposed method and the value of using cca in the tracking context 
this paper present a linear method to estimate the pose of a noncentral catadioptric system with a quadric shaped mirror in relation to a world reference frame or local reference frame without loss of generality the vision system is assumed to be calibrated the method us also a input data the structure of the scene it is proved that any reflection point should belong to an analytical quadric that intersects the mirror quadric itself this constraint can be written linearly in the d scene point coordinate in the camera reference frame the unknown pose screw transformation that relates camera and world reference frame can then be used in the linear model allowing for the construction of a linear equation in the pose transformation element additional constraint are used to force the estimated rotation element to build an orthogonal matrix test with simulated data and also on real image with different mirror proved the method to be consistent and to estimate the pose accurately however it wa also observed that the method is sensitive to noise the result are compared with another method 
we address the issue of euclidean path mu ling in a single camera for activity monitoring in a multi camera video surveillance system me paperpmposes a novel linear solufwn ro auto calibrafe any camera observing pedestrian and us these calibrated camera to detect unusual object behaviot the input rrajectories are metric rectified and e inpur sequence are registered to rh sarellia imagery and prototype pa model are constructed during e testing phase using our simple yet eflcient similarity measure we seek a relation between the input trajectory derivedfrom a sequence ad he protorype path model real world pedesrrian sequence are used ro demonstrate rhe practicality of he proposed method 
in this paper we present a new rotation invariant texture descriptor algorithm called invariant feature of local texture iflt the proposed algorithm extract rotation invariant feature from a small neighbourhood of pixel around a centre pixel or a texture patch intensity vector which is derived from a texture patch is normalized and haar wavelet filtered to derive rotation invariant feature texture classification experiment on the brodatz album and outex database have shown that the proposed algorithm ha a high rate of correct classification 
object identification oid is specialized recognition where the category is known e g car and the algorithm recognizes an object s exact identity e g bob s bmw two special challenge characterize oid inter class variation is often small many car look alike and may be dwarfed by illumination or pose change there may be many class but few or just one positive training example per class due to a solution must locate possibly subtle object specific salient feature a door handle while avoiding distracting one a specular highlight however rule out direct technique of feature selection we describe an online algorithm that take one model image from a known category and build an efficient same v different classification cascade by predicting the most discriminative feature set for that object our method not only estimate the saliency and scoring function for each candidate feature but also model the dependency between feature building an ordered feature sequence unique to a specific model image maximizing cumulative information content learned stopping threshold make the classifier very efficient to make this possible category specific characteristic are learned automatically in an off line training procedure from labeled image pair of the category without prior knowledge about the category our method using the same algorithm for both car and face outperforms a wide variety of other method 
in we showed that graph cut can find hyper surface of globally minimal length or area under any riemannian metric here we show that graph cut on directed regular grid can approximate a significantly more general class of continuous non symmetric metric using submodularity condition we obtain a tight characterization of graph representable metric such submodular metric have an elegant geometric interpretation via hyper surface functionals combining length area and flux practically speaking we extend geo cut algorithm to a wider class of geometrically motivated hypersurface functionals and show how to globally optimize any combination of length area and flux of a given vector field the concept of flux wa recently introduced into computer vision by but it wa mainly studied within variational framework so far we are first to show that flux can be integrated into graph cut a well combining geometric concept of flux and length area within the global optimization framework of graph cut allows principled discrete segmentation model and advance the state of the art for the graph cut method in vision in particular we address the shrinking problem of graph cut improve segmentation of long thin object and introduce useful shape constraint 
in most case when information is to be extracted from an image there are prior available on the state of the world and therefore on the detailed measurement which will be obtained while such prior are commonly combined with the actual measurement via bayes rule to calculate posterior probability distribution on model parameter their additional value in guiding efficient image processing ha almost always been overlooked prior tell u where to look for information in an image how much computational effort we can expect to expend to extract it and of how much utility to the task in hand it is likely to be such consideration are of importance in all practical real time vision system where the processing resource available at each frame in a sequence are strictly limited and it is exactly in high frame rate real time system such a tracker where strong prior are most likely to be available in this paper we use shannon information theory to analyse the fundamental value of measurement using mutual information score in absolute unit of bit specifically looking at the overwhelming case where uncertainty can be characterised by gaussian probability distribution we then compare these measurement value with the computational cost of the image processing required to obtain them this theory put on a firm footing for the first time principle of active search for efficient guided image processing in which candidate feature of possibly different type can be compared and selected automatically for measurement 
this paper introduces a new method for surface reconstruction from multiple calibrated image the primary contribution of this work is the notion of local prior to combine the flexibility of the carving approach with the accuracy of graph cut optimization a progressive refinement scheme is used to recover the topology and reason the visibility of the object within each voxel a detailed surface patch is optimally reconstructed using a graph cut method the advantage of this technique is it ability to handle complex shape similarly to level set while enjoying a higher precision compared to carving technique the addressed problem is well posed and the produced surface doe not suffer from aliasing in addition our approach seamlessly handle complete and partial reconstruction if the scene is only partially visible the process naturally produce an open surface otherwise if the scene is fully visible it creates a complete shape these property are demonstrated on real image sequence 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
in this paper we present a novel approach to keyframe based tracking called bi directional tracking given two object template in the beginning and ending keyframes the bi directional tracker output the map maximum a posterior solution of the whole state sequence of the target object in the bayesian framework first a number of d trajectory segment of the object are extracted from the input video using a novel trajectory segment analysis second these disconnected trajectory segment due to occlusion are linked by a number of inferred occlusion segment last the map solution is obtained by trajectory optimization in a coarse to fine manner experimental result show the robustness of our approach with respect to sudden motion ambiguity and short and long period of occlusion 
a novel deformable model for image segmentation and shape recovery is presented the model is inspired by fluid dynamic and is based on a flooding simulation similar to the watershed paradigm unlike most watershed method our model ha a continuous formulation being described by two partial differential equation in this model different fluid added by placing density dye source manually or automatically are attracted towards the contour of the object of interest by an image force in contrast to the watershed method when different fluid meet they may mix when the topographical relief of the image is flooded the interface separating homogeneous fluid region can be traced to yield the object contour we demonstrate the flexibility and potential of our model in two experimental setting shape recovery using manual initialization and automated segmentation 
we present an object class detection approach which fully integrates the complementary strength offered by shape matcher like an object detector it can learn class model directly from image and localize novel instance in the presence of intra class variation clutter and scale change like a shape matcher it find the accurate boundary of the object rather than just their bounding box this is made possible by a novel technique for learning a shape model of an object class given image of example instance the combination of hough style voting with a non rigid point matching algorithm to localize the model in cluttered image a demonstrated by an extensive evaluation our method can localize object boundary accurately while needing no segmented example for training only bounding box 
we discus calibration and removal of vignetting radial falloff and exposure gain variation from sequence of image unique solution for vignetting exposure and scene radiance are possible when the response curve is known when the response curve is unknown an exponential ambiguity prevents u from recovering these parameter uniquely however the vignetting and exposure variation can nonetheless be removed from the image without resolving this ambiguity application include panoramic image mosaic photometry for material reconstruction image based rendering and preprocessing for correlation based vision algorithm 
this paper present a computer vision system for tracking high speed non rigid skater over a large playing area in short track speeding skating competition the output of the tracking system are spatio temporal trajectory of the player which can be further processed and analyzed by sport expert given very fast and non smooth camera motion to capture highly complex and dynamic scene of skating tracking amorphous skater should be a challenging task we propose a new method of automatically computing the transformation matrix to map each frame of the imagery to the globally consistent model of the rink and incorporating the hierarchical model based on the contextual knowledge and multiple cue into the unscented kalman filter to improve the tracking performance when occlusion occurs experimental result show that the proposed algorithm is very efficient and effective on video recorded live by the author in the world short track speed skating championship 
in this paper we extend the class of energy function for which the optimal expansion and swap move can be computed in polynomial time specifically we introduce a class of higher order clique potential and show that the expansion and swap move for any energy function composed of these potential can be found by minimizing a submodular function we also show that for a subset of these potential the optimalmove can be found by solving an st mincut problem we refer to this subset a the p n potts model our result enable the use of powerful move making algorithm i e expansion and swap for minimization of energy function involving higher order clique such function have the capability of modelling the rich statistic of natural scene and can be used for many application in computer vision we demonstrate their use on one such application i e the texture based video segmentation problem 
the matching of planar shape can be cast a a problem of finding the shortest path through a graph spanned by the two shape where the node of the graph encode the local similarity of respective point on each contour while this problem can be solved using dynamic time warping the complete search over the initial correspondence lead to cubic runtime in the number of sample point in this paper we cast the shape matching problem a one of finding the shortest circular path on a torus we propose an algorithm to determine this shortest cycle which ha provably sub cubic runtime numerical experiment demonstrate that the proposed algorithm provides faster shape matching than previous method a an application we show that it allows to efficiently compute a clustering of a shape data base 
translucent object pose a difcult problem for traditional structured light d scanning technique subsurface scattering corrupts the range estimation in two way by drastically reducing the signal to noise ratio and by shifting the intensity peak beneath the surface to a point which doe not coincide with the point of incidence in this paper we analyze and compare two descattering method in order to obtain reliable d coordinate for translucent object by using polarization difference imaging subsurface scattering can be lter ed out because multiple scattering randomizes the polarization direction of light while the surface reectance partially keep the polarization direction of the illumination the descattered reectance can be used for reliable d reconstruction using traditional optical d scanning technique such a structured light phase shifting is another effective descattering technique if the frequency of the projected pattern is sufciently high we demonstrate the performance of these two technique and the combination of them on scanning real world translucent object 
this paper address the problem of image based surface reconstruction the main contribution is the computation of the exact derivative of the reprojection error functional this allows it rigorous minimization via gradient descent surface evolution the main difficulty ha been to correctly take into account the visibility change that occur when the surface move a geometric and analytical study of these change is presented and used for the computation of derivative our analysis show the strong influence that the movement of the contour generator ha on the reprojection error a a consequence during the proper minimization of the reprojection error the contour generator of the surface are automatically moved to their correct location in the image therefore current method adding additional silhouette or apparent contour constraint to ensure this alignment can now be understood and justified by a single criterion the reprojection error 
even though sensor fusion technique based on particle filter have been applied to object tracking their implemen tations have been limited to combining measurement from multiple sensor by the simple product of individual likeli hood therefore the number of observation is increased a many time a the number of sensor and the combined observation may become unreliable through blind integration of sensor observation especially if some sensor are too noisy and non discriminative we describe a methodology to model interaction between multiple sensor and to estimate the current state by using a mixture of bayesian filter one filter for each sensor where each filter make a different level of contribution to estimate the combined po sterior in a reliable manner in this framework an adaptive particle arrangement system is constructed in which each particle is allocated to only one of the sensor for observation and a different number of sample is assigned to each sensor using prior distribution and partial observation we apply this technique to visual tracking in logical and physi cal sensor fusion framework and demonstrate it effectiv ene through tracking result 
energy minimizing active contour model snake have been proposed for solving many computer vision problem such a object segmentation surface reconstruction and object tracking dynamic programming which allows natural enforcement of constraint is an effective method for computing the global minimum of energy function however this method is only limited to snake problem with one dimensional d topology i e a contour and cannot handle problem with two dimensional d topology in this paper we have extended the dynamic programming method to address the snake problem with d topology using a novel graph reduction algorithm given a d snake with first order energy term a set of reduction operation are defined and used to simplify the graph of the d snake into one single vertex while retaining the minimal energy of the snake the proposed algorithm ha a polynomial time complexity bound and the optimality of the solution for a reducible d snake is guaranteed however not all type of d snake can be reduced into one single vertex using the proposed algorithm the reduction of general planar snake is an np complete problem the proposed method ha been applied to optimize d building topology extracted from airborne lidar data to examine the effectiveness of the algorithm the result demonstrate that the proposed approach successfully found the global optimum for over of building topology in a polynomial time 
most d reconstruction solution focus on surface and there ha not been much research attention paid to the problem of reconstructing d scene made up of large number of particle while the ability to reconstruct such dynamic scene is potentially very useful in many area such a colony behavior research and visual modeling this paper proposes an approach relative epipolar motion rem towards solving the correspondence problem in stereopsis by utilizing the motion clue it match feature trajectory instead of the feature themselves a used by existing method the proposed method ha the following new capability it support reconstructing dynamic d scene of large number of undistinguishable drifting particle it is applicable to correspondence establishment for dynamic surface made up of repetitive texture it offer an alternative way to project structured light in active mode for deforming surface reconstruction experiment result on both simulated and real world scene demonstrate it effectiveness 
we propose a general method that parameterizes general surface with complex possible branching topology using riemann surface structure rather than evolve the surface geometry to a plane or sphere we instead use the fact that all orientable surface are riemann surface and admit conformal structure which induce special curvilinear coordinate system on the surface we can then automatically partition the surface using a critical graph that connects zero point in the global conformal structure on the surface the trajectory of iso parametric curve canonically partition a surface into patch each of these patch is either a topological disk or a cylinder and can be conformally mapped to a parallelogram by integrating a holomorphic form defined on the surface the resulting surface subdivision and the parameterizations of the component are intrinsic and stable for surface with similar topology and geometry we show that the parameterization result are consistent and the subdivided surface can be matched to each other using constrained harmonic map the surface similarity can be measured by direct computation of distance between each pair of corresponding point on two surface to illustrate the technique we computed conformal structure for anatomical surface in mri scan of the brain and human face surface we found that the resulting parameterizations were consistent across subject even for branching structure such a the ventricle which are otherwise difficult to parameterize our method provides a surface based framework for statistical comparison of surface and for generating grid on surface for pde based signal processing 
we introduce a non linear shape prior for the deformable model framework that we learn from a set of shape sample using recent manifold learning technique we model a category of shape a a finite dimensional manifold which we approximate using diffusion map that we call the shape prior manifold our method computes a delaunay triangulation of the reduced space considered a euclidean and us the resulting space partition to identify the closest neighbor of any given shape based on it nystr om extension our contribution lie in three aspect first we propose a solution to the pre image problem and define the projection of a shape onto the manifold based on closest neighbor for the diffusion distance we then describe a variational framework for manifold denoising finally we introduce a shape prior term for the deformable framework through a non linear energy term designed to attract a shape towards the manifold at given constant embedding result on shape of car and ventricule nucleus are presented and demonstrate the potential of our method 
boosting ha been widely applied in computer vision especially after viola and jones s seminal work the marriage of rectangular feature and integral imageenabled fast computation make boosting attractive for many vision application however this popular way of applying boosting normally employ an exhaustive feature selection scheme from a very large hypothesis pool which result in a le efficient learning process furthermore this pose additional constraint on applying boosting in an onine fashion where feature re selection is often necessary because of varying data characteristic but yet impractical due to the huge hypothesis pool this paper proposes a gradient based feature selection approach assuming a generally trained feature set and labeled sample are given our approach iteratively update each feature using the gradient descent by minimizing the weighted least square error between the estimated feature response and the true label in addition we integrate the gradient based feature selection with an online boosting framework this new online boosting algorithm not only provides an efficient way of updating the discriminative feature set but also present a unified objective for both feature selection and weak classifier updating experiment on the person detection and tracking application demonstrate the effectiveness of our proposal 
we propose a novel method for identifying road vehicle between two nonoverlapping camera the problem is formulated a a same different classification problem probability of two vehicle image from two distinct camera being from the same vehicle or from different vehicle the key idea is to compute the probability without matching the two vehicle image directly which is a process vulnerable to drastic appearance and aspect change we represent each vehicle image a an embedding amongst representative exemplar of vehicle within the same camera the embedding is computed a a vector each of whose component is a nonmetric distance for a vehicle to an exemplar the nonmetric distance are computed using robust matching of oriented edge image a set of truthed training example of same different vehicle pairing across the two camera is used to learn a classifier that encodes the probability distribution a pair of the embeddings representing two vehicle across two camera is then used to compute the same different probability in order for the vehicle exemplar to be representative for both camera we also propose a method for jointly selection of corresponding exemplar using the training data experiment on observation of over vehicle under drastically illumination and camera condition demonstrate promising result 
this paper examines the problem of detecting change in a d scene from a sequence of image taken by camera with arbitrary but known pose no prior knowledge of the state of normal appearance and geometry of object surface is assumed and abnormal change can occur in any image of the sequence to the author knowledge this paper is the first to address the change detection problem in such a general framework existing change detection algorithm that exploit multiple image viewpoint typically can detect only motion change or assume a planar world geometry which cannot cope effectively with appearance change due to occlusion and un modeled d scene geometry egomotion parallax the approach presented here can manage the complication of unknown and sometimes changing world surface by maintaining a d voxel based model where probability distribution for surface occupancy and image appearance are stored in each voxel the probability distribution at each voxel are continuously updated a new image are received the key question of convergence of this joint estimation problem is answered by a formal proof based on realistic assumption about the nature of real world scene a series of experiment are presented that evaluate change detection accuracy under laboratorycontrolled condition a well a aerial reconnaissance scenario done on detecting change in aerial imagery but it is limited by the range of camera motion allowed and the kind of change detected the ultimate objective of the research initiated in this paper is a solution to a large class of change detection problem where image are formed by camera of arbitrary but known position orientation and resolution and under very different illumination condition the final solution should be a system which process an image at a time update the world model from what ha been learned and discard the image having incorporated all of the image s relevant information in the model this paper is the first step toward that goal the algorithm described here handle the restricted case where the image are of approximately the same resolution and are taken under similar lighting condition but may still be taken from arbitrary viewpoint with substantial foreground clutter the objective of this paper is to demonstrate the algorithm s success at learning surface color and geometry probability under these restriction figure change detection result for an urban scene after training on a sequence of aerial image a an unseen image b handmarked ground truth change on this image c a planar change detection algorithm applied to ground registered image d voxel algorithm change detection result voxel algorithm detects all change with minimal error while the planar algorithm make many large error on the building 
for a large object scanning from the air is one of the most efficient method of obtaining d data in the case of large cultural heritage object there are some difficulty in scanning with respect to safety and efficiency to remedy these problem we have been developing a novel d measurement system the floating laser range sensor flrs in which a range sensor is suspended beneath a balloon the obtained data however have some distortion due to sensor movement during the scanning process in this paper we propose a method to recover d range data obtained by a moving laser range sensor this method is applicable not only to our flrs but also to a general moving range sensor using image sequence from a video camera mounted on the flrs enables u to estimate the motion of the flrs without any physical sensor such a gyro or gps in the first stage the initial value of camera motion parameter are estimated by full perspective factorization the next stage refines camera motion parameter using the relationship between camera image and range data distortion finally by using the refined parameter the distorted range data are recovered in addition our method is applicable with an uncalibrated video camera and range sensor system we applied this method to an actual scanning project and the result showed the effectiveness of our method 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
we present the conformal embedding analysis cea for feature extraction and dimensionality reduction incorporating both conformal mapping and discriminating analysis cea project the high dimensional data onto the unit hypersphere and preserve intrinsic neighbor relation with local graph modeling through the embedding resulting data pair from the same class keep the original angle and distance information on the hypersphere whereas neighboring point of different class are kept apart to boost discriminating power the subspace learned by cea is gray level variation tolerable since the cosine angle metric and the normalization processing enhance the robustness of the conformal feature extraction we demonstrate the effectiveness of the proposed method with comprehensive comparison on visual classification experiment 
automatically discovering common visual pattern from a collection of image is an interesting but yet challenging task in part because it is computationally prohibiting although representing image a visual document based on discrete visual word offer advantage in computation the performance of these word based method largely depends on the quality of the visual word dictionary this paper present a novel approach base on spatial random partition and fast word free image matching represented a a set of continuous visual primitive each image is randomly partitioned many time to form a pool of subimages each subimage is queried and matched against the pool and then common pattern can be localized by aggregating the set of matched subimages the asymptotic property and the complexity of the proposed method are given in this paper along with many real experiment both theoretical study and experiment result show it advantage 
we propose a full automatic technique to project virtual texture on a real textureless d object our sytem is composed of camera and projector and are used to determine the pose of the object in the real world with the projector a reference and then estimate the image seen by the projector if it would be a camera 
abstract it is well known that in order to calibrate a single camera with a one dimensional d calibration object the object must undertake some constrained motion in other word it is impossible to calibrate a single camera if the object motion is of general one for a multi camera setup i e when the number of camera is more than one can the camera be calibrated by a d object under general motion in this work we prove that all camera can indeed be calibrated and a calibration algorithm is also proposed and experimentally tested in contrast to other multi camera calibration method no one calibrated base camera is needed in addition we show that for such multi camera case the minimum condition of calibration and critical motion are similar to those of calibrating a single camera with d calibration object 
abstract using an imaging system in which the image plane can be tilted with respect to the optical axis of the lens the image of a large scale scene that appears to be a miniature to human eye can be captured this phenomenon suggests that the image contains information regarding the scale of the scene and that human vision can extract this information and recognize the scene scale from a single image in this study we consider how human vision can perform this single view scale estimation although it is obvious that the existence of defocus blur in the image that simulates a shallow dof play an essential role in the scale estimation we propose that this alone is not sufficient to explain the estimtation mechanism by incorporating a few assumption we theoretically show that scale estimation is made possible when the d structure of the scene can be recovered from the image and furthermore the structure is combined with the defocus blur further we present a simple algorithm for scale recognition and demonstrate it working using a real image 
nearly all existing method for stereo reconstruction assume that scene reflectance is lambertian and make use of color constancy a a matching invariant we introduce a new invariant for stereo reconstruction called light transport constancy which allows completely arbitrary scene reflectance brdfs this invariant can be used to formulate a rank constraint on multiview stereo matching when the scene is observed in several lighting configuration in addition we show that this multiview constraint can be used with a few a two camera and two lighting configuration unlikely previous method for brdf invariant stereo light transport constancy doe not require precisely configured or calibrated light source nor calibration object in the scene importantly the new constraint can be used to provide brdf invariance to any existing stereo method whenever appropriate lighting variation is available 
a newefficientmrf optimizationalgorithm calledfastpd is proposed which generalizes expansion one of it main advantage is that it offer a substantial speedup over that method e g it can be at least time faster than expansion it efficiency is a result of the fact that fast pdexploitsinformationcomingnotonlyfrom theoriginal mrf problem but also from a dual problem furthermore besides static mrfs it can also be used for boosting the performance of dynamic mrfs i e mrfs varying over time on top of that fast pd make no compromise about the optimality of it solution it can compute exactly the same answer a expansion but unlike that method it can also guarantee an almost optimal solution for a much wider class of np hard mrf problem result on static and dynamic mrfs demonstrate the algorithm s efficiency and power e g fast pd ha been able to compute disparity forstereoscopicsequencesin real time with theresulting disparity coinciding with that of expansion can that method also offer a computational advantage for the case of dynamic mrfs with respect to the question raised above this work make the following contribution efficiency for single mrfs expansion work by solving a series of max flow problem it efficiency is thus largely determined from the efficiency of these max flow problem which in turn depends on the number of augmenting path per max flow here we build upon recent work of and propose a new primal dual mrf optimization method called fast pd this method like or expansion also end up solving a max flow problem for a series of graph however unlike these technique the graph constructed by fast pd ensure that the number of augmentation per max flow decrease dramatically over time thus boosting the efficiency of mrf inference to show this we prove a generalized relationship between the number of augmentation and the so called primal dual gap associated with the original mrf problem and it dual furthermore to fully exploit the above property new extension are also proposed an adapted max flow algorithm a well a an incremental graph construction method optimality property despite it efficiency our method also make no compromise regarding the optimality of it solution so if d is a metric fast pd is a powerful a expansion i e it computes exactly the same solution but with a substantial speedup moreover it applies to a much wider class of mrfs e g even with a non metric d while still guaranteeing an almost optimal solution efficiency for dynamic mrfs furthermore our 
in recent year boosting ha been successfully applied to many practical problem in pattern recognition and computer vision field such a object detection and tracking a boosting is an offline training process with beforehand collected data once learned it cannot make use of any newly arriving one however an offline boosted detector is to be exploited online and inevitably there must be some special case that are not covered by those beforehand collected training data a a result the inadaptable detector often performs badly in diverse and changeful environment which are ordinary for many real life application to alleviate this problem this paper proposes an incremental learning algorithm to effectively adjust a boosted strong classifier with domain partitioning weak hypothesis to online sample which adopts a novel approach to efficient estimation of training loss received from offline sample by this mean the offline learned general purpose detector can be adapted to special online situation at a low extra cost and still retains good generalization ability for common environment the experiment show convincing result of our incremental learning approach on challenging face detection problem with partial occlusion and extreme illumination 
abstract in this paper a generic rule induction framework based on trajectory series analysis is proposed to learn the event rule first the trajectory acquired by a tracking system are mapped into a set of primitive event that represent some basic motion pattern of moving object then a minimum description length mdl principle based grammar induction algorithm is adopted to infer the meaningful rule from the primitive event series compared with previous grammar rule based work on event recognition where the rule are all defined manually our work aim to learn the event rule automatically experiment in a traffic crossroad have demonstrated the effectiveness of our method shown in the experimental result most of the grammar rule obtained by our algorithm are consistent with the actual traffic event in the crossroad furthermore the traffic light rule in the crossroad can also be leaned correctly with the help of eliminating the irrelevant trajectory 
in this paper we propose a new variational framework for computing continuous curve skeleton from discrete object that are suitable for structural shape representation we have derived a new energy function which is proportional to some medialness function such that the minimum cost path between any two medial voxels in the shape is a curve skeleton we have employed two different medialness function the euclidean distance field and a variant of the magnitude of the gradient vector flow gvf resulting in two different energy function the first energy control the identificationof the shape topologicalnodes from which curve skeleton start while the second one control the extraction of curve skeleton the accuracy and robustness of the proposed framework are validated both quantitatively and qualitatively against competing technique a well a several d shape of different complexity 
traditional image retrieval method require a query image to initiate a search for member of an image category however when the image database is unstructured and when the category is semantic and resides only in the mind of the user there is no obvious way to begin the page zero problem we propose a new mathematical framework for relevance feedback based on mental matching and starting from a random sample of image at each iteration the user declares which of several displayed image is closest to his category performance is measured by the number of iteration necessary to display an instance our core contribution is a bayesian formulation which scale to large database with no semantic annotation the two key component are a response model which account for the user s subjective perception of similarity and a display algorithm which seek to maximize the flow of information experiment with real user and a database with image demonstrate the efficiency of the search process 
we present a solution for optimal triangulation in three view the solution is guaranteed to find the optimal solution because it computes all the stationary point of the maximum likelihood objective function internally the solution is found by computing root of multi variate polynomial equation directly solving the condition for stationarity the solver make use of standard method from computational commutative algebra to convert the root finding problem into a non symmetric eigen problem although there are in general root counting both real and complex one the number of real root is usually much smaller we also show experimentally that the number of stationary point that are local minimum and lie in front of each camera is small but doe depend on the scene geometry 
pattern variation is a major factor that affect the performance of recognition system in this paper a novel manifold tangent modeling method called discriminant additive tangent space dat is proposed for invariant pattern recognition in dat intra class variation for traditional tangent learning are called positive tangent sample in addition extra class variation are introduced a negative tangent sample we use log odds to measure the significance of sample being positive or negative and then directly characterizes this log odds using generalized additive model gam this model is estimated to maximally discriminate positive and negative sample besides since traditional gam fitting algorithm can not handle the high dimensional data in visual recognition task we also present an efficient sparse solution for gam estimation the resulting dat is a nonparametric discriminant model based on quite weak prior hypothesis hence it can depict various pattern variation effectively experiment demonstrate the effectiveness of our method in several recognition task 
new view synthesis nv using texture prior a opposed to surface smoothness prior can yield high quality result but the standard formulation is in term of largeclique markov random field mrfs only local optimization method such a iterated conditional mode which are prone to fall into local minimum close to the initial estimate are practical for solving these problem in this paper we replace the large clique energy with pairwise potential by restricting the patch dictionary for each clique to image region suitable for that clique this enables for the first time the use of a global optimization method such a tree reweighted message passing to solve the nv problem with image based prior we employ a robust truncated quadratic kernel to reject outlier caused by occlusion specularities and moving object within our global optimization because the mrf optimization is thus fast computing the unary potential becomes the new performance bottleneck an additional contribution of this paper is a novel fast method for enumerating color mode of the per pixel unary potential despite the non convex nature of our robust kernel we compare the result of our technique with other rendering method and discus the relative merit and flaw of regularizing color and of local versus global dictionary 
we present a particle lter based target tracking algorithm for flir imagery a dual foreground and background model is proposed for target representation which support robust and accurate target tracking and size estimation a novel online feature selection technique is introduced that is able to adaptively select the optimal feature to maximize the tracking condence moreover a coupled particle lter ing approach is developed for joint target tracking and feature selection in an unied bayesian estimation framework the experimental result show that the proposed algorithm can accurately track poorly visible target in flir imagery even with strong ego motion the tracking performance is improved when compared to the tracker with a foregroundbased target model and without online feature selection 
we present a two layer hierarchical formulation to exploit different level of contextual information in image for robust classification each layer is modeled a a conditional field that allows one to capture arbitrary observation dependent label interaction the proposed framework ha two main advantage first it encodes both the short range interaction e g pixelwise label smoothing a well a the long range interaction e g relative configuration of object or region in a tractable manner second the formulation is general enough to be applied to different domain ranging from pixelwise image labeling to contextual object detection the parameter of the model are learned using a sequential maximum likelihood approximation the benefit of the proposed framework are demonstrated on four different datasets and comparison result are presented 
object class detection in scene of realistic complexity remains a challenging task in computer vision most recent approach focus on a single and general model for object class detection however in particular in the context of image sequence it may be advantageous to adapt the general model to a more object instance specic model in order to detect this particular object reliably within the image sequence in this work we present a generative object model that is capable to scale from a general object class model to a more specic object instance model this allows to detect class instance a well a to distinguish between individual object instance reliably we experimentally evaluate the performance of the proposed system on both still image and image sequence 
a novel approach to pattern matching is presented in which time complexity is reduced by two order of magnitude compared to traditional approach the suggested approach us an efficient projection scheme which bound the distance between a pattern and an image window using very few operation on average the projection framework is combined with a rejection scheme which allows rapid rejection of image window that are distant from the pattern experiment show that the approach is effective even under very noisy condition the approach described here can also be used in classification scheme where the projection value serve a input feature that are informative and fast to extract 
boosting is a remarkably simple and flexible classification algorithm with widespread application in computer vision however the application of boosting to noneuclidean infinite length and time varying data such a video is not straightforward in dynamic texture for example the temporal evolution of image intensity is captured by a linear dynamical system whose parameter live in a stiefel manifold clearly non euclidean in this paper we present a novel boosting method for the recognition of visual dynamical process our key contribution is the design of weak classifier feature that are formulated a linear dynamical system the main advantage of such feature is that they can be applied to infinitely long sequence and that they can be efficiently computed by solving a set of sylvester equation we also present an application of our method to dynamic texture classification 
in this work we systematically study the problem of visual event recognition in unconstrained news video sequence we adopt the discriminative kernel based method for which video clip similarity play an important role first we represent a video clip a a bag of orderless descriptor extracted from all of the constituent frame and apply earth mover s distance emd to integrate similarity among frame from two clip observing that a video clip is usually comprised of multiple sub clip corresponding to event evolution over time we further build a multilevel temporal pyramid at each pyramid level we integrate the information from different sub clip with integer valueconstrained emd to explicitly align the sub clip by fusing the information from the different pyramid level we develop temporally aligned pyramid matching tapm for measuring video similarity we conduct comprehensive experiment on the trecvid corpus which contains more than clip our experiment demonstrate that the tapm multi level method clearly outperforms single level emd and single level emd outperforms by a large margin in mean average precision basic detection method that use only a single key frame extensive analysis of the result also reveals an intuitive interpretation of subclip alignment at different level 
we present an object recognition algorithm that us model and image line feature to locate complex object in high clutter environment finding correspondence between model and image feature is the main challenge in most object recognition system in our approach corresponding line feature are determined by a three stage process the first stage generates a large number of approximate pose hypothesis from correspondence of one or two line in the model and image next the pose hypothesis from the previous stage are quickly ranked by comparing local image neighborhood to the corresponding local model neighborhood fast nearest neighbor and range search algorithm are used to implement a distance measure that is unaffected by clutter and partial occlusion the ranking of pose hypothesis is invariant to change in image scale orientation and partially invariant to affine distortion finally a robust pose estimation algorithmis applied for refinement and verification starting from the few best approximate pose produced by the previous stage experiment on real image demonstrate robust recognition of partially occluded object in very high clutter environment 
this paper present a new algorithm for the problem of robust subspace learning rsl i e the estimation of linear subspace parameter from a set of data point in the presence of outlier and missing data the algorithm is derived on the basis of the variational bayes vb method which is a bayesian generalization of the em algorithm for the purpose of the derivation of the algorithm a well a the comparison with existing algorithm we present two formulation of the em algorithm for rsl one yield a variant of the irls algorithm which is the standard algorithm for rsl the other is an extension of roweis s formulation of an em algorithm for pca which yield a robust version of the alternated least square al algorithm this al based algorithm can only deal with a certain type of outlier termed vector wise outlier the vb method is used to resolve this limitation which result in the proposed algorithm experimental result using synthetic data show that the proposed algorithm outperforms the irls algorithm in term of the convergence property and the computational time 
detecting nonrigid surface is an interesting research problem for computer vision and image analysis one important challenge of nonrigid surface detection is how to register a nonrigid surface mesh having a large number of free deformation parameter this is particularly significant for detecting nonrigid surface from noisy observation nonrigid surface detection is usually regarded a a robust parameter estimation problem which is typically solved iteratively from a good initialization in order to avoid local minimum in this paper we propose a novel progressive finite newton optimization scheme for the nonrigid surface detection problem which is reduced to only solving a set of linear equation the key of our approach is to formulate the nonrigid surface detection a an unconstrained quadratic optimization problem which ha a closed form solution for a given set of observation moreover we employ a progressive active set selection scheme which take advantage of the rank information of detected correspondence we have conducted extensive experiment for performance evaluationon various environment whose promising result show that the proposed algorithm is more efficient and effective than the existing iterative method 
we present a hierarchical generative model for object recognition that is constructed by weakly supervised learning a key component is a novel adaptive patch feature whose width and height are automatically determined the optimality criterion is based on minimum variance analysis which first computes the variance of the appearance model for various patch deformation and then selects the patch dimension that yield the minimum variance over the training data they are integrated into each level of our hierarchical representation that is learned in an iterative bottom up fashion at each level of the hierarchy pair of feature are identified that tend to occur at stable position relative to each other by clustering the configurational distribution of observed feature co occurrence using expectation maximization for recognition evidence is propagated using nonparametric belief propagation discriminative model are learned on the basis of our feature hierarchy by combining a svm classifier with feature selection based on the fisher score experiment on two very different challenging image database demonstrate the effectiveness of this framework for object class recognition a well a the contribution of the adaptive patch feature towards attaining highly competitive result 
abstract it is known that the problem of multiview reconstruction can be solved in two step first estimate camera rotation and then translation using them this paper present new robust technique for both of these step i given pairwise relative rotation global camera rotation are estimated linearly in least square ii camera translation are estimated using a standard technique based on second order cone programming robustness is achieved by using only a subset of point according to a new criterion that diminishes the risk of chosing a mismatch it is shown that only four point chosen in a special way are sufficient to 
a new message passing scheme for mrf optimization is proposed in this paper this scheme inherits better theoretical property than all other state of the art message passing method and in practice performs equally well outperforms them it is based on the very powerful technique of dual decomposition and lead to an elegant and general framework for understanding designing message passing algorithm that can provide new insight into existing technique promising experimental result and comparison with the state of the art demonstrate the extreme theoretical and practical potential of our approach 
electric chronic stimulation of the human motor cortex ecsm ha been reported to alleviate chronic severe pain however the mechanism of action of ecsm is still hypothetical this is due mainly to the poor knowledge of the electric diffusion through the multiple structure beneath the epidural contact i e dura matter cerebrospinal fluid space arachnoid membrane grey and white matter layer pie mere and vascular tree the absence of consensus concerning the stimulation parameter mono versus bipolar stimulation cathodic or anodic current and the detailed cortical topography of the contact in this study we focused on the precise identification of the cortical area covered by the electric contact in a series of twelve patient operated on for ecsm we propose a new automatic 
this paper present geometric invariant of point and their application under central catadioptric camera model although the image ha severe distortion under the model we establish some accurate projective geometric invariant of scene point and their image point these invariant being function of principal point are useful from which a method for calibrating the camera principal point and a method for recovering planar scene structure are proposed the main advantage of using these in variant for plane reconstruction is that neither camera motion nor the intrinsic parameter except for the principal point is needed the theoretical correctness of the established invariant and robustness of the proposed method are demonstrated by experiment in addition our result are found to be applicable to some more general camera model other than the catadioptric one 
we present a fast and accurate framework for registration of multi modal volumetric image based on decoupled estimation of registration parameter utilizing spatial information in the form of gradient intensity we introduce gradient intensity a a measure of spatial strength of an image in a given direction and show that it can be used to determine the rotational misalignment independent of translation between the image the rotation parameter are obtained by maximizing the mutual information of d gradient intensity matrix obtained from d image hence reducing the dimensionality of the problem and improving efficiency the rotation parameter along with estimation of translation are then used to initialize an optimization step over a conventional pixel intensity based method to achieve sub voxel accuracy our optimization algorithm converges quickly and is le subject to the common problem of misregistration due to local extremum experiment show that our method significantly improves the robustness performance and efficiency of registration compared to conventional pixel intensity based method 
model based image interpretation extract high level information from image using a priori knowledge about the object of interest the computational challenge in model fitting is to determine the model parameter that best match a given image which corresponds to finding the global optimum of the objective function when it come to the robustness and accuracy of fitting model to specific image human still outperform stateof the art model fitting system therefore we propose a method in which non expert can guide the process of designing model fitting algorithm in particular this paper demonstrates how to obtain robust objective function for face model fitting application by learning their calculation rule from example image annotated by human we evaluate the obtained function using a publicly available image database and compare it to a recent state of the art approach in term of accuracy 
this paper present a probabilistic part based approach for texture and object recognition texture are represented using a part dictionary found by quantizing the appearance of scaleor affine invariant keypoints object class are represented using a dictionary of composite semi local part or group of neighboring keypoints with stable and distinctive appearance and geometric layout a discriminative maximum entropy framework is used to learn the posterior distribution of the class label given the occurrence of part from the dictionary in the training set experiment on two texture and two object database demonstrate the effectiveness of this framework for visual classification 
we advocate the use of scaled gaussian process latent variable model sgplvm to learn prior model of d human pose for d people tracking the sgplvm simultaneously optimizes a low dimensional embedding of the high dimensional pose data and a density function that both give higher probability to point close to training data and provides a nonlinear probabilistic mapping from the low dimensional latent space to the full dimensional pose space the sgplvm is a natural choice when only small amount of training data are available we demonstrate our approach with two distinct motion golfing and walking we show that the sgplvm sufficiently constrains the problem such that tracking can be accomplished with straighforward deterministic optimization 
in this paper we propose a new method for simultaneously estimating the illumination of the scene and the reflectanceproperty of the object from a single image we assume that the illumination consists of multiple point source and the shape of the object is known unlike previous method we will recover not only the direction and intensity of the light source but also the number of light source and the specular reflection parameter of the object first we represent the illumination on the surface of a unit sphere a a finite mixture of von mi fisher distribution by deriving a spherical specular reflection model next we estimate this mixture and the number of distribution finally using this result a initial estimate we refine the estimate using the original specular reflection model we can use the result to render the object under novel lighting condition 
autonomous car will likely play an important role in the future a vision system designed to support outdoor navigation for such vehicle ha to deal with large dynamic environment changing imaging condition and temporary occlusion by other moving object this paper present a novel appearance based navigation framework relying on a single perspective vision sensor which is aimed towards resolving of the above issue the solution is based on a hierarchical environment representation created during a teaching stage when the robot is controlled by a human operator at the top level the representation contains a graph of key image with extracted d feature enabling a robust navigation by visual servoing the information stored at the bottom level enables to efficiently predict the location of the feature which are currently not visible and eventually re start their tracking the outstanding property of the proposed framework is that it enables robust and scalable navigation without requiring a globally consistent map even in interconnected environment this result ha been confirmed by realistic off line experiment and successful real time navigation trial in public urban area ric primitive while their position are expressed in coordinate of the common environment wide frame during the navigation the detected feature are associated with the element of the model in order to localize the robot and to effectively search for new model element however the quality of the obtained result depends directly on the precision of the underlying model this pose a strong assumption which impairs the scalability and depending on the input may not be attainable at all the alternative appearance based approach employ a sensor centred representation of the environment which is usually a multidimensional array of sensor reading in the context of computer vision the representation usually contains a set of key image which are acquired during a learning stage and organized within a graph node of the graph correspond to key image while the arc link the image containing a distinctive set of common landmark this is illustrated in figure the navigation 
abstract this paper present a technique for determining an object s shape based on the similarity of radiance change observed at point on it surface under varying illumination to examine the similarity we use an observation vector that represents a sequence of pixel intensity of a point on the surface under different lighting condition assuming convex object under distant illumination and orthographic projection we show that the similarity between two observation vector is closely related to the similarity between the surface normal of the corresponding point this enables u to estimate the object s surface normal solely from the similarity of radiance change under unknown distant lighting by using dimensionality reduction unlike most previous shape reconstruction method our technique neither assumes particular reflection model nor requires reference material this make our method applicable to a wide variety of object made of different material 
this paper proposes and present a solution to the problem of simultaneous learning of multiple visual category present in an arbitrary image set and their intercategory relationship these relationship also called their taxonomy allow category to be defined recursively a spatial configuration of simpler subcategories each o f which may be shared by many category each image is represented by a segmentation tree whose structure capture recursive embedding of image region in a multiscale segmentation and whose node contain the associated region property the presence of any occurring category is reflected in the occurrence of associated similar subtre e within the image tree similar subtrees across the entire image set are clustered each cluster corresponds to a discovered category represented by the cluster property a subcategory cluster of small matching subtrees may occur within multiple cluster category of larger matching s ubtrees in different spatial relationship with subtrees fr om other small cluster such recursive embedding grouping and intersection of cluster is captured in a directed acyclic graph dag which represents the discovered taxonomy detection recognition and segmentation of any of the learned category present in a new image are simultaneously conducted by matching the segmentation tree of the new image with the learned dag this matching also yield a semantic explanation of the recognized category in term of the presence of it subcategories experiment with a newly compiled dataset of four legged animal demonstrate good cross category resolvability 
we propose a novel approach for shape based segmentation based on a specially designed level set function format this format permit u to better control the process of object registration which is an important part in the shapebased segmentation framework 
abstract discriminative learning is challenging when example are set of feature and the set vary in cardinality and lack any sort of meaningful ordering kernel based classification method can learn complex decision boundary but a kernel over unordered set input must somehow solve for correspondence generally a computationally expensive task that becomes impractical for large set size we present a new fast kernel function which map unordered feature set to multi resolution histogram and computes a weighted histogram intersection in this space this pyramid match computation is linear in the number of feature and it implicitly find correspondence based on the finest resolutionhistogramcell wherea matchedpairfirst appears since the kernel doe not penalize the presence of extra feature it is robust to clutter we show the kernel function is positive definite making it valid for use in learning algorithm whose optimal solution are guaranteed only for mercer kernel we demonstrate our algorithm on object recognition task and show it to be accurate and dramatically faster than current approach 
tumor segmentation from mri data is an important but time consuming task performed manually by medical expert automating this process is challenging due to the high diversity in appearance of tumor tissue among different patient and in many case similarity between tumor and normal tissue one other challenge is how to make use of prior information about the appearance of normal brain in this paper we propose a variational brain tumor segmentation algorithm that extends current approach from texture segmentation by using a high dimensional feature set calculated from mri data and registered atlas using manually segmented data we learn a statistical model for tumor and normal tissue we show that using a conditional model to discriminate between normal and abnormal region significantly improves the segmentation result compared to traditional generative model validation is performed by testing the method on several cancer patient mri scan 
a new method for localising and recognising hand pose and object in real time is presented this problem is important in vision driven application where it is natural for a user to combine hand gesture and real object when interacting with a machine example include using a real eraser to remove word from a document displayed on an electronic surface in this paper the task of simultaneously recognising object class hand gesture and detecting touch event is cast a a single classification problem a random forest algorithm is employed which adaptively selects and combine a minimal set of appearance shape and stereo feature to achieve maximum class discrimination for a given image this minimal set lead to both efficiency at run time and good generalisation unlike previous stereo work which explicitly construct disparity map here the stereo matching cost are used directly a visual cue and only computed on demand i e only for pixel where they are necessary for recognition this lead to improved efficiency the proposed method is assessed on a database of a variety of object and hand pose selected for interacting on a flat surface in an office environment 
in this paper we introduce a tuned eigenspace technique so a to classify human motion the method presented here overcomes those problem related to articulated motion and dress texture effect by learning various human motion in term of their sequential posture in an eigenspace in order to cope with the variability inherent to articulated motion we propose a method to tune the set of sequential eigenspaces once the learnt tuned eigenspaces are at hand the recognition task then becomes a nearest neighbor search over the eigenspaces we show how our tuned eigenspace method can be used for purpose of real world and synthetic pose recognition we also discus and overcome the problem related to clothing texture that occurs in real world data and propose a background subtraction method to employ the method in out door environment we provide result on synthetic imagery for a number of human pose and illustrate the utility of the method for the purpose of human motion recognition 
in this paper we propose a non stationary stochastic filtering framework for the task of albedo estimation from a single image there are several approach in literature for albedo estimation but few include the error in estimate of surface normal and light source direction to improve the albedo estimate the proposed approach effectively utilizes the error statistic of surface normal and illumination direction for robust estimation of albedo the albedo estimate obtained is further used to generate albedo free normalized image for recovering the shape of an object illustration and experiment are provided to show the efficacyof the approach and it application to illumination invariant matching and shape recovery of the estimated shape and illumination condition error in shape and illumination estimate lead to error in albedo in this paper we show how statistical characterizationof error in normal and light source direction can be utilized to obtain robust albedo estimate the problem of albedo estimation is formulated a an image estimation problem given an initial albedo map obtained using available domain dependent average shape information we obtain a robust albedo estimate by modeling the true unknown albedo a a non stationary mean and non stationary variance field unlike a stationary model this model can account for the albedo variation present in most real object the initial albedo map is written a a sum of the true unknown albedo and a signal dependent nonstationary noise the noise term incorporates the error in surface normal and illumination information posing this a an image estimation problem the albedo is estimated a the linear minimum mean square error lmmse estimate of the true albedo the robustness of the estimated albedo map allow u to use them for the task of shape recovery traditional shape from shading sfs approach often make constant piece wiseconstantalbedo assumptionto recovershape of an object from a single image such assumption thoughuseful to make the problemless intractable often limit the applicability of the approach for real world object with varying albedo here using the estimated albedo we obtain albedo free image that can be handled by traditional sfs approach experiment show that albedo estimate obtained using the proposed approach are quite close to the true value we evaluate the illumination insensitivity of the estimated albedo map by using them for face recognition recognition result on pie dataset show that not only the estimated albedo map significantly outperform the initial erroneous one but also compare well with several recent illumination invariantapproaches for face recognition 
most existing subspace analysis based tracking algorithm utilize a flattened vector to represent a target resulting in a high dimensional data learning problem recently subspace analysis is incorporated into the multilinear framework which offline construct a representation of image ensemble using high order tensor this reduces spatio temporal redundancy substantially whereas the computational and memory cost is high in this paper we present an effective online tensor subspace learning algorithm which model the appearance change of a target by incrementally learning a low order tensor eigenspace representation through adaptively updating the sample mean and eigenbasis tracking then is led by the state inference within the framework in which a particle filter is used for propagating sample distribution over the time a novel likelihood function based on the tensor reconstruction error norm is developed to measure the similarity between the test image and the learned tensor subspace model during the tracking theoretic analysis and experimental evaluation against a state of the art method demonstrate the promise and effectiveness of this algorithm 
this paper present a novel scheme for manifold learning different from the previous work reducing data to euclidean space which cannot handle the looped manifold well we map the scattered data to it intrinsic parameter manifold by semi supervised learning given a set of partially labeled point the map to a specified parameter manifold is computed by an iterative neighborhood average method called anchor point diffusion procedure apd we explore this idea on the most frequently used close formed manifold stiefel manifold whose special case include hyper sphere and orthogonal group the experiment show that apd can recover the underlying intrinsic parameter of point on scattered data manifold successfully 
this paper present our progress on openvl a novel software architecture to address efficiency through facilitating hardware acceleration reusability and scalability for computer vision a logical image understanding pipeline is introduced to allow parallel processing a well we discus our middleware vlut that enables application to operate transparently over a heterogeneous collection of hardware implementation openvl work a a state machine with an event driven mechanism to provide user with application level interaction various explicit or implicit synchronization and communication method are supported among distributed process in the logical pipeline the intent of openvl is to allow user to quickly and easily recover useful information from multiple scene across various software environment and hardware platform we implement two different human tracking system to validate the critical underlying concept of openvl 
we present a variational method for unfolding of the cortex based on a user chosen point of view a an alternative to more traditional global flattening method which incur more distortion around the region of interest our approach involves two novel contribution the first is an energy function and it corresponding gradient flow to measure the average visibility of a region of interest of a surface from a given viewpoint the second is an additional energy function and flow designed to preserve the d topology of the evolving surface this latter contribution receives significant focus in this paper a it is crucial to obtain the desired unfolding effect derived from the first energy functional and flow without it the resulting topology change render the unconstrained evolution uninteresting for the purpose of cortical visualization exploration and inspection 
we introduce novel discriminative learning algorithm for dynamical system model such a conditional random field or maximum entropy markov model outperform the generative hidden markov model in sequence tagging problem in discrete domain however continuous state domain introduce a set of constraint that can prevent direct application of these traditional model instead we suggest to learn generative dynamic model with discriminative cost functionals for linear dynamical system the proposed method provide significantly lower prediction error than the standard maximum likelihood estimator often comparable to nonlinear model a a result the model with lower representational capacity but computationally more tractable than nonlinear model can be used for accurate and efficient state estimation we evaluate the generalization performance of our method on the d human pose tracking problem from monocular video the experiment indicate that the discriminative learning can lead to improved accuracy of pose estimation with no increase in computational cost of tracking 
numerous application processing d point data will gain from the ability to estimate reliably normal and differential geometric property normal estimate are notoriously noisy the error propagate and may lead to flawed inaccurate and inconsistent curvature estimate frankotchellappa introduced the use of integrability constraint in normal estimation their approach deal with graph z f x y we present a newly discovered general orientability constraint goc for d point cloud sampled from general surface not just graph it provides a tool to quantify the confidence in the estimation of normal topology and geometry from a point cloud furthermore similarly to the frankot chellappa constraint the goc can be used directly to extract the topology and the geometry of the manifold underlying d point cloud a an illustration we describe an automatic cloud to geometry pipeline which exploit the goc 
recognition of specular object is particularly difficult because their appearance is much more sensitive to lighting change than that of lambertian object we consider an approach in which we use a d model to deduce the lighting that best match the model to the image in this case an important constraint is that incident lighting should be non negative everywhere in this paper we propose a new method to enforce this constraint and explore it usefulness in specular object recognition using the spherical harmonic representation of lighting the method follows from a novel extension of szego s eigenvalue distribution theorem to spherical harmonic and us semidefinite programming to perform a constrained optimization the new method is faster a well a more accurate than previous method experiment on both synthetic and real data indicate that the constraint can improve recognition of specular object by better separating the correct and incorrect model 
in this paper we propose a robust and efficient lagrangian approach which we call delaunay deformable model for modeling moving surface undergoing large deformation and topology change our work us the concept of restricted delaunay triangulation borrowed from computational geometry in our approach the interface is represented by a triangular mesh embedded in the delaunay tetrahedralization of interface point the mesh is iteratively updated by computing the restricted delaunay triangulation of the deformed object our method ha many advantage over popular eulerian technique such a the level set method and over hybrid eulerian lagrangian technique such a the particle level set method localization accuracy adaptive resolution ability to track property associated to the interface seamless handling of triple junction our work brings a rigorous and efficient alternative to existing topology adaptive mesh technique such a tsnakes 
in this paper we present a dynamic model for simulating face aging process we adopt a high resolution grammatical face model and augment it with age and hair feature this model represents all face image by a multi layer and or graph and integrates three most prominent aspect related to aging change global appearance change in hair style and shape deformation and aging effect of facial component and wrinkle appearance at various facial zone then face aging is modeled a a dynamic markov process on this graph representation which is learned from a large dataset given an input image we firstly compute the graph representation and then sample the graph structure over various age group according to the learned dynamic model finally we generate new face image with the sampled graph our approach ha three novel aspect the aging model is learned from a dataset of adult face at different age we explicitly model the uncertainty in face aging andean sample multiple plausible aged face for an input image and we conduct a simple human experiment to validate the simulated aging process 
in this paper we address the issue of extracting contour of the object with a specific shape a hierarchical graphical model is proposed to represent shape variation a complex shape is decomposed into several component which are described a principal component analysis pca based model in various level the hierarchical representation allows for chain like conditional dependency within a single level and bidirectional communication between different level additionally a sequential monte carlo smc based inference algorithm that can explore the graphical structure is proposed to estimate the contour the experiment performed on real world hand and face image show that the proposed method is effective in combating occlusion and cluttered background moreover it is possible to isolate the localization error to an individual component of a shape attributed to the hierarchical representation 
we formulate the problem of scene summarization a selecting a set of image that efficiently represents the visual content of a given scene the ideal summary present the most interesting and important aspect of the scene with minimal redundancy we propose a solution to this problem using multi user image collection from the internet our solution examines the distribution of image in the collection to select a set of canonical view to form the scene summary using clustering technique on visual feature the summary we compute also lend themselves naturally to the browsing of image collection and can be augmented by analyzing user specified image tag data we demonstrate the approach using a collection of image of the city of rome showing the ability to automatically decompose the image into separate scene and identify canonical view for each scene 
long duration tracking of general target is quite challenging for computer vision because in practice target may undergo large uncertainty in it visual appearance and the unconstrained environment may be cluttered and distractive although tracking ha never been a challenge to the human visual system psychological and cognitive finding indicate that the human perception is attentional and selective and both early attentional selection that may be innate and late attentional selection that may be learned are necessary for human visual tracking this paper proposes a new visual tracking approach by reflecting some aspect of spatial selective attention and present a novel attentional visual tracking avt algorithm in avt the early selection process extract a pool of attentional region ar that are defined a the salient image region which have good localization property and the late selection process dynamically identifies a subset of discriminative attentional region d ar through a discriminative learning on the historical data on the fly the computationally demanding process of matching of the ar pool is done in an efficient and innovative way by using the idea in the locality sensitive hashing lsh technique the proposed avt algorithm is general robust and computationally efficient a shown in extensive experiment on a large variety of real world video 
automatic annotation is an elegant alternative to explicit recognition in image in annotation the image is matched with keyword model and the most relevant keywords are assigned to the image using existing technique the annotation time for large collection is very high while the annotation performance degrades with increase in number of keywords towards the goal of large scale annotation we present an approach called reverse annotation unlike traditional annotation where keywords are identied for a given image in reverse annotation the relevant image are identied for each keyword with this seemingly simple shift in perspective the annotation time is reduced signicantly to be able to rank relevant image the approach is extended to probabilistic reverse annotation our framework is applicable to a wide variety of multimedia document and scalable to large collection here we demonstrate the framework over a large collection of document image containing million word segment annotated by keywords our image retrieval system replicates text based search engine in response time 
in this study we demonstrate the effectiveness of using extended light source for modeling the appearance of an object for varying illumination extended light source have a radiance distribution that is similar to that of the gaussian function and have the potential of functioning a a low pas filter when the appearance of an object is sampled under them this enables u to obtain a set of basis image of an object for variable illumination from input image of the object taken under those light source without suffering aliasing caused by insufficient sampling of it appearance furthermore extended light source are useful in term of reducing high contrast in image intensity due to specular and diffuse reflection component this help u observe both specular and diffuse reflection component of an object in the same image taken with a single shutter speed we have tested our proposed approach based on extended light source with object of complex appearance that are generally difficult to model using image based modeling technique 
this paper present a novel framework prototype embedding and embedding transition peet for matching object especially vehicle that undergo drastic pose appearance and even modality change the problem of matching object seen under drastic variation is reduced to matching embeddings of object appearance instead of matching the object image directly an object appearance is first embedded in the space of a representative set of model prototype prototype embedding pe object captured at disparate temporal and spatial site are embedded in the space of prototype that are rendered with the pose of the camera at the respective site low dimensional embedding vector are subsequently matched a significant feature of our approach is that no mapping function is needed to compute the distance between embedding vector extracted from object viewed from disparate pose and appearance change instead an embedding transition et scheme is utilized to implicitly realize the complex and non linear mapping with high accuracy the heterogeneous nature of matching between high resolution and low resolution image object in peet is discussed and an unsupervised learning scheme based on the exploitation of the heterogeneous nature is developed to improve the overall matching performance of mixed resolution object the proposed approach ha been applied to vehicular object classification and query application and the extensive experimental result demonstrate the efficacy and versatility of the peet framework 
we propose a method for face recognition based on a discriminative linear projection in this formulation image are treated a tensor rather than the more conventional vector of pixel projection are pursued sequentially and take the form of a rank one tensor i e a tensor which is the outer product of a set of vector a novel and effective technique is proposed to ensure that the rank one tensor projection are orthogonal to one another these constraint on the tensor projection provide a strong inductive bias and result in better generalization on small training set our work is related to spectrum method which achieve orthogonal rank one projection by pursuing consecutive projection in the complement space of previous projection although this may be meaningful for application such a reconstruction it is le meaningful for pursuing discriminant projection our new scheme iteratively solves an eigenvalue problem with orthogonality constraint on one dimension and solves unconstrained eigenvalue problem on the other dimension experiment demonstrate that on small and medium sized face recognition datasets this approach outperforms previous embedding method on large face datasets this approach achieves result comparable with the best often using fewer discriminant projection 
in this study we address the problem of d dense metric reconstruction and registration from multiple image given that the observed surface is nearly planar this is difficult a classical method work well only if the scene is truly planar mosaicing or the scene ha certain significant depth variation classical structure frommotion sfm one domain in which this problem occurs is image analysis of the retinal fundus our approach is to first assume planarity and perform d global registration a first bundle adjustment is applied to find the camera position in metric space we then select two image and compute the epipolar geometry between them using plane parallax approach these image are matched to generate a dense disparity map using mutual information a second bundle adjustment is applied to transform the disparity map into a dense metric depth map fixing the camera position a third bundle adjustment is performed to refine both camera position and a d structure all image are back projected to the d structure for the final registration the entire process is fully automatic in addition a clear definition of near planarity is provided d reconstruction is shown visually the method is general and can be applied to other domain a shown in the experiment 
matching and registration of shape is a key issue in computer vision pattern recognition and medical image analysis this paper present a shape representation framework based on gaussian curvature and markov random field mrfs for the purpose of shape matching the method is based on a surface mesh model in r which is projected into a two dimensional space and there modeled a an extended boundary closed markov random field the surface is homeomorphic to s the mrf encodes in the node entropy feature of the corresponding similarity based on gaussian curvature and in the edge the spatial consistency of the mesh correspondence between two surface mesh is then established by performing probabilistic inference on the mrf via gibbs sampling the technique combine both geometric topological and probabilistic information which can be used to represent shape in three dimensional space and can be generalized to higher dimensional space a a result the representation can be used for shape matching registration and statistical shape analysis 
abstract the quantitative evaluation of optical ow algorithm by barron et al led to signicant advance in performance the challenge for optical ow algorithm today go beyond the datasets and evaluation method proposed in that paper instead they center on problem associated with complex natural scene including nonrigid motion real sensor noise and motion discontinuity we propose a new set of benchmark and evaluation method for the next generation of optical ow algorithm to that end we contribute four type of data to test dierent aspect of optical ow algorithm sequence with nonrigid motion where the ground truth ow is determined by tracking hidden uorescent texture realistic synthetic sequence high frame rate video used to study interpolation error and modied stereo sequence of static scene in addition to the average angular error used by barron et al we compute the absolute ow endpoint error measure for frame interpolation error improved statistic and result at motion discontinuity and in textureless region in october we published the performance of several well known method on a preliminary version of our data to establish the current state of the art we also made the data freely available on the web at http vision middlebury edu ow subsequently a number of researcher have uploaded their result to our website and published paper using the data a signicant improvement in performance ha already been achieved in this paper we analyze the result obtained to date and draw a large number of conclusion from them i 
we present an algorithm that recognizes object of a given category using a small number of hand segmented image a reference our method first over segment an input image into superpixels and then find a shortlist of optimal combination of superpixels that best fit one of template part under affine transformation second we develop a contextual interpretation of the part gluing image segment using top down fiducial point and checking overall shape similarity in contrast to previous work the search for candidate superpixel combination is not exponential in the number of segment and in fact lead to a very efficient detection scheme both the storage and the detection of template only require space and time proportional to the length of the template boundary allowing u to store potentially million of template and to detect a template anywhere in a large image in roughly second we apply our algorithm on the weizmann horse database and show our method is comparable to the state of the art while offering a simpler and more efficient alternative compared to previous work 
this paper present a novel approach that represents an image or a set of image using a non orthogonal binary subspace nb spanned by box like base vector these base vector posse the property that the inner product operation with them can be computed very efficiently we investigate the optimized orthogonal matching pursuit method for finding the best nb base vector it is demonstrated in this paper how the nb based expansion can be applied to speed up several common computer vision algorithm including normalized cross correlation ncc sum of squared difference ssd matching appearance subspace projection and subspace based object recognition promising experimental result on facial and natural image are demonstrated in this paper 
we present an automatic and efficient method to register and stitch thousand of video frame into a large panoramic mosaic our method preserve the robustness and accuracy of image stitcher that match all pair of image while utilizing the ordering information provided by video we reduce the cost of searching for match between video frame by adaptively identifying key frame based on the amount of image to image overlap key frame are matched to all other key frame but intermediate video frame are only matched to temporally neighboring key frame and intermediate frame image orientation can be estimated from this sparse set of match in time quadratic to cubic in the number of key frame but only linear in the number of intermediate frame additionally the match between pair of image are compressed by replacing measurement within small window in the image with a single representative measurement we show that this approach substantially reduces the time required to estimate the image orientation with minimal loss of accuracy finally we demonstrate both the efficiency and quality of our result by registering several long video sequence 
this paper investigates the impact of pixel level fusion of video from visible viz and infrared ir surveillance camera on object tracking performance a compared to tracking in single modality video tracking ha been accomplished by mean of a particle filter which fuse a colour cue and the structural similarity measure ssim the highest tracking accuracy ha been obtained in ir sequence whereas the viz video showed the worst tracking performance due to higher level of clutter however metric for fusion assessment clearly point towards the supremacy of the multiresolutional method especially dual tree complex wavelet transform method thus a new tracking oriented metric is needed that is able to accurately ass how fusion affect the performance of the tracker 
this paper present a new method for object tracking in video sequence that is especially suitable in very noisy environment in such situation segmented image from one frame to the next one are usually so different that it is very hard or even impossible to match the corresponding region or contour of both image with the aim of tracking object in these situation our approach ha two main characteristic on one hand we assume that the tracking approach based on contour cannot be applied and therefore our system us object recognition result computed from region specifically colour spot from segmented image on the other hand we discard to match the spot of consecutive segmented image and consequently the method that represent the object by structure such a graph or skeleton since the structure obtained may be too different in consecutive frame thus we represent the location of tracked object through image of probability that are updated dynamically using both recognition and tracking result in previous step from these probability and a simple prediction of the apparent motion of the object in the image a binary decision can be made for each pixel and abject 
we consider the problem of matching a face in a low resolution query video sequence against a set of higher quality gallery sequence this problem is of interest in many application such a law enforcement our main contribution is an extension of the recently proposed generic shapeillumination manifold gsim framework specifically i we show how super resolution across pose and scale can be achieved implicitly by off line learning of subsampling artefact ii we use this result to propose an extension to the statistical model of the gsim by compounding it with a hierarchy of subsampling model at multiple scale and iii we describe an extensive empirical evaluation of the method on over video sequence we first measure the degradation in performance of the original gsim algorithm a query sequence resolution is decreased and then show that the proposed extension produce an error reduction in the mean recognition rate of over 
