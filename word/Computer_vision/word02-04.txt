in this paper we describe a flexible approach for determining the relative orientation of the camera with respect to the scene the main premise of the approach is the fact that in man made environment the majority of line is aligned with the principal orthogonal direction of the world coordinate frame we exploit this observation towards ecient detection and estimation of vanishing point which provide strong constraint on camera parameter and relative orientation of the camera with respect to the scene by combining ecient image processing technique in the line detection and initialization stage we demonstrate that simultaneous grouping and estimation of vanishing direction can be achieved in the absence of internal parameter of the camera constraint between vanishing point are then used for partial calibration and relative rotation estimation the algorithm ha been tested in a variety of indoors and outdoors scene and it eciency and automation make it amenable for implementation on robotic platform 
we cast the problem of multiframe stereo reconstruction of a smooth surface a the global region segmentation of a collection of image of the scene dually the problem of segmenting multiple calibrated image of an object becomes that of estimating the solid shape that give rise to such image we assume that the radiance of the scene result in piecewise homogeneous image statistic this simplifying assumption cover lambertian scene with constant albedo a well a fine homogeneous texture which are known challenge to stereo algorithm based on local correspondence we pose the segmentation problem within a variational framework and use fast level set method to find the optimal solution numerically our algorithm doe not work in the presence of strong photometric feature where traditional reconstruction algorithm do it enjoys significant robustness to noise under the assumptiong it is designed for 
the problem considered in this paper is the fully asutomaticconstruction of panorama fundamentally thisproblem requires recognition a we need to know whichparts of the panorama join up previous approach haveused human input or restriction on the image sequencefor the matching step in this work we use object recognitiontechniques based on invariant local feature to selectmatchings image and a probabilistic model for verification because of this our method is insensitive to the ordering orientation scale and illumination of the image it is also insensitive to noise image which are not partof the panorama at all that is it recognises panorama this suggests a useful application for photographer thesystem take a input the image on an entire flash card orfilm recognises image that form part of a panorama andstitches them with no user input whatsoever 
helmholtz stereopsis ha been introduced recently a a surfacereconstruction technique that doe not assume a modelof surface reflectance in the reported formulation correspondencewas established using a rank constraint necessitatingat least three viewpoint and three pair of image here it is revealed that the fundamental helmholtz stereopsisconstraint defines a nonlinear partial differential equation which can be solved using only two image it is shownthat unlike conventional stereo binocular helmholtz stereopsisis able to establish correspondence and thereby recoversurface depth for object having an arbitrary andunknown brdf and in textureless region i e region ofconstant or slowly varying brdf an implementation andexperimental result validate the method for specular surfaceswith and without texture 
we report here on the problem of estimating a smooth planar curve t and it derivative from an ordered sample of interpolation point t t t i t i t m t m where t t t i t i t m t m t and the t i are not known precisely for i m such situtation may appear while searching for the boundary of planar object or tracking the mass center of a rigid body with no time available in this paper we assume that the distribution of t i coincides with more or le uniform sampling a fast algorithm yielding quartic convergence rate based on point piecewise quadratic interpolation is analysed and tested our algorithm form a substantial improvement with respect to the speed of convergence of piecewise point quadratic lagrange intepolation and some related work can be found in our result may be of interest in computer vision and digital image processing or computer graphic or approximation and complexity theory or and digital and computational geometry and 
sequential random sampling markov chain monte carlo is a popular strategy for many vision problem involving multimodal distribution over high dimensional parameter space it applies both to importance sampling where one want to sample point according to their importance for some calculation but otherwise fairly and toglobal optimization where one want to find good minimum or at least good starting point for local minimization regardless of fairness unfortunately most sequential sampler are very prone to becoming trapped for long period in unrepresentative local minimum which lead to biased or highly variable estimate we present a general strategy for reducing mcmc trapping that generalizes voter s hyperdynamic sampling from computational chemistry the local gradient and curvature of the input distribution are used to construct an adaptive importance sampler that focus sample on low cost negative curvature region likely to contain transition state codimension saddle point representing mountain pass connecting adjacent cost basin this substantially accelerates inter basin transition rate while still preserving correct relative transition probability experimental test on the difficult problem of d articulated human pose estimation from monocular image show significantly enhanced minimum exploration 
the multiple view geometry of static scene is now well understood recently attention wa turned to dynamic scene where scene point may move while the camera move the triangulation of linear trajectory is now well handled the case of quadratic trajectory also received some attention we present a complete generalization and address the problem of general trajectory triangulation of moving point from non synchronized camera our method is based on a particular representation of curve trajectory where a curve is represented by a family of hypersurfaces in the projective space this representation is linear even for highly non linear trajectory we show how this representation allows the recovery of the trajectory of a moving point from non synchronized sequence we show how this representation can be converted into a more standard representation we also show how one can extract directly from this representation the position of the moving point at each time instant an image wa made experiment on synthetic data and on real image demonstrate the feasibility of our approach 
in this paper we propose a novel approach for facialexpression decomposition higher order singular valuedecomposition hosvd a natural generalization ofmatrix svd we learn the expression subspace and personsubspace from a corpus of image showing seven basicfacial expression rather than resort to expert coded facialexpression parameter a in we propose a simultaneousface and facial expression recognition algorithm which can classify the given image into one of the sevenbasic facial expression category and then other facialexpressions of the new person can be synthesized using thelearned expression subspace model the contribution ofthis work lie mainly in two aspect first we propose a newhosvd based approach to model the mapping betweenpersons and expression used for facial expression synthesisfor a new person second we realize simultaneous faceand facial expression recognition a a result of facialexpression decomposition experimental result are presentedthat illustrate the capability of the person subspaceand expression subspace in both synthesis and recognitiontasks a a quantitative measure of the quality of synthesis we propose using gradient minimum square error gmse which measure the gradient difference between the originaland synthesized image 
existing autocalibration technique use numerical optimizationalgorithms that are prone to the problem of localminima to address this problem we have developeda method where an interval branch and bound method isemployed for numerical minimization thanks to the propertiesof interval analysis this method is guaranteed to convergeto the global solution with mathematical certainty andarbitrary accuracy and the only input information it requiresfrom the user is a set of point correspondence anda search box the cost function is based on the huang faugerasconstraint of the fundamental matrix a recentlyproposed interval extension based on bernstein polynomialforms ha been investigated to speed up the search for thesolution finally some experimental result on syntheticimages are presented 
texture can often more easily be described a a composition of subtextures than a a single texture the paper proposes a way to model and synthesize such composite texture where the layout of the different subtextures is itself modeled a a texture which can be generated automatically example are shown for building material with an intricate structure and for the automatic creation of landscape texture first a model of the composite texture is generated this procedure comprises manual or unsupervised texture segmentation to learn the spatial layout of the composite texture and the extraction of model for each of the subtextures synthesis of a composite texture includes the generation of a layout texture which is subsequently filled in with the appropriate subtextures this scheme is refined further by also including interaction between neighboring subtextures 
we address the problem of segmenting a sequence of imagesof natural scene into disjoint region that are characterizedby constant spatio temporal statistic we model thespatio temporal dynamic in each region by gauss markovmodels and infer the model parameter a well a theboundary of the region in a variational optimization framework numerical result demonstrate that in contrast topurely texture based segmentation scheme our method iseffective in segmenting region that differ in their dynamicseven when spatial statistic are identical 
we propose a new tracking technique that is able to capture non rigid motion by exploiting a space time rank constraint most tracking method use a prior model in order to deal with challenging local feature the model usually ha to be trained on carefully handlabeled example data before the tracking algorithm can be used our new model free tracking technique can overcome such limitation this can be achieved in redefining the problem instead of first training a model and then tracking the model parameter we are able to derive trajectory constraint first and then estimate the model this reduces the search space significantly and allows for a better feature disambiguation that would not be possible withtraditional tracker we demonstrate th at sampling in the trajectory space instead of in the space of shape configuration allows u to track challenging footage without use of prior model 
we show that a large and realistic face dataset can be built from news photograph and their associated caption our automatically constructed face dataset consists of face image obtained by applying a face nder to approximately half a million captioned news image and labeled using image information from the photograph and word information extracted from the corresponding caption this dataset is more realistic than usual face recognition datasets because it contains face captured in the wild in a variety of congurations with respect to the camera taking a variety of expression and under illumination of widely varying color face are extracted from the image and name with context are extracted from the associated caption our system us a clustering procedure to nd the correspondence between face and associated name in news picture caption pair the context in which a name appears in a caption provides powerful cue a to whether it is depicted in the associated image by incorporating simple natural language technique we are able to improve our name assignment signicantly we use two model of word context a naive bayes model and a maximum entropy model once our procedure is complete we have an accurately labeled set of face an appearance model for each individual depicted and a natural language model that can produce accurate result on caption in isolation 
many of the computer vision algorithm have been posed invariousforms of differential equation derived from minimization ofspecific energy functionals and the finite element representationand computation have become the de facto numerical strategy forsolving these problem however for case where domain mappingsbetween numerical iteration or image frame involve largegeometrical shape change such a deformable model for objectsegmentation and non rigid motion tracking these strategy mayexhibit considerable loss of accuracy when themesh element becomeextremely skewed or compressed we present a new computationalparadigm the meshfree particle method where the objectrepresentation and the numerical calculation are purely based onthe nodal point and do not require the meshing of the analysisdomain this meshfree strategy can naturally handle largedeformation and domain discontinuity issue and achieve desirednumerical accuracy through adaptive node and polynomial shapefunction refinement we discus in detail the element free galerkinmethod including the shape function construction using the movingleast square approximation and the galerkin weak form formulation and we demonstrate it application to deformable model basedsegmentation and mechanically motivated left ventricular motionanalysis 
we propose a principled account on multiclass spectral clustering given a discrete clustering formulation we first solve a relaxedcontinuous optimization problem by eigen decomposition we clarifythe role of eigenvectors a a generator of all optimal solutionsthrough orthonormal transforms we then solve an optimaldiscretization problem which seek a discrete solution closest tothe continuous optimum the discretization is efficiently computedin an iterative fashion using singular value decomposition andnon maximum suppression the resulting discrete solution arenearly global optimal our method is robust to randominitialization and converges faster than other clustering method experiment on real image segmentation are reported 
we present a novel framework for motion segmentation that combine the concept of layer based method and featurebased motion estimation we estimate the initial correspondence by comparing vector of filter output at interest point from which we compute candidate scene relation via random sampling of minimal subset of correspondence we achieve a dense piecewise smooth assignment of pixel to motion layer using a fast approximate graphcut algorithm based on a markov random field formulation we demonstrate our approach on image pair containing large inter frame motion and partial occlusion the approach is efficient and it successfully segment scene with inter frame disparity previously beyond the scope of layerbased motion segmentation method 
textons refer to fundamental micro structure in generic natural image and thus constitute the basic element in early preattentive visual perception however the word texton remains a vague concept in the literature of computer vision and visual perception and a precise mathematical definition ha yet to be found in this article we argue that the definition of texton should be governed by a sound mathematical model of image and the set of textons must be learned from or best tuned to an image ensemble we adopt a generative image model that an image is a superposition of base from an over complete dictionary then a texton is defined a a mini template that consists of a varying number of image base with some geometric and photometric configuration by analogy to physic if image base are like proton neutron and electron then textons are like atom then a small number of textons can be learned from training image a repeating micro structure we report four experiment for comparison the first experiment computes cluster in feature space of filter response the second use transformed component analysis in both feature space and image patch the third adopts a two layer generative model where an image is generated by image base and image base are generated by textons the fourth experiment show textons from motion image sequence which we call movetons 
an interesting and potentially useful vision graphic task is to render an input image in an enhanced form or also in an unusual style for example with increased sharpness or with some artistic quality in previous work researcher showed that by estimating the mapping from an input image to a registered aligned image of the same scene in a different style or resolution the mapping could be used to render a new input image in that style or resolution frequently a registered pair is not available but instead the user may have only a source image of an unrelated scene that contains the desired style in this case the task of inferring the output image is much more difficult since the algorithm must both infer correspondence between feature in the input image and the source image and infer the unknown mapping between the image we describe a bayesian technique for inferring the most likely output image the prior on the output image p x is a patch based markov random field obtained from the source image the likelihood of the input p y x is a bayesian network that can represent different rendering style we describe a computationally efficient probabilistic inference and learning algorithm for inferring the most likely output image and learning the rendering style we also show that current technique for image restoration or reconstruction proposed in the vision literature e g image super resolution or de noising and image based nonphotorealistic rendering could be seen a special case of our model we demonstrate our technique using several task including rendering a photograph in the artistic style of an unrelated scene de noising and texture transfer 
the problem we study is given n view and a subset of the interview fundamental matrix which of the other fundamental matrix can we compute using only the precomputed fundamental matrix this ha application in d reconstruction and when we want to reproject an area of one view on another or to compute epipolar line when the correspondence problem is too difficult to compute between every two view a complete solution using linear algorithm to compute the missing fundamental matrix is given for up to six view in many case problem with more than six view can also be handled 
we address the issue of regularizing osher and rudin s shock filter used for image deblurring in order to allow process that are more robust against noise previous solution to the problem suggested adding some sort of diffusion term to the shock equation we analyze and prove some property of coupled shock and diffusion process finally we propose an original solution of adding a complex diffusion term to the shock equation this new term is used to smooth out noise and indicate inflection point simultaneously the imaginary value which is an approximated smoothed second derivative scaled by time is used to control the process this result in a robust deblurring process that performs well also on noisy signal 
we consider the problem of segmentation of image that can bemodelled a piecewise continuous signal having unknown non stationary statistic we propose a solution to this problemwhich first us a regression framework to estimate the image pdf and then mean shift to find the mode of this pdf the segmentationfollows from mode identification wherein pixel cluster or imagesegments are identified with unique mode of the multi modal pdf each pixel is mapped to a mode using a convergent iterativeprocess the effectiveness of the approach depends upon theaccuracy of the implicit estimate of the underlying multi modaldensity function and thus on the bandwidth parameter used for itsestimate using parzen window automatic selection of bandwidthparameters is a desired feature of the algorithm we show that theproposed regression based model admits a realistic framework toautomatically choose bandwidth parameter which minimizes a globalerror criterion we validate the theory presented with result onreal image 
significant progress in image segmentation ha beenmade by viewing the problem in the framework of graphpartitioning in particular spectral clustering method suchas normalized cut ncuts can efficiently calculate goodsegmentations using eigenvector calculation however spectral method when applied to image with local connectivityoften oversegment homogenous region more importantly they lack a straightforward probabilistic interpretationwhich make it difficult to automatically set parametersusing training data in this paper we revisit the typical cut criterion proposedin we show that computing the typical cut isequivalent to performing inference in an undirected graphicalmodel this equivalence allows u to use the powerfulmachinery of graphical model for learning and inferringimage segmentation for inferring segmentation weshow that the generalized belief propagation gbp algorithmcan give excellent result with a runtime that is usuallyfaster than the ncut eigensolver for learning segmentationswe derive a maximum likelihood learning algorithmto learn affinity matrix from labelled datasets we illustrateboth learning and inference on challenging real andsynthetic image 
a new method for visual tracking of articulated objectsis presented analyzing articulated motion is challengingbecause the dimensionality increase potentially demandstremendous increase of computation to ease this problem we propose an approach that analyzes subpart locallywhile reinforcing the structural constraint at the meantime the computational model of the proposed approachis based on a dynamic markov network a generative modelwhich characterizes the dynamic and the image observationsof each individual subpart a well a the motion constraintsamong different subpart probabilistic variationalanalysis of the model reveals a mean field approximationto the posterior density of each subpart given visual evidence and provides a computationally efficient way forsuch a difficult bayesian inference problem in addition we design mean field monte carlo mfmc algorithm inwhich a set of low dimensional particle filter interact witheach other and solve the high dimensional problem collaboratively extensive experiment on tracking human bodyparts demonstrate the effectiveness significance and computationalefficiency of the proposed method 
this paper deal with the autocalibration of a systemthat consists of a planar screen multiple projector and acamera in the system either multiple projector or a singlemoving projector project pattern on a screen while a stationarycamera placed in front of the screen take image ofthe pattern we treat the case in which the pattern that theprojectors project toward space are assumed to be known i e the projector are calibrated whereas pose of theprojectors are unknown under these condition we considerthe problem of estimating screen to camera homographyfrom the image alone this is intended for case wherethere is no clue on the screen surface that enables directestimation of the screen to camera homography one applicationis a dof input device pose of a multi beamprojector freely moving in space are computed from the imagesof beam spot on the screen the primary contributionof the paper is theoretical result on the uniqueness of solutionsand a noniterative algorithm for the problem theeffectiveness of the method is shown by experimental resultson synthetic a well a on real image 
shape from shading sfs is a fundamental problem incomputer vision the vast majority of research in this fieldhave assumed orthography a it projection model thispaper re examines the basis of sfs the image irradianceequation under an assumption of perspective projection the paper also show that the perspective image irradianceequation depends merely on the natural logarithm of thedepth function and not on the depth function itself and assuch it is invariant to scale change of the depth function we then suggest a simple reconstruction algorithm basedon the perspective formula and compare it to existing orthographicsfs algorithm this simple algorithm obtainedlower error rate than legacy sfs algorithm and equatedwith and sometimes surpassed state of the art algorithm these finding lend support to the assumption that transitionto a more realistic set of assumption improves reconstructionsignificantly 
we demonstrate a novel approach to modelling arbitrary temporally deforming object using spatio temporal fourier descriptor this is a continuous boundary descriptor which can handle shape that vary in a periodic manner such a a walking subject a such we can handle non rigid moving shape that self occlude we show how this approach ha led to successful shape extraction and description with both laboratory sourced and real world data a consequence of exploiting temporal shape correlation in this approach ha led to very good tolerance of noise and other positive performance factor further to this our new approach hold sufficient descriptive power not only for extraction but also for description purpose and we have been pleased to note high recognition rate in human gait recognition on a large database 
previous work have demonstrated that the face recognitionperformance can be improved significantly in low dimensional linearsubspaces conventionally principal component analysis pca andlinear discriminant analysis lda are considered effective inderiving such a face subspace however both of them effectivelysee only the euclidean structure of face space in this paper wepropose a new approach to mapping face image into a sub spaceobtained by locality preserving projection lpp for faceanalysis we call this laplacian face approach different from pcaand lda lpp find an embedding that preserve local information and obtains a face space that best detects the essential manifoldstructure in this way the unwanted variation resulting fromchanges in lighting facial expression and pose may be eliminatedor reduced we compare the proposed laplacian face approach witheigenface and fisherface method on three test datasets experimental result show that the proposed laplacianface approachprovides a better representation and achieves lower error rate inface recognition 
we present two extension to the space carving framework the first is a progressive scheme to better reconstruct surface lacking sufficient texture the second is a novel photo consistency measure that is valid for both specular and diffuse surface under unknown lighting condition 
real scene are full of specularities highlight and reflection and yet most vision algorithm ignore them in order to capture the appearance of realistic scene we need to model specularities a separate layer in this paper we study the behavior of specularities in static scene a the camera move and describe their dependence on varying surface geometry orientation and scene point and camera location for a rectilinear camera motion with constant velocity we study how the specular motion deviate from a straight trajectory disparity deviation and how much it violates the epipolar constraint epipolar deviation surprisingly for surface that are convex or not highly undulating these deviation are usually quite small we also study the appearance of specularities i e how they interact with the body reflection and with the usual occlusion ordering constraint applicable to diffuse opaque layer we present a taxonomy of specularities based on their photometric property a a guide for designing separation technique finally we propose a technique to extract specularities a a separate layer and demonstrate it using an image sequence of a complex scene 
vision task such a segmentation grouping recognition can beformulated a graph partition problem the recent literaturewitnessed two popular graph cut algorithm the ncut using spectralgraph analysis and the minimum cut using the maximum flowalgorithm this paper present a third major approach bygeneralizing the swendsen wang methoda well celebrated algorithmin statistical mechanic our algorithm simulates ergodic reversible markov chain jump in the space of graph partition tosample a posterior probability at each step the algorithm split merges or re group a sizable subgraph and achieves fast mixingat low temperature enabling a fast annealing procedure experimentsshow it converges in second in a pc for image segmentation this is time faster than the single site update gibbs sampler and time faster than the ddmcmc algorithm the algorithm canoptimize over the number of model and work for general form ofposterior probability so it is more general than the existinggraph cut approach 
this paper introduces the concept of eigen dynamic andproposes an eigen dynamic analysis eda method to learnthe dynamic of natural hand motion from labelled set ofmotion captured with a data glove the result is parameterizedwith a high order stochastic linear dynamic system lds consisting of five lower order lds each correspondingto one eigen dynamic based on the eda model weconstruct a dynamic bayesian network dbn to analyzethe generative process of a image sequence of natural handmotion using the dbn a hand tracking system is implemented experiment on both synthesized and real worlddata demonstrate the robustness and effectiveness of thesetechniques 
uncertainty handling play an important role during shape tracking we have recently shown that the fusion of measurement information with system dynamic and shape prior greatly improves the tracking performance for very noisy image such a ultrasound sequence nevertheless this approach required user initialization of the tracking process this paper solves the automatic initialization problem by performing boosted shape detection a a generic measurement process and integrating it in our tracking framework we show how to propagate the local detection uncertainty of multiple shape candidate during shape alignment fusion with the predicted shape prior and fusion with subspace constraint a a result we treat all source of information in a unified way and derive the posterior shape model a the shape with the maximum likelihood our framework is applied for the automatic tracking of endocardium in ultrasound sequence of the human heart reliable detection and robust tracking result are achieved when compared to existing approach and interexpert variation 
this paper address the problem of computing visual hull from image contour we propose a new hybrid approach which overcomes the precision complexity trade off inherent to voxel based approach by taking advantage of surface based approach to this aim we introduce a space discretization which doe not rely on a regular grid where most cell are ineffective but rather on an irregular grid where sample point lie on the surface of the visual hull such a grid is composed of tetrahedral cell obtained by applying a delaunay triangulation on the sample point these cell are carved afterward according to image silhouette information the proposed approach keep the robustness of volumetric approach while drastically improving their precision and reducing their time and space complexity it thus allows modeling of object with complex geometry and it also make real time feasible for precise model preliminary result with synthetic and real data are presented 
this paper present a new linear method for reconstructing simultaneously d feature point line and plane and camera from many perspective view by solving a single linear system it assumes that a real or virtual reference plane is visible in all view we call it the direct reference plane drp method it is well knownthatthe projectionrelationship between uncalibrated camera and d feature is non linear in the absence of a reference plane with a known reference plane point and camera have a linear relationship a shown in the main contribution of this paper is that line and camera a well a plane and camera also have a linear relationship consequently all d feature and all camera can be reconstructed simultaneously from a single linear system which handle missing image measurement naturally a further contribution is an extensive experimental comparison using real data of different reference plane and non reference plane reconstruction method for difficult reference plane scenario with point or line feature the drp method is superior to all compared method finally an extensive list of reference plane scenario is presented which show the wide applicability of the drp method 
texture segmentation is a difficult problem a is apparentfrom camouflage picture a textured region can containtexture element of various size each of which can itselfbe textured we approach this problem using a bottom upaggregation framework that combine structural characteristicsof texture element with filter response our processadaptively identifies the shape of texture element and characterizethem by their size aspect ratio orientation brightness etc and then us various statistic of these propertiesto distinguish between different texture at the sametime our process us the statistic of filter response tocharacterize texture in our process the shape measuresand the filter response crosstalk extensively in addition a top down cleaning process is applied to avoid mixing thestatistics of neighboring segment we tested our algorithmon real image and demonstrate that it can accurately segmentregions that contain challenging texture 
we develop a fast and accurate variable window approach the two main idea for achieving accuracy are choosing a useful range of window size shape for evaluation and developing a new window cost which is particularly suitable for comparing window of different size the speed of our approach is due to the integral image technique which allows computation of our window cost over any rectangular window in constant time regardless of window size our method rank in the top four on the middlebury stereo database with ground truth and performs best out of method which have comparable efficiency 
in this paper we describe a flexible approach for determining the relative orientation of the camera with respect to the scene the main premise of the approach is the fact that in man made environment the majority of line is aligned with the principal orthogonal direction of the world coordinate frame we exploit this observation towards ecient detection and estimation of vanishing point which provide strong constraint on camera parameter and relative orientation of the camera with respect to the scene by combining ecient image processing technique in the line detection and initialization stage we demonstrate that simultaneous grouping and estimation of vanishing direction can be achieved in the absence of internal parameter of the camera constraint between vanishing point are then used for partial calibration and relative rotation estimation the algorithm ha been tested in a variety of indoors and outdoors scene and it eciency and automation make it amenable for implementation on robotic platform 
we cast the problem of multiframe stereo reconstruction of a smooth surface a the global region segmentation of a collection of image of the scene dually the problem of segmenting multiple calibrated image of an object becomes that of estimating the solid shape that give rise to such image we assume that the radiance of the scene result in piecewise homogeneous image statistic this simplifying assumption cover lambertian scene with constant albedo a well a fine homogeneous texture which are known challenge to stereo algorithm based on local correspondence we pose the segmentation problem within a variational framework and use fast level set method to find the optimal solution numerically our algorithm doe not work in the presence of strong photometric feature where traditional reconstruction algorithm do it enjoys significant robustness to noise under the assumptiong it is designed for 
the problem considered in this paper is the fully asutomaticconstruction of panorama fundamentally thisproblem requires recognition a we need to know whichparts of the panorama join up previous approach haveused human input or restriction on the image sequencefor the matching step in this work we use object recognitiontechniques based on invariant local feature to selectmatchings image and a probabilistic model for verification because of this our method is insensitive to the ordering orientation scale and illumination of the image it is also insensitive to noise image which are not partof the panorama at all that is it recognises panorama this suggests a useful application for photographer thesystem take a input the image on an entire flash card orfilm recognises image that form part of a panorama andstitches them with no user input whatsoever 
helmholtz stereopsis ha been introduced recently a a surfacereconstruction technique that doe not assume a modelof surface reflectance in the reported formulation correspondencewas established using a rank constraint necessitatingat least three viewpoint and three pair of image here it is revealed that the fundamental helmholtz stereopsisconstraint defines a nonlinear partial differential equation which can be solved using only two image it is shownthat unlike conventional stereo binocular helmholtz stereopsisis able to establish correspondence and thereby recoversurface depth for object having an arbitrary andunknown brdf and in textureless region i e region ofconstant or slowly varying brdf an implementation andexperimental result validate the method for specular surfaceswith and without texture 
we report here on the problem of estimating a smooth planar curve t and it derivative from an ordered sample of interpolation point t t t i t i t m t m where t t t i t i t m t m t and the t i are not known precisely for i m such situtation may appear while searching for the boundary of planar object or tracking the mass center of a rigid body with no time available in this paper we assume that the distribution of t i coincides with more or le uniform sampling a fast algorithm yielding quartic convergence rate based on point piecewise quadratic interpolation is analysed and tested our algorithm form a substantial improvement with respect to the speed of convergence of piecewise point quadratic lagrange intepolation and some related work can be found in our result may be of interest in computer vision and digital image processing or computer graphic or approximation and complexity theory or and digital and computational geometry and 
sequential random sampling markov chain monte carlo is a popular strategy for many vision problem involving multimodal distribution over high dimensional parameter space it applies both to importance sampling where one want to sample point according to their importance for some calculation but otherwise fairly and toglobal optimization where one want to find good minimum or at least good starting point for local minimization regardless of fairness unfortunately most sequential sampler are very prone to becoming trapped for long period in unrepresentative local minimum which lead to biased or highly variable estimate we present a general strategy for reducing mcmc trapping that generalizes voter s hyperdynamic sampling from computational chemistry the local gradient and curvature of the input distribution are used to construct an adaptive importance sampler that focus sample on low cost negative curvature region likely to contain transition state codimension saddle point representing mountain pass connecting adjacent cost basin this substantially accelerates inter basin transition rate while still preserving correct relative transition probability experimental test on the difficult problem of d articulated human pose estimation from monocular image show significantly enhanced minimum exploration 
the multiple view geometry of static scene is now well understood recently attention wa turned to dynamic scene where scene point may move while the camera move the triangulation of linear trajectory is now well handled the case of quadratic trajectory also received some attention we present a complete generalization and address the problem of general trajectory triangulation of moving point from non synchronized camera our method is based on a particular representation of curve trajectory where a curve is represented by a family of hypersurfaces in the projective space this representation is linear even for highly non linear trajectory we show how this representation allows the recovery of the trajectory of a moving point from non synchronized sequence we show how this representation can be converted into a more standard representation we also show how one can extract directly from this representation the position of the moving point at each time instant an image wa made experiment on synthetic data and on real image demonstrate the feasibility of our approach 
in this paper we propose a novel approach for facialexpression decomposition higher order singular valuedecomposition hosvd a natural generalization ofmatrix svd we learn the expression subspace and personsubspace from a corpus of image showing seven basicfacial expression rather than resort to expert coded facialexpression parameter a in we propose a simultaneousface and facial expression recognition algorithm which can classify the given image into one of the sevenbasic facial expression category and then other facialexpressions of the new person can be synthesized using thelearned expression subspace model the contribution ofthis work lie mainly in two aspect first we propose a newhosvd based approach to model the mapping betweenpersons and expression used for facial expression synthesisfor a new person second we realize simultaneous faceand facial expression recognition a a result of facialexpression decomposition experimental result are presentedthat illustrate the capability of the person subspaceand expression subspace in both synthesis and recognitiontasks a a quantitative measure of the quality of synthesis we propose using gradient minimum square error gmse which measure the gradient difference between the originaland synthesized image 
existing autocalibration technique use numerical optimizationalgorithms that are prone to the problem of localminima to address this problem we have developeda method where an interval branch and bound method isemployed for numerical minimization thanks to the propertiesof interval analysis this method is guaranteed to convergeto the global solution with mathematical certainty andarbitrary accuracy and the only input information it requiresfrom the user is a set of point correspondence anda search box the cost function is based on the huang faugerasconstraint of the fundamental matrix a recentlyproposed interval extension based on bernstein polynomialforms ha been investigated to speed up the search for thesolution finally some experimental result on syntheticimages are presented 
texture can often more easily be described a a composition of subtextures than a a single texture the paper proposes a way to model and synthesize such composite texture where the layout of the different subtextures is itself modeled a a texture which can be generated automatically example are shown for building material with an intricate structure and for the automatic creation of landscape texture first a model of the composite texture is generated this procedure comprises manual or unsupervised texture segmentation to learn the spatial layout of the composite texture and the extraction of model for each of the subtextures synthesis of a composite texture includes the generation of a layout texture which is subsequently filled in with the appropriate subtextures this scheme is refined further by also including interaction between neighboring subtextures 
we address the problem of segmenting a sequence of imagesof natural scene into disjoint region that are characterizedby constant spatio temporal statistic we model thespatio temporal dynamic in each region by gauss markovmodels and infer the model parameter a well a theboundary of the region in a variational optimization framework numerical result demonstrate that in contrast topurely texture based segmentation scheme our method iseffective in segmenting region that differ in their dynamicseven when spatial statistic are identical 
we propose a new tracking technique that is able to capture non rigid motion by exploiting a space time rank constraint most tracking method use a prior model in order to deal with challenging local feature the model usually ha to be trained on carefully handlabeled example data before the tracking algorithm can be used our new model free tracking technique can overcome such limitation this can be achieved in redefining the problem instead of first training a model and then tracking the model parameter we are able to derive trajectory constraint first and then estimate the model this reduces the search space significantly and allows for a better feature disambiguation that would not be possible withtraditional tracker we demonstrate th at sampling in the trajectory space instead of in the space of shape configuration allows u to track challenging footage without use of prior model 
we show that a large and realistic face dataset can be built from news photograph and their associated caption our automatically constructed face dataset consists of face image obtained by applying a face nder to approximately half a million captioned news image and labeled using image information from the photograph and word information extracted from the corresponding caption this dataset is more realistic than usual face recognition datasets because it contains face captured in the wild in a variety of congurations with respect to the camera taking a variety of expression and under illumination of widely varying color face are extracted from the image and name with context are extracted from the associated caption our system us a clustering procedure to nd the correspondence between face and associated name in news picture caption pair the context in which a name appears in a caption provides powerful cue a to whether it is depicted in the associated image by incorporating simple natural language technique we are able to improve our name assignment signicantly we use two model of word context a naive bayes model and a maximum entropy model once our procedure is complete we have an accurately labeled set of face an appearance model for each individual depicted and a natural language model that can produce accurate result on caption in isolation 
many of the computer vision algorithm have been posed invariousforms of differential equation derived from minimization ofspecific energy functionals and the finite element representationand computation have become the de facto numerical strategy forsolving these problem however for case where domain mappingsbetween numerical iteration or image frame involve largegeometrical shape change such a deformable model for objectsegmentation and non rigid motion tracking these strategy mayexhibit considerable loss of accuracy when themesh element becomeextremely skewed or compressed we present a new computationalparadigm the meshfree particle method where the objectrepresentation and the numerical calculation are purely based onthe nodal point and do not require the meshing of the analysisdomain this meshfree strategy can naturally handle largedeformation and domain discontinuity issue and achieve desirednumerical accuracy through adaptive node and polynomial shapefunction refinement we discus in detail the element free galerkinmethod including the shape function construction using the movingleast square approximation and the galerkin weak form formulation and we demonstrate it application to deformable model basedsegmentation and mechanically motivated left ventricular motionanalysis 
we propose a principled account on multiclass spectral clustering given a discrete clustering formulation we first solve a relaxedcontinuous optimization problem by eigen decomposition we clarifythe role of eigenvectors a a generator of all optimal solutionsthrough orthonormal transforms we then solve an optimaldiscretization problem which seek a discrete solution closest tothe continuous optimum the discretization is efficiently computedin an iterative fashion using singular value decomposition andnon maximum suppression the resulting discrete solution arenearly global optimal our method is robust to randominitialization and converges faster than other clustering method experiment on real image segmentation are reported 
we present a novel framework for motion segmentation that combine the concept of layer based method and featurebased motion estimation we estimate the initial correspondence by comparing vector of filter output at interest point from which we compute candidate scene relation via random sampling of minimal subset of correspondence we achieve a dense piecewise smooth assignment of pixel to motion layer using a fast approximate graphcut algorithm based on a markov random field formulation we demonstrate our approach on image pair containing large inter frame motion and partial occlusion the approach is efficient and it successfully segment scene with inter frame disparity previously beyond the scope of layerbased motion segmentation method 
textons refer to fundamental micro structure in generic natural image and thus constitute the basic element in early preattentive visual perception however the word texton remains a vague concept in the literature of computer vision and visual perception and a precise mathematical definition ha yet to be found in this article we argue that the definition of texton should be governed by a sound mathematical model of image and the set of textons must be learned from or best tuned to an image ensemble we adopt a generative image model that an image is a superposition of base from an over complete dictionary then a texton is defined a a mini template that consists of a varying number of image base with some geometric and photometric configuration by analogy to physic if image base are like proton neutron and electron then textons are like atom then a small number of textons can be learned from training image a repeating micro structure we report four experiment for comparison the first experiment computes cluster in feature space of filter response the second use transformed component analysis in both feature space and image patch the third adopts a two layer generative model where an image is generated by image base and image base are generated by textons the fourth experiment show textons from motion image sequence which we call movetons 
an interesting and potentially useful vision graphic task is to render an input image in an enhanced form or also in an unusual style for example with increased sharpness or with some artistic quality in previous work researcher showed that by estimating the mapping from an input image to a registered aligned image of the same scene in a different style or resolution the mapping could be used to render a new input image in that style or resolution frequently a registered pair is not available but instead the user may have only a source image of an unrelated scene that contains the desired style in this case the task of inferring the output image is much more difficult since the algorithm must both infer correspondence between feature in the input image and the source image and infer the unknown mapping between the image we describe a bayesian technique for inferring the most likely output image the prior on the output image p x is a patch based markov random field obtained from the source image the likelihood of the input p y x is a bayesian network that can represent different rendering style we describe a computationally efficient probabilistic inference and learning algorithm for inferring the most likely output image and learning the rendering style we also show that current technique for image restoration or reconstruction proposed in the vision literature e g image super resolution or de noising and image based nonphotorealistic rendering could be seen a special case of our model we demonstrate our technique using several task including rendering a photograph in the artistic style of an unrelated scene de noising and texture transfer 
the problem we study is given n view and a subset of the interview fundamental matrix which of the other fundamental matrix can we compute using only the precomputed fundamental matrix this ha application in d reconstruction and when we want to reproject an area of one view on another or to compute epipolar line when the correspondence problem is too difficult to compute between every two view a complete solution using linear algorithm to compute the missing fundamental matrix is given for up to six view in many case problem with more than six view can also be handled 
we address the issue of regularizing osher and rudin s shock filter used for image deblurring in order to allow process that are more robust against noise previous solution to the problem suggested adding some sort of diffusion term to the shock equation we analyze and prove some property of coupled shock and diffusion process finally we propose an original solution of adding a complex diffusion term to the shock equation this new term is used to smooth out noise and indicate inflection point simultaneously the imaginary value which is an approximated smoothed second derivative scaled by time is used to control the process this result in a robust deblurring process that performs well also on noisy signal 
we consider the problem of segmentation of image that can bemodelled a piecewise continuous signal having unknown non stationary statistic we propose a solution to this problemwhich first us a regression framework to estimate the image pdf and then mean shift to find the mode of this pdf the segmentationfollows from mode identification wherein pixel cluster or imagesegments are identified with unique mode of the multi modal pdf each pixel is mapped to a mode using a convergent iterativeprocess the effectiveness of the approach depends upon theaccuracy of the implicit estimate of the underlying multi modaldensity function and thus on the bandwidth parameter used for itsestimate using parzen window automatic selection of bandwidthparameters is a desired feature of the algorithm we show that theproposed regression based model admits a realistic framework toautomatically choose bandwidth parameter which minimizes a globalerror criterion we validate the theory presented with result onreal image 
significant progress in image segmentation ha beenmade by viewing the problem in the framework of graphpartitioning in particular spectral clustering method suchas normalized cut ncuts can efficiently calculate goodsegmentations using eigenvector calculation however spectral method when applied to image with local connectivityoften oversegment homogenous region more importantly they lack a straightforward probabilistic interpretationwhich make it difficult to automatically set parametersusing training data in this paper we revisit the typical cut criterion proposedin we show that computing the typical cut isequivalent to performing inference in an undirected graphicalmodel this equivalence allows u to use the powerfulmachinery of graphical model for learning and inferringimage segmentation for inferring segmentation weshow that the generalized belief propagation gbp algorithmcan give excellent result with a runtime that is usuallyfaster than the ncut eigensolver for learning segmentationswe derive a maximum likelihood learning algorithmto learn affinity matrix from labelled datasets we illustrateboth learning and inference on challenging real andsynthetic image 
a new method for visual tracking of articulated objectsis presented analyzing articulated motion is challengingbecause the dimensionality increase potentially demandstremendous increase of computation to ease this problem we propose an approach that analyzes subpart locallywhile reinforcing the structural constraint at the meantime the computational model of the proposed approachis based on a dynamic markov network a generative modelwhich characterizes the dynamic and the image observationsof each individual subpart a well a the motion constraintsamong different subpart probabilistic variationalanalysis of the model reveals a mean field approximationto the posterior density of each subpart given visual evidence and provides a computationally efficient way forsuch a difficult bayesian inference problem in addition we design mean field monte carlo mfmc algorithm inwhich a set of low dimensional particle filter interact witheach other and solve the high dimensional problem collaboratively extensive experiment on tracking human bodyparts demonstrate the effectiveness significance and computationalefficiency of the proposed method 
this paper deal with the autocalibration of a systemthat consists of a planar screen multiple projector and acamera in the system either multiple projector or a singlemoving projector project pattern on a screen while a stationarycamera placed in front of the screen take image ofthe pattern we treat the case in which the pattern that theprojectors project toward space are assumed to be known i e the projector are calibrated whereas pose of theprojectors are unknown under these condition we considerthe problem of estimating screen to camera homographyfrom the image alone this is intended for case wherethere is no clue on the screen surface that enables directestimation of the screen to camera homography one applicationis a dof input device pose of a multi beamprojector freely moving in space are computed from the imagesof beam spot on the screen the primary contributionof the paper is theoretical result on the uniqueness of solutionsand a noniterative algorithm for the problem theeffectiveness of the method is shown by experimental resultson synthetic a well a on real image 
shape from shading sfs is a fundamental problem incomputer vision the vast majority of research in this fieldhave assumed orthography a it projection model thispaper re examines the basis of sfs the image irradianceequation under an assumption of perspective projection the paper also show that the perspective image irradianceequation depends merely on the natural logarithm of thedepth function and not on the depth function itself and assuch it is invariant to scale change of the depth function we then suggest a simple reconstruction algorithm basedon the perspective formula and compare it to existing orthographicsfs algorithm this simple algorithm obtainedlower error rate than legacy sfs algorithm and equatedwith and sometimes surpassed state of the art algorithm these finding lend support to the assumption that transitionto a more realistic set of assumption improves reconstructionsignificantly 
we demonstrate a novel approach to modelling arbitrary temporally deforming object using spatio temporal fourier descriptor this is a continuous boundary descriptor which can handle shape that vary in a periodic manner such a a walking subject a such we can handle non rigid moving shape that self occlude we show how this approach ha led to successful shape extraction and description with both laboratory sourced and real world data a consequence of exploiting temporal shape correlation in this approach ha led to very good tolerance of noise and other positive performance factor further to this our new approach hold sufficient descriptive power not only for extraction but also for description purpose and we have been pleased to note high recognition rate in human gait recognition on a large database 
previous work have demonstrated that the face recognitionperformance can be improved significantly in low dimensional linearsubspaces conventionally principal component analysis pca andlinear discriminant analysis lda are considered effective inderiving such a face subspace however both of them effectivelysee only the euclidean structure of face space in this paper wepropose a new approach to mapping face image into a sub spaceobtained by locality preserving projection lpp for faceanalysis we call this laplacian face approach different from pcaand lda lpp find an embedding that preserve local information and obtains a face space that best detects the essential manifoldstructure in this way the unwanted variation resulting fromchanges in lighting facial expression and pose may be eliminatedor reduced we compare the proposed laplacian face approach witheigenface and fisherface method on three test datasets experimental result show that the proposed laplacianface approachprovides a better representation and achieves lower error rate inface recognition 
we present two extension to the space carving framework the first is a progressive scheme to better reconstruct surface lacking sufficient texture the second is a novel photo consistency measure that is valid for both specular and diffuse surface under unknown lighting condition 
real scene are full of specularities highlight and reflection and yet most vision algorithm ignore them in order to capture the appearance of realistic scene we need to model specularities a separate layer in this paper we study the behavior of specularities in static scene a the camera move and describe their dependence on varying surface geometry orientation and scene point and camera location for a rectilinear camera motion with constant velocity we study how the specular motion deviate from a straight trajectory disparity deviation and how much it violates the epipolar constraint epipolar deviation surprisingly for surface that are convex or not highly undulating these deviation are usually quite small we also study the appearance of specularities i e how they interact with the body reflection and with the usual occlusion ordering constraint applicable to diffuse opaque layer we present a taxonomy of specularities based on their photometric property a a guide for designing separation technique finally we propose a technique to extract specularities a a separate layer and demonstrate it using an image sequence of a complex scene 
vision task such a segmentation grouping recognition can beformulated a graph partition problem the recent literaturewitnessed two popular graph cut algorithm the ncut using spectralgraph analysis and the minimum cut using the maximum flowalgorithm this paper present a third major approach bygeneralizing the swendsen wang methoda well celebrated algorithmin statistical mechanic our algorithm simulates ergodic reversible markov chain jump in the space of graph partition tosample a posterior probability at each step the algorithm split merges or re group a sizable subgraph and achieves fast mixingat low temperature enabling a fast annealing procedure experimentsshow it converges in second in a pc for image segmentation this is time faster than the single site update gibbs sampler and time faster than the ddmcmc algorithm the algorithm canoptimize over the number of model and work for general form ofposterior probability so it is more general than the existinggraph cut approach 
this paper introduces the concept of eigen dynamic andproposes an eigen dynamic analysis eda method to learnthe dynamic of natural hand motion from labelled set ofmotion captured with a data glove the result is parameterizedwith a high order stochastic linear dynamic system lds consisting of five lower order lds each correspondingto one eigen dynamic based on the eda model weconstruct a dynamic bayesian network dbn to analyzethe generative process of a image sequence of natural handmotion using the dbn a hand tracking system is implemented experiment on both synthesized and real worlddata demonstrate the robustness and effectiveness of thesetechniques 
uncertainty handling play an important role during shape tracking we have recently shown that the fusion of measurement information with system dynamic and shape prior greatly improves the tracking performance for very noisy image such a ultrasound sequence nevertheless this approach required user initialization of the tracking process this paper solves the automatic initialization problem by performing boosted shape detection a a generic measurement process and integrating it in our tracking framework we show how to propagate the local detection uncertainty of multiple shape candidate during shape alignment fusion with the predicted shape prior and fusion with subspace constraint a a result we treat all source of information in a unified way and derive the posterior shape model a the shape with the maximum likelihood our framework is applied for the automatic tracking of endocardium in ultrasound sequence of the human heart reliable detection and robust tracking result are achieved when compared to existing approach and interexpert variation 
this paper address the problem of computing visual hull from image contour we propose a new hybrid approach which overcomes the precision complexity trade off inherent to voxel based approach by taking advantage of surface based approach to this aim we introduce a space discretization which doe not rely on a regular grid where most cell are ineffective but rather on an irregular grid where sample point lie on the surface of the visual hull such a grid is composed of tetrahedral cell obtained by applying a delaunay triangulation on the sample point these cell are carved afterward according to image silhouette information the proposed approach keep the robustness of volumetric approach while drastically improving their precision and reducing their time and space complexity it thus allows modeling of object with complex geometry and it also make real time feasible for precise model preliminary result with synthetic and real data are presented 
this paper present a new linear method for reconstructing simultaneously d feature point line and plane and camera from many perspective view by solving a single linear system it assumes that a real or virtual reference plane is visible in all view we call it the direct reference plane drp method it is well knownthatthe projectionrelationship between uncalibrated camera and d feature is non linear in the absence of a reference plane with a known reference plane point and camera have a linear relationship a shown in the main contribution of this paper is that line and camera a well a plane and camera also have a linear relationship consequently all d feature and all camera can be reconstructed simultaneously from a single linear system which handle missing image measurement naturally a further contribution is an extensive experimental comparison using real data of different reference plane and non reference plane reconstruction method for difficult reference plane scenario with point or line feature the drp method is superior to all compared method finally an extensive list of reference plane scenario is presented which show the wide applicability of the drp method 
texture segmentation is a difficult problem a is apparentfrom camouflage picture a textured region can containtexture element of various size each of which can itselfbe textured we approach this problem using a bottom upaggregation framework that combine structural characteristicsof texture element with filter response our processadaptively identifies the shape of texture element and characterizethem by their size aspect ratio orientation brightness etc and then us various statistic of these propertiesto distinguish between different texture at the sametime our process us the statistic of filter response tocharacterize texture in our process the shape measuresand the filter response crosstalk extensively in addition a top down cleaning process is applied to avoid mixing thestatistics of neighboring segment we tested our algorithmon real image and demonstrate that it can accurately segmentregions that contain challenging texture 
we develop a fast and accurate variable window approach the two main idea for achieving accuracy are choosing a useful range of window size shape for evaluation and developing a new window cost which is particularly suitable for comparing window of different size the speed of our approach is due to the integral image technique which allows computation of our window cost over any rectangular window in constant time regardless of window size our method rank in the top four on the middlebury stereo database with ground truth and performs best out of method which have comparable efficiency 
in this paper we propose a novel method to recover thesurface shape of transparent object the degree of polarizationof the light reflected from the object surface dependson the reflection angle which in turn depends on the object ssurface normal thus by measuring the degree of polarization we are able to calculate the surface normal of theobject however degree of polarization and surface normaldoes not correspond one to one making u to analyze twopolarization image taken from two different view in orderto solve the ambiguity a parabolic curve will be a strongclue to correspond a point in one image to a point in theother image where both point represent the same point onobject surface by comparing the degree of polarization atsuch corresponding point the true surface normal can bedetermined 
this paper present a framework to reconstruct a scenecaptured in multiple camera view based on a prior modelof the scene geometry the framework is applied to thecapture of animated model of people a multiple camerastudio is used to simultaneously capture a moving personfrom multiple viewpoint a humanoid computer graphicsmodel is animated to match the pose at each time frame constrained optimisation is then used to recover the multipleview correspondence from silhouette stereo and featurecues updating the geometry and appearance of the model the key contribution of this paper is a model based computervision framework for the reconstruction of shape andappearance from multiple view this is compared to currentmodel free approach for multiple view scene capture the technique demonstrates improved scene reconstructionin the presence of visual ambiguity and providesthe mean to capture a dynamic scene with a consistentmodel that is instrumented with an animation structure toedit the scene dynamic or to synthesise new content 
our paper address the problem of enforcing constraint in human body tracking a projection technique is derived to impose kinematic constraint on independent multibody motion we show that for small motion the multibody articulated motion space can be approximated by a linear manifold estimated directly from the previous body pose we propose a learning approach to model nonlinear constraint we train a support vector classifier from motion capture data to model the boundary of the space of valid pose linear and nonlinear body pose constraint are enforced by first projecting unconstrained motion onto the articulated motion space and then optimizing to find point on this linear manifold that lie within the non linear constraint surface modeled by the svm classifier 
color based tracker recently proposed in have been proved robust and versatile for a modest computational cost they are especially appealing for tracking task where the spatial structure of the tracked object exhibit such a dramatic variability that tracker based on a space dependent appearance reference would break down very fast tracker in rely on the deterministic search of a window whose color content match a reference histogram color model relying on the same principle of color histogram distance but within a probabilistic framework we introduce a new monte carlo tracking technique the use of a particle filter allows u to better handle color clutter in the background a well a complete occlusion of the tracked entity over a few frame this probabilistic approach is very flexible and can be extended in a number of useful way in particular we introduce the following ingredient multi part color modeling to capture a rough spatial layout ignored by global histogram incorporation of a background color model when relevant and extension to multiple object 
we consider image texture due to the illumination of d surface corrugation on globally smooth curved surface the same surface corrugation give rise to different image texture depending on illumination and viewing geometry we study surface that are on the average approximately lambertian the surface roughness give rise to luminance modulation of the global shading pattern the extreme value of the luminance depend on simple geometrical factor such a whether surface micro facet exist that squarely face the light source or are in shadow we find that a simple microfacet based model suffices to describe texture in natural scene robustly in a semi quantitative manner robust statistical measure of the texture yield the parameter for simple model that allow prediction of the brdf thus texture analysis allows the input parameter for inverse renderingand material recognition to be estimated 
we present a fast robust and automatic method for computing central path through tubular structure for application to virtual endoscopy the key idea is to utilize a medial surface algorithm which exploit property of the average outward flux of the gradient vector field of a euclidean distance function the boundary of the structure of interest the algorithm is modified to yield a collection of d curve each of which is locally centered the approach requires no user interaction is virtually parameter free and ha low computational complexity we illustrate the approach on segmented colon and vessel data 
we present propagation network p net a novel approach for representing and recognizing sequential activity that include parallel stream of action we represent each activity using partially ordered interval each interval is restricted by both temporal and logical constraint including information about it duration and it temporal relationship with other interval p net associate one node with each temporal interval each node is triggered according to a probability density function that depends on the state of it parent node each node also ha an associated observation function that characterizes supporting perceptual evidence to facilitate realtime analysis we introduce a particle filter framework to explore the conditional state space we modify the original condensation algorithm to more efficiently sample a discrete state space d condensation experiment in the domain of blood glucose monitor calibration demonstrate both the representational power of p net and the effectiveness of the d condensation algorithm 
we present a novel non parametric unsupervised segmentationalgorithm based on region competition but implemented within a level set framework thekey novelty of the algorithm is that it can solve n classsegmentation problem using just one embedded surface this is achieved by controlling the merging and splitting behaviourof the level set according to a minimum descriptionlength mdl cost function this is in contrastto n class region based level set segmentation method todate which operate by evolving multiple coupled embeddedsurfaces in parallel furthermore it operates inan unsupervised manner it is necessary neither to specifythe value of n nor the class model a priori we argue that the level set methodology provides amore convenient framework for the implementation of theregion competition algorithm which is conventionally implementedusing region membership array due to the lackof a intrinsic curve representation finally we generalisethe gaussian region model used in standard region competitionto the non parametric case the region boundary motionand merge equation become simple expression containingcross entropy and entropy term 
computing reflective symmetry of d and d shape is a classical problem in computer vision and computational geometry most prior work ha focused on finding the main ax of symmetry or determining that none exists in this paper we introduce a new reflective symmetry descriptor that represents a measure of reflective symmetry for an arbitrary d voxel model for all plane through the model s center of mass even if they are not plane of symmetry the main benefit of this new shape descriptor are that it is defined over a canonical parameterization the sphere and describes global property of a d shape using fourier method our algorithm computes the symmetry descriptor in time for an voxel grid and computes a multiresolution approximation in time in our initial experiment we have found the symmetry descriptor to be useful for registration matching and classification of shape 
determining shape from stereo ha often been posed a a global minimization problem once formulated the minimization problem are then solved with a variety of algorithmic approach these approach include technique such a dynamic programming min cut and alpha expansion in this paper we show how an algorithmic technique that construct a discrete spatial minimal cost surface can be brought to bear on stereo global minimization problem this problem can then be reduced to a single min cut problem we use this approach to solve a new global minimization problem that naturally arises when solving for three camera trinocular stereo our formulation treat the three camera symmetrically while imposing a natural occlusion cost and uniqueness constraint 
determining shape from stereo ha often been posed a a global minimization problem once formulated the minimization problem are then solved with a variety of algorithmic approach these approach include technique such a dynamic programming min cut and alpha expansion in this paper we show how an algorithmic technique that construct a discrete spatial minimal cost surface can be brought to bear on stereo global minimization problem this problem can then be reduced to a single min cut problem we use this approach to solve a new global minimization problem that naturally arises when solving for three camera trinocular stereo our formulation treat the three camera symmetrically while imposing a natural occlusion cost and uniqueness constraint 
in video sequence processing shadow remains a major source of error for object segmentation traditional method of shadow removal are mainly based on colour difference thresholding between the background and current image the application of colour filter on mpeg or mjpeg image however is often erroneous a the chrominance information is significantly reduced due to compression in addition a the colour attribute of shadow and object are often very similar discrete thresholding cannot always provide reliable result this paper present a novel approach for adaptive shadow removal by incorporating four different filter in a neuro fuzzy framework the neurofuzzy classifier ha the ability of real time self adaptation and training and it performance ha been quantitatively assessed with both indoor and outdoor video sequence 
we present a novel method for inferring three dimensional shape froma collection of defocused image it is based on the observation that defocusedimages are the null space of certain linear operator that depend on the threedimensionalshape of the scene a well a on the optic of the camera unlike mostcurrent work based on inverting the imaging model to recover the quot deblurred quot imageand the shape of the scene we approach the problem from a new angle bycollecting a number of 
a large part of image processing involves the computation of significant point curve and area feature these can be defined a locus where absolute differential invariant of the image assume fiducial value taking spatial scale and intensity in a generic sense scale into account differential invariance implies a group of similarity or congruence these motion define the geometrical structure of image space classical euclidian invariant don t apply to image because image space is non euclidian we analyze image structure from first principle and construct the fundamental group of image space motion image space is a cayley klein geometry with one isotropic dimension the analysis lead to a principled definition of feature and the operator that define them 
recent progress in stereo algorithm performance is quickly outpacing the ability of existing stereo data set to discriminate among the best performing algorithm motivating the need for more challenging scene with accurate ground truth information this paper describes a method for acquiring high complexity stereo image pair with pixel accurate correspondence information using structured light unlike traditional range sensing approach our method doe not require the calibration of the light source and yield registered disparity map between all pair of camera and illumination projector we present new stereo data set acquired with our method and demonstrate their suitability for stereo algorithm evaluation our result are available at http www middlebury edu stereo 
this paper describes a set of representation of gait appearance feature for the purpose of person identification our gait representation ha two stage the first stage computes a set of image feature that are based on moment extracted from orthogonal view video silhouette of human walking motion the second stage applies three method of aggregating these image feature over time to create the gait sequence feature despite their simplicity the resulting gait sequence feature vector contain enough information to perform well on human identification we demonstrate the accuracy of recognition using gait video sequence collected over different day and time under varying lighting environment and explore the difference in the three time aggregation method for the purpose of recognition 
this paper present a novel solution to the illuminant estimationproblem the problem of how given an image of ascene taken under an unknown illuminant we can recoveran estimate of that light the work is founded on previousgamut mapping solution to the problem which solvefor a scene illuminant by determining the set of diagonalmappings which take image data captured under an unknownlight to a gamut of reference colour taken undera known light unfortunately a diagonal model is not alwaysa valid model of illumination change and so previousapproaches sometimes return a null solution in addition previous method are difficult to implement we addressthese problem by recasting the problem a one ofilluminant classification we define a prioria set of plausiblelights thus ensuring that a scene illuminant estimatewill always be found a plausible light is represented bythe gamut of colour observable under it and the illuminantin an image is classified by determining the plausible lightwhose gamut is most consistent with the image data weshow that this step the main computational burden of thealgorithm can be performed simply quickly and efficientlyby mean of a non negative least square optimisation wereport result on a large set of real image which show thatit provides excellent illuminant estimation outperformingprevious algorithm 
we present a model based method for accurate extraction of pedestrian silhouette from video sequence our approach is based on two assumption there is a common appearance to all pedestrian and each individual look like him herself over a short amount of time these assumption allow u to learn pedestrian model that encompass both a pedestrian population appearance and the individual appearance variation using our model we are able to produce pedestrian silhouette that have fewer noise pixel and missing part we apply our silhouette extraction approach to the nist gait data set and show that under the gait recognition task our model based silhouette result in much higher recognition rate than silhouette directly extracted from background subtraction or any nonmodel based smoothing scheme 
local image feature or interest point provide compact andabstract representation of pattern in an image in this paper wepropose to extend the notion of spatial interest point into thespatio temporal domain and show how the resulting feature oftenreflect interesting event that can be used for a compactrepresentation of video data a well a for it interpretation todetect spatio temporal event we build on the idea of the harrisand f rstner interest point operator and detect localstructures in space time where the image value have significantlocal variation in both space and time we then estimate thespatio temporal extent of the detected event and compute theirscale invariant spatio temporal descriptor using suchdescriptors we classify event and construct video representationin term of labeled space time point for the problem of humanmotion analysis we illustrate how the proposed method allows fordetection of walking people in scene with occlusion and dynamicback ground 
we study the problem of object in particular face recognition under varying imaging condition object are represented using local characteristic feature called textons appearance variation due to changing condition are encoded by the correlation between the textons we propose two solution to model these correlation the first one assumes locational independence we call it the conditional texton distribution model the second capture the second order variation across location using fisher linear discriminant analysis we call it the fisher texton model our two model are effective in the problem of face recognition from a single image across a wide range of illumination pose and time 
in many vision problem the observed data lie in a nonlinear manifold in a high dimensional space this paper present a generic modelling scheme to characterize the nonlinear structure of the manifold and to learn it multimodal distribution our approach represents the data a a linear combination of parameterized local component where the statistic of the component parameterization describe the nonlinear structure of the manifold the component are adaptively selected from the training data through a progressive density approximation procedure which lead to the maximum likelihood estimate of the underlying density we show result on both synthetic and real training set and demonstrate that the proposed scheme ha the ability to reveal important structure of the data 
recognition system have generally treated specular highlightsas noise we show how to use these highlight asa positive source of information that improves recognitionof shiny object this also enables u to recognize verychallenging shiny transparent object such a wine glass specifically we show how to find highlight that are consistentwith an hypothesized pose of an object of known dshape we do this using only a qualitative description ofhighlight formation that is consistent with most model ofspecular reflection so no specific knowledge of an object sreflectance property is needed we first present a methodthat find highlight produced by a dominant compact lightsource whose position is roughly known we then show howto estimate the lighting automatically for object whose reflectionis part specular and part lambertian we demonstratethis method for two class of object first we showthat specular information alone can suffice to identify objectswith no lambertian reflectance such a transparentwine glass second we use our complete system to recognizeshiny object such a pottery 
abstract principal component analysis pca ha been successfully applied to construct linear model of shape graylevel and motion in particular pca ha been widely used to model the variation in the appearance of people s face we extend previous work on facial modeling for tracking face in video sequence a they undergo significant change due to facial expression here we develop person specific facial appearance model psfam which use modular pca to model complex intra person appearance change such model require aligned vi sual training data in previous work this ha involved a time consuming and error prone hand alignment and cropping process instead we introduce parameterized component analysis to learn a subspace that is invariant to affine or higher order geometric transformation the automatic learning of a psfam given a training image sequence is posed a a continuous optimization problem and is solved with a mixture of stochastic and deterministic technique achieving sub pixel accuracy we illustrate the use of the d psfam model with several application including video conferencing realistic avatar animation and eye tracking 
abstract projection matrix from projective space p and method for extracting the non rigid structure and motion for each application keywords dynamic structure from motion multiple view geometry multi linear constraint 
we introduce a new type of local feature based on the phase and amplitude response of complex valued steerable filter the design of this local feature is motivated by a desire to obtain feature vector which are semi invariant under common image deformation yet distinctive enough to provide useful identity information a recent proposal for such local feature involves combining differential invariant to particular image deformation such a rotation our approach differs in that we consider a wider class of image deformation including the addition of noise along with both global and local brightness variation we use steerable filter to make the feature robust to rotation and we exploit the fact that phase data is often locally stable with respect to scale change noise and common brightness change we provide empirical result comparing our local feature with one based on differential invariant the result show that our phase based local feature lead to better performance when dealing with common illumination change and d rotation while giving comparable effect in term of scale change 
this paper introduces a novel method for constructingand selecting scale invariant object part scale invariantlocal descriptor are first grouped into basic part a classifieris then learned for each of these part and featureselection is used to determine the most discriminative one this approach allows robust part detection and it is invariantunder scale change that is neither the training imagesnor the test image have to be normalized the proposed method is evaluated in car detectiontasks with significant variation in viewing condition andpromising result are demonstrated different local region classifier and feature selection method are quantitativelycompared our evaluation show that local invariantdescriptors are an appropriate representation for objectclasses such a car and it underline the importance offeature selection 
in the eye gaze tracking problem the goal is to determine where on a monitor screen a computer user is looking the gaze point existing system generally have one of two limitation either the head must remain fixed in front of a stationary camera or to allow for head motion the user must wear an obtrusive device we introduce a d eye tracking system where head motion is allowed without the need for marker or worn device we use a pair of stereo system a wide angle stereo system detects the face and steer an active narrow fov stereo system to track the eye at high resolution for high resolution tracking the eye is modeled in d including the corneal ball pupil and fovea in this paper we discus the calibration of the stereo system the eye model eye detection and tracking and we close with an evaluation of the accuracy of the estimated gaze point on the monitor 
multibody factorization algorithm give an elegant and simple solution to the problem of structure from motion even for scene containing multiple independent motion despite this elegance it is still quite difficult to apply these algorithm to arbitrary scene first their performance deteriorates rapidly with increasing noise second they cannot be applied unless all the point can be tracked in all the frame a will rarely happen in real scene third they cannot incorporate prior knowledge on the structure or the motion of the object in this paper we present a multibody factorization algorithm that can handle arbitrary noise covariance for each feature a well a missing data we show how to formulate the problem a one of factor analysis and derive an expectation maximization based maximum likelihood algorithm one of the advantage of our formulation is that we can easily incorporate prior knowledge including the assumption of temporal coherence we show that this assumption greatly enhances the robustness of our algorithm and present result on challenging sequence 
in this paper we show that efficient object recognition canbeobtained by combining informative feature with linearclassification the result demonstrate the superiority ofinformative class specific feature a compared with generic typefeatures such a wavelet for the task of object recognition weshow that information rich feature can reach optimal performancewith simple linear separation rule while generic feature basedclassifiers require more complex classification scheme this issignificant because efficient and optimal method have beendeveloped for space that allow linear separation to comparedifferent strategy for feature extraction we trained andcompared classifier working in feature space of the same lowdimensionality using two feature type image fragment v wavelet and two classification rule linear hyperplane and abayesian network the result show that by maximizing theindividual information of the feature it is possible to obtainefficient classification by a simple linear separating rule aswellas more efficient learning 
independent representation have recently attracted significant attention from the biological vision and cognitive science community it ha been argued that property such a sparseness and independence play a major role in visual perception and shown that imposing such property on visual representation originates receptive field similar to those found in human vision we present a study of the impact of feature independence in the performance of visual recognition architecture the contribution of this study are of both theoretical and empirical nature and support two main conclusion the first is that the intrinsic complexity of the recognition problem bayes error is higher for independent representation the increase can be significant close to in the database we considered the second is that criterion commonly used in independent component analysis are not sufficient to eliminate all the dependency that impact recognition in fact independent component can be le independent than previous representation such a principal component or wavelet base 
generating vehicle trajectory from video data is an important application of it intelligent transportation system we introduce a new tracking approach which us model based d vehicle detection and description algorithm our vehicle detection and description algorithm is based on a probabilistic line feature grouping and it is faster by up to an order of magnitude and more flexible than previous image based algorithm we present the system implementation and the vehicle detection and tracking result 
edge in man made environment grouped according to vanishing point direction provide single view constraint that have been exploited before a a precursor to both scene understanding and camera calibration a bayesian approach to edge grouping wa proposed in the manhattan world paper by coughlan and yuille where they assume the existence of three mutually orthogonal vanishing direction in the scene we extend the thread of work spawned by coughlan and yuille in several signicant way we propose to use the expectation maximization em algorithm to perform the search over all continuous parameter that inuence the location of the vanishing point in a scene because em behaves well in high dimensional space our method can optimize over many more parameter than the exhaustive and stochastic algorithm used previously for this task among other thing this let u optimize over multiple group of orthogonal vanishing direction each of which induces one additional degree of freedom em is also well suited to recursive estimation of the kind needed for image sequence and or in mobile robotics we present experimental result on image of atlanta world complex urban scene with multiple orthogonal edge group that validate our approach we also show result for continuous relative orientation estimation on a mobile robot 
magnetic resonance imaging mri is used in clinical routine to map the brain s morphology structural change due to brain growth aging surgical intervention or pathological process may be detected by image registration of time series imaging data to monitor structural change a three step approach is pursued here rigid registration and intensity matching of an initial reference and follow up mri scan a non rigid registration of the scan and the segmentation of the resulting displacement field cro correlation is used a a similarity measure for rigid registration non rigid registration is based on a fluid dynamical model the resulting displacement field are usually large and therefore hard to interpret for a simplified but sufficient description of such vector field contraction mapping is proposed to detect vector field singularity this enables the detection and analysis of singularity of any order a critical point which reflect the topology of the vector field an application demonstrates how this method help to increase the understanding of pathological process in the brain 
this paper describes a pde based method for densedepth extraction from multiple wide baseline image emphasislies on the usage of only a small amount of image the integration of these multiple wide baseline view isguided by the relative confidence that the system ha in thematching to different view this weighting is fine grainedin that it is determined for every pixel at every iteration reliable information spread fast at the expense of le reliabledata both in term of spatial communication withina view and in term of information exchange between theviews change in intensity between image can be handledin a similar fine grained fashion 
this paper study the inference of d shape from a set of n noisy photo we derive a probabilistic framework to specify what one can infer about d shape for arbitrarily shaped lambertian scene and arbitrary viewpoint configuration based on formal definition of visibility occupancy emptiness and photo consistency the theoretical development yield a formulation of the photo hull distribution the tightest probabilistic bound on the scene s true shape that can be inferred from the photo we show how to express this distribution in term of image measurement represent it compactly by assigning an occupancy probability to each point in space and design a stochastic reconstruction algorithm that draw fair sample i e d photo hull from it we also present experimental result for complex d scene 
the denoising of color image is an increasingly studied problem whose state of the art solution employ a variety of diffusion scheme specifying the correct diffusion is difficult however in part because of the subtlety of color interaction we address this difficulty by proposing a perceptual organization approach to color denoising based on the principle of good continuation we exploit the periodic chromatic hue component of the color in it representation a a frame field we derive two hue curvature and use them to construct a local model for the behavior of the color which in turn specifies consistency constraint between nearby color measurement these constraint are then used to replace noisy pixel by examining their spatial context such a contextual analysis combined with standard method to handle the scalar channel saturation and lightness result in a robust noise removal process that preserve discontinuity singularity and fine chromatic structure including those that diffusion process are prone to distort we demonstrate our approach on a variety of synthetic and natural image 
we model the dynamic geometry of a time varying scene a a d isosurface in space time the intersection of the isosurface with plane of constant time yield the geometry at a single time instant an optimal fit of our model to multiple video sequence is defined a the minimum of an energy functional this functional is given by an integral over the entire hypersurface which is designed to optimize photo consistency a pde based evolution derived from the euler lagrange equation maximizes consistency with all of the given video data simultaneously the result is a d model of the scene which varies smoothly over time the geometry reconstructed by this scheme is significantly better than result obtained by space carving approach that do not enforce temporal coherence 
nearest neighbor nn classification relies on the assumption that class conditional probability are locally constant this assumption becomes false in high dimension with finite sample due to the curse of dimensionality the nn rule introduces severe bias under these condition we propose a locally adaptive neighborhood morphing classification method to try to minimize bias we use local support vector machine learning to estimate an effective metric for producing neighborhood that are elongated along le discriminant feature dimension and constricted along most discriminant one a a result the class conditional probability can be expected to be approximately constant in the modified neighborhood whereby better classification performance can be achieved the efficacy of our method is validated and compared against other competing technique using a number of datasets 
we introduce a novel approach to modeling the dynamic of human facial motion induced by the action of speech for the purpose of synthesis we represent the trajectory of a number of salient feature on the human face a the output of a dynamical system made up of two subsystem one driven by the deterministic speech input and a second driven by an unknown stochastic input inference of the model learning is performed automatically and involves an extension of independent component analysis to time depentend data using a shapetexture decompositional representation for the face we generate facial image sequence reconstructed from synthesized feature point position 
in this paper a new camera calibration algorithm is proposed which is from the quasi affine invariance of two parallel circle two parallel circle here mean two circle in one plane or in two parallel plane they are quite common in our life between two parallel circle and their image under a perspective projection we set up a quasi affine invariance especially if their image under a perspective projection are separate we find out an interesting distribution of the image and the virtual intersection of the image and prove that it is a quasi affine invariance the quasi affine invariance is very useful which is applied to identify the image of circular point after the image of the circular point are identified linear equation on the intrinsic parameter are established from which a camera calibration algorithm is proposed we perform both simulated and real experiment to verify it the result validate this method and show it accuracy and robustness compared with the method in the past literature the advantage of this calibration method are it is from parallel circle with minimal number it is simple by virtue of the proposed quasi affine invariance it doe not need any matching excepting it application on camera calibration the proposed quasiaffine invariance can also be used to remove the ambiguity of recovering the geometry of single axis motion by conic fitting method in and in the two literature three conic are needed to remove the ambiguity of their method while two conic are enough to remove it if the two conic are separate and the quasi affine invariance proposed by u is taken into account 
we address the problem of camera motion and structurereconstruction from line correspondence across multiple view from initialization to final bundle adjustment one of the maindifficulties when dealing with line feature is their algebraicrepresentation first we consider the triangulation problem basedon pl cker coordinate to represent the line we propose amaximum likelihood algorithm relying on linearising thepl cker constraint and on a pl cker correction procedureto compute the closest pl cker coordinate to a given vector second we consider the bundle adjustment problem previous overparameterizations of d line induce gauge freedomsand or internal consistency constraint we propose the orthonormalrepresentation which allows handy non linear optimization of dlines using the minimum parameter within an unconstrainednon linear optimizer we compare our algorithm to existing one onsimulated and real data 
the body of work on multi body factorization separate between object whose motion are independent in this work we show that in many case object moving with different d motion will be captured a a single object using these approach we analyze what cause these degeneracy between object and suggest an approach for overcoming some of them we further show that in the case of multiple sequence linear dependency can supply information for temporal synchronization of sequence and for spatial matching of point across sequence 
this paper present a framework for finding point correspondencesin monocular image sequence over multiple frame the generalproblem of multi frame point correspondence is np hard for three ormore frame a polynomial time algorithm for a restriction of thisproblem is presented and is used a the basis of proposed greedyalgorithm for the general problem the greedy nature of theproposed algorithm allows it to be used in real time system fortracking and surveillance etc in addition the proposed algorithmdeals with the problem of occlusion missed detection and falsepositives by using a single non iterative greedy optimizationscheme and hence reduces the complexity of the overall algorithmas compared to most existing approach where multiple heuristicsare used for the same purpose while most greedy algorithm forpoint tracking do not allow for entry and exit of point from thescene this is not a limitation for the proposed algorithm experiment with real and synthetic data show that the proposedalgorithm outperforms the existing technique and is applicable inmore general setting 
abstract wepropose a computational model motivated by human cognitive process for detecting change of driving environment the model call dynamic visual model consists of three major component sensory perceptual and conceptual component the proposed model is used a the underlying framework in which a system for detecting and recognizing road sign is developed 
the perception of transparent object from image is knownto be a very hard problem in vision given a single image it is difficult to even detect the presence of transparent objectsin the scene in this paper we explore what can be saidabout transparent object by a moving observer we showhow feature that are imaged through a transparent objectbehave differently from those that are rigidly attached to thescene we present a novel model based approach to recoverthe shape and the pose of transparent object from knownmotion the object can be complex in that they may be composedof multiple layer with different refractive index wehave conducted numerous simulation to verify the practicalfeasibility of our algorithm we have applied it to real scenesthat include transparent object and recovered the shape ofthe object with high accuracy 
in this paper we study a family of analytical probability model for image within the spectral representation framework first the input image is decomposed using a bank of filter and probability model are imposed on the filter output or spectral component a two parameter analytical form called a bessel k form derived based on a generator model is used to model the marginal probability of these spectral component the bessel k parameter can be estimated efficiently from the filtered image and extensive simulation using video infrared and range image have demonstrated bessel k form s fit to the observed histogram the effectiveness of bessel k form is also demonstrated through texture modeling and synthesis in contrast to numeric based dimension reduction representation which are derived purely based on numerical method the bessel k representation are derived based on object representation and this enables u to establish relationship between the bessel parameter and certain characteristic of the imaged object we have derived a pseudometric on the image space to quantify image similarity difference using an analytical expression for l metric on the set of bessel k form we have applied the bessel k representation to texture modeling and synthesis clutter classification pruning of hypothesis for object recognition and object classification result show that bessel k representation capture important image feature suggesting it role in building efficient image understanding paradigm and system 
we aim to infer d body pose directly from human silhouette given a visual input silhouette the objective is to recover the intrinsic body configuration recover the view point reconstruct the input and detect any spatial or temporal outlier in order to recover intrinsic body configuration pose from the visual input silhouette we explicitly learn view based representation of activity manifold a well a learn mapping function between such central representation and both the visual input space and the d body pose space the body pose can be recovered in a closed form in two step by projecting the visual input to the learned representation of the activity manifold i e finding the point on the learned manifold representation corresponding to the visual input followed by interpolating d pose 
the bounded hough transform is introduced to track object in a sequence of sparse range image the method is based upon a variation of the general hough transform that exploit the coherence across image frame that result from the relationship between known bound on the object s velocity and the sensor frame rate it is extremely efficient running in o n for n range data point and effectively trade off localization precision for runtime efficiency the method ha been implemented and tested on a variety of object including freeform surface using both simulated and real data from lidar and stereovision sensor the motion bound allow the inter frame transformation space to be reduced to a reasonable and indeed small size containing only possible state in a variation the rotational subspace is projected onto the translational subspace which further reduces the transformation space to only state experimental result confirm that the technique work well with very sparse data possibly comprising only ten of point per frame and that it is also robust to measurement error and outlier 
graphical model are powerful tool for processing image however the large dimensionality of even local image data pose a difficulty representing the range of possible graphical model node variable with discrete state lead to an overwhelmingly large number of state for the model often making both exact and approximate inference computationally intractable we propose a representation that allows a small number of discrete state to represent the large number of possible image value at each pixel or local image patch each node in the graph represents the best regression function chosen from a set of candidate function for estimating the unobserved image pixel from the observed sample this permit a small number of discrete state to summarize the range of possible image value at each point in the image belief propagation is then used to find the best regressor to use at each point to demonstrate the usefulness of this technique we apply it to two problem super resolution and color demosaicing in both case we find our method compare well against other technique for these problem 
this paper address the problem of applying powerful patternrecognition algorithm based on kernel to efficient visualtracking recently avidan ha shown that object recognizersusing kernel svms can be elegantly adapted to localization by meansof spatial perturbation of the svm using optic flow whereasavidan s svm applies to each frame of a video independently ofother frame the benefit of temporal fusion of data are wellknown this issue is addressed here by using a fully probabilistic relevance vector machine rvm to generate observation withgaussian distribution that can be fused over time to improveperformance further rather than adapting a recognizer webuild alocalizer directly using the regression form of the rvm aclassification svm is used in tandem for object verification andthis provides the capability of automatic initialization andrecovery the approach is demonstrated in real time face andvehicle tracking system the sparsity of the rvms mean thatonly a fraction of cpu time is required to track at frame rate tracker output is demonstrated in a camera management task in whichzoom and pan are controlled inresponse to speaker vehicle positionand orientation over an extended period the advantage oftemporal fusion inthis system are demonstrated 
in this paper we describe an approach to recognizing location from mobile device using image based web search we demonstrate the usefulness of common image search metric applied on image captured with a camera equipped mobile device to find matching image on the world wide web or other general purpose database searching the entire web can be computationally overwhelming so we devise a hybrid image and keyword searching technique first image search is performed over image and link to their source web page in a database that index only a small fraction of the web then relevant keywords on these web page are automatically identified and submitted to an existing text based search engine e g google that index a much larger portion of the web finally the resulting image set is filtered to retain image close to the original query it is thus possible to efficiently search hundred of million of image that are not only textually related but also visually relevant we demonstrate our approach on an application allowing user to browse web page matching the image of a nearby location 
many problem in computer vision may be considered a low rank approximation problem in which a matrix of measured data must be approximated by a matrix of given low rank if the matrix ha no missing entry then this is easily accomplished by a singular value decomposition svd if some measurement are missing however and the matrix ha hole then the svd method can not be applied we present here a practical iterative method for approximating a data matrix possibly with missing entry with another matrix of small rank r for a complete data matrix the method reduces to the well known power method which is provably convergent to a unique global optimum if the data is well approximated by a matrix of rankr the power method ha rapid convergence our method for incomplete data is applied to several problem of d reconstruction generalizing the tomasi kanade method for orthographic camera and the sturm triggs method for projective camera to missing and uncertain data 
a unified approach for treating the scale selection problem in the anisotropic scale space is proposed the anisotropic scale space is a generalization of the classical isotropic gaussian scale space by considering the gaussian kernel with a fully parameterized analysis scale bandwidth matrix the maximum over scale and the moststable over scale criterion are constructed by employing the l normalized scale space derivative i e responsenormalized derivative in the anisotropic scale space this extension allows u to directly analyze the anisotropic ellipsoidal shape of local structure the main conclusion are i the norm of the a ndl normalized anisotropic scale space derivative with a constant are maximized regardless of the signal s dimension iff the analysis scale matrix is equal to the signal s covariance and ii the most stable over scale criterion with the isotropic scale space outperforms the maximum over scale criterion in the presence of noise experiment with d and d synthetic data confirm the above finding d implementation of the most stable over scale method are applied to the problem of estimating anisotropic spread of pulmonary tumor shown in high resolution computedtomography hrct image comparison of the firstand second order method show the advantage of exploiting the second order information 
we describe a tracker that can track moving people in long sequence without manual initialization moving people are modeled with the assumption that while configuration can vary quite substantially from frame to frame appearance doe not this lead to an algorithm that firstly build a model of the appearance of the body of each individual by clustering candidate body segment and then us this model to find all individual in each frame unusually the tracker doe not rely on a model of human dynamic to identify possible instance of people such model are unreliable because human motion is fast and large acceleration are common we show our tracking algorithm can be interpreted a a loopy inference procedure on an underlying bayes net experiment on video of real scene demonstrate that this tracker can a count distinct individual b identify and track them c recover when it loses track for example if individual are occluded or briefly leave the view d identify the configuration of the body largely correctly and e is not dependent on particular model of human motion 
the modal correspondence method of shapiro and brady aim to match point set by comparing the eigenvectors of a pairwise point proximity matrix although elegant by mean of it matrix representation the method is notoriously susceptible to difference in the relational structure of the point set under consideration in this paper we demonstrate how the method can be rendered robust to structural difference by adopting a hierarchical approach we place the modal matching problem in a probabilistic setting in which the correspondence between pairwise cluster can be used to constrain the individual point correspondence to meet this goal we commence by describing an iterative method which can be applied to the point proximity matrix to identify the location of pairwise modal cluster once we have assigned point to cluster we compute within cluster and between cluster proximity matrix the modal co efficients for these two set of proximity matrix are used to compute cluster correspondence and cluster conditional point correspondence probability a sensitivity study on synthetic point set reveals that the method is considerably more robust than the conventional method to clutter or point set contamination 
visual learning is expected to be a continuous and robustprocess which treat input image and pixel selectively in this paper we present a method for subspace learning which take these consideration into account wepresent an incremental method which sequentially updatesthe principal subspace considering weighted influence ofindividual image a well a individual pixel within an image this approach is further extended to enable determinationof consistency in the input data and imputation of thevalues in inconsistent pixel using the previously acquiredknowledge resulting in a novel incremental weighted androbust method for subspace learning 
estimation of camera pose from an image of n point or line with known correspondence is a thoroughly studied problem in computer vision most solution are iterative and depend on nonlinear optimization of some geometric constraint either on the world coordinate or on the projection to the image plane for real time application we are interested in linear or closed form solution free of initialization we present a general framework which allows for a novel set of linear solution to the pose estimation problem for both n point and n line we present a number of simulation which compare our result to two other recent linear algorithm a well a to iterative approach we conclude with test on real imagery in an augmented reality setup we also present an analysis of the sensitivity of our algorithm to image noise 
the context of this work is lateral vehicle control using a camera a a sensor a natural tool for controlling a vehicle is recursive filtering the well known kalman filtering theory relies on gaussian assumption on both the state and measure random variable however image processing algorithm yield measurement that most of the time are far from gaussian a experimentally shown on real data in our application it is therefore necessary to make the approach more robust leading to the so called robust kalman filtering in this paper we review this approach from a very global point of view adopting a constrained least square approach which is very similar to the half quadratic theory and justifies the use of iterative reweighted least square algorithm a key issue in robust kalman filtering is the choice of the prediction error covariance matrix unlike in the gaussian case it computation is not straightforward in the robust case due to the nonlinearity of the involved expectation we review the classical alternative and propose new one a theoretical study of these approximation is out of the scope of this paper however we do provide an experimental comparison on synthetic data perturbed with cauchy distributed noise 
the catchment feature model cfm address two question in multimodal interaction how do we bridge video and audio processing withthe reality of human multimodal communication and how information from the different mode may be fused we discus the need for our model motivate the cfm from psycholinguistic research andpresent the model in contrast to wholegesture recognition the cfm applies a feature decomposition approach that facilitates cross modal fusion at the level of discourse planningand conceptualization we present our experimental framework for cfm based research and cite three concrete example of catchment feature cf and propose new direction of multimodal research based on the model the importance of gesture of hand head face eyebrow eye and body posture in human communication in conjunction with speech is self evident hitherto visionbased gesture research ha by and large ignored the nexus of speech and other multimodal behavior even though such behavior underlies much of human gesture use the key and yet unmet challenge for the field of gesture analysis is how we may be relevant to such real world gesticulation this paper advance a perspective of high level gesture understanding that proceeds from human multimodal language we do not present any particular new algorithm instead we draw our evidence from scientifically proven published research to motivate and derive an overarching model that open the door of discourse understanding for vision speech processing research we shall show that this high level understanding is not inconsequential it ha deep implication on how the entire enterprise of high and low level vision based gesture research may be carried out we present the result of a set of discourse segmentation experiment that support our model 
this paper present a novel approach for continuous detection and tracking of moving object observed by multiple stationary camera we address the tracking problem by simultaneously modeling motion and appearance of the moving object the object s appearance is represented using color distribution model invariant to d rigid and scale transformation it provides an efficient blob similarity measure for tracking the motion model are obtained using a kalman filter kf process which predicts the position of the moving object in d and d the tracking is performed by the maximization of a joint probability model reflecting object motion and appearance the novelty of our approach consists in integrating multiple cue and multiple view in a jpdaf for tracking a large number of moving people with partial and total occlusion we demonstrate the performance of the proposed method on a soccer game captured by two stationary camera 
the emerging cognitive vision paradigm is concerned with vision system that evaluate gather and integrate contextual knowledge for visual analysis in reasoning about event and structure cognitive vision system should rely on multiple computation in order to perform robustly even in noisy domain action recognition in an unconstrained office environment thus provides an excellent testbed for research on cognitive computer vision in this contribution we present a system that consists of several computational module for object and action recognition it applies attention mechanism visual learning and contextual a well a probabilistic reasoning to fuse individual result and verify their consistency database technology are used for information storage and an xml based communication framework integrates all module into a consistent architecture 
we present a complete system for the purpose of automatically assembling d pot given d measurement of their fragment commonly called sherd a bayesian approach is formulated which at present model the data given a set of sherd geometric parameter dense sherd measurement data is obtained by scanning the outside surface of each sherd with a laser scanner mathematical model specied by a set of geometric parameter represent the sherd outer surface and break curve on the outer surface where two sherd have broken apart optimal alignment of assembly of sherd called congur ations is implemented a maximum likelihood estimation mle of the surface and break curve parameter given the measured sherd data for all sherd in a congur ation the assembly process start with a fast clustering scheme which approximates the mle solution for all sherd pair i e congur ations of size using a subspace of the geometric parameter i e the sherd break curve more accurate mle value based on all parameter i e sherd alignment are computed when sherd pair are merged with other sherd congur ations merges take place in order of constant probability starting at the most probable congur ation this method is robust to missing sherd or group of sherd which contain sherd from more than one pot the system represents at least three signicant advance over previous d puzzle solving approach a bayesian framework which allows for easily combining diverse type of information extracted from each sherd a search which reduces comparison on unlikely congur ations and a robust computationally reasonable method for aligning break curve and sherd outer surface simultaneously in addition a number of insight are given which have not previously been discussed and signicantly reduce computation method proposed for and represent important contribution to the eld of puzzle assembly d geometry learning and dataset alignment and are critical to making d puzzle solution tractable to compute result are presented which include assembling a sherd pot where only an incomplete set of sherd is available keywords automatic d puzzle assembly d structure from unorganized d data d alignment geometric learning perceptual grouping hierarchical clustering 
surface representation is needed for almost all modelingand visualization application but unfortunately d datafrom a passive vision system are often insufficient for a traditionalsurface reconstruction technique that is designedfor densely scanned d point data in this paper we developa new method for surface reconstruction by combiningboth d data and d image information the silhouetteinformation extracted from d image can also be integratedas an option if it is available the new methodis a variational approach with a new functional integrating d stereo data with d image information this givesa more robust approach than existing method using onlypure d information or d stereo data we also propose abounded regularization method to implement efficiently thesurface evolution by level set method the property ofthe algorithm are discussed proved for some case andempirically demonstrated through intensive experiment onreal sequence 
we present a design technique for realizing given projection a catadioptric sensor in general these problem do not have solution but approximate solution may often be found that are visually acceptable our approach which we call the method of vector field reduces the problem to solving a linear system a given transformation between the image plane object surface is shown to determine a vector field which is normal to the surface in the case where the vector field is a gradient if the vector field is not a gradient we present several functionals that may be minimized to give approximate solution 
in the present paper we address the problem of recovering the true underlying model of a surface while performing the segmentation a novel criterion for surface model selection is introduced and it performance for selecting the underlying model of various surface ha been tested and compared with many other existing technique using this criterion we then present a range data segmentation algorithm capable of segmenting complex object with planar and curved surface the algorithm simultaneously identifies the type order and geometric shape of surface and separate all the point that are part of that surface from the rest in a range image the paper includes the segmentation result of a large collection of range image obtained from object with planar and curved surface 
a bayesian network formulation for relational shapematching is presented the main advantage of the relationalshape matching approach is the obviation ofthe non rigid spatial mapping used by recent non rigidmatching approach the basic variable that need tobe estimated in the relational shape matching objectivefunction are the global rotation and scale and the localdisplacements and correspondence the new bethefree energy approach is used to estimate the pairwisecorrespondences between link of the template graphsand the data the resulting framework is useful inboth registration and recognition context result areshown on hand drawn template and on d transverset weighted mr image 
this paper considers the problem of reconstructing visuallyrealistic d model of fire from a very small setof simultaneous view even two by modeling fire a asemi transparent d density field we show that fire reconstructionis equivalent to a severely under constrained computerizedtomography problem for which traditional methodsbreak down our approach is based on the observationthat every pair of photograph of a semi transparentscene defines a unique density field called a flame sheet that concentrate all it density on one connected semi transparentsurface reproduces the two photo exactly and is the most spatially coherent density field that doesso from this observation we reduce fire reconstruction tothe convex combination of sheet like density field each ofwhich is derived from the flame sheet of two input photo experimental result suggest that this method enables high qualityview extrapolation without over fitting artifact 
the problem of establishing image to image correspondence is fundamental in computer vision recently several wide baseline matching algorithm capable of handling large change of viewpoint have appeared by computing feature value from image data these algorithm mainly use appearance a a cue for matching topological information i e spatial relation between feature ha also been used but not nearly to the same extent a appearance in this paper we incorporate topological constraint into an existing matching algorithm which match image intensity profile between interest point we show that the algorithm can be improved by exploiting the constraint that the intensity profile around each interest point should be cyclically ordered string matching technique allows for an efficient implementation of the ordering constraint experiment with real data indicate that the modified algorithm indeed give superior result to the original one the method of enforcing the spatial constraint is not limited to the presented case but can be used on any algorithm where interest point correspondence are sought 
in recent work we presented a framework for many to many matching of multi scale feature hierarchy in which feature and their relation were captured in a vertex labeled edge weighted directed graph the algorithm wa based on a metric tree representation of labeled graph and their metric embedding into normed vector space using the embedding algorithm of matou sek however the method wa limited by the fact that two graph to be matched were typically embedded into vector space with dieren t dimensionality before the embeddings could be matched a dimensionality reduction technique pca wa required which wa both costly and prone to error in this paper we introduce a more ecien t embedding procedure based on a spherical coding of directed graph the advantage of this novel embedding technique is that it prescribes a single vector space into which both graph are embedded this reduces the problem of directed graph matching to the problem of geometric point matching for which ecien t many to many matching algorithm exist such a the earth mover s distance we apply the approach to the problem of multi scale view based object recognition in which an image is decomposed into a set of blob and ridge with automatic scale selection 
we work with a model of object recognition where word must be placed on image region this approach mean that large scale experiment are relatively easy so we can evaluate the effect of various early and midlevel vision algorithm on recognition performance we evaluate various image segmentation algorithm by determining word prediction accuracy for image segmented in various way and represented by various feature we take the view that good segmentation respect object boundary and so word prediction should be better for a better segmentation however it is usually very difficult in practice to obtain segmentation that do not break up object so most practitioner attempt to merge segment to get better putative object representation we demonstrate that our paradigm of word prediction easily allows u to predict potentially useful segment merges even for segment that do not look similar for example merging the black and white 
we wish to determine the epipolar geometry of a stereo camera pair from image measurement alone this paper describes a solution to this problem which doe not require a parametric model of the camera system and consequently applies equally well to a wide class of stereo configuration example in the paper range from a standard pinhole stereo configuration to more exotic system combining curved mirror and wide angle lens the method described here allows epipolar curve to be learned from multiple image pair presented to the stereo camera by aggregating information over the multiple image a dense map of the epipolar curve can be determined on the image the algorithm requires a large number of image but ha the distinct benefit that the correspondence problem doe not have to be explicitly solved we show that for standard stereo configuration the result are comparable to those obtained from a state of the art parametric model method despite the significantly weaker constraint on the non parametric model the new algorithm is simple to implement so it may easily be employed on a new and possibly complex camera system 
inspired by tensor voting we present luminance voting a novelapproach for image registration with global and local luminancealignment the key to our modeless approach is the directestimation of replacement function by reducing the complexestimation problem to the robust d tensor voting in thecorresponding voting space no model for replacement function isassumed luminance data are first encoded into d ball tensor subject to the monotonic constraint only we vote for an optimalreplacement function by propagating the smoothness constraint usinga dense tensor field our method effectively infers missing curvesegments and reject image outlier without assuming anysimplifying or complex curve model the voted replacement functionsare used in our iterative registration algorithm for computing thebest warping matrix unlike previous approach our robust methodcorrects exposure disparity even if the two overlapping image areinitially misaligned luminance voting is effective in correctingexposure difference eliminating vignette and thus improvingimage registration we present result on a variety of image 
visual surveillance using a camera network ha imposed newchallenges to camera calibration an essential problem is that alarge number of camera may not have a common field of view or evenbe synchronized well we propose to use a hybrid camera networkthat consists of catadioptric and perspective camera for a visualsurveillance task the relation between multiple view of a scenecaptured from different camera can be then calibrated under thecatadioptric camera s coordinate system this paper address theimportant issue of how to calibrate the hybrid camera network wecalibrate the hybrid camera network in three step first wecalibrate the catadioptric camera using only the vanishing point in order to reduce computational complexity we calibrate thecamera without the mirror first and then calibrate the catadioptriccamera system second we determine d position of some pointsusingas few a two spatial parallel line and some equidistancepoints finally we calibrate other perspective camera based onthese known spatial point 
in this note we present a coupled optimization model forboundary determination one part of the model incorporatesa prior shape into a geometric active contour modelwith a fixed parameter the second part determines the best parameter used in the first part by maximizing the mutualinformation of the image geometry between the priorand an aligned novel image over all the alignment thatare the solution of the first part corresponding to differentparameters we also present an alternative method whichgenerates an intensity model formed a the average of a setof aligned training image experimental result on cardiacultrasound image are presented these result indicatethat the proposed model provides close agreement withexpert traced border and the parameter determined in thismodel for one image can be used for image with similarproperties the existence of a solution to the proposed minimizationproblem is also discussed 
this paper address the problem of probabilistically modeling d human motion for synthesis and tracking given the high dimensional nature of human motion learning an explicit probabilistic model from available training data is currently impractical instead we exploit method from texture synthesis that treat image a representing an implicit empirical distribution these method replace the problem of representing the probability of a texture pattern with that of searching the training data for similar instance of that pattern we extend this idea to temporal data representing d human motion with a large database of example motion to make the method useful in practice we must address the problem of efficient search in a large training set efficiency is particularly important for tracking towards that end we learn a low dimensional linear model of human motion that is used to structure the example motion database into a binary tree an approximate probabilistic tree search method exploit the coefficient of this low dimensional representation and run in sub linear time this probabilistic tree search return a particular sample human motion with probability approximating the true distribution of human motion in the database this sampling method is suitable for use with particle filtering technique and is applied to articulated d tracking of human within a bayesian framework successful tracking result are presented along with example of synthesizing human motion using the model 
we present a novel approach to surface reconstruction from multiple image the central idea is to explore the integration of both d stereo data and d calibrated image this is motivated by the fact that only robust and accurate feature point that survived the geometry scrutiny of multiple image are reconstructed in space the density insuciency and the inevitable hole in the stereo data should be lled in by using information from multiple image the idea is therefore to rst construct small surface patch from stereo point then to progressively propagate only reliable patch in their neighborhood from image into the whole surface using a best rst strategy the problem reduces to searching for an optimal local surface patch going through a given set of stereo point from image this constrained optimization for a surface patch could be handled by a local graph cut that we develop real experiment demonstrate the usability and accuracy of the approach 
this paper explores the use of multisensory information fusion technique with dynamic bayesian network dbns for modeling and understanding the temporal behavior of facial expression in image sequence our approach to the facial expression understanding lie in a probabilistic framework by integrating the dbns with the facial action unit au from psychological view the dbns provide a coherent and unified hierarchical probabilistic framework to represent spatial and temporal information related to facial expression and to actively select the most informative visual cue from the available information to minimize the ambiguity in recognition the recognition of facial expression is accomplished by fusing not only from the current visual observation but also from the previous visual evidence consequently the recognition becomes more robust and accurate through modeling the temporal behavior of facial expression experimental result demonstrate that our approach is more admissible for facial expression analysis in image sequence 
particle filter provide a mean to track the state of an object even when the dynamic and the observation are non linear non gaussian however they can be very inefficient when the observation noise is low a compared to the system noise a it is often the case in visual tracking application in this paper we propose a new two stage sampling procedure to boost the performance of particle filter under this condition the new procedure is shown to reduce the variance of the weight by mean of a theoretical analysis this result is confirmed in a series of synthetic and real world visual tracking experiment 
this paper describes a novel application of statisticallearning theory slt to control model complexity in flowestimation slt provides analytical generalization boundssuitable for practical model selection from small and noisydata set of image measurement normal flow the methodaddresses the aperture problem by using the penalized risk ridge regression we demonstrate an application of thismethod on both synthetic and real image sequence and useit for motion interpolation and extrapolation our experimentalresults show that our approach compare favorablyagainst alternative model selection method such a theakaike s final prediction error schwartz s criterion generalizedcross validation and shibata s model selector 
visual hull vh construction from silhouette image isa popular method of shape estimation the method alsoknown a shape from silhouette sfs is used in many applicationssuch a non invasive d model acquisition obstacleavoidance and more recently human motion trackingand analysis one of the limitation of sfs however is that the approximated shape can be very coarse whenthere are only a few camera in this paper we proposean algorithm to improve the shape approximation by 
in this paper we propose a novel method to establish temporalcorrespondence between the frame of two video d epipolargeometry is used to eliminate the distortion generated bythe projection from d to d although the fundamental matrixcontains the extrinsic property of the projective geometrybetween view it is sensitive to noise therefore wepropose the use of a rank constraint of corresponding pointsin two view to measure the similarity between trajectory this rank constraint show more robustness and avoids computationof the fundamental matrix a dynamic programmingapproach using the similarity measurement is proposed to findthe non linear time warping function for video containinghuman activity in this way video of different individualstaken at different time and from distinct viewpoint canbe synchronized a temporal pyramid of trajectory is appliedto improve the accuracy of the view invariant dynamictime warping approach we show various application of thisapproach such a video synthesis human action recognition and computer aider training compared to state of the arttechniques our method show a great improvement 
in this paper we describe a new approach for recovering d geometry from an uncalibrated image sequence of a single axis turntable motion unlike previous method the computation of multiple view encoded by the fundamental matrix or trifocal tensor is not required instead the new approach is based on fitting a conic locus to corresponding image point over multiple view it is then shown that the geometry of single axis motion can be recovered given at least two such conic in the case of two conic the reconstruction may have a two fold ambiguity but this ambiguity is removed if three conic are used the approach enables the geometry of the single axis motion the d rotation axis and euclidean geometry in plane perpendicular to this axis to be estimated using the minimal number of parameter it is demonstrated that a maximum likelihood estimation result in measurement that are a good a or superior to those obtained by previous method and with a far simpler algorithm example are given on various real sequence which show the accuracy and robustness of the new algorithm 
relevance feedback rf is an interactive process which refines theretrievals by utilizing user s feedback history most researchersstrive to develop new rf technique and ignore the advantage ofexisting one in this paper we propose an image relevancereinforcement learning irrl model for integrating existing rftechniques various integration scheme are presented and along term shared memory is used to exploit the retrieval experiencefrom multiple user also a concept digesting method is proposedto reduce the complexity of storage demand the experimentalresults manifest that the integration of multiple rf approachesgives better retrieval performance than using one rf techniquealone and that the sharing of relevance knowledge between multiplequery session also provides significant contribution forimprovement further the storage demand is significantly reducedby the concept digesting technique this show the scalability ofthe proposed model against a growing size database 
facial motion produce not only facial feature point motion but also subtle appearance change such a wrinklesand shading change these subtle change are importantyet difficult issue for both analysis tracking and synthesis animation previous approach were mostly basedon model learned from extensive training appearance example however the space of all possible facial motionappearance is huge thus it is not feasible to collect samplescovering all possible variation due to lighting condition individuality and head pose therefore it is difficultto adapt such model to new condition in this paper we present an adaptive technique for analyzing subtle facialappearance change we propose a new ratio imagebased appearance feature which is independent of a person sface albedo this feature is used to track face appearancevariations based on exemplar to adapt the exemplarappearance model to new people and lighting condition we develop an online em based algorithm experimentsshow that the proposed method improves classification resultsin a facial expression recognition task where a varietyof people and lighting condition are involved 
how a robot should grasp an object depends on it size and shape such parameter can be estimated visually but this is fallible particularly for unrecognized unfamiliar object failure will result in a clumsy grasp or glancing blow against the object if the robot doe not learn something from the encounter then it will be apt to repeat the same mistake again and again this paper show how to recover information about an object s extent by poking it either accidentally or deliberately poking an object make it move and motion is a powerful cue for visual segmentation the period immediately before and after the moment of impact turn out to be particularly informative and give visual evidence for the boundary of the object that is well suited to segmentation using graph cut the segmentation algorithm is shown to produce result consistent enough to support autonomous collection of datasets for object recognition which enables often encountered object to be segmented without the need for further poking figure a motivating scenario the robot left reach towards an object in it environment while fixating it with a camera the robot s view is shown on the right the boundary between the cube and the table it is sitting on is clear to human eye but too subtle to be reliably segmented by current automatic method but once the robot arm come in contact with the object it can be easily segmented from the background using the motion due to the impact 
we address three crucial issue encountered in dt mri diffusiontensor magnetic resonance imaging diffusion tensor estimation regularization and fiber bundle visualization we first reviewrelated algorithm existing in the literature and propose thenalternative variational formalism that lead to new and improvedschemes thanks to the preservation of important tensor constraint positivity symmetry we illustrate how our complete dt mriprocessing pipeline can be successfully used to construct and drawfiber bundle in the white matter of the brain from a set of noisyraw mri image 
a commonly used representation of a visual pattern is the set ofmarginal probability distribution of the output of a bank offilters gaussian laplacian gabor etc this representationhas been used effectively for a variety of vision task includingtexture classification texture synthesis object detection andimage retrieval this paper examines the ability of thisrepresentation to discriminate between an arbitrary pair of visualstimuli example of pattern are derived that provably posse thesame marginal statistical property yet are visually distinct these result suggest the need for either employing a large anddiverse filter bank or incorporating joint statistic in order torepresent a large class of visual pattern 
this paper describes a new and simple method of recovering thegeometry of uncalibrated circular motion or single axis motionusing a minimal data set of point in image this problem hasbeen solved using non minimal data either by computing thefundamental matrix and trifocal tensor in image or by fittingconics to tracked point in image our new method first computesa planar homography from a minimum of point in image it isshown that two eigenvectors of this homography are the image ofthe circular point then other fixed image entity and rotationangles can be straightforwardly computed the crux of the methodlies in relating this planar homography from two different pointsto a homology naturally induced by corresponding point ondifferent conic locus from a circular motion the experiment onreal image sequence demonstrate the simplicity accuracy androbustness of the new method 
dynamic probabilistic network dpns are exploited for modeling the temporal relationship among a set of different object temporal event in the scene for a coherent and robust scene level behaviour interpretation in particular we develop a dynamically multi linked hidden markov model dml hmm to interpret group activity involving multiple object captured in an outdoor scene the model is based on the discovery of salient dynamic interlinks among multiple temporal event using dpns object temporal event are detected and labeled using gaussian mixture model with automatic model order selection a dml hmm is built using schwarz s bayesian information criterion based factorisation resulting in it topology being intrinsically determined by the underlying causality and temporal order among different object event our experiment demonstrate that it performance on modelling group activity in a noisy outdoor scene is superior compared to that of a multi observation hidden markov model mohmm a parallel hidden markov model pahmm and a coupled hidden markov model chmm 
hand gesture are example of fast and complex motion computer fail to track these in fast video but sleight ofhand fool human a well what happens too quickly wejust cannot see we show a d tracker for these type ofmotions that relies on the recognition of familiar configurationsin d image classification and fill the gapsin between interpolation we illustrate this idea with experimentson hand motion similar to finger spelling thepenalty for a recognition failure is often small if two configurationsare confused they are often similar to eachother and the illusion work well enough for instance todrive a graphic animation of the moving hand we contributeadvances in both feature design and classifier training our image feature are invariant to image scale translation and rotation and we propose a classification methodthat combine vqpca with discrimination tree 
in this paper we describe a novel technique for detecting salient region in an image the detector is a generalization to a ne invariance of the method introduced by kadir and brady the detector deems a region salient if it exhibit unpredictability in both it attribute and it spatial scale 
this paper present a novel approach for detecting affine invariant interest point our method can deal with significant affine transformation including large scale change such transformation introduce significant change in the point location a well a in the scale and the shape of the neighbourhood of an interest point our approach allows to solve for these problem simultaneously it is based on three key idea the second moment matrix computed in a point can be used to normalize a region in an affine invariant way skew and stretch the scale of the local structure is indicated by local extremum of normalized derivative over scale an affine adapted harris detector determines the location of interest point a multi scale version of this detector is used for initialization an iterative algorithm then modifies location scale and neighbourhood of each point and converges to affine invariant point for matching and recognition the image is characterized by a set of affine invariant point the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination change a quantitative comparison of our detector with existing one show a significant improvement in the presence of large affine deformation experimental result for wide baseline matching show an excellent performance in the presence of large perspective transformation including significant scale change result for recognition are very good for a database with more than image 
a new algorithm is proposed for novel view generation in one to oneteleconferencing application given the video stream acquired bytwo camera placed on either side of a computer monitor theproposed algorithm synthesis image from a virtual camera inarbitrary position typically located within the monitor tofacilitate eye contact our technique is based on an improved dynamic programming stereo algorithm for efficient novel viewgeneration the two main contribution of this paper are i a newtype of three plane graph for dense stereo dynamic programming that encourages correct occlusion labeling ii a compact geometricderivation for novel view synthesis by direct projection of theminimum cost surface furthermore this paper present a novelalgorithm for the temporal maintenance of a background model toenhance the rendering of occlusion and reduce temporal artefact flicker and a cost aggregation algorithm that act directly onour three dimensional matching cost space example are given thatdemonstrate the robustness of the new algorithm to spatial andtemporal artefact for long stereo video stream these includedemonstrations of synthesis of cyclopean view of extendedconversational sequence we further demonstrate synthesis from afreely translating virtual camera 
most of the work on d object recognition from rangedata ha used an alignment verification approach in whicha specific d object is matched to an exact instance of thesame object in a scene this approach ha been successfullyused in industrial machine vision but it is not capable ofdealing with the complexity of recognizing class of similarobjects this paper undertakes this task by proposingand testing a component based methodology encompassingthree main ingredient a new way of learning and extractingshape class component from surface shape information a new shape representation called a symbolicsurface signature that summarizes the geometric relationshipsamong component and an abstract representationof shape class formed by a hierarchy of classifiersthat learn object class part and their spatial relationshipsfrom example 
we propose a solution to the problem of inferring the depth map radiance and motion of a scene from a collection of motion blurred and defocused image we model motion blur and defocus a an anisotropic diusion process whose initial condition depend on the radiance and whose diusion tensor encodes the shape of the scene the motion field and the optic parameter we show that this model is well posed and propose an ecient algorithm to infer the unknown of the model inference is performed by minimizing the discrepancy between the measured blurred image and the one synthesized via forward diusion since the problem is ill posed we also introduce additional tikhonov regularization term the resulting method is fast and robust to noise a shown by experiment with both synthetic and real data 
method based on local viewpoint invariant feature have proven capable of recognizing object in spite of viewpoint change occlusion and clutter however these approach fail when these factor are too strong due to the limited repeatability and discriminative power of the feature a additional shortcoming the object need to be rigid and only their approximate location is found we present a novel object recognition approach which overcomes these limitation an initial set of feature correspondence is first generated the method anchor on it and then gradually explores the surrounding area trying to construct more and more matching feature increasingly farther from the initial one the resulting process cover the object with match and simultaneously separate the correct match from the wrong one hence recognition and segmentation are achieved at the same time only very few correct initial match suffice for reliable recognition the experimental result demonstrate the stronger power of the presented method in dealing with extensive clutter dominant occlusion large scale and viewpoint change moreover non rigid deformation are explicitly taken into account and the approximative contour of the object are produced the approach can extend any viewpoint invariant feature extractor 
this paper proposes an image matching method that is robust to illumination variation and affine distortion our idea is to do image matching through establishing an imaging function that describes the functional relationship relating intensity value between two image similar methodology ha been proposed by viola and lai fang viola proposed to do image matching through establishment of an imaging function based on a consistency principle lai fang proposed a parametric form of the imaging function in case where the illumination variation is not globally uniform and the parametric form of imaging function is not obvious one need to have a more robust method our method aim to take care of spatially non uniform illumination variation and affine distortion central to our method is the proposal of a localized consistency principle implemented through a non parametric way of estimating the imaging function the estimation is effected through optimizing a similarity measure that is robust under spatially non uniform illumination variation and affine distortion experimental result are presented from both synthetic and real data encouraging result were obtained 
abstract we describe a mixture density propagation algorithm to estimate d human motion in monocular videosequences based on observation encoding the appearance of image silhouette our approach is discriminative rather than generative therefore it doe not require the probabilistic inversion of a predictive observationmodel instead it us a large human motion capture data base and a d computer graphic humanmodel to synthesize training pair of typical human configuration together with 
we aim at using color information to classify the physicalnature of edge in video to achieve physic based edgeclassification we first propose a novel approach to coloredge detection by automatic noise adaptive thresholdingderived from sensor noise analysis then we present a taxonomyon color edge type a a result a parameter freeedge classifier is obtained labeling color transition intoone of the following type shadow geometry highlightedges material edge the proposed method isempirically verified on image showing complex real worldscenes 
this paper describes a novel application of support vector machinesand multiscale texture and color invariant to a problem inbiological oceanography the identification of specie of bivalvelarvae our data consists of polarized color image of scallop andother bivalve larva between and day old collected from theocean by a shipboard optical imaging system of our design larvaeof scallop clam and oyster are small micron with fewdistinguishing feature when observed under standard lightmicroscopy however the use of polarized light with a full waveretardation plate produce a vivid color bi refringence pattern the pattern display very subtle difference between specie oftennot discernable to human observer we show that a soft marginsupport vector machine with gaussian rbf kernel is a gooddiscriminator on a feature set extracted from gabor wavelettransforms and color distribution angle of each image byconstraining the gabor center frequency to be low the resultingsystem can attain classification accuracy in excess of forvertically oriented image and in excess of for randomlyoriented image 
natural image are the composite consequence of multiple factor related to scene structure illumination and imaging multilinear algebra the algebra of higher order tensor offer a potent mathematical framework for analyzing the multifactor structure of image ensemble and for addressing the difficult problem of disentangling the constituent factor or mode our multilinear modeling technique employ a tensor extension of the conventional matrix singular value decomposition svd known a the n mode svd a a concrete example we consider the multilinear analysis of ensemble of facial image that combine several mode including different facial geometry people expression head pose and lighting condition our resulting tensorfaces representation ha several advantage over conventional eigenfaces more generally multilinear analysis show promise a a unifying framework for a variety of computer vision problem 
a method for solving binocular and multi view stereomatching problem is presented in this paper a weakconsistency constraint is proposed which express thevisibility constraint in the image space it can be provedthat the weak consistency constraint hold for scene thatcan be represented by a set of d point a well alsoproposed is a new reliability measure for dynamicprogramming technique which evaluates the reliability ofa given match a novel reliability based dynamicprogramming algorithm is derived accordingly which canselectively assign disparity value to pixel when thereliabilities of the corresponding match exceed a giventhreshold consistency constraint and the new reliability baseddynamic programming algorithm can be combinedin an iterative approach the experimental result showthat the iterative approach can produce dense and reliable total error rate of matching forbinocular stereo datasets it can also generate promisingdisparity map for trinocular and multi view stereodatasets 
under the lambertian reflectance model uncalibrated photometricstereo with unknown light source is inherentlyambiguous in this paper we consider the use of a moregeneral reflectance model namely the torrance and sparrowmodel in uncalibrated photometric stereo we demonstratethat this can not only resolve the ambiguity when thelight source are unknown but can also result in more accuratesurface reconstruction and can capture the reflectanceproperties of a large number of non lambertian surface our method us single light source image with unknownlighting and no knowledge about the parameter of the reflectancemodel it can recover the d shape of surface up to the binary convex concave ambiguity together withtheir reflectance property we have successfully tested ouralgorithm on a variety of non lambertian surface demonstratingthe effectiveness of our approach in the case ofhuman face the estimated skin reflectance ha been shownto closely resemble the measured skin reflectance reportedin the literature we also demonstrate improved recognitionresults on image of face with variable lightingand viewpoint when the synthetic image based representationsof the face are generated using the surface reconstructionsand reflectance property recovered while assumingthe extended reflectance model 
this paper present a framework for texture recognitionbased on local affine invariant descriptor and their spatiallayout at modeling time a generative model of localdescriptors is learned from sample image using the em algorithm the em framework allows the incorporation ofunsegmented multi texture image into the training set thesecond modeling step consists of gathering co occurrencestatistics of neighboring descriptor at recognition time initial probability computed from the generative modelare refined using a relaxation step that incorporates co occurrencestatistics performance is evaluated on imagesof an indoor scene and picture of wild animal 
we propose a novel approach on how to rectify the photo image of the bound document the surface of the document is modeled by a cylindrical surface by the geometry of camera image formation the equation using the cue of directrixes to map the point on the surface in the d scene to the point on the image plane are achieved baseline of the horizontal text line are extracted a projection of directrixes to estimate the bending extent of the surface and then the image are rectified the proposed method need no auxiliary device experimental result are presented to demonstrate the feasibility and the application of the method 
we propose a probabilistic algorithm able to detect the curve thatare unexpectedy smooth in a set of digital curve the onlyparameter is a false alarme rate influencing the detection only byits logarithm we experiment the good continuation criterion onimage level line one of the conclusion is that accordingly togestalt theory onecan detect egdes in a way that is widelyindependent of contrast we also use the same kind of method todetect corner and junction 
an image sequence based framework for appearance based object recognition is proposed in this paper compared with the method of using a single view for object recognition inter frame consistency can be exploited in a sequence based method so that a better recognition performance can be achieved we use the nearest feature line method nfl to model each object the nfl method is extended in this paper by further integrating motion continuity information between feature line in a probabilistic framework the associated recognition task is formulated a maximizing an a posteriori probability measure the recognition problem is then further transformed to a shortest path searching problem and a dynamic programming technique is used to solve it 
we present a new approach to modeling and processing multimedia data this approach is based on graphical model that combine audio and video variable we demonstrate it by developing a new algorithm for tracking a moving object in a cluttered noisy scene using two microphone and a camera our model us unobserved variable to describe the data in term of the process that generates them it is therefore able to capture and exploit the statistical structure of the audio and video data separately a well a their mutual dependency model parameter are learned from data via an em algorithm and automatic calibration is performed a part of this procedure tracking is done by bayesian inference of the object location from data we demonstrate successful performance on multimedia clip captured in real world scenario using off the shelf equipment 
occlusion are common place in man made and natural environment they often result in photometric feature where a line terminatesat an occluding boundary resembling a t we show that the dmotion of such t junction in multiple view carry non trivialinformation on the d structure of the scene and it motionrelative to the camera we show how the constraint among multipleviews of t junction can be used to reliably detect them anddifferentiate them from ordinary point feature finally wepropose an integrated algorithm to recursively and causallyestimate structure and motion in the presence of t junction alongwith other point feature 
the propose of this paper is to introduce a new regularization formulation for inverse problem in computer vision and image processing that allows one to reconstruct second order piece wise smooth image that is image consisting of an assembly of region with almost constant value almost constant slope or almost constant curvature this formulation is based on the idea of using potential function that correspond to spring or thin plate with an adaptive rest condition efficient algorithm for computing the solution and example illustrating the performance of this scheme compared with other known regularization scheme are presented a well 
this paper present a method for evaluating multiple feature spaceswhile tracking and for adjusting the set of feature used toimprove tracking performance our hypothesisis that the featuresthat best discriminate between object and background are also bestfor tracking the object we develop an on line feature selectionmechanism based on the two class variance ratio measure applied tolog likelihood distribution computed with respect to a givenfeature from sample of object and background pixel this featureselection mechanism is embedded in a tracking system thatadaptively selects the top ranked discriminative feature fortracking example are presented to illustrate how the methodadapts to changing appearance of both tracked object and scenebackground 
the problem of interactive foreground background segmentation in still image is of great practical importance in image editing the state of the art in interactive segmentation is probably represented by the graph cut algorithm of boykov and jolly iccv it underlying model us both colour and contrast information together with a strong prior for region coherence estimation is performed by solving a graph cut problem for which very efcient algorithm have recently been developed however the model depends on parameter which must be set by hand and the aim of this work is for those constant to be learned from image data first a generative probabilistic formulation of the model is set out in term of a gaussian mixture markov random field gmmrf secondly a pseudolikelihood algorithm is derived which jointly learns the colour mixture and coherence parameter for foreground and background respectively error rate for gmmrf segmentation are calculated throughout using a new image database available on the web with ground truth provided by a human segmenter the graph cut algorithm using the learned parameter generates good object segmentation with little interaction however pseudolikelihood learning prof to be frail which limit the complexity of usable model and hence also the achievable error rate 
in this paper we present a mathematical theory for marr s primal sketch the theory ha four component the first component is a primal sketch model for natural image which integrates the descriptive markov random field model and the generative wavelet model the former is applied to textural location without distinguishable element called non sketchable and the latter is applied to geometric location called sketchable the second component is a sketching pursuit process which coordinate the competition between two pursuit algorithm the matching pursuit and the filter pursuit or the competition of the two family of model that seek to explain the image by base and filter respectively the third component is a theoretical definition of sketchability which state a critical condition and thus a dividing point for our perceptual jump between texture and geometry the fourth component is to learn a generic dictionary of image primitive or textons in julesz s term for natural image our dictionary is found to be far more effective than conventional gabor and log base our model is not only extremely parsimonious for image representation but produce meaningful sketch a marr hoped for over a large number of generic image 
in this contribution we present an approach for d d pose estimation of d free form surface model in our scenario we observe a free form object in an image of a calibrated camera pose estimation mean to estimate the relative position and orientation of the d object to the reference camera system the object itself is modeled a a two parametric d surface and extended by one parametric contour part of the object a twist representation which is equivalent to a fourier representation allows for a low pas approximation of the object model which is advantageously applied to regularize the pose problem the experiment show that our developed algorithm are fast m frame and accurate o rotational error frame 
in this paper we use the cumulative distribution of a randomvariable to define the information content in it and use it todevelop a novel measure of information that parallel shannonentropy which we dub cumulative residual entropy cre the keyfeatures of cre may be summarized a it definition is valid inboth the continuous and discrete domain it is mathematicallymore general than the shannon entropy and it computation fromsample data is easy and these computation converge asymptoticallyto the true value we define the cross cre ccre between tworandom variable and apply it to solve the uni multi modalimage alignment problem for parameterized rigid affine andprojective transformation the key strength of the ccre overusing the now popular mutual information method based on shannon sentropy are that the former ha significantly larger noiseimmunity and a much larger convergence range over the field ofparameterized transformation these strength of ccre aredemonstrated via experiment on synthesized and real image data 
in vision and graphic there is a sustained interest incapturing accurate d shape with various scanning device however the resulting geometric representation isonly part of the story surface texture of real object isalso an important component of the representation and fine scalesurface geometry such a surface marking roughness and imprint are essential in highly realistic renderingand accurate prediction we present a novel approachfor measuring the fine scale surface shape of specular surfacesusing a curved mirror to view multiple angle in asingle image a distinguishing aspect of our method is thatit is designed for specular surface unlike many method e g laser scanning which cannot handle highly specularobjects also the spatial resolution is very high so that itcan resolve very small surface detail that are beyond theresolution of standard device furthermore our approachincorporates the simultaneous use of a bidirectional texturemeasurement method so that spatially varying bidirectionalreflectance is measured at the same time a surfaceshape 
photometric invariance is used in many computer vision application the advantage of photometric invariance is therobustness against shadow shading and illumination condition however the drawback of photometric invarianceis the loss of discriminative power and the inherent instabilitiescaused by the non linear transformation to computethe invariant in this paper we propose a new class of derivativeswhich we refer to a photometric quasi invariant thesequasi invariant share with full invariant the nice propertythat they are robust against photometric edge such asshadows or specular edge further these quasi invariantsdo not have the inherent instability of full photometric invariant we will apply these quasi invariant derivativesin the context of photometric invariant edge detection andclassification experiment show that the quasi invariantderivatives are stable and they significantly outperform thefull invariant derivative in discriminative power 
labeling video data is an essential prerequisite for many visionapplications that depend on training data such a visualinformation retrieval object recognition and human activitymodeling however manually creating label is not onlytime consuming but also subject to human error and eventually becomes impossible for a very large amount of data e g surveillance video to minimize the human effort in labeling wepropose a unified multi class active learning approach forautomatically labeling video data the contribution of this paperinclude extending active learning from binary class to multipleclasses and evaluating several practical sample selectionstrategies the experimental result show that the proposedapproach work effectively even with a significantly reduced amountof labeled data the best sample selection strategy can achievemore than a error reduction over random sample selection 
in this paper we present a method for unsupervised clustering ofimage database the method is based on a recently introducedinformation theoretic principle the information bottleneck ib principle image archive are clustered such that the mutualinformation between the cluster and the image content is maximallypreserved the ib principle is applied to both discrete andcontinuous image representation using discrete image histogramsand probabilistic continuous image modeling based on mixture ofgaussian density respectively experimental result demonstratethe performance of the proposed method forimage clustering on alarge image database several clustering algorithm derived fromthe ib principle are explored and compared 
in this paper a general method is given for reconstruction of a set of feature point in an arbitrary dimensional projective space from their projection into lower dimensional space the method extends the method applied in the well studied problem of reconstruction of a set of scene point in p given their projection in a set of image in this case the bifocal trifocal and quadrifocal tensor are used to carry out this computation it is shown that similar method will apply in a much more general context and hence may be applied to projection from pn to pm which have been used in the analysis of dynamic scene for sufficiently many generic projection reconstruction of the scene is shown to be unique up to projectivity except in the case of projection onto one dimensional image space line 
we introduce an incremental singular value decomposition svd of incomplete data the svd is developed a data arrives and can handle arbitrary missing untrusted value correlated uncertainty across row or column of the measurement matrix and user prior since incomplete data doe not uniquely specify an svd the procedure selects one having minimal rank for a dense p q matrix of low rank r the incremental method ha time complexity o pqr and space complexity o p q r better than highly optimized batch algorithm such a matlab s svd in case of missing data it produce factoring of lower rank and residual than batch svd algorithm applied to standard missing data imputation we show application in computer vision and audio feature extraction in computer vision we use the incremental svd to develop an efficient and unusually robust subspace estimating flow based tracker and to handle occlusion missing point in structure from motion factorization 
an important issue in tracking is how to incorporate an appropriate degree of adaptivity into the observation model without any adaptivity tracking fails when object property change for example when illumination change affect surface colour conversely if an observation model adapts too readily then during some transient failure of tracking it is liable to adapt erroneously to some part of the background the approach proposed here is to adapt selectively allowing adaptation only during period when two particular condition are met that the object should be both present and in motion the proposed mechanism for adaptivity is tested here with a foreground colour and motion model the experimental setting itself is novel in that it us combined colour and motion observation from a fixed filter bank with motion used also for initialisation via a monte carlo proposal distribution adaptation is performed using a stochastic em algorithm during period that meet the condition above test verify the value of such adaptivity in that immunity to distraction from clutter of similar colour to the object is considerably enhanced 
it ha been proven that a catadioptric projection can be modeled by an equivalent spherical projection in this paper we present an extension and improvement of those idea using the conformal geometric algebra a modern framework for the projective space of hyper sphere using this mathematical system the analysis of diverse catadioptric mirror becomes transparent and computationally simpler a a result the algebraic burden is reduced allowing the user to work in a much more effective framework for the development of algorithm for omnidirectional vision this paper includes complementary experimental analysis related to omnidirectional vision guided robot navigation 
we describe a d layered representation for visual motion analysis the representation provides a global interpretation of image motion in term of several spatially localized foreground region along with a background region each of these region comprises a parametric shape model and a parametric motion model the representation also contains depth ordering so visibility and occlusion are rightly included in the estimation of the model parameter finally because the number of object their position shape and size and their relative depth are all unknown initial model are drawn from a proposal distribution and then compared using a penalized likelihood criterion this allows u to automatically initialize new model and to compare different depth ordering 
principal component analysis pca ha been successfully applied to construct linear model of shape graylevel and motion in particular pca ha been widely used to model the variation in the appearance of people s face we extend previous work on facial modeling for tracking face in video sequence a they undergo significant change due to facial expression here we develop person specific facial appearance model psfam which use modular pca to model complex intra person appearance change such model require aligned visual training data in previous work this ha involved a time consuming and errorprone hand alignment and cropping process instead we introduce parameterized component analysis to learn a subspace that is invariant to affine or higher order geometric transformation the automatic learning of a psfam given a training image sequence is posed a a continuous optimization problem and is solved with a mixture of stochastic and deterministic technique achieving sub pixel accuracy we illustrate the use of the d psfam model with several application including video conferencing realistic avatar animation and eye tracking 
we present a technique for performing the tracking stage of optical motion capture which retains at each time frame multiple marker association hypothesis and estimate of the subject s position central to this technique are the equation for calculating the likelihood of a sequence of association hypothesis which we develop using a bayesian approach the system is able to perform motion capture using fewer camera and a lower frame rate than ha been used previously and doe not require the assistance of a human operator we conclude by demonstrating the tracker on real data and provide an example in which our technique is able to correctly determine all marker association and standard tracking technique fail 
feature space analysis is the main module in many computer visiontasks the most popular technique k mean clustering however hastwo inherent limitation the cluster are constrained to bespherically symmetric and their number ha to be known a priori innonparametric clustering method like the one based on mean shift these limitation are eliminated but the amount of computationbecomes prohibitively large a the dimension of the spaceincreases we exploit a recently proposed approximation technique locality sensitive hashing lsh to reduce the computationalcomplexity of adaptive mean shift in our implementation of lsh theoptimal parameter of the data structure are determined by a pilotlearning procedure and the partition are data driven a anapplication the performance of mode and k mean based textons arecompared in a texture classification study 
photometric stereo algorithm use a lambertian reflectance model with a varying albedo field and involve the appearance of only one object this paper extends photometric stereo algorithm to handle all the appearance of all the object in a class in particular the class of human face similarity among all facial appearance motivates a rank constraint on the albedo and surface normal in the class this lead to a factorization of an observation matrix that consists of exemplar image of different object under different illumination which is beyond what can be analyzed using bilinear analysis bilinear analysis requires exemplar image of different object under same illumination to fully recover the class specific albedo and surface normal integrability and face symmetry constraint are employed the proposed linear algorithm take into account the effect of the varying albedo field by approximating the integrability term using only the surface normal a an application face recognition under illumination variation is presented the rank constraint enables an algorithm to separate the illumination source from the observed appearance and keep the illuminant invariant information that is appropriate for recognition good recognition result have been obtained using the pie dataset 
detecting the dominant normal direction to the decisionsurface is an established technique for feature selectionin high dimensional classification problem several approacheshave been proposed to render this strategy moreamenable to practice but they still show a number of importantshortcomings from a pragmatic point of view this paperintroduces a novel such approach which combine thenormal direction idea with support vector machine classifier the two make a natural and powerful match a svsare located nearby and fully describe the decision surface the approach can be included elegantly into the training ofperformant classifier from extensive datasets the potentialis corroborated by experiment both on synthetic andreal data the latter on a face detection experiment in thisexperiment we demonstrate how our approach can lead to asignificant reduction of cpu time with neglectable loss ofclassification performance 
this paper present a novel approach for landmark basedshape deformation in which fitting error and shapedifference are formulated into a support vector machine svm regression problem to well describe nonrigid shapedeformation this paper measure the shape difference usinga thin plate spline model the proposed approach iscapable of preserving the topology of the template shape inthe deformation this property is achieved by inserting aset of additional point and imposing a set of linear equalityand or inequality constraint the underlying optimizationproblem is solved using a quadratic programming algorithm the proposed method ha been tested using practicaldata in the context of shape based image segmentation some relevant practical issue such a missing detectedlandmarks and selection of the regularization parameter arealso briefly discussed 
this paper present a multi scale generative model for representinganimate shape and extracting meaningful part of object themodel assumes that animate shape d simple closed curve areformed by a linear superposition of a number of shape base theseshapebases resemble the multi scale gabor base in image pyramidrepresentation are well localized in both spatial and frequencydomains and form an over complete dictionary this model issimpler than the popular b spline representation since it doe notengage a domainpartition thus it eliminates the interferencebetween adjacent b spline base and becomes a true linear additivemodel we pursue the base by reconstructing the shape in acoarse to fine procedure through curve evolution these shape basesare further organized ina tree structure where the base in eachsubtree sum up to an intuitive part of the object to buildprobabilistic model for a class of object we propose a markovrandom field model at each level of the tree representation toaccount for the spatial relationship between base thus the finalmodel integrates a markov tree generative model over scale and amarkov random field over space we adopt em type algorithm forlearning the meaningful part for a shape class and show someresults on shape synthesis 
an approach for model free markerless motion capture of human is presented this approach is centered on generating underlying nonlinear ax or a skeleton curve from a volume of a human subject human volume are captured from multiple calibrated camera we describe the use of skeleton curve for determining the kinematic posture of a human captured volume our motion capture us a skeleton curve found in each frame of a volume sequence to automatically produce kinematic motion we apply several type of motion to our capture approach and use the result to actuate a dynamically simulated humanoid robot 
in this paper we overcome a major drawback of the levelset framework the lack of point correspondence we maintainexplicit backward correspondence from the evolvinginterface to the initial one by advecting the initial point coordinateswith the same speed a the level set function ourmethod lead to a system of coupled eulerian partial differentialequations we show in a variety of numerical experimentsthat it can handle both normal and tangential velocity large deformation shock rarefaction and topologicalchanges application are many in computer vision andelsewhere since our method can upgrade virtually any levelset evolution we complement our work with the design ofnon zero tangential velocity that preserve the relative areaof interface patch this feature may be crucial in such applicationsas computational geometry grid generation orunfolding of the organ surface e g brain in medicalimaging 
an approach to recognizing human hand gesture from a monocular temporal sequence of image is presented of particular concern is the representation and recognition of hand movement that are used in single handed american sign language asl the approach exploit previous linguistic analysis of manual language that decompose dynamic gesture into their static and dynamic component the first level of decomposition is in term of three set of primitive hand shape location and movement further level of decomposition involve the lexical and sentence level and are part of our plan for future work we propose and subsequently demonstrate that given a monocular gesture sequence kinematic feature can be recovered from the apparent motion that provide distinctive signature for primitive movement of asl the approach ha been implemented in software and evaluated on a database of gesture sequence with an overall recognition rate of for fully automated processing and for manually initialized processing 
in this paper we propose a novel face photo retrievalsystem using sketch drawing by transforming a photoimage into a sketch we reduce the difference betweenphoto and sketch significantly thus allow effectivematching between the two to improve the synthesisperformance we separate shape and texture informationin a face photo and conduct transformation on themrespectively finally a bayesian classifier is used torecognize the probing sketch from the synthesizedpseudo sketch experiment on a data set containing people clearly demonstrate the efficacy of thealgorithm 
the flow pattern of ridge in a fingerprint is unique to the person in that no two people with the same fingerprint have yet been found fingerprint have been in use in forensic application for many year and more recently in computer automated identification and authentication for automated fingerprint image matching a machine representation of a fingerprint image is often a set of minutia in the print a minimal but fundamental representation is just a set of ridge ending and bifurcation oddly however after all the year of using minutia a precise definition of minutia ha never been formulated we provide a formal definition of a minutia based on the gray scale image this definition is constructive in that given a minutia image the minutia location and orientation can be uniquely determined 
natural eye design are optimized with regard to the tasksthe eye carrying organism ha to perform for survival thisoptimization ha been performed by the process of naturalevolution over many million of year every eye capturesa subset of the space of light ray the information containedin this subset and the accuracy to which the eye canextract the necessary information determines an upper limiton how well an organism can perform a given task in thiswork we propose a new methodology for camera design byinterpreting eye a sample pattern in light ray space wecan phrase the problem of eye design in a signal processingframework this allows u to develop mathematical criteriafor optimal eye design which in turn enables u to build thebest eye for a given task without the trial and error phase ofnatural evolution the principle is evaluated on the task of d ego motion estimation 
we describe a new framework based on boosting algorithm and cascade structure to efficiently detect object face with occlusion while our approach is motivated by the work of viola and jones several technique have been developed for establishing a more general system including i a robust boosting scheme to select useful weak learner and to avoid overfitting ii reinforcement training to reduce false positive rate via a more effective training procedure for boosted cascade and iii cascading with evidence to extend the system to handle occlusion without compromising in detection speed experimental result on detecting face under various situation are provided to demonstrate the performance of the proposed method 
the boundary of image region necessarily consist of edge inparticular step and roof edge corner and junction currently different algorithm are used to detect each boundarytype separately but the integration of the result into a singleboundary representation is difficult therefore a method for thesimultaneous detection of all boundary type is needed we proposeto combine response of suitable polar separable filter into whatwe will call the boundary tensor the trace of this tensor is ameasure of boundary strength while the small eigenvalue and itsdifference to the large one represent corner junction and edgestrengths respectively we prove that the edge strength measurebehaves like a rotationally invariant quadrature filter a numberof example demonstrate the property of the new method andillustrate it application to image segmentation 
inpainting is the problem of filling in hole in image considerable progress ha been made by technique that use theimmediate boundary of the hole and some prior information on imagesto solve this problem these algorithm successfully solve thelocal inpainting problem but they must by definition give thesame completion to any two hole that have the same boundary evenwhen the rest of the image is vastly different in this paper weaddress a different more global inpainting problem how can we usethe rest of the image in order to learn how to inpaint we approachthis problem from the context of statistical learning given atraining image we build an exponential family distribution overimages that is based on the histogram of local feature we thenuse this image specific distribution to in paint the hole byfinding the most probable image given the boundary and thedistribution the optimization is done using loopy beliefpropagation we show that our method can successfully completeholes while taking into account the specific image statistic inparticular it can give vastly different completion even when thelocal neighborhood are identical 
we propose a novel method for new view generation from a rectified sequence of image our new image correspond to a new camera model which we call a bi centric camera in this model the center of horizontal and vertical projection lie in different location on the camera s optical axis this model reduces to the regular pinhole camera when the two projection center coincide and the pushbroom camera when one projection center lie at infinity we first analyze the property of this camera model we then show how to generate new bi centric view from vertical cut in the epipolar volume of a rectified sequence every vertical cut generates a new bi centric view where the specific parameter of the cut determine the location of the projection center we discus and demonstrate application including the generation of image where the virtual camera lie behind occluding surface e g behind the back wall of a room and in unreachable position e g in front of a glass window our final application is the generation of movie taken by a simulated forward moving camera using a input a movie taken by a sideways moving camera 
detecting low level image feature such a edge and ridge with spatial filter is improved if the scale of the feature are known a priori scale space representation and wavelet pyramid address the problem by using filter over multiple scale however the scale of the filter are still fixed beforehand and the number of scale is limited by computational power the filtering operation are thus not adapted to detect image structure at their optimal or intrinsic scale we adopt the steering approach to obtain filter response at arbitrary scale from a small set of filter at scale chosen to accurately sample the scale space within a given range in particular we use the moore penrose inverse to learn the steering coefficient which we then regress by polynomial function fitting to the scale parameter in order to steer the filter response continuously across scale we show that the extremum of the polynomial steering function can be easily computed to detect interesting feature such a phase independent energy maximum such point of energy maximum in our scale space correspond to the intrinsic scale of the filtered image structure we apply the technique to several well known image to segment image structure which are mostly characterised by their intrinsic scale 
we present a method for object categorization in real world scene following a common consensus in the field we do not assume that a figureground segmentation is available prior to recognition however in contrast to most standard approach for object class recognition our approach automatically segment the object a a result of the categorization this combination of recognition and segmentation into one process is made possible by our use of an implicit shape model which integrates both into a common probabilistic framework in addition to the recognition and segmentation result it also generates a per pixel confidence measure specifying the area that support a hypothesis and how much it can be trusted we use this confidence to derive a natural extension of the approach to handle multiple object in a scene and resolve ambiguity between overlapping hypothesis with a novel mdl based criterion in addition we present an extensive evaluation of our method on a standard dataset for car detection and compare it performance to existing method from the literature our result show that the proposed method significantly outperforms previously published method while needing one order of magnitude le training example finally we present result for articulated object which show that the proposed method can categorize and segment unfamiliar object in different articulation and with widely varying texture pattern even under significant partial occlusion 
in order to investigate the deep structure of gaussian scale space image one need to understand the behaviour of spatial critical point under the influence of blurring we show how the mathematical framework of catastrophe theory can be used to describe the behaviour of critical point trajectory when various different type of generic event viz annihilation and creation of pair of spatial critical point almost coincide although such event are nongeneric in mathematical sense they are not unlikely to be encountered in practice furthermore the behaviour lead to the observation that fine to coarse tracking of critical point doesn t suffice we apply the theory to an artificial image and a simulated mr image and show the occurrence of the described behaviour 
in order to investigate the deep structure of gaussian scale space image one need to understand the behaviour of spatial critical point under the influence of blurring we show how the mathematical framework of catastrophe theory can be used to describe and model the behaviour of critical point trajectory when various different type of generic event viz annihilation and creation of pair of spatial critical point almost coincide although such event are non generic in mathematical sense they are not unlikely to be encountered in practice due to numerical limitation furthermore the behaviour of these trajectory lead to the observation that fine to coarse tracking of critical point doesn t suffice since they can form closed loop in scale space the modelling of the trajectory include these loop we apply the theory to an artificial image and a simulated mr image and show the occurrence of the described behaviour 
we present a method for learning feature descriptor using multiple image motivated by the problem of mobile robot navigation and localization the technique us the relative simplicity of small baseline tracking in image sequence to develop descriptor suitable for the more challenging task of wide baseline matching across significant viewpoint change the variation in the appearance of each feature are learned using kernel principal component analysis kpca over the course of image sequence an approximate version of kpca is applied to reduce the computational complexity of the algorithm and yield a compact representation our experiment demonstrate robustness to wide appearance variation on non planar surface including change in illumination viewpoint scale and geometry of the scene 
we propose modeling image and related visual object a bag ofpixels or set of vector for instance gray scale image aremodeled a a collection or bag of x y i pixel vector thisrepresentation implies a permutational invariance over the bag ofpixels which is naturally handled by endowing each image with apermutation matrix each matrix permit the image to span amanifold of multiple configuration capturing the vector set sinvariance to ordering or permutation transformation permutationconfigurations are optimized while jointly modeling many image viamaximum likelihood the solution is a uniquely solvable convexprogram which computes correspondence simultaneously for all image a opposed to traditional pairwise correspondence solution maximum likelihood performs a nonlinear dimensionality reduction choosing permutation that compact the permuted image vector intoa volumetrically minimal subspace this is highly suitable forprincipal component analysis which when applied to thepermutationally invariant bag of pixel representation outperformspca on appearance based vectorization by order ofmagnitude furthermore the bag of pixel subspace benefit fromautomatic correspondence estimation giving rise to meaningfullinear variation such a morphings translation and jointlyspatio textural image transformation result are shown forseveral datasets 
abstract particle filtering is a very popular technique for sequential state estimation problem however it convergence greatly depends on the balance between the number of particle hypothesis and the fitness of the dynamic model in particular in case where the dynamic are complex or poorly modeled thousand of particle are usually required for real application this paper present a hybrid sampling solution that combine the sampling in the image feature space and in the state space via ransac and particle filtering respectively we show that the number of particle can be reduced to dozen for a full d tracking problem which contains considerable noise of different type for unexpected motion a specific set of dynamic may not exist but it is avoided in our algorithm the theoretical convergence proof for particle filtering when integrating ransac is difficult but we address this problem by analyzing the likelihood distribution of particle from a real tracking example the sampling efficiency on the more likely area is much higher by the use of ransac we also discus the tracking quality measurement in the sense of entropy or statistical testing the algorithm ha been applied to the problem of d face pose tracking with changing moderate or intense expression we demonstrate the validity of our approach with several video sequence acquired in an unstructured environment key word random projection ransac particle filtering robust d face tracking 
background modeling and subtraction is a core componentin motion analysis the central idea behind such moduleis to create a probabilistic representation of the staticscene that is compared with the current input to performsubtraction such approach is efficient when the scene to bemodeled refers to a static structure with limited perturbation in this paper we address the problem of modeling dynamicscenes where the assumption of a static backgroundis not valid waving tree beach escalator naturalscenes with rain or snow are example inspired by the workproposed in we propose an on line auto regressivemodel to capture and predict the behavior of such scene towards detection of event we introduce a new metric thatis based on a state driven comparison between the predictionand the actual frame promising result demonstratethe potential of the proposed framework 
many sensing technique and image processing applicationsare characterized by noisy or corrupted image data anisotropic diffusion is a popular and theoretically wellunderstood technique for denoising such image diffusionapproaches however require the selection of an edgestopping function the definition of which is typically adhoc we exploit and extend recent work on the statisticsof natural image to define principled edge stopping functionsfor different type of imagery we consider a varietyof anisotropic diffusion scheme and note that they computespatial derivative at fixed scale from which we estimatethe appropriate algorithm specific image statistic goingbeyond traditional work on image statistic we also modelthe statistic of the eigenvalue of the local structure tensor novel edge stopping function are derived from these imagestatistics giving a principled way of formulating anisotropicdiffusion problem in which all edge stopping parametersare learned from training data 
we address the problem of finding a set of contour curve in a d or d image we consider the problem of perceptual grouping and contour completion where the data is an unstructured set of region in the image a new method to find complete curve from a set of edge point is presented contour are found a minimal path between connected component using the fast marching algorithm we find the minimal path between each of these component until the complete set of these region is connected the path are obtained using backpropagation from the saddle point to both component we then extend this technique to d the data is a set of connected component in a d image we find d minimal path that link together these component using a potential based on vessel detection we illustrate the capability of our approach to reconstruct tree structure in a d medical image dataset 
we are entering an era of more intelligent cognitive vision system such system can analyse activity in dynamic scene to compute conceptual description from motion trajectory of moving people and the object they interact with here we review progress in the development of flexible generative model that can explain visual input a a combination of hidden variable and can adapt to new type of input such model are particularly appropriate for the task posed by cognitive vision a 
two new technique based on nonparametric estimation of probability density are introduced which improve on the performance of equivalent robust method currently employed in computer vision the first technique draw from the projection pursuit paradigm in statistic and carry out regression m estimation with a weak dependence on the accuracy of the scale estimate the second technique exploit the property of the multivariate adaptive mean shift and accomplishes the fusion of uncertain measurement arising from an unknown number of source a an example the two technique are extensively used in an algorithm for the recovery of multiple structure from heavily corrupted data 
a requirement common to most dynamic vision applicationsis the ability to track object in a sequence of frame thisproblem ha been extensively studied in the past few year leading to several technique such a unscented particlefilter based tracker that exploit a combination of the assumed target dynamic empirically learned noise distributionsand past position observation while successful inmany scenario these tracker remain fragile to occlusionand model uncertainty in the target dynamic a we showin this paper these difficulty can be addressed by modelingthe dynamic of the target a an unknown operator thatsatisfies certain interpolation condition result from interpolationtheory can then be used to find this operator bysolving a convex optimization problem a illustrated withseveral example combining this operator with kalman andupf technique lead to both robustness improvement andcomputational complexity reduction 
abstract this paper quantifies the information gained in integrating local measurement using spectral graph partitioning we employ a large dataset of manually segmented image in order to learn an optimal affinity function between nearby pair of pixel region cue are computed a the similarity in brightness color and texture between image patch boundary cue are incorporated by looking for the presence of an intervening contour a large gradient along a straight line connecting two pixel we then use spectral clustering to find an approximate minimizer of the normalized cut partitioning the image into coherent segment we evaluate the power of local measurement and global segmentation in predicting the location of image boundary by computing the precision and recall with respect to the human groundtruth data the result show that spectral clustering is successful in suppressing noise and boosting weak signal over a wide variety of natural image 
in recent year particle filter have become a tremendouslypopular tool to perform tracking for non linearand or non gaussian model this is due to their simplicity generality and success over a wide range of challengingapplications particle filter and monte carlo methodsin general are however poor at consistently maintainingthe multi modality of the target distribution that may arisedue to ambiguity or the presence of multiple object toaddress this shortcoming this paper proposes to model thetarget distribution a a non parametric mixture model andpresents the general tracking recursion in this case it isshown how a monte carlo implementation of the generalrecursion lead to a mixture of particle filter that interactonly in the computation of the mixture weight thus leadingto an efficient numerical algorithm where all the resultspertaining to standard particle filter apply the ability ofthe new method to maintain posterior multi modality is illustratedon a synthetic example and a real world trackingproblem involving the tracking of football player in a videosequence 
we analyze visibility from static sensor in a dynamic scene with moving obstacle people such analysis is considered in a probabilistic sense in the context of multiple sensor so that visibility from e ven one sensor might be sufficient additionally we analyze worst case scenari o for high security area where target are non cooperative such visibility analysis provides important performance characterization of multi camera system furthermore maximization of visibility in a given region of interest yield the op timum number and placement of camera in the scene our analysis ha application in surveillance manual or automated and can be utilized for sensor planning in place like museum shopping mall subway station and parking lot we present several example scene simulated and real for which interesting camera configuration were obtained using the formal analysis developed in the paper 
we investigate the statistic of local geometric structure in natural image previous study of high contrast natural image patch have shown that in the state space of these patch we have a concentration of data point along a low dimensional non linear manifold that corresponds to edge structure in this paper we extend our analysis to a filter based multiscale image representation namely the local jet of gaussian scale space representation a new picture of natural image statistic seems to emerge where primitive such a edge blob and bar generate low dimensional non linear structure in the state space of image data 
this paper present a new method of detecting andpredicting motion tracking failure with application inhuman motion and gait analysis we define a trackingfailure a an event and describe it temporal characteristicsusing a hidden markov model hmm thisstochastic model is trained using previous example oftracking failure we derive vector observation for thehmm using the noise covariance matrix characterizinga tracked d structural model of the human body weshow a causal relationship between the conditional outputprobability of the hmm a transformed using alogarithmic mapping function and impending trackingfailures result are illustrated on several multi viewsequences of complex human motion 
the instability of the medial axis of a shape under deformation have long been recognized a a major obstacle to it use in recognition and other application these instability or transition occur when the structure of the medial axis graph change abruptly under deformation of shape the recent classification of these transition in d for the medial axis and for the shock graph wa a key factor both in the development of an object recognition system and an approach to perceptual organization this paper classifies generic transition of the d medial axis by examining the order of contact of sphere with the surface leading to an enumeration of possible transition which are then examined on a case by case basis some case are ruled out a never occurring in any family of deformation while others are shown to be non generic in a one parameter family of deformation finally the remaining case are shown to be viable by developing a specific example for each we relate these transition to a classification by bogaevsky of singularity of the viscosity solution of the hamilton jacobi equation we believe that the classification of these transition is vital to the successful regularization of the medial axis and it use in real application 
automatic unloading of piled box like object is undoubtedlyof great importance to the industry in this contributiona system addressing this problem is described weemploy a laser range finder for data acquisition and globallydeformable superquadrics for object modeling our technique is based on a hypothesis generation andrefinement scheme the vertex of the piled object are extractedand superquadric seed are aligned at these vertex the model parameter recovery task is decomposedinto two subproblems each dealing with a subset of themodel s parameter set both region and boundary based informationsources are used for parameter estimation comparedto a widespread strategy for superquadric recovery our method show advantage in term of robustnessand computational efficiency in addition our system exhibitsversatility with regard to existing industrial system since it can effectively deal with both neatly placed and jumbledconfigurations of object 
a linear discriminative supervised technique for reducing feature vector extracted from image data to a lower dimensional representation is proposed it is derived from classical fisher linear discriminant analysis lda and useful for example in supervised segmentation task in which high dimensional feature vector describes the local structure of the image in general the main idea of the technique is applicable in discriminative and statistical modelling that involves contextual data lda is a basic well known and useful technique in many application our contribution is that we extend the use of lda to case where there is dependency between the output variable i e the class label and not only between the input variable the latter can be dealt with in standard lda the principal idea is that where standard lda merely take into account a single class label for every feature vector the new technique incorporates class label of it neighborhood in it analysis a well in this way the spatial class label configuration in the vicinity of every feature vector is accounted for resulting in a technique suitable for e g image data this spatial lda is derived from a formulation of standard lda in term of canonical correlation analysis the linearly dimension reduction transformation thus obtained is called the canonical contextual correlation projection an additional drawback of lda is that it cannot extract more feature than the number of class minus one in the two class case this mean that only a reduction to one dimension is possible our contextual lda approach can avoid such extreme deterioration of the classification space and retain more than one dimension the technique is exemplified on a pixel based segmentation problem an illustrative experiment on a medical image segmentation task show the performance improvement possible employing the canonical contextual correlation projection 
we present a computational framework capable of labelingthe effort of an action corresponding to the perceivedlevel of exertion by the performer low high the approachinitially factorizes example at different effort ofan action into it three mode principal component to reducethe dimensionality then a learning phase is introducedto compute expressive feature weight to adjust themodel s estimation of effort to conform to given perceptuallabels for the example experiment are demonstrated recognizingthe effort of a person carrying bag of differentweight and for multiple people walking at different pace 
from the web with their enclosing web page or captioned news image we demonstrate that it is possible to automatically identify and often fix inaccuracy and resolve ambiguity in a large pool of inaccurately and ambiguously labelled face image rich and complex datasets tend to be inaccurately labelled cleaning up the labelling automatically make it possible to perform recognition experiment on interesting real world datasets we show quite good face clustering is possible for such a dataset our dataset is face image obtained by apply ing a face finder to approximately half a million captioned news image this dataset is more realistic than usual face recognition datasets because it contains face captured in the wild in a variety of configuration with respect to the camera taking a variety of expression and under illumi nation of widely varying color each face image is associ ated with a set of name automatically extracted from the associated caption many but not all such set contain the correct name we cluster face image in appropriate discriminant co ordinate we use a clustering procedure to break ambigu ities in labelling and identify incorrectly labelled face a merging procedure then identifies variant of name that re fer to the same individual the resulting representation can be used to label face in news image or to organize news picture by individual present an alternative view of our procedure is a a process that clean up noisy supervised data we demonstrate how to use entropy measure to evaluate such procedure and compare a variety of method for cleaning up our face data set 
existing method for incorporating subspace model constraint in contour tracking use only partial information from the measurement and model distribution we propose a complete fusion formulation for robust contour tracking optimally resolving uncertainty from heteroscedastic measurement noise system dynamic and a subspace model the resulting non orthogonal subspace projection is a natural extension of the traditional model constraint using orthogonal projection we build model for coupled double contour and exploit information from the ground truth initialization through a strong model adaptation our framework is applied for tracking in echocardiogram where the noise is heteroscedastic each heart ha distinct shape and the relative motion of epiand endocardial border reveal crucial diagnostic feature the proposed method significantly outperforms the traditional shape space constrained tracking algorithm due to the joint fusion of heteroscedastic uncertainty the strong model adaptation and the coupled tracking of double contour robust performance is observed even on the most challenging case 
we formulate the shape localization problem in the bayesian framework in the learning stage we propose the constrained rank boost approach to model the likelihood of local feature associated with the key point of an object like face while preserve the prior ranking order between the ground truth position of a key point and it neighbor in the inferring stage a simple efficient iterative algorithm is proposed to uncover the map shape by locally modeling the likelihood distribution around each key point via our proposed variational locally weighted learning vlwl method our proposed framework ha the following benefit compared to the classical pca model the likelihood presented by the ranking prior likelihood model ha more discriminating power a to the optimal position and it neighbor especially in the problem with ambiguity between the optimal position and their neighbor the vlwl method guarantee that the posterior probability of the derived shape increase monotonously and the above two method are both based on accurate probability formulation which spontaneously lead to a robust confidence measure for the discovered shape moreover we present a theoretical analysis for the convergence of the constrained rank boost extensive experiment compared with the active shape model demonstrate the accuracy robustness and stability of our proposed framework 
we present a new approach to d scene modeling basedon geometric constraint contrary to the existing method we can quickly obtain d scene model that respectthe given constraint exactly our system can describe alarge variety of linear and non linear constraint in a flexibleway to deal with the constraint we decided to exploit theproperties of the gpdof algorithm developed in the constraintprogramming community the approach isbased on a dictionary of so called r method based on theoremsof geometry which can solve a subset of geometricconstraints in a very efficient way gpdof is used to find in polynomial time a reduced parameterization of a scene and to decompose the equation system induced by constraint into a sequence of r method we have validatedour approach in reconstructing from image d modelsof building based on linear and quadratic geometric constraint 
this paper present an approach to build high resolution digital elevation map from a sequence of unregistered low altitude stereovision image pair the approach first us a visual motion estimation algorithm that determines the d motion of the camera between consecutive acquisition on the basis of visually detected and matched environment feature an extended kalman filter then estimate both the position parameter and the d position of the memorized feature a image are acquired detail are given on the filter implementation and on the estimation of the uncertainty on the feature observation and motion estimation experimental result show that the precision of the method enables to build spatially consistent very large map 
imaging of object under variable lighting direction is animportant and frequent practice in computer vision andimage based rendering we introduce an approach that significantlyimproves the quality of such image traditionalmethods for acquiring image under variable illuminationdirections use only a single light source per acquired image in contrast our approach is based on a multiplexing principle in which multiple light source illuminate the objectsimultaneously from different direction thus the objectirradiance is much higher the acquired image are thencomputationally demultiplexed the number of image acquisitionsis the same a in the single source method theapproach is useful for imaging dim object area we givethe optimal code by which the illumination should be multiplexedto obtain the highest quality output for n imagescorresponding to n light source the noise is reduced by sqrt n relative to the signal this noise reduction translatesto a faster acquisition time or an increase in density of illuminationdirection sample it also enables one to use lightingwith high directional resolution using practical setup a we demonstrate in our experiment 
in this paper we define a function r p which is defined for any polygon p and which map a given polygon p into a number from the interval the number r p can be used a an estimate of the rectilinearity of p the mapping r p ha the following desirable property any polygon p ha the estimated rectilinearity r p which is a number from r p if and only if p is a rectilinear polygon i e all interior angle of p belong to the set inf p r p where denotes the set of all polygon a polygon s rectilinearity measure is invariant under similarity transformation a simple procedure for computing r p for a given polygon p is described a well 
we derive a new class of photometric invariant that can beused for a variety of vision task including lighting invariantmaterial segmentation change detection and tracking aswell a material invariant shape recognition the key ideais the formulation of a scene radiance model for the class of separable brdfs that can be decomposed into materialrelated term and object shape and lighting related term all the proposed invariant are simple rational function ofthe appearance parameter say material or shape and lighting the invariant in this class differ from one another in thenumber and type of image measurement they require mostof the invariant in this class need change in illumination orobject position between image acquisition the invariantscan handle large change in lighting which pose problem formost existing vision algorithm we demonstrate the power ofthese invariant using scene with complex shape material texture shadow and specularities 
we present a novel approach called the one circle algorithm for measuring the eye gaze using a monocular image that zoom in on only one eye of a person observing that the iris contour is a circle we estimate the normal direction of this iris circle considered a the eye gaze from it elliptical image from basic projective geometry an ellipse can be back projected into space onto two circle of different orientation however by using an anthropometric property of the eyeball the correct solution can be disambiguated this allows u to obtain a higher resolution image of the iris with a zoom in camera and thereby achieving higher accuracy in the estimation the robustness of our gaze determination approach wa verified statistically by the extensive experiment on synthetic and real image data the two key contribution are that we show the possibility of finding the unique eye gaze direction from a single image of one eye and that one can obtain better accuracy a a consequence of this 
dominant set are a new graph theoretic concept that ha proven tobe relevant in partitional flat clustering a well a imagesegmentation problem however in many computer visionapplications such a the organization of an image database it isimportant to provide the data to be clustered with a hierarchicalorganization and it is not clear how to do this within thedominant set framework in this paper we address precisely thisproblem and present a simple and elegant solution to it to thisend we consider a family of continuous quadratic program whichcontain a parameterized regularization term that control theglobal shape of the energy landscape when the regularizationparameter is zero the local solution are known to be in one to onecorrespondence with dominant set but when it is positive aninteresting picture emerges we determine bound for theregularization parameter that allow u to exclude from the set oflocal solution those inducing cluster of size smaller than aprescribed threshold this suggests a new divisive hierarchicalapproach to clustering which is based on the idea of properlyvarying the regularization parameter during the clustering process straight forward dynamic from evolutionary game theory are used tolocate the solution of the quadratic program at each level of thehierarchy we apply the proposed framework to the problem oforganizing a shape database experiment with three differentsimilarity matrix and database reported in the literature havebeen conducted and the result confirm the effectiveness of ourapproach 
in this work we present discriminative random field drfs a discriminative framework for the classification ofimage region by incorporating neighborhood interactionsin the label a well a the observed data the discriminativerandom field offer several advantage over the conventionalmarkov random field mrf framework first the drfs allow to relax the strong assumption of conditionalindependence of the observed data generally used inthe mrf framework for tractability this assumption is toorestrictive for a large number of application in vision second the drfs derive their classification power by exploitingthe probabilistic discriminative model instead of thegenerative model used in the mrf framework finally allthe parameter in the drf model are estimated simultaneouslyfrom the training data unlike the mrf frameworkwhere likelihood parameter are usually learned separatelyfrom the field parameter we illustrate the advantage ofthe drfs over the mrf framework in an application ofman made structure detection in natural image taken fromthe corel database 
a novel active contour method is presented and applied to pose refinement and tracking the main innovation is that no feature are detected at any stage contour are simply assumed to remove statistical dependency between pixel on opposite side of the contour this assumption together with a simple model of shape variability of the geometric model lead to the application of an em method for maximizing the likelihood of pose parameter in addition a dynamical model of the system lead to the application of a kalman filter the method is demonstrated by tracking motor vehicle with d model 
we understand and reconstruct special surface from d data with line geometry method based on estimated surface normal we use approximation technique in line space to recognize and reconstruct rotational helical developable and other surface which are characterized by the configuration of locally intersecting surface normal for the computational solution we use a modified version of the klein model of line space obvious application of these method lie in reverse engineering we have tested our algorithm on real world data obtained from object a antique pottery gear wheel and a surface of the ankle joint 
we consider the problem of image segmentation using active contoursthrough the minimization of an energy criterion involving bothregion and boundary functionals these functionals are derivedthrough a shape derivative approach instead of classical calculusof variation the equation can be elegantly derived withoutconverting the region integral into boundary integral from thederivative we deduce the evolution equation of an active contourthat make it evolve towards a minimum of the criterion we focusmore particularly on statistical feature globally attached to theregion and especially to the probability density function of imagefeatures such a the color histogram of a region a theoreticalframework is set for the minimization of the distance between twohistograms for matching or tracking purpose an application ofthis framework to the segmentation of color histogram in videosequences is then proposed we briefly describe our numericalscheme and show some experimental result 
this paper is concerned with computing graph edit distance one ofthe criticism that can be leveled at existing method forcomputing graph edit distance is that it lack the formality andrigour of the computation of string edit distance hence our aimis to convert graph to string sequence so that standard stringedit distance technique can be used to do this we use graphspectral seriation method to convert the adjacency matrix into astring or sequence order we pose the problem of graph matching asmaximum aposteriori probability alignment of the seriationsequences for pair of graph this treatment lead to anexpression for the edit cost we compute the edit distance byfinding the sequence of string edit operation which minimise thecost of the path traversing the edit lattice the edit cost aredefined in term of the a posteriori probability of visiting a siteon the lattice we demonstrate the method with result on adata set of delaunay graph 
we address the problem of using external rotation information with uncalibrated video sequence the main problem addressed is what is the benefit of the orientation information for camera calibration it is shown that in case of a rotating camera the camera calibration problem is linear even in the case that all intrinsic parameter vary for arbitrarily moving camera the calibration problem is also linear but underdetermined for the general case of varying all intrinsic parameter however if certain constraint are applied to the intrinsic parameter the camera calibration can be computed linearily it is analyzed which constraint are needed for camera calibration of freely moving camera furthermore we address the problem of aligning the camera data with the rotation sensor data in time we give an approach to align these data in case of a rotating camera 
in this paper we present a mathematical theory for marr sprimal sketch we first conduct a theoretical study ofthe descriptive markov random field model and the generativewavelet sparse coding model from the perspectiveof entropy and complexity the competition between thetwo type of model defines the concept of sketchability which divide image into texture and geometry we then proposea primal sketch model that integrates the two modelsand in addition a gestalt field model for spatial organization we also propose a sketching pursuit process that coordinatesthe competition between two pursuit algorithm the matching pursuit and the filter pursuit that seekto explain the image by base and filter respectively themodel can be used to learn a dictionary of image primitive or textons in julesz s language for natural image the primal sketch model is not only parsimonious for imagerepresentation but produce meaningful sketch overa large number of generic image 
registration of a preoperative ct d image to one or more x rayprojection d image a special case of the pose estimationproblem ha been attempted in a variety of way with varyingdegrees of success recently there ha been a great deal ofinterest in intensity based method one of the drawback to suchmethods is the need to create digitally reconstructed radiograph drrs at each step of the optimization process drrs are typicallygenerated by ray casting an operation that requires o n time where we assume that n is approximately the size in voxels of oneside of the drr a well a one side of the ct volume we addressthis issue by extending light field rendering technique from thecomputer graphic community to generate drrs instead ofconventional rendered image using light field allows most of thecomputation to be performed in a preprocessing step after thisprecomputation very accurate drrs can be generated in o n time another important issue for d d registration algorithm isvalidation previously reported d d registration algorithm werevalidated using synthetic data or phantom but not clinical data we present an intensity based d d registration system thatgenerates drrs using light field we validate it performanceusing clinical data with a known gold standard transformation 
recently a d face recognition approach based on geometric invariant signature ha been proposed the key idea of the algorithm is a representation of the facial surface invariant to isometric deformation such a those resulting from facial expression one of the crucial stage in the construction of the geometric invariant is the measurement of geodesic distance on triangulated surface carried out by fast marching on triangulated domain fmtd proposed here is a method which us only the metric tensor of the surface for geodesic distance computation when combined with photometric stereo used for facial surface acquisition it allows constructing a bendinginvariant representation of the face without reconstructing the d surface 
this article proposes a solution of the lambertian shapefrom shading sfs problem in the case of a pinhole cameramodel performing a perspective projection our approachis based upon the notion of viscosity solution of hamilton jacobiequations this approach allows u to naturallydeal with nonsmooth solution and provides a mathematicalframework for proving correctness of our algorithm our work extends previous work in the area in three aspect first it model the camera a a pinhole whereasmost author assume an orthographic projection see for a panorama of the sfs problem up to and for a recent survey thereby extending the applicability ofshape from shading method to more realistic image inparticular it extends the work of and second byadapting the brightness equation to the perspective problem we obtain a new partial differential equation pde result about the existence and uniqueness of it solutionare also obtained third it allows u to come up with a newapproximation scheme and a new algorithm for computingnumerical approximation of the continuous solution aswell a a proof of their convergence toward that solution 
we present a single image highlight removal method thatincorporates illumination based constraint into image inpainting unlike occluded image region filled by traditional inpainting highlight pixel contain some useful information for guiding theinpainting process constraint provided by observed pixel color highlight color analysis and illumination color uniformity areemployed in our method to improve estimation of the underlyingdiffuse color the inclusion of these illumination constraintsallows for better recovery of shading and texture by inpainting experimental result are given to demonstrate the performance ofour method 
medical imaging often involves the injection of contrast agent andthe subsequent analysis of tissue enhancement pattern manyimportant type of tissue have characteristic enhancement pattern for example in magnetic resonance mr mammography malignanciesexhibit a characteristic wash out temporal pattern while in mrangiography artery vein and parenchyma each have their owndistinctive temporal signature in such image sequence there aresubstantial change in intensity however this change is dueprimarily to the contrast agent rather than the motion of sceneelements a a result the task of segmenting contrast enhancedimages pose interesting new challenge for computer vision inthis paper we propose a new image segmentation algorithm for imagesequences with contrast enhancement using a model based timeseries analysis of individual pixel we use energy minimizationvia graph cut to efficiently ensure spatial coherence the energyis minimized in an expectation maximization fashion that alternatesbetween segmenting the image into a number of non overlappingregions and finding the temporal profile parameter which bestdescribe the behavior of each region preliminary experiment on mrmammography and mr angiography study show the algorithm s abilityto find an accurate segmentation 
in this paper we present a novel class based segmentation method which is guided by a stored representation of the shape of object within a general class such a horse image the approach is different from bottom up segmentation method that primarily use the continuity of grey level texture and bounding contour we show that the method lead to markedly improved segmentation result and can deal with significant variation in shape and varying background we discus the relative merit of class specific and general image based segmentation method and suggest how they can be usefully combined 
previous manifold learning algorithm mainly focus on uncovering the low dimensional geometry structure from a set of sample that lie on or nearly on a manifold in an unsupervised manner however the representation from unsupervised learning are not always optimal in discriminating capability in this paper a novel algorithm is introduced to conduct discriminant analysis in term of the embedded manifold structure we propose a novel clustering algorithm called intra cluster balanced k mean icbkm which ensures that there are balanced sample for the class in a cluster and the local discriminative feature for all cluster are simultaneously calculated by following the global fisher criterion compared to the traditional linear kernel discriminant analysis algorithm ours ha the following characteristic it is approximately a locally linear yet globally nonlinear discriminant analyzer it can be considered a special kernel da with geometry adaptive kernel in contrast to traditional kda whose kernel is independent to the sample and it computation and memory cost are reduced a great deal compared to traditional kda especially for the case with large number of sample it doe not need to store the original sample for computing the low dimensional representation for new data the evaluation on toy problem show that it is effective in deriving discriminative representation for the problem with nonlinear classification hyperplane when applied to the face recognition problem it is shown that compared with lda and traditional kda on yale and pie database the proposed algorithm significantly outperforms lda and 
reconstruction based super resolution from motion video ha been an active area of study in computer vision and video analysis image alignment is a key component of super resolution algorithm almost all previous super resolution algorithm have assumed that standard method of image alignment can provide accurate enough alignment for creating super resolution image however a systematic study of the demand on accuracy of multi image alignment and it effect on super resolution ha been lacking furthermore implicitly or explicitly most algorithm have assumed that the multiple video frame or specific region of interest are related through global parametric transformation from previous work it is not at all clear how super resolution performs under alignment with piecewise parametric or local optical flow based method this paper is an attempt at understanding the influence of image alignment and warping error on super resolution requirement on the consistency of optical flow across multiple image are studied and it is shown that error resulting from traditional flow algorithm may render super resolution infeasible 
the robust regression technique in the ransac family are popular today in computer vision but their performance depends on a user supplied threshold we eliminate this drawback of ransac by reformulating another robust method the m estimator a a projection pursuit optimization problem the projection based pbm estimator automatically derives the threshold from univariate kernel density estimate nevertheless the performance of the pbm estimator equal or exceeds that of ransac technique tuned to the optimal threshold a value which is never available in practice experiment were performed both with synthetic and real data in the affine motion and fundamental matrix estimation task 
active object tracking for example in surveillance task becomesmore and more important these day besides the tracking algorithmsthemselves methodology have to be developed for reasonable activecontrol of the degree of freedom of all involved camera in thispaper we present an information theoretic approach that allows theoptimal selection of the focal length of two camera during active d object tracking the selection is based on the uncertainty inthe d estimation this allows u to resolve the trade off betweensmall and large focal length in the former case the chance isincreased to keep the object in the field of view of the camera in the latter one d estimation becomes more reliable also moredetails are provided for example for recognizing theobjects beyond a rigorous mathematical framework we presentreal time experiment demonstrating that we gain an improvementin d trajectory estimation by up to in comparison with trackingusing a fixed focal length 
feature point for image correspondence are often selectedaccording to subjective criterion e g edge density nostril in this paper we present a general non subjectivecriterion for selecting informative feature point based onthe correspondence model itself we describe the approachwithin the framework of the bayesian markov random field mrf model where the degree of feature point informationis encoded by the entropy of the likelihood term we proposethat feature selection according to minimum entropy of likelihood eol is le likely to lead to correspondence ambiguity thus improving the optimization process in termsof speed and quality of solution experimental resultsdemonstrate the criterion s ability to select optimal featurespoints in a wide variety of image context e g object face comparison with the automatic kanade lucas tomasifeature selection criterion show correspondence tobe significantly faster with feature point selected accordingto minimum eol in difficult correspondence problem 
an iterative method for reconstructing a d polygonalmesh and color texture map from multiple view of an objectis presented in each iteration the method first estimate atexture map given the current shape estimate the texturemap and it associated residual error image are obtainedvia maximum a posteriori estimation and reprojection of themultiple view into texture space next the surface shape isadjusted to minimize residual error in texture space thesurface is deformed towards a photometrically consistentsolution via a series of d epipolar search at randomlyselected surface point the texture space formulation hasimproved computational complexity over standard image basederror aproaches and allows computation of the reprojectionerror and uncertainty for any point on the surface moreover shape adjustment can be constrained suchthat the recovered model s silhouette match those of theinput image experiment with real world imagery demonstratethe validity of the approach 
a novel procedure is presented to construct image domainfilters receptive field that directly recover localmotion and shape parameter these receptive field arederived from training on image deformation that best discriminatebetween different shape and motion parameter beginning with the construction of d receptive fieldsthat detect local surface shape and motion parameterswithin cross section we show how the recovered shape andmotion model parameter are sufficient to produce local estimatesof time to collision in general filter pair receptive field can be synthesizedto perform or detect specific image deformation atthe heart of the method is the use of a matrix to representimage deformation correspondence between individual pixelsof two view of a surface the image correspondencematrix can be decomposed using singular value decompositionto yield a pair of corresponding receptive field thatdetect image change due to the deformation of interest 
traditional technique of dense optical flow estimation don t generally yield symmetrical solution the result will differ if they are applied between image i and i or between image i and i in this work we present a method to recover a dense optical flow field map from two image while explicitely taking into account the symmetry across the image a well a possible occlusion and discontinuity in the flow field the idea is to consider both displacement vector from i to i and i to i and to minimise an energy functional that explicitely encodes all those property this variational problem is then solved using the gradient flow defined by the euler lagrange equation associated to the energy in order to reduce the risk to be trapped within some irrelevant minimum a focusing strategy based on a multi resolution technique is used to converge toward the solution promising experimental result on both synthetic and real image are presented to illustrate the capability of this symmetrical variational approach to recover accurate optical flow 
we propose a switching hypothesized measurement shm model supporting multimodal probability distribution and present the application of the model in handling potential variability in visual environment when tracking multiple object jointly for a set of occlusion hypothesis a frame is measured once under each hypothesis resulting in a set of measurement at each time instant a computationally efficient shm filter is derived for online joint region tracking both occlusion relationship and state of the object are recursively estimated from the history of hypothesized measurement the reference image is updated adaptively to deal with appearance change of the object the shm model is generally applicable to various dynamic process with multiple alternative measurement method 
edge detection depends not only upon the assumed model of what an edge is but also on how this model is represented the problem of how to represent the edge model is typically neglected despite the fact that the representation is a bottleneck for both computational cost and accuracy we propose to represent edge model by a partition of the edge manifold corresponding to the edge model where each local element of the partition is described by it principal component we describe the construction of this representation and demonstrate it benefit for various edge model 
wepresentaprobabilisticframeworkforrecognizingobjects in image of cluttered scene hundred of object may be considered and searched in parallel each object is learned from a single training image and modeled by the visual appearance of a set of feature and theirpositionwithrespecttoacommonreferenceframe therecognition processcomputesidentityandpositionofobjectsinthescenebyflnding thebestinterpretationofthesceneintermsoflearnedobjects feature detected in an input image are either paired with database feature or marked a clutter each hypothesis is scored using a generative model of the image which is deflned using the learned object and a model for clutter while the space of possible hypothesis is enormously large one mayflndthebesthypothesise ciently weexploresomeheuristicstodo so our algorithm compare favorably with state of the art recognition system 
human activity can be described a a sequence of d body posture the traditional approach to recognition and d reconstruction of human activity ha been to track motion in d mainly using advanced geometric and dynamic model in this paper we reverse this process view based activity recognition serf a an input to a human body location tracker with the ultimate goal of d reanimation in mind we demonstrate that specific human action can be detected from single frame posture in a video sequence by recognizing the image of a person s posture a corresponding to a particular key frame from a set of stored key frame it is possible to map body location from the key frame to actual frame this is achieved using a shape matching algorithm based on qualitative similarity that computes point to point correspondence between shape together with information about appearance a the mapping is from fixed key frame our tracking doe not suffer from the problem of having to reinitialise when it get lost it is effectively a closed loop we present experimental result both for recognition and tracking for a sequence of a tennis player 
our goal is to recognize human action at a distance at resolution where a whole person may be say pixelstall we introduce a novel motion descriptor based onoptical flow measurement in a spatio temporal volume foreach stabilized human figure and an associated similaritymeasure to be used in a nearest neighbor framework makinguse of noisy optical flow measurement is the key challenge which is addressed by treating optical flow not asprecise pixel displacement but rather a a spatial patternof noisy measurement which are carefully smoothed andaggregated to form our spatio temporal motion descriptor to classify the action being performed by a human figurein a query sequence we retrieve nearest neighbor s from adatabase of stored annotated video sequence we can alsouse these retrieved exemplar to transfer d d skeletonsonto the figure in the query sequence a well a two formsof data based action synthesis do a i do and do a isay result are demonstrated on ballet tennis a well asfootball datasets 
we extend the constellation model to include heterogeneous part which may represent either the appearance or the geometry of a region of the object the part and their spatial conguration are learnt simultaneously and automatically without supervision from cluttered image we describe how this model can be employed for ranking the output of an image search engine when searching for object category it is shown that visual consistency in the output image can be identied and then used to rank the image according to their closeness to the visual object category although the proportion of good image may be small the algorithm is designed to be robust and is capable of learning in either a totally unsupervised manner or with a very limited amount of supervision we demonstrate the method on image set returned by google s image search for a number of object category including bottle camel car horse tiger and zebra 
learning visual model of object category notoriously requiresthousands of training example this is due to thediversity and richness of object appearance which requiresmodels containing hundred of parameter we present amethod for learning object category from just a few image it is based on incorporating generic knowledge which may be obtained from previously learntmodels of unrelated category we operate in a variationalbayesian framework object category are represented byprobabilistic model and prior knowledge is representedas a probability density function on the parameter of thesemodels the posterior model for an object category is obtainedby updating the prior in the light of one or more observation our idea are demonstrated on four diverse category human face airplane motorcycle spotted cat initially three category are learnt from hundred of trainingexamples and a prior is estimated from these thenthe model of the fourth category is learnt from to trainingexamples and is used for detecting new exemplar a setof test image 
the introduction of the joint image manifold allows to treatthe problem of recovering camera motion and epipolar geometryas the problem of fitting a manifold to the data measuredin a stereo pair the manifold ha a singularity andboundary therefore care must be taken when fitting it this paper review the notion of joint image manifold and how previous motion recovery method can be viewedin it context and then offer a new fitting method whichimproves upon previous result especially when the extentof the data and or the motion are small 
bayesian filtering provides a principled approach for a variety of problem in machine perception and robotics current filtering method work with analog hypothesis space and find approximate solution to the resulting non linear filtering problem using monte carlo approximation i e particle filter or linear approximation e g extended kalman filter instead in this paper we propose digitizing the hypothesis space into a large number n of discrete hypothesis thus the approach becomes equivalent to standard hidden markov model hmm except for the fact that we use a very large number of state one reason this approach ha not been tried in the past is that the standard forward filtering equation for discrete hmms require order n operation per time step and thus rapidly become prohibitive in our model however the state are arranged in two dimensional topology with locationindependent dynamic with this arrangement predictive distribution can be computed via convolution in addition the computation of log likelihood ratio can also be performed via convolution we describe algorithm that solve the filtering equation performing this convolution for a special class of transition kernel in order n operation per time step this allows exact solution of filtering problem in real time with hundred of thousand of discrete hypothesis we found this number of hypothesis sucient for object tracking problem we also propose principled method to adapt the model parameter in non stationary environment and to detect and recover from tracking error 
natural image are highly structured in their spatialconfiguration where one would expect a different spatialdistribution for every image a each image ha a differentspatiallay out we show that the spatial statistic of recordedimages can be explained by a single process of sequentialfragmentation the observation by a resolution limited sensorysystem turn out to have a profound influence on the observedstatistics of natural image the power law and normal distributionrepresent the extreme case of sequential fragmentation betweenthese two extreme spatial detail statistic deform from power lawto normal through the weibull type distribution a receptive fieldsize increase relative to image detail size 
we present a framework for calculating low dimensional base torepresent image irradiance from surface with isotropic reflectanceunder arbitrary illumination by representing the illumination andthe bidirectional reflectance distribution function brdf infrequency space a model for the image irradiance is derived thismodel is then reduced in dimensionality by analyticallyconstructing the principal component basis for all image given thevariations in both the illumination and the surface material theprincipal component basis are constructed in such a way that allthe symmetry helmholtz reciprocity and isotropy of the brdf arepreserved in the basis function using the framework we calculatea basis using a database of natural illumination and the curetdatabase containing brdfs of real world surface material 
this paper proposes a novel texture representation suitablefor recognizing image of textured surface under a widerange of transformation including viewpoint change andnon rigid deformation unlike many existing feature extractionmethods which treat the neighborhood of everypixel a a candidate texture element the proposed algorithmworks by selecting a sparse set of affine invariant localpatches this spatial selection process besides providinggreater computational efficiency 
paracatadioptric sensor combine a parabolic shaped mirrorand a camera inducing an orthographic projection such a configuration provides a wide field of view whilekeeping a single effective viewpoint previous work in centralcatadioptric sensor proved that a line project into aconic curve and that three line image are enough to calibratethe system however the estimation of the coniccurves where line are mapped is hard to accomplish ingeneral only a small arc of the conic is visible in the imageand conventional conic fitting technique are unable to correctlyestimate the curve the present work show that a setof conic curve corresponds to paracatadioptric line imagesif and only if certain property are verified these propertiesare used to constraint the search space and correctlyestimate the curve the accurate estimation of a minimumof three line image allows the complete calibration of theparacatadioptric camera if the camera is skewless and theaspect ratio is known then the conic fitting problem is solvednaturally by an eigensystem for the general situation theconic curve are estimated using non linear optimization 
it is widely known that for the affine camera model both shapeand motion can be factorized directly from the so called imagemeasurement matrix constructed from image point coordinate theability to extract both shape and motion from this matrix by asingle svd operation make this shape from motion approachattractive however it cannot deal with missing feature pointsand in the presence of outlier a direct svd to the matrix wouldyield highly unreliable shape and motion component in this paper we present an outlier correction scheme that iteratively updatesthe element of the image measurement matrix the magnitude andsign of the update to each element is dependent upon the residualrobustly estimated in each iteration the result is that outliersare corrected and retained giving improved reconstruction andsmaller reprojection error our iterative outlier correctionscheme ha been applied to both synthesized and real videosequences the result obtained are remarkably good 
we address visual correspondence problem without assuming that scene point have similar intensity in different view this situation is common usually due to nonlambertian scene or to difference between camera we use maximization of mutual information a powerful technique for registering image that requires no a priori model of the relationship between scene intensity in different view however it ha proven difficult to use mutual information to compute dense visual correspondence comparing fixed size window via mutual information suffers from the well known problem of fixed window namely poor performance at discontinuity and in low texture region in this paper we show how to compute visual correspondence using mutual information without suffering from these problem using a simple approximation mutual information can be incorporated into the standard energy minimization framework used in early vision the energy can then be efficiently minimized using graph cut which preserve discontinuity and handle low texture region the resulting algorithm combine the accurate disparity map that come from graph cut with the tolerance for intensity change that come from mutual information 
geodesic active contour and graph cut are two standard imagesegmentation technique we introduce a new segmentation methodcombining some of their benefit our main intuition is that anycut on a graph embedded in some continuous space can be interpretedas a contour in d or a surface in d we show how to build agrid graph and set it edge weight so that the cost of cut isarbitrarily close to the length area of the correspondingcontours surface for any anisotropic riemannian metric there aretwo interesting consequence of this technical result first graphcut algorithm can be used to find globally minimum geodesiccontours minimal surface in d under arbitrary riemannian metricfor a given set of boundary condition second we show how tominimize metrication artifact in existing graph cut based methodsin vision theoretically speaking our work provides an interestinglink between several branch of mathematics differentialgeometry integral geometry and combinatorial optimization themain technical problem is solved using cauchy crofton formula fromintegral geometry 
while navigating in an environment a vision system ha to be ableto recognize where it is and what the main object in the sceneare in this paper we present a context based vision system forplace and object recognition the goal is to identify familiarlocations e g office conference room main street tocategorize new environment office corridor street and to usethat information to provide contextual prior for objectrecognition e g table are more likely in an office than astreet we present a low dimensional global image representationthat provides relevant information for place recognition andcategorization and show how such contextual information introducesstrong prior that simplify object recognition we have trained thesystem to recognize over location indoors and outdoors and tosuggest the presence and location of more than different objecttypes the algorithm ha been integrated into a mobile system thatprovides real time feedback to the user 
abstract an efficient algorithmic solution to the classical five point relative pose problem is presented the problem is to find the possible solution for relative camera motion between two calibrated view given five corresponding point the algorithm consists of computing the coefficient of a tenth degree polynomial and subsequently finding it root it is the first algorithm well suited for numerical implementation that also corresponds to the inherent complexity of the problem the algorithm is used in a robust hypothesise and test framework to estimate structure and motion in real time 
abstract current computational approach to learning vi sual object category require thousand of training image are slow cannot learn in an incremental manner and cannot incorporate prior information into the learning process in addition no algorithm presented in the literature ha been tested on more than a handful of object category we present an method for learning object category from just a few training image it is quick and it us prior information in a principled way we test it on a dataset composed of image of object belonging to widely varied category our proposed method is based on making use of prior information assembled from unrelated object category which were previously learnt a generative probabilistic model is used which represents the shape and appearance of a constellation of feature belonging to the object the parameter of the model are learnt incrementally in a bayesian manner our incremental algorithm is compared experimentally to an earlier batch bayesian algorithm a well a to one based on maximum likelihood the incremental and batch version have comparable classification performance on small training set but incremental learning is significantly faster making real time learning feasible both bayesian method outperform maximum likelihood on small training set 
in this paper we present a probabilistic tracking framework that combine sound and vision to achieve more robust and accurate tracking of multiple object in a cluttered or noisy scene our measurement have a non gaussian multimodal distribution we apply a particle filter to track multiple people using combined audio and video observation we have applied our algorithm to the domain of tracking people with a stereo based visual foreground detection algorithm and audio localization using a beamforming technique our model also accurately reflects the number of people present we test the efficacy of our system on a sequence of multiple people moving and speaking in an indoor environment 
in low level vision the representation of scene property such a shape albedo etc are very high dimensional a they haveto describe complicated structure the approach proposed here is to let the image itself bear a much of the representationalburden a possible in many situation scene and image are closely related and it is possible to find a functional relationshipbetween them the scene information can be represented in reference to the image where the functional specifies how 
the optimal distance measure for a given discrimination task underthe nearest neighbor framework ha been shown to be the likelihoodthat a pair of measurement have different class label forimplementation and efficiency consideration the optimal distancemeasure wa approximated by combining more elementary distancemeasures defined on simple feature space in this paper weaddress two important issue that arise in practice for such anapproach a what form should the elementary distance measure ineach feature space take we motivate the need to use the optimaldistance measure in simple feature space a the elementarydistance measure such distance measure have the desirableproperty that they are invariant to distance respectingtransformations b how do we combine the elementary distancemeasures we present the precise statistical assumption underwhich a linear logistic model hold exactly we benchmark our modelwith three other method on a challenging face discrimination taskand show that our approach is competitive with the state of theart 
a method is proposed to track the full hand motion from d point reconstructed using a stereoscopic set of camera this approach combine the advantage of method that use d motion e g optical flow and those that use a d reconstruction at each time frame to capture the hand motion matching either contour or a d reconstruction against a d hand model is usually very difficult due to self occlusion and the locally cylindrical structure of each phalanx in the model but our use of d point trajectory constrains the motion and overcomes these problem our tracking procedure us both the d point match between two time frame and a smooth surface model of the hand build with implicit surface we used animation technique to represent faithfully the skin motion especially near joint robustness is obtained by using an em version of the icp algorithm for matching point between consecutive frame and the tracked point are then registered to the surface of the hand model result are presented on a stereoscopic sequence of a moving hand and are evaluated using a side view of the sequence 
there are two kind of omnidirectional camera often used in computer vision central catadioptric camera and fisheye camera previous literature use different imaging model to describe them separately a unified imaging model is however presented in this paper the unified model in this paper can be considered a an extension of the unified imaging model for central catadioptric camera proposed by geyer and daniilidis we show that our unified model can cover some existing model for fisheye camera and fit well for many actual fisheye camera used in previous literature under our unified model central catadioptric camera and fisheye camera can be classified by the model s characteristic parameter and a fisheye image can be transformed into a central catadioptric one vice versa an important merit of our new unified model is that existing calibration method for central catadioptric camera can be directly applied to fisheye camera furthermore the metric calibration from single fisheye image only using projection of line becomes possible via our unified model but the existing method for fisheye camera in the literature till now are all non metric under the same condition experimental result of calibration from some central catadioptric and fisheye image confirm the validity and usefulness of our new unified model 
this paper address the problem of computing the trajectoryof a camera from sparse positional measurementsthat have been obtained from visual localisation and densedifferential measurement from odometry or inertial sensor a fast method is presented for fusing these two sourcesof information to obtain the maximum a posteriori estimateof the trajectory a formalism is introduced for representingprobability density function over euclidean transformation and it is shown how these density function can bepropagated along the data sequence and how multiple estimatesof a transformation can be combined a three passalgorithm is described which make use of these result toyield the trajectory of the camera simulation result are presented which are validatedagainst a physical analogue of the vision problem and resultsare then shown from sequence of approximately frame captured from a video camera mounted on a go kart several of these frame are processed using computer visionto obtain estimate of the position of the go kart the algorithmfuses these estimate with odometry from the entiresequence in m to obtain the trajectory of the kart 
we derive a probabilistic multi scale model for contour completion based on image statistic the boundary of human segmented image are used a ground truth a probabilistic formulation of contour demand a prior model and a measurement model from the image statistic of boundary contour we derive both the prior model of contour shape and the local likelihood model of image measurement we observe multi scale phenomenon in the data and accordingly propose a higher order markov model over scale for the contour continuity prior various image cue derived from orientation energy are evaluated and incorporated into the measurement model based on these model we have designed a multi scale algorithm for contour completion which exploit both contour continuity and texture experimental result are shown on a wide range of image 
helmholtz stereopsis ha been previously introduced a a surface reconstruction technique that doe not assume a model of surface reectance this technique relies on the use of multiple camera and light source and it ha been shown to be effective when the camera and source position are known here we take a stratied look at uncalibrated helmholtz stereopsis we derive a new photometric matching constraint that can be used to establish correspondence without any knowledge of the camera and source except that they are co located and we determine condition under which we can obtain afne and metric reconstruction an implementation and experimental result are presented 
for structured light range imaging color stripe can be used for increasing the number of distinguishable light pattern compared to binary bw stripe therefore an appropriate use of color pattern can reduce the number of light projection and range imaging is achievable in single video frame or in one shot on the other hand the reliability and range resolution attainable from color stripe is generally lower than those from multiply projected binary bw pattern since color contrast is affected by object color reflectance and ambient light this paper present new method for selecting stripe color and designing multiple stripe pattern for one shot and two shot imaging we show that maximizing color contrast between the stripe in one shot imaging reduces the ambiguity resulting from colored object surface and limitation in sensor projector resolution two shot imaging add an extra video frame and maximizes the color contrast between the first and second video frame to diminish the ambiguity even further experimental result demonstrate the effectiveness of the presented one shot and two shot color stripe imaging scheme 
this paper present a method to estimate geometrical photometrical and environmental information of a single viewedobject in one integrated framework under fixed viewingposition and fixed illumination direction these threetypes of information are important to render a photorealisticimage of a real object photometrical information representsthe texture and the surface roughness of an object while geometrical and environmental information representthe d shape of an object and the illumination distribution respectively the proposed method estimate the d shapeby computing the surface normal from polarization data calculates the texture of the object from the diffuse only reflectioncomponent determines the illumination directionsfrom the position of the brightest intensity in the specularreflection component and finally computes the surfaceroughness of the object by using the estimated illuminationdistribution 
we present a novel method for tracking object by combiningdensity matching with shape prior density matchingis a tracking method which operates by maximizing thebhattacharyya similarity measure between the photometricdistribution from an estimated image region and a modelphotometric distribution such tracker can be expressed aspde based curve evolution which can be implemented usinglevel set shape prior can be combined with this level setimplementation of density matching by representing theshape prior a a series of level set a variational approachallows for a natural parametrization independentshape term to be derived experimental result on real imagesequences are shown 
we present a novel approach to modelling the non linear and timevarying dynamic of human motion using statistical method to capture the characteristic motion pattern that exist in typical human activity our method is based on automatically clustering the body pose space into connected region exhibiting similar dynamical characteristic modelling the dynamic in each region a a gaussian autoregressive process activity that would require large number of exemplar in example based method are covered by comparatively few motion model different region correspond roughly to different action fragment and our class inference scheme allows for smooth transition between these thus making it useful for activity recognition task the method is used to track activity including walking running etc using a planar d body model it effectiveness is demonstrated by it success in tracking complicated motion like turn without any key frame or d information 
is the real problem in resolving correspondence using currentstereo algorithm the lack of the right matching criterion in studying the related task of reconstructing three dimensionalspace curve from their projection in multipleviews we suggest that the problem is more basic matchingand reconstruction are coupled and so reconstruction algorithmsshould exploit this rather than assuming that matchingcan be successfully performed before reconstruction torealize this coupling a generative model of curve is introducedwhich ha two key component i a prior distributionof general space curve and ii an image formation modelwhich describes how d curve are projected onto the imageplane a novel aspect of the image formation model is that ituses an exact description of the gradient field of a piecewiseconstant image based on this forward model a fully automaticalgorithm for solving the inverse problem is developedfor an arbitrary number of view the resulting algorithmis robust to partial occlusion deficiency in image curveextraction and it doe not rely on photometric information the relative motion of the camera is assumed to be given several experiment are carried out on various realistic scenario in particular we focus on scene where traditionalcorrelation based method would fail 
d morphable model a a mean to generate image of a class ofobjects and to analyze them have become increasingly popular theproblematic part of this frameworkis the registration of the modelto an image a k a the fitting the characteristic feature of afitting algorithm are it efficiency robustness accuracy andautomation many accurate algorithm based on gradient descenttechniques exist which are unfortunately short on the otherfeatures recently an efficient algorithm called inversecompositional image alignment icia algorithm able to fit dimages wa introduced in this paper we extent this algorithm tofit d morphable model using a novel mathematical notation whichfacilitates the formulation of the fitting problem thisformulation enables u to avoid a simplification so far used in theicia being a efficient and leading to improved fitting precision additionally the algorithm is robust without sacrificing itsefficiency and accuracy thereby conforming to three of the fourcharacteristics of a good fitting algorithm 
ego motion estimation for an agile single camera movingthrough general unknown scene becomes a much morechallenging problem when real time performance is requiredrather than under the off line processing conditionsunder which most successful structure from motion workhas been achieved this task of estimating camera motionfrom measurement of a continuously expanding set of self mappedvisual feature is one of a class of problem knownas simultaneous localisation and mapping slam in therobotics community and we argue that such real time mappingresearch despite rarely being camera based is morerelevant here than off line structure from motion methodsdue to the more fundamental emphasis placed on propagationof uncertainty we present a top down bayesian framework for single cameralocalisation via mapping of a sparse set of naturalfeatures using motion modelling and an information guidedactive measurement strategy in particular addressingthe difficult issue of real time feature initialisation viaa factored sampling approach real time handling of uncertaintypermits robust localisation via the creating andactive measurement of a sparse map of landmark such thatregions can be re visited after period of neglect and localisationcan continue through period when few feature arevisible result are presented of real time localisation forum hand waved camera with very sparse prior scene knowledgeand all processing carried out on a desktop pc 
we present a novel method for generic visual categorization the problem of identifying the object content of natural image while generalizing across variation inherent to the object class this bag of keypoints method is based on vector quantization of affine invariant descriptor of image patch we propose and compare two alternative implementation using different classifier na ve bayes and svm the main advantage of the method are that it is simple computationally efficient and intrinsically invariant we present result for simultaneously classifying seven semantic visual category these result clearly demonstrate that the method is robust to background clutter and produce good categorization accuracy even without exploiting geometric information 
following futurism we show how periodic motion can be represented by a small number of eigen shape that capture the whole dynamic mechanism of periodic motion spectral decomposition of a silhouette of an object in motion serf a a basis for behavior classification by principle component analysis the boundary contour of the walking dog for example is first computed efficiently and accurately after normalization the implicit representation of a sequence of silhouette contour given by their corresponding binary image is used for generating eigen shape for the given motion singular value decomposition produce these eigen shape that are then used to analyze the sequence we show example of object a well a behavior classification based on the eigen decomposition of the binary silhouette sequence 
concept learning in content based image retrieval cbir system isa challenging task this paper present an active concept learningapproach based on mixture model to deal with the two basic aspectsof a database system changing image insertion or removal natureof a database and user query to achieve concept learning wedevelop a novel model selection method based on bayesian analysisthat evaluates the consistency of hypothesized model with theavailable information the analysis of exploitation v explorationin the search space help to find optimal model efficiently experimental result on corel database show the efficacy of ourapproach 
this paper proposes a robust estimation and validation framework for characterizing local structure in a positive multi variate continuous function approximated by a gaussian based model the new solution is robust against data with large deviation from the model and margin truncation induced by neighboring structure to this goal it unifies robust statistical estimation for parametric model fitting and multi scale analysis based on continuous scale space theory the unification is realized by formally extending the mean shift based density analysis towards continuous signal whose local structure is characterized by an anisotropic fully parameterized covariance matrix a statistical validation method based on analyzing residual error of the chi square fitting is also proposed to complement this estimation framework the strength of our solution is the aforementioned robustness experiment with synthetic d and d data clearly demonstrate this advantage in comparison with the normalized laplacian approach and the standard sample estimation approach p the new framework is applied to d volumetric analysis of lung tumor a d implementation is evaluated with high resolution ct image of patient with tumor including part solid or ground glass opacity nodule that are highly nongaussian and clinically significant our system accurately estimated d anisotropic spread and orientation for of the total tumor and also correctly rejected all the failure without any false rejection and false acceptance this system process each voxel volume of interest by an average of two second with a ghz intel cpu our framework is generic and can be applied for the analysis of blob like structure in various other application 
the objective of active recognition is to iteratively collect the next best measurement e g camera angle or viewpoint to maximally reduce ambiguity in recognition however existing work largely overlooked feature interaction issue feature selection on the other hand focus on the selection of a subset of measurement for a given classification task but is not context sensitive i e the decision doe not depend on the current input this paper proposes a unified perspective through conditional feature sensitivity analysis taking into account both current context and feature interaction based on different representation of the contextual uncertainty we present three treatment model and exploit their joint power for dealing with complex feature interaction synthetic example are used to systematically test the validity of the proposed model a practical application in medical domain is illustrated using an echocardiography database with more than video segment with both subjective from expert and objective validation 
the crossed slit x slit camera is defined by two non intersectingslits which replace the pinhole in the commonperspective camera each point in space is projected to theimage plane by a ray which pass through the point and thetwo slit the x slit projection model includes the pushb roomcamera a a special case in addition it describesa certain class of panoramic image which are generatedfrom sequence obtained by translating pinhole camera in this paper we develop the epipolar geometry of the x slitsprojection model we show an object which is similarto the fundamental matrix our matrix however describesa quadratic relation between corresponding image point using the veronese mapping similarly the equivalent ofepipolar line are conic in the image plane unlike the pin holecase epipolar surface do not usually exist in the sensethat matching epipolar line lie on a single surface we analyzethe case when epipolar surface exist and characterizetheir property finally we demonstrate the matchingof point in pair of x slit panoramic image 
estimating the number of people in a crowded environment is acentral task in civilian surveillance most vision based countingtechniques depend on detecting individual in order to count anunrealistic proposition in crowded setting we propose analternative approach that directly estimate the number of people in our system group of image sensor segment foreground objectsfrom the background aggregate the resulting silhouette over anetwork and compute a planar projection of the scene s visualhull we introduce a geometric algorithm that calculates bound onthe number of person in each region of the projection afterphantom region have been eliminated the computationalrequirements scale well with the number of sensor and the numberof people and only limited amount of data are transmitted overthe network because of these property our system run inreal time and can be deployed a an untethered wireless sensornetwork we describe the major component of our system and reportpreliminary experiment with our first prototype implementation 
within this paper a new framework for bayesian tracking ispresented which approximates the posterior distribution atmultiple resolution we propose a tree based representationof the distribution where the leaf define a partition ofthe state space with piecewise constant density the advantageof this representation is that region with low probabilitymass can be rapidly discarded in a hierarchical search and the distribution can be approximated to arbitrary precision we demonstrate the effectiveness of the technique byusing it for tracking d articulated and non rigid motionin front of cluttered background more specifically we areinterested in estimating the joint angle position and orientationof a d hand model in order to drive an avatar 
one significant challenge in the construction of visualdetection system is the acquisition of sufficient labeleddata this paper describes a new technique for trainingvisual detector which requires only a small quantity of labeleddata and then us unlabeled data to improve performanceover time unsupervised improvement is based onthe co training framework of blum and mitchell in whichtwo disparate classifier are trained simultaneously unlabeledexamples which are confidently labeled by one classifierare added with label to the training set of the otherclassifier experiment are presented on the realistic task ofautomobile detection in roadway surveillance video in thisapplication co training reduces the false positive rate by afactor of to from the classifier trained with labeled dataalone 
abstract we present an analytic solution to the problem of estimating multiple d and d motion model from two view correspondence or optical flow the key to our approach is to view the estimation of multiple motion model a the estimation of a single multibody motion model this is possible thanks to two im portant algebraic fact first we show that all the image measurement regardless of their associated motion model can be fit with a real or complex polynomial second we show that the parameter of the motion model associated with an im age measurement can be obtained from the derivative of the polynomial at the measurement this lead to a novel motion segmentation algorithm that applies to most of the two view motion model adopted in computer vision our experi ments show that the proposed algorithm outperforms existing algebraic method in term of efficiency and robustness and provides a good initialization for itera tive technique such a em which is strongly dependent on correct initialization 
in mixed reality especially in augmented virtuality whichvirtualizes real object it is important to estimate objectsurface reflectance property to render the object underarbitrary illumination condition though several method have beenexplored to estimate the surface reflectance property it isstill difficult to estimate surface reflectance parametersfaithfully for complex object which have non uniform surfacereflectance property and exhibitinter reflection this paperdescribes a new method for densely estimating non uniform surfacereflectance property of real object constructed of convex andconcave surface with interreflection we use registered range andsurface color texture image obtained by a laser range finder experiment show the usefulness of the proposed method 
in this paper we consider the image taken from pair ofparabolic catadioptric camera separated by discrete motion despite the nonlinearity of the projection model theepipolar geometry arising from such a system like the perspectivecase can be encoded in a bilinear form the catadioptricfundamental matrix we show that all such matriceshave equal lorentzian singular value and they definea nine dimensional manifold in the space of matrix furthermore this manifold can be identified with a quotientof two lie group we present a method to estimate a matrixin this space so a to obtain an estimate of the motion we show that the estimation procedure are robust to modestdeviations from the ideal assumption 
we aim to define an event ontology that allows natural representation of complex spatio temporal event common in the physical world by a composition of simpler event the event are abstracted into three hierarchy primitive event are defined directly from the mobile object property single thread composite event are a number of primitive event with temporal sequencing multi thread composite event are a number of single thread event with temporal spatial logical relationship this hierarchical event representation naturally lead to a language description of the event we define an event recognition language erl which allows the user to define the event of interest conveniently without interacting with the low level processing in the program we will also briefly mention some approach to compute the proposed representation 
this paper give an algorithm for detecting and reading text in natural image the algorithm is intended for use by blind and visually impaired subject walking through city scene we first obtain a dataset of city image taken by blind and normally sighted subject from this dataset we manually label and extract the text region next we perform statistical analysis of the text region to determine which image feature are reliable indicator of text and have low entropy i e feature response is similar for all text image we obtain weak classifier by using joint probability for feature response on and off text these weak classifier are used a input to an adaboost machine learning algorithm to train a strong classifier in practice we trained a cascade with strong classifier containg feature an adaptive binarization and extension algorithm is applied to those region selected by the cascade classifier an commercial ocr software is used to read the text or reject it a a non text region the overall algorithm ha a success rate of over evaluated by complete detection and reading of the text on the test set and the unread text is typically small and distant from the viewer 
in order to investigate the deep structure of gaussian scale space image one need to understand the behaviour of critical point under the influence of parameter driven blurring during this evolution two different type of special point are encountered the so called scale space saddle and the catastrophe point the latter describing the pairwise annihilation and creation of critical point the mathematical framework of catastrophe theory is used to model nongeneric event that might occur due to e g local symmetry in the image it is shown how this knowledge can be exploited in conjunction with the scale space saddle point yielding a scale space hierarchy tree that can be used for segmentation furthermore the relevance of creation of pair of critical point with respect to the hierarchy is discussed we clarify the theory with an artificial image and a simulated mr image 
in many medical computer vision task the relevant data isattached to a specific tissue such a the colon or the cortex this situation call for regularization technique whichare defined over surface we introduce in this paper thebeltrami flow over implicit manifold this new regularizationtechnique overcomes the over smoothing of the l flow and the staircasing effect of the l flow that wererecently suggested via the harmonic map method the keyof our approach is first to clarify the link between the intrinsic polyakov action and the implicit harmonic energyfunctional and then use the geometrical understanding ofthe beltrami flow to generalize it to image on implicitlydefined non flat surface it is shown that once again thebeltrami flow interpolates between the l and l flow onnon flat surface the implementation scheme of this flowis presented and various experimental result obtained on aset of various real image illustrate the performance of theapproach a well a the difference with the harmonic mapflows this extension of the beltrami flow to the case of nonflat surface open new perspective in the regularization ofnoisy data defined on manifold 
tahonen hadid mkp ee oulu fi http www ee oulu fi mvg abstract in this work we present a novel approach to face recognition which considers both shape and texture information to represent face image the face area is first divided into small region from which local binary pattern lbp histogram are extracted and concatenated into a 
we present a novel approach to modeling human gait such a walking and running we represent the trajectory of a certain number of salient feature on the human body a the output of a dynamical system driven by an unknown stochastic input we present technique for inferring model parameter and input signal distribution corresponding to difierent optimality criterion and evaluate the corresponding model for accuracy and predictive power in particular we exploit the higherorder statistical information content in motion capture data to arrive at input signal with independent component we show that human gait synthesized from nongaussian input best capture the dynamic complexity of the original gait data 
this paper present an optimization framework for estimating the motion and underlying physical parameter of a rigid body in free flight from video the algorithm take a video clip of a tumbling rigid body of known shape and generates a physical simulation of the object observed in the video clip this solution is found by optimizing the simulation parameter to best match the motion observed in the video sequence these simulation parameter include initial position and velocity environment parameter like gravity direction and parameter of the camera a global objective function computes the sum squared difference between the silhouette of the object in simulation and the silhouette obtained from video at each frame application include creating interesting rigid body animation tracking complex rigid body motion in video and estimating camera parameter from video 
we present a probabilistic approach to learning objectrepresentations based on the content and style bilineargenerative model of tenenbaum and freeman in contrastto their earlier svd based approach our approach modelsimages using particle filter we maintain separate particlefilters to represent the content and style space allowing usto define arbitrary weighting function over the particle tohelp estimate the content style density we combine thisapproach with a new em based method for learning basisvectors that describe content style mixing using a particle basedrepresentation permit good reconstruction despitereduced dimensionality and increase storage capacity andcomputational efficiency we describe how learning the distributionsusing particle filter allows u to efficiently computea probabilistic novelty term our example applicationconsiders a dataset of face under different lightingconditions the system classifies face of people it ha seenbefore and can identify previously unseen face a new content using a probabilistic definition of novelty in conjunctionwith learning content style separability provides a crucialbuilding block for designing real world real time objectrecognition system 
in this paper a bayesian self calibration approach using sequential importance sampling si is proposed given a set of feature correspondence tracked through an image sequence the joint posterior distribution of both camera extrinsic and intrinsic parameter a well a the scene structure are approximated by a set of sample and their corresponding weight the critical motion sequence are explicitly considered in the design of the algorithm the probability of the existence of the critical motion sequence is inferred from the sample and weight set obtained from the si procedure no initial guess for the calibration parameter is required the proposed approach ha been extensively tested on both synthetic and real image sequence and satisfactory performance ha been observed 
analyzing fluid motion is essential in number of domain and can rarely be handled using generic computer vision technique in this particular application context we address two distinct problem first we describe a dedicated dense motion estimator the approach relies on constraint issuing from fluid motion property and allows u to recover dense motion field of good quality secondly we address the problem of analyzing such velocity field we present a kind of motion based segmentation relying on an analytic representation of the motion field that permit to extract important quantity such a singularity stream function or velocity potential the proposed method ha the advantage to be robust simple and fast 
we present a set of algorithm that recovers detailed building surface structure from large set of urban image containing severe occlusion and lighting variation an iterative weighted average algorithm is introduced to recover high quality consensus facade texture d and d method are combined to extract microstructures facilitating urban model renemen t and visualization 
automatically understanding event happening at a site is the ultimate goal of visual surveillance system we investigate the challenge faced by automated surveillance system operating in hostile condition and demonstrate the developed algorithm via a system that detects water crisis within highly dynamic aquatic environment an efficient segmentation algorithm based on robust block based background modelling and thresholding with hysteresis methodology enables swimmer to be reliably detected amid reflection ripple splash and rapid lighting change partial occlusion are resolved using a markov random field framework that enhances the tracking capability of the system visual indicator of water crisis are identified based on professional knowledge of water crisis detection based on which a set of swimmer descriptor ha been defined through seamlessly fusing the extracted swimmer descriptor based on a novel functional link network the system achieves promising result for water crisis detection the developed algorithm have been incorporated into a live system with robust performance for different hostile environment faced by an outdoor swimming pool 
to what extent can three dimensional shape and radiancebe inferred from a collection of image can the two be estimatedseparately while retaining optimality how shouldthe optimality criterion be computed when is it necessaryto employ an explicit model of the reflectance property ofa scene in this paper we introduce a separation principlefor shape and radiance estimation that applies to lambertianscenes and hold for any choice of norm when thescene is not lambertian however shape cannot be decoupledfrom radiance and therefore matching image to imageis not possible directly we employ a rank constraint onthe radiance tensor which is commonly used in computergraphics and construct a novel cost functional whose minimizationleads to an estimate of both shape and radiancefor non lambertian object which we validate experimentally 
we present an novel algorithm that reconstructs voxels of a general d specular surface from multiple image of a calibrated camera acalibrated scene i e point whose d coordinate are known isreflected by the unknown specular surface onto the image plane ofthe camera for every viewpoint surface normal are associated tothe voxels traversed by each projection ray formed by thereflection of a scene point a decision process then discardsvoxels whose associated surface normal are not consistent with oneanother the output of the algorithm is a collection of voxels andsurface normal in d space whose quality and size depend onuser set threshold the method ha been tested on synthetic andreal image visual and quantified experimental result arepresented 
previous study have demonstrated that the appearance ofan object under varying illumination condition can be representedby a low dimensional linear subspace a set ofbasis image spanning such a linear subspace can be obtainedby applying the principal component analysis pca for a large number of image taken under different lightingconditions while the approach based on pca havebeen used successfully for object recognition under varyingillumination condition little is known about how many imageswould be required in order to obtain the basis imagescorrectly in this study we present a novel method for analyticallyobtaining a set of basis image of an object forarbitrary illumination from input image of the object takenunder a point light source the main contribution of ourwork is that we show that a set of lighting direction canbe determined for sampling image of an object dependingon the spectrum of the object s brdf in the angularfrequency domain such that a set of harmonic image canbe obtained analytically based on the sampling theorem onspherical harmonic in addition unlike the previously proposedtechniques based on spherical harmonic our methoddoes not require the d shape and reflectance property ofan object used for rendering harmonic image of the objectsynthetically 
abstract nonlinear partial differential equation pde are now widely used to regularize image they allow to eliminate noise and artifact while preserving large global feature such a object contour in this context we propose a geometric framework to design pde flow actingon constrained datasets we focus our interest on flow of matrixvalued function undergoing orthogonal and spectral constraint the correspondingevolution pde s are found by minimization of cost functionals and depend on the natural metric of the underlyingconstrained manifold viewed a lie group or homogeneous space suitable numerical scheme that fit the constraint are also presented we illustrate this theoretical framework through a recent and challenging problem in medical imaging the regularization of diffusion tensor volume dtmri 
we propose a variational method for segmenting imagesequences into spatio temporal domain of homogeneousmotion to this end we formulate the problem of motionestimation in the framework of bayesian inference using aprior which favor domain boundary of minimal surfacearea we derive a cost functional which depends on a surfacein space time separating a set of motion region aswell a a set of vector modeling the motion in each region we propose a multiphase level set formulation of thisfunctional in which the surface and the motion region arerepresented implicitly by a vector valued level set function joint minimization of the proposed functional result in aneigenvalue problem for the motion model of each region andin a gradient descent evolution for the separating interface numerical result on real world sequence demonstratethat minimization of a single cost functional generates asegmentation of space time into multiple motion region 
automatic construction of shape model from example hasbeen the focus of intense research during the last coupleof year these method have proved to be useful forshape segmentation tracking and shape understanding inthis paper novel theory to automate shape modelling is described the theory is intrinsically defined for curve althoughcurves are infinite dimensional object the theoryis independent of parameterisation and affine transformation we suggest a method for implementing the ideasand compare it to minimising the description length of themodel mdl it turn out that the accuracy of the two methodsis comparable both the mdl and our approach can getstuck at local minimum our algorithm is le computationalexpensive and relatively good solution are obtained after afew iteration the mdl is however better suited at fine tuningthe parameter given good initial estimate to theproblem it is shown that a combination of the two methodsoutperforms either on it own 
cheap camera and fast processor have made it possible to visually exploit geometric constraint in real time it ha been shown that the fast depth segmentation fds algorithm successfully exploit geometric constraint to perform visual foreground background segmentation in environment where other vision routine fail this paper present new insight into the operation of the fds algorithm that lead to the concept of a virtual surface margin we then show how surface margin can be used to extend the fds algorithm and thereby enable a class of logical volume operation that go far beyond simple background segmentation task an example application called touchit is demonstrated touchit utilizes surface margin to create a virtual volume configuration that is useful for detecting physical proximity to a surface we also present refinement in the the implementation of the fds algorithm that make these volumetric computation practical for interactive application by taking advantage of the single instruction multiple data simd instruction set extension that have recently become commonly available in consumer grade microprocessor 
we present a new approach to recognizing event invideos we first detect and track moving object in thescene based on the shape and motion property ofthese object we infer probability of primitive eventsframe by frame by using bayesian network compositeevents consisting of multiple primitive event overextended period of time are analyzed by using a hidden semi markov finite state model this result in morereliable event segmentation compared to the use of standardhmms in noisy video sequence at the cost of someincrease in computational complexity we describe ourapproach to reducing this complexity we demonstratethe effectiveness of our algorithm using both real worldand pertubed data 
there are many challenge associated with the integration ofsynthetic and real imagery one particularly difficult problem isthe automatic extraction of salient parameter of natural phenomenain real video footage for subsequent application to syntheticobjects can we ensure that the hair and clothing of a syntheticactor placed in a meadow of swaying grass will move consistentlywith the wind that moved that grass the video footage can be seenas a controller for the motion of synthetic feature a concept wecall video input driven animation vida we propose a schema thatanalyzes an input video sequence extract parameter from themotion of object in the video and us this information to drivethe motion of synthetic object to validate the principle ofvida we approximate the inverse problem to harmonic oscillation which we use to extract parameter of wind and of regular waterwaves we observe the effect of wind on a tree in a video estimatewind speed parameter from it motion and then use this to makesynthetic object move we also extract water elevation parametersfrom the observed motion of boat and apply the resulting waterwaves to synthetic boat 
this article present a novel representation for dynamic scene composed of multiple rigid object that may undergo different motion and are observed by a moving camera multi view constraint associated with group of affine co variant scene patch and a normalized description of their appearance are used to segment a scene into it rigid component construct three dimensional model of these component and match instance of model recovered from different image sequence the proposed approach ha been applied to the detection and matching of moving object in video sequence and to shot matching i e the identification of shot that depict the s ame scene in a video clip 
this paper present an algorithm for computing optical flow shape motion lighting and albedo from an image sequenceof a rigidly moving lambertian object under distant illumination the problem is formulated in a manner that subsumesstructure from motion multi view stereo and photometricstereo a special case the algorithm utilizes bothspatial and temporal intensity variation a cue the formerconstrains flow and the latter constrains surface orientation combining both cue enables dense reconstruction ofboth textured and texture le surface the algorithm worksby iteratively estimating affine camera parameter illumination shape and albedo in an alternating fashion result aredemonstrated on video of hand held object moving in frontof a fixed light and camera 
statistical background modelling and subtraction ha proved to be apopular and effective class of algorithm for segmentingindependently moving foreground object outfrom a staticbackground without requiring any a priori information of theproperties of foreground object this paper present twocontributions on this topic aimed towards robotics where an activehead is mounted on a mobile vehicle in period when the vehicle swheels are not driven camera translation is virtually zero andbackground subtraction technique are applicable part of thiswork are also highly relevant to surveillance and videoconferencing the first part of the paper present an efficientprobabilistic framework for when the camera pan and tilt aunified approach is developed for handling various source oferror including motion blur sub pixel camera motion mixed pixelsat object boundary and also uncertainty in backgroundstabilisation caused by noise unmodelled radial distortion andsmall translation of the camera the second contribution regard abayesian approach to specifically incorporate uncertaintyconcerning whether the background ha yet been uncovered by movingforeground object this is an important requirement duringinitialisation of a system we cannot assume that a backgroundmodel is available in advance since that would involve storingmodels for each possible position in every room of the robot soperating environment instead the background model must begenerated online very possibly in the presence of moving object 
abstract in many application of graphical model arising in computer vision the hi dden variable of interest are most naturally specified by continuous non gaussian distribution there ex ist inference algorithm for discrete approximation to these continuous distribution but fo r the high dimensional variable typically of interest discrete inference becomes infeasible stochastic method such a particle filter provide an appealing alternative however existing technique fail to exp loit the rich structure of the graphical model describing many vision problem drawing on idea from regularized particle filter and belief propagation b p this paper develops a nonparametric belief propagation nbp algorithm applicable to general graph each nbp iteration us an efficient sampling procedure to update kernel based approximation t o the true continuous likelihood the algorithm can accomodate an extremely broad class of potential function including nonparametric representation thus nbp extends particle filtering method t o the more general vision problem that graphical model can describe we apply the nbp algorithm to infer component interrelationship in a part based face model allowing location and reconstruction o f occluded feature this report describes research done within the laboratory for information and decision system and the artificial intelli 
this paper proposes a solution for the automatic detection and tracking of human motion in image sequence due to the complexity of the human body and it motion automatic detection of d human motion remains an open and important problem existing approach for automatic detection and tracking focus on d cue and typically exploit object appearance color distribution shape or knowledge of a static background in contrast we exploit d optical flow information which provides rich descriptive cue while being independent of object and background appearance to represent the optical flow pattern of people from arbitrary viewpoint we develop a novel representation of human motion using low dimensional spatio temporal model that are learned using motion capture data of human subject in addition to human motion the foreground we probabilistically model the motion of generic scene the background these statistical model are defined a gibbsian field specified from the first order derivative of motion observation detection and tracking are posed in a principled bayesian framework which involves the computation of a posterior probability distribution over the model parameter i e the location and the type of the human motion given a sequence of optical flow observation particle filtering is used to represent and predict this non gaussian posterior distribution over time the model parameter of sample from this distribution are related to the pose parameter of a d articulated model e g the approximate joint angle and movement direction thus the approach prof suitable for initializing more complex probabilistic model of human motion a shown by experiment on real image sequence our method is able to detect and track people under different viewpoint with complex background 
given a set of image acquired from known viewpoint wedescribe a method for synthesizing the image which wouldbe seen from a new viewpoint in contrast to existing technique which explicity reconstruct the d geometry of thescene we transform the problem to the reconstruction ofcolour rather than depth this retains the benefit of geometricconstraints but project out the ambiquities in depthestimation which occur in textureless region on the other hand regularization is still needed in orderto generate high quality image the paper s secondcontribution is to constrain the generated view to lie in thespace of image whose texture statistic are those of the inputimages this amount to a image based prior on thereconstruction which regularizes the solution yielding realisticsynthetic view example are given of new viewgeneration for camera interpolated between the acquisitionviewpoints which enables synthetic steadicam stabilizationof a sequence with a high level of realism 
given a set of image acquired from known viewpoint we describe a method for synthesizing the image which would be seen from a new viewpoint in contrast to existing technique which explicitly reconstruct the d geometry of the scene we transform the problem to the reconstruction of colour rather than depth this retains the benefit of geometric constraint but project out the ambiguity in depth estimation which occur in textureless region on the other hand regularization is still needed in order to generate high quality image the paper s second contribution is to constrain the generated view to lie in the space of image whose texture statistic are those of the input image this amount to an image based prior on the reconstruction which regularizes the solution yielding realistic synthetic view example are given of new view generation for camera interpolated between the acquisition viewpoint which enables synthetic steadicam stabilization of a sequence with a high level of realism 
vision algorithm utilizing camera network with a commonfield of view are becoming increasingly feasible andimportant calibration of such camera network is a challengingand cumbersome task the current approach forcalibration using plane or a known d target may not befeasible a these object may not be simultaneously visiblein all the camera in this paper we present a new algorithmto calibrate camera using occluding contour of sphere in general an occluding contour of a sphere project to anellipse in the image our algorithm us the projection ofthe occluding contour of three sphere and solves for theintrinsic parameter and the location of the sphere theproblem is formulated in the dual space and the parametersare solved for optimally and efficiently using semi definiteprogramming the technique is flexible accurate and easyto use in addition since the contour of a sphere is simultaneouslyvisible in all the camera our approach cangreatly simplify calibration of multiple camera with a commonfield of view experimental result from computer simulateddata and real world data both for a single cameraand multiple camera are presented 
we consider a sequence of three model for skin detection built from a large collection of labelled image each model is a maximum entropy model with respect to constraint concerning marginal distribution our model are nested the first model is well known from practitioner pixel are considered a independent the second model is a hidden markov model it includes constraint that force smoothness of the solution the third model is a first order model the full color gradient is included parameter estimation a well a optimization cannot be tackled without approximation we use thoroughly bethe tree approximation of the pixel lattice within it parameter estimation is eradicated and the belief propagation algorithm permit to obtain exact and fast solution for skin probability at pixel location we then ass the performance on the compaq database 
recent result on sparse coding and independent component analysis suggest that human vision first represents a visual image by a linear superposition of a relatively small number of localized elongate oriented image base with this representation the sketch of an image consists of the location orientation and elongation of the image base and the sketch can be visually illustrated by depicting each image base by a linelet of the same length and orientation built on the insight of sparse and independent component analysis we propose a two level generative model for texture at the bottom level the texture image is represented by a linear superposition of image base at the top level a markov model is assumed for the placement of the image base or the sketch and the model is characterized by a set of simple geometrical feature statistic 
d surface classification is a fundamental problem incomputer vision and computational geometry surface canbe classified by different transformation group traditionalclassification method mainly use topological transformationgroups and euclidean transformation group this paperintroduces a novel method to classify surface by conformaltransformation group conformal equivalent classis refiner than topological equivalent class and coarser thanisometric equivalent class making it suitable for practicalclassification purpose for general surface the gradientfields of conformal map form a vector space which hasa natural structure invariant under conformal transformation we present an algorithm to compute this conformalstructure which can be represented a matrix and use itto classify surface the result is intrinsic to the geometry invariant to triangulation and insensitive to resolution tothe best of our knowledge this is the first paper to classifysurfaces with arbitrary topology by global conformal invariant the method introduced here can also be used forsurface matching problem 
to bridge the gap between low level feature and high level semantic query in image retrieval detecting meaningful visual entity e g face sky foliage building etc based on trained pattern classifier ha become an active research trend however a drawback of the supervised learning approach is the human effort to provide labeled region a training sample in this paper we propose a new three stage hybrid framework to discover local semantic pattern and generate their sample for training with minimal human intervention support vector machine svm are first trained on local image block from a small number of image labeled a several semantic category then to bootstrap the local semantics image block that produce high svm output are grouped into discovered semantic region dsrs using fuzzy c mean clustering the training sample for these dsrs are automatically induced from cluster membership and subject to support vector machine learning to form local semantic detector for dsrs an image is then indexed a a tessellation of dsr histogram and matched using histogram intersection we evaluate our method against the linear fusion of color and texture feature using semantic query on heterogeneous consumer photo the dsr model achieved a promising improvement in average precision over that of the feature fusion approach 
this paper address the problem of large scale multiview registration of range image captured from unknown viewing direction to reduce the computational burden we decouple the local problem of pairwise registration on neighboring view from the global problem of distribution of accumulated error we define the global problem over the graph of neighboring view and we show that this graph can be decomposed into a set of cycle such that the optimal transformation parameter for each cycle can be solved in closed form we then describe an iterative procedure that can be used to integrate the solution for the set of cycle across the graph this method for error distribution doe not require point correspondence between view and therefore can be used together with robot odometry or any method of pairwise registration experimental result demonstrate the effectiveness of this technique on range image of an indoor facility 
abstract it is a well known classical result that given the image projection of three known world point it is possible to solve for the pose of a calibrated perspective camera to up to four pair of solution we solve the generalised problem where the camera is allowed to sample ray in some arbitrary but known fashion and is not assumed to perform a central perspective projection that is given three back projected ray that emanate from a camera or multi camera rig in an arbitrary but known fashion we seek the possible pose of the camera such that the three ray meet three known world point we show that the generalised problem ha up to eight solution that can be found a the intersection between a circle and a ruled quartic surface a minimal and efficient constructive numerical algorithm is given to find the solution the algorithm derives an octic polynomial whose root correspond to the solution in the classical case when the three ray are concurrent the ruled quartic surface and the circle posse a reflection symmetry such that their intersection come in symmetric pair this manifest itself in that the odd order term of the octic polynomial vanish a a result the up to four pair of solution can be found in closed form the proposed algorithm can be used to solve for the pose of any type of calibrated camera or camera rig the intended use for the algorithm is in a hypothesise and test architecture 
we present a novel representation of shape for closedplanar contour explicitly designed to posse a linearstructure this greatly simplifies linear operation suchas averaging principal component analysis or differentiation in the space of shape the representation reliesupon embedding the contour on a subset of the space ofharmonic function of which the original contour is thezero level set 
various problem in computer vision become dicult due to a strong influence of lighting on the image of an object recent work showed analytically that the set of all image of a convex lambertian object can be accurately approximated by the low dimensional linear subspace constructed using spherical harmonic function in this paper we present two major contribution first we extend previous analysis of spherical harmonic approximation to the case of arbitrary object second we analyze it applicability for near light we begin by showing that under distant lighting with uniform distribution of light source the average accuracy of spherical harmonic representation can be bound from below this bound hold for object of arbitrary geometry and color and for general illumination consisting of any number of light source we further examine the case when light is coming from above and provide an analytic expression for the accuracy obtained in this case finally we show that low dimensional representation using spherical harmonic provide an accurate approximation also for fairly near light our analysis assumes lambertian reflectance and account for attached but not for cast shadow we support this analysis by simulation and real experiment including an example of a d shape reconstruction by photometric stereo under very close unknown lighting 
multiple projection of a scene cannot be arbitrary the allowedconfigurations being given by matching constraint this paper present new matching constraint on multipleprojections of a rigid point set by uncalibrated camera obtainedby formulation in the oriented projective rather thanprojective geometry they follow from consistency of orientationsof camera ray and from the fact that the scene is theaffine rather that projective space for their non parametricnature we call them combinatorial the constraint are derivedin a unified theoretical framework using the theory oforiented matroids for example we present constraint on point correspondence for d camera resectioning on correspondence in two d camera and on correspondencesin two d camera 
this paper describes a novel approach to automatically recovercorresponding feature point and epipolar geometry over two widebaseline frame our contribution consist of several aspect first the use of an affine invariant feature edge corner isintroduced to provide a robust and consistent matching primitive second based on svd decomposition of affine matrix the affinematching space between two corner can be approximately dividedinto two independent space by rotation angle and scaling factor employing this property a two stage affine matching algorithm isdesigned to obtain robust match over two frame third using theepipolar geometry estimated by these match more correspondingfeature point are determined based on these robustcorrespondences the fundamental matrix is refined and a series ofvirtual view of the scene are synthesized finally severalexperiments are presented to illustrate that a number of robustcorrespondences can be stably determined for two wide baselineimages under significant camera motion with illumination change occlusion and self similarity after testing a number ofexamples and comparing with the existing method the experimentalresults strongly demonstrate that our matching method outperformsthe state of art algorithm for all of the test case 
recent development in computer vision have shown that localfeatures can provide efficient representation suitable for robustobject recognition support vector machine have been establishedas powerful learning algorithm with good generalizationcapabilities in this paper we combine these two approach andpropose a general kernel method for recognition with localfeatures we show that the proposed kernel satisfies the mercercondition and that it is suitable for many established localfeature framework large scale recognition result are presentedon three different database which demonstrate that svms with theproposed kernel perform better than standard matching technique onlocal feature in addition experiment on noisy and occludedimages show that local feature representation significantlyoutperform global approach 
this paper address the problem of recognizing three dimensional d object in photograph and image sequence it revisits viewpoint invariant a a local representation of shape and appearance and proposes a unified framework for object recognition where object model consist of a collection of small planar patch their invariant and a description of their d spatial relationship this approach is applied to two fundamental instance of the d object recognition problem modeling rigid d object from a small set of unregistered picture and recognizing them in cluttered photograph taken from unconstrained viewpoint and recognizing non uniform texture pattern despite appearance variation due to non rigid transformation and change in viewpoint it is validated through several experiment and extension to the analysis of video sequence and the recognition of object category are briefly discussed 
symmetry is an effective geometric cue to facilitate conventionalsegmentation technique on image of man madeenvironment based on three fundamental principle thatsummarize the relation between symmetry and perspectiveimaging namely structure from symmetry symmetry hypothesistesting and global symmetry testing we developa prototype system which is able to automatically segmentsymmetric object in space from single d perspective image the result of such a segmentation is a hierarchy ofgeometric primitive called symmetry cell and complex whose d structure and pose are fully recovered such ageometrically meaningful segmentation may greatly facilitateapplications such a feature matching and robot navigation 
we present a new texture classification scheme whichis invariant to surface rotation many textureclassification approach have been presented in the pastthat are image rotation invariant however imagerotation is not necessarily the same a surface rotation we have therefore developed a classifier that usesinvariants that are derived from surface property ratherthan image property previously we developed ascheme that used surface gradient normal fieldsestimated using photometric stereo in this paper weaugment these data with albedo information and an alsoemploy an additional feature set the radial spectrum we used real texture to test the new classifier aclassification accuracy of wa achieved whenalbedo and gradient d polar and radial feature werecombined the best performance wa also achieved byusing d albedo and gradient spectrum the classificationaccuracy is 
the algorithm presented in this paper aim to segment theforeground object in video e g people given time varying textured background example of time varying background includewaves on water cloud moving tree waving in the wind automobiletraffic moving crowd escalator etc we have developed a novelforeground background segmentation algorithm that explicitlyaccounts for the non stationary nature and clutter like appearanceof many dynamic texture the dynamic texture is modeled byanautoregressive moving average model arma a robust kalman filteralgorithm iteratively estimate the intrinsic appearance of thedynamic texture a well a the region of the foreground object preliminary experiment with this method have demonstratedpromising result 
getting trapped in suboptimal local minimum is a perennial problem in model based vision especially in application like monocular human body tracking where complex nonlinear parametric model are repeatedly fitted to ambiguous image data we show that the trapping problem can be attacked by building roadmaps of nearby minimum linked by transition pathway path leading over low col or pass in the cost surface found by locating the transition state codimension saddle point at the top of the pas and then sliding downhill to the next minimum we know of no previous vision or optimization work on numerical method for locating transition state but such method do exist in computational chemistry where transition are critical for predicting reaction parameter we present two family of method originally derived in chemistry but here generalized clarified and adapted to the need of model based vision eigenvector tracking is a modified form of damped newton minimization while hypersurface sweeping sweep a moving hypersurface through the space tracking minimum within it experiment on the challenging problem of estimating d human pose from monocular image show that our algorithm find nearby transition state and minimum very efficiently but also underline the disturbingly large number of minimum that exist in this and similar model based vision problem 
we describe an approach to object and scene retrievalwhich search for and localizes all the occurrence of auser outlined object in a video the object is represented bya set of viewpoint invariant region descriptor so that recognitioncan proceed successfully despite change in viewpoint illumination and partial occlusion the temporalcontinuity of the video within a shot is used to track theregions in order to reject unstable region and reduce theeffects of noise in the descriptor the analogy with text retrieval is in the implementationwhere match on descriptor are pre computed using vectorquantization and inverted file system and documentrankings are used the result is that retrieval is immediate returning a ranked list of key frame shot in the manner ofgoogle the method is illustrated for matching on two full lengthfeature film 
conventional tracking approach assume proximity inspace time and appearance of object in successive observation however observation of object are often widelyseparated in time and space when viewed from multiplenon overlapping camera to address this problem wepresent a novel approach for establishing object correspondenceacross non overlapping camera our multi cameratracking algorithm exploit the redundance in path thatpeople and car tend to follow e g road walk way orcorridors by using motion trend and appearance of object to establish correspondence our system doe notrequire any inter camera calibration instead the systemlearns the camera topology and path probability of objectsusing parzen window during a training phase oncethe training is complete correspondence are assigned usingthe maximum a posteriori map estimation framework the learned parameter are updated with changing trajectorypatterns experiment with real world video are reported which validate the proposed approach 
a system capable of performing robust live ego motion estimationfor perspective camera is presented the system is powered byrandom sample consensus with preemptive scoring of the motionhypotheses a general statement of the problem of efficientpreemptive scoring is given then a theoretical investigation ofpreemptive scoring under a simple inlier outlier model isperformed a practical preemption scheme is proposed and it isshown that the preemption is powerful enough to enable robust livestructure and motion estimation 
evaluating sum of multivariate gaussians is a common computational task in computer vision and pattern recognition including in the general and powerful kernel density estimation technique the quadratic computational complexity of the summation is a significant barrier to the scalability of this algorithm to practical application the fast gauss transform fgt ha successfully accelerated the kernel density estimation to linear running time for low dimensional problem unfortunately the cost of a direct extension of the fgt to higher dimensional problem grows exponentially with dimension making it impractical for dimension above we develop an improved fast gauss transform to efficiently estimate sum of gaussians in higher dimension where a new multivariate expansion scheme and an adaptive space subdivision technique dramatically improve the performance the improved fgt ha been applied to the mean shift algorithm achieving linear computational complexity experimental result demonstrate the efficiency and effectiveness of our algorithm 
quadrature filter are a well known method of low level computer vision for estimating certain property of the signal a there are local amplitude and local phase however d quadrature filter suffer from being not rotation invariant furthermore they do not allow to detect truly d feature a corner and junction unless they are combined to form the structure tensor the present paper deal with a new d generalization of quadrature filter which is rotation invariant and allows to analyze intrinsically d signal hence the new approach can be considered a the union of property of quadrature filter and of the structure tensor the proposed method first estimate the local orientation of the signal which is then used for steering some basis filter response certain linear combination of these filter response are derived which allow to estimate the local isotropy and two perpendicular phase of the signal the phase model is based on the assumption of an angular band limitation in the signal a an application a simple and efficient point of interest operator is presented and it is compared to the plessey detector 
natural scene contain rich stochastic motion pattern which are characterized by the movement of a large number of small element such a falling snow raining flying bird firework and waterfall in this paper we call these motion pattern textured motion and present a generative method that combine statistical model and algorithm from both texture and motion analysis the generative method includes the following three aspect photometrically an image is represented a a superposition of linear base in atomic decomposition using an overcomplete dictionary such a gabor or laplacian such base representation is known to be generic for natural image and it is low dimensional a the number of base is often time smaller than the number of pixel geometrically each moving element called moveton such a the individual snowflake and bird is represented by a deformable template which is a group of several spatially adjacent base such template are learned through clustering dynamically the movetons are tracked through the image sequence by a stochastic algorithm maximizing a posterior probability a classic second order markov chain model is adopted for the motion dynamic the source and sink of the movetons are modeled by birth and death map we adopt an em like stochastic gradient algorithm for inference of the hidden variable base movetons birth death map parameter of the dynamic the learned model are also verified through synthesizing random textured motion sequence which bear similar visual appearance with the observed sequence 
natural scene contain rich stochastic motion pattern which are characterized by the movement of a large number of small element such a falling snow raining flying bird firework and waterfall in this paper we call these motion pattern textured motion and present a generative method that combine statistical model and algorithm from both texture and motion analysis the generative method includes the following three aspect photometrically an image is represented a a superposition of linear base in atomic decomposition using an over complete dictionary such a gabor or laplacian such base representation is known to be generic for natural image and it is low dimensional a the number of base is often time smaller than the number of pixel geometrically each moving element called moveton such a the individual snowflake and bird is represented by a deformable template which is a group of several spatially adjacent base such template are learned through clustering dynamically the movetons are tracked through the image sequence by a stochastic algorithm maximizing a posterior probability a classic second order markov chain model is adopted for the motion dynamic the source and sink of the movetons are modeled by birth and death map we adopt an em like stochastic gradient algorithm for inference of the hidden variable base movetons birth death map parameter of the dynamic the learned model are also verified through synthesizing random textured motion sequence which bear similar visual appearance with the observed sequence 
motion layer estimation ha recently emerged a apromising object tracking method in this paper we extendprevious research on layer based tracker by introducingthe concept of background occluding layer and explicitlyinferring depth ordering of foreground layer thebackground occluding layer lie in front of behind and inbetween foreground layer each pixel in the backgroundregions belongs to one of these layer and occludes all theforeground layer behind it together with the foregroundordering the complete information necessary for reliablytracking object through occlusion is included in ourrepresentation an map estimation framework isdeveloped to simultaneously update the motion layerparameters the ordering parameter and the backgroundoccluding layer experimental result show that undervarious condition with occlusion including situationswith moving object undergoing complex motion orhaving complex interaction our tracking algorithm isable to handle many difficult tracking task reliably 
this paper describes technique for fusing the output of multiple cue to robustly and accurately segment foreground object from the background in image sequence two different method for cue integration are presented and tested the first is a probabilistic approach which at each pixel computes the likelihood of observation over all cue before assigning pixel to foreground or background layer using bayes rule the second method allows each cue to make a decision independent of the other cue before fusing their output with a weighted sum a further important contribution of our work concern demonstrating how model for some cue can be learnt and subsequently adapted online in particular region of coherent motion are used to train distribution for colour and for a simple texture descriptor an additional aspect of our framework is in providing mechanism for suppressing cue when they are believed to be unreliable for instance during training or when they disagree with the general consensus result on extended video sequence are presented 
we present an image based approach to infer d structureparameters using a probabilistic shape structure model the d shape of an object class is represented by setsof contour from silhouette view simultaneously observedfrom multiple calibrated camera while structural featuresof interest on the object are denoted by a number of d location a prior density over the multi view shape and correspondingstructure is constructed with a mixture of probabilisticprincipal component analyzer given a novelset of contour we infer the unknown structure parametersfrom the new shape s bayesian reconstruction modelmatching and parameter inference are done entirely in theimage domain and require no explicit d construction ourshape model enables accurate estimation of structure despitesegmentation error or missing view in the input silhouette and it work even with only a single input view using a training set of thousand of pedestrian image generatedfrom a synthetic model we can accurately infer the d location of joint on the body based on observedsilhouette contour from real image 
a new feature detection technique is presented that utilises local radial symmetry to identify region of interest within a scene this transform is significantly faster than existing technique using radial symmetry and offer the possibility of real time implementation on a standard processor the new transformis shown to perform well on a wide variety of image and it performance is tested against leading technique from the literature both a a facial feature detector and a a generic region of interest detector the new transformis seen to offer equal or superior performance to contemporary technique whilst requiring drastically le computational effort 
we describe a novel method for human detection in single image which can detect full body a well a close up view in the presence of clutter and occlusion human are modeled a flexible assembly of part and robust part detection is the key to the approach the part are represented by co occurrence of local feature which capture the spatial layout of the part s appearance feature selection and the part detector are learnt from training image using adaboost the detection algorithm is very efficient a i all part detector use the same initial feature ii a coarse to fine cascade approach is used for part detection iii a part assembly strategy reduces the number of spurious detection and the search space the result outperform existing human detector 
building on recent progress in modeling lter responsestatistics of natural image we integrate a statistical modelinto a variational framework for image segmentation incorporatedin a sound probabilistic distance measure themodel drive level set toward meaningful segmentationsof complex texture and natural scene since each regioncomprises two model parameter only the approachis computationally ef cient and enables the application ofvariational segmentation to a considerably larger class ofreal world image we validate the statistical basis of ourapproach on thousand of natural image and demonstratethat our model outperforms recent variational segmentationmethods based on second order statistic 
we present a common variational framework for dense depth recoveryand dense three dimensional motion field estimation from multiplevideo sequence which is robustto camera spectral sensitivitydifferences and illumination change for this purpose we firstshow that both problem reduce to a generic image matching problemafter backprojecting the input image onto suitable surface wethen solve this matching problem in the case of statisticalsimilarity criterion that can handle frequently occurring non affineimage intensity dependency our method lead to an efficientand elegant implementation based on fast recursive filter weobtain good result on real image 
we propose a general framework for parsing image into region and object in this framework the detection and recognition of object proceed simultaneously with image segmentation in a competitive and cooperative manner we illustrate our approach on natural image of complex city scene where the object of primary interest are face and text this method make use of bottom up proposal combined with top down generative model using the data driven markov chain monte carlo ddmcmc algorithm which is guaranteed to converge to the optimal estimate asymptotically more precisely we define generative model for face text and generic regionse g shading texture and clutter these model are activated by bottom up proposal the proposal for face and text are learnt using a probabilistic version of adaboost the ddmcmc combine reversible jump and diffusion dynamic to enable the generative model to explain the input image in a competitive and cooperative manner our experiment illustrate the advantage and importance of combining bottom up and top down model and of performing segmentation and object detection recognition simultaneously 
we propose an ecient alignment method for textured doosabin subdivision surface template a variation of the inverse compositional image alignment is derived by introducing smooth adjustment in the parametric space of the surface and relating them to the control point increment the convergence property of the proposed method are improved by a coarse to fine multiscale matching the method is applied to real time tracking of specially marked surface from a single camera view 
recent stereo algorithm have achieved impressive resultsby modelling the disparity image a a markov randomfield mrf an important component of an mrf basedapproach is the inference algorithm used to find the mostlikely setting of each node in the mrf algorithm havebeen proposed which use graph cut or belief propagationfor inference these stereo algorithm differ in both theinference algorithm used and the formulation of the mrf it is unknown whether to attribute the responsibility for differencesin performance to the mrf or the inference algorithm we address this through controlled experiment bycomparing the belief propagation algorithm and the graphcuts algorithm on the same mrf s which have been createdfor calculating stereo disparity we find that the labellingsproduced by the two algorithm are comparable the solution produced by graph cut have a lower energythan those produced with belief propagation but this doesnot necessarily lead to increased performance relative tothe ground truth 
abstract we consider here the problem of image classification when morethan one visual feature are available in these case bayes fusionoffers an attractive solution by combining the result of differentclassifiers one classifier per feature this is a general form of theso called quot naive bayes quot approach analyzing the performance ofbayes fusion with respect to a bayesian classifier over the jointfeature distribution however is tricky on the one hand it is wellknownthat the latter ha 
this paper describes a real time system for multi target tracking and classification in image sequence from a single stationary camera several target can be tracked simultaneously in spite of split and merges amongst the foreground object and presence of clutter in the segmentation result in result we show tracking of upto target simultaneously the algorithm combine kalman filter based motion and shape tracking with an efficient pattern matching algorithm the latter facilitates the use of a dynamic programming strategy to efficiently solve the data association problem in presence of multiple split and merges the system is fully automatic and requires no manual input of any kind for initialization of tracking the initialization for tracking is done using attributed graph the algorithm give stable and noise free track initialization the image based tracking result are used a input to a bayesian network based classifier to classify the target into different category after classification a simple d model for each class is used along with camera calibration to obtain d tracking result for the target we present result on a large number of real world image sequence and accurate d tracking result compared with the reading from the speedometer of the vehicle the complete tracking system including segmentation of moving target work at about hz for resolution color image on a ghz pentium desktop 
we propose a method for constructing a video sequence of high space time resolution by combining information from multiple low resolution video sequence of the same dynamic scene super resolution is performed simultaneously in time and in space by temporal super resolution we mean recovering rapid dynamic event that occur faster than regular frame rate such dynamic event are not visible or else observed incorrectly in any of the input sequence even if these are played in slow motion the spatial and temporal dimension are very different in nature yet are inter related this lead to interesting visual tradeoff in time and space and to new video application these include i treatment of spatial artifact e g motion blur by increasing the temporal resolution and ii combination of input sequence of different space time resolution e g ntsc pal and even high quality still image to generate a high quality video sequence 
we present a method for shape reconstruction from severalimages of a moving object the reconstruction is dense up to image resolution the method assumes that themotion is known e g by tracking a small number of featurepoints on the object the object is assumed lambertian completely matte light source should not be veryclose to the object but otherwise arbitrary and no knowledgeof lighting condition is required an object changesits appearance significantly when it change it orientationrelative to light source causing violation of the commonbrightness constancy assumption while a lot of effort isdevoted to deal with this violation we demonstrate howto exploit it to recover d structure from d image wepropose a new correspondence measure that enables pointmatching across view of a moving object the method hasbeen tested both on computer simulated example and on areal object 
a new approach to automatically extract the main feature in colorfundus image are proposed in this paper optic disk is localizedby the principal component analysis pca and it shape is detectedby a modified active shape model asm exudate are extracted bythe combined region growing and edge detection a fundus coordinatesystem is further set up based on the fovea localization to providea better description of the feature in fundus image the successrates achieved are and for disk localization diskboundary detection and fovea localization respectively thesensitivity and specificity for exudate detection are and the success of the proposed algorithm can be attributed to theutilization of the model based method 
in this work we present two new method for approximating thekullback liebler kl divergence between two mixture of gaussians the first method is based on matching between the gaussian elementsof the two gaussian mixture density the second method is basedon the unscented transform the proposed method are utilized forimage retrieval task continuous probabilistic image modelingbased on mixture of gaussians together with kl measure for imagesimilarity can be used for image retrieval task with remarkableperformance the efficiency and the performance of the klapproximation method proposed are demonstrated on both simulateddata and real image datasets the experimental result indicatethat our proposed approximation outperform previously suggestedmethods 
we propose a face difference model that decomposesface difference into three component intrinsicdifference transformation difference and noise usingthe face difference model and a detailed subspace analysison the three component we develop a unified frameworkfor subspace analysis using this framework we discoverthe inherent relationship among different subspacemethods and their unique contribution to the extractionof discriminating information from the face difference this eventually lead to the construction of a dparameter space that us three subspace dimension asaxis within this parameter space we develop a unifiedsubspace analysis method that achieves better recognitionperformance than the standard subspace method on over face image from the feret database 
we present technique for improving the speed of robust motion estimation based on random sampling of image feature starting from torr and zisserman s mlesac algorithm we address some of the problem posed from both practical and theoretical standpoint and in doing so allow the random search to be replaced by a guided search guidance of the search is based on readily available information which is usually discarded but can significantly reduce the search time this guided sampling algorithm is further specialised for tracking of multiple motion for which result are presented 
the beltrami flow is one of the most effective denoising algorithm in image processing for gray level image we show that the beltrami flow equation can be arranged in a reaction diffusion form this reveals the edge enhancing property of the equation and suggests the application of additive operator split aos method for faster convergence a we show with numerical simulation the aos method result in an unconditionally stable semi implicit linearized difference scheme in d and d the value of the edge indicator function are used from the previous step in scale while the pixel value of the next step are used to approximate the flow the optimum ratio between the reaction and diffusion counterpart of the governing pde is studied in order to achieve a better quality of segmentation the computational time decrease by a factor of ten a compared to the explicit scheme for d color image the beltrami flow equation are coupled and do not yield readily to the aos technique however in the proximity of an edge the cross product of color gradient nearly vanish and the coupling becomes weak the principal direction of the edge indicator matrix are normal and tangent to the edge replacing the action of the matrix on the gradient vector by an action of it eigenvalue we reduce the color problemto the gray level case with a reasonable accuracy the scalar edge indicator function for the color case becomes essentially the same a that for the gray level image and the fast implicit technique is implemented 
principal component analysis ha proven to be useful for understanding geometric variability in population of parameterized object the statistical framework is well understood when the parameter of the object are element of a euclidean vector space this is certainly the case when the object are described via landmark or a a dense collection of boundary point we have been developing representation of geometry based on the medial axis description or m rep although this description ha proven to be effective the medial parameter are not naturally element of a euclidean space in this paper we show that medial description are in fact element of a lie group we develop methodology based on lie group for the statistical analysis of medially defined anatomical object 
this paper address the problem of calibrating camera lensdistortion which can be significant in medium to wide anglelenses while almost all existing nonmetric distortion calibrationmethods need user involvement in one form or another we present anautomatic approach based on the robust the least median of square lmeds estimator our approach is thus le sensitive to erroneousinput data such a image curve that are mistakenly considered asprojections of d linear segment our approach uniquely us fast closed form solution to the distortion coefficient which serveas an initial point for a non linear optimization algorithm tostraighten imaged line moreover we propose a method fordistortion model selection based on geometrical inference successful experiment to evaluate the performance of this approachon synthetic and real data are reported 
this paper present a novel approach to sign language recognition that provides extremely high classication rate on minimal training data key to this approach is a stage classication procedure where an initial classication stage extract a high level description of hand shape and motion this high level description is based upon sign linguistics and describes action at a conceptual level easily understood by human moreover such a description broadly generalises temporal activity naturally overcoming variability of people and environment a second stage of classication is then used to model the temporal transition of individual sign using a classier bank of markov chain combined with independent component analysis we demonstrate classication rate a high a for a lexicon of word using only single instance training outperforming previous approach where thousand of training example are required 
a general classification framework called boostingchain is proposed for learning boosting cascade in thisframework a chain structure is introduced to integratehistorical knowledge into successive boosting learning moreover a linear optimization scheme is proposed toaddress the problem of redundancy in boosting learningand threshold adjusting in cascade coupling by thismeans the resulting classifier consists of fewer weakclassifiers yet achieves lower error rate than boostingcascade in both training and test experimentalcomparisons of boosting chain and boosting cascade areprovided through a face detection problem thepromising result clearly demonstrate the effectivenessmade by boosting chain 
we propose a two class classification model for grouping human segmented natural image are used a positive example negative example of grouping are constructed by randomly matching human segmentation and image in a preprocessing stage an image is over segmented into super pixel we define a variety of feature derived from the classical gestalt cue including contour texture brightness and good continuation information theoretic analysis is applied to evaluate the power of these grouping cue we train a linear classifier to combine these feature to demonstrate the power of the classification model a simple algorithm is used to randomly search for good segmentation result are shown on a wide range of image 
dimensionality reduction technique seek to representa set of image a a set of point in a low dimensionalspace here we explore a video representation thatconsiders a video a two part a space of possibleimages and a trajectory through that space the non lineardimensionality reduction technique of isomap give for many interesting scene a very low dimensionalrepresentation of the space of possible image analysis of the shape of the video trajectory throughthese image space give new tool for video analysis experiment with natural video sequence illustratemethods for the very different tasts of classifyingvideo clip and temporal super resolution 
we present a method for unsupervised learning of classesof motion in video we project optical flow field to a complete orthogonal a priori set of basis function in a probabilisticfashion which improves the estimation of the projectionsby incorporating uncertainty in the flow we thencluster the projection using a mixture of feature weightedgaussians over optical flow field the resulting modelextracts a concise probabilistic description of the majorclasses of optical flow present the method is demonstratedon a video of a person s facial expression 
robust estimator such a least median of squared lmeds residual m estimator the least trimmed square lts etc havebeen employed to estimate optical flow from image sequence inrecent year however these robust estimator have a breakdownpoint of no more than in this paper we propose a novel robustestimator called variable bandwidth quick maximum density powerestimator vbqmdpe which can tolerate more than outlier weapply the novel proposed estimator to robust optical flowestimation our method yield better result than most otherrecently proposed method and it ha the potential to betterhandle multiple motion effect 
this paper describes an approach to recovering surface model ofcomplex scene from the quasi sparse data returned by a featurebased stereo system the method can be used to merge stereo resultsobtained from different viewpoint into a single coherent surfacemesh the technique proceeds by exploiting the free space theoremwhich provides a principled mechanism for reasoning about thestructure of the scene based on quasi sparse correspondence inmultiple image effective method for overcoming the difficultiesposed by missing feature and outlier are discussed resultsobtained by applying this approach to actual image are presented 
we present a systematic comparison of machine learning method applied to the problem of fully automatic recognition of facial expression including adaboost support ve ctor machine and linear discriminant analysis each video frame is first scanned in real time to detect upright fronta l face the face found are scaled into image patch of equal size and sent downstream for further processing gabor energy filter are applied at the scaled image patch followed by a recognition engine that code facial expression into dimension in real time neutral anger disgust fear joy sadness surprise we report result on a series of experiment comparing spatial frequency range feature selection technique and recognition engine be st result were obtained by selecting a subset of gabor filter using adaboost and then training support vector machine on the output of the filter selected by adaboost the generalization performance to new subject for a way forced choice wa and correct on two publicly available datasets the best performance reported so far on these datasets surprisingly registration of internal facial f eatures wa not necessary even though the face detector doe not provide precisely registered image the output of the classifier change smoothly a a function of time and thus can be used for unobtrusive motion capture we developed an end to end system that provides facial expression code at frame per second and animates a computer generated character in real time 
bundle ajustment is used to obtain accurate visual reconstructionsby minimizing the reprojection error the coordinateframe ambiguity or more generality the gauge freedom ha been dealt with in different manner it ha oftenbeen reported that standard bundle adjustment algorithmswere not gauge invariant two iteration within differentgauges can lead to geometrically very different result surprisingly most algorithm do not exploit gauge freedom toimprove performance we consider this issue we analyzetheoretically the impact of the gauge on standard algorithm we show that a sufficiently general damping matrixin levenberg marquardt iteration can be used to implicitlyreproduce a gauge transformation we show that if thedamping matrix is chosen such that the decrease in the reprojectionerror is maximized then the iteration is gauge invariant experimental result on simulated and real data showthat our gauge invariant bundle adjustment algorithm outperformsexisting one in term of stability 
this paper discus building complex classifier from a singlelabeled example and vast number of unlabeled observation set eachderived from observation of a single processor object when datacan be measured by observation it is often plentiful and it isoften possible to make more than one observation of the state of aprocess or object this paper discus how to exploit thevariability across such set of observation of the same object toestimate class label for unlabeled example given a minimal numberof labeled example in contrast to similar semi supervisedclassification procedure that define the likelihood that twoobservations share a label a a function of the embedded distancebetween the two observation this method us the naive bayesestimate of how often the two observation did result from the sameobserved process exploiting this additional source of informationin an iterative estimation procedure can generalize complexclassification model from single labeled observation someexamples involving classification of tracked object in alow dimensional feature space given thousand of unlabeledobservation set are used to illustrate the effectiveness of thismethod 
there ha been considerable success in automated reconstruction for image sequence where small baseline algorithm can be used to establish match across a number of image in contrast in the case of widely separated view method have generally been restricted to two or three view in this paper we investigate the problem of establishing relative viewpoint given a large number of image where no ordering information is provided a typical application would be where image are obtained from different source or at different time both the viewpoint position orientation scale and lighting condition may vary significantly over the data set such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive a the number of view increase instead we investiate how a combination of image invariant covariants and multiple view relation can be used in concord to enable efficient multiple view matching the result is a matching algorithm which is linear in the number of view the method are illustrated on several real image data set the output enables an image based technique for navigating in a d scene moving from one image to whichever image is the next most appropriate 
we present novel simple appearance and shape model that we callepitomes the epitome of an image is it miniature condensedversion containing the essence of the textural and shape propertiesof the image a opposed to previously used simple image model such a template or basis function the size of the epitome isconsiderably smaller than the size of the image or object itrepresents but the epitome still contains most constitute elementsneeded to reconstruct the image fig a collection of imagesoften share an epitome e g when image are a few consecutiveframes from a video sequence or when they are photograph ofsimilar object a particular image in a collection is defined byits epitome and a smooth mapping from the epitome to the imagepixels when the epitomic representation is used within ahierarchical generative model appropriate inference algorithm canbe derived to extract the epitome from a single image or acollection of image and at the same time perform various inferencetasks such a image segmentation motion estimation objectremoval and super resolution 
estimating the parameter of a pencil of line is addressed a statistical model for the measurement is developed from which the cramer rao lower bound is determined an estimator is derived and it performance is simulated and compared to the bound the estimator is shown to be asymptotically efficient and superior to the classical least square algorithm 
a new calibration algorithm for multi camera systemsusing a planar reference pattern is proposed the algorithmis an extension of sturm maybank zhang style plane basedcalibration technique for use with multiple camera rigiddisplacements between the camera are recovered a well asthe intrinsic parameter only by capturing with the camerasa model plane with known reference point placed at threeor more location thus the algorithm yield a simple calibrationmeans for stereo vision system with an arbitrarynumber of camera while maintaining the handiness andflexibility of the original method the algorithm is based onfactorization of homography matrix between the modeland image plane into the camera and plane parameter to compensate for the indetermination of scaling factor each homography matrix is rescaled by a double eigenvalueof a planar homology defined by two view and two modelplanes the obtained parameter are finally refined by anon linear maximum likelihood estimation mle process the validity of the proposed technique wa verified throughsimulation and experiment with real data 
in this paper we aim to recover the d shape of a human face using a single image we use a combination of symmetric shape from shading by zhao and chellappa and statistical approach for facial shape reconstruction by atick griffin and redlich given a single frontal image of a human face under a known directional illumination from a side we represent the solution a a linear combination of basis shape and recover the coefficient using a symmetry constraint on a facial shape and albedo by solving a single least square system of equation our algorithm provides a closed form solution which satisfies both symmetry and statistical constraint in the best possible way our procedure take only a few second account for varying facial albedo and is simpler than the previous method in the special case of horizontal illuminant direction our algorithm run even a fast a matrix vector multiplication 
the problem of selecting a subset of relevant feature in apotentially overwhelming quantity of data is classic and found inmany branch of science including example in computer vision text processing and more recently bio informatics are abundant inthis work we present a definition of relevancy based on spectralproperties of the affinity or laplacian of the feature measurement matrix the feature selection process is then based ona continuous ranking of the feature defined by a least squaresoptimization process a remarkable property of the featurerelevance function is that sparse solution for the ranking valuesnaturally emerge a a result of a biased non negativity of a keymatrix in the process a a result a simple least squaresoptimization process converges onto a sparse solution i e aselection of a subset of feature which form a local maximum overthe relevance function the feature selection algorithm can beembedded in both unsupervised and supervised inference problem andempirical evidence show that the feature selection typicallyachieve high accuracy even when only a small fraction of thefeatures are relevant 
we propose a spectral partitioning approach for large scaleoptimization problem specifically structure from motion in structure from motion partitioning method reduce theproblem into smaller and better conditioned subproblemswhich can be efficiently optimized our partitioning methoduses only the hessian of the reprojection error and it eigenvector we show that partitioned system that preserve theeigenvectors corresponding to small eigenvalue result inlower residual error when optimized we create partitionsby clustering the entry of the eigenvectors of the hessiancorresponding to small eigenvalue this is a more generaltechnique than relying on domain knowledge and heuristicssuch a bottom up structure from motion approach simultaneously it take advantage of more information thangeneric matrix partitioning algorithm 
we propose a unified approach for summarization based on the analysis of video structure and video highlight our approach emphasizes both the content balance and perceptual quality of a summary normalized cut algorithm is employed to globally and optimally partition a video into cluster a motion attention model based on human perception is employed to compute the perceptual quality of shot and cluster the cluster together with the computed attention value form a temporal graph similar to markov chain that inherently describes the evolution and perceptual importance of video cluster in our application the flow of a temporal graph is utilized to group similar cluster into scene while the attention value are used a guideline to select appropriate subshots in scene for summarization 
the performance of many image analysis task depend on the image resolution at which they are applied traditionally resolution selection method rely on spatial derivative of image intensity differential measurement however are sensitive to noise and are local they cannot characterize pattern such a texture which are defined over extensive image region in this work we present a novel tool for resolution selection that considers sufficiently large image region and is robust to noise it is based on the generalized entropy of the histogram of an image at multiple resolution we first examine in general the variation of histogram entropy with image resolution then we examine the sensitivity of this variation for shape and texture in an image finally we discus the significance of resolution of maximum histogram entropy it is shown that computing feature at these resolution increase the discriminability between image it is also shown that maximum histogram entropy value can be used to improve optical flow estimate for block based algorithm in image sequence with a changing zoom factor 
in this paper we present a generative model for textured motionphenomena such a falling snow wavy river and dancing grass etc firstly we represent an image a a linear superposition of imagebases selected from a generic and over complete dictionary thedictionary contains gabor base for point particle element andfourier base for wave element these base compete to explain theinput image the transform from a raw image to a base or a tokenrepresentation lead to large dimension reduction secondly weintroduce a unified motion equation to characterize the motion ofthese base and the interaction between wave and particle e g a ball floating on water we use statistical learning algorithm toidentify the structure of moving object and their trajectoriesautomatically then novel sequence can be synthesized easily fromthe motion and image model thirdly we replace the dictionary ofgabor and fourier base with symbolic sketch also base withthe same image and motion model we can render realistic andstylish cartoon animation in our view cartoon and sketch aresymbolic visualization of the inner representation for visualperception the success of the cartoon animation in turn suggeststhat our image and motion model capture the essence of visualperception of textured motion 
this paper present a novel method for detecting vehicle asobstacles in various road scene using a single on board camera vehicle are detected by testing whether the motion of a set ofthree horizontal line segment which are always on the vehicle satisfies the motion constraint of the ground plane or that of thesurface plane of the vehicle the motion constraint of each planeis derived from the projective invariant combined with thevanishing line of the plane that is a prior knowledge of roadscenes the proposed method is implemented into a newly developedon board lsi experimental result for real road scene undervarious condition show the effectiveness of the proposed method 
the problem of tracking a varying number of non rigid object ha two major diculties first the observation model and target distribution can be highly non linear and non gaussian second the presence of a large varying number of object creates complex interaction with overlap and ambiguity to surmount these diculties we introduce a vision system that is capable of learning detecting and tracking the object of interest the system is demonstrated in the context of tracking hockey player using video sequence our approach combine the strength of two successful algorithm mixture particle lters and adaboost the mixture particle lter is ideally suited to multi target tracking a it assigns a mixture component to each player the crucial design issue in mixture particle lters are the choice of the proposal distribution and the treatment of object leaving and entering the scene here we construct the proposal distribution using a mixture model that incorporates information from the dynamic model of each player and the detection hypothesis generated by adaboost the learned adaboost proposal distribution allows u to quickly detect player entering the scene while the ltering process enables u to keep track of the individual player the result of interleaving adaboost with mixture particle lters is a simple yet powerful and fully automatic multiple object tracking system 
abstract specular reflection present di culties for many area of computer vision such a stereo and segmentation to separate specu lar and difiuse reflection component previous approach generally re quire accurate segmentation regionally uniform reflectance or structured lighting to overcome these limiting assumption we propose a method based on color analysis and multibaseline stereo that simultaneously e timates the separation and the true depth of specular reflection first pixel with a specular component are detected by a novel form of color histogram difierencing that utilizes the epipolar constraint this process us relevant data from all the stereo image for robustness and ad dress the problem of color occlusion based on the lambertian model of difiuse reflectance stereo correspondence is then employed to compute for specular pixel their corresponding difiuse component in other view the result of color based detection aid the stereo correspondence which determines both separation and true depth of specular pixel our ap proach integrates color analysis and multibaseline stereo in a synergistic manner to yield accurate separation and depth a demonstrated by our result on synthetic and real image sequence 
estimation of camera motion and structure of rigid object in the d world from multiple camera image by bundle adjustment is often performed by iterative minimization method due to their low computational effort these method need a robust initialization in order to converge to the global minimum in this paper a new criterion for keyframe selection is presented while state of the art criterion just avoid degenerated camera motion configuration the proposed criterion selects the keyframe pairing with the lowest expected estimation error of initial camera motion and object structure the presented result show that the convergence probability of bundle adjustment is significantly improved with the new criterion compared to the state of the art approach 
abstract to human computer interaction and force u to think innew way about how computer could be used in daily life face to face communication is a real time process operatingat a a time scale in the order of millisecond thelevel of uncertainty at this time scale is considerable makingit necessary for human and machine to rely on sensoryrich perceptual primitive rather than slow symbolic inferenceprocesses in this paper we present progress on onesuch perceptual primitive the 
the problem of denoising image is one of the most important and widely studied problem in image processing and computer vision various image filtering strategy based on linear system statistic information theory and variational calculus have been effective but invariably make strong assumption about the property of the signal and or noise therefore they lack the generality to be easily applied to new application or diverse image collection this paper describes a novel unsupervised information theoretic adaptive filter uinta that improves the predictability of pixel intensity from their neighborhood by decreasing the joint entropy between them in this way uinta automatically discovers the statistical property of the signal and can thereby reduce noise in a wide spectrum of image and application the paper describes the formulation required to minimize the joint entropy measure present several important practical consideration in estimating image region statistic and then present a series of result and comparison on both real and synthetic data 
we consider object recognition a the process of attaching meaningful label to specic region of an image and propose a model that learns spatial relationship between object given a set of image and their associated text e g keywords caption description the objective is to segment an image in either a crude or sophisticated fashion then to nd the proper association between word and region previous model are limited by the scope of the representation in particular they fail to exploit spatial context in the image and word we develop a more expressive model that take this into account we formulate a spatially consistent probabilistic mapping between continuous image feature vector and the supplied word token by learning both word to region association and object relation the proposed model augments scene segmentation due to smoothing implicit in spatial consistency context introduces cycle to the undirected graph so we cannot rely on a straightforward implementation of the em algorithm for estimating the model parameter and density of the unknown alignment variable instead we develop an approximate em algorithm that us loopy belief propagation in the inference step and iterative scaling on the pseudo likelihood approximation in the parameter update step the experiment indicate that our approximate inference and learning algorithm converges to good local solution experiment on a diverse array of image show that spatial context considerably improves the accuracy of object recognition most signican tly spatial context combined with a nonlinear discrete object representation allows our model to cope well with over segmented scene 
in this work we describe a novel statistical video representationand modeling scheme unsupervised clusteringvia gaussian mixture modeling extract coherent spacetimeregions in feature space and corresponding coherentsegments video region in the video content a key featureof the system is the analysis of video input a a singleentity a opposed to a sequence of separate frame spaceand time are treated uniformly the extracted space timeregions allow for the detection and 
in this paper we present a method that integrates cue from shading shadow and specular reflection for estimating directional illumination in a textured scene texture pose a problem for lighting estimation since texture edge can be mistaken for change in illumination condition and unknown variation in albedo make reflectance model fitting impractical unlike previous work which all assume known or uniform reflectance our method can deal with the effect of texture by capitalizing on physical consistency that exist among the lighting cue since scene texture do not exhibit such coherence we use this property to minimize the influence of texture on illumination direction estimation for the recovered light source direction a technique for estimating their intensity in the presence of texture is also proposed 
several technique have been developed for recovering reflectanceproperties of real surface under unknown illumination condition however in most case those technique assume that the lightsources are located at inifinity which cannot be applied to forexample photometric modeling of indoor environment in thispaper we propose two method to estimate the surface reflectanceproperty of an object a well a the position of a light sourcefrom a single image without the distant illumination assumption given a color image of an object with specular reflection a aninput the first method estimate the light source position byfitting to the lambertian diffuse component while separating thespecular and diffuse component by using an iterative relaxationscheme moreover we extend the above method by using a singlespecular image a an input thus removing it constraint on thediffuse reflectance property and the number of light source thismethod simultaneously recovers the reflectance property and thelight source position by optimizing the linearity of alog transformed torrance sparrow model by estimating the object sreflectance property and the light source position we can freelygenerate synthetic image of the target object under arbitrarysource direction and source surface distance 
this paper present a new approach to imaging thatsignificantly enhances the dynamic range of a camera the key idea is to adapt the exposure of each pixel onthe image detector based on the radiance value of thecorresponding scene point this adaptation is done inthe optical domain that is during image formation inpractice this is achieved using a spatial light modulatorwhose transmittance can be varied with high resolutionover space and time a real time control algorithm isdeveloped that us acquired image to automaticallyadjust the transmittance function of the spatial modulator each captured image and it corresponding transmittance function are used to compute a very high dynamic range image that is linear in scene radiance we have implemented a video rate adaptive dynamicrange camera that consists of a color ccd detector anda controllable liquid crystal light modulator experiment have been conducted in scenario with complexand harsh lighting condition the result indicate thatadaptive imaging can have a significant impact on visionapplications such a monitoring tracking recognition and navigation 
video based handwritten character recognition vcr system is a new type of character recognitionsystem with many unique advantage over on linecharacter recognition system it main problem is toeffectively extract stroke dynamic information fromvideo data for character recognition in this paper wepropose a new stroke extraction algorithm throughdynamic stroke information analysis for a vcr system the experimental result on over video charactersequences show that our system can extract the chinesecharacter stroke dynamic information similar to an on line system 
in this paper we introduce a set of novel distance metric that use model based representation for trajectory we determine the similarity of trajectory using the conformity of the corresponding hmm model these metric enable the comparison of trajectory without any limitation of the conventional measure they accurately identify the coordinate orientation and speed affinity the proposed hmm based distance metric can be used not only for ground truth comparison but for clustering a well our experiment prove that they have superior discriminative property 
pan tilt camera are often used a component of wide areasurveillance system it is necessary to calibrate these camera inrelation to one another in order to obtain a consistentrepresentation of the entire space existing method forcalibrating pan tilt camera have assumed an idealized model ofcamera mechanic in addition most method have been calibratedusing only asmall range of camera motion this paper present amethod for calibrating pan tilt camera that introduces a morecomplete model of camera motion pan and tilt rotation are modeledas occurring around arbitrary ax in space in addition the widearea surveillance system itself is used to build a large virtualcalibration object resulting in better calibration than would bepossible with a single small calibration target finally theproposed enhancement are validated experimentally withcomparisons showing the improvement provided over more traditionalmethods 
this paper describes a pedestrian detection system that integratesimage intensity information with motion information we use a detection style algorithm that scan a detectorover two consecutive frame of a video sequence thedetector is trained using adaboost to take advantage ofboth motion and appearance information to detect a walkingperson past approach have built detector based onmotion information or detector based on appearance information but ours is the first to combine both source ofinformation in a single detector the implementation describedruns at about frame second detects pedestriansat very small scale a small a x pixel and ha avery low false positive rate our approach build on the detection work of viola andjones novel contribution of this paper include i developmentof a representation of image motion which is extremelyefficient and ii implementation of a state of theart pedestrian detection system which operates on low resolutionimages under difficult condition such a rain andsnow 
this paper describes a pedestrian detection system that integrates image intensity information with motion information we use a detection style algorithm that scan a detector over two consecutive frame of a video sequence the detector is trained using adaboost to take advantage of both motion and appearance information to detect a walking person past approach have built detector based on motion information or detector based on appearance information but ours is the first to combine both source of information in a single detector the implementation described run at about frame second detects pedestrian at very small scale a small a x pixel and ha a very low false positive rate our approach build on the detection work of viola and jones novel contribution of this paper include i development of a representation of image motion which is extremely efficient and ii implementation of a state of the art pedestrian detection system which operates on low resolution image under difficult condition such a rain and snow 
making sense of large amount of unlabeled data is hard but this is what we are up against in many real life situation our key observation is that in many real life application additional partial information about the data can be obtained with very little cost for example in video indexing we may want to use the fact that a sequence of face obtained from successive frame in roughly the same location are likely to contain the same unknown individual similarly when querying an image database using a standard retrieval engine user may be asked to partition the retrieved set into category this mode of supervision doe not provide label of data point but rather supply relational information about the label equivalence of data point learning using equivalence relation is different from learning using label and pose new technical challenge existing machine learning technique are not designed to exploit this information we therefore developed a number of novel method which learn from relational data we provide result of our method on a distributed image querying system that work on a large facial image database and on the clustering and retrieval of surveillance data our result show that we can significantly improve the performance of image retrieval by taking advantage of such assumption a temporal continuity in the data significant improvement is also obtained by asking the user of the system take the role of distributed teacher which reduces the need for expensive labeling by paid labor 
this paper is about learning using partial information in the form of equivalence constraint equivalence constraint provide relational information about the label of data point rather than the label themselves our work is motivated by the observation that in many real life application partial information about the data can be obtained with very little cost for example in video indexing we may want to use the fact that a sequence of face obtained from successive frame in roughly the same location is likely to contain the same unknown individual learning using equivalence constraint is different from learning using label and pose new technical challenge in this paper we present three novel method for clustering and classification which use equivalence constraint we provide result of our method on a distributed image querying system that work on a large facial image database and on the clustering and retrieval of surveillance data our result show that we can significantly improve the performance of image retrieval by taking advantage of such assumption a temporal continuity in the data significant improvement is also obtained by making the user of the system take the role of distributed teacher which reduces the need for expensive labeling by paid human labor 
this paper describes a system that can build appearance model ofanimals automatically from a video sequence of the relevant animalwith no explicit supervisory information the video sequence neednot have any form of special background animal are modeled a a d kinematic chain of rectangular segment where the number ofsegments and the topology of the chain are unknown the systemdetects possible segment cluster segment whose appearance iscoherent over time and then build a spatial model of such segmentclusters the resulting representation of the spatial configurationof the animal in each frame can be seen either a a track inwhich case the system described should be viewed a a generalizedtracker that is capable of modeling object while tracking them or a the source of an appearance model which can be used to builddetectors for the particular animal this is because knowing avideo sequence is temporally coherent i e that a particularanimal is present through the sequence is a strong supervisorysignal the method is shown to be successful a a tracker on videosequences of real scene showing three different animal for thesame reason it is successful a a tracker the method result indetectors that can be used to find each animal fairly reliablywithin the corel collection of image 
self calibration using pure rotation is a well known technique and ha been shown to be a reliable mean for recovering intrinsic camera parameter however in practice it is virtually impossible to ensure that the camera motion for this type of self calibration is a pure rotation in this paper we present an error analysis of recovered intrinsic camera parameter due to the presence of translation we derived closed form error expression for a single pair of image with nondegenerate motion for multiple rotation for which there are no closed form solution analysis wa done through repeated experiment among others we show that translation independent solution do exist under certain practical condition our analysis can be used to help choose the least error prone approach if multiple approach exist for a given set of condition 
abstract model of spatial variation in image are central to a large number of low level computer vision problem including segmentation registration and d structure detection often image are represented using parametric model to characterize noise free image variation and additive noise however the noise model may be unknown and para metric model may only be valid on individual segment of the image consequently we model noise using a nonparametric kernel density esti mation framework and use a locally or globally linear parametric model to represent the noise free image pattern this result in a novel ro bust redescending m parameter estimator for the above image model which we call the kernel maximum likelihood estimator kml we also provide a provably convergent iterative algorithm for the resultant optimization problem the estimation framework is empirically validated on synthetic data and applied to the task of range image segmentation 
the problem of pose estimation arises in many area of computer vision including object recognition object tracking site inspection and updating and autonomous navigation using scene model we present a new algorithm called softposit for determining the pose of a d object from a single d image in the case that correspondence between model point and image point are unknown the algorithm combine gold s iterative softassign algorithm for computing correspondence and dementhon s iterative posit algorithm for computing object pose under a full perspective camera model our algorithm unlike most previous algorithm for this problem doe not have to hypothesize small set of match and then verify the remaining image point instead all possible match are treated identically throughout the search for an optimal pose the performance of the algorithm is extensively evaluated in monte carlo simulation on synthetic data under a variety of level of clutter occlusion and image noise these test show that the algorithm performs well in a variety of difficult scenario and empirical evidence suggests that the algorithm ha a run time complexity that is better than previous method by a factor equal to the number of image point the algorithm is being applied to the practical problem of autonomous vehicle navigation in a city through registration of a d architectural model of building to image obtained from an on board camera 
we present a system that is capable of segmenting detecting and tracking multiple people in a cluttered scene using multiple synchronized camera located far from each other the system improves upon existing system in many way including we do not assume that a foreground connected component belongs to only one object rather we segment the view taking into account color model for the object and the background this help u to not only separate foreground region belonging to different object but to also obtain better background region than traditional background subtraction method a it us foreground color model in the algorithm it is fully automatic and doe not require any manual input or initialization of any kind instead of taking decision about object detection and tracking from a single view or camera pair we collect evidence from each pair and combine the evidence to obtain a decision in the end this help u to obtain much better detection and tracking a opposed to traditional system several innovation help u tackle the problem the first is the introduction of a region based stereo algorithm that is capable of finding d point inside an object if we know the region belonging to the object in two view no exact point matching is required this is especially useful in wide baseline camera system where exact point matching is very difficult due to self occlusion and a substantial change in viewpoint the second contribution is the development of a scheme for setting prior for use in segmentation of a view using bayesian classification the scheme which assumes knowledge of approximate shape and location of object dynamically assigns prior for different object at each pixel so that occlusion information is encoded in the prior the third contribution is a scheme for combining evidence gathered from different camera pair using occlusion analysis so a to obtain a globally optimum detection and tracking of object the system ha been tested using different density of people in the scene which help u to determine the number of camera required for a particular density of people 
we investigate the influence of the mirror shape on the imaging quality of catadioptric sensor for axially symmetrical mirror we calculate the location of the virtual image point considering incident quasi parallel light ray using second order approximation we give analytical expression for the two limiting surface of this virtual image zone this is different to numerical or ray tracing approach for the estimation of the blur region e g we show how these equation can be used to estimate the image blur caused by the shape of the mirror a example we present two different omnidirectional stereo sensor with single camera and equi angular mirror that are used on mobile robot to obtain a larger stereo baseline one of these sensor consists of two separated mirror of the same angular magnification and differs from a similar configuration proposed by ollis et al we calculate the caustic surface and show that this stereo configuration can be approximated by two single view point yielding an effective vertical stereo baseline of approx cm an example of panoramic disparity computation using a physiologically motivated stereo algorithm is given 
this paper examines projectively invariant local property ofsmooth curve and surface oriented projective differentialgeometry is proposed a a theoretical framework for establishingsuch invariant and describing the local shape of surface andtheir outline this framework is applied to two problem aprojective proof of koenderink s famous characterization ofconvexities concavity and inflection of apparent contour andthe determination of the relative orientation of rim tangent atfrontier point 
this paper address the problem of clustering image of object seen from different viewpoint that is given an unlabelled set of image of n object we seek an unsupervised algorithm that can group the image into n disjoint subset such that each subset only contains image of a single object we formulate this clustering problem under a very broad geometric framework the theme is the interplay between the geometry of appearance manifold and the symmetry of the d affine group specifically we identify three important notion for image clustering the l distance metric of the image space the local linear structure of the appearance manifold and the action of the d affine group in the image space based on these notion we propose a new image clustering algorithm in a broad outline the algorithm us the metric to determine a neighborhood structure in the image space for each input image using local linear structure comparison affinity between image are computed only among the neighbor these local comparison are agglomerated into an affinity matrix and a spectral clustering algorithm is used to yield the final clustering result the technical part of the algorithm is to make all of these compatible with the action of the d affine group using human face image and image from the coil database we demonstrate experimentally that our algorithm is effective in clustering image according to ojbect identity where there is a large range of pose variation 
deformable d d medical image registration is an essential technique in computer integrated surgery ci to fuse d pre operative data with d intra operative data several factor may affect the accuracy of d d registration including the number of d view the angle between view the view angle relative to anatomical object the co registration error between view the image noise and the image distortion in this paper we investigate and ass the relationship between these factor and the accuracy of d d registration we proposed a deformable d d registration method based on a statistical model we conducted experiment using a hemi pelvis model and simulated x ray image some discussion are provided on how to improve the accuracy of d d registration based on our assessment 
the aim of this paper is to find the best representation for the appearance of surface with lambertian reflectance under varying illumination previous work using principal component analysis pca found the best sub space to represent all image of an object under a varying point light source we extend this to image from any illumination distribution specifically we calculate the base for all configuration of a point plus ambient light source and two point light source a well a from a database of captured real world illumination we also reformulate the optimization criterion used in pca the resulting basis we believe ha higher representability and is better for analyzing image of shaded object the different base are compared on a database of image to test the representability 
example based method are effective for parameter estimation problem when the underlying system is simple or the dimensionality of the input is low for complex and high dimensional problem such a pose estimation the number of required example and the computational complexity rapidly become prohibitively high we introduce a new algorithm that learns a set of hashing function that efficiently index example relevant to a particular estimation task our algorithm extends locality sensitive hashing a recently developed method to find approximate neighbor in time sublinear in the number of example this method depends critically on the choice of hash function that are optimally relevant to a particular estimation problem experiment demonstrate that the resulting algorithm which we call parameter sensitive hashing can rapidly and accurately estimate the articulated pose of human figure from a large database of example image 
this paper extends the face detection framework proposed by viola and jones to handle profile view and rotated face a in the work of rowley et al and schneiderman et al we build different detector for different view of the face a decision tree is then trained to determine the viewpoint class such a right profile or rotated degree for a given window of the image being examined this is similar to the approach of rowley et al the appropriate detector for that viewpoint can then be run instead of running all detector on all window this technique yield good result and maintains the speed advantage of the viola jones detector 
dynamic analysis of video sequence often relies on the segmentation of the sequence into region of consistent motion approaching this problem requires a definition of which motion are regarded a consistent common approach to motion segmentation usually group together point or image region that have the same motion between successive frame where the same motion can be d d or non rigid in this paper we define a new type of motion consistency which is based on temporal consistency of behavior across multiple frame in the video sequence our definition of consistent temporal behavior is expressed in term of multi frame linear subspace constraint this definition applies to d d and some non rigid motion without requiring prior model selection we further present a multi frame multi body segmentation algorithm which applies the new motion consistency constraint directly to image brightness measurement without requiring prior correspondence estimation nor feature tracking 
