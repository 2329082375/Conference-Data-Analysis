we present a modification of normalized cut to incorporate prior which can be used for constrained image segmentation compared to previous generalization of normalized cut which incorporate constraint our technique ha two advantage first we seek solution which are sufficiently correlated with prior which allows u to use noisy top down information for example from an object detector second given the spectral solution of the unconstrained problem the solution of the constrained one can be computed in small additional time which allows u to run the algorithm in an interactive mode we compare our algorithm to other graph cut based algorithm and highlight the advantage 
we present a hybrid parametric and nonparametric algorithm exemplar cut for generating class specific object segmentation hypothesis for the parametric part we train a pylon model on a hierarchical region tree a the energy function for segmentation for the nonparametric part we match the input image with each exemplar by using region to obtain a score which augments the energy function from the pylon model our method thus generates a set of highly plausible segmentation hypothesis by solving a series of exemplar augmented graph cut experimental result on the graz and pascal datasets show that the proposed algorithm achieves favorable segmentation performance against the state of the art method in term of visual quality and accuracy 
the quality of any tracking by assignment hinge on the accuracy of the foregoing target detection segmentation step in many kind of image error in this first stage are unavoidable these error then propagate to and corrupt the tracking result our main contribution is the first probabilistic graphical model that can explicitly account for overand under segmentation error even when the number of tracking target is unknown and when they may divide a in cell culture the tracking model we present implement global consistency constraint for the number of target comprised by each detection and is solved to global optimality on reasonably large d t and d t datasets in addition we empirically demonstrate the effectiveness of a post processing that allows to establish target identity even across occlusion under segmentation the usefulness and efficiency of this new tracking method is demonstrated on three different and challenging d t and d t datasets from developmental biology 
recent study have shown that hashing method are effective for high dimensional nearest neighbor search a common problem shared by many existing hashing method is that in order to achieve a satisfied performance a large number of hash table i e long code word are required to address this challenge in this paper we propose a novel approach called compressed hashing by exploring the technique of sparse coding and compressed sensing in particular we introduce a parse coding scheme based on the approximation theory of integral operator that generate sparse representation for high dimensional vector we then project s parse code into a low dimensional space by effectively exploring the restricted isometry property rip a key property in compressed sensing theory both of the theoretical analysis and the empirical study on two large data set show that the proposed approach is more effective than the state of the art hashing algorithm 
computing optical flow between any pair of internet face photo is challenging for most current state of the art flow estimation method due to difference in illumination pose and geometry we show that flow estimation can be dramatically improved by leveraging a large photo collection of the same or similar object in particular consider the case of photo of a celebrity from google image search any two such photo may have different facial expression lighting and face orientation the key idea is that instead of computing flow directly between the input pair i j we compute version of the image i j in which facial expression and pose are normalized while lighting is preserved this is achieved by iteratively projecting each photo onto an appearance subspace formed from the full photo collection the desired flow is obtained through concatenation of flow i i o j j our approach can be used with any two frame optical flow algorithm and significantly boost the performance of the algorithm by providing invariance to lighting and shape change 
cosegmentation is typically defined a the task of jointly segmenting something similar in a given set of image existing method are too generic and so far have not demonstrated competitive result for any specific task in this paper we overcome this limitation by adding two new aspect to cosegmentation the something ha to be an object and the similarity measure is learned in this way we are able to achieve excellent result on the recently introduced icoseg dataset which contains small set of image of either the same object instance or similar object of the same class the challenge of this dataset lie in the extreme change in viewpoint lighting and object deformation within each set we are able to considerably outperform several competitor to achieve this performance we borrow recent idea from object recognition the use of powerful feature extracted from a pool of candidate object like segmentation we believe that our work will be beneficial to several application area such a image retrieval 
this work attempt to considerably reduce the amount of user effort in the natural image matting problem the key observation is that the nonlocal principle introduced to denoise image can be successfully applied to the alpha matte to obtain sparsity in matte representation and therefore dramatically reduce the number of pixel a user need to manually label we show how to avoid making the user provide redundant and unnecessary input develop a method for clustering the image pixel for the user to label and a method to perform high quality matte extraction we show that this algorithm is therefore faster easier and higher quality than state of the art method 
this paper proposes to apply the nonlocal principle to general alpha matting for the simultaneous extraction of multiple image layer each layer may have disjoint a well a coherent segment typical of foreground matte in natural image matting the estimated alpha also satisfy the summation constraint a in nonlocal matting our approach doe not assume the local color line model and doe not require sophisticated sampling or learning strategy on the other hand our matting method generalizes well to any color or feature space in any dimension any number of alpha and layer at a pixel beyond two and come with an arguably simpler implementation which we have made publicly available our matting technique aptly called knn matting capitalizes on the nonlocal principle by using k nearest neighbor knn in matching nonlocal neighborhood and contributes a simple and fast algorithm that produce competitive result with sparse user markup knn matting ha a closed form solution that can leverage the preconditioned conjugate gradient method to produce an efficient implementation experimental evaluation on benchmark datasets indicates that our matting result are comparable to or of higher quality than state of the art method requiring more involved implementation in this paper we take the nonlocal principle beyond alpha estimation and extract overlapping image layer using the same laplacian framework given the alpha value our closed form solution can be elegantly generalized to solve the multilayer extraction problem we perform qualitative and quantitative comparison to demonstrate the accuracy of the extracted image layer 
while numerous algorithm have been proposed for object tracking with demonstrated success it remains a challenging problem for a tracker to handle large change in scale motion shape deformation with occlusion one of the main reason is the lack of effective image representation to account for appearance variation most tracker use high level appearance structure or low level cue for representing and matching target object in this paper we propose a tracking method from the perspective of mid level vision with structural information captured in superpixels we present a discriminative appearance model based on superpixels thereby facilitating a tracker to distinguish the target and the background with mid level cue the tracking task is then formulated by computing a target background confidence map and obtaining the best candidate by maximum a posterior estimate experimental result demonstrate that our tracker is able to handle heavy occlusion and recover from drift in conjunction with online update the proposed algorithm is shown to perform favorably against existing method for object tracking 
we present a novel stochastic framework for non blind deconvolution based on point sample obtained from random walk unlike previous method that must be tailored to specific regularization strategy the new stochastic deconvolution method allows arbitrary prior including non convex and data dependent regularizers to be introduced and tested with little effort stochastic deconvolution is straightforward to implement produce state of the art result and directly lead to a natural boundary condition for image boundary and saturated pixel 
many binary code encoding scheme based on hashing have been actively studied recently since they can provide efficient similarity search especially nearest neighbor search and compact data representation suitable for handling large scale image database in many computer vision problem existing hashing technique encode high dimensional data point by using hyperplane based hashing function in this paper we propose a novel hypersphere based hashing function spherical hashing to map more spatially coherent data point into a binary code compared to hyperplane based hashing function furthermore we propose a new binary code distance function spherical hamming distance that is tailored to our hypersphere based binary coding scheme and design an efficient iterative optimization process to achieve balanced partitioning of data point for each hash function and independence between hashing function our extensive experiment show that our spherical hashing technique significantly outperforms six state of the art hashing technique based on hyperplanes across various image benchmark of size ranging from one to million of gist descriptor the performance gain are consistent and large up to improvement the excellent result confirm the unique merit of the proposed idea in using hyperspheres to encode proximity region in high dimensional space finally our method is intuitive and easy to implement 
we propose a top down approach for understanding indoor scene such a bedroom and living room these environment typically have the manhattan world property that many surface are parallel to three principle one further the d geometry of the room and object within it can largely be approximated by non overlapping simple structure such a single block e g the room boundary thin block e g picture frame and object that are well modeled by single block e g simple bed we separately model the d geometry the imaging process camera parameter and edge likelihood to provide a generative statistical model for image data we fit this model using data driven mcmc sampling we combine reversible jump metropolis hastings sample for discrete change in the model such a the number of block and stochastic dynamic to estimate continuous parameter value in a particular parameter space that includes block position block size and camera parameter we tested our approach on two datasets using room box pixel orientation despite using only bounding box geometry and in particular not training on appearance our method achieves result approaching those of others we also introduce a new evaluation method for this domain based on ground truth camera parameter which we found to be more sensitive to the task of understanding scene geometry 
human nameable visual attribute can benefit various recognition task however existing technique restrict these property to categorical label for example a person is smiling or not a scene is dry or not and thus fail to capture more general semantic relationship we propose to model relative attribute given training data stating how object scene category relate according to different attribute we learn a ranking function per attribute the learned ranking function predict the relative strength of each property in novel image we then build a generative model over the joint space of attribute ranking output and propose a novel form of zero shot learning in which the supervisor relates the unseen object category to previously seen object via attribute for example bear are furrier than giraffe we further show how the proposed relative attribute enable richer textual description for new image which in practice are more precise for human interpretation we demonstrate the approach on datasets of face and natural scene and show it clear advantage over traditional binary attribute prediction for these new task 
many recent object retrieval system rely on local feature for describing an image the similarity between a pair of image is measured by aggregating the similarity between their corresponding local feature in this paper we present a probabilistic framework for modeling the feature to feature similarity measure we then derive a query adaptive distance which is appropriate for global similarity evaluation furthermore we propose a function to score the individual contribution into an image to image similarity within the probabilistic framework experimental result show that our method improves the retrieval accuracy significantly and consistently moreover our result compare favorably to the state of the art 
we present a modification of normalized cut to incorporate prior which can be used for constrained image segmentation compared to previous generalization of normalized cut which incorporate constraint our technique ha two advantage first we seek solution which are sufficiently correlated with prior which allows u to use noisy top down information for example from an object detector second given the spectral solution of the unconstrained problem the solution of the constrained one can be computed in small additional time which allows u to run the algorithm in an interactive mode we compare our algorithm to other graph cut based algorithm and highlight the advantage 
we present a new paradigm for tracking object in video in the presence of other similar object this branch and track paradigm is also useful in the absence of motion for the discovery of repetitive pattern in image the object of interest is the lead object and the distracters are extra the lead tracker branch out tracker for extra when they are detected and all tracker share a common set of feature sometimes extra are tracked because they are of interest in their own right in other case and perhaps more importantly tracking extra make tracking the lead nimbler and more robust both because shared feature provide a richer object model and because tracking extra account for source of confusion explicitly sharing feature also make joint tracking le expensive and coordinating tracking across lead and extra allows optimizing window position jointly rather than separately for better result the joint tracking of both lead and extra can be solved optimally by dynamic programming and branching is quickly determined by efficient subwindow search matlab experiment show near real time performance at frame per second on a single core laptop for by image 
we present an image editing tool called content aware rotation casually shot photo can appear tilted and are often corrected by rotation and cropping this trivial solution may remove desired content and hurt image integrity instead of doing rigid rotation we propose a warping method that creates the perception of rotation and avoids cropping human vision study suggest that the perception of rotation is mainly due to horizontal vertical line we design an optimization based method that preserve the rotation of horizontal vertical line maintains the completeness of the image content and reduces the warping distortion an efficient algorithm is developed to address the challenging optimization we demonstrate our content aware rotation method on a variety of practical case 
we investigate the fine grained object categorization problem of determining the breed of animal from an image to this end we introduce a new annotated dataset of pet covering different breed of cat and dog the visual problem is very challenging a these animal particularly cat are very deformable and there can be quite subtle difference between the breed we make a number of contribution first we introduce a model to classify a pet breed automatically from an image the model combine shape captured by a deformable part model detecting the pet face and appearance captured by a bag of word model that describes the pet fur fitting the model involves automatically segmenting the animal in the image second we compare two classification approach a hierarchical one in which a pet is first assigned to the cat or dog family and then to a breed and a flat one in which the breed is obtained directly we also investigate a number of animal and image orientated spatial layout these model are very good they beat all previously published result on the challenging asirra test cat v dog discrimination when applied to the task of discriminating the different breed of pet the model obtain an average accuracy of about a very encouraging result considering the difficulty of the problem 
in this paper we introduce a new approach to constrained clustering which treat the constraint a feature our method augments the original feature space with additional dimension each of which derived from a given cannot link constraint the specified cannot link pair get extreme coordinate value and the rest of the point get coordinate value that express their spatial influence from the specified constrained pair after augmenting all the new feature a standard unconstrained clustering algorithm can be performed like k mean or spectral clustering we demonstrate the efficacy of our method for active semi supervised learning applied to image segmentation and compare it to alternative method we also evaluate the performance of our method on the four most commonly evaluated datasets from the uci machine learning repository 
contour is an important cue for object recognition in this paper built upon the concept of torque in image space we propose a new contour related feature to detect and describe local contour information in image there are two component for our proposed feature one is a contour patch detector for detecting image patch with interesting information of object contour which we call the maximal minimal torque patch mtp detector the other is a contour patch descriptor for characterizing a contour patch by sampling the torque value which we call the multi scale torque mst descriptor experiment for object recognition on the caltech dataset showed that the proposed contour feature outperforms other contour related feature and is on a par with many other type of feature when combing our descriptor with the complementary sift descriptor impressive recognition result are observed 
the objective of this paper is large scale object instance retrieval given a query image a starting point of such system is feature detection and description for example using sift the focus of this paper however is towards very large scale retrieval where due to storage requirement very compact image descriptor are required and no information about the original sift descriptor can be accessed directly at run time we start from vlad the state of the art compact descriptor introduced by jegou et al for this purpose and make three novel contribution first we show that a simple change to the normalization method significantly improves retrieval performance second we show that vocabulary adaptation can substantially alleviate problem caused when image are added to the dataset after initial vocabulary learning these two method set a new state of the art over all benchmark investigated here for both mid dimensional k d to k d and small d descriptor our third contribution is a multiple spatial vlad representation multivlad that allows the retrieval and localization of object that only extend over a small part of an image again without requiring use of the original image sift descriptor 
this paper introduces a novel classification method termed alternating decision forest adfs which formulates the training of random forest explicitly a a global loss minimization problem during training the loss are minimized via keeping an adaptive weight distribution over the training sample similar to boosting method in order to keep the method a flexible and general a possible we adopt the principle of employing gradient descent in function space which allows to minimize arbitrary loss contrary to boosted tree in our method the loss minimization is an inherent part of the tree growing process thus allowing to keep the benefit of common random forest such a parallel processing we derive the new classifier and give a discussion and evaluation on standard machine learning data set furthermore we show how adfs can be easily integrated into an object detection application compared to both standard random forest and boosted tree adfs give better performance in our experiment while yielding more compact model in term of tree depth 
the task of object pose estimation ha been a challenge since the early day of computer vision to estimate the pose or viewpoint of an object people have mostly looked at object intrinsic feature such a shape or appearance surprisingly informative feature provided by other external element in the scene have so far mostly been ignored at the same time contextual cue have been shown to be of great benefit for related task such a object detection or action recognition in this paper we explore how information from other object in the scene can be exploited for pose estimation in particular we look at object configuration we show that starting from noisy object detection and pose estimate exploiting the estimated pose and location of other object in the scene can help to estimate the object pose more accurately we explore both a camera centered a well a an object centered representation for relation experiment on the challenging kitti dataset show that object configuration can indeed be used a a complementary cue to appearance based pose estimation in addition object centered relational representation can also assist object detection 
inverted indexing is a popular non exhaustive solution to large scale search an inverted file is built by a quantizer such a k mean or a tree structure it ha been found that multiple inverted file obtained by multiple independent random quantizers are able to achieve practically good recall and speed instead of computing the multiple quantizers independently we present a method that creates them jointly our method jointly optimizes all code word in all quantizers then it assigns these code word to the quantizers in experiment this method show significant improvement over various existing method that use multiple independent quantizers on the one billion set of sift vector our method is faster and more accurate than a recent state of the art inverted indexing method 
image registration and d reconstruction are fundamental computer vision and medical imaging problem they are particularly challenging when the input data are image of a deforming body obtained by a single moving camera we propose a new modelling framework the multiview d warp existing model are twofold they estimate inter image warp which are often inconsistent between the different image and do not model the underlying d structure or reconstruct just a sparse set of point in contrast our multiview d warp combine the advantage of both they have an explicit d component and a set of d deformation combined with projection to d they thus capture the dense deforming body s time varying shape and camera pose the advantage over the classical solution are numerous thanks to our feature based estimation method for the multiview d warp one can not only augment the original image but also retarget or clone the observed body s d deformation by changing the pose experimental result on simulated and real data are reported confirming the advantage of our framework over existing method 
in recent year the rise of digital image and video data available ha led to an increasing demand for image annotation in this paper we propose an interactive object annotation method that incrementally train an object detector while the user provides annotation in the design of the system we have focused on minimizing human annotation time rather than pure algorithm learning performance to this end we optimize the detector based on a realistic annotation cost model based on a user study since our system give live feedback to the user by detecting object on the fly and predicts the potential annotation cost of unseen image data can be efficiently annotated by a single user without excessive waiting time in contrast to popular tracking based method for video annotation our method is suitable for both still image and video we have evaluated our interactive annotation approach on three datasets ranging from surveillance television to cell microscopy 
when dealing with object with complex structure saliency detection confronts a critical problem namely that detection accuracy could be adversely affected if salient foreground or background in an image contains small scale high contrast pattern this issue is common in natural image and form a fundamental challenge for prior method we tackle it from a scale point of view and propose a multi layer approach to analyze saliency cue the final saliency map is produced in a hierarchical model different from varying patch size or downsizing image our scale based region handling is by finding saliency value optimally in a tree model our approach improves saliency detection on many image that cannot be handled well traditionally a new dataset is also constructed 
graph matching play a central role in solving correspondence problem in computer vision graph matching problem that incorporate pair wise constraint can be cast a a quadratic assignment problem qap unfortunately qap is np hard and many algorithm have been proposed to solve different relaxation this paper present factorized graph matching fgm a novel framework for interpreting and optimizing graph matching problem in this work we show that the affinity matrix can be factorized a a kronecker product of smaller matrix there are three main benefit of using this factorization in graph matching there is no need to compute the costly in space and time pair wise affinity matrix the factorization provides a taxonomy for graph matching and reveals the connection among several method using the factorization we derive a new approximation of the original problem that improves state of the art algorithm in graph matching experimental result in synthetic and real database illustrate the benefit of fgm the code is available at http humansensing c cmu edu fgm 
we handle a special type of motion blur considering that camera move primarily forward or backward solving this type of blur is of unique practical importance since nearly all car traffic and bike mounted camera follow out of plane translational motion we start with the study of geometric model and analyze the difficulty of existing method to deal with them we also propose a solution accounting for depth variation homographies associated with different d plane are considered and solved for in an optimization framework our method is verified on several natural image example that cannot be satisfyingly dealt with by previous method 
we propose an unsupervised domain adaptation method that exploit intrinsic compact structure of category across different domain using binary attribute our method directly optimizes for classification in the target domain the key insight is finding attribute that are discriminative across category and predictable across domain we achieve a performance that significantly exceeds the state of the art result on standard benchmark in fact in many case our method reach the same domain performance the upper bound in unsupervised domain adaptation scenario 
color description is a challenging task because of large variation in rgb value which occur due to scene accidental event such a shadow shading specularities illuminant color change and change in viewing geometry traditionally this challenge ha been addressed by capturing the variation in physic based model and deriving invariant for the undesired variation the drawback of this approach is that set of distinguishable color in the original color space are mapped to the same value in the photometric invariant space this result in a drop of discriminative power of the color description in this paper we take an information theoretic approach to color description we cluster color value together based on their discriminative power in a classification problem the clustering ha the explicit objective to minimize the drop of mutual information of the final representation we show that such a color description automatically learns a certain degree of photometric invariance we also show that a universal color representation which is based on other data set than the one at hand can obtain competing performance experiment show that the proposed descriptor outperforms existing photometric invariant furthermore we show that combined with shape description these color descriptor obtain excellent result on four challenging datasets namely pascal voc flower stanford dog and bird 
a fundamental limitation of quantization technique like the k mean clustering algorithm is the storage and run time cost associated with the large number of cluster required to keep quantization error small and model fidelity high we develop new model with a compositional parameterization of cluster center so representational capacity increase super linearly in the number of parameter this allows one to effectively quantize data using billion or trillion of center we formulate two such model orthogonal k mean and cartesian k mean they are closely related to one another to k mean to method for binary hash function optimization like itq gong and lazebnik and to product quantization for vector quantization jegou et al the model are tested on large scale ann retrieval task m gist b sift feature and on codebook learning for object recognition cifar 
traditional video compression method obtain a compact representation for image frame by computing coarse motion field defined on patch of pixel called block in order to compensate for the motion in the scene across frame this piecewise constant approximation make the motion field efficiently encodable but it introduces block artifact in the warped image frame in this paper we address the problem of estimating dense motion field that while accurately predicting one frame from a given reference frame by warping it with the field are also compressible we introduce a representation for motion field based on wavelet base and approximate the compressibility of their coefficient with a piecewise smooth surrogate function that yield an objective function similar to classical optical flow formulation we then show how to quantize and encode such coefficient with adaptive precision we demonstrate the effectiveness of our approach by comparing it performance with a state of the art wavelet video encoder experimental result on a number of standard flow and video datasets reveal that our method significantly outperforms both block based and optical flow based motion compensation algorithm 
recently hashing technique have been widely applied to solve the approximate nearest neighbor search problem in many vision application generally these hashing approach generate c bucket where c is the length of the hash code a good hashing method should satisfy the following two requirement mapping the nearby data point into the same bucket or nearby measured by the hamming distance bucket all the data point are evenly distributed among all the bucket in this paper we propose a novel algorithm named complementary projection hashing cph to find the optimal hashing function which explicitly considers the above two requirement specifically cph aim at sequentially finding a series of hyper plane hashing function which cross the sparse region of the data at the same time the data point are evenly distributed in the hyper cube generated by these hyper plane the experiment comparing with the state of the art hashing method demonstrate the effectiveness of the proposed method 
coherency sensitive hashing csh extends locality sensitivity hashing lsh and patchmatch to quickly find matching patch between two image lsh relies on hashing which map similar patch to the same bin in order to find matching patch patchmatch on the other hand relies on the observation that image are coherent to propagate good match to their neighbor in the image plane it us random patch assignment to seed the initial matching csh relies on hashing to seed the initial patch matching and on image coherence to propagate good match in addition hashing let it propagate information between patch with similar appearance i e map to the same bin this way information is propagated much faster because it can use similarity in appearance space or neighborhood in the image plane a a result csh is at least three to four time faster than patchmatch and more accurate especially in textured region where reconstruction artifact are most noticeable to the human eye we verified csh on a new large scale data set of image pair 
the advance in image acquisition technique make recording image never easier and brings a great convenience to our daily life it raise at the same time the issue of privacy protection in the photograph one particular problem addressed in this paper is about covert photograph which are taken secretly and often violate the subject willingness we study the task of automatic covert photograph classification which can be used to help inhibiting distribution of such image e g internet image filtering by carefully collecting and investigating a large covert v non covert photograph dataset we observed that there are many feature e g degree of blur that seem to be correlated with covert photograph but counter example always exist in addition we observed that image visual attribute e g photo composition play an important role in distinguishing covert photograph these observation motivate u to fuse both low level image statistic and middle level attribute feature for classifying covert image in particular we propose a solution using multiple kernel learning to combine different image feature and image attribute we evaluated thoroughly the proposed approach together with many different solution including some state of the art image classifier the effectiveness of the proposed solution is clearly demonstrated in the result furthermore a the first study to this problem we expect our study to motivate further research investigation 
object functionality refers to the quality of an object that allows human to perform some specific action it ha been shown in psychology that functionality affordance is at least a essential a appearance in object recognition by human in computer vision most previous work on functionality either assumes exactly one functionality for each object or requires detailed annotation of human pose and object in this paper we propose a weakly supervised approach to discover all possible object functionality each object functionality is represented by a specific type of human object interaction our method take any possible human object interaction into consideration and evaluates image similarity in d rather than d in order to cluster human object interaction more coherently experimental result on a dataset of people interacting with musical instrument show the effectiveness of our approach 
spatial pyramid representation spr is a widely used method for embedding both global and local spatial information into a feature and it show good performance in term of generic image recognition in spr the image is divided into a sequence of increasingly finer grid on each pyramid level feature are extracted from all of the grid cell and are concatenated to form one huge feature vector a a result expensive computational cost are required for both learning and testing moreover because the strategy for partitioning the image at each pyramid level is designed by hand there is weak theoretical evidence of the appropriate partitioning strategy for good categorization in this paper we propose discriminative spr which is a new representation that form the image feature a a weighted sum of semi local feature over all pyramid level the weight are automatically selected to maximize a discriminative power the resulting feature is compact and preserve high discriminative power even in low dimension furthermore the discriminative spr can suggest the distinctive cell and the pyramid level simultaneously by observing the optimal weight generated from the fine grid cell 
this paper introduces a new formulation for discrete image labeling task the decision tree field dtf that combine and generalizes random forest and conditional random field crf which have been widely used in computer vision in a typical crf model the unary potential are derived from sophisticated random forest or boosting based classifier however the pairwise potential are assumed to have a simple parametric form with a pre specified and fixed dependence on the image data and to be defined on the basis of a small and fixed neighborhood in contrast in dtf local interaction between multiple variable are determined by mean of decision tree evaluated on the image data allowing the interaction to be adapted to the image content this result in powerful graphical model which are able to represent complex label structure our key technical contribution is to show that the dtf model can be trained efficiently and jointly using a convex approximate likelihood function enabling u to learn over a million free model parameter we show experimentally that for application which have a rich and complex label structure our model achieves excellent result 
most conventional single image deblurring method assume that the underlying scene is static and the blur is caused by only camera shake in this paper in contrast to this restrictive assumption we address the deblurring problem of general dynamic scene which contain multiple moving object a well a camera shake in case of dynamic scene moving object and background have different blur motion so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately thus we propose a novel energy model designed with the weighted sum of multiple blur data model which estimate different motion blur and their associated pixel wise weight and resulting sharp image in this framework the local weight are determined adaptively and get high value when the corresponding data model have high data fidelity and the weight information is used for the segmentation of the motion blur non local regularization of weight are also incorporated to produce more reliable segmentation result a convex optimization based method is used for the solution of the proposed energy model experimental result demonstrate that our method outperforms conventional approach in deblurring both dynamic scene and static scene 
we present a novel method for clustering data drawn from a union of arbitrary dimensional subspace called discriminative subspace clustering disc disc solves the subspace clustering problem by using a quadratic classifier trained from unlabeled data clustering by classification we generate label by exploiting the locality of point from the same subspace and a basic affinity criterion a number of classifier are then diversely trained from different partition of the data and their result are combined together in an ensemble in order to obtain the final clustering result we have tested our method with challenging datasets and compared against state of the art method from literature our result show that disc is a very strong performer in both accuracy and robustness and also of low computational complexity 
the objective of this work is to learn sub category rather than casting this a a problem of unsupervised clustering we investigate a weakly supervised approach using both positive and negative sample of the category we make the following contribution i we introduce a new model for discriminative sub categorization which determines cluster membership for positive sample whilst simultaneously learning a max margin classifier to separate each cluster from the negative sample ii we show that this model doe not suffer from the degenerate cluster problem that afflicts several competing method e g latent svm and max margin clustering iii we show that the method is able to discover interpretable sub category in various datasets the model is evaluated experimentally over various datasets and it performance advantage over k mean and latent svm are demonstrated we also stress test the model and show it resilience in discovering sub category a the parameter are varied 
graph matching gm is a fundamental problem in computer science and it ha been successfully applied to many problem in computer vision although widely used existing gm algorithm cannot incorporate global consistence among node which is a natural constraint in computer vision problem this paper proposes deformable graph matching dgm an extension of gm for matching graph subject to global rigid and non rigid geometric constraint the key idea of this work is a new factorization of the pair wise affinity matrix this factorization decouples the affinity matrix into the local structure of each graph and the pair wise affinity edge besides the ability to incorporate global geometric transformation this factorization offer three more benefit first there is no need to compute the costly in space and time pair wise affinity matrix second it provides a unified view of many gm method and extends the standard iterative closest point algorithm third it allows to use the path following optimization algorithm that lead to improved optimization strategy and matching performance experimental result on synthetic and real database illustrate how dgm outperforms state of the art algorithm for gm the code is available at http humansensing c cmu edu fgm 
we propose a randomized ensemble algorithm to model the time varying appearance of an object for visual tracking in contrast with previous online method for updating classifier ensemble in tracking by detection the weight vector that combine weak classifier is treated a a random variable and the posterior distribution for the weight vector is estimated in a bayesian manner in essence the weight vector is treated a a distribution that reflects the confidence among the weak classifier used to construct and adapt the classifier ensemble the resulting formulation model the time varying discriminative ability among weak classifier so that the ensembled strong classifier can adapt to the varying appearance background and occlusion the formulation is tested in a tracking by detection implementation experiment on challenging benchmark video demonstrate that the proposed method can achieve result comparable to and often better than those of state of the art approach 
this paper proposes a recursive implementation of the bilateral filter unlike previous method this implementation yield an bilateral filter whose computational complexity is linear in both input size and dimensionality the proposed implementation demonstrates that the bilateral filter can be a efficient a the recent edge preserving filtering method especially for high dimensional image let the number of pixel contained in the image be n and the number of channel be d the computational complexity of the proposed implementation will be o nd it is more efficient than the state of the art bilateral filtering method that have a computational complexity of o nd linear in the image size but polynomial in dimensionality or o nlog n d linear in the dimensionality thus faster than for high dimensional filtering specifically the proposed implementation take about m to process a one megapixel color image and about m to process a megapixel grayscale image which is about faster than and faster than the experiment were conducted on a macbook air laptop computer with a ghz intel core i cpu and gb memory the memory complexity of the proposed implementation is also low a few a the image memory will be required memory for the image before and after filtering is excluded this paper also derives a new filter named gradient domain bilateral filter from the proposed recursive implementation unlike the bilateral filter it performs bilateral filtering on the gradient domain it can be used for edge preserving filtering but avoids sharp edge that are observed to cause visible artifact in some computer graphic task the proposed implementation were proved to be effective for a number of computer vision and computer graphic application including stylization tone mapping detail enhancement and stereo matching 
a huge fraction of camera used nowadays is based on cmos sensor with a rolling shutter that expose the image line by line for dynamic scene camera this introduces undesired effect like stretch shear and wobble it ha been shown earlier that rotational shake induced rolling shutter effect in hand held cell phone capture can be compensated based on an estimate of the camera rotation in contrast we analyse the case of significant camera motion e g where a bypassing street level capture vehicle us a rolling shutter camera in a d reconstruction framework the introduced error is depth dependent and cannot be compensated based on camera motion rotation alone invalidating also rectification for stereo camera system on top significant lens distortion a often present in wide angle camera intertwines with rolling shutter effect a it change the time at which a certain d point is seen we show that naive d reconstruction assuming global shutter will deliver biased geometry already for very mild assumption on vehicle speed and resolution we then develop rolling shutter dense multiview stereo algorithm that solve for time of exposure and depth at the same time even in the presence of lens distortion and perform an evaluation on ground truth laser scan model a well a on real street level data 
we address the problem of labeling individual datapoints given some knowledge about small subset or group of them the knowledge we have for a group is the likelihood value for each group member to satisfy a certain model this problem is equivalent to hypergraph labeling problem where each datapoint corresponds to a node and the each subset correspond to a hyperedge with likelihood value a it weight we propose a novel method to model the label dependence using an undirected graphical model and reduce the problem of hypergraph labeling into an inference problem this paper describes the structure and necessary component of such model and proposes useful cost function we discus the behavior of proposed algorithm with different form of the cost function identify suitable algorithm for inference and analyze required property when it is theoretically guaranteed to have exact solution example of several real world problem are shown a application of the proposed method 
this paper address the problem of semantic segmentation of d point cloud we extend the inference machine framework of ross et al by adding spatial factor that model mid range and long range dependency inherent in the data the new model is able to account for semantic spatial context during training our method automatically isolates and retains factor modelling spatial dependency between variable that are relevant for achieving higher prediction accuracy we evaluate the proposed method by using it to predict category semantic segmentation on set of stitched kinect scan experimental result show that the spatial dependency learned by our method significantly improve the accuracy of segmentation they also show that our method outperforms the existing segmentation technique of koppula et al 
many technique in computer vision machine learning and statistic rely on the fact that a signal of interest admits a sparse representation over some dictionary dictionary are either available analytically or can be learned from a suitable training set while analytic dictionary permit to capture the global structure of a signal and allow a fast implementation learned dictionary often perform better in application a they are more adapted to the considered class of signal in imagery unfortunately the numerical burden for i learning a dictionary and for ii employing the dictionary for reconstruction task only allows to deal with relatively small image patch that only capture local image information the approach presented in this paper aim at overcoming these drawback by allowing a separable structure on the dictionary throughout the learning process on the one hand this permit larger patch size for the learning phase on the other hand the dictionary is applied efficiently in reconstruction task the learning procedure is based on optimizing over a product of sphere which update the dictionary a a whole thus enforces basic dictionary property such a mutual coherence explicitly during the learning procedure in the special case where no separable structure is enforced our method competes with state of the art dictionary learning method like k svd 
we consider the problem of quantizing data generated from disparate source e g subject performing action with different style movie with particular genre bias various condition in which image of object are taken etc these are scenario where unsupervised clustering produce inadequate codebooks because algorithm like k mean tend to cluster sample based on data bias e g cluster subject rather than cluster similar sample across source e g cluster action we propose a new quantization technique source constrained clustering scc which extends the k mean algorithm by enforcing cluster to group sample from multiple source we evaluate the method in the context of activity recognition from video in an unconstrained environment experiment on several task and feature show that using source information improves classification performance 
the goal of face hallucination is to generate high resolution image with fidelity from low resolution one in contrast to existing method based on patch similarity or holistic constraint in the image space we propose to exploit local image structure for face hallucination each face image is represented in term of facial component contour and smooth region the image structure is maintained via matching gradient in the reconstructed high resolution output for facial component we align input image to generate accurate exemplar and transfer the high frequency detail for preserving structural consistency for contour we learn statistical prior to generate salient structure in the high resolution image a patch matching method is utilized on the smooth region where the image gradient are preserved experimental result demonstrate that the proposed algorithm generates hallucinated face image with favorable quality and adaptability 
we describe a method for learning steerable deformable part model our model exploit the fact that part template can be written a linear filter bank we demonstrate that one can enforce steerability and separability during learning by applying rank constraint these constraint are enforced with a coordinate descent learning algorithm where each step can be solved with an off the shelf structured svm solver the resulting model are order of magnitude smaller than their counterpart greatly simplifying learning and reducing run time computation limiting the degree of freedom also reduces overfitting which is useful for learning large part vocabulary from limited training data we learn steerable variant of several state of the art model for object detection human pose estimation and facial landmark estimation our steerable model are smaller faster and often improve performance 
we propose a method for simultaneous shape constrained segmentation and parameter recovery the parameter can describe anything from d shape to d pose and we place no restriction on the topology of the shape i e they can have hole or be made of multiple part we use shared gaussian process latent variable model to learn multimodal shape parameter space these allow non linear embeddings of the high dimensional shape and parameter space in low dimensional space in a fully probabilistic manner we propose a method for exploring the multimodality in the joint space in an efficient manner by learning a mapping from the latent space to a space that encodes the similarity between shape we further extend the sgp lvm to a model that make use of a hierarchy of embeddings and show that this yield faster convergence and greater accuracy over the standard non hierarchical embedding shape are represented implicitly using level set and inference is made tractable by compressing the level set embedding function with discrete cosine transforms we show state of the art result in various field ranging from pose recovery to gaze tracking and to monocular d reconstruction 
this paper introduces a schematic representation for architectural scene together with robust algorithm for reconstruction from sparse d point cloud data the schematic model architecture a a network of transport curve approximating a floorplan with associated profile curve together comprising an interconnected set of swept surface the representation is extremely concise composed of a handful of planar curve and easily interpretable by human the approach also provides a principled mechanism for interpolating a dense surface and enables filling in hole in the data by mean of a pipeline that employ a global optimization over all parameter by incorporating a displacement map on top of the schematic surface it is possible to recover fine detail experiment show the ability to reconstruct extremely clean and simple model from sparse structure from motion point cloud of complex architectural scene 
in this paper we address the two class classification problem within the tensor based framework by formulating the support tucker machine stums more precisely in the proposed stums the weight parameter are regarded to be a tensor calculated according to the tucker tensor decomposition a the multiplication of a core tensor with a set of matrix one along each mode we further extend the proposed stums to the s s wstums in order to fully exploit the information offered by the total or the within class covariance matrix and whiten the data thus providing in variance to affine transformation in the feature space we formulate the two above mentioned problem in such a way that they can be solved in an iterative manner where at each iteration the parameter corresponding to the projection along a single tensor mode are estimated by solving a typical support vector machine type problem the superiority of the proposed method in term of classification accuracy is illustrated on the problem of gait and action recognition 
super pixel algorithm represent a very useful and increasingly popular preprocessing step for a wide range of computer vision application a they offer the potential to boost efficiency and effectiveness in this regard this paper present a highly competitive approach for temporally consistent super pixel for video content the approach is based on energy minimizing clustering utilizing a novel hybrid clustering strategy for a multi dimensional feature space working in a global color subspace and local spatial subspace moreover a new contour evolution based strategy is introduced to ensure spatial coherency of the generated super pixel for a thorough evaluation the proposed approach is compared to state of the art super voxel algorithm using established benchmark and show a superior performance 
we present a method for computing ambient occlusion ao for a stack of image of a scene from a fixed viewpoint ambient occlusion a concept common in computer graphic characterizes the local visibility at a point it approximates how much light can reach that point from different direction without getting blocked by other geometry while ao ha received surprisingly little attention in vision we show that it can be approximated using simple per pixel statistic over image stack based on a simplified image formation model we use our derived ao measure to compute reflectance and illumination for object without relying on additional smoothness prior and demonstrate state of the art performance on the mit intrinsic image benchmark we also demonstrate our method on several synthetic and real scene including d printed object with known ground truth geometry 
in this paper we address the problem of recovering both the topology and the geometry of a deformable shape using temporal mesh sequence the interest arises in multi camera application when unknown natural dynamic scene are captured while several approach allow recovery of shape model from static scene few consider dynamic scene with evolving topology and without prior knowledge in this nonetheless generic situation a single time observation is not necessarily sufficient to infer the correct topology of the observed shape and evidence must be accumulated over time in order to learn the topology and to enable temporally consistent modelling this appears to be a new problem for which no formal solution exists we propose a principled approach based on the assumption that the observed object have a fixed topology under this assumption we can progressively learn the topology meanwhile capturing the deformation of the dynamic scene the approach ha been successfully experimented on several standard d datasets 
a new paradigm for multivariate regression is proposed principal regression analysis pra it entail learning a low dimensional subspace over sample specific regressors for a given input the model predicts a subspace thought to contain the corresponding response using this subspace a a prior the search space is considerably more constrained an efficient local optimisation strategy is proposed for learning and a practical choice for it initialisation suggested the utility of pra is demonstrated on the task of non rigid face and car alignment using challenging in the wild datasets where substantial performance improvement are observed over alignment with a conventional prior 
in this paper we propose a new family of binary local feature descriptor called nested shape descriptor these descriptor are constructed by pooling oriented gradient over a large geometric structure called the hawaiian earring which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance this distance function is unique to the nested descriptor and provides robustness to outlier from order statistic in this paper we define the nested shape descriptor family and introduce a specific member called the seed of life descriptor we perform a trade study to determine optimal descriptor parameter for the task of image matching finally we evaluate performance compared to state of the art local feature descriptor on the vgg affine image matching benchmark showing significant performance gain our descriptor is the first binary descriptor to outperform sift on this benchmark 
in this paper we introduce a new problem which we call object co detection given a set of image with object observed from two or multiple image the goal of co detection is to detect the object establish the identity of individual object instance a well a estimate the viewpoint transformation of corresponding object instance in designing a co detector we follow the intuition that an object ha consistent appearance when observed from the same or different viewpoint by modeling an object using state of the art part based representation such a we measure appearance consistency between object by comparing part appearance and geometry across image this allows to effectively account for object self occlusion and viewpoint transformation extensive experimental evaluation indicates that our co detector obtains more accurate detection result than if object were to be detected from each image individually moreover we demonstrate the relevance of our co detection scheme to other recognition problem such a single instance object recognition wide baseline matching and image query 
the paper proposes a vision based online mapping of large scale environment our novel approach us a hybrid representation of a fully metric euclidean environment map and a topological map this novel hybrid representation facilitates our scalable online hierarchical bundle adjustment approach the proposed method achieves scalability by solving the local registration through embedding neighboring keyframes and landmark into a euclidean space the global adjustment is performed on a segmentation of the keyframes and posed a the iterative optimization of the arrangement of keyframes in each segment and the arrangement of rigidly moving segment the iterative global adjustment is performed concurrently with the local registration of the keyframes in a local map thus the map is always locally metric around the current location and likely to be globally consistent loop closure are handled very efficiently benefiting from the topological nature of the map and overcoming the loss of the metric map property a previous approach the effectiveness of the proposed method is demonstrated in real time on various challenging video sequence 
recent local stereo matching algorithm based on an adaptive weight strategy achieve accuracy similar to global approach one of the major problem of these algorithm is that they are computationally expensive and this complexity increase proportionally to the window size this paper proposes a novel cost aggregation step with complexity independent of the window size i e o that outperforms state of the art o method moreover compared to other o approach our method doe not rely on integral histogram enabling aggregation using colour image instead of grayscale one finally to improve the result of the proposed algorithm a disparity refinement pipeline is also proposed the overall algorithm produce result comparable to those of state of the art stereo matching algorithm 
learning filter to produce sparse image representation in term of over complete dictionary ha emerged a a powerful way to create image feature for many different purpose unfortunately these filter are usually both numerous and non separable making their use computationally expensive in this paper we show that such filter can be computed a linear combination of a smaller number of separable one thus greatly reducing the computational complexity at no cost in term of performance this make filter learning approach practical even for large image or d volume and we show that we significantly outperform state of the art method on the linear structure extraction task in term of both accuracy and speed moreover our approach is general and can be used on generic filter bank to reduce the complexity of the convolution 
we present the design and implementation of new inexact newton type bundle adjustment algorithm that exploit hardware parallelism for efficiently solving large scale d scene reconstruction problem we explore the use of multicore cpu a well a multicore gpus for this purpose we show that overcoming the severe memory and bandwidth limitation of current generation gpus not only lead to more space efficient algorithm but also to surprising saving in runtime our cpu based system is up to ten time and our gpu based system is up to thirty time faster than the current state of the art method while maintaining comparable convergence behavior the code and additional result are available at http grail c washington edu project mcba 
bottom up fully unsupervised segmentation remains a daunting challenge for computer vision in the cosegmentation context on the other hand the availability of multiple image assumed to contain instance of the same object class provides a weak form of supervision that can be exploited by discriminative approach unfortunately most existing algorithm are limited to a very small number of image and or object class typically two of each this paper proposes a novel energy minimization approach to cosegmentation that can handle multiple class and a significantly larger number of image the proposed cost function combine spectraland discriminative clustering term and it admits a probabilistic interpretation it is optimized using an efficient em method initialized using a convex quadratic approximation of the energy comparative experiment show that the proposed approach match or improves the state of the art on several standard datasets 
we consider the problem of shape recovery for real world scene where a variety of global illumination interreflection subsurface scattering etc and illumination defocus effect are present these effect introduce systematic and often significant error in the recovered shape we introduce a structured light technique called micro phase shifting which overcomes these problem the key idea is to project sinusoidal pattern with frequency limited to a narrow high frequency band these pattern produce a set of image over which global illumination and defocus effect remain constant for each point in the scene this enables high quality reconstruction of scene which have traditionally been considered hard using only a small number of image we also derive theoretical lower bound on the number of input image needed for phase shifting and show that micro p achieves the bound 
we present a method to analyze daily activity such a meal preparation using video from an egocentric camera our method performs inference about activity action hand and object daily activity are a challenging domain for activity recognition which are well suited to an egocentric approach in contrast to previous activity recognition method our approach doe not require pre trained detector for object and hand instead we demonstrate the ability to learn a hierarchical model of an activity by exploiting the consistent appearance of object hand and action that result from the egocentric context we show that joint modeling of activity action and object lead to superior performance in comparison to the case where they are considered independently we introduce a novel representation of action based on object hand interaction and experimentally demonstrate the superior performance of our representation in comparison to standard activity representation such a bag of word 
with the explosion in the usage of mobile device and other smart electronics embedded device are becoming ubiquitous most such embedded architecture utilize fixed point rather than floating point computation to meet power heat and speed requirement leading to the need for integer based processing algorithm operation involving gaussian kernel are common to such algorithm but the standard method of constructing such kernel result in approximation and lack a property that enables efficient bitwise shift operation to overcome these limitation we present how to precisely combine the power of integer arithmetic and bitwise shift with intrinsically real valued gaussian kernel we prove mathematically that there exist a set of what we call magic sigma for which the integer kernel exactly represent the gaussian function whose value are all power of two and we discovered that the maximum sigma that lead to such property is about we also designed a simple and precise algorithm for designing kernel composed exclusively of integer given any arbitrary sigma and show how this can be exploited for gaussian filter design considering the ubiquity of gaussian filtering and the need for integer computation for increasing number of embedded device this is an important result for both theoretical and practical purpose 
naive bayes nearest neighbor nbnn ha recently been proposed a a powerful non parametric approach for object classification that manages to achieve remarkably good result thanks to the avoidance of a vector quantization step and the use of image to class comparison yielding good generalization in this paper we introduce a kernelized version of nbnn this way we can learn the classifier in a discriminative setting moreover it then becomes straightforward to combine it with other kernel in particular we show that our nbnn kernel is complementary to standard bag of feature based kernel focussing on local generalization a opposed to global image composition by combining them we achieve state of the art result on caltech and scene datasets a a side contribution we also investigate how to speed up the nbnn computation 
a novel local image descriptor is proposed in this paper which combine intensity order and gradient distribution in multiple support region the novelty lie in three aspect the gradient is calculated in a rotation invariant way in a given support region the rotation invariant gradient are adaptively pooled spatially based on intensity order in order to encode spatial information multiple support region are used for constructing descriptor which further improves it discriminative ability therefore the proposed descriptor encodes not only gradient information but also information about relative relationship of intensity a well a spatial information in addition it is truly rotation invariant in theory without the need of computing a dominant orientation which is a major error source of most existing method such a sift result on the standard oxford dataset and d object have shown a significant improvement over the state of the art method under various image transformation 
although tracing linear structure in d image and d image stack ha received much attention over the year full automation remains elusive in this paper we formulate the delineation problem a one of solving a quadratic mixed integer program q mip in a graph of potential path which can be done optimally up to a very small tolerance we further propose a novel approach to weighting these path which result in a q mip solution that accurately match the ground truth we demonstrate that our approach outperforms a state of the art technique based on the k minimum spanning tree formulation on a d dataset of aerial image and a d dataset of confocal microscopy stack 
we propose a novel riemannian framework for comparing signal and image in a manner that is invariant to their level of blur this framework us a log fourier representation of signal image in which the set of all possible gaussian blur of a signal i e it orbit under semigroup action of gaussian blur function is a straight line using a set of riemannian metric under which the group action are by isometry the orbit are compared via distance between orbit we demonstrate this framework using a number of experimental result involving d signal and d image 
acquiring transparent refractive object is challenging a these kind of object can only be observed by analyzing the distortion of reference background pattern we present a new single image approach to reconstructing thin transparent surface such a thin solid or surface of fluid our method is based on observing the distortion of light field background illumination light field probe have the potential to encode up to four dimension in varying color and intensity spatial and angular variation on the probe surface commonly employed reference pattern are only two dimensional by coding either position or angle on the probe we show that the additional information can be used to reconstruct refractive surface normal and a sparse set of control point from a single photograph 
in this paper we address the challenging problem of detecting pedestrian who appear in group and have interaction a new approach is proposed for single pedestrian detection aided by multi pedestrian detection a mixture model of multi pedestrian detector is designed to capture the unique visual cue which are formed by nearby multiple pedestrian but cannot be captured by single pedestrian detector a probabilistic framework is proposed to model the relationship between the configuration estimated by single and multi pedestrian detector and to refine the single pedestrian detection result with multi pedestrian detection it can integrate with any single pedestrian detector without significantly increasing the computation load state of the art single pedestrian detection approach are investigated on three widely used public datasets caltech tud brussels and eth experimental result show that our framework significantly improves all these approach the average improvement is on the caltech test dataset on the tud brussels dataset and on the eth dataset in term of average miss rate the lowest average miss rate is reduced from to on the caltech test dataset from to on the tud brussels dataset and from to on the eth dataset 
this paper proposes contour based feature for articulated pose estimation most of recent method are designed using tree structured model with appearance evaluation only within the region of each part while these model allow u to speed up global optimization in localizing the whole part useful appearance cue between neighboring part are missing our work focus on how to evaluate part connectivity using contour cue unlike previous work we locally evaluate part connectivity only along the orientation between neighboring part within where they overlap this adaptive localization of the feature is required for suppressing bad effect due to nuisance edge such a those of background clutter and clothing texture a well a for reducing computational cost discriminative training of the contour feature improves estimation accuracy more experimental result verify the effectiveness of our contour based feature 
point set are the standard output of many d scanning system and depth camera presenting the set of point a is might hide the prominent feature of the object from which the point are sampled our goal is to reduce the number of point in a point set for improving the visual comprehension from a given viewpoint this is done by controlling the density of the reduced point set so a to create bright region low density and dark region high density producing an effect of shading this data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint in addition we introduce a new dual problem for determining visibility of a point from infinity and show how a limitation of it solution can be leveraged in a similar way 
despite the continuous advance in local stereo matching for year most effort are on developing robust cost computation and aggregation method little attention ha been seriously paid to the disparity refinement in this work we study weighted median filtering for disparity refinement we discover that with this refinement even the simple box filter aggregation achieves comparable accuracy with various sophisticated aggregation method with the same refinement this is due to the nice weighted median filtering property of removing outlier error while respecting edge structure this reveals that the previously overlooked refinement can be at least a crucial a aggregation we also develop the first constant time algorithm for the previously time consuming weighted median filter this make the simple combination box aggregation weighted median an attractive solution in practice for both speed and accuracy a a byproduct the fast weighted median filtering unleashes it potential in other application that were hampered by high complexity we show it superiority in various application such a depth up sampling clip art jpeg artifact removal and image stylization 
we present a framework to super resolve planar region found in urban scene and other man made environment by taking into account their d geometry such region have highly structured straight edge but this prior is challenging to exploit due to deformation induced by the projection onto the imaging plane our method factor out such deformation by using recently developed tool based on convex optimization to learn a transform that map the image to a domain where it gradient ha a simple group sparse structure this allows to obtain a novel convex regularizer that enforces global consistency constraint between the edge of the image computational experiment with real image show that this data driven approach to the design of regularizers promoting transform invariant group sparsity is very effective at high super resolution factor we view our approach a complementary to most recent super resolution method which tend to focus on hallucinating high frequency texture 
recently the sparse representation or coding based classification src ha been successfully used in face recognition in src the testing image is represented a a sparse linear combination of the training sample and the representation fidelity is measured by the l norm or l norm of coding residual such a sparse coding model actually assumes that the coding residual follows gaussian or laplacian distribution which may not be accurate enough to describe the coding error in practice in this paper we propose a new scheme namely the robust sparse coding rsc by modeling the sparse coding a a sparsity constrained robust regression problem the rsc seek for the mle maximum likelihood estimation solution of the sparse coding problem and it is much more robust to outlier e g occlusion corruption etc than src an efficient iteratively reweighted sparse coding algorithm is proposed to solve the rsc model extensive experiment on representative face database demonstrate that the rsc scheme is much more effective than state of the art method in dealing with face occlusion corruption lighting and expression change etc 
one of the key challenge in search based image annotation model is to define an appropriate similarity measure between image many kernel distance metric learning kml algorithm have been developed in order to capture the nonlinear relationship between visual feature and semantics of the image one fundamental limitation in applying kml to image annotation is that it requires converting image annotation into binary constraint leading to a significant information loss in addition most kml algorithm suffer from high computational cost due to the requirement that the learned matrix ha to be positive semi definitive psd in this paper we propose a robust kernel metric learning rkml algorithm based on the regression technique that is able to directly utilize image annotation the proposed method is also computationally more efficient because psd property is automatically ensured by regression we provide the theoretical guarantee for the proposed algorithm and verify it efficiency and effectiveness for image annotation by comparing it to state of the art approach for both distance metric learning and image annotation 
single sample face recognition is one of the most challenging problem in face recognition we propose a novel face recognition algorithm to address this problem based on a sparse representation based classification src framework the new algorithm is robust to image misalignment and pixel corruption and is able to reduce required training image to one sample per class to compensate the missing illumination information typically provided by multiple training image a sparse illumination transfer sit technique is introduced the sit algorithm seek additional illumination example of face image from one or more additional subject class and form an illumination dictionary by enforcing a sparse representation of the query image the method can recover and transfer the pose and illumination information from the alignment stage to the recognition stage our extensive experiment have demonstrated that the new algorithm significantly outperform the existing algorithm in the single sample regime and with le restriction in particular the face alignment accuracy is comparable to that of the well known deformable src algorithm using multiple training image and the face recognition accuracy exceeds those of the src and extended src algorithm using hand labeled alignment initialization 
temporal misalignment and duration variation in video action largely influence the performance of action recognition but it is very difficult to specify effective temporal alignment on action sequence to address this challenge this paper proposes a novel discriminative learning based temporal alignment method called maximum margin temporal warping mmtw to align two action sequence and measure their matching score based on the latent structure svm formulation the proposed mmtw method is able to learn a phantom action template to represent an action class for maximum discrimination against other class the recognition of this action class is based on the associated learned alignment of the input action extensive experiment on five benchmark datasets have demonstrated that this mmtw model is able to significantly promote the accuracy and robustness of action recognition under temporal misalignment and variation 
nowadays numerous social image have been emerging on the web how to precisely label these image is critical to image retrieval however traditional image level tagging method may become le effective because global image matching approach can hardly cope with the diversity and arbitrariness of web image content this raise an urgent need for the fine grained tagging scheme in this work we study how to establish mapping between tag and image region i e localize tag to image region so a to better depict and index the content of image we propose the spatial group sparse coding sgsc by extending the robust encoding ability of group sparse coding with spatial correlation among training region we present spatial correlation in a two dimensional image space and design group specific spatial kernel to produce a more interpretable regularizer further we propose a joint version of the sgsc model which is able to simultaneously encode a group of intrinsically related region within a test image an effective algorithm is developed to optimize the objective function of the joint sgsc the tag localization task is conducted by propagating tag from sparsely selected group of region to the target region according to the reconstruction coefficient extensive experiment on three public image datasets illustrate that our proposed model achieve great performance improvement over the state of the art method in the tag localization task 
image in general are captured under a diverse set of condition an image of the same object can be captured with varied pose illumination scale background and probably different camera parameter the task of image classification then lie in forming feature of the input image in a representational space where classifier can be better supported in spite of the above variation existing method have mostly focused on obtaining feature which are invariant to scale and translation and thus they generally suffer from performance degradation on datasets which consist of image with varied pose or camera orientation in this paper we present a new framework for image classification which is built upon a novel way of feature extraction that generates largely affine invariant feature called affine sparse code this is achieved through learning a compact dictionary of feature from affine transformed input image analysis and experiment indicate that this novel feature is highly discriminative in addition to being largely affine invariant a classifier using adaboost is then designed using the affine sparse code a the input extensive experiment with standard database demonstrate that the proposed approach can obtain the state of the art result outperforming existing leading approach in the literature 
traditionally researcher tend to exclude fluorescence from color appearance algorithm in computer vision and image processing because of it complexity in reality fluorescence is a very common phenomenon observed in many object from gem and coral to different kind of writing paper and to our clothes in this paper we provide detailed theory of fluorescence phenomenon in particular we show that the color appearance of fluorescence is unaffected by illumination in which it differs from ordinary reflectance moreover we show that the color appearance of object with reflective and fluorescent component can be represented a a linear combination of the two component a linear model allows u to separate the two component using image taken under two unknown illuminant using independent component analysis ica the effectiveness of the proposed method is demonstrated using digital image of various fluorescent object 
estimating geographic location from image is a challenging problem that is receiving recent attention in contrast to many existing method that primarily model discriminative information corresponding to different location we propose joint learning of information that image across location share and vary upon starting with generative and discriminative subspace pertaining to domain which are obtained by a hierarchical grouping of image from adjacent location we present a top down approach that first model cross domain information transfer by utilizing the geometry of these subspace and then encodes the model result onto individual image to infer their location we report competitive result for location recognition and clustering on two public datasets im gps and san francisco and empirically validate the utility of various design choice involved in the approach 
we present a weakly supervised visual data mining approach that discovers connection between recurring mid level visual element in historic temporal and geographic spatial image collection and attempt to capture the underlying visual style in contrast to existing discovery method that mine for pattern that remain visually consistent throughout the dataset our goal is to discover visual element whose appearance change due to change in time or location i e exhibit consistent stylistic variation across the label space date or geo location to discover these element we first identify group of patch that are style sensitive we then incrementally build correspondence to find the same element across the entire dataset finally we train style aware regressors that model each element s range of stylistic difference we apply our approach to date and geo location prediction and show substantial improvement over several baseline that do not model visual style we also demonstrate the method s effectiveness on the related task of fine grained classification 
we present a riemannian framework for analyzing shape of planar contour in which metric and other analysis are invariant to affine transformation and re parameterizations of contour current method that are affine invariant are restricted to point set and do not handle full curve while method that analyze parameterized curve are restricted to equivalence under similarity transformation rigid motion and scale we construct a pre shape manifold of standardized curve curve whose centroid is at the origin are of unit length and their x and y coordinate are uncorrelated and develop a path straightening technique for computing geodesic on this nonlinear manifold under the elastic riemannian metric the removal of the rotation and the re parameterization group result in a quotient space termed affine elastic shape space and the resulting geodesic path exhibit an improved matching of feature across curve these geodesic are used for shape comparison retrieval and statistical modeling of given curve experimental result using both simulated and real data and an application involving poseinvariant activity recognition demonstrate the success of this framework 
we consider the problem of automatically estimating the d pose of human from image taken from multiple calibrated view we show that it is possible and tractable to extend the pictorial structure framework popular for d pose estimation to d we discus how to use this framework to impose view skeleton joint angle and intersection constraint in d the d pictorial structure are evaluated on multiple view data from a professional football game the evaluation is focused on computational tractability but we also demonstrate how a simple d part detector can be plugged into the framework 
recent work in structure from motion sfm ha successfully built d model from large unstructured collection of image downloaded from the internet most approach use incremental algorithm that solve progressively larger bundle adjustment problem these incremental technique scale poorly a the number of image grows and can drift or fall into bad local minimum we present an alternative formulation for sfm based on finding a coarse initial solution using a hybrid discrete continuous optimization and then improving that solution using bundle adjustment the initial optimization step us a discrete markov random field mrf formulation coupled with a continuous levenberg marquardt refinement the formulation naturally incorporates various source of information about both the camera and the point including noisy geotags and vanishing point estimate we test our method on several large scale photo collection including one with measured camera position and show that it can produce model that are similar to or better than those produced with incremental bundle adjustment but more robustly and in a fraction of the time 
in deflectometry the shape of mirror object is recovered from distorted image of a calibrated scene while remarkably high accuracy are achievable state of the art method suffer from two distinct weakness first for mainly constructive reason these can only capture a few square centimeter of surface area at once second reconstruction are ambiguous i e infinitely many surface lead to the same visual impression we resolve both of these problem by introducing the first multiview specular stereo approach which jointly evaluates a series of overlapping deflectometric image two publicly available benchmark accompany this paper enabling u to numerically demonstrate viability and practicability of our approach 
in underwater imagery the image formation process includes refraction that occur when light pass from water into the camera housing typically through a flat glass port we extend the existing work on physical refraction model by considering the dispersion of light and derive new constraint on the model parameter for use in calibration this lead to a novel calibration method that achieves improved accuracy compared to existing work we describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiment 
we propose a novel framework for imposing label ordering constraint in multilabel optimization in particular label jump can be penalized differently depending on the jump direction in contrast to the recently proposed mrf based approach the proposed method arises from the viewpoint of spatially continuous optimization it unifies and generalizes previous approach to label ordering constraint firstly it provides a common solution to three different problem which are otherwise solved by three separate approach we provide an exact characterization of the penalization function expressible with our approach secondly we show that it naturally extends to three and higher dimension of the image domain thirdly it allows novel application such a the convex shape prior despite this generality our model is easily adjustable to various label layout and is also easy to implement on a number of experiment we show that it work quite well producing solution comparable and superior to those obtained with previous approach 
tracking the mitral valve leaflet in an ultrasound sequence is a challenging task because of the poor image quality and fast and irregular leaflet motion previous algorithm usually applied standard segmentation method based on edge object intensity and anatomical information to segment the mitral leaflet in static frame however they are limited in practical application due to the requirement of manual input for initialization or large annotated datasets for training in this paper we present a completely automatic and unsupervised algorithm for mitral leaflet detection and tracking we demonstrate that the image sequence of a cardiac cycle can be well approximated with a low rank matrix except for the mitral leaflet region with fast motion and tissue deformation based on this difference we propose to track the mitral leaflet by detecting contiguous outlier in the low rank representation with this formulation the leaflet is tracked using the motion cue but the complicated motion computation is avoided to the best of our knowledge the proposed algorithm is the first unsupervised method for mitral leaflet tracking the algorithm wa tested on both d and d echocardiography which achieved accurate segmentation with an average distance of mm compared to the manual tracing 
automatic segmentation using multi atlas label fusion ha been widely applied in medical image analysis to simplify the label fusion problem most method implicitly make a strong assumption that the segmentation error produced by different atlas are uncorrelated we show that violating this assumption significantly reduces the efficiency of multi atlas segmentation to address this problem we propose a regression based approach for label fusion our experiment on segmenting the hippocampus in magnetic resonance image mri show significant improvement over previous label fusion technique 
a novel method for registering d surface with large deformation is presented which is based on quasi conformal geometry a general diffeomorphism distorts the conformal structure of the surface which is represented a the beltrami coefficient inversely the diffeomorphism can be determined by the beltrami coefficient in an essentially unique way our registration method first extract the feature on the surface then estimate the beltrami coefficient and finally uniquely determines the registration mapping by solving beltrami equation using curvature flow the method is general it can search the desired registration in the whole space of diffeomorphisms which includes the conventional searching space such a rigid motion isometric transformation or conformal mapping global optimal the global optimum is determined by the method unique up to a dimensional transformation group robust it handle large surface with complicated topology rigorous it ha solid theoretic foundation experiment on the real surface with large deformation and complicated topology demonstrate the efficiency robustness of the proposed method 
light field imaging system have got much attention recently a the next generation camera model a light field imaging system consists of three part data acquisition manipulation and application given an acquisition system it is important to understand how a light field camera convert from it raw image to it resulting refocused image in this paper using the lytro camera a an example we describe step by step procedure to calibrate a raw light field image in particular we are interested in knowing the spatial and angular coordinate of the micro lens array and the resampling process for image reconstruction since lytro us a hexagonal arrangement of a micro lens image additional treatment in calibration are required after calibration we analyze and compare the performance of several resampling method for image reconstruction with and without calibration finally a learning based interpolation method is proposed which demonstrates a higher quality image reconstruction than previous interpolation method including a method used in lytro software 
we address the problem of upper body human pose estimation in uncontrolled monocular video sequence without manual initialization most current method focus on isolated video frame and often fail to correctly localize arm and hand inferring pose over a video sequence is advantageous because pose of people in adjacent frame exhibit property of smooth variation due to the nature of human and camera motion to exploit this previous method have used prior knowledge about distinctive action or generic temporal prior combined with static image likelihood to track people in motion here we take a different approach based on a simple observation information about how a person move from frame to frame is present in the optical flow field we develop an approach for tracking articulated motion that link articulated shape model of people in adjacent frame through the dense optical flow key to this approach is a d shape model of the body that we use to compute how the body move over time the resulting flowing puppet provide a way of integrating image evidence across frame to improve pose inference we apply our method on a challenging dataset of tv video sequence and show state of the art performance 
in this paper we formulate human action recognition a a novel multi task sparse learning mtsl framework which aim to construct a test sample with multiple feature from a few base a possible learning the sparse representation under each feature modality is considered a a single task in mtsl since the task are generated from multiple feature associated with the same visual input they are not independent but inter related we introduce a beta process bp prior to the hierarchical mtsl model which efficiently learns a compact dictionary and infers the sparse structure shared across all the task the mtsl model enforces the robustness in coefficient estimation compared with performing each task independently besides the sparseness is achieved via the beta process formulation rather than the computationally expensive l norm penalty in term of non informative gamma hyper prior the sparsity level is totally decided by the data finally the learning problem is solved by gibbs sampling inference which estimate the full posterior on the model parameter experimental result on the kth and ucf sport datasets demonstrate the effectiveness of the proposed mtsl approach for action recognition 
a new bayesian model for image segmentation based on a gaussian mixture model is proposed the model structure allows the automatic determination of the number of segment while ensuring spatial smoothness of the final output this is achieved by defining two separate mixture weight set the first set of weight is spatially variant and incorporates an mrf edge preserving smoothing prior the second set of weight is governed by a dirichlet prior in order to prune unnecessary mixture component the model is trained using variational inference and the majorization minimization mm algorithm resulting in closed form parameter update the algorithm wa successfully evaluated in term of various segmentation index using the berkeley image data base 
the problem of multi target tracking is comprised of two distinct but tightly coupled challenge i the naturally discrete problem of data association i e assigning image observation to the appropriate target ii the naturally continuous problem of trajectory estimation i e recovering the trajectory of all target to go beyond simple greedy solution for data association recent approach often perform multi target tracking using discrete optimization this ha the disadvantage that trajectory need to be pre computed or represented discretely thus limiting accuracy in this paper we instead formulate multi target tracking a a discrete continuous optimization problem that handle each aspect in it natural domain and allows leveraging powerful method for multi model fitting data association is performed using discrete optimization with label cost yielding near optimality trajectory estimation is posed a a continuous fitting problem with a simple closed form solution which is used in turn to update the label cost we demonstrate the accuracy and robustness of our approach with state of the art performance on several standard datasets 
this paper describes modeling and numerical computation of orthogonal base which are used to describe image and motion field motion estimation from image data is then studied on subspace spanned by these base a reduced model is obtained a the galerkin projection on these subspace of a physical model based on euler and optical flow equation a data assimilation method is studied which assimilates coefficient of image data in the reduced model in order to estimate motion coefficient the approach is first quantified on synthetic data it demonstrates the interest of model reduction a a compromise between result quality and computational cost result obtained on real data are then displayed so a to illustrate the method 
we study the problem of online subspace learning in the context of sequential observation involving structured perturbation in online subspace learning the observation are an unknown mixture of two component presented to the model sequentially the main effect which pertains to the subspace and a residual error term if no additional requirement is imposed on the residual it often corresponds to noise term in the signal which were unaccounted for by the main effect to remedy this one may impose structural contiguity which ha the intended effect of leveraging the secondary term a a covariate that help the estimation of the subspace itself instead of merely serving a a noise residual we show that the corresponding online estimation procedure can be written a an approximate optimization process on a grassmannian we propose an efficient numerical solution gosus grassmannian online subspace update with structured sparsity for this problem gosus is expressive enough in modeling both homogeneous perturbation of the subspace and structural contiguity of outlier and after certain manipulation solvable via an alternating direction method of multiplier admm we evaluate the empirical performance of this algorithm on two problem of interest online background subtraction and online multiple face tracking and demonstrate that it achieves competitive performance with the state of the art in near real time 
many state of the art segmentation algorithm rely on markov or conditional random field model designed to enforce spatial and global consistency constraint this is often accomplished by introducing additional latent variable to the model which can greatly increase it complexity a a result estimating the model parameter or computing the best maximum a posteriori map assignment becomes a computationally expensive task in a series of experiment on the pascal and the msrc datasets we were unable to find evidence of a significant performance increase attributed to the introduction of such constraint on the contrary we found that similar level of performance can be achieved using a much simpler design that essentially ignores these constraint this more simple approach make use of the same local and global feature to leverage evidence from the image but instead directly bias the preference of individual pixel while our investigation doe not prove that spatial and consistency constraint are not useful in principle it point to the conclusion that they should be validated in a larger context 
we propose a reduced algebraic cost based on pairwise epipolar constraint for the iterative refinement of a multiple view d reconstruction the aim is to accelerate the intermediate step required when incrementally building a reconstruction from scratch though the proposed error is algebraic careful input data normalization make it a good approximation to the true geometric epipolar distance it minimization is significantly faster and obtains a geometric reprojection error very close to the optimum value requiring very few iteration of final standard ba refinement smart usage of a reduced measurement matrix for each pair of view allows elimination of the variable corresponding to the d point prior to nonlinear optimization subsequently reducing computation memory usage and considerably accelerating convergence this approach ha been tested in a wide range of real and synthetic problem consistently obtaining significant robustness and convergence improvement even when starting from rough initial solution it efficiency and scalability make it thus an ideal choice for incremental sfm in real time tracking application or scene modelling from large image database 
many method have been proposed to solve the image classification problem for a large number of category among them method based on tree based representation achieve good trade off between accuracy and test time efficiency while focusing on learning a tree shaped hierarchy and the corresponding set of classifier most of them use a greedy prediction algorithm for test time efficiency we argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithm in this work we propose a classifier which achieves a better trade off between efficiency and accuracy with a given tree shaped hierarchy first we convert the classification problem a finding the best path in the hierarchy and a novel branch and bound like algorithm is introduced to efficiently search for the best path second we jointly train the classifier using a novel structured svm ssvm formulation with additional bound constraint a a result our method achieves a significant and relative and improvement in accuracy at high efficiency compared to state of the art greedy tree based method on caltech sun and image net k dataset respectively finally we show that our branch and bound like algorithm naturally rank the path in the hierarchy fig so that user can further process them 
making a high dimensional e g k dim feature for face recognition seems not a good idea because it will bring difficulty on consequent training computation and storage this prevents further exploration of the use of a high dimensional feature in this paper we study the performance of a high dimensional feature we first empirically show that high dimensionality is critical to high performance a k dim feature based on a single type local binary pattern lbp descriptor can achieve significant improvement over both it low dimensional version and the state of the art we also make the high dimensional feature practical with our proposed sparse projection method named rotated sparse regression both computation and model storage can be reduced by over time without sacrificing accuracy quality 
this paper is aimed at calibrating the relative posture and position i e extrinsic parameter of a stationary camera against a d reference object which is not directly visible from the camera we capture the reference object via a mirror under three different unknown pose and then calibrate the extrinsic parameter from d appearance of reflection of the reference object in the mirror the key contribution of this paper is to present a new algorithm which return a unique solution of three p p problem from three mirrored image while each p p problem ha up to four solution and therefore a set of three p p problem ha up to solution our method can select a solution based on an orthogonality constraint which should be satisfied by all family of reflection of a single reference object in addition we propose a new scheme to compute the extrinsic parameter by solving a large system of linear equation these two point enable u to provide a unique and robust solution we demonstrate the advantage of the proposed method against a state of the art by qualitative and quantitative evaluation using synthesized and real data 
we present a method whereby an embodied agent using visual perception can efficiently create a model of a local indoor environment from it experience of moving within it our method us motion cue to compute likelihood of indoor structure hypothesis based on simple generic geometric knowledge about point line plane and motion we present a single image analysis not to attempt to identify a single accurate model but to propose a set of plausible hypothesis about the structure of the environment from an initial frame we then use data from subsequent frame to update a bayesian posterior probability distribution over the set of hypothesis the likelihood function is efficiently computable by comparing the predicted location of point feature on the environment model to their actual tracked location in the image stream our method run in real time and it avoids the need of extensive prior training and the manhattan world assumption which make it more practical and efficient for an intelligent robot to understand it surroundings compared to most previous scene understanding method experimental result on a collection of indoor video suggest that our method is capable of an unprecedented combination of accuracy and efficiency 
alpha matting refers to the problem of softly extracting the foreground from an image given a trimap specifying known foreground background and unknown pixel a straightforward way to compute the alpha value is to sample some known foreground and background color for each unknown pixel existing sampling based matting method often collect sample near the unknown pixel only they fail if good sample cannot be found nearby in this paper we propose a global sampling method that us all sample available in the image our global sample set avoids missing good sample a simple but effective cost function is defined to tackle the ambiguity in the sample selection process to handle the computational complexity introduced by the large number of sample we pose the sampling task a a correspondence problem the correspondence search is efficiently achieved by generalizing a randomized algorithm previously designed for patch matching a variety of experiment show that our global sampling method produce both visually and quantitatively high quality matting result 
approximate inference by decomposition of discrete graphical model and lagrangian relaxation ha become a key technique in computer vision the resulting dual objective function is convenient from the optimization point of view in principle due to it inherent non smoothness however it is not directly amenable to efficient convex optimization related work either weakens the relaxation by smoothing or applies variation of the inefficient projected subgradient method in either case heuristic choice of tuning parameter influence the performance and significantly depend on the specific problem at hand in this paper we introduce a novel approach based on bundle method from the field of combinatorial optimization it is directly based on the non smooth dual objective function requires no tuning parameter and showed a markedly improved efficiency uniformly over a large variety of problem instance including benchmark experiment our code will be publicly available after publication of this paper 
in this paper we propose a new method for the simultaneous segmentation and d reconstruction of interest point based articulated motion we decompose a set of point track into rigid bodied overlapping region which are associated with skeletal link while joint centre can be derived from the region of overlap this allows u to formulate the problem of d reconstruction a one of model assignment where each model corresponds to the motion and shape parameter of an articulated body part we show how this labelling can be optimised using a combination of pre existing graph cut based inference and robust structure from motion factorization technique the strength of our approach come from viewing both the decomposition into part and the d reconstruction a the optimisation of a single cost function namely the image re projection error we show result of full d shape recovery on challenging real world sequence with one or more articulated body in the presence of outlier and missing data 
informative image representation are important in achieving state of the art performance in object recognition task among feature learning algorithm that are used to develop image representation restricted boltzmann machine rbms have good expressive power and build effective representation however the difficulty of training rbms ha been a barrier to their wide use to address this difficulty we show the connection between mixture model and rbms and present an efficient training method for rbms that utilize these connection to the best of our knowledge this is the first work showing that rbms can be trained with almost no hyperparameter tuning to provide classification performance similar to or significantly better than mixture model e g gaussian mixture model along with this efficient training we evaluate the importance of convolutional training that can capture a larger spatial context with le redundancy a compared to non convolutional training overall our method achieves state of the art performance on both caltech datasets using a single type of feature 
in interactive image search a user iteratively refines his result by giving feedback on exemplar image active selection method aim to elicit useful feedback but traditional approach suffer from expensive selection criterion and cannot predict in formativeness reliably due to the imprecision of relevance feedback to address these drawback we propose to actively select pivot exemplar for which feedback in the form of a visual comparison will most reduce the system s uncertainty for example the system might ask is your target image more or le crowded than this image our approach relies on a series of binary search tree in relative attribute space together with a selection function that predicts the information gain were the user to compare his envisioned target to the next node deeper in a given attribute s tree it make interactive search more efficient than existing strategy both in term of the system s selection time a well a the user s feedback effort 
depth ordering is instrumental for understanding the d geometry of an image human are surprisingly good at depth ordering even with abstract d line drawing in this paper we propose a learning based framework for depth ordering inference boundary and junction characteristic are important clue for this task and we have developed new feature based on these attribute although each feature individually can produce reasonable depth ordering result each still ha limitation and we can achieve better performance by combining them in practice local depth ordering inference can be contradictory therefore we propose a markov random field model with term that are more global than previous work and use graph optimization to encourage a globally consistent ordering in addition to produce better object segmentation for the task of depth ordering we propose to explicitly enforce closed loop and long edge for the occlusion boundary detection we collect a new depth order dataset for this problem including more than a thousand human labeled image with various daily object and configuration the proposed algorithm show promising performance over conventional method on both synthetic and real scene 
visual landmark matching with a pre built landmark database is a popular technique for localization traditionally landmark database wa built with visual odometry system and the d information of each visual landmark is reconstructed from video due to the drift of the visual odometry system a global consistent landmark database is difficult to build and the inaccuracy of each d landmark limit the performance of landmark matching in this paper we demonstrated that with the use of precise d li dar range data we are able to build a global consistent database of high precision d visual landmark which improves the landmark matching accuracy dramatically in order to further improve the accuracy and robustness landmark matching is fused with a multi stereo based visual odometry system to estimate the camera pose in two aspect first a local visual odometry trajectory based consistency check is performed to reject some bad landmark matchings or those with large error and then a kalman filtering is used to further smooth out some landmark matching error finally a disk cache mechanism is proposed to obtain the real time performance when the size of the landmark grows for a large scale area a week long real time live marine training experiment have demonstrated the high precision and robustness of our proposed system 
the goal of natural image denoising is to estimate a clean version of a given noisy image utilizing prior knowledge on the statistic of natural image the problem ha been studied intensively with considerable progress made in recent year however it seems that image denoising algorithm are starting to converge and recent algorithm improve over previous one by only fractional db value it is thus important to understand how much more can we still improve natural image denoising algorithm and what are the inherent limit imposed by the actual statistic of the data the challenge in evaluating such limit is that constructing proper model of natural image statistic is a long standing and yet unsolved problem to overcome the absence of accurate image prior this paper take a non parametric approach and represents the distribution of natural image using a huge set of patch we then derive a simple statistical measure which provides a lower bound on the optimal bayesian minimum mean square error mmse this imposes a limit on the best possible result of denoising algorithm which utilize a fixed support around a denoised pixel and a generic natural image prior our finding suggest that for small window state of the art denoising algorithm are approaching optimality and cannot be further improved beyond db value 
this paper introduces a novel geometrical solution for the pose estimation of a stereo camera system a commonly used in robotics where the camera system balance between coverage and overlap the proposed approach considers a set of feature observed respectively in four three and two view in contrast to most algebraic solution our constraint are geometrically meaningful initially we use a four view feature to restrict our translation vector to lie on the surface of a sphere while setting orientation a a function of translation up to a single rotational degree of freedom next we use a three view feature to restrict the translation vector to lie on a circle on the sphere while completely defining orientation a a function of translation finally we use a two view feature to determine the translation vector lying on the intersection of the circle and one of the generator line of a doubly ruled quadric we show how for this final step the problem can be reduced to the intersection of two coplanar circle we also analyze the degenerate configuration of the proposed solver and perform an experimental evaluation 
we investigate the problem of reconstructing normal albedo and light of lambertian surface in uncalibrated photometric stereo under the perspective projection model our analysis is based on establishing the integrability constraint in the orthographic projection case it is well known that when such constraint is imposed a solution can be identified only up to parameter the so called generalized ba relief gbr ambiguity we show that in the perspective projection case the solution is unique we also propose a closed form solution which is simple efficient and robust we test our algorithm on synthetic data and publicly available real data our quantitative test show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection 
co segmentation is defined a jointly partitioning multiple image depicting the same or similar object into foreground and background our method consists of a multiple scale multiple image generative model which jointly estimate the foreground and background appearance distribution from several image in a non supervised manner in contrast to other co segmentation method our approach doe not require the image to have similar foreground and different background to function properly region matching is applied to exploit inter image information by establishing correspondence between the common object that appear in the scene moreover computing many to many association of region allow further application like recognition of object part across image we report result on icoseg a challenging dataset that present extreme variability in camera viewpoint illumination and object deformation and pose we also show that our method is robust against large intra class variability in the msrc database 
despite significant progress tracking is still considered to be a very challenging task recently the increasing popularity of depth sensor ha made it possible to obtain reliable depth easily this may be a game changer for tracking since depth can be used to prevent model drift and handle occlusion we also observe that current tracking algorithm are mostly evaluated on a very small number of video collected and annotated by different group the lack of a reasonable size and consistently constructed benchmark ha prevented a persuasive comparison among different algorithm in this paper we construct a unified benchmark dataset of rgbd video with high diversity propose different kind of rgbd tracking algorithm using d or d model and present a quantitative comparison of various algorithm with rgb or rgbd input we aim to lay the foundation for further research in both rgb and rgbd tracking and our benchmark is available at http tracking c princeton edu 
we present a method to identify and exploit structure that are shared across different object category by using sparse coding to learn a shared basis for the part and root template of deformable part model dpms our first contribution consists in using shift invariant sparse coding sisc to learn mid level element that can translate during coding this result in systematically better approximation than those attained using standard sparse coding to emphasize that the learned mid level structure are shiftable we call them shufflets our second contribution consists in using the resulting score to construct probabilistic upper bound to the exact template score instead of taking them at face value a is common in current work we integrate shufflets in dualtree branch and bound and cascade dpms and demonstrate that we can achieve a substantial acceleration with practically no loss in performance 
assigning a visual code to a low level image descriptor which we call code assignment is the most computationally expensive part of image classification algorithm based on the bag of visual word bow framework this paper proposes a fast computation method neighbor to neighbor ntn search for this code assignment based on the fact that image feature from an adjacent region are usually similar to each other this algorithm effectively reduces the cost of calculating the distance between a codeword and a feature vector this method can be applied not only to a hard codebook constructed by vector quantization ntn vq but also to a soft codebook a gaussian mixture model ntn gmm we evaluated this method on the pascal voc classification challenge task ntn vq reduced the assignment cost by in super vector coding and ntn gmm reduced it by in fisher vector coding without any significant degradation in classification performance 
tracking the articulated d motion of the hand ha important application for example in human computer interaction and teleoperation we present a novel method that can capture a broad range of articulated hand motion at interactive rate our hybrid approach combine in a voting scheme a discriminative part based pose retrieval method with a generative pose estimation method based on local optimization color information from a multi view rgb camera setup along with a person specific hand model are used by the generative method to find the pose that best explains the observed image in parallel our discriminative pose estimation method us fingertip detected on depth data to estimate a complete or partial pose of the hand by adopting a part based pose retrieval strategy this part based strategy help reduce the search space drastically in comparison to a global pose retrieval strategy quantitative result show that our method achieves state of the art accuracy on challenging sequence and a near real time performance of fps on a desktop computer 
we present an active learning approach to choose image annotation request among both object category label and the object attribute label the goal is to solicit those label that will best use human effort when training a multi class object recognition model in contrast to previous work in active visual category learning our approach directly exploit the dependency between human nameable visual attribute and the object they describe shifting it request in either label space accordingly we adopt a discriminative latent model that capture object attribute and attribute attribute relationship and then define a suitable entropy reduction selection criterion to predict the influence a new label might have throughout those connection on three challenging datasets we demonstrate that the method can more successfully accelerate object learning relative to both passive learning and traditional active learning approach 
in this paper we propose an ordinal hyperplane ranking algorithm called ohrank which estimate human age via facial image the design of the algorithm is based on the relative order information among the age label in a database each ordinal hyperplane separate all the facial image into two group according to the relative order and a cost sensitive property is exploited to find better hyperplanes based on the classification cost human age are inferred by aggregating a set of preference from the ordinal hyperplanes with their cost sensitivity our experimental result demonstrate that the proposed approach outperforms conventional multiclass based and regression based approach a well a recently developed ranking based age estimation approach 
this paper address the problem of image segmentation with a reference distribution recent study have shown that segmentation with global consistency measure outperforms conventional technique based on pixel wise measure however such global approach require a precise distribution to obtain the correct extraction to overcome this strict assumption we propose a new approach in which the given reference distribution play a guiding role in inferring the latent distribution and it consistent region the inference is based on an assumption that the latent distribution resembles the distribution of the consistent region but is distinct from the distribution of the complement region we state the problem a the minimization of an energy function consisting of global similarity based on the bhattacharyya distance and then implement a novel iterated distribution matching process for jointly optimizing distribution and segmentation we evaluate the proposed algorithm on the grabcut dataset and demonstrate the advantage of using our approach with various segmentation problem including interactive segmentation background subtraction and co segmentation 
due to occlusion and object non rigid deformation in the scene the obtained motion trajectory from common tracker may contain a number of missing or mi associated entry to cluster such corrupted point based trajectory into multiple motion is still a hard problem in this paper we present an approach that exploit temporal and spatial characteristic from tracked point to facilitate segmentation of incomplete and corrupted trajectory thereby obtain highly robust result against severe data missing and noise our method first us the discrete cosine transform dct base a a temporal smoothness constraint on trajectory projection to ensure the validity of resulting component to repair pathological trajectory then based on an observation that the trajectory of foreground and background in a scene may have different spatial distribution we propose a two stage clustering strategy that first performs foreground background separation then segment remaining foreground trajectory we show that with this new clustering strategy sequence with complex motion can be accurately segmented by even using a simple translational model finally a series of experiment on hopkins dataset and berkeley motion segmentation dataset show the advantage of our method over other state of the art motion segmentation algorithm in term of both effectiveness and robustness 
we propose an algorithm utilizing geodesic distance to upsample a low resolution depth image using a registered high resolution color image specifically it computes depth for each pixel in the high resolution image using geodesic path to the pixel whose depth are known from the low resolution one though this is closely related to the all pair shortest path problem which ha o n log n complexity we develop a novel approximation algorithm whose complexity grows linearly with the image size and achieve realtime performance we compare our algorithm with the state of the art on the benchmark dataset and show that our approach provides more accurate depth upsampling with fewer artifact in addition we show that the proposed algorithm is well suited for upsampling depth image using binary edge map an important sensor fusion application 
due to occlusion the estimation of the full pose of a human hand interacting with an object is much more challenging than pose recovery of a hand observed in isolation in this work we formulate an optimization problem whose solution is the dof hand pose together with the pose and model parameter of the manipulated object optimization seek for the joint hand object model that a best explains the incompleteness of observation resulting from occlusion due to hand object interaction and b is physically plausible in the sense that the hand doe not share the same physical space with the object the proposed method is the first that solves efficiently the continuous full dof joint hand object tracking problem based solely on markerless multicamera input additionally it is the first to demonstrate how hand object interaction can be exploited a a context that facilitates hand pose estimation instead of being considered a a complicating factor extensive quantitative and qualitative experiment with simulated and real world image sequence a well a a comparative evaluation with a state of the art method for pose estimation of isolated hand support the above finding 
recent progress ha shown that learning from hierarchical feature representation lead to improvement in various computer vision task motivated by the observation that human activity data contains information at various temporal resolution we present a hierarchical sequence summarization approach for action recognition that learns multiple layer of discriminative feature representation at different temporal granularity we build up a hierarchy dynamically and recursively by alternating sequence learning and sequence summarization for sequence learning we use crfs with latent variable to learn hidden spatio temporal dynamic for sequence summarization we group observation that have similar semantic meaning in the latent space for each layer we learn an abstract feature representation through non linear gate function this procedure is repeated to obtain a hierarchical sequence summary representation we develop an efficient learning method to train our model and show that it complexity grows sub linearly with the size of the hierarchy experimental result show the effectiveness of our approach achieving the best published result on the arm gesture and canal datasets 
in this paper we propose a novel framework to construct dense and high quality consistent correspondence between non rigid surface our correspondence framework exploit dual shape dna dual laplace beltrami spectral embedding to capture global characteristic of object and convert two originally different and complex shape into two similar and simple shape to facilitate the correspondence since our method avoids the computation of geodesic distance it is robust to local topology change by exploiting the excellent property of the dual domain our dual spectral framework can robustly construct laplace beltrami embeddings on highly non regular d mesh after performing initial non rigid matching in the dual laplace beltrami spectral domain we return d spatial domain and apply a shape preserving non rigid deformation to produce the final dense consistent correspondence we show that our framework is suitable for non rigid consistent correspondence and the high quality correspondence result are achieved 
when describing image human tend not to talk about the obvious but rather mention what they find interesting we argue that abnormality and deviation from typicality are among the most important component that form what is worth mentioning in this paper we introduce the abnormality detection a a recognition problem and show how to model typicality and consequently meaningful deviation from prototypical property of category our model can recognize abnormality and report the main reason of any recognized abnormality we also show that abnormality prediction can help image categorization we introduce the abnormality detection dataset and show interesting result on how to reason about abnormality 
pose variation remains to be a major challenge for real world face recognition we approach this problem through a probabilistic elastic matching method we take a part based representation by extracting local feature e g lbp or sift from densely sampled multi scale image patch by augmenting each feature with it location a gaussian mixture model gmm is trained to capture the spatial appearance distribution of all face image in the training corpus each mixture component of the gmm is confined to be a spherical gaussian to balance the influence of the appearance and the location term each gaussian component build correspondence of a pair of feature to be matched between two face face track for face verification we train an svm on the vector concatenating the difference vector of all the feature pair to decide if a pair of face face track is matched or not we further propose a joint bayesian adaptation algorithm to adapt the universally trained gmm to better model the pose variation between the target pair of face face track which consistently improves face verification accuracy our experiment show that our method outperforms the state of the art in the most restricted protocol on labeled face in the wild lfw and the youtube video face database by a significant margin 
solving the person re identification problem ha become important for understanding people s behaviour in a multicamera network of non overlapping view in this work we address the problem of re identification from a set based verification perspective more specifically we have a small set of target people on a watch list a set and we aim to verify whether a query image of a person is on this watch list this differs from the existing person re identification problem in that the probe is verified against a small set of known people but requires much higher degree of verification accuracy with very limited sampling data for each candidate in the set that is rather than recognising everybody in the scene we consider identifying a small set of target people against non target people when there is only a limited number of target training sample and a large number of unlabelled unknown non target sample available to this end we formulate a transfer learning framework for mining discriminant information from non target people data to solve the watch list set verification problem based on the proposed approach we introduce the concept of multi shot and one shot verification we also design new criterion for evaluating the performance of the proposed transfer learning method against the i lid and ethz data set 
we propose an uncalibrated photometric stereo method that work with general and unknown isotropic reflectance our method us a pixel intensity profile which is a sequence of radiance intensity recorded at a pixel across multi illuminance image we show that for general isotropic material the geodesic distance between intensity profile is linearly related to the angular difference of their surface normal and that the intensity distribution of an intensity profile conveys information about the reflectance property when the intensity profile is obtained under uniformly distributed directional lighting based on these observation we show that surface normal can be estimated up to a convex concave ambiguity a solution method based on matrix decomposition with missing data is developed for a reliable estimation quantitative and qualitative evaluation of our method are performed using both synthetic and real world scene 
this paper aim to extract salient closed contour froman image for this vision task both region segmentation cue e g color texture homogeneity and boundary detection cue e g local contrast edge continuity and contour closure play important and complementary role in this paper we show how to combine both cue in a unified framework the main focus is given to how to maintain the consistency compatibility between the region cue and the boundary cue to this end we introduce the use of winding number a well known concept in topology a a powerful mathematical device by this device the region boundary consistency is represented a aset of simple linear relationship our method is applied to the figure ground segmentation problem the experiment show clearly improved result 
in this paper we propose an automatic approach to simultaneously name face and discover scene in tv show we follow the multi modal idea of utilizing script to assist video content understanding but without using timestamp provided by script subtitle alignment a the connection instead the temporal relation between face in the video and name in the script is investigated in our approach and an global optimal video script alignment is inferred according to the character correspondence the contribution of this paper is two fold we propose a generative model named tvparser to depict the temporal character correspondence between video and script from which face name relationship can be automatically learned a a model parameter and meanwhile video scene structure can be effectively inferred a a hidden state sequence we find fast algorithm to accelerate both model parameter learning and state inference resulting in an efficient and global optimal alignment we conduct extensive comparative experiment on popular tv series and report comparable and even superior performance over existing method 
fitting statistical d and d shape model to image is necessary for a variety of task such a video editing and face recognition much progress ha been made on local fitting from an initial guess but determining a close enough initial guess is still an open problem one approach is to detect distinct landmark in the image and initalize the model fit from these correspondence this is difficult because detection of landmark based only on the local appearance is inherently ambiguous this make it necessary to use global shape information for the detection we propose a method to solve the combinatorial problem of selecting out of a large number of candidate landmark detection the configuration which is best supported by a shape model our method a opposed to previous approach always find the globally optimal configuration the algorithm can be applied to a very general class of shape model and is independent of the underlying feature point detector it theoretic optimality is shown and it is evaluated on a large face dataset 
subspace embedding is a powerful tool for extracting salient information from matrix and it ha numerous application in image processing however it applicability ha been severely limited by the computational complexity of o n n is the number of the point which usually arises in explicitly evaluating the eigenvalue and eigenvectors in this paper we propose an implicit subspace embedding method which avoids explicitly evaluating the eigenvectors also we show that this method can be seamlessly incorporated into the unsupervised multi scale image segmentation framework and the resulted algorithm ha a running time of genuine o n moreover we can explicitly determine the number of iteration for the algorithm by estimating the desired size of the subspace which also control the amount of information we want to extract for this unsupervised learning we performed extensive experiment to verify the validity and effectiveness of our method and we conclude that it only requires le than second cpu g and memory g to cut a color image and order of magnitude faster than original multi scale image segmentation with explicit spectral decomposition while maintaining the same or a better segmentation quality 
we propose a novel approach to both learning and detecting local contour based representation for mid level feature our feature called sketch token are learned using supervised mid level information in the form of hand drawn contour in image patch of human generated contour are clustered to form sketch token class and a random forest classifier is used for efficient detection in novel image we demonstrate our approach on both top down and bottom up task we show state of the art result on the top down task of contour detection while being over x faster than competing method we also achieve large improvement in detection accuracy for the bottom up task of pedestrian and object detection a measured on inria and pascal respectively these gain are due to the complementary information provided by sketch token to low level feature such a gradient histogram 
we present a very general algorithmic framework for structured prediction learning that is able to efficiently handle both pairwise and higher order discrete mrfs crfs it relies on a dual decomposition approach that ha been recently proposed for mrf optimization by properly combining this approach with a max margin method our framework manages to reduce the training of a complex high order mrf to the parallel training of a series of simple slave mrfs that are much easier to handle this lead to an extremely efficient and general learning scheme furthermore the proposed framework can yield learning algorithm of increasing accuracy since it naturally allows a hierarchy of convex relaxation to be used for mrf inference within a max margin learning approach it also offer extreme flexibility and can be easily adapted to take advantage of any special structure of a given class of mrfs experimental result demonstrate the great effectiveness of our method 
in this work we investigate how to automatically uncover the underlying group structure of a feature vector such that each group characterizes certain object specific pattern e g visual pattern or motion trajectory from one object by mining the group structure we can effectively alleviate the mutual inference of multiple object and improve the performance in various visual analysis task to this end we propose a novel auto grouped sparse representation asr method asr group semantically correlated feature element together through optimally fusing their multiple sparse representation due to the intractability of primal objective function we also propose well behaved convex relaxation and smooth approximation to guarantee obtaining a global optimal solution effectively finally we apply asr in two important visual analysis task multi label image classification and motion segmentation comprehensive experimental evaluation show that asr is able to achieve superior performance compared with the state of the art on these two task 
unlike traditional image which do not offer information for different direction of incident light a light field is defined on ray space and implicitly encodes scene geometry data in a rich structure which becomes visible on it epipolar plane image in this work we analyze regularization of light field in variational framework and show that their variational structure is induced by disparity which is in this context best understood a a vector field on epipolar plane image space we derive differential constraint on this vector field to enable consistent disparity map regularization furthermore we show how the disparity field is related to the regularization of more general vector valued function on the d ray space of the light field this way we derive an efficient variational framework with convex prior which can serve a a fundament for a large class of inverse problem on ray space 
we propose a new method for the task of fine grained visual categorization the method build a model of the base level category that can be fitted to image producing high quality foreground segmentation and mid level part localization the model can be learnt from the typical datasets available for fine grained categorization where the only annotation provided is a loose bounding box around the instance e g bird in each image both segmentation and part localization are then used to encode the image content into a highly discriminative visual signature the model is symbiotic in that part discovery localization is helped by segmentation and conversely the segmentation is helped by the detection e g part layout our model build on top of the part based object category detector of felzenszwalb et al and also on the powerful grab cut segmentation algorithm of rother et al and add a simple spatial saliency coupling between them in our evaluation the model improves the categorization accuracy over the state of the art it also improves over what can be achieved with an analogous system that run segmentation and part localization independently 
the graph laplacian operator which originated in spectral graph theory is commonly used for learning application such a spectral clustering and embedding in this paper we explore the laplacian distance a distance function related to the graph laplacian and use it for visual search we show that previous technique such a matching by tone mapping mtm are particular case of the laplacian distance generalizing the laplacian distance result in distance measure which are tolerant to various visual distortion a novel algorithm based on linear decomposition make it possible to compute these generalized distance efficiently the proposed approach is demonstrated for tone mapping invariant outlier robust and multimodal template matching 
this paper describes a method to construct seamless image mosaic of a panoramic scene containing two predominate plane a distant back plane and a ground plane that sweep out from the camera s location while this type of panorama can be stitched when the camera is carefully rotated about it optical center such ideal scene capture is hard to perform correctly existing technique use a single homography per image to perform alignment followed by seam cutting or image blending to hide inevitable alignment artifact in this paper we demonstrate how to use two homographies per image to produce a more seamless image specifically our approach blend the homographies in the alignment procedure to perform a nonlinear warping once the image are geometrically stitched they are further processed to blend seam and reduce curvilinear visual artifact due to the nonlinear warping a demonstrated in our paper our procedure is able to produce result for this type of scene where current state of the art technique fail 
single image matting technique assume high quality input image the vast majority of image on the web and in personal photo collection are encoded using jpeg compression jpeg image exhibit quantization artifact that adversely affect the performance of matting algorithm to address this situation we propose a learning based post processing method to improve the alpha matte extracted from jpeg image our approach learns a set of sparse dictionary from training example that are used to transfer detail from high quality alpha matte to alpha matte corrupted by jpeg compression three different dictionary are defined to accommodate different object structure long hair short hair and sharp boundary a back projection criterion combined within an mrf framework is used to automatically select the best dictionary to apply on the object s local boundary we demonstrate that our method can produce superior result over existing state of the art matting algorithm on a variety of input and compression level 
we propose a novel approach to automated delineation of linear structure that form complex and potentially loopy network this is in contrast to earlier approach that usually assume a tree topology for the network at the heart of our method is an integer programming formulation that allows u to find the global optimum of an objective function designed to allow cycle but penalize spurious junction and early termination we demonstrate that it outperforms state of the art technique on a wide range of datasets 
this paper introduces a probabilistic graphical model for continuous action recognition with two novel component substructure transition model and discriminative boundary model the first component encodes the sparse and global temporal transition prior between action primitive in state space model to handle the large spatial temporal variation within an action class the second component enforces the action duration constraint in a discriminative way to locate the transition boundary between action more accurately the two component are integrated into a unified graphical structure to enable effective training and inference our comprehensive experimental result on both public and in house datasets show that with the capability to incorporate additional information that had not been explicitly or efficiently modeled by previous method our proposed algorithm achieved significantly improved performance for continuous action recognition 
conventional decision forest based method for image labelling task like object segmentation make prediction for each variable pixel independently this prevents them from enforcing dependency between variable and translates into locally inconsistent pixel labellings random field model instead encourage spatial consistency of label at increased computational expense this paper present a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependency directly in the feature space the forest operate on such correlation are captured via new long range soft connectivity feature computed via generalized geodesic distance transforms our model can be thought of a a generalization of the successful semantic texton forest auto context and entangled forest model a second contribution is to show the connection between the typical conditional random field crf energy and the forest training objective this analysis yield a new objective for training decision forest that encourages more accurate structured prediction our geof model is validated quantitatively on the task of semantic image segmentation on four challenging and very diverse image datasets geof outperforms both state of the art forest model and the conventional pair wise crf 
we present a novel non rigid surface registration method that achieves high accuracy and match characteristic feature without manual intervention the key insight is to consider the entire shape a a collection of local structure that individually undergo rigid transformation to collectively deform the global structure we realize this locally rigid but globally non rigid surface registration with a newly derived dual grid free form deformation ffd framework we first represent the source and target shape with their signed distance field sdf we then superimpose a sampling grid onto a conventional ffd grid that is dual to the control point each control point is then iteratively translated by a rigid transformation that minimizes the difference between two sdfs within the corresponding sampling region the translated control point then interpolate the embedding space within the ffd grid and determine the overall deformation the experimental result clearly demonstrate that our method is capable of overcoming the difficulty of preserving and matching local feature 
integral imaging display iid is a promising technology to provide realistic d image without glass to achieve a large screen iid with a reasonable fabrication cost a potential solution is a tiled lens array iid tla iid however tla iids are subject to d image artifact when there are even slight misalignment between the lens array this work aim at compensating these artifact by calibrating the lens array pose with a camera and including them in a ray model used for rendering the d image since the lens array are transparent this task is challenging for traditional calibration method in this paper we propose a novel calibration method based on defining a set of principle observation ray that pas lens center of the tla and the camera s optical center the method is able to determine the lens array pose with only one camera at an arbitrary unknown position without using any additional marker the principle observation ray are automatically extracted using a structured light based method from a dense correspondence map between the displayed and captured pixel experiment show that lens array misalignment can be estimated with a standard deviation smaller than pixel based on this d image artifact are shown to be effectively removed in a test tla iid with challenging misalignment 
we use temporally sequenced flash illumination to capture coded exposure image of fast moving object in low light environment these coded flash image allow for accurate estimation of blur free latent image in the presence of object motion by distributing flash over a window of time we lessen eye safety concern associated with powerful all at once flash we show how our flash based coded exposure system ha better robustness to increasing object velocity than shutter based exposure coding thereby obviating the need for pre exposure velocity estimation we also show that the quality of the estimated sharp image is robust to varying level of ambient illumination this and other benefit of our coded flash system are demonstrated with real image acquired using prototype hardware 
this paper investigates the role that nonlinear camera response function crfs have on image deblurring in particular we show how nonlinear crfs can cause a spatially invariant blur to behave a a spatially varying blur this can result in noticeable ringing artifact when deconvolution is applied even with a known point spread function psf in addition we show how crfs can adversely affect psf estimation algorithm in the case of blind deconvolution to help counter these effect we introduce two method to estimate the crf directly from one or more blurred image when the psf is known or unknown while not a accurate a conventional crf estimation algorithm based on multiple exposure or calibration pattern our approach is still quite effective in improving deblurring result in situation where the crf is unknown 
we present a new pedestrian detector that improves both in speed and quality over state of the art by efficiently handling different scale and transferring computation from test time to training time detection speed is improved when processing monocular image our system provides high quality detection at fps we also propose a new method for exploiting geometric context extracted from stereo image on a single cpu gpu desktop machine we reach fps when processing street scene from rectified input to detection output 
recent year have witnessed a growing interest in understanding the semantics of point cloud in a wide variety of application however point cloud labeling remains an open problem due to the difficulty in acquiring sufficient d point label towards training effective classifier in this paper we overcome this challenge by utilizing the existing massive d semantic labeled datasets from decade long community effort such a image net and label me and a novel cross domain label propagation approach our proposed method consists of two major novel component exemplar svm based label propagation which effectively address the cross domain issue and a graphical model based contextual refinement incorporating d constraint most importantly the entire process doe not require any training data from the target scene also with good scalability towards large scale application we evaluate our approach on the well known cornell point cloud dataset achieving much greater efficiency and comparable accuracy even without any d training data our approach show further major gain in accuracy when the training data from the target scene is used outperforming state of the art approach with far better efficiency 
visual tracking in unconstrained environment is very challenging due to the existence of several source of variety such a change in appearance varying lighting condition cluttered background and frame cut a major factor causing tracking failure is the emergence of region having similar appearance a the target it is even more challenging when the target leaf the field of view fov leading the tracker to follow another similar object and not reacquire the right target when it reappears this paper present a method to address this problem by exploiting the context on the fly in two term distracters and supporter both of them are automatically explored using a sequential randomized forest an online template based appearance model and local feature distracters are region which have similar appearance a the target and consistently co occur with high confidence score the tracker must keep tracking these distracters to avoid drifting supporter on the other hand are local key point around the target with consistent co occurrence and motion correlation in a short time span they play an important role in verifying the genuine target extensive experiment on challenging real world video sequence show the tracking improvement when using this context information comparison with several state of the art approach are also provided 
both image segmentation and dense d modeling from image represent an intrinsically ill posed problem strong regularizers are therefore required to constrain the solution from being too noisy unfortunately these prior generally yield overly smooth reconstruction and or segmentation in certain region whereas they fail in other area to constrain the solution sufficiently in this paper we argue that image segmentation and dense d reconstruction contribute valuable information to each other s task a a consequence we propose a rigorous mathematical framework to formulate and solve a joint segmentation and dense reconstruction problem image segmentation provide geometric cue about which surface orientation are more likely to appear at a certain location in space whereas a dense d reconstruction yield a suitable regularization for the segmentation problem by lifting the labeling from d image to d space we show how appearance based cue and d surface orientation prior can be learned from training data and subsequently used for class specific regularization experimental result on several real data set highlight the advantage of our joint formulation 
image based classification of histology section in term of distinct component e g tumor stroma normal provides a series of index for tumor composition furthermore aggregation of these index from each whole slide image wsi in a large cohort can provide predictive model of the clinical outcome however performance of the existing technique is hindered a a result of large technical variation and biological heterogeneity that are always present in a large cohort we propose a system that automatically learns a series of basis function for representing the underlying spatial distribution using stacked predictive sparse decomposition psd the learned representation is then fed into the spatial pyramid matching framework spm with a linear svm classifier the system ha been evaluated for classification of a distinct histological component for two cohort of tumor type and b colony organization of normal and malignant cell line in d cell culture model throughput ha been increased through the utility of graphical processing unit gpu and evaluation indicates a superior performance result compared with previous research 
pedestrian detection is one of the most challenging task in computer vision and ha received a lot of attention in the last year recently some author have shown the advantage of using combination of part patch based detector in order to cope with the large variability of pose and the existence of partial occlusion in this paper we propose a pedestrian detection method that efficiently combine multiple local expert by mean of a random forest ensemble the proposed method work with rich block based representation such a hog and lbp in such a way that the same feature are reused by the multiple local expert so that no extra computational cost is needed with respect to a holistic method furthermore we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency in particular the resulting detector operates at five frame per second using a laptop machine we tested the proposed method with well known challenging datasets such a caltech eth daimler and inria the method proposed in this work consistently rank among the top performer in all the datasets being either the best method or having a small difference with the best one 
graph cut is a popular algorithm for finding the map assignment of many large scale graphical model that are common in computer vision while graph cut is powerful it doe not provide information about the marginal probability associated with the solution it find to ass uncertainty we are forced to fall back on le efficient and inexact inference algorithm such a loopy belief propagation or use le principled surrogate representation of uncertainty such a the min marginal approach of kohli torr in this work we give new justification for using min marginals to compute the uncertainty in conditional random field framing the min marginal output a exact marginals under a specially chosen generative probabilistic model we leverage this view to learn properly calibrated marginal probability a the result of straightforward maximization of the training likelihood showing that the necessary subgradients can be computed efficiently using dynamic graph cut operation we also show how this approach can be extended to compute multi label marginal distribution where again dynamic graph cut enable efficient marginal inference and maximum likelihood learning we demonstrate empirically that after proper training uncertainty based on min marginals provide better calibrated probability than baseline and that these distribution can be exploited in a decision theoretic way for improved segmentation in low level vision 
we study the map labeling problem for graphical model by optimizing a dual problem obtained by lagrangian decomposition in this paper we focus specifically on ne terov s optimal first order optimization scheme for non smooth convex program that ha been studied for a range of other problem in computer vision and machine learning in recent year we show that in order to obtain an efficiently convergent iteration this approach should be augmented with a dynamic estimation of a corresponding lip schitz constant leading to a runtime complexity of o in term of the desired precision additionally we devise a stopping criterion based on a duality gap a a sound basis for competitive comparison and show how to compute it efficiently we evaluate our result using the publicly available middlebury database and a set of computer generated graphical model that highlight specific aspect along with other state of the art method for map inference 
human saccade is a dynamic process of information pursuit based on the principle of information maximization we propose a computational model to simulate human saccadic scanpaths on natural image the model integrates three related factor a driven force to guide eye movement sequentially reference sensory response fovea periphery resolution discrepancy and visual working memory for each eye movement we compute three multi band filter response map a a coherent representation for the three factor the three filter response map are combined into multi band residual filter response map on which we compute residual perceptual information rpi at each location the rpi map is a dynamic saliency map varying along with eye movement the next fixation is selected a the location with the maximal rpi value on a natural image dataset we compare the saccadic scanpaths generated by the proposed model and several other visual saliency based model against human eye movement data experimental result demonstrate that the proposed model achieves the best prediction accuracy on both static fixation location and dynamic scanpaths 
a widely used technique to recover a d surface from photograph is patch based multi view stereo reconstruction current method are able to reproduce fine surface detail they are however limited by the sampling density and the patch size used for reconstruction we show that there is a systematic error in the reconstruction depending on the detail in the unknown surface frequency and the reconstruction resolution for this purpose we present a theoretical analysis of patch based depth reconstruction we prove that our model of the reconstruction process yield a linear system allowing u to apply the transfer or system function concept we derive the modulation transfer function theoretically and validate it experimentally on synthetic example using rendered image a well a on photograph of a d test target our analysis prof that there is a significant but predictable amplitude loss in reconstruction of fine scale detail in a first experiment on real world data we show how this can be compensated for within the limit of noise and reconstruction accuracy by an inverse transfer function in frequency space 
in recent year there ha been a great deal of progress in describing object with attribute attribute have proven useful for object recognition image search face verification image description and zero shot learning typically attribute are either binary or relative they describe either the presence or absence of a descriptive characteristic or the relative magnitude of the characteristic when comparing two exemplar however prior work fails to model the actual way in which human use these attribute in descriptive statement of image specifically it doe not address the important interaction between the binary and relative aspect of an attribute in this work we propose a spoken attribute classifier which model a more natural way of using an attribute in a description for each attribute we train a classifier which capture the specific way this attribute should be used we show that a a result of using this model we produce description about image of people that are more natural and specific than past system 
in this paper we introduce a novel framework for computing a path of diffeomorphisms between a pair of input diffeomorphisms direct computation of a geodesic path on the space of diffeomorphisms diff is difficult and it can be attributed mainly to the infinite dimensionality of diff our proposed framework to some degree bypass this difficulty using the quotient map of diff to the quotient space diff m diff m obtained by quotienting out the subgroup of volume preserving diffeomorphisms diff m this quotient space wa recently identified a the unit sphere in a hilbert space in mathematics literature a space with well known geometric property our framework leverage this recent result by computing the diffeomorphic path in two stage first we project the given diffeomorphism pair onto this sphere and then compute the geodesic path between these projected point second we lift the geodesic on the sphere back to the space of diffeomerphisms by solving a quadratic programming problem with bilinear constraint using the augmented lagrangian technique with penalty term in this way we can estimate the path of diffeomorphisms first staying in the space of diffeomorphisms and second preserving shape volume in the deformed image along the path a much a possible we have applied our framework to interpolate intermediate frame of frame sub sampled video sequence in the reported experiment our approach compare favorably with the popular large deformation diffeomorphic metric mapping framework lddmm 
we present an unsupervised shape based method for joint clustering of multiple image segmentation given two or more closely related image such a nearby frame in a video sequence or image of the same scene taken under different lighting condition our method generates a joint segmentation of the image we introduce a novel contour based representation that allows u to cast the shape based joint clustering problem a a quadratic semi assignment problem our score function is additive we use complex valued affinity to ass the quality of matching the edge element at the exterior bounding contour of cluster while ignoring the contribution of element that fall in the interior of the cluster we further combine this contour based score with region information and use a linear programming relaxation to solve for the joint cluster we evaluate our approach on the occlusion boundary data set of stein et al 
we propose a novel approach to associate object across multiple ptz camera that can be used to perform camera handoff in wide area surveillance scenario while previous approach relied on geometric appearance or correlation based information for establishing correspondence between static camera they each have well known limitation and are not extendable to wide area setting with ptz camera in our approach the slave camera only passively follows the target by loose registration with the master and bootstrap itself from it own incoming imagery thus effectively circumventing the problem faced by previous approach and avoiding the need to perform any model transfer towards this goal we also propose a novel multiple instance learning mil formulation for the problem based on the logistic softmax function of covariance based region feature within a map estimation framework we demonstrate our approach with multiple ptz camera sequence in typical outdoor surveillance setting and show a comparison with state of the art approach 
we address the challenging issue of camera localization in a partially known environment i e for which a geometric d model that cover only a part of the observed scene is available when this scene is static both known and unknown part of the environment provide constraint on the camera motion this paper proposes a nonlinear refinement process of an initial sfm reconstruction that take advantage of these two type of constraint compare to those that exploit only the model constraint i e the known part of the scene including the unknown part of the environment in the optimization process yield a faster more accurate and robust refinement it also present a much larger convergence basin this paper will demonstrate these statement on varied synthetic and real sequence for both d object tracking and outdoor localization application 
we propose a system for the automatic segmentation of novelty from the background in scenario where multiple image of the same environment are available e g obtained by wearable visual camera our method find the pixel in a query image corresponding to the underlying background environment by comparing it to reference image of the same scene this is achieved despite the fact that all the image may have different viewpoint significantly different illumination condition and contain different object car people bicycle etc occluding the background we estimate the probability of each pixel in the query image belonging to the background by computing it appearance inconsistency to the multiple reference image we then produce multiple segmentation of the query image using an iterated graph cut algorithm initializing from these estimated probability and consecutively combine these segmentation to come up with a final segmentation of the background detection of the background in turn highlight the novel pixel we demonstrate the effectiveness of our approach on a challenging outdoors data set 
we develop a completion pipeline for fragmented and damaged skull the goal of this work is to convert scanned incomplete skull fragment to a complete skull model for subsequent forensic or archeological task such a facial reconstruction the proposed assembly and completion algorithm can also be used to repair other fragmented object with inherent symmetry a two step assembly framework is proposed rough assembly by an icp like template matching algorithm integrated with the slippage feature and spin image descriptor assembly refinement by a global optimization on least square transformation error lste of break curve the assembled skull is finally repaired by a symmetry based completion algorithm experiment on repairing scanned skull fragment demonstrate the efficacy and robustness of this framework 
we present a hybrid parametric and nonparametric algorithm exemplar cut for generating class specific object segmentation hypothesis for the parametric part we train a pylon model on a hierarchical region tree a the energy function for segmentation for the nonparametric part we match the input image with each exemplar by using region to obtain a score which augments the energy function from the pylon model our method thus generates a set of highly plausible segmentation hypothesis by solving a series of exemplar augmented graph cut experimental result on the graz and pascal datasets show that the proposed algorithm achieves favorable segmentation performance against the state of the art method in term of visual quality and accuracy 
the quality of any tracking by assignment hinge on the accuracy of the foregoing target detection segmentation step in many kind of image error in this first stage are unavoidable these error then propagate to and corrupt the tracking result our main contribution is the first probabilistic graphical model that can explicitly account for overand under segmentation error even when the number of tracking target is unknown and when they may divide a in cell culture the tracking model we present implement global consistency constraint for the number of target comprised by each detection and is solved to global optimality on reasonably large d t and d t datasets in addition we empirically demonstrate the effectiveness of a post processing that allows to establish target identity even across occlusion under segmentation the usefulness and efficiency of this new tracking method is demonstrated on three different and challenging d t and d t datasets from developmental biology 
recent study have shown that hashing method are effective for high dimensional nearest neighbor search a common problem shared by many existing hashing method is that in order to achieve a satisfied performance a large number of hash table i e long code word are required to address this challenge in this paper we propose a novel approach called compressed hashing by exploring the technique of sparse coding and compressed sensing in particular we introduce a parse coding scheme based on the approximation theory of integral operator that generate sparse representation for high dimensional vector we then project s parse code into a low dimensional space by effectively exploring the restricted isometry property rip a key property in compressed sensing theory both of the theoretical analysis and the empirical study on two large data set show that the proposed approach is more effective than the state of the art hashing algorithm 
computing optical flow between any pair of internet face photo is challenging for most current state of the art flow estimation method due to difference in illumination pose and geometry we show that flow estimation can be dramatically improved by leveraging a large photo collection of the same or similar object in particular consider the case of photo of a celebrity from google image search any two such photo may have different facial expression lighting and face orientation the key idea is that instead of computing flow directly between the input pair i j we compute version of the image i j in which facial expression and pose are normalized while lighting is preserved this is achieved by iteratively projecting each photo onto an appearance subspace formed from the full photo collection the desired flow is obtained through concatenation of flow i i o j j our approach can be used with any two frame optical flow algorithm and significantly boost the performance of the algorithm by providing invariance to lighting and shape change 
cosegmentation is typically defined a the task of jointly segmenting something similar in a given set of image existing method are too generic and so far have not demonstrated competitive result for any specific task in this paper we overcome this limitation by adding two new aspect to cosegmentation the something ha to be an object and the similarity measure is learned in this way we are able to achieve excellent result on the recently introduced icoseg dataset which contains small set of image of either the same object instance or similar object of the same class the challenge of this dataset lie in the extreme change in viewpoint lighting and object deformation within each set we are able to considerably outperform several competitor to achieve this performance we borrow recent idea from object recognition the use of powerful feature extracted from a pool of candidate object like segmentation we believe that our work will be beneficial to several application area such a image retrieval 
this work attempt to considerably reduce the amount of user effort in the natural image matting problem the key observation is that the nonlocal principle introduced to denoise image can be successfully applied to the alpha matte to obtain sparsity in matte representation and therefore dramatically reduce the number of pixel a user need to manually label we show how to avoid making the user provide redundant and unnecessary input develop a method for clustering the image pixel for the user to label and a method to perform high quality matte extraction we show that this algorithm is therefore faster easier and higher quality than state of the art method 
this paper proposes to apply the nonlocal principle to general alpha matting for the simultaneous extraction of multiple image layer each layer may have disjoint a well a coherent segment typical of foreground matte in natural image matting the estimated alpha also satisfy the summation constraint a in nonlocal matting our approach doe not assume the local color line model and doe not require sophisticated sampling or learning strategy on the other hand our matting method generalizes well to any color or feature space in any dimension any number of alpha and layer at a pixel beyond two and come with an arguably simpler implementation which we have made publicly available our matting technique aptly called knn matting capitalizes on the nonlocal principle by using k nearest neighbor knn in matching nonlocal neighborhood and contributes a simple and fast algorithm that produce competitive result with sparse user markup knn matting ha a closed form solution that can leverage the preconditioned conjugate gradient method to produce an efficient implementation experimental evaluation on benchmark datasets indicates that our matting result are comparable to or of higher quality than state of the art method requiring more involved implementation in this paper we take the nonlocal principle beyond alpha estimation and extract overlapping image layer using the same laplacian framework given the alpha value our closed form solution can be elegantly generalized to solve the multilayer extraction problem we perform qualitative and quantitative comparison to demonstrate the accuracy of the extracted image layer 
while numerous algorithm have been proposed for object tracking with demonstrated success it remains a challenging problem for a tracker to handle large change in scale motion shape deformation with occlusion one of the main reason is the lack of effective image representation to account for appearance variation most tracker use high level appearance structure or low level cue for representing and matching target object in this paper we propose a tracking method from the perspective of mid level vision with structural information captured in superpixels we present a discriminative appearance model based on superpixels thereby facilitating a tracker to distinguish the target and the background with mid level cue the tracking task is then formulated by computing a target background confidence map and obtaining the best candidate by maximum a posterior estimate experimental result demonstrate that our tracker is able to handle heavy occlusion and recover from drift in conjunction with online update the proposed algorithm is shown to perform favorably against existing method for object tracking 
we present a novel stochastic framework for non blind deconvolution based on point sample obtained from random walk unlike previous method that must be tailored to specific regularization strategy the new stochastic deconvolution method allows arbitrary prior including non convex and data dependent regularizers to be introduced and tested with little effort stochastic deconvolution is straightforward to implement produce state of the art result and directly lead to a natural boundary condition for image boundary and saturated pixel 
many binary code encoding scheme based on hashing have been actively studied recently since they can provide efficient similarity search especially nearest neighbor search and compact data representation suitable for handling large scale image database in many computer vision problem existing hashing technique encode high dimensional data point by using hyperplane based hashing function in this paper we propose a novel hypersphere based hashing function spherical hashing to map more spatially coherent data point into a binary code compared to hyperplane based hashing function furthermore we propose a new binary code distance function spherical hamming distance that is tailored to our hypersphere based binary coding scheme and design an efficient iterative optimization process to achieve balanced partitioning of data point for each hash function and independence between hashing function our extensive experiment show that our spherical hashing technique significantly outperforms six state of the art hashing technique based on hyperplanes across various image benchmark of size ranging from one to million of gist descriptor the performance gain are consistent and large up to improvement the excellent result confirm the unique merit of the proposed idea in using hyperspheres to encode proximity region in high dimensional space finally our method is intuitive and easy to implement 
we propose a top down approach for understanding indoor scene such a bedroom and living room these environment typically have the manhattan world property that many surface are parallel to three principle one further the d geometry of the room and object within it can largely be approximated by non overlapping simple structure such a single block e g the room boundary thin block e g picture frame and object that are well modeled by single block e g simple bed we separately model the d geometry the imaging process camera parameter and edge likelihood to provide a generative statistical model for image data we fit this model using data driven mcmc sampling we combine reversible jump metropolis hastings sample for discrete change in the model such a the number of block and stochastic dynamic to estimate continuous parameter value in a particular parameter space that includes block position block size and camera parameter we tested our approach on two datasets using room box pixel orientation despite using only bounding box geometry and in particular not training on appearance our method achieves result approaching those of others we also introduce a new evaluation method for this domain based on ground truth camera parameter which we found to be more sensitive to the task of understanding scene geometry 
human nameable visual attribute can benefit various recognition task however existing technique restrict these property to categorical label for example a person is smiling or not a scene is dry or not and thus fail to capture more general semantic relationship we propose to model relative attribute given training data stating how object scene category relate according to different attribute we learn a ranking function per attribute the learned ranking function predict the relative strength of each property in novel image we then build a generative model over the joint space of attribute ranking output and propose a novel form of zero shot learning in which the supervisor relates the unseen object category to previously seen object via attribute for example bear are furrier than giraffe we further show how the proposed relative attribute enable richer textual description for new image which in practice are more precise for human interpretation we demonstrate the approach on datasets of face and natural scene and show it clear advantage over traditional binary attribute prediction for these new task 
many recent object retrieval system rely on local feature for describing an image the similarity between a pair of image is measured by aggregating the similarity between their corresponding local feature in this paper we present a probabilistic framework for modeling the feature to feature similarity measure we then derive a query adaptive distance which is appropriate for global similarity evaluation furthermore we propose a function to score the individual contribution into an image to image similarity within the probabilistic framework experimental result show that our method improves the retrieval accuracy significantly and consistently moreover our result compare favorably to the state of the art 
we present a modification of normalized cut to incorporate prior which can be used for constrained image segmentation compared to previous generalization of normalized cut which incorporate constraint our technique ha two advantage first we seek solution which are sufficiently correlated with prior which allows u to use noisy top down information for example from an object detector second given the spectral solution of the unconstrained problem the solution of the constrained one can be computed in small additional time which allows u to run the algorithm in an interactive mode we compare our algorithm to other graph cut based algorithm and highlight the advantage 
we present a new paradigm for tracking object in video in the presence of other similar object this branch and track paradigm is also useful in the absence of motion for the discovery of repetitive pattern in image the object of interest is the lead object and the distracters are extra the lead tracker branch out tracker for extra when they are detected and all tracker share a common set of feature sometimes extra are tracked because they are of interest in their own right in other case and perhaps more importantly tracking extra make tracking the lead nimbler and more robust both because shared feature provide a richer object model and because tracking extra account for source of confusion explicitly sharing feature also make joint tracking le expensive and coordinating tracking across lead and extra allows optimizing window position jointly rather than separately for better result the joint tracking of both lead and extra can be solved optimally by dynamic programming and branching is quickly determined by efficient subwindow search matlab experiment show near real time performance at frame per second on a single core laptop for by image 
we present an image editing tool called content aware rotation casually shot photo can appear tilted and are often corrected by rotation and cropping this trivial solution may remove desired content and hurt image integrity instead of doing rigid rotation we propose a warping method that creates the perception of rotation and avoids cropping human vision study suggest that the perception of rotation is mainly due to horizontal vertical line we design an optimization based method that preserve the rotation of horizontal vertical line maintains the completeness of the image content and reduces the warping distortion an efficient algorithm is developed to address the challenging optimization we demonstrate our content aware rotation method on a variety of practical case 
we investigate the fine grained object categorization problem of determining the breed of animal from an image to this end we introduce a new annotated dataset of pet covering different breed of cat and dog the visual problem is very challenging a these animal particularly cat are very deformable and there can be quite subtle difference between the breed we make a number of contribution first we introduce a model to classify a pet breed automatically from an image the model combine shape captured by a deformable part model detecting the pet face and appearance captured by a bag of word model that describes the pet fur fitting the model involves automatically segmenting the animal in the image second we compare two classification approach a hierarchical one in which a pet is first assigned to the cat or dog family and then to a breed and a flat one in which the breed is obtained directly we also investigate a number of animal and image orientated spatial layout these model are very good they beat all previously published result on the challenging asirra test cat v dog discrimination when applied to the task of discriminating the different breed of pet the model obtain an average accuracy of about a very encouraging result considering the difficulty of the problem 
in this paper we introduce a new approach to constrained clustering which treat the constraint a feature our method augments the original feature space with additional dimension each of which derived from a given cannot link constraint the specified cannot link pair get extreme coordinate value and the rest of the point get coordinate value that express their spatial influence from the specified constrained pair after augmenting all the new feature a standard unconstrained clustering algorithm can be performed like k mean or spectral clustering we demonstrate the efficacy of our method for active semi supervised learning applied to image segmentation and compare it to alternative method we also evaluate the performance of our method on the four most commonly evaluated datasets from the uci machine learning repository 
contour is an important cue for object recognition in this paper built upon the concept of torque in image space we propose a new contour related feature to detect and describe local contour information in image there are two component for our proposed feature one is a contour patch detector for detecting image patch with interesting information of object contour which we call the maximal minimal torque patch mtp detector the other is a contour patch descriptor for characterizing a contour patch by sampling the torque value which we call the multi scale torque mst descriptor experiment for object recognition on the caltech dataset showed that the proposed contour feature outperforms other contour related feature and is on a par with many other type of feature when combing our descriptor with the complementary sift descriptor impressive recognition result are observed 
the objective of this paper is large scale object instance retrieval given a query image a starting point of such system is feature detection and description for example using sift the focus of this paper however is towards very large scale retrieval where due to storage requirement very compact image descriptor are required and no information about the original sift descriptor can be accessed directly at run time we start from vlad the state of the art compact descriptor introduced by jegou et al for this purpose and make three novel contribution first we show that a simple change to the normalization method significantly improves retrieval performance second we show that vocabulary adaptation can substantially alleviate problem caused when image are added to the dataset after initial vocabulary learning these two method set a new state of the art over all benchmark investigated here for both mid dimensional k d to k d and small d descriptor our third contribution is a multiple spatial vlad representation multivlad that allows the retrieval and localization of object that only extend over a small part of an image again without requiring use of the original image sift descriptor 
this paper introduces a novel classification method termed alternating decision forest adfs which formulates the training of random forest explicitly a a global loss minimization problem during training the loss are minimized via keeping an adaptive weight distribution over the training sample similar to boosting method in order to keep the method a flexible and general a possible we adopt the principle of employing gradient descent in function space which allows to minimize arbitrary loss contrary to boosted tree in our method the loss minimization is an inherent part of the tree growing process thus allowing to keep the benefit of common random forest such a parallel processing we derive the new classifier and give a discussion and evaluation on standard machine learning data set furthermore we show how adfs can be easily integrated into an object detection application compared to both standard random forest and boosted tree adfs give better performance in our experiment while yielding more compact model in term of tree depth 
the task of object pose estimation ha been a challenge since the early day of computer vision to estimate the pose or viewpoint of an object people have mostly looked at object intrinsic feature such a shape or appearance surprisingly informative feature provided by other external element in the scene have so far mostly been ignored at the same time contextual cue have been shown to be of great benefit for related task such a object detection or action recognition in this paper we explore how information from other object in the scene can be exploited for pose estimation in particular we look at object configuration we show that starting from noisy object detection and pose estimate exploiting the estimated pose and location of other object in the scene can help to estimate the object pose more accurately we explore both a camera centered a well a an object centered representation for relation experiment on the challenging kitti dataset show that object configuration can indeed be used a a complementary cue to appearance based pose estimation in addition object centered relational representation can also assist object detection 
inverted indexing is a popular non exhaustive solution to large scale search an inverted file is built by a quantizer such a k mean or a tree structure it ha been found that multiple inverted file obtained by multiple independent random quantizers are able to achieve practically good recall and speed instead of computing the multiple quantizers independently we present a method that creates them jointly our method jointly optimizes all code word in all quantizers then it assigns these code word to the quantizers in experiment this method show significant improvement over various existing method that use multiple independent quantizers on the one billion set of sift vector our method is faster and more accurate than a recent state of the art inverted indexing method 
image registration and d reconstruction are fundamental computer vision and medical imaging problem they are particularly challenging when the input data are image of a deforming body obtained by a single moving camera we propose a new modelling framework the multiview d warp existing model are twofold they estimate inter image warp which are often inconsistent between the different image and do not model the underlying d structure or reconstruct just a sparse set of point in contrast our multiview d warp combine the advantage of both they have an explicit d component and a set of d deformation combined with projection to d they thus capture the dense deforming body s time varying shape and camera pose the advantage over the classical solution are numerous thanks to our feature based estimation method for the multiview d warp one can not only augment the original image but also retarget or clone the observed body s d deformation by changing the pose experimental result on simulated and real data are reported confirming the advantage of our framework over existing method 
in recent year the rise of digital image and video data available ha led to an increasing demand for image annotation in this paper we propose an interactive object annotation method that incrementally train an object detector while the user provides annotation in the design of the system we have focused on minimizing human annotation time rather than pure algorithm learning performance to this end we optimize the detector based on a realistic annotation cost model based on a user study since our system give live feedback to the user by detecting object on the fly and predicts the potential annotation cost of unseen image data can be efficiently annotated by a single user without excessive waiting time in contrast to popular tracking based method for video annotation our method is suitable for both still image and video we have evaluated our interactive annotation approach on three datasets ranging from surveillance television to cell microscopy 
when dealing with object with complex structure saliency detection confronts a critical problem namely that detection accuracy could be adversely affected if salient foreground or background in an image contains small scale high contrast pattern this issue is common in natural image and form a fundamental challenge for prior method we tackle it from a scale point of view and propose a multi layer approach to analyze saliency cue the final saliency map is produced in a hierarchical model different from varying patch size or downsizing image our scale based region handling is by finding saliency value optimally in a tree model our approach improves saliency detection on many image that cannot be handled well traditionally a new dataset is also constructed 
graph matching play a central role in solving correspondence problem in computer vision graph matching problem that incorporate pair wise constraint can be cast a a quadratic assignment problem qap unfortunately qap is np hard and many algorithm have been proposed to solve different relaxation this paper present factorized graph matching fgm a novel framework for interpreting and optimizing graph matching problem in this work we show that the affinity matrix can be factorized a a kronecker product of smaller matrix there are three main benefit of using this factorization in graph matching there is no need to compute the costly in space and time pair wise affinity matrix the factorization provides a taxonomy for graph matching and reveals the connection among several method using the factorization we derive a new approximation of the original problem that improves state of the art algorithm in graph matching experimental result in synthetic and real database illustrate the benefit of fgm the code is available at http humansensing c cmu edu fgm 
we handle a special type of motion blur considering that camera move primarily forward or backward solving this type of blur is of unique practical importance since nearly all car traffic and bike mounted camera follow out of plane translational motion we start with the study of geometric model and analyze the difficulty of existing method to deal with them we also propose a solution accounting for depth variation homographies associated with different d plane are considered and solved for in an optimization framework our method is verified on several natural image example that cannot be satisfyingly dealt with by previous method 
we propose an unsupervised domain adaptation method that exploit intrinsic compact structure of category across different domain using binary attribute our method directly optimizes for classification in the target domain the key insight is finding attribute that are discriminative across category and predictable across domain we achieve a performance that significantly exceeds the state of the art result on standard benchmark in fact in many case our method reach the same domain performance the upper bound in unsupervised domain adaptation scenario 
color description is a challenging task because of large variation in rgb value which occur due to scene accidental event such a shadow shading specularities illuminant color change and change in viewing geometry traditionally this challenge ha been addressed by capturing the variation in physic based model and deriving invariant for the undesired variation the drawback of this approach is that set of distinguishable color in the original color space are mapped to the same value in the photometric invariant space this result in a drop of discriminative power of the color description in this paper we take an information theoretic approach to color description we cluster color value together based on their discriminative power in a classification problem the clustering ha the explicit objective to minimize the drop of mutual information of the final representation we show that such a color description automatically learns a certain degree of photometric invariance we also show that a universal color representation which is based on other data set than the one at hand can obtain competing performance experiment show that the proposed descriptor outperforms existing photometric invariant furthermore we show that combined with shape description these color descriptor obtain excellent result on four challenging datasets namely pascal voc flower stanford dog and bird 
a fundamental limitation of quantization technique like the k mean clustering algorithm is the storage and run time cost associated with the large number of cluster required to keep quantization error small and model fidelity high we develop new model with a compositional parameterization of cluster center so representational capacity increase super linearly in the number of parameter this allows one to effectively quantize data using billion or trillion of center we formulate two such model orthogonal k mean and cartesian k mean they are closely related to one another to k mean to method for binary hash function optimization like itq gong and lazebnik and to product quantization for vector quantization jegou et al the model are tested on large scale ann retrieval task m gist b sift feature and on codebook learning for object recognition cifar 
traditional video compression method obtain a compact representation for image frame by computing coarse motion field defined on patch of pixel called block in order to compensate for the motion in the scene across frame this piecewise constant approximation make the motion field efficiently encodable but it introduces block artifact in the warped image frame in this paper we address the problem of estimating dense motion field that while accurately predicting one frame from a given reference frame by warping it with the field are also compressible we introduce a representation for motion field based on wavelet base and approximate the compressibility of their coefficient with a piecewise smooth surrogate function that yield an objective function similar to classical optical flow formulation we then show how to quantize and encode such coefficient with adaptive precision we demonstrate the effectiveness of our approach by comparing it performance with a state of the art wavelet video encoder experimental result on a number of standard flow and video datasets reveal that our method significantly outperforms both block based and optical flow based motion compensation algorithm 
recently hashing technique have been widely applied to solve the approximate nearest neighbor search problem in many vision application generally these hashing approach generate c bucket where c is the length of the hash code a good hashing method should satisfy the following two requirement mapping the nearby data point into the same bucket or nearby measured by the hamming distance bucket all the data point are evenly distributed among all the bucket in this paper we propose a novel algorithm named complementary projection hashing cph to find the optimal hashing function which explicitly considers the above two requirement specifically cph aim at sequentially finding a series of hyper plane hashing function which cross the sparse region of the data at the same time the data point are evenly distributed in the hyper cube generated by these hyper plane the experiment comparing with the state of the art hashing method demonstrate the effectiveness of the proposed method 
coherency sensitive hashing csh extends locality sensitivity hashing lsh and patchmatch to quickly find matching patch between two image lsh relies on hashing which map similar patch to the same bin in order to find matching patch patchmatch on the other hand relies on the observation that image are coherent to propagate good match to their neighbor in the image plane it us random patch assignment to seed the initial matching csh relies on hashing to seed the initial patch matching and on image coherence to propagate good match in addition hashing let it propagate information between patch with similar appearance i e map to the same bin this way information is propagated much faster because it can use similarity in appearance space or neighborhood in the image plane a a result csh is at least three to four time faster than patchmatch and more accurate especially in textured region where reconstruction artifact are most noticeable to the human eye we verified csh on a new large scale data set of image pair 
the advance in image acquisition technique make recording image never easier and brings a great convenience to our daily life it raise at the same time the issue of privacy protection in the photograph one particular problem addressed in this paper is about covert photograph which are taken secretly and often violate the subject willingness we study the task of automatic covert photograph classification which can be used to help inhibiting distribution of such image e g internet image filtering by carefully collecting and investigating a large covert v non covert photograph dataset we observed that there are many feature e g degree of blur that seem to be correlated with covert photograph but counter example always exist in addition we observed that image visual attribute e g photo composition play an important role in distinguishing covert photograph these observation motivate u to fuse both low level image statistic and middle level attribute feature for classifying covert image in particular we propose a solution using multiple kernel learning to combine different image feature and image attribute we evaluated thoroughly the proposed approach together with many different solution including some state of the art image classifier the effectiveness of the proposed solution is clearly demonstrated in the result furthermore a the first study to this problem we expect our study to motivate further research investigation 
object functionality refers to the quality of an object that allows human to perform some specific action it ha been shown in psychology that functionality affordance is at least a essential a appearance in object recognition by human in computer vision most previous work on functionality either assumes exactly one functionality for each object or requires detailed annotation of human pose and object in this paper we propose a weakly supervised approach to discover all possible object functionality each object functionality is represented by a specific type of human object interaction our method take any possible human object interaction into consideration and evaluates image similarity in d rather than d in order to cluster human object interaction more coherently experimental result on a dataset of people interacting with musical instrument show the effectiveness of our approach 
spatial pyramid representation spr is a widely used method for embedding both global and local spatial information into a feature and it show good performance in term of generic image recognition in spr the image is divided into a sequence of increasingly finer grid on each pyramid level feature are extracted from all of the grid cell and are concatenated to form one huge feature vector a a result expensive computational cost are required for both learning and testing moreover because the strategy for partitioning the image at each pyramid level is designed by hand there is weak theoretical evidence of the appropriate partitioning strategy for good categorization in this paper we propose discriminative spr which is a new representation that form the image feature a a weighted sum of semi local feature over all pyramid level the weight are automatically selected to maximize a discriminative power the resulting feature is compact and preserve high discriminative power even in low dimension furthermore the discriminative spr can suggest the distinctive cell and the pyramid level simultaneously by observing the optimal weight generated from the fine grid cell 
this paper introduces a new formulation for discrete image labeling task the decision tree field dtf that combine and generalizes random forest and conditional random field crf which have been widely used in computer vision in a typical crf model the unary potential are derived from sophisticated random forest or boosting based classifier however the pairwise potential are assumed to have a simple parametric form with a pre specified and fixed dependence on the image data and to be defined on the basis of a small and fixed neighborhood in contrast in dtf local interaction between multiple variable are determined by mean of decision tree evaluated on the image data allowing the interaction to be adapted to the image content this result in powerful graphical model which are able to represent complex label structure our key technical contribution is to show that the dtf model can be trained efficiently and jointly using a convex approximate likelihood function enabling u to learn over a million free model parameter we show experimentally that for application which have a rich and complex label structure our model achieves excellent result 
most conventional single image deblurring method assume that the underlying scene is static and the blur is caused by only camera shake in this paper in contrast to this restrictive assumption we address the deblurring problem of general dynamic scene which contain multiple moving object a well a camera shake in case of dynamic scene moving object and background have different blur motion so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately thus we propose a novel energy model designed with the weighted sum of multiple blur data model which estimate different motion blur and their associated pixel wise weight and resulting sharp image in this framework the local weight are determined adaptively and get high value when the corresponding data model have high data fidelity and the weight information is used for the segmentation of the motion blur non local regularization of weight are also incorporated to produce more reliable segmentation result a convex optimization based method is used for the solution of the proposed energy model experimental result demonstrate that our method outperforms conventional approach in deblurring both dynamic scene and static scene 
we present a novel method for clustering data drawn from a union of arbitrary dimensional subspace called discriminative subspace clustering disc disc solves the subspace clustering problem by using a quadratic classifier trained from unlabeled data clustering by classification we generate label by exploiting the locality of point from the same subspace and a basic affinity criterion a number of classifier are then diversely trained from different partition of the data and their result are combined together in an ensemble in order to obtain the final clustering result we have tested our method with challenging datasets and compared against state of the art method from literature our result show that disc is a very strong performer in both accuracy and robustness and also of low computational complexity 
the objective of this work is to learn sub category rather than casting this a a problem of unsupervised clustering we investigate a weakly supervised approach using both positive and negative sample of the category we make the following contribution i we introduce a new model for discriminative sub categorization which determines cluster membership for positive sample whilst simultaneously learning a max margin classifier to separate each cluster from the negative sample ii we show that this model doe not suffer from the degenerate cluster problem that afflicts several competing method e g latent svm and max margin clustering iii we show that the method is able to discover interpretable sub category in various datasets the model is evaluated experimentally over various datasets and it performance advantage over k mean and latent svm are demonstrated we also stress test the model and show it resilience in discovering sub category a the parameter are varied 
graph matching gm is a fundamental problem in computer science and it ha been successfully applied to many problem in computer vision although widely used existing gm algorithm cannot incorporate global consistence among node which is a natural constraint in computer vision problem this paper proposes deformable graph matching dgm an extension of gm for matching graph subject to global rigid and non rigid geometric constraint the key idea of this work is a new factorization of the pair wise affinity matrix this factorization decouples the affinity matrix into the local structure of each graph and the pair wise affinity edge besides the ability to incorporate global geometric transformation this factorization offer three more benefit first there is no need to compute the costly in space and time pair wise affinity matrix second it provides a unified view of many gm method and extends the standard iterative closest point algorithm third it allows to use the path following optimization algorithm that lead to improved optimization strategy and matching performance experimental result on synthetic and real database illustrate how dgm outperforms state of the art algorithm for gm the code is available at http humansensing c cmu edu fgm 
we propose a randomized ensemble algorithm to model the time varying appearance of an object for visual tracking in contrast with previous online method for updating classifier ensemble in tracking by detection the weight vector that combine weak classifier is treated a a random variable and the posterior distribution for the weight vector is estimated in a bayesian manner in essence the weight vector is treated a a distribution that reflects the confidence among the weak classifier used to construct and adapt the classifier ensemble the resulting formulation model the time varying discriminative ability among weak classifier so that the ensembled strong classifier can adapt to the varying appearance background and occlusion the formulation is tested in a tracking by detection implementation experiment on challenging benchmark video demonstrate that the proposed method can achieve result comparable to and often better than those of state of the art approach 
this paper proposes a recursive implementation of the bilateral filter unlike previous method this implementation yield an bilateral filter whose computational complexity is linear in both input size and dimensionality the proposed implementation demonstrates that the bilateral filter can be a efficient a the recent edge preserving filtering method especially for high dimensional image let the number of pixel contained in the image be n and the number of channel be d the computational complexity of the proposed implementation will be o nd it is more efficient than the state of the art bilateral filtering method that have a computational complexity of o nd linear in the image size but polynomial in dimensionality or o nlog n d linear in the dimensionality thus faster than for high dimensional filtering specifically the proposed implementation take about m to process a one megapixel color image and about m to process a megapixel grayscale image which is about faster than and faster than the experiment were conducted on a macbook air laptop computer with a ghz intel core i cpu and gb memory the memory complexity of the proposed implementation is also low a few a the image memory will be required memory for the image before and after filtering is excluded this paper also derives a new filter named gradient domain bilateral filter from the proposed recursive implementation unlike the bilateral filter it performs bilateral filtering on the gradient domain it can be used for edge preserving filtering but avoids sharp edge that are observed to cause visible artifact in some computer graphic task the proposed implementation were proved to be effective for a number of computer vision and computer graphic application including stylization tone mapping detail enhancement and stereo matching 
a huge fraction of camera used nowadays is based on cmos sensor with a rolling shutter that expose the image line by line for dynamic scene camera this introduces undesired effect like stretch shear and wobble it ha been shown earlier that rotational shake induced rolling shutter effect in hand held cell phone capture can be compensated based on an estimate of the camera rotation in contrast we analyse the case of significant camera motion e g where a bypassing street level capture vehicle us a rolling shutter camera in a d reconstruction framework the introduced error is depth dependent and cannot be compensated based on camera motion rotation alone invalidating also rectification for stereo camera system on top significant lens distortion a often present in wide angle camera intertwines with rolling shutter effect a it change the time at which a certain d point is seen we show that naive d reconstruction assuming global shutter will deliver biased geometry already for very mild assumption on vehicle speed and resolution we then develop rolling shutter dense multiview stereo algorithm that solve for time of exposure and depth at the same time even in the presence of lens distortion and perform an evaluation on ground truth laser scan model a well a on real street level data 
we address the problem of labeling individual datapoints given some knowledge about small subset or group of them the knowledge we have for a group is the likelihood value for each group member to satisfy a certain model this problem is equivalent to hypergraph labeling problem where each datapoint corresponds to a node and the each subset correspond to a hyperedge with likelihood value a it weight we propose a novel method to model the label dependence using an undirected graphical model and reduce the problem of hypergraph labeling into an inference problem this paper describes the structure and necessary component of such model and proposes useful cost function we discus the behavior of proposed algorithm with different form of the cost function identify suitable algorithm for inference and analyze required property when it is theoretically guaranteed to have exact solution example of several real world problem are shown a application of the proposed method 
this paper address the problem of semantic segmentation of d point cloud we extend the inference machine framework of ross et al by adding spatial factor that model mid range and long range dependency inherent in the data the new model is able to account for semantic spatial context during training our method automatically isolates and retains factor modelling spatial dependency between variable that are relevant for achieving higher prediction accuracy we evaluate the proposed method by using it to predict category semantic segmentation on set of stitched kinect scan experimental result show that the spatial dependency learned by our method significantly improve the accuracy of segmentation they also show that our method outperforms the existing segmentation technique of koppula et al 
many technique in computer vision machine learning and statistic rely on the fact that a signal of interest admits a sparse representation over some dictionary dictionary are either available analytically or can be learned from a suitable training set while analytic dictionary permit to capture the global structure of a signal and allow a fast implementation learned dictionary often perform better in application a they are more adapted to the considered class of signal in imagery unfortunately the numerical burden for i learning a dictionary and for ii employing the dictionary for reconstruction task only allows to deal with relatively small image patch that only capture local image information the approach presented in this paper aim at overcoming these drawback by allowing a separable structure on the dictionary throughout the learning process on the one hand this permit larger patch size for the learning phase on the other hand the dictionary is applied efficiently in reconstruction task the learning procedure is based on optimizing over a product of sphere which update the dictionary a a whole thus enforces basic dictionary property such a mutual coherence explicitly during the learning procedure in the special case where no separable structure is enforced our method competes with state of the art dictionary learning method like k svd 
we consider the problem of quantizing data generated from disparate source e g subject performing action with different style movie with particular genre bias various condition in which image of object are taken etc these are scenario where unsupervised clustering produce inadequate codebooks because algorithm like k mean tend to cluster sample based on data bias e g cluster subject rather than cluster similar sample across source e g cluster action we propose a new quantization technique source constrained clustering scc which extends the k mean algorithm by enforcing cluster to group sample from multiple source we evaluate the method in the context of activity recognition from video in an unconstrained environment experiment on several task and feature show that using source information improves classification performance 
the goal of face hallucination is to generate high resolution image with fidelity from low resolution one in contrast to existing method based on patch similarity or holistic constraint in the image space we propose to exploit local image structure for face hallucination each face image is represented in term of facial component contour and smooth region the image structure is maintained via matching gradient in the reconstructed high resolution output for facial component we align input image to generate accurate exemplar and transfer the high frequency detail for preserving structural consistency for contour we learn statistical prior to generate salient structure in the high resolution image a patch matching method is utilized on the smooth region where the image gradient are preserved experimental result demonstrate that the proposed algorithm generates hallucinated face image with favorable quality and adaptability 
we describe a method for learning steerable deformable part model our model exploit the fact that part template can be written a linear filter bank we demonstrate that one can enforce steerability and separability during learning by applying rank constraint these constraint are enforced with a coordinate descent learning algorithm where each step can be solved with an off the shelf structured svm solver the resulting model are order of magnitude smaller than their counterpart greatly simplifying learning and reducing run time computation limiting the degree of freedom also reduces overfitting which is useful for learning large part vocabulary from limited training data we learn steerable variant of several state of the art model for object detection human pose estimation and facial landmark estimation our steerable model are smaller faster and often improve performance 
we propose a method for simultaneous shape constrained segmentation and parameter recovery the parameter can describe anything from d shape to d pose and we place no restriction on the topology of the shape i e they can have hole or be made of multiple part we use shared gaussian process latent variable model to learn multimodal shape parameter space these allow non linear embeddings of the high dimensional shape and parameter space in low dimensional space in a fully probabilistic manner we propose a method for exploring the multimodality in the joint space in an efficient manner by learning a mapping from the latent space to a space that encodes the similarity between shape we further extend the sgp lvm to a model that make use of a hierarchy of embeddings and show that this yield faster convergence and greater accuracy over the standard non hierarchical embedding shape are represented implicitly using level set and inference is made tractable by compressing the level set embedding function with discrete cosine transforms we show state of the art result in various field ranging from pose recovery to gaze tracking and to monocular d reconstruction 
this paper introduces a schematic representation for architectural scene together with robust algorithm for reconstruction from sparse d point cloud data the schematic model architecture a a network of transport curve approximating a floorplan with associated profile curve together comprising an interconnected set of swept surface the representation is extremely concise composed of a handful of planar curve and easily interpretable by human the approach also provides a principled mechanism for interpolating a dense surface and enables filling in hole in the data by mean of a pipeline that employ a global optimization over all parameter by incorporating a displacement map on top of the schematic surface it is possible to recover fine detail experiment show the ability to reconstruct extremely clean and simple model from sparse structure from motion point cloud of complex architectural scene 
in this paper we address the two class classification problem within the tensor based framework by formulating the support tucker machine stums more precisely in the proposed stums the weight parameter are regarded to be a tensor calculated according to the tucker tensor decomposition a the multiplication of a core tensor with a set of matrix one along each mode we further extend the proposed stums to the s s wstums in order to fully exploit the information offered by the total or the within class covariance matrix and whiten the data thus providing in variance to affine transformation in the feature space we formulate the two above mentioned problem in such a way that they can be solved in an iterative manner where at each iteration the parameter corresponding to the projection along a single tensor mode are estimated by solving a typical support vector machine type problem the superiority of the proposed method in term of classification accuracy is illustrated on the problem of gait and action recognition 
super pixel algorithm represent a very useful and increasingly popular preprocessing step for a wide range of computer vision application a they offer the potential to boost efficiency and effectiveness in this regard this paper present a highly competitive approach for temporally consistent super pixel for video content the approach is based on energy minimizing clustering utilizing a novel hybrid clustering strategy for a multi dimensional feature space working in a global color subspace and local spatial subspace moreover a new contour evolution based strategy is introduced to ensure spatial coherency of the generated super pixel for a thorough evaluation the proposed approach is compared to state of the art super voxel algorithm using established benchmark and show a superior performance 
we present a method for computing ambient occlusion ao for a stack of image of a scene from a fixed viewpoint ambient occlusion a concept common in computer graphic characterizes the local visibility at a point it approximates how much light can reach that point from different direction without getting blocked by other geometry while ao ha received surprisingly little attention in vision we show that it can be approximated using simple per pixel statistic over image stack based on a simplified image formation model we use our derived ao measure to compute reflectance and illumination for object without relying on additional smoothness prior and demonstrate state of the art performance on the mit intrinsic image benchmark we also demonstrate our method on several synthetic and real scene including d printed object with known ground truth geometry 
in this paper we address the problem of recovering both the topology and the geometry of a deformable shape using temporal mesh sequence the interest arises in multi camera application when unknown natural dynamic scene are captured while several approach allow recovery of shape model from static scene few consider dynamic scene with evolving topology and without prior knowledge in this nonetheless generic situation a single time observation is not necessarily sufficient to infer the correct topology of the observed shape and evidence must be accumulated over time in order to learn the topology and to enable temporally consistent modelling this appears to be a new problem for which no formal solution exists we propose a principled approach based on the assumption that the observed object have a fixed topology under this assumption we can progressively learn the topology meanwhile capturing the deformation of the dynamic scene the approach ha been successfully experimented on several standard d datasets 
a new paradigm for multivariate regression is proposed principal regression analysis pra it entail learning a low dimensional subspace over sample specific regressors for a given input the model predicts a subspace thought to contain the corresponding response using this subspace a a prior the search space is considerably more constrained an efficient local optimisation strategy is proposed for learning and a practical choice for it initialisation suggested the utility of pra is demonstrated on the task of non rigid face and car alignment using challenging in the wild datasets where substantial performance improvement are observed over alignment with a conventional prior 
in this paper we propose a new family of binary local feature descriptor called nested shape descriptor these descriptor are constructed by pooling oriented gradient over a large geometric structure called the hawaiian earring which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance this distance function is unique to the nested descriptor and provides robustness to outlier from order statistic in this paper we define the nested shape descriptor family and introduce a specific member called the seed of life descriptor we perform a trade study to determine optimal descriptor parameter for the task of image matching finally we evaluate performance compared to state of the art local feature descriptor on the vgg affine image matching benchmark showing significant performance gain our descriptor is the first binary descriptor to outperform sift on this benchmark 
in this paper we introduce a new problem which we call object co detection given a set of image with object observed from two or multiple image the goal of co detection is to detect the object establish the identity of individual object instance a well a estimate the viewpoint transformation of corresponding object instance in designing a co detector we follow the intuition that an object ha consistent appearance when observed from the same or different viewpoint by modeling an object using state of the art part based representation such a we measure appearance consistency between object by comparing part appearance and geometry across image this allows to effectively account for object self occlusion and viewpoint transformation extensive experimental evaluation indicates that our co detector obtains more accurate detection result than if object were to be detected from each image individually moreover we demonstrate the relevance of our co detection scheme to other recognition problem such a single instance object recognition wide baseline matching and image query 
the paper proposes a vision based online mapping of large scale environment our novel approach us a hybrid representation of a fully metric euclidean environment map and a topological map this novel hybrid representation facilitates our scalable online hierarchical bundle adjustment approach the proposed method achieves scalability by solving the local registration through embedding neighboring keyframes and landmark into a euclidean space the global adjustment is performed on a segmentation of the keyframes and posed a the iterative optimization of the arrangement of keyframes in each segment and the arrangement of rigidly moving segment the iterative global adjustment is performed concurrently with the local registration of the keyframes in a local map thus the map is always locally metric around the current location and likely to be globally consistent loop closure are handled very efficiently benefiting from the topological nature of the map and overcoming the loss of the metric map property a previous approach the effectiveness of the proposed method is demonstrated in real time on various challenging video sequence 
recent local stereo matching algorithm based on an adaptive weight strategy achieve accuracy similar to global approach one of the major problem of these algorithm is that they are computationally expensive and this complexity increase proportionally to the window size this paper proposes a novel cost aggregation step with complexity independent of the window size i e o that outperforms state of the art o method moreover compared to other o approach our method doe not rely on integral histogram enabling aggregation using colour image instead of grayscale one finally to improve the result of the proposed algorithm a disparity refinement pipeline is also proposed the overall algorithm produce result comparable to those of state of the art stereo matching algorithm 
learning filter to produce sparse image representation in term of over complete dictionary ha emerged a a powerful way to create image feature for many different purpose unfortunately these filter are usually both numerous and non separable making their use computationally expensive in this paper we show that such filter can be computed a linear combination of a smaller number of separable one thus greatly reducing the computational complexity at no cost in term of performance this make filter learning approach practical even for large image or d volume and we show that we significantly outperform state of the art method on the linear structure extraction task in term of both accuracy and speed moreover our approach is general and can be used on generic filter bank to reduce the complexity of the convolution 
we present the design and implementation of new inexact newton type bundle adjustment algorithm that exploit hardware parallelism for efficiently solving large scale d scene reconstruction problem we explore the use of multicore cpu a well a multicore gpus for this purpose we show that overcoming the severe memory and bandwidth limitation of current generation gpus not only lead to more space efficient algorithm but also to surprising saving in runtime our cpu based system is up to ten time and our gpu based system is up to thirty time faster than the current state of the art method while maintaining comparable convergence behavior the code and additional result are available at http grail c washington edu project mcba 
bottom up fully unsupervised segmentation remains a daunting challenge for computer vision in the cosegmentation context on the other hand the availability of multiple image assumed to contain instance of the same object class provides a weak form of supervision that can be exploited by discriminative approach unfortunately most existing algorithm are limited to a very small number of image and or object class typically two of each this paper proposes a novel energy minimization approach to cosegmentation that can handle multiple class and a significantly larger number of image the proposed cost function combine spectraland discriminative clustering term and it admits a probabilistic interpretation it is optimized using an efficient em method initialized using a convex quadratic approximation of the energy comparative experiment show that the proposed approach match or improves the state of the art on several standard datasets 
we consider the problem of shape recovery for real world scene where a variety of global illumination interreflection subsurface scattering etc and illumination defocus effect are present these effect introduce systematic and often significant error in the recovered shape we introduce a structured light technique called micro phase shifting which overcomes these problem the key idea is to project sinusoidal pattern with frequency limited to a narrow high frequency band these pattern produce a set of image over which global illumination and defocus effect remain constant for each point in the scene this enables high quality reconstruction of scene which have traditionally been considered hard using only a small number of image we also derive theoretical lower bound on the number of input image needed for phase shifting and show that micro p achieves the bound 
we present a method to analyze daily activity such a meal preparation using video from an egocentric camera our method performs inference about activity action hand and object daily activity are a challenging domain for activity recognition which are well suited to an egocentric approach in contrast to previous activity recognition method our approach doe not require pre trained detector for object and hand instead we demonstrate the ability to learn a hierarchical model of an activity by exploiting the consistent appearance of object hand and action that result from the egocentric context we show that joint modeling of activity action and object lead to superior performance in comparison to the case where they are considered independently we introduce a novel representation of action based on object hand interaction and experimentally demonstrate the superior performance of our representation in comparison to standard activity representation such a bag of word 
with the explosion in the usage of mobile device and other smart electronics embedded device are becoming ubiquitous most such embedded architecture utilize fixed point rather than floating point computation to meet power heat and speed requirement leading to the need for integer based processing algorithm operation involving gaussian kernel are common to such algorithm but the standard method of constructing such kernel result in approximation and lack a property that enables efficient bitwise shift operation to overcome these limitation we present how to precisely combine the power of integer arithmetic and bitwise shift with intrinsically real valued gaussian kernel we prove mathematically that there exist a set of what we call magic sigma for which the integer kernel exactly represent the gaussian function whose value are all power of two and we discovered that the maximum sigma that lead to such property is about we also designed a simple and precise algorithm for designing kernel composed exclusively of integer given any arbitrary sigma and show how this can be exploited for gaussian filter design considering the ubiquity of gaussian filtering and the need for integer computation for increasing number of embedded device this is an important result for both theoretical and practical purpose 
naive bayes nearest neighbor nbnn ha recently been proposed a a powerful non parametric approach for object classification that manages to achieve remarkably good result thanks to the avoidance of a vector quantization step and the use of image to class comparison yielding good generalization in this paper we introduce a kernelized version of nbnn this way we can learn the classifier in a discriminative setting moreover it then becomes straightforward to combine it with other kernel in particular we show that our nbnn kernel is complementary to standard bag of feature based kernel focussing on local generalization a opposed to global image composition by combining them we achieve state of the art result on caltech and scene datasets a a side contribution we also investigate how to speed up the nbnn computation 
a novel local image descriptor is proposed in this paper which combine intensity order and gradient distribution in multiple support region the novelty lie in three aspect the gradient is calculated in a rotation invariant way in a given support region the rotation invariant gradient are adaptively pooled spatially based on intensity order in order to encode spatial information multiple support region are used for constructing descriptor which further improves it discriminative ability therefore the proposed descriptor encodes not only gradient information but also information about relative relationship of intensity a well a spatial information in addition it is truly rotation invariant in theory without the need of computing a dominant orientation which is a major error source of most existing method such a sift result on the standard oxford dataset and d object have shown a significant improvement over the state of the art method under various image transformation 
although tracing linear structure in d image and d image stack ha received much attention over the year full automation remains elusive in this paper we formulate the delineation problem a one of solving a quadratic mixed integer program q mip in a graph of potential path which can be done optimally up to a very small tolerance we further propose a novel approach to weighting these path which result in a q mip solution that accurately match the ground truth we demonstrate that our approach outperforms a state of the art technique based on the k minimum spanning tree formulation on a d dataset of aerial image and a d dataset of confocal microscopy stack 
we propose a novel riemannian framework for comparing signal and image in a manner that is invariant to their level of blur this framework us a log fourier representation of signal image in which the set of all possible gaussian blur of a signal i e it orbit under semigroup action of gaussian blur function is a straight line using a set of riemannian metric under which the group action are by isometry the orbit are compared via distance between orbit we demonstrate this framework using a number of experimental result involving d signal and d image 
acquiring transparent refractive object is challenging a these kind of object can only be observed by analyzing the distortion of reference background pattern we present a new single image approach to reconstructing thin transparent surface such a thin solid or surface of fluid our method is based on observing the distortion of light field background illumination light field probe have the potential to encode up to four dimension in varying color and intensity spatial and angular variation on the probe surface commonly employed reference pattern are only two dimensional by coding either position or angle on the probe we show that the additional information can be used to reconstruct refractive surface normal and a sparse set of control point from a single photograph 
in this paper we address the challenging problem of detecting pedestrian who appear in group and have interaction a new approach is proposed for single pedestrian detection aided by multi pedestrian detection a mixture model of multi pedestrian detector is designed to capture the unique visual cue which are formed by nearby multiple pedestrian but cannot be captured by single pedestrian detector a probabilistic framework is proposed to model the relationship between the configuration estimated by single and multi pedestrian detector and to refine the single pedestrian detection result with multi pedestrian detection it can integrate with any single pedestrian detector without significantly increasing the computation load state of the art single pedestrian detection approach are investigated on three widely used public datasets caltech tud brussels and eth experimental result show that our framework significantly improves all these approach the average improvement is on the caltech test dataset on the tud brussels dataset and on the eth dataset in term of average miss rate the lowest average miss rate is reduced from to on the caltech test dataset from to on the tud brussels dataset and from to on the eth dataset 
this paper proposes contour based feature for articulated pose estimation most of recent method are designed using tree structured model with appearance evaluation only within the region of each part while these model allow u to speed up global optimization in localizing the whole part useful appearance cue between neighboring part are missing our work focus on how to evaluate part connectivity using contour cue unlike previous work we locally evaluate part connectivity only along the orientation between neighboring part within where they overlap this adaptive localization of the feature is required for suppressing bad effect due to nuisance edge such a those of background clutter and clothing texture a well a for reducing computational cost discriminative training of the contour feature improves estimation accuracy more experimental result verify the effectiveness of our contour based feature 
point set are the standard output of many d scanning system and depth camera presenting the set of point a is might hide the prominent feature of the object from which the point are sampled our goal is to reduce the number of point in a point set for improving the visual comprehension from a given viewpoint this is done by controlling the density of the reduced point set so a to create bright region low density and dark region high density producing an effect of shading this data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint in addition we introduce a new dual problem for determining visibility of a point from infinity and show how a limitation of it solution can be leveraged in a similar way 
despite the continuous advance in local stereo matching for year most effort are on developing robust cost computation and aggregation method little attention ha been seriously paid to the disparity refinement in this work we study weighted median filtering for disparity refinement we discover that with this refinement even the simple box filter aggregation achieves comparable accuracy with various sophisticated aggregation method with the same refinement this is due to the nice weighted median filtering property of removing outlier error while respecting edge structure this reveals that the previously overlooked refinement can be at least a crucial a aggregation we also develop the first constant time algorithm for the previously time consuming weighted median filter this make the simple combination box aggregation weighted median an attractive solution in practice for both speed and accuracy a a byproduct the fast weighted median filtering unleashes it potential in other application that were hampered by high complexity we show it superiority in various application such a depth up sampling clip art jpeg artifact removal and image stylization 
we present a framework to super resolve planar region found in urban scene and other man made environment by taking into account their d geometry such region have highly structured straight edge but this prior is challenging to exploit due to deformation induced by the projection onto the imaging plane our method factor out such deformation by using recently developed tool based on convex optimization to learn a transform that map the image to a domain where it gradient ha a simple group sparse structure this allows to obtain a novel convex regularizer that enforces global consistency constraint between the edge of the image computational experiment with real image show that this data driven approach to the design of regularizers promoting transform invariant group sparsity is very effective at high super resolution factor we view our approach a complementary to most recent super resolution method which tend to focus on hallucinating high frequency texture 
recently the sparse representation or coding based classification src ha been successfully used in face recognition in src the testing image is represented a a sparse linear combination of the training sample and the representation fidelity is measured by the l norm or l norm of coding residual such a sparse coding model actually assumes that the coding residual follows gaussian or laplacian distribution which may not be accurate enough to describe the coding error in practice in this paper we propose a new scheme namely the robust sparse coding rsc by modeling the sparse coding a a sparsity constrained robust regression problem the rsc seek for the mle maximum likelihood estimation solution of the sparse coding problem and it is much more robust to outlier e g occlusion corruption etc than src an efficient iteratively reweighted sparse coding algorithm is proposed to solve the rsc model extensive experiment on representative face database demonstrate that the rsc scheme is much more effective than state of the art method in dealing with face occlusion corruption lighting and expression change etc 
one of the key challenge in search based image annotation model is to define an appropriate similarity measure between image many kernel distance metric learning kml algorithm have been developed in order to capture the nonlinear relationship between visual feature and semantics of the image one fundamental limitation in applying kml to image annotation is that it requires converting image annotation into binary constraint leading to a significant information loss in addition most kml algorithm suffer from high computational cost due to the requirement that the learned matrix ha to be positive semi definitive psd in this paper we propose a robust kernel metric learning rkml algorithm based on the regression technique that is able to directly utilize image annotation the proposed method is also computationally more efficient because psd property is automatically ensured by regression we provide the theoretical guarantee for the proposed algorithm and verify it efficiency and effectiveness for image annotation by comparing it to state of the art approach for both distance metric learning and image annotation 
single sample face recognition is one of the most challenging problem in face recognition we propose a novel face recognition algorithm to address this problem based on a sparse representation based classification src framework the new algorithm is robust to image misalignment and pixel corruption and is able to reduce required training image to one sample per class to compensate the missing illumination information typically provided by multiple training image a sparse illumination transfer sit technique is introduced the sit algorithm seek additional illumination example of face image from one or more additional subject class and form an illumination dictionary by enforcing a sparse representation of the query image the method can recover and transfer the pose and illumination information from the alignment stage to the recognition stage our extensive experiment have demonstrated that the new algorithm significantly outperform the existing algorithm in the single sample regime and with le restriction in particular the face alignment accuracy is comparable to that of the well known deformable src algorithm using multiple training image and the face recognition accuracy exceeds those of the src and extended src algorithm using hand labeled alignment initialization 
temporal misalignment and duration variation in video action largely influence the performance of action recognition but it is very difficult to specify effective temporal alignment on action sequence to address this challenge this paper proposes a novel discriminative learning based temporal alignment method called maximum margin temporal warping mmtw to align two action sequence and measure their matching score based on the latent structure svm formulation the proposed mmtw method is able to learn a phantom action template to represent an action class for maximum discrimination against other class the recognition of this action class is based on the associated learned alignment of the input action extensive experiment on five benchmark datasets have demonstrated that this mmtw model is able to significantly promote the accuracy and robustness of action recognition under temporal misalignment and variation 
nowadays numerous social image have been emerging on the web how to precisely label these image is critical to image retrieval however traditional image level tagging method may become le effective because global image matching approach can hardly cope with the diversity and arbitrariness of web image content this raise an urgent need for the fine grained tagging scheme in this work we study how to establish mapping between tag and image region i e localize tag to image region so a to better depict and index the content of image we propose the spatial group sparse coding sgsc by extending the robust encoding ability of group sparse coding with spatial correlation among training region we present spatial correlation in a two dimensional image space and design group specific spatial kernel to produce a more interpretable regularizer further we propose a joint version of the sgsc model which is able to simultaneously encode a group of intrinsically related region within a test image an effective algorithm is developed to optimize the objective function of the joint sgsc the tag localization task is conducted by propagating tag from sparsely selected group of region to the target region according to the reconstruction coefficient extensive experiment on three public image datasets illustrate that our proposed model achieve great performance improvement over the state of the art method in the tag localization task 
image in general are captured under a diverse set of condition an image of the same object can be captured with varied pose illumination scale background and probably different camera parameter the task of image classification then lie in forming feature of the input image in a representational space where classifier can be better supported in spite of the above variation existing method have mostly focused on obtaining feature which are invariant to scale and translation and thus they generally suffer from performance degradation on datasets which consist of image with varied pose or camera orientation in this paper we present a new framework for image classification which is built upon a novel way of feature extraction that generates largely affine invariant feature called affine sparse code this is achieved through learning a compact dictionary of feature from affine transformed input image analysis and experiment indicate that this novel feature is highly discriminative in addition to being largely affine invariant a classifier using adaboost is then designed using the affine sparse code a the input extensive experiment with standard database demonstrate that the proposed approach can obtain the state of the art result outperforming existing leading approach in the literature 
traditionally researcher tend to exclude fluorescence from color appearance algorithm in computer vision and image processing because of it complexity in reality fluorescence is a very common phenomenon observed in many object from gem and coral to different kind of writing paper and to our clothes in this paper we provide detailed theory of fluorescence phenomenon in particular we show that the color appearance of fluorescence is unaffected by illumination in which it differs from ordinary reflectance moreover we show that the color appearance of object with reflective and fluorescent component can be represented a a linear combination of the two component a linear model allows u to separate the two component using image taken under two unknown illuminant using independent component analysis ica the effectiveness of the proposed method is demonstrated using digital image of various fluorescent object 
estimating geographic location from image is a challenging problem that is receiving recent attention in contrast to many existing method that primarily model discriminative information corresponding to different location we propose joint learning of information that image across location share and vary upon starting with generative and discriminative subspace pertaining to domain which are obtained by a hierarchical grouping of image from adjacent location we present a top down approach that first model cross domain information transfer by utilizing the geometry of these subspace and then encodes the model result onto individual image to infer their location we report competitive result for location recognition and clustering on two public datasets im gps and san francisco and empirically validate the utility of various design choice involved in the approach 
we present a weakly supervised visual data mining approach that discovers connection between recurring mid level visual element in historic temporal and geographic spatial image collection and attempt to capture the underlying visual style in contrast to existing discovery method that mine for pattern that remain visually consistent throughout the dataset our goal is to discover visual element whose appearance change due to change in time or location i e exhibit consistent stylistic variation across the label space date or geo location to discover these element we first identify group of patch that are style sensitive we then incrementally build correspondence to find the same element across the entire dataset finally we train style aware regressors that model each element s range of stylistic difference we apply our approach to date and geo location prediction and show substantial improvement over several baseline that do not model visual style we also demonstrate the method s effectiveness on the related task of fine grained classification 
we present a riemannian framework for analyzing shape of planar contour in which metric and other analysis are invariant to affine transformation and re parameterizations of contour current method that are affine invariant are restricted to point set and do not handle full curve while method that analyze parameterized curve are restricted to equivalence under similarity transformation rigid motion and scale we construct a pre shape manifold of standardized curve curve whose centroid is at the origin are of unit length and their x and y coordinate are uncorrelated and develop a path straightening technique for computing geodesic on this nonlinear manifold under the elastic riemannian metric the removal of the rotation and the re parameterization group result in a quotient space termed affine elastic shape space and the resulting geodesic path exhibit an improved matching of feature across curve these geodesic are used for shape comparison retrieval and statistical modeling of given curve experimental result using both simulated and real data and an application involving poseinvariant activity recognition demonstrate the success of this framework 
we consider the problem of automatically estimating the d pose of human from image taken from multiple calibrated view we show that it is possible and tractable to extend the pictorial structure framework popular for d pose estimation to d we discus how to use this framework to impose view skeleton joint angle and intersection constraint in d the d pictorial structure are evaluated on multiple view data from a professional football game the evaluation is focused on computational tractability but we also demonstrate how a simple d part detector can be plugged into the framework 
recent work in structure from motion sfm ha successfully built d model from large unstructured collection of image downloaded from the internet most approach use incremental algorithm that solve progressively larger bundle adjustment problem these incremental technique scale poorly a the number of image grows and can drift or fall into bad local minimum we present an alternative formulation for sfm based on finding a coarse initial solution using a hybrid discrete continuous optimization and then improving that solution using bundle adjustment the initial optimization step us a discrete markov random field mrf formulation coupled with a continuous levenberg marquardt refinement the formulation naturally incorporates various source of information about both the camera and the point including noisy geotags and vanishing point estimate we test our method on several large scale photo collection including one with measured camera position and show that it can produce model that are similar to or better than those produced with incremental bundle adjustment but more robustly and in a fraction of the time 
in deflectometry the shape of mirror object is recovered from distorted image of a calibrated scene while remarkably high accuracy are achievable state of the art method suffer from two distinct weakness first for mainly constructive reason these can only capture a few square centimeter of surface area at once second reconstruction are ambiguous i e infinitely many surface lead to the same visual impression we resolve both of these problem by introducing the first multiview specular stereo approach which jointly evaluates a series of overlapping deflectometric image two publicly available benchmark accompany this paper enabling u to numerically demonstrate viability and practicability of our approach 
in underwater imagery the image formation process includes refraction that occur when light pass from water into the camera housing typically through a flat glass port we extend the existing work on physical refraction model by considering the dispersion of light and derive new constraint on the model parameter for use in calibration this lead to a novel calibration method that achieves improved accuracy compared to existing work we describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiment 
we propose a novel framework for imposing label ordering constraint in multilabel optimization in particular label jump can be penalized differently depending on the jump direction in contrast to the recently proposed mrf based approach the proposed method arises from the viewpoint of spatially continuous optimization it unifies and generalizes previous approach to label ordering constraint firstly it provides a common solution to three different problem which are otherwise solved by three separate approach we provide an exact characterization of the penalization function expressible with our approach secondly we show that it naturally extends to three and higher dimension of the image domain thirdly it allows novel application such a the convex shape prior despite this generality our model is easily adjustable to various label layout and is also easy to implement on a number of experiment we show that it work quite well producing solution comparable and superior to those obtained with previous approach 
tracking the mitral valve leaflet in an ultrasound sequence is a challenging task because of the poor image quality and fast and irregular leaflet motion previous algorithm usually applied standard segmentation method based on edge object intensity and anatomical information to segment the mitral leaflet in static frame however they are limited in practical application due to the requirement of manual input for initialization or large annotated datasets for training in this paper we present a completely automatic and unsupervised algorithm for mitral leaflet detection and tracking we demonstrate that the image sequence of a cardiac cycle can be well approximated with a low rank matrix except for the mitral leaflet region with fast motion and tissue deformation based on this difference we propose to track the mitral leaflet by detecting contiguous outlier in the low rank representation with this formulation the leaflet is tracked using the motion cue but the complicated motion computation is avoided to the best of our knowledge the proposed algorithm is the first unsupervised method for mitral leaflet tracking the algorithm wa tested on both d and d echocardiography which achieved accurate segmentation with an average distance of mm compared to the manual tracing 
automatic segmentation using multi atlas label fusion ha been widely applied in medical image analysis to simplify the label fusion problem most method implicitly make a strong assumption that the segmentation error produced by different atlas are uncorrelated we show that violating this assumption significantly reduces the efficiency of multi atlas segmentation to address this problem we propose a regression based approach for label fusion our experiment on segmenting the hippocampus in magnetic resonance image mri show significant improvement over previous label fusion technique 
a novel method for registering d surface with large deformation is presented which is based on quasi conformal geometry a general diffeomorphism distorts the conformal structure of the surface which is represented a the beltrami coefficient inversely the diffeomorphism can be determined by the beltrami coefficient in an essentially unique way our registration method first extract the feature on the surface then estimate the beltrami coefficient and finally uniquely determines the registration mapping by solving beltrami equation using curvature flow the method is general it can search the desired registration in the whole space of diffeomorphisms which includes the conventional searching space such a rigid motion isometric transformation or conformal mapping global optimal the global optimum is determined by the method unique up to a dimensional transformation group robust it handle large surface with complicated topology rigorous it ha solid theoretic foundation experiment on the real surface with large deformation and complicated topology demonstrate the efficiency robustness of the proposed method 
light field imaging system have got much attention recently a the next generation camera model a light field imaging system consists of three part data acquisition manipulation and application given an acquisition system it is important to understand how a light field camera convert from it raw image to it resulting refocused image in this paper using the lytro camera a an example we describe step by step procedure to calibrate a raw light field image in particular we are interested in knowing the spatial and angular coordinate of the micro lens array and the resampling process for image reconstruction since lytro us a hexagonal arrangement of a micro lens image additional treatment in calibration are required after calibration we analyze and compare the performance of several resampling method for image reconstruction with and without calibration finally a learning based interpolation method is proposed which demonstrates a higher quality image reconstruction than previous interpolation method including a method used in lytro software 
we address the problem of upper body human pose estimation in uncontrolled monocular video sequence without manual initialization most current method focus on isolated video frame and often fail to correctly localize arm and hand inferring pose over a video sequence is advantageous because pose of people in adjacent frame exhibit property of smooth variation due to the nature of human and camera motion to exploit this previous method have used prior knowledge about distinctive action or generic temporal prior combined with static image likelihood to track people in motion here we take a different approach based on a simple observation information about how a person move from frame to frame is present in the optical flow field we develop an approach for tracking articulated motion that link articulated shape model of people in adjacent frame through the dense optical flow key to this approach is a d shape model of the body that we use to compute how the body move over time the resulting flowing puppet provide a way of integrating image evidence across frame to improve pose inference we apply our method on a challenging dataset of tv video sequence and show state of the art performance 
in this paper we formulate human action recognition a a novel multi task sparse learning mtsl framework which aim to construct a test sample with multiple feature from a few base a possible learning the sparse representation under each feature modality is considered a a single task in mtsl since the task are generated from multiple feature associated with the same visual input they are not independent but inter related we introduce a beta process bp prior to the hierarchical mtsl model which efficiently learns a compact dictionary and infers the sparse structure shared across all the task the mtsl model enforces the robustness in coefficient estimation compared with performing each task independently besides the sparseness is achieved via the beta process formulation rather than the computationally expensive l norm penalty in term of non informative gamma hyper prior the sparsity level is totally decided by the data finally the learning problem is solved by gibbs sampling inference which estimate the full posterior on the model parameter experimental result on the kth and ucf sport datasets demonstrate the effectiveness of the proposed mtsl approach for action recognition 
a new bayesian model for image segmentation based on a gaussian mixture model is proposed the model structure allows the automatic determination of the number of segment while ensuring spatial smoothness of the final output this is achieved by defining two separate mixture weight set the first set of weight is spatially variant and incorporates an mrf edge preserving smoothing prior the second set of weight is governed by a dirichlet prior in order to prune unnecessary mixture component the model is trained using variational inference and the majorization minimization mm algorithm resulting in closed form parameter update the algorithm wa successfully evaluated in term of various segmentation index using the berkeley image data base 
the problem of multi target tracking is comprised of two distinct but tightly coupled challenge i the naturally discrete problem of data association i e assigning image observation to the appropriate target ii the naturally continuous problem of trajectory estimation i e recovering the trajectory of all target to go beyond simple greedy solution for data association recent approach often perform multi target tracking using discrete optimization this ha the disadvantage that trajectory need to be pre computed or represented discretely thus limiting accuracy in this paper we instead formulate multi target tracking a a discrete continuous optimization problem that handle each aspect in it natural domain and allows leveraging powerful method for multi model fitting data association is performed using discrete optimization with label cost yielding near optimality trajectory estimation is posed a a continuous fitting problem with a simple closed form solution which is used in turn to update the label cost we demonstrate the accuracy and robustness of our approach with state of the art performance on several standard datasets 
this paper describes modeling and numerical computation of orthogonal base which are used to describe image and motion field motion estimation from image data is then studied on subspace spanned by these base a reduced model is obtained a the galerkin projection on these subspace of a physical model based on euler and optical flow equation a data assimilation method is studied which assimilates coefficient of image data in the reduced model in order to estimate motion coefficient the approach is first quantified on synthetic data it demonstrates the interest of model reduction a a compromise between result quality and computational cost result obtained on real data are then displayed so a to illustrate the method 
we study the problem of online subspace learning in the context of sequential observation involving structured perturbation in online subspace learning the observation are an unknown mixture of two component presented to the model sequentially the main effect which pertains to the subspace and a residual error term if no additional requirement is imposed on the residual it often corresponds to noise term in the signal which were unaccounted for by the main effect to remedy this one may impose structural contiguity which ha the intended effect of leveraging the secondary term a a covariate that help the estimation of the subspace itself instead of merely serving a a noise residual we show that the corresponding online estimation procedure can be written a an approximate optimization process on a grassmannian we propose an efficient numerical solution gosus grassmannian online subspace update with structured sparsity for this problem gosus is expressive enough in modeling both homogeneous perturbation of the subspace and structural contiguity of outlier and after certain manipulation solvable via an alternating direction method of multiplier admm we evaluate the empirical performance of this algorithm on two problem of interest online background subtraction and online multiple face tracking and demonstrate that it achieves competitive performance with the state of the art in near real time 
many state of the art segmentation algorithm rely on markov or conditional random field model designed to enforce spatial and global consistency constraint this is often accomplished by introducing additional latent variable to the model which can greatly increase it complexity a a result estimating the model parameter or computing the best maximum a posteriori map assignment becomes a computationally expensive task in a series of experiment on the pascal and the msrc datasets we were unable to find evidence of a significant performance increase attributed to the introduction of such constraint on the contrary we found that similar level of performance can be achieved using a much simpler design that essentially ignores these constraint this more simple approach make use of the same local and global feature to leverage evidence from the image but instead directly bias the preference of individual pixel while our investigation doe not prove that spatial and consistency constraint are not useful in principle it point to the conclusion that they should be validated in a larger context 
we propose a reduced algebraic cost based on pairwise epipolar constraint for the iterative refinement of a multiple view d reconstruction the aim is to accelerate the intermediate step required when incrementally building a reconstruction from scratch though the proposed error is algebraic careful input data normalization make it a good approximation to the true geometric epipolar distance it minimization is significantly faster and obtains a geometric reprojection error very close to the optimum value requiring very few iteration of final standard ba refinement smart usage of a reduced measurement matrix for each pair of view allows elimination of the variable corresponding to the d point prior to nonlinear optimization subsequently reducing computation memory usage and considerably accelerating convergence this approach ha been tested in a wide range of real and synthetic problem consistently obtaining significant robustness and convergence improvement even when starting from rough initial solution it efficiency and scalability make it thus an ideal choice for incremental sfm in real time tracking application or scene modelling from large image database 
many method have been proposed to solve the image classification problem for a large number of category among them method based on tree based representation achieve good trade off between accuracy and test time efficiency while focusing on learning a tree shaped hierarchy and the corresponding set of classifier most of them use a greedy prediction algorithm for test time efficiency we argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithm in this work we propose a classifier which achieves a better trade off between efficiency and accuracy with a given tree shaped hierarchy first we convert the classification problem a finding the best path in the hierarchy and a novel branch and bound like algorithm is introduced to efficiently search for the best path second we jointly train the classifier using a novel structured svm ssvm formulation with additional bound constraint a a result our method achieves a significant and relative and improvement in accuracy at high efficiency compared to state of the art greedy tree based method on caltech sun and image net k dataset respectively finally we show that our branch and bound like algorithm naturally rank the path in the hierarchy fig so that user can further process them 
making a high dimensional e g k dim feature for face recognition seems not a good idea because it will bring difficulty on consequent training computation and storage this prevents further exploration of the use of a high dimensional feature in this paper we study the performance of a high dimensional feature we first empirically show that high dimensionality is critical to high performance a k dim feature based on a single type local binary pattern lbp descriptor can achieve significant improvement over both it low dimensional version and the state of the art we also make the high dimensional feature practical with our proposed sparse projection method named rotated sparse regression both computation and model storage can be reduced by over time without sacrificing accuracy quality 
this paper is aimed at calibrating the relative posture and position i e extrinsic parameter of a stationary camera against a d reference object which is not directly visible from the camera we capture the reference object via a mirror under three different unknown pose and then calibrate the extrinsic parameter from d appearance of reflection of the reference object in the mirror the key contribution of this paper is to present a new algorithm which return a unique solution of three p p problem from three mirrored image while each p p problem ha up to four solution and therefore a set of three p p problem ha up to solution our method can select a solution based on an orthogonality constraint which should be satisfied by all family of reflection of a single reference object in addition we propose a new scheme to compute the extrinsic parameter by solving a large system of linear equation these two point enable u to provide a unique and robust solution we demonstrate the advantage of the proposed method against a state of the art by qualitative and quantitative evaluation using synthesized and real data 
we present a method whereby an embodied agent using visual perception can efficiently create a model of a local indoor environment from it experience of moving within it our method us motion cue to compute likelihood of indoor structure hypothesis based on simple generic geometric knowledge about point line plane and motion we present a single image analysis not to attempt to identify a single accurate model but to propose a set of plausible hypothesis about the structure of the environment from an initial frame we then use data from subsequent frame to update a bayesian posterior probability distribution over the set of hypothesis the likelihood function is efficiently computable by comparing the predicted location of point feature on the environment model to their actual tracked location in the image stream our method run in real time and it avoids the need of extensive prior training and the manhattan world assumption which make it more practical and efficient for an intelligent robot to understand it surroundings compared to most previous scene understanding method experimental result on a collection of indoor video suggest that our method is capable of an unprecedented combination of accuracy and efficiency 
alpha matting refers to the problem of softly extracting the foreground from an image given a trimap specifying known foreground background and unknown pixel a straightforward way to compute the alpha value is to sample some known foreground and background color for each unknown pixel existing sampling based matting method often collect sample near the unknown pixel only they fail if good sample cannot be found nearby in this paper we propose a global sampling method that us all sample available in the image our global sample set avoids missing good sample a simple but effective cost function is defined to tackle the ambiguity in the sample selection process to handle the computational complexity introduced by the large number of sample we pose the sampling task a a correspondence problem the correspondence search is efficiently achieved by generalizing a randomized algorithm previously designed for patch matching a variety of experiment show that our global sampling method produce both visually and quantitatively high quality matting result 
approximate inference by decomposition of discrete graphical model and lagrangian relaxation ha become a key technique in computer vision the resulting dual objective function is convenient from the optimization point of view in principle due to it inherent non smoothness however it is not directly amenable to efficient convex optimization related work either weakens the relaxation by smoothing or applies variation of the inefficient projected subgradient method in either case heuristic choice of tuning parameter influence the performance and significantly depend on the specific problem at hand in this paper we introduce a novel approach based on bundle method from the field of combinatorial optimization it is directly based on the non smooth dual objective function requires no tuning parameter and showed a markedly improved efficiency uniformly over a large variety of problem instance including benchmark experiment our code will be publicly available after publication of this paper 
in this paper we propose a new method for the simultaneous segmentation and d reconstruction of interest point based articulated motion we decompose a set of point track into rigid bodied overlapping region which are associated with skeletal link while joint centre can be derived from the region of overlap this allows u to formulate the problem of d reconstruction a one of model assignment where each model corresponds to the motion and shape parameter of an articulated body part we show how this labelling can be optimised using a combination of pre existing graph cut based inference and robust structure from motion factorization technique the strength of our approach come from viewing both the decomposition into part and the d reconstruction a the optimisation of a single cost function namely the image re projection error we show result of full d shape recovery on challenging real world sequence with one or more articulated body in the presence of outlier and missing data 
informative image representation are important in achieving state of the art performance in object recognition task among feature learning algorithm that are used to develop image representation restricted boltzmann machine rbms have good expressive power and build effective representation however the difficulty of training rbms ha been a barrier to their wide use to address this difficulty we show the connection between mixture model and rbms and present an efficient training method for rbms that utilize these connection to the best of our knowledge this is the first work showing that rbms can be trained with almost no hyperparameter tuning to provide classification performance similar to or significantly better than mixture model e g gaussian mixture model along with this efficient training we evaluate the importance of convolutional training that can capture a larger spatial context with le redundancy a compared to non convolutional training overall our method achieves state of the art performance on both caltech datasets using a single type of feature 
in interactive image search a user iteratively refines his result by giving feedback on exemplar image active selection method aim to elicit useful feedback but traditional approach suffer from expensive selection criterion and cannot predict in formativeness reliably due to the imprecision of relevance feedback to address these drawback we propose to actively select pivot exemplar for which feedback in the form of a visual comparison will most reduce the system s uncertainty for example the system might ask is your target image more or le crowded than this image our approach relies on a series of binary search tree in relative attribute space together with a selection function that predicts the information gain were the user to compare his envisioned target to the next node deeper in a given attribute s tree it make interactive search more efficient than existing strategy both in term of the system s selection time a well a the user s feedback effort 
depth ordering is instrumental for understanding the d geometry of an image human are surprisingly good at depth ordering even with abstract d line drawing in this paper we propose a learning based framework for depth ordering inference boundary and junction characteristic are important clue for this task and we have developed new feature based on these attribute although each feature individually can produce reasonable depth ordering result each still ha limitation and we can achieve better performance by combining them in practice local depth ordering inference can be contradictory therefore we propose a markov random field model with term that are more global than previous work and use graph optimization to encourage a globally consistent ordering in addition to produce better object segmentation for the task of depth ordering we propose to explicitly enforce closed loop and long edge for the occlusion boundary detection we collect a new depth order dataset for this problem including more than a thousand human labeled image with various daily object and configuration the proposed algorithm show promising performance over conventional method on both synthetic and real scene 
visual landmark matching with a pre built landmark database is a popular technique for localization traditionally landmark database wa built with visual odometry system and the d information of each visual landmark is reconstructed from video due to the drift of the visual odometry system a global consistent landmark database is difficult to build and the inaccuracy of each d landmark limit the performance of landmark matching in this paper we demonstrated that with the use of precise d li dar range data we are able to build a global consistent database of high precision d visual landmark which improves the landmark matching accuracy dramatically in order to further improve the accuracy and robustness landmark matching is fused with a multi stereo based visual odometry system to estimate the camera pose in two aspect first a local visual odometry trajectory based consistency check is performed to reject some bad landmark matchings or those with large error and then a kalman filtering is used to further smooth out some landmark matching error finally a disk cache mechanism is proposed to obtain the real time performance when the size of the landmark grows for a large scale area a week long real time live marine training experiment have demonstrated the high precision and robustness of our proposed system 
the goal of natural image denoising is to estimate a clean version of a given noisy image utilizing prior knowledge on the statistic of natural image the problem ha been studied intensively with considerable progress made in recent year however it seems that image denoising algorithm are starting to converge and recent algorithm improve over previous one by only fractional db value it is thus important to understand how much more can we still improve natural image denoising algorithm and what are the inherent limit imposed by the actual statistic of the data the challenge in evaluating such limit is that constructing proper model of natural image statistic is a long standing and yet unsolved problem to overcome the absence of accurate image prior this paper take a non parametric approach and represents the distribution of natural image using a huge set of patch we then derive a simple statistical measure which provides a lower bound on the optimal bayesian minimum mean square error mmse this imposes a limit on the best possible result of denoising algorithm which utilize a fixed support around a denoised pixel and a generic natural image prior our finding suggest that for small window state of the art denoising algorithm are approaching optimality and cannot be further improved beyond db value 
this paper introduces a novel geometrical solution for the pose estimation of a stereo camera system a commonly used in robotics where the camera system balance between coverage and overlap the proposed approach considers a set of feature observed respectively in four three and two view in contrast to most algebraic solution our constraint are geometrically meaningful initially we use a four view feature to restrict our translation vector to lie on the surface of a sphere while setting orientation a a function of translation up to a single rotational degree of freedom next we use a three view feature to restrict the translation vector to lie on a circle on the sphere while completely defining orientation a a function of translation finally we use a two view feature to determine the translation vector lying on the intersection of the circle and one of the generator line of a doubly ruled quadric we show how for this final step the problem can be reduced to the intersection of two coplanar circle we also analyze the degenerate configuration of the proposed solver and perform an experimental evaluation 
we investigate the problem of reconstructing normal albedo and light of lambertian surface in uncalibrated photometric stereo under the perspective projection model our analysis is based on establishing the integrability constraint in the orthographic projection case it is well known that when such constraint is imposed a solution can be identified only up to parameter the so called generalized ba relief gbr ambiguity we show that in the perspective projection case the solution is unique we also propose a closed form solution which is simple efficient and robust we test our algorithm on synthetic data and publicly available real data our quantitative test show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection 
co segmentation is defined a jointly partitioning multiple image depicting the same or similar object into foreground and background our method consists of a multiple scale multiple image generative model which jointly estimate the foreground and background appearance distribution from several image in a non supervised manner in contrast to other co segmentation method our approach doe not require the image to have similar foreground and different background to function properly region matching is applied to exploit inter image information by establishing correspondence between the common object that appear in the scene moreover computing many to many association of region allow further application like recognition of object part across image we report result on icoseg a challenging dataset that present extreme variability in camera viewpoint illumination and object deformation and pose we also show that our method is robust against large intra class variability in the msrc database 
despite significant progress tracking is still considered to be a very challenging task recently the increasing popularity of depth sensor ha made it possible to obtain reliable depth easily this may be a game changer for tracking since depth can be used to prevent model drift and handle occlusion we also observe that current tracking algorithm are mostly evaluated on a very small number of video collected and annotated by different group the lack of a reasonable size and consistently constructed benchmark ha prevented a persuasive comparison among different algorithm in this paper we construct a unified benchmark dataset of rgbd video with high diversity propose different kind of rgbd tracking algorithm using d or d model and present a quantitative comparison of various algorithm with rgb or rgbd input we aim to lay the foundation for further research in both rgb and rgbd tracking and our benchmark is available at http tracking c princeton edu 
we present a method to identify and exploit structure that are shared across different object category by using sparse coding to learn a shared basis for the part and root template of deformable part model dpms our first contribution consists in using shift invariant sparse coding sisc to learn mid level element that can translate during coding this result in systematically better approximation than those attained using standard sparse coding to emphasize that the learned mid level structure are shiftable we call them shufflets our second contribution consists in using the resulting score to construct probabilistic upper bound to the exact template score instead of taking them at face value a is common in current work we integrate shufflets in dualtree branch and bound and cascade dpms and demonstrate that we can achieve a substantial acceleration with practically no loss in performance 
assigning a visual code to a low level image descriptor which we call code assignment is the most computationally expensive part of image classification algorithm based on the bag of visual word bow framework this paper proposes a fast computation method neighbor to neighbor ntn search for this code assignment based on the fact that image feature from an adjacent region are usually similar to each other this algorithm effectively reduces the cost of calculating the distance between a codeword and a feature vector this method can be applied not only to a hard codebook constructed by vector quantization ntn vq but also to a soft codebook a gaussian mixture model ntn gmm we evaluated this method on the pascal voc classification challenge task ntn vq reduced the assignment cost by in super vector coding and ntn gmm reduced it by in fisher vector coding without any significant degradation in classification performance 
tracking the articulated d motion of the hand ha important application for example in human computer interaction and teleoperation we present a novel method that can capture a broad range of articulated hand motion at interactive rate our hybrid approach combine in a voting scheme a discriminative part based pose retrieval method with a generative pose estimation method based on local optimization color information from a multi view rgb camera setup along with a person specific hand model are used by the generative method to find the pose that best explains the observed image in parallel our discriminative pose estimation method us fingertip detected on depth data to estimate a complete or partial pose of the hand by adopting a part based pose retrieval strategy this part based strategy help reduce the search space drastically in comparison to a global pose retrieval strategy quantitative result show that our method achieves state of the art accuracy on challenging sequence and a near real time performance of fps on a desktop computer 
we present an active learning approach to choose image annotation request among both object category label and the object attribute label the goal is to solicit those label that will best use human effort when training a multi class object recognition model in contrast to previous work in active visual category learning our approach directly exploit the dependency between human nameable visual attribute and the object they describe shifting it request in either label space accordingly we adopt a discriminative latent model that capture object attribute and attribute attribute relationship and then define a suitable entropy reduction selection criterion to predict the influence a new label might have throughout those connection on three challenging datasets we demonstrate that the method can more successfully accelerate object learning relative to both passive learning and traditional active learning approach 
in this paper we propose an ordinal hyperplane ranking algorithm called ohrank which estimate human age via facial image the design of the algorithm is based on the relative order information among the age label in a database each ordinal hyperplane separate all the facial image into two group according to the relative order and a cost sensitive property is exploited to find better hyperplanes based on the classification cost human age are inferred by aggregating a set of preference from the ordinal hyperplanes with their cost sensitivity our experimental result demonstrate that the proposed approach outperforms conventional multiclass based and regression based approach a well a recently developed ranking based age estimation approach 
this paper address the problem of image segmentation with a reference distribution recent study have shown that segmentation with global consistency measure outperforms conventional technique based on pixel wise measure however such global approach require a precise distribution to obtain the correct extraction to overcome this strict assumption we propose a new approach in which the given reference distribution play a guiding role in inferring the latent distribution and it consistent region the inference is based on an assumption that the latent distribution resembles the distribution of the consistent region but is distinct from the distribution of the complement region we state the problem a the minimization of an energy function consisting of global similarity based on the bhattacharyya distance and then implement a novel iterated distribution matching process for jointly optimizing distribution and segmentation we evaluate the proposed algorithm on the grabcut dataset and demonstrate the advantage of using our approach with various segmentation problem including interactive segmentation background subtraction and co segmentation 
due to occlusion and object non rigid deformation in the scene the obtained motion trajectory from common tracker may contain a number of missing or mi associated entry to cluster such corrupted point based trajectory into multiple motion is still a hard problem in this paper we present an approach that exploit temporal and spatial characteristic from tracked point to facilitate segmentation of incomplete and corrupted trajectory thereby obtain highly robust result against severe data missing and noise our method first us the discrete cosine transform dct base a a temporal smoothness constraint on trajectory projection to ensure the validity of resulting component to repair pathological trajectory then based on an observation that the trajectory of foreground and background in a scene may have different spatial distribution we propose a two stage clustering strategy that first performs foreground background separation then segment remaining foreground trajectory we show that with this new clustering strategy sequence with complex motion can be accurately segmented by even using a simple translational model finally a series of experiment on hopkins dataset and berkeley motion segmentation dataset show the advantage of our method over other state of the art motion segmentation algorithm in term of both effectiveness and robustness 
we propose an algorithm utilizing geodesic distance to upsample a low resolution depth image using a registered high resolution color image specifically it computes depth for each pixel in the high resolution image using geodesic path to the pixel whose depth are known from the low resolution one though this is closely related to the all pair shortest path problem which ha o n log n complexity we develop a novel approximation algorithm whose complexity grows linearly with the image size and achieve realtime performance we compare our algorithm with the state of the art on the benchmark dataset and show that our approach provides more accurate depth upsampling with fewer artifact in addition we show that the proposed algorithm is well suited for upsampling depth image using binary edge map an important sensor fusion application 
due to occlusion the estimation of the full pose of a human hand interacting with an object is much more challenging than pose recovery of a hand observed in isolation in this work we formulate an optimization problem whose solution is the dof hand pose together with the pose and model parameter of the manipulated object optimization seek for the joint hand object model that a best explains the incompleteness of observation resulting from occlusion due to hand object interaction and b is physically plausible in the sense that the hand doe not share the same physical space with the object the proposed method is the first that solves efficiently the continuous full dof joint hand object tracking problem based solely on markerless multicamera input additionally it is the first to demonstrate how hand object interaction can be exploited a a context that facilitates hand pose estimation instead of being considered a a complicating factor extensive quantitative and qualitative experiment with simulated and real world image sequence a well a a comparative evaluation with a state of the art method for pose estimation of isolated hand support the above finding 
recent progress ha shown that learning from hierarchical feature representation lead to improvement in various computer vision task motivated by the observation that human activity data contains information at various temporal resolution we present a hierarchical sequence summarization approach for action recognition that learns multiple layer of discriminative feature representation at different temporal granularity we build up a hierarchy dynamically and recursively by alternating sequence learning and sequence summarization for sequence learning we use crfs with latent variable to learn hidden spatio temporal dynamic for sequence summarization we group observation that have similar semantic meaning in the latent space for each layer we learn an abstract feature representation through non linear gate function this procedure is repeated to obtain a hierarchical sequence summary representation we develop an efficient learning method to train our model and show that it complexity grows sub linearly with the size of the hierarchy experimental result show the effectiveness of our approach achieving the best published result on the arm gesture and canal datasets 
in this paper we propose a novel framework to construct dense and high quality consistent correspondence between non rigid surface our correspondence framework exploit dual shape dna dual laplace beltrami spectral embedding to capture global characteristic of object and convert two originally different and complex shape into two similar and simple shape to facilitate the correspondence since our method avoids the computation of geodesic distance it is robust to local topology change by exploiting the excellent property of the dual domain our dual spectral framework can robustly construct laplace beltrami embeddings on highly non regular d mesh after performing initial non rigid matching in the dual laplace beltrami spectral domain we return d spatial domain and apply a shape preserving non rigid deformation to produce the final dense consistent correspondence we show that our framework is suitable for non rigid consistent correspondence and the high quality correspondence result are achieved 
when describing image human tend not to talk about the obvious but rather mention what they find interesting we argue that abnormality and deviation from typicality are among the most important component that form what is worth mentioning in this paper we introduce the abnormality detection a a recognition problem and show how to model typicality and consequently meaningful deviation from prototypical property of category our model can recognize abnormality and report the main reason of any recognized abnormality we also show that abnormality prediction can help image categorization we introduce the abnormality detection dataset and show interesting result on how to reason about abnormality 
pose variation remains to be a major challenge for real world face recognition we approach this problem through a probabilistic elastic matching method we take a part based representation by extracting local feature e g lbp or sift from densely sampled multi scale image patch by augmenting each feature with it location a gaussian mixture model gmm is trained to capture the spatial appearance distribution of all face image in the training corpus each mixture component of the gmm is confined to be a spherical gaussian to balance the influence of the appearance and the location term each gaussian component build correspondence of a pair of feature to be matched between two face face track for face verification we train an svm on the vector concatenating the difference vector of all the feature pair to decide if a pair of face face track is matched or not we further propose a joint bayesian adaptation algorithm to adapt the universally trained gmm to better model the pose variation between the target pair of face face track which consistently improves face verification accuracy our experiment show that our method outperforms the state of the art in the most restricted protocol on labeled face in the wild lfw and the youtube video face database by a significant margin 
solving the person re identification problem ha become important for understanding people s behaviour in a multicamera network of non overlapping view in this work we address the problem of re identification from a set based verification perspective more specifically we have a small set of target people on a watch list a set and we aim to verify whether a query image of a person is on this watch list this differs from the existing person re identification problem in that the probe is verified against a small set of known people but requires much higher degree of verification accuracy with very limited sampling data for each candidate in the set that is rather than recognising everybody in the scene we consider identifying a small set of target people against non target people when there is only a limited number of target training sample and a large number of unlabelled unknown non target sample available to this end we formulate a transfer learning framework for mining discriminant information from non target people data to solve the watch list set verification problem based on the proposed approach we introduce the concept of multi shot and one shot verification we also design new criterion for evaluating the performance of the proposed transfer learning method against the i lid and ethz data set 
we propose an uncalibrated photometric stereo method that work with general and unknown isotropic reflectance our method us a pixel intensity profile which is a sequence of radiance intensity recorded at a pixel across multi illuminance image we show that for general isotropic material the geodesic distance between intensity profile is linearly related to the angular difference of their surface normal and that the intensity distribution of an intensity profile conveys information about the reflectance property when the intensity profile is obtained under uniformly distributed directional lighting based on these observation we show that surface normal can be estimated up to a convex concave ambiguity a solution method based on matrix decomposition with missing data is developed for a reliable estimation quantitative and qualitative evaluation of our method are performed using both synthetic and real world scene 
this paper aim to extract salient closed contour froman image for this vision task both region segmentation cue e g color texture homogeneity and boundary detection cue e g local contrast edge continuity and contour closure play important and complementary role in this paper we show how to combine both cue in a unified framework the main focus is given to how to maintain the consistency compatibility between the region cue and the boundary cue to this end we introduce the use of winding number a well known concept in topology a a powerful mathematical device by this device the region boundary consistency is represented a aset of simple linear relationship our method is applied to the figure ground segmentation problem the experiment show clearly improved result 
in this paper we propose an automatic approach to simultaneously name face and discover scene in tv show we follow the multi modal idea of utilizing script to assist video content understanding but without using timestamp provided by script subtitle alignment a the connection instead the temporal relation between face in the video and name in the script is investigated in our approach and an global optimal video script alignment is inferred according to the character correspondence the contribution of this paper is two fold we propose a generative model named tvparser to depict the temporal character correspondence between video and script from which face name relationship can be automatically learned a a model parameter and meanwhile video scene structure can be effectively inferred a a hidden state sequence we find fast algorithm to accelerate both model parameter learning and state inference resulting in an efficient and global optimal alignment we conduct extensive comparative experiment on popular tv series and report comparable and even superior performance over existing method 
fitting statistical d and d shape model to image is necessary for a variety of task such a video editing and face recognition much progress ha been made on local fitting from an initial guess but determining a close enough initial guess is still an open problem one approach is to detect distinct landmark in the image and initalize the model fit from these correspondence this is difficult because detection of landmark based only on the local appearance is inherently ambiguous this make it necessary to use global shape information for the detection we propose a method to solve the combinatorial problem of selecting out of a large number of candidate landmark detection the configuration which is best supported by a shape model our method a opposed to previous approach always find the globally optimal configuration the algorithm can be applied to a very general class of shape model and is independent of the underlying feature point detector it theoretic optimality is shown and it is evaluated on a large face dataset 
subspace embedding is a powerful tool for extracting salient information from matrix and it ha numerous application in image processing however it applicability ha been severely limited by the computational complexity of o n n is the number of the point which usually arises in explicitly evaluating the eigenvalue and eigenvectors in this paper we propose an implicit subspace embedding method which avoids explicitly evaluating the eigenvectors also we show that this method can be seamlessly incorporated into the unsupervised multi scale image segmentation framework and the resulted algorithm ha a running time of genuine o n moreover we can explicitly determine the number of iteration for the algorithm by estimating the desired size of the subspace which also control the amount of information we want to extract for this unsupervised learning we performed extensive experiment to verify the validity and effectiveness of our method and we conclude that it only requires le than second cpu g and memory g to cut a color image and order of magnitude faster than original multi scale image segmentation with explicit spectral decomposition while maintaining the same or a better segmentation quality 
we propose a novel approach to both learning and detecting local contour based representation for mid level feature our feature called sketch token are learned using supervised mid level information in the form of hand drawn contour in image patch of human generated contour are clustered to form sketch token class and a random forest classifier is used for efficient detection in novel image we demonstrate our approach on both top down and bottom up task we show state of the art result on the top down task of contour detection while being over x faster than competing method we also achieve large improvement in detection accuracy for the bottom up task of pedestrian and object detection a measured on inria and pascal respectively these gain are due to the complementary information provided by sketch token to low level feature such a gradient histogram 
we present a very general algorithmic framework for structured prediction learning that is able to efficiently handle both pairwise and higher order discrete mrfs crfs it relies on a dual decomposition approach that ha been recently proposed for mrf optimization by properly combining this approach with a max margin method our framework manages to reduce the training of a complex high order mrf to the parallel training of a series of simple slave mrfs that are much easier to handle this lead to an extremely efficient and general learning scheme furthermore the proposed framework can yield learning algorithm of increasing accuracy since it naturally allows a hierarchy of convex relaxation to be used for mrf inference within a max margin learning approach it also offer extreme flexibility and can be easily adapted to take advantage of any special structure of a given class of mrfs experimental result demonstrate the great effectiveness of our method 
in this work we investigate how to automatically uncover the underlying group structure of a feature vector such that each group characterizes certain object specific pattern e g visual pattern or motion trajectory from one object by mining the group structure we can effectively alleviate the mutual inference of multiple object and improve the performance in various visual analysis task to this end we propose a novel auto grouped sparse representation asr method asr group semantically correlated feature element together through optimally fusing their multiple sparse representation due to the intractability of primal objective function we also propose well behaved convex relaxation and smooth approximation to guarantee obtaining a global optimal solution effectively finally we apply asr in two important visual analysis task multi label image classification and motion segmentation comprehensive experimental evaluation show that asr is able to achieve superior performance compared with the state of the art on these two task 
unlike traditional image which do not offer information for different direction of incident light a light field is defined on ray space and implicitly encodes scene geometry data in a rich structure which becomes visible on it epipolar plane image in this work we analyze regularization of light field in variational framework and show that their variational structure is induced by disparity which is in this context best understood a a vector field on epipolar plane image space we derive differential constraint on this vector field to enable consistent disparity map regularization furthermore we show how the disparity field is related to the regularization of more general vector valued function on the d ray space of the light field this way we derive an efficient variational framework with convex prior which can serve a a fundament for a large class of inverse problem on ray space 
we propose a new method for the task of fine grained visual categorization the method build a model of the base level category that can be fitted to image producing high quality foreground segmentation and mid level part localization the model can be learnt from the typical datasets available for fine grained categorization where the only annotation provided is a loose bounding box around the instance e g bird in each image both segmentation and part localization are then used to encode the image content into a highly discriminative visual signature the model is symbiotic in that part discovery localization is helped by segmentation and conversely the segmentation is helped by the detection e g part layout our model build on top of the part based object category detector of felzenszwalb et al and also on the powerful grab cut segmentation algorithm of rother et al and add a simple spatial saliency coupling between them in our evaluation the model improves the categorization accuracy over the state of the art it also improves over what can be achieved with an analogous system that run segmentation and part localization independently 
the graph laplacian operator which originated in spectral graph theory is commonly used for learning application such a spectral clustering and embedding in this paper we explore the laplacian distance a distance function related to the graph laplacian and use it for visual search we show that previous technique such a matching by tone mapping mtm are particular case of the laplacian distance generalizing the laplacian distance result in distance measure which are tolerant to various visual distortion a novel algorithm based on linear decomposition make it possible to compute these generalized distance efficiently the proposed approach is demonstrated for tone mapping invariant outlier robust and multimodal template matching 
this paper describes a method to construct seamless image mosaic of a panoramic scene containing two predominate plane a distant back plane and a ground plane that sweep out from the camera s location while this type of panorama can be stitched when the camera is carefully rotated about it optical center such ideal scene capture is hard to perform correctly existing technique use a single homography per image to perform alignment followed by seam cutting or image blending to hide inevitable alignment artifact in this paper we demonstrate how to use two homographies per image to produce a more seamless image specifically our approach blend the homographies in the alignment procedure to perform a nonlinear warping once the image are geometrically stitched they are further processed to blend seam and reduce curvilinear visual artifact due to the nonlinear warping a demonstrated in our paper our procedure is able to produce result for this type of scene where current state of the art technique fail 
single image matting technique assume high quality input image the vast majority of image on the web and in personal photo collection are encoded using jpeg compression jpeg image exhibit quantization artifact that adversely affect the performance of matting algorithm to address this situation we propose a learning based post processing method to improve the alpha matte extracted from jpeg image our approach learns a set of sparse dictionary from training example that are used to transfer detail from high quality alpha matte to alpha matte corrupted by jpeg compression three different dictionary are defined to accommodate different object structure long hair short hair and sharp boundary a back projection criterion combined within an mrf framework is used to automatically select the best dictionary to apply on the object s local boundary we demonstrate that our method can produce superior result over existing state of the art matting algorithm on a variety of input and compression level 
we propose a novel approach to automated delineation of linear structure that form complex and potentially loopy network this is in contrast to earlier approach that usually assume a tree topology for the network at the heart of our method is an integer programming formulation that allows u to find the global optimum of an objective function designed to allow cycle but penalize spurious junction and early termination we demonstrate that it outperforms state of the art technique on a wide range of datasets 
this paper introduces a probabilistic graphical model for continuous action recognition with two novel component substructure transition model and discriminative boundary model the first component encodes the sparse and global temporal transition prior between action primitive in state space model to handle the large spatial temporal variation within an action class the second component enforces the action duration constraint in a discriminative way to locate the transition boundary between action more accurately the two component are integrated into a unified graphical structure to enable effective training and inference our comprehensive experimental result on both public and in house datasets show that with the capability to incorporate additional information that had not been explicitly or efficiently modeled by previous method our proposed algorithm achieved significantly improved performance for continuous action recognition 
conventional decision forest based method for image labelling task like object segmentation make prediction for each variable pixel independently this prevents them from enforcing dependency between variable and translates into locally inconsistent pixel labellings random field model instead encourage spatial consistency of label at increased computational expense this paper present a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependency directly in the feature space the forest operate on such correlation are captured via new long range soft connectivity feature computed via generalized geodesic distance transforms our model can be thought of a a generalization of the successful semantic texton forest auto context and entangled forest model a second contribution is to show the connection between the typical conditional random field crf energy and the forest training objective this analysis yield a new objective for training decision forest that encourages more accurate structured prediction our geof model is validated quantitatively on the task of semantic image segmentation on four challenging and very diverse image datasets geof outperforms both state of the art forest model and the conventional pair wise crf 
we present a novel non rigid surface registration method that achieves high accuracy and match characteristic feature without manual intervention the key insight is to consider the entire shape a a collection of local structure that individually undergo rigid transformation to collectively deform the global structure we realize this locally rigid but globally non rigid surface registration with a newly derived dual grid free form deformation ffd framework we first represent the source and target shape with their signed distance field sdf we then superimpose a sampling grid onto a conventional ffd grid that is dual to the control point each control point is then iteratively translated by a rigid transformation that minimizes the difference between two sdfs within the corresponding sampling region the translated control point then interpolate the embedding space within the ffd grid and determine the overall deformation the experimental result clearly demonstrate that our method is capable of overcoming the difficulty of preserving and matching local feature 
integral imaging display iid is a promising technology to provide realistic d image without glass to achieve a large screen iid with a reasonable fabrication cost a potential solution is a tiled lens array iid tla iid however tla iids are subject to d image artifact when there are even slight misalignment between the lens array this work aim at compensating these artifact by calibrating the lens array pose with a camera and including them in a ray model used for rendering the d image since the lens array are transparent this task is challenging for traditional calibration method in this paper we propose a novel calibration method based on defining a set of principle observation ray that pas lens center of the tla and the camera s optical center the method is able to determine the lens array pose with only one camera at an arbitrary unknown position without using any additional marker the principle observation ray are automatically extracted using a structured light based method from a dense correspondence map between the displayed and captured pixel experiment show that lens array misalignment can be estimated with a standard deviation smaller than pixel based on this d image artifact are shown to be effectively removed in a test tla iid with challenging misalignment 
we use temporally sequenced flash illumination to capture coded exposure image of fast moving object in low light environment these coded flash image allow for accurate estimation of blur free latent image in the presence of object motion by distributing flash over a window of time we lessen eye safety concern associated with powerful all at once flash we show how our flash based coded exposure system ha better robustness to increasing object velocity than shutter based exposure coding thereby obviating the need for pre exposure velocity estimation we also show that the quality of the estimated sharp image is robust to varying level of ambient illumination this and other benefit of our coded flash system are demonstrated with real image acquired using prototype hardware 
this paper investigates the role that nonlinear camera response function crfs have on image deblurring in particular we show how nonlinear crfs can cause a spatially invariant blur to behave a a spatially varying blur this can result in noticeable ringing artifact when deconvolution is applied even with a known point spread function psf in addition we show how crfs can adversely affect psf estimation algorithm in the case of blind deconvolution to help counter these effect we introduce two method to estimate the crf directly from one or more blurred image when the psf is known or unknown while not a accurate a conventional crf estimation algorithm based on multiple exposure or calibration pattern our approach is still quite effective in improving deblurring result in situation where the crf is unknown 
we present a new pedestrian detector that improves both in speed and quality over state of the art by efficiently handling different scale and transferring computation from test time to training time detection speed is improved when processing monocular image our system provides high quality detection at fps we also propose a new method for exploiting geometric context extracted from stereo image on a single cpu gpu desktop machine we reach fps when processing street scene from rectified input to detection output 
recent year have witnessed a growing interest in understanding the semantics of point cloud in a wide variety of application however point cloud labeling remains an open problem due to the difficulty in acquiring sufficient d point label towards training effective classifier in this paper we overcome this challenge by utilizing the existing massive d semantic labeled datasets from decade long community effort such a image net and label me and a novel cross domain label propagation approach our proposed method consists of two major novel component exemplar svm based label propagation which effectively address the cross domain issue and a graphical model based contextual refinement incorporating d constraint most importantly the entire process doe not require any training data from the target scene also with good scalability towards large scale application we evaluate our approach on the well known cornell point cloud dataset achieving much greater efficiency and comparable accuracy even without any d training data our approach show further major gain in accuracy when the training data from the target scene is used outperforming state of the art approach with far better efficiency 
visual tracking in unconstrained environment is very challenging due to the existence of several source of variety such a change in appearance varying lighting condition cluttered background and frame cut a major factor causing tracking failure is the emergence of region having similar appearance a the target it is even more challenging when the target leaf the field of view fov leading the tracker to follow another similar object and not reacquire the right target when it reappears this paper present a method to address this problem by exploiting the context on the fly in two term distracters and supporter both of them are automatically explored using a sequential randomized forest an online template based appearance model and local feature distracters are region which have similar appearance a the target and consistently co occur with high confidence score the tracker must keep tracking these distracters to avoid drifting supporter on the other hand are local key point around the target with consistent co occurrence and motion correlation in a short time span they play an important role in verifying the genuine target extensive experiment on challenging real world video sequence show the tracking improvement when using this context information comparison with several state of the art approach are also provided 
both image segmentation and dense d modeling from image represent an intrinsically ill posed problem strong regularizers are therefore required to constrain the solution from being too noisy unfortunately these prior generally yield overly smooth reconstruction and or segmentation in certain region whereas they fail in other area to constrain the solution sufficiently in this paper we argue that image segmentation and dense d reconstruction contribute valuable information to each other s task a a consequence we propose a rigorous mathematical framework to formulate and solve a joint segmentation and dense reconstruction problem image segmentation provide geometric cue about which surface orientation are more likely to appear at a certain location in space whereas a dense d reconstruction yield a suitable regularization for the segmentation problem by lifting the labeling from d image to d space we show how appearance based cue and d surface orientation prior can be learned from training data and subsequently used for class specific regularization experimental result on several real data set highlight the advantage of our joint formulation 
image based classification of histology section in term of distinct component e g tumor stroma normal provides a series of index for tumor composition furthermore aggregation of these index from each whole slide image wsi in a large cohort can provide predictive model of the clinical outcome however performance of the existing technique is hindered a a result of large technical variation and biological heterogeneity that are always present in a large cohort we propose a system that automatically learns a series of basis function for representing the underlying spatial distribution using stacked predictive sparse decomposition psd the learned representation is then fed into the spatial pyramid matching framework spm with a linear svm classifier the system ha been evaluated for classification of a distinct histological component for two cohort of tumor type and b colony organization of normal and malignant cell line in d cell culture model throughput ha been increased through the utility of graphical processing unit gpu and evaluation indicates a superior performance result compared with previous research 
pedestrian detection is one of the most challenging task in computer vision and ha received a lot of attention in the last year recently some author have shown the advantage of using combination of part patch based detector in order to cope with the large variability of pose and the existence of partial occlusion in this paper we propose a pedestrian detection method that efficiently combine multiple local expert by mean of a random forest ensemble the proposed method work with rich block based representation such a hog and lbp in such a way that the same feature are reused by the multiple local expert so that no extra computational cost is needed with respect to a holistic method furthermore we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency in particular the resulting detector operates at five frame per second using a laptop machine we tested the proposed method with well known challenging datasets such a caltech eth daimler and inria the method proposed in this work consistently rank among the top performer in all the datasets being either the best method or having a small difference with the best one 
graph cut is a popular algorithm for finding the map assignment of many large scale graphical model that are common in computer vision while graph cut is powerful it doe not provide information about the marginal probability associated with the solution it find to ass uncertainty we are forced to fall back on le efficient and inexact inference algorithm such a loopy belief propagation or use le principled surrogate representation of uncertainty such a the min marginal approach of kohli torr in this work we give new justification for using min marginals to compute the uncertainty in conditional random field framing the min marginal output a exact marginals under a specially chosen generative probabilistic model we leverage this view to learn properly calibrated marginal probability a the result of straightforward maximization of the training likelihood showing that the necessary subgradients can be computed efficiently using dynamic graph cut operation we also show how this approach can be extended to compute multi label marginal distribution where again dynamic graph cut enable efficient marginal inference and maximum likelihood learning we demonstrate empirically that after proper training uncertainty based on min marginals provide better calibrated probability than baseline and that these distribution can be exploited in a decision theoretic way for improved segmentation in low level vision 
we study the map labeling problem for graphical model by optimizing a dual problem obtained by lagrangian decomposition in this paper we focus specifically on ne terov s optimal first order optimization scheme for non smooth convex program that ha been studied for a range of other problem in computer vision and machine learning in recent year we show that in order to obtain an efficiently convergent iteration this approach should be augmented with a dynamic estimation of a corresponding lip schitz constant leading to a runtime complexity of o in term of the desired precision additionally we devise a stopping criterion based on a duality gap a a sound basis for competitive comparison and show how to compute it efficiently we evaluate our result using the publicly available middlebury database and a set of computer generated graphical model that highlight specific aspect along with other state of the art method for map inference 
human saccade is a dynamic process of information pursuit based on the principle of information maximization we propose a computational model to simulate human saccadic scanpaths on natural image the model integrates three related factor a driven force to guide eye movement sequentially reference sensory response fovea periphery resolution discrepancy and visual working memory for each eye movement we compute three multi band filter response map a a coherent representation for the three factor the three filter response map are combined into multi band residual filter response map on which we compute residual perceptual information rpi at each location the rpi map is a dynamic saliency map varying along with eye movement the next fixation is selected a the location with the maximal rpi value on a natural image dataset we compare the saccadic scanpaths generated by the proposed model and several other visual saliency based model against human eye movement data experimental result demonstrate that the proposed model achieves the best prediction accuracy on both static fixation location and dynamic scanpaths 
a widely used technique to recover a d surface from photograph is patch based multi view stereo reconstruction current method are able to reproduce fine surface detail they are however limited by the sampling density and the patch size used for reconstruction we show that there is a systematic error in the reconstruction depending on the detail in the unknown surface frequency and the reconstruction resolution for this purpose we present a theoretical analysis of patch based depth reconstruction we prove that our model of the reconstruction process yield a linear system allowing u to apply the transfer or system function concept we derive the modulation transfer function theoretically and validate it experimentally on synthetic example using rendered image a well a on photograph of a d test target our analysis prof that there is a significant but predictable amplitude loss in reconstruction of fine scale detail in a first experiment on real world data we show how this can be compensated for within the limit of noise and reconstruction accuracy by an inverse transfer function in frequency space 
in recent year there ha been a great deal of progress in describing object with attribute attribute have proven useful for object recognition image search face verification image description and zero shot learning typically attribute are either binary or relative they describe either the presence or absence of a descriptive characteristic or the relative magnitude of the characteristic when comparing two exemplar however prior work fails to model the actual way in which human use these attribute in descriptive statement of image specifically it doe not address the important interaction between the binary and relative aspect of an attribute in this work we propose a spoken attribute classifier which model a more natural way of using an attribute in a description for each attribute we train a classifier which capture the specific way this attribute should be used we show that a a result of using this model we produce description about image of people that are more natural and specific than past system 
in this paper we introduce a novel framework for computing a path of diffeomorphisms between a pair of input diffeomorphisms direct computation of a geodesic path on the space of diffeomorphisms diff is difficult and it can be attributed mainly to the infinite dimensionality of diff our proposed framework to some degree bypass this difficulty using the quotient map of diff to the quotient space diff m diff m obtained by quotienting out the subgroup of volume preserving diffeomorphisms diff m this quotient space wa recently identified a the unit sphere in a hilbert space in mathematics literature a space with well known geometric property our framework leverage this recent result by computing the diffeomorphic path in two stage first we project the given diffeomorphism pair onto this sphere and then compute the geodesic path between these projected point second we lift the geodesic on the sphere back to the space of diffeomerphisms by solving a quadratic programming problem with bilinear constraint using the augmented lagrangian technique with penalty term in this way we can estimate the path of diffeomorphisms first staying in the space of diffeomorphisms and second preserving shape volume in the deformed image along the path a much a possible we have applied our framework to interpolate intermediate frame of frame sub sampled video sequence in the reported experiment our approach compare favorably with the popular large deformation diffeomorphic metric mapping framework lddmm 
we present an unsupervised shape based method for joint clustering of multiple image segmentation given two or more closely related image such a nearby frame in a video sequence or image of the same scene taken under different lighting condition our method generates a joint segmentation of the image we introduce a novel contour based representation that allows u to cast the shape based joint clustering problem a a quadratic semi assignment problem our score function is additive we use complex valued affinity to ass the quality of matching the edge element at the exterior bounding contour of cluster while ignoring the contribution of element that fall in the interior of the cluster we further combine this contour based score with region information and use a linear programming relaxation to solve for the joint cluster we evaluate our approach on the occlusion boundary data set of stein et al 
we propose a novel approach to associate object across multiple ptz camera that can be used to perform camera handoff in wide area surveillance scenario while previous approach relied on geometric appearance or correlation based information for establishing correspondence between static camera they each have well known limitation and are not extendable to wide area setting with ptz camera in our approach the slave camera only passively follows the target by loose registration with the master and bootstrap itself from it own incoming imagery thus effectively circumventing the problem faced by previous approach and avoiding the need to perform any model transfer towards this goal we also propose a novel multiple instance learning mil formulation for the problem based on the logistic softmax function of covariance based region feature within a map estimation framework we demonstrate our approach with multiple ptz camera sequence in typical outdoor surveillance setting and show a comparison with state of the art approach 
we address the challenging issue of camera localization in a partially known environment i e for which a geometric d model that cover only a part of the observed scene is available when this scene is static both known and unknown part of the environment provide constraint on the camera motion this paper proposes a nonlinear refinement process of an initial sfm reconstruction that take advantage of these two type of constraint compare to those that exploit only the model constraint i e the known part of the scene including the unknown part of the environment in the optimization process yield a faster more accurate and robust refinement it also present a much larger convergence basin this paper will demonstrate these statement on varied synthetic and real sequence for both d object tracking and outdoor localization application 
we propose a system for the automatic segmentation of novelty from the background in scenario where multiple image of the same environment are available e g obtained by wearable visual camera our method find the pixel in a query image corresponding to the underlying background environment by comparing it to reference image of the same scene this is achieved despite the fact that all the image may have different viewpoint significantly different illumination condition and contain different object car people bicycle etc occluding the background we estimate the probability of each pixel in the query image belonging to the background by computing it appearance inconsistency to the multiple reference image we then produce multiple segmentation of the query image using an iterated graph cut algorithm initializing from these estimated probability and consecutively combine these segmentation to come up with a final segmentation of the background detection of the background in turn highlight the novel pixel we demonstrate the effectiveness of our approach on a challenging outdoors data set 
we develop a completion pipeline for fragmented and damaged skull the goal of this work is to convert scanned incomplete skull fragment to a complete skull model for subsequent forensic or archeological task such a facial reconstruction the proposed assembly and completion algorithm can also be used to repair other fragmented object with inherent symmetry a two step assembly framework is proposed rough assembly by an icp like template matching algorithm integrated with the slippage feature and spin image descriptor assembly refinement by a global optimization on least square transformation error lste of break curve the assembled skull is finally repaired by a symmetry based completion algorithm experiment on repairing scanned skull fragment demonstrate the efficacy and robustness of this framework 
with the advent of cheap high fidelity digital imaging system the quantity and rate of generation of visual data can dramatically outpace a human ability to label or annotate it in these situation there is scope for the use of unsupervised approach that can model these datasets and automatically summarise their content to this end we present a totally unsupervised and annotation le model for scene understanding this model can simultaneously cluster whole image and segment descriptor thereby forming an unsupervised model of scene and object we show that this model outperforms other unsupervised model that can only cluster one source of information image or segment at once we are able to compare unsupervised and supervised technique using standard measure derived from confusion matrix and contingency table this show that our unsupervised model is competitive with current supervised and weakly supervised model for scene understanding on standard datasets we also demonstrate our model operating on a dataset with more than image collected by an autonomous underwater vehicle 
since high level event in image e g dinner motorcycle stunt etc may not be directly correlated with their visual appearance low level visual feature do not carry enough semantics to classify such event satisfactorily this paper explores a fully compositional approach for event based image retrieval which is able to overcome this shortcoming furthermore the approach is fully scalable in both adding new event and new primitive using the pascal voc dataset our contribution are the following i we apply the faceted analysis synthesis theory fast to build a hierarchy of high level event ii we show that rule based classifier are better suited for compositional recognition of event than svms in addition rule based classifier provide semantically meaningful event description which help bridging the semantic gap iii we demonstrate that compositionality enables unseen event recognition we can use rule learned from non visual cue together with object detector to get reasonable performance on unseen event category 
we present a new unsupervised algorithm to discover and segment out common object from large and diverse image collection in contrast to previous co segmentation method our algorithm performs well even in the presence of significant amount of noise image image not containing a common object a typical for datasets collected from internet search the key insight to our algorithm is that common object pattern should be salient within each image while being sparse with respect to smooth transformation across other image we propose to use dense correspondence between image to capture the sparsity and visual variability of the common object over the entire database which enables u to ignore noise object that may be salient within their own image but do not commonly occur in others we performed extensive numerical evaluation on established co segmentation datasets a well a several new datasets generated using internet search our approach is able to effectively segment out the common object for diverse object category while naturally identifying image where the common object is not present 
given a set of image which share an object from the same semantic category we would like to co segment the shared object we define good co segment to be one which can be easily composed like a puzzle from large piece of other co segment yet are difficult to compose from remaining image part these piece must not only match well but also be statistically significant hard to compose at random this give rise to co segmentation of object in very challenging scenario with large variation in appearance shape and large amount of clutter we further show how multiple image can collaborate and score each others co segment to improve the overall fidelity and accuracy of the co segmentation our co segmentation can be applied both to large image collection a well a to very few image where there is too little data for unsupervised learning at the extreme it can be applied even to a single image to extract it co occurring object our approach obtains state of the art result on benchmark datasets we further show very encouraging co segmentation result on the challenging pascal voc dataset 
image color are biased by the color of the prevailing illumination a such the color at pixel cannot always be used directly in solving vision task from recognition to tracking to general scene understanding illuminant estimation algorithm attempt to infer the color of the light incident in a scene and then a color cast removal step discount the color bias due to illumination however despite sustained research since almost the inception of computer vision progress ha been modest the best algorithm now often built on top of expensive feature extraction and machine learning are only about twice a good a the simplest approach this paper in effect will show how simple moment based algorithm such a gray world can with the addition of a simple correction step deliver much improved illuminant estimation performance the corrected gray world algorithm map the mean image color using a fixed per camera x matrix transform more generally our moment approach employ st nd and higher order moment of color or feature such a color derivative and these again are linearly corrected to give an illuminant estimate the question of how to correct the moment is an important one yet we will show a simple alternating least square training procedure suffices remarkably across the major datasets evaluated using a fold cross validation procedure our simple corrected moment approach always delivers the best result and the performance increment is often large compared with the prior art significantly outlier performance wa found to be much improved 
in this work we investigate how illuminant estimation can be performed exploiting the color statistic extracted from the face automatically detected in the image the proposed method is based on two observation first skin color tend to form a cluster in the color space making it a cue to estimate the illuminant in the scene second many photographic image are portrait or contain people the proposed method ha been tested on a public dataset of image in raw format using both a manual and a real face detector experimental result demonstrate the effectiveness of our approach the proposed method can be directly used in many digital still camera processing pipeline with an embedded face detector working on gray level image 
the recent availability of large amount of geotagged imagery ha inspired a number of data driven solution to the image geolocalization problem existing approach predict the location of a query image by matching it to a database of georeferenced photograph while there are many geotagged image available on photo sharing and street view site most are clustered around landmark and urban area the vast majority of the earth s land area ha no ground level reference photo available which limit the applicability of all existing image geolocalization method on the other hand there is no shortage of visual and geographic data that densely cover the earth we examine overhead imagery and land cover survey data but the relationship between this data and ground level query photograph is complex in this paper we introduce a cross view feature translation approach to greatly extend the reach of image geolocalization method we can often localize a query even if it ha no corresponding ground level image in the database a key idea is to learn the relationship between ground level appearance and overhead appearance and land cover attribute from sparsely available geotagged ground level image we perform experiment over a km region containing a variety of scene and land cover type for each query our algorithm produce a probability density over the region of interest 
binary key point descriptor provide an efficient alternative to their floating point competitor a they enable faster processing while requiring le memory in this paper we propose a novel framework to learn an extremely compact binary descriptor we call bin boost that is very robust to illumination and viewpoint change each bit of our descriptor is computed with a boosted binary hash function and we show how to efficiently optimize the different hash function so that they complement each other which is key to compactness and robustness the hash function rely on weak learner that are applied directly to the image patch which free u from any intermediate representation and let u automatically learn the image gradient pooling configuration of the final descriptor our resulting descriptor significantly outperforms the state of the art binary descriptor and performs similarly to the best floating point descriptor at a fraction of the matching time and memory footprint 
in this paper we address the problem of finding the most probable state of discrete markov random field mrf with associative pairwise term although of practical importance this problem is known to be np hard in general we propose a new type of mrf decomposition submodular decomposition smd unlike existing decomposition approach smd decomposes the initial problem into sub problem corresponding to a specific class label while preserving the graph structure of each subproblem such decomposition enables u to take into account several type of global constraint in an efficient manner we study theoretical property of the proposed approach and demonstrate it applicability on a number of problem 
we propose a new objective function for superpixel segmentation this objective function consists of two component entropy rate of a random walk on a graph and a balancing term the entropy rate favor formation of compact and homogeneous cluster while the balancing function encourages cluster with similar size we present a novel graph construction for image and show that this construction induces a matroid a combinatorial structure that generalizes the concept of linear independence in vector space the segmentation is then given by the graph topology that maximizes the objective function under the matroid constraint by exploiting submodular and mono tonic property of the objective function we develop an efficient greedy algorithm furthermore we prove an approximation bound of for the optimality of the solution extensive experiment on the berkeley segmentation benchmark show that the proposed algorithm outperforms the state of the art in all the standard evaluation metric 
surface registration is a fundamental step in the reconstruction of three dimensional object while there are several fast and reliable method to align two surface the tool available to align multiple surface are relatively limited in this paper we propose a novel multiview registration algorithm that project several pairwise alignment onto a common reference frame the projection is performed by representing the motion a dual quaternion an algebraic structure that is related to the group of d rigid transformation and by performing a diffusion along the graph of adjacent i e pairwise alignable view the approach allows for a completely generic topology with which the pair wise motion are diffused an extensive set of experiment show that the proposed approach is both order of magnitude faster than the state of the art and more robust to extreme positional noise and outlier the dramatic speedup of the approach allows it to be alternated with pairwise alignment resulting in a smoother energy profile reducing the risk of getting stuck at local minimum 
we propose a novel method for the multi view reconstruction problem surface which do not have direct support in the input d point cloud and hence need not be photo consistent but represent real part of the scene e g low textured wall window car are important for achieving complete reconstruction we augmented the existing labatut cgf method with the ability to cope with these difficult surface just by changing the t edge weight in the construction of surface by a minimal s t cut our method us visual hull to reconstruct the difficult surface which are not sampled densely enough by the input d point cloud we demonstrate importance of these surface on several real world data set we compare our improvement to our implementation of the labatut cgf method and show that our method can considerably better reconstruct difficult surface while preserving thin structure and detail in the same quality and computational time 
a large number of vision application rely on matching keypoints across image the last decade featured an arm race towards faster and more robust keypoints and association algorithm scale invariant feature transform sift speed up robust feature surf and more recently binary robust invariant scalable keypoints brisk i to name a few these day the deployment of vision algorithm on smart phone and embedded device with low memory and computation complexity ha even upped the ante the goal is to make descriptor faster to compute more compact while remaining robust to scale rotation and noise to best address the current requirement we propose a novel keypoint descriptor inspired by the human visual system and more precisely the retina coined fast retina keypoint freak a cascade of binary string is computed by efficiently comparing image intensity over a retinal sampling pattern our experiment show that freak are in general faster to compute with lower memory load and also more robust than sift surf or brisk they are thus competitive alternative to existing keypoints in particular for embedded application 
gaining invariance to camera and illumination variation ha been a well investigated topic in active appearance model aam fitting literature the major problem lie in the inability of the appearance parameter of the aam to generalize to unseen condition an attractive approach for gaining invariance is to fit an aam to a multiple filter response e g gabor representation of the input image naively applying this concept with a traditional aam is computationally prohibitive especially a the number of filter response increase in this paper we present a computationally efficient aam fitting algorithm based on the lucas kanade lk algorithm posed in the fourier domain that affords invariance to both expression and illumination we refer to this a a fourier aam faam and show that this method give substantial improvement in person specific aam fitting performance over traditional aam fitting method 
sparse coding ha become an increasingly popular method in learning and vision for a variety of classification reconstruction and coding task the canonical approach intrinsically assumes independence between observation during learning for many natural signal however sparse coding is applied to sub element i e patch of the signal where such an assumption is invalid convolutional sparse coding explicitly model local interaction through the convolution operator however the resulting optimization problem is considerably more complex than traditional sparse coding in this paper we draw upon idea from signal processing and augmented lagrange method alms to produce a fast algorithm with globally optimal sub problem and super linear convergence 
this paper present a probabilistic volumetric framework for image based modeling of general dynamic d scene the framework is targeted towards high quality modeling of complex scene evolving over thousand of frame extensive storage and computational resource are required in processing large scale space time d data existing method typically store separate d model at each time step and do not address such limitation a novel d representation is proposed that adaptively subdivides in space and time to explain the appearance of d dynamic surface this representation is shown to achieve compression of d data and provide efficient spatio temporal processing the advance of the proposed framework is demonstrated on standard datasets using free viewpoint video and d tracking application 
in many case the predictive power of structured model for for complex vision task is limited by a trade off between the expressiveness and the computational tractability of the model however choosing this trade off statically a priori is sub optimal a image and video in different setting vary tremendously in complexity on the other hand choosing the trade off dynamically requires knowledge about the accuracy of different structured model on any given example in this work we propose a novel two tier architecture that provides dynamic speed accuracy trade offs through a simple type of introspection our approach which we call dynamic structured model selection dm leverage typically intractable feature in structured learning problem in order to automatically determine which of several model should be used at test time in order to maximize accuracy under a fixed budgetary constraint we demonstrate dm on two sequential modeling vision task and we establish a new state of the art in human pose estimation in video with an implementation that is roughly faster than the previous standard implementation 
in this work we exploit segmentation to construct appearance descriptor that can robustly deal with occlusion and background change for this we downplay measurement coming from area that are unlikely to belong to the same region a the descriptor s center a suggested by soft segmentation mask our treatment is applicable to any image point i e dense and it computational overhead is in the order of a few second we integrate this idea with dense sift and also with dense scale and rotation invariant descriptor sid delivering descriptor that are densely computable invariant to scaling and rotation and robust to background change we apply our approach to standard benchmark on large displacement motion estimation using sift flow and wide baseline stereo systematically demonstrating that the introduction of segmentation yield clear improvement 
visual tracking of general object often relies on the assumption that gradient descent of the alignment function will reach the global optimum a common technique to smooth the objective function is to blur the image however blurring the image destroys image information which can cause the target to be lost to address this problem we introduce a method for building an image descriptor using distribution field dfs a representation that allows smoothing the objective function without destroying information about pixel value we present experimental evidence on the superiority of the width of the basin of attraction around the global optimum of dfs over other descriptor dfs also allow the representation of uncertainty about the tracked object this help in disregarding outlier during tracking like occlusion or small misalignment without modeling them explicitly finally this provides a convenient way to aggregate the observation of the object through time and maintain an updated model we present a simple tracking algorithm that us dfs and obtains state of the art result on standard benchmark 
turbulence near hot surface such a desert terrain and road during the summer cause shimmering distortion and blurring in image while recent work have focused on image restoration this paper explores what information about the scene can be extracted from the distortion caused by turbulence based on the physical model of wave propagation we first study the relationship between the scene depth and the amount of distortion caused by homogenous turbulence we then extend this relationship to more practical scenario such a finite extent and height varying turbulence and present simple algorithm to estimate depth ordering depth discontinuity and relative depth from a sequence of short exposure image in the case of general non homogenous turbulence we show that a statistical property of turbulence can be used to improve long range structure from motion or stereo we demonstrate the accuracy of our method in both laboratory and outdoor setting and conclude that turbulence when present can be a strong and useful depth cue 
non blind deblurring is an integral component of blind approach for removing image blur due to camera shake even though learning based deblurring method exist they have been limited to the generative case and are computationally expensive to this date manually defined model are thus most widely used though limiting the attained restoration quality we address this gap by proposing a discriminative approach for non blind deblurring one key challenge is that the blur kernel in use at test time is not known in advance to address this we analyze existing approach that use half quadratic regularization from this analysis we derive a discriminative model cascade for image deblurring our cascade model consists of a gaussian crf at each stage based on the recently introduced regression tree field we train our model by loss minimization and use synthetically generated blur kernel to generate training data our experiment show that the proposed approach is efficient and yield state of the art restoration quality on image corrupted with synthetic and real blur 
in this work we propose an exemplar based face image segmentation algorithm we take inspiration from previous work on image parsing for general scene our approach assumes a database of exemplar face image each of which is associated with a hand labeled segmentation map given a test image our algorithm first selects a subset of exemplar image from the database our algorithm then computes a nonrigid warp for each exemplar image to align it with the test image finally we propagate label from the exemplar image to the test image in a pixel wise manner using trained weight to modulate and combine label map from different exemplar we evaluate our method on two challenging datasets and compare with two face parsing algorithm and a general scene parsing algorithm we also compare our segmentation result with contour based face alignment result that is we first run the alignment algorithm to extract contour point and then derive segment from the contour our algorithm compare favorably with all previous work on all datasets evaluated 
fine grained recognition concern categorization at sub ordinate level where the distinction between object class is highly local compared to basic level recognition fine grained categorization can be more challenging a there are in general le data and fewer discriminative feature this necessitates the use of stronger prior for feature selection in this work we include human in the loop to help computer select discriminative feature we introduce a novel online game called bubble that reveals discriminative feature human use the player s goal is to identify the category of a heavily blurred image during the game the player can choose to reveal full detail of circular region bubble with a certain penalty with proper setup the game generates discriminative bubble with assured quality we next propose the bubble bank algorithm that us the human selected bubble to improve machine recognition performance experiment demonstrate that our approach yield large improvement over the previous state of the art on challenging benchmark 
in this paper we describe an interest point detector using edge focus unlike traditional detector that compute interest point directly from image intensity we use normalized intensity edge and their orientation we hypothesize that detector based on the presence of oriented edge are more robust to non linear lighting variation and background clutter than intensity based technique specifically we detect edge focus which are point in the image that are roughly equidistant from edge with orientation perpendicular to the point the scale of the interest point is defined by the distance between the edge focus and the edge we quantify the performance of our detector using the interest point s repeatability uniformity of spatial distribution and the uniqueness of the resulting descriptor result are found using traditional datasets and new datasets with challenging non linear lighting variation and occlusion 
in this paper we present a compositional and or graph grammar model for human pose estimation our model ha three distinguishing feature roman numeral large appearance difference between people are handled compositionally by allowing part or collection of part to be substituted with alternative variant roman numeral each variant is a sub model that can define it own articulated geometry and context sensitive compatibility with neighboring part variant and roman numeral background region segmentation is incorporated into the part appearance model to better estimate the contrast of a part region from it surroundings and improve resilience to background clutter the resulting integrated framework is trained discriminatively in a max margin framework using an efficient and exact inference algorithm we present experimental evaluation of our model on two popular datasets and show performance improvement over the state of art on both benchmark 
one of the main challenge in computed tomography ct is how to balance between the amount of radiation the patient is exposed to during scan time and the quality of the ct image we propose a mathematical model for adaptive ct acquisition whose goal is to reduce dosage level while maintaining high image quality at the same time the adaptive algorithm iterates between selective limited acquisition and improved reconstruction with the goal of applying only the dose level required for sufficient image quality the theoretical foundation of the algorithm is nonlinear ridge let approximation and a discrete form of ridge let analysis is used to compute the selective acquisition step that best capture the image edge we show experimental result where for the same number of line projection the adaptive model produce higher image quality when compared with standard limited angle non adaptive acquisition algorithm 
brain mapping transforms the brain cortical surface to canonical planar domain which play a fundamental role in morphological study most existing brain mapping method are based on angle preserving map which may introduce large area distortion this work proposes an area preserving brain mapping method based on monge brenier theory the brain mapping is intrinsic to the riemannian metric unique and diffeomorphic the computation is equivalent to convex energy minimization and power voronoi diagram construction comparing to the existing approach based on monge kantorovich theory the proposed one greatly reduces the complexity from n unknown to n and improves the simplicity and efficiency experimental result on caudate nucleus surface mapping and cortical surface mapping demonstrate the efficacy and efficiency of the proposed method conventional method for caudate nucleus surface mapping may suffer from numerical instability in contrast current method produce diffeomorpic mapping stably in the study of cortical surface classification for recognition of alzheimer s disease the proposed method outperforms some other morphometry feature 
with the improved accessibility to an exploding amount of video data and growing demand in a wide range of video analysis application video based action recognition classification becomes an increasingly important task in computer vision in this paper we propose a two layer structure for action recognition to automatically exploit a mid level acton representation the actons are learned via a new max margin multi channel multiple instance learning framework the learned actons with no requirement for detailed manual annotation thus observe a property of being compact informative discriminative and easy to scale this is different from the standard unsupervised e g k mean or supervised e g random forest coding strategy in action recognition applying the learned actons in our two layer structure yield the state of the art classification performance on youtube and hmdb datasets 
detecting and registering nonrigid surface are two important research problem for computer vision much work ha been done with the assumption that there exists only one instance in the image in this work we propose an algorithm that detects and register multiple nonrigid instance of given object in a cluttered image specifically after we use low level feature point to obtain the initial match between template and the input image a novel high order affinity graph is constructed to model the consistency of local topology a hierarchical clustering approach is then used to locate the nonrigid surface to remove the outlier in the cluster we propose a deterministic annealing approach based on the thin plate spline tps model the proposed method achieves high accuracy even when the number of outlier is nineteen time larger than the inliers a the match may appear sparsely in each instance we propose a tps based match growing approach to propagate the match finally an approach that fuse feature and appearance information is proposed to register each nonrigid surface extensive experiment and evaluation demonstrate that the proposed algorithm achieves promising result in detecting and registering multiple non rigid surface in a cluttered scene 
the same object can be observed at different viewpoint or even by different sensor thus generating multiple distinct even heterogeneous sample nowadays more and more application need to recognize object from distinct view some seminal work have been proposed for object recognition across two view and applied to multiple view in some inefficient pairwise manner in this paper we propose a multi view discriminant analysis mvda method which seek for a discriminant common space by jointly learning multiple view specific linear transforms for robust object recognition from multiple view in a non pairwise manner specifically our mvda is formulated to jointly solve the multiple linear transforms by optimizing a generalized rayleigh quotient i e maximizing the between class variation and minimizing the within class variation of the low dimensional embeddings from both intra view and inter view in the common space by reformulating this problem a a ratio trace problem an analytical solution can be achieved by using the generalized eigenvalue decomposition the proposed method is applied to three multi view face recognition problem face recognition across pose photo sketch face recognition and visual vi image v near infrared nir image face recognition evaluation are conducted respectively on multi pie cufsf and hfb database intensive experiment show that mvda can achieve a more discriminant common space with up to improvement compared with the best known result 
super resolution sr algorithm typically assume that the blur kernel is known either the point spread function psf of the camera or some default low pas filter e g a gaussian however the performance of sr method significantly deteriorates when the assumed blur kernel deviate from the true one we propose a general framework for blind super resolution in particular we show that i unlike the common belief the psf of the camera is the wrong blur kernel to use in sr algorithm ii we show how the correct sr blur kernel can be recovered directly from the low resolution image this is done by exploiting the inherent recurrence property of small natural image patch either internally within the same image or externally in a collection of other natural image in particular we show that recurrence of small patch across scale of the low re image which form the basis for single image sr can also be used for estimating the optimal blur kernel this lead to significant improvement in sr result 
real time recognition may be limited by scarce memory and computing resource for performing classification although prior research ha addressed the problem of training classifier with limited data and computation few effort have tackled the problem of memory constraint on recognition we explore method that can guide the allocation of limited storage resource for classifying streaming data so a to maximize discriminatory power we focus on computation of the expected value of information with nearest neighbor classifier for online face recognition experiment on real world datasets show the effectiveness and power of the approach the method provide a principled approach to vision under bounded resource and have immediate application to enhancing recognition capability in consumer device with limited memory 
modern descriptor like hog and sift are now commonly used in vision for pattern detection within image and video from a signal processing perspective this detection process can be efficiently posed a a correlation convolution between a multi channel image and a multi channel detector filter which result in a single channel response map indicating where the pattern e g object ha occurred in this paper we propose a novel framework for learning a multi channel detector filter efficiently in the frequency domain both in term of training time and memory footprint which we refer to a a multichannel correlation filter to demonstrate the effectiveness of our strategy we evaluate it across a number of visual detection localization task where we i exhibit superior performance to current state of the art correlation filter and ii superior computational and memory efficiency compared to state of the art spatial detector 
in this paper we propose method for speeding up minimal solver based on gr bner base and action matrix eigenvalue computation almost all existing gr bner basis solver spend most time in the eigenvalue computation we present two method which speed up this phase of gr bner basis solver a method based on a modified fglm algorithm for transforming gr bner base which result in a single variable polynomial followed by direct calculation of it root using sturm sequence and for larger problem fast calculation of the characteristic polynomial of an action matrix again solved using sturm sequence we enhanced the fglm method by replacing time consuming polynomial division performed in standard fglm algorithm with efficient matrix vector multiplication and we show how this method is related to the characteristic polynomial method our approach allow computing root only in some feasible interval and in desired precision proposed method can significantly speedup many existing solver we demonstrate them on three important minimal computer vision problem 
this paper introduces a simple yet effective method to improve visual word based image retrieval our method is based on an analysis of the k reciprocal nearest neighbor structure in the image space at query time the information obtained from this process is used to treat different part of the ranked retrieval list with different distance measure this lead effectively to a re ranking of retrieved image a we will show this ha two benefit first using different similarity measure for different part of the ranked list allows for compensation of the curse of dimensionality second it allows for dealing with the uneven distribution of image in the data space dealing with both challenge ha very beneficial effect on retrieval accuracy furthermore a major part of the process happens offline so it doe not affect speed at retrieval time finally the method operates on the bag of word level only thus it could be combined with any additional measure on e g either descriptor level or feature geometry making room for further improvement we evaluate our approach on common object retrieval benchmark and demonstrate a significant improvement over standard bag of word retrieval 
human activity recognition is central to many practical application ranging from visual surveillance to gaming interfacing most approach addressing this problem are based on localized spatio temporal feature that can vary significantly when the viewpoint change a a result their performance rapidly deteriorate a the difference between the viewpoint of the training and testing data increase in this paper we introduce a new type of feature the hankelet that capture dynamic property of short tracklets while hankelets do not carry any spatial information they bring invariant property to change in viewpoint that allow for robust cross view activity recognition i e when action are recognized using a classifier trained on data from a different viewpoint our experiment on the ixmas dataset show that using hanklets improves the state of the art performance by over 
this paper considers the problem of reconstructing the motion of a d articulated tree from d point correspondence subject to some temporal prior hitherto smooth motion ha been encouraged using a trajectory basis yielding a hard combinatorial problem with time complexity growing exponentially in the number of frame branch and bound strategy have previously attempted to curb this complexity whilst maintaining global optimality however they provide no guarantee of being more efficient than exhaustive search inspired by recent work which reconstructs general trajectory using compact high pas filter we develop a dynamic programming approach which scale linearly in the number of frame leveraging the intrinsically local nature of filter interaction extension to affine projection enables reconstruction without estimating camera 
we present a novel probabilistic framework for rigid tracking and segmentation of shape observed from multiple camera most existing method have focused on solving each of these problem individually segmenting the shape assuming surface registration is solved or conversely performing surface registration assuming shape segmentation or kinematic structure is known we assume no prior kinematic or registration knowledge except for an over estimate k of the number of rigidity in the scene instead proposing to simultaneously discover adapt and track it rigid structure on the fly we simultaneously segment and infer pose of rigid subcomponents of a single chosen reference mesh acquired in the sequence we show that this problem can be rigorously cast a a likelihood maximization over rigid component parameter we solve this problem using an expectation maximization algorithm with latent observation assignment to reference vertex and rigid part our experiment on synthetic and real data show the validity of the method robustness to noise and it promising applicability to complex sequence 
we cast the problem of recognizing related category a a unified learning and structured prediction problem with shared body plan when provided with detailed annotation of object and their part these body plan model object in term of shared part and layout simultaneously capturing a variety of category in varied pose we can use these body plan to jointly train many detector in a shared framework with structured learning leading to significant gain for each supervised task using our model we can provide detailed prediction of object and their part for both familiar and unfamiliar category 
most previous visual recognition system simply assume ideal input without real world degradation such a low resolution motion blur and out of focus blur in presence of such unknown degradation the conventional approach first resort to blind image restoration and then feed the restored image into a classifier treating restoration and recognition separately such a straightforward approach however suffers greatly from the defective output of the ill posed blind image restoration in this paper we present a joint blind image restoration and recognition method based on the sparse representation prior to handle the challenging problem of face recognition from low quality image where the degradation model is realistic and totally unknown the sparse representation prior state that the degraded input image if correctly restored will have a good sparse representation in term of the training set which indicates the identity of the test image the proposed algorithm achieves simultaneous restoration and recognition by iteratively solving the blind image restoration in pursuit of the sparest representation for recognition based on such a sparse representation prior we demonstrate that the image restoration task and the recognition task can benefit greatly from each other extensive experiment on face datasets under various degradation are carried out and the result of our joint model show significant improvement over conventional method of treating the two task independently 
category in multi class data are often part of an underlying semantic taxonomy recent work in object classification ha found interesting way to use this taxonomy structure to develop better recognition algorithm here we propose a novel framework to learn similarity metric using the class taxonomy we show that a nearest neighbor classifier using the learned metric get improved performance over the best discriminative method moreover by incorporating the taxonomy our learned metric can also help in some taxonomy specific application we show that the metric can help determine the correct placement of a new category that wa not part of the original taxonomy and can provide effective classification amongst category local to specific subtrees of the taxonomy 
many task in computer vision are formulated a graph matching problem despite the np hard nature of the problem fast and accurate approximation have led to significant progress in a wide range of application learning graph model from observed data however still remains a challenging issue this paper present an effective scheme to parameterize a graph model and learn it structural attribute for visual object matching for this we propose a graph representation with histogram based attribute and optimize them to increase the matching accuracy experimental evaluation on synthetic and real image datasets demonstrate the effectiveness of our approach and show significant improvement in matching accuracy over graph with pre defined structure 
supervised method for learning an embedding aim to map high dimensional image to a space in which perceptually similar observation have high measurable similarity most approach rely on binary similarity typically defined by class membership where label are expensive to obtain and or difficult to define in this paper we propose crowd sourcing similar image by soliciting human imitation we exploit temporal coherence in video to generate additional pairwise graded similarity between the user contributed imitation we introduce two method for learning nonlinear invariant mapping that exploit graded similarity we learn a model that is highly effective at matching people in similar pose it exhibit remarkable invariance to identity clothing background lighting shift and scale 
in this paper we present a novel intrinsic image recovery approach using optimization our approach is based on the assumption of in a local window in natural image our method adopts a premise that neighboring pixel in a local window of a single image having similar intensity value should have similar reflectance value thus the intrinsic image decomposition is formulated by optimizing an energy function with adding a weighting constraint to the local image property in order to improve the intrinsic image extraction result we specify local constrain cue by integrating the user stroke in our energy formulation including constant reflectance constant illumination and fixed illumination brush our experimental result demonstrate that our approach achieves a better recovery of intrinsic reflectance and illumination component than by previous approach 
in this paper we present a new concept of building a morph able model directly from photo on the internet morph able model have shown very impressive result more than a decade ago and could potentially have a huge impact on all aspect of face modeling and recognition one of the challenge however is to capture and register d laser scan of large number of people and facial expression nowadays there are enormous amount of face photo on the internet large portion of which ha semantic label we propose a framework to build a morph able model directly from photo the framework includes dense registration of internet photo a well a new single view shape reconstruction and modification algorithm 
spatially discrete markov random field mrfs and spatially continuous variational approach are ubiquitous in low level vision including image restoration segmentation optical flow and stereo even though both family of approach are fairly similar on an intuitive level they are frequently seen a being technically rather distinct since they operate on different domain in this paper we explore their connection and develop a direct rigorous link with a particular emphasis on first order regularizers by representing spatially continuous function a linear combination of finite element with local support and performing explicit integration of the variational objective we derive mrf potential that make the resulting mrf energy equivalent to the variational energy functional in contrast to previous attempt we provide an explicit connection for modern non quadratic regularizers and also integrate the data term the established connection open certain class of mrfs to spatially continuous interpretation and variational formulation to a broad range of probabilistic learning and inference algorithm 
surface registration play a fundamental role in many application in computer vision and aim at finding a one to one correspondence between surface conformal mapping based surface registration method conformally map d d surface onto d canonical domain and perform the matching on the d plane this registration framework reduces dimensionality and the result is intrinsic to riemannian metric and invariant under isometric deformation however conformal mapping will be affected by inconsistent boundary and non isometric deformation of surface in this work we quantify the effect of boundary variation and non isometric deformation to conformal mapping and give the theoretical upper bound for the distortion of conformal mapping under these two factor besides giving the thorough theoretical proof of the theorem we verified them by concrete experiment using d human facial scan with dynamic expression and varying boundary furthermore we used the distortion estimate for reducing search range in feature matching of surface registration application the experimental result are consistent with the theoretical prediction and also demonstrate the performance improvement in feature tracking 
we propose a generalized gaussian process model ggpm which is a unifying framework that encompasses many existing gaussian process gp model such a gp regression classification and counting in the ggpm framework the observation likelihood of the gp model is itself parameterized using the exponential family distribution by deriving approximate inference algorithm for the generalized gp model we are able to easily apply the same algorithm to all other gp model novel gp model are created by changing the parameterization of the likelihood function which greatly simplifies their creation for task specific output domain we also derive a closed form efficient taylor approximation for inference on the model and draw interesting connection with other model specific closed form approximation finally using the ggpm we create several new gp model and show their efficacy in building task specific gp model for computer vision 
among image segmentation algorithm there are two major group a method assuming known appearance model and b method estimating appearance model jointly with segmentation typically the first group optimizes appearance log likelihood in combination with some spacial regularization this problem is relatively simple and many method guarantee globally optimal result the second group treat model parameter a additional variable transforming simple segmentation energy into high order np hard functionals zhu yuille chan vese grab cut etc it is known that such method indirectly minimize the appearance overlap between the segment we propose a new energy term explicitly measuring l distance between the object and background appearance model that can be globally maximized in one graph cut we show that in many application our simple term make np hard segmentation functionals unnecessary our one cut algorithm effectively replaces approximate iterative optimization technique based on block coordinate descent 
data driven dictionary have produced state of the art result in various classification task however when the target data ha a different distribution than the source data the learned sparse representation may not be optimal in this paper we investigate if it is possible to optimally represent both source and target by a common dictionary specifically we describe a technique which jointly learns projection of data in the two domain and a latent dictionary which can succinctly represent both the domain in the projected low dimensional space an efficient optimization technique is presented which can be easily kernelized and extended to multiple domain the algorithm is modified to learn a common discriminative dictionary which can be further used for classification the proposed approach doe not require any explicit correspondence between the source and target domain and show good result even when there are only a few label available in the target domain various recognition experiment show that the method performs on par or better than competitive state of the art method 
we present a novel algorithm for estimating the broad d geometric structure of outdoor video scene leveraging spatio temporal video segmentation we decompose a dynamic scene captured by a video into geometric class based on prediction made by region classifier that are trained on appearance and motion feature by examining the homogeneity of the prediction we combine prediction across multiple segmentation hierarchy level alleviating the need to determine the granularity a priori we built a novel extensive dataset on geometric context of video to evaluate our method consisting of over ground truth annotated outdoor video with over frame to further scale beyond this dataset we propose a semi supervised learning framework to expand the pool of labeled data with high confidence prediction obtained from unlabeled data our system produce an accurate prediction of geometric context of video achieving accuracy across main geometric class 
action recognition in unconstrained situation is a difficult task suffering from massive intra class variation it is made even more challenging when complex d action are projected down to the image plane losing a great deal of information the recent emergence of d data both in broadcast content and commercial depth sensor provides the possibility to overcome this issue this paper present a new dataset for benchmarking action recognition algorithm in natural environment while making use of d information the dataset contains around video clip across class in addition two state of the art action recognition algorithm are extended to make use of the d data and five new interest point detection strategy are also proposed that extend to the d data our evaluation compare all feature descriptor using different type of interest point over a variety of threshold level for the hollywood d dataset we make the dataset including stereo video estimated depth map and all code required to reproduce the benchmark result available to the wider community 
the advantage of gait over other biometrics such a face or fingerprint is that it can operate from a distance and without subject cooperation however this also make gait subject to change in various covariate condition including carrying clothing surface and view angle existing approach attempt to address these condition change by feature selection feature transformation or discriminant subspace learning however they suffer from lack of training sample from each subject can only cope with change in a subset of condition with limited success and are based on the invalid assumption that the covariate condition are known a priori they are thus unable to perform gait recognition under a genuine uncooperative setting we propose a novel approach which cast gait recognition a a bipartite ranking problem and leverage training sample from different class people and even from different datasets this make our approach suitable for recognition under a genuine uncooperative setting and robust against any covariate type a demonstrated by our extensive experiment 
color information play an important role in better understanding of natural scene by at least facilitating discriminating boundary of object or area in this study we propose a new framework for boundary detection in complex natural scene based on the color opponent mechanism of the visual system the red green and blue yellow color opponent channel in the human visual system are regarded a the building block for various color perception task such a boundary detection the proposed framework is a feed forward hierarchical model which ha direct counterpart to the color opponent mechanism involved in from the retina to the primary visual cortex v result show that our simple framework ha excellent ability to flexibly capture both the structured chromatic and achromatic boundary in complex scene 
this paper introduces an automatic method for removing reflection interference when imaging a scene behind a glass surface our approach exploit the subtle change in the reflection with respect to the background in a small set of image taken at slightly different view point key to this idea is the use of sift flow to align the image such that a pixel wise comparison can be made across the input set gradient with variation across the image set are assumed to belong to the reflected scene while constant gradient are assumed to belong to the desired background scene by correctly labelling gradient belonging to reflection or background the background scene can be separated from the reflection interference unlike previous approach that exploit motion our approach doe not make any assumption regarding the background or reflected scene geometry nor requires the reflection to be static this make our approach practical for use in casual imaging scenario our approach is straight forward and produce good result compared with existing method 
we posit that visually descriptive language offer computer vision researcher both information about the world and information about how people describe the world the potential benefit from this source is made more significant due to the enormous amount of language data easily available today we present a system to automatically generate natural language description from image that exploit both statistic gleaned from parsing large quantity of text data and recognition algorithm from computer vision the system is very effective at producing relevant sentence for image it also generates description that are notably more true to the specific image content than previous work 
this paper present the first dynamic d facs data set for facial expression research containing subject performing between and different au both individually and in combination in total the corpus contains au sequence the peak expression frame of each sequence ha been manually facs coded by certified facs expert this provides a ground truth for d facs based au recognition system in order to use this data we describe the first framework for building dynamic d morphable model this includes a novel active appearance model aam based d facial registration and mesh correspondence scheme the approach overcomes limitation in existing method that require facial marker or are prone to optical flow drift we provide the first quantitative assessment of such d facial mesh registration technique and show how our proposed method provides more reliable correspondence 
an approximately euclidean representation of the visible scene can be obtained directly from a range or time of flight camera an uncalibrated binocular system in contrast give only a projective reconstruction of the scene this paper analyzes the geometric mapping between the two representation without requiring an intermediate calibration of the binocular system the mapping can be found by either of two new method one of which requires point correspondence between the range and colour camera and one of which doe not it is shown that these method can be used to reproject the range data into the binocular image which make it possible to associate high resolution colour and texture with each point in the euclidean representation 
traditional image stitching using parametric transforms such a homography only produce perceptually correct composite for planar scene or parallax free camera motion between source frame this limit mosaicing to source image taken from the same physical location in this paper we introduce a smoothly varying affine stitching field which is flexible enough to handle parallax while retaining the good extrapolation and occlusion handling property of parametric transforms our algorithm which jointly estimate both the stitching field and correspondence permit the stitching of general motion source image provided the scene do not contain abrupt protrusion 
this paper address the problem of image alignment using direct intensity based method for affine and homography transformation direct method often employ scale space smoothing gaussian blur of the image to avoid local minimum although it is known that the isotropic blur used is not optimal for some motion model the correct blur kernel have not been rigorously derived for motion model beyond translation in this work we derive blur kernel that result from smoothing the alignment objective function for some common motion model such a affine and homography we show the derived kernel remove poor local minimum and reach lower energy solution in practice 
this paper describes a novel method to acquire depth image using a pair of tof time of flight camera a opposed to approach that filter calibrate or do d reconstruction posterior to the image acquisition we propose to combine the measurement of the two camera at the acquisition level to do so we define a three stage procedure during which we actively modify the infrared lighting of the scene first the two camera emit an infrared signal one after the other stage and and then simultaneously stage assuming the scene is static during the three stage we gather the depth measurement obtained with both camera and define a cost function to optimize the two depth image a quantitative evaluation of the performance of the proposed method for different object and stereo configuration is provided based on a simulation of the tof camera result on real image are also presented both in simulation and real image the stereo tof acquisition produce more accurate depth measurement 
the problem of salient region detection is formulated a the well studied facility location problem from operation research high level prior are combined with low level feature to detect salient region salient region detection is achieved by maximizing a sub modular objective function which maximizes the total similarity i e total profit between the hypothesized salient region center i e facility location and their region element i e client and penalizes the number of potential salient region i e the number of open facility the similarity are efficiently computed by finding a closed form harmonic solution on the constructed graph for an input image the saliency of a selected region is modeled in term of appearance and spatial location by exploiting the sub modularity property of the objective function a highly efficient greedy based optimization algorithm can be employed this algorithm is guaranteed to be at least a e e approximation to the optimum experimental result demonstrate that our approach outperforms several recently proposed saliency detection approach 
in this paper we address two problem in sparse subspace clustering algorithm ssc i e scalability issue and out of sample problem ssc construct a sparse similarity graph for spectral clustering by using l minimization based coefficient ha achieved state of the art result for image clustering and motion segmentation however the time complexity of ssc is proportion to the cubic of problem size such that it is inefficient to apply ssc into large scale setting moreover ssc doe not handle with out of sample data that are not used to construct the similarity graph for each new datum ssc need recalculating the cluster membership of the whole data set which make ssc is not competitive in fast online clustering to address the problem this paper proposes out of sample extension of ssc named a scalable sparse subspace clustering sssc which make ssc feasible to cluster large scale data set the solution of sssc adopts a sampling clustering coding and classifying strategy extensive experimental result on several popular data set demonstrate the effectiveness and efficiency of our method comparing with the state of the art algorithm 
conventional rigid structure from motion sfm address the problem of recovering the camera parameter motion and the d location structure of scene point given observed d image feature point in this paper we propose a new formulation called semantic structure from motion ssfm in addition to the geometrical constraint provided by sfm ssfm take advantage of both semantic and geometrical property associated with object in the scene fig these property allow u to recover not only the structure and motion but also the d location pose and category of object in the scene we cast this problem a a max likelihood problem where geometry camera point object and semantic information object class are simultaneously estimated the key intuition is that in addition to image feature the measurement of object across view provide additional geometrical constraint that relate camera and scene parameter these constraint make the geometry estimation process more robust and in turn make object detection more accurate our framework ha the unique ability to i estimate camera pose only from object detection ii enhance camera pose estimation compared to feature point based sfm algorithm iii improve object detection given multiple un calibrated image compared to independently detecting object in single image extensive quantitative result on three datasets lidar car street view pedestrian and kinect office desktop verify our theoretical claim 
we propose a novel algorithm to detect occlusion for visual tracking through learning with observation likelihood in our technique target is divided into regular grid cell and the state of occlusion is determined for each cell using a classifier each cell in the target is associated with many small patch and the patch likelihood observed during tracking construct a feature vector which is used for classification since the occlusion is learned with patch likelihood instead of patch themselves the classifier is universally applicable to any video or object for occlusion reasoning our occlusion detection algorithm ha decent performance in accuracy which is sufficient to improve tracking performance significantly the proposed algorithm can be combined with many generic tracking method and we adopt l minimization tracker to test the performance of our framework the advantage of our algorithm is supported by quantitative and qualitative evaluation and successful tracking and occlusion reasoning result are illustrated in many challenging video sequence 
we introduce a compact topical descriptor to learn a compact yet discriminative image signature from the reference image corpus this descriptor is deployed over the well used bag of word image histogram with two merit over the traditional topical feature first we propose to directly control the topical sparsity to achieve the descriptor compactness second we ensure the descriptor discriminability by minimizing the bag of word reconstruction error during the topical histogram encoding to this end we have a generative viewpoint of the topical feature extraction which is estimated a a sparse map estimation over the original bag of word we learn such estimation by a bi convex optimization iterating between both hierarchical sparse coding from word to topical histogram and dictionary learning of the corresponding word to topic transform especially supervised label such a image ranking list can be also incorporated into our descriptor learning paradigm we quantize our performance in both im agenet k and nu wide with comparison to bag of word lda minibof and aggregated local descriptor in practice we also implement our descriptor for a low bit rate mobile visual search application i e sending compact descriptor instead of the image to reduce the query delivery latency our descriptor ha significantly outperformed the state of the art compact descriptor by quantitative evaluation over million reference image 
we introduce three dimensional kaleidoscopic imaging a promising alternative for recording multi view imagery the main limitation of multi view reconstruction technique is the limited number of view that are available from multi camera system especially for dynamic scene our new system is based on imaging an object inside a kaleidoscopic mirror system we show that this approach can generate a large number of high quality view well distributed over the hemisphere surrounding the object in a single shot in comparison to existing multi view system our method offer a number of advantage it is possible to operate with a single camera the individual view are perfectly synchronized and they have the same radiometric and colorimetric property we describe the setup both theoretically and provide method for a practical implementation enabling interfacing to standard multi view algorithm for further processing is an important goal of our technique 
we propose a novel tracking framework called visual tracker sampler that track a target robustly by searching for the appropriate tracker in each frame since the real world tracking environment varies severely over time the tracker should be adapted or newly constructed depending on the current situation to do this our method obtains several sample of not only the state of the target but also the tracker themselves during the sampling process the tracker are efficiently sampled using the markov chain monte carlo method from the predefined tracker space by proposing new appearance model motion model state representation type and observation type which are the basic important component of visual tracker then the sampled tracker run in parallel and interact with each other while covering various target variation efficiently the experiment demonstrates that our method track target accurately and robustly in the real world tracking environment and outperforms the state of the art tracking method 
a new data structure for efficient similarity search in very large dataseis of high dimensional vector is introduced this structure called the inverted multi index generalizes the inverted index idea by replacing the standard quantization within inverted index with product quantization for very similar retrieval complexity and preprocessing time inverted multi index achieve a much denser subdivision of the search space compared to inverted index while retaining their memory efficiency our experiment with large dataseis of sift and gist vector demonstrate that because of the denser subdivision inverted multi index are able to return much shorter candidate list with higher recall augmented with a suitable reranking procedure multi index were able to improve the speed of approximate nearest neighbor search on the dataset of billion sift vector by an order of magnitude compared to the best previously published system while achieving better recall and incurring only few percent of memory overhead 
we investigate human interest in photo based on our own and others psychophysical experiment we identify various cue for interestingness namely aesthetic unusualness and general preference for the ranking of retrieved image interestingness show to be more appropriate than cue proposed earlier interestingness is correlated with what people believe they will remember this is opposed to actual memorability which is uncorrelated to both we introduce a set of feature computationally capturing the three main aspect of visual interestingness and build an interestingness predictor from them it performance is shown on three datasets with varying context reflecting the prior knowledge of the viewer 
although the scale of isotropic visual element such a blob and interest point e g sift ha been well studied and adopted in various application how to determine the scale of anisotropic element such a edge is still an open problem in this paper we study the scale of edge and try to answer two question what is the scale of edge and how to calculate it from the point of human cognition and physical interpretation we illustrate the existence of the scale of edge and provide a quantitative definition then an automatic edge scale selection approach is proposed finally a cognitive experiment is conducted to validate the rationality of the detected scale moreover the importance of identifying the scale of edge is also shown in application such a boundary detection and hierarchical edge parsing 
although action recognition in video is widely studied current method often fail on real world datasets many recent approach improve accuracy and robustness to cope with challenging video sequence but it is often unclear what affect the result most this paper attempt to provide insight based on a systematic performance evaluation using thoroughly annotated data of human action we annotate human joint for the hmdb dataset j hmdb this annotation can be used to derive ground truth optical flow and segmentation we evaluate current method using this dataset and systematically replace the output of various algorithm with ground truth this enables u to discover what is important for example should we work on improving flow algorithm estimating human bounding box or enabling pose estimation in summary we find that high level pose feature greatly outperform low mid level feature in particular pose over time is critical but current pose estimation algorithm are not yet reliable enough to provide this information we also find that the accuracy of a top performing action recognition framework can be greatly increased by refining the underlying low mid level feature this suggests it is important to improve optical flow and human detection algorithm our analysis and j hmdb dataset should facilitate a deeper understanding of action recognition algorithm 
we propose a method of clustering image that combine algorithmic and human input an algorithm provides u with pairwise image similarity we then actively obtain selected more accurate pairwise similarity from human a novel method is developed to choose the most useful pair to show a person obtaining constraint that improve clustering in a clustering assignment element in each data pair are either in the same cluster or in different cluster we simulate inverting these pairwise relation and see how that affect the overall clustering we choose a pair that maximizes the expected change in the clustering the proposed algorithm ha high time complexity so we also propose a version of this algorithm that is much faster and exactly replicates our original algorithm we further improve run time by adding heuristic and show that these do not significantly impact the effectiveness of our method we have run experiment in two different domain namely leaf image and face image and show that clustering performance can be improved significantly 
scene labeling research ha mostly focused on outdoor scene leaving the harder case of indoor scene poorly understood microsoft kinect dramatically changed the landscape showing great potential for rgb d perception color depth our main objective is to empirically understand the promise and challenge of scene labeling with rgb d we use the nyu depth dataset a collected and analyzed by silberman and fergus for rgb d feature we adapt the framework of kernel descriptor that convert local similarity kernel to patch descriptor for contextual modeling we combine two line of approach one using a superpixel mrf and the other using a segmentation tree we find that kernel descriptor are very effective in capturing appearance rgb and shape d similarity both superpixel mrf and segmentation tree are useful in modeling context and the key to labeling accuracy is the ability to efficiently train and test with large scale data we improve labeling accuracy on the nyu dataset from to we also apply our approach to image only scene labeling and improve the accuracy on the stanford background dataset from to 
object co detection aim at simultaneous detection of object of the same category from a pool of related image by exploiting consistent visual pattern present in candidate object in the image the related image set may contain a mixture of annotated object and candidate object generated by automatic detector co detection differs from the conventional object detection paradigm in which detection over each test image is determined one by one independently without taking advantage of common pattern in the data pool in this paper we propose a novel robust approach to dramatically enhance co detection by extracting a shared low rank representation of the object instance in multiple feature space the idea is analogous to that of the well known robust pca cite rpca but ha not been explored in object co detection so far the representation is based on a linear reconstruction over the entire data set and the low rank approach enables effective removal of noisy and outlier sample the extracted low rank representation can be used to detect the target object by spectral clustering extensive experiment over diverse benchmark datasets demonstrate consistent and significant performance gain of the proposed method over the state of the art object co detection method and the generic object detection method without co detection formulation 
accurate matching of local feature play an essential role in visual object search instead of matching individual feature separately using the spatial context e g bundling a group of co located feature into a visual phrase ha shown to enable more discriminative matching despite previous work it remains a challenging problem to extract appropriate spatial context for matching we propose a randomized approach to deriving visual phrase in the form of spatial random partition by averaging the matching score over multiple randomized visual phrase our approach offer three benefit the aggregation of the matching score over a collection of visual phrase of varying size and shape provides robust local matching object localization is achieved by simple thresholding on the voting map which is more efficient than subimage search our algorithm lends itself to easy parallelization and also allows a flexible trade off between accuracy and speed by adjusting the number of partition time both theoretical study and experimental comparison with the state of the art method validate the advantage of our approach 
following the success of hashing method for multidimensional indexing more and more work are interested in embedding visual feature space in compact hash code such approach are not an alternative to using index structure but a complementary way to reduce both the memory usage and the distance computation cost several data dependent hash function have notably been proposed to closely fit data distribution and provide better selectivity than usual random projection such a lsh however improvement occur only for relatively small hash code size up to or bit a discussed in the paper this is mainly due to the lack of independence between the produced hash function we introduce a new hash function family that attempt to solve this issue in any kernel space rather than boosting the collision probability of close point our method focus on data scattering by training purely random split of the data regardless the closeness of the training sample it is indeed possible to generate consistently more independent hash function on the other side the use of large margin classifier allows to maintain good generalization performance experiment show that our new random maximum margin hashing scheme rmmh outperforms four state of the art hashing method notably in kernel space 
in camera with radial distortion straight line in space are in general mapped to curve in the image although epipolar geometry also get distorted there is a set of special epipolar line that remain straight namely those that go through the distortion center by finding these straight epipolar line in camera pair we can obtain constraint on the distortion center s without any calibration object or plumb line assumption in the scene although this hold for all radial distortion model we conceptually prove this idea using the division distortion model and the radial fundamental matrix which allow for a very simple closed form solution of the distortion center from two view same distortion or three view different distortion the non iterative nature of our approach make it immune to local minimum and allows finding the distortion center also for cropped image or those where no good prior exists besides this we give comprehensive relation between different undistortion model and discus advantage and drawback 
multi view structure from motion sfm estimate the position and orientation of picture in a common d coordinate frame when view are treated incrementally this external calibration can be subject to drift contrary to global method that distribute residual error evenly we propose a new global calibration approach based on the fusion of relative motion between image pair we improve an existing method for robustly computing global rotation we present an efficient a contrario trifocal tensor estimation method from which stable and precise translation direction can be extracted we also define an efficient translation registration method that recovers accurate camera position these component are combined into an original sfm pipeline our experiment show that on most datasets it outperforms in accuracy other existing incremental and global pipeline it also achieves strikingly good running time it is about time faster than the other global method we could compare to and a fast a the best incremental method more importantly it feature better scalability property 
in this paper we focus on face clustering in video given the detected face from real world video we partition all face into k disjoint cluster different from clustering on a collection of facial image the face from video are organized a face track and the frame index of each face is also provided a a result many pair wise constraint between face can be easily obtained from the temporal and spatial knowledge of the face track these constraint can be effectively incorporated into a generative clustering model based on the hidden markov random field hmrfs within the hmrf model the pair wise constraint are augmented by label level and constraint level local smoothness to guide the clustering process the parameter for both the unary and the pair wise potential function are learned by the simulated field algorithm and the weight of constraint can be easily adjusted we further introduce an efficient clustering framework specially for face clustering in video considering that face in adjacent frame of the same face track are very similar the framework is applicable to other clustering algorithm to significantly reduce the computational cost experiment on two face data set from real world video demonstrate the significantly improved performance of our algorithm over state of the art algorithm 
in this paper we introduce visual phrase complex visual composite like a person riding a horse visual phrase often display significantly reduced visual complexity compared to their component object because the appearance of those object can change profoundly when they participate in relation we introduce a dataset suitable for phrasal recognition that us familiar pascal object category and demonstrate significant experimental gain resulting from exploiting visual phrase we show that a visual phrase detector significantly outperforms a baseline which detects component object and reason about relation even though visual phrase training set tend to be smaller than those for object we argue that any multi class detection system must decode detector output to produce final result this is usually done with non maximum suppression we describe a novel decoding procedure that can account accurately for local context without solving difficult inference problem we show this decoding procedure outperforms the state of the art finally we show that decoding a combination of phrasal and object detector produce real improvement in detector result 
this paper introduces a bundle adjustment ba method that obtains accurate structure and motion from rolling shutter r video sequence rsba when a classical ba algorithm process a rolling shutter video the resultant camera trajectory is brittle and complete failure are not uncommon we exploit the temporal continuity of the camera motion to define residual of image point trajectory with respect to the camera trajectory we compare the camera trajectory from rsba to those from classical ba and from classical ba on rectified video the comparison are done on real video sequence from an iphone with ground truth obtained from a global shutter camera rigidly mounted to the iphone compared to classical ba the rolling shutter model requires just six extra parameter it also degrades the sparsity of the system jacobian slightly but a we demonstrate the increase in computation time is moderate decisive advantage are that rsba succeeds in case where competing method diverge and consistently produce more accurate result 
rolling shutter r camera are used across a wide range of consumer electronic device from smart phone to high end camera it is well known that if a r camera is used with a moving camera or scene significant image distortion are introduced the quality or even success of structure from motion on rolling shutter image requires the usual intrinsic parameter such a focal length and distortion coefficient a well a accurate modelling of the shutter timing the current state of the art technique for calibrating the shutter timing requires specialised hardware we present a new method that only requires video of a known calibration pattern experimental result on over real datasets show that our method is more accurate than the current state of the art 
model free tracker can track arbitrary object based on a single bounding box annotation of the object whilst the performance of model free tracker ha recently improved significantly simultaneously tracking multiple object with similar appearance remains very hard in this paper we propose a new multi object model free tracker based on tracking by detection that resolve this problem by incorporating spatial constraint between the object the spatial constraint are learned along with the object detector using an online structured svm algorithm the experimental evaluation of our structure preserving object tracker spot reveals significant performance improvement in multi object tracking we also show that spot can improve the performance of single object tracker by simultaneously tracking different part of the object 
for scene understanding one popular approach ha been to model the object object relationship in this paper we hypothesize that such relationship are only an artifact of certain hidden factor such a human for example the object monitor and keyboard are strongly spatially correlated only because a human type on the keyboard while watching the monitor our goal is to learn this hidden human context i e the human object relationship and also use it a a cue for labeling the scene we present infinite factored topic model iftm where we consider a scene a being generated from two type of topic human configuration and human object relationship this enables our algorithm to hallucinate the possible configuration of the human in the scene parsimoniously given only a dataset of scene containing object but not human we show that our algorithm can recover the human object relationship we then test our algorithm on the task of attribute and object labeling in d scene and show consistent improvement over the state of the art 
strong ambient illumination severely degrades the performance of structured light based technique this is especially true in outdoor scenario where the structured light source have to compete with sunlight whose power is often order of magnitude larger than the projected light in this paper we propose the concept of light concentration to overcome strong ambient illumination our key observation is that given a fixed light power budget it is always better to allocate it sequentially in several portion of the scene a compared to spreading it over the entire scene at once for a desired level of accuracy we show that by distributing light appropriately the proposed approach requires order lower acquisition time than existing approach our approach is illumination adaptive a the optimal light distribution is determined based on a measurement of the ambient illumination level since current light source have a fixed light distribution we have built a prototype light source that support flexible light distribution by controlling the scanning speed of a laser scanner we show several high quality d scanning result in a wide range of outdoor scenario the proposed approach will benefit d vision system that need to operate outdoors under extreme ambient illumination level on a limited time and power budget 
drawing a box around an intended segmentation target ha become both a popular user interface and a common output for learning driven detection algorithm despite the ubiquity of using a box to define a segmentation target it is unclear in the literature whether a box is sufficient to define a unique segmentation or whether segmentation from a box is ill posed without higher level semantic knowledge of the intended target we examine this issue by conducting a study of subject who are asked to segment a boxed target in a set of real image for which they have no semantic attachment we find that the subject do indeed perceive and trace almost the same segmentation a each other despite the inhomogeneity of the image intensity irregular shape of the segmentation target and weakness of the target boundary since the subject produce the same segmentation we conclude that the problem is well posed and then provide a new segmentation algorithm from a box which achieves result close to the perceived target 
we address the problem of automatic d segmentation of a stack of electron microscopy section of brain tissue unlike previous effort where the reconstruction is usually done on a section to section basis or by the agglomerative clustering of d segment we leverage information from the entire volume to obtain a globally optimal d segmentation to do this we formulate the segmentation a the solution to a fusion problem we first enumerate multiple possible d segmentation for each section in the stack and a set of d link that may connect segment across consecutive section we then identify the fusion of segment and link that provide the most globally consistent segmentation of the stack we show that this two step approach of pre enumeration and posterior fusion yield significant advantage and provides state of the art reconstruction result finally a part of this method we also introduce a robust rotationally invariant set of feature that we use to learn and enumerate the above d segmentation our feature outperform previous connectomic specific descriptor without relying on a large set of heuristic or manually designed filter bank 
estimating the reflectance and illumination from a single image becomes particularly challenging when the object surface consists of multiple material the key difficulty lie in recovering the reflectance from sparse angular sample while correctly assigning them to different material we tackle this problem by extracting and fully leveraging reflectance prior the idea is to strongly constrain the possible solution so that the recovered reflectance conform with those of real world material we achieve this by modeling the parameter space of a directional statistic brdf model and by extracting an analytical distribution of the subspace that real world material span this is used with other prior in a layered mrf based formulation that model material region and their spatially varying reflectance with continuous latent layer the material region and their reflectance and the direction and strength of a single point source are jointly estimated we demonstrate the effectiveness of the method on real and synthetic image 
recent year have witnessed the growing popularity of hashing in large scale vision problem it ha been shown that the hashing quality could be boosted by leveraging supervised information into hash function learning however the existing supervised method either lack adequate performance or often incur cumbersome model training in this paper we propose a novel kernel based supervised hashing model which requires a limited amount of supervised information i e similar and dissimilar data pair and a feasible training cost in achieving high quality hashing the idea is to map the data to compact binary code whose hamming distance are minimized on similar pair and simultaneously maximized on dissimilar pair our approach is distinct from prior work by utilizing the equivalence between optimizing the code inner product and the hamming distance this enables u to sequentially and efficiently train the hash function one bit at a time yielding very short yet discriminative code we carry out extensive experiment on two image benchmark with up to one million sample demonstrating that our approach significantly outperforms the state of the art in searching both metric distance neighbor and semantically similar neighbor with accuracy gain ranging from to 
we describe a simple model for parsing pedestrian based on shape our model assembles candidate part from an oversegmentation of the image and match them to a library of exemplar our matching us a hierarchical decomposition into a variable number of part and computes score on partial matchings in order to prune the search space of candidate segment simple constraint enforce consistent layout of part because our model is shape based it generalizes well we use exemplar from a controlled dataset of pose but achieve good test performance on unconstrained image of pedestrian in street scene we demonstrate result of parsing detection returned from a standard scanning window pedestrian detector and use the resulting parse to perform viewpoint prediction and detection re scoring 
in this paper we introduce a subcategory aware object classification framework to boost category level object classification performance motivated by the observation of considerable intra class diversity and inter class ambiguity in many current object classification datasets we explicitly split data into subcategories by ambiguity guided subcategory mining we then train an individual model for each subcategory rather than attempt to represent an object category with a monolithic model more specifically we build the instance affinity graph by combining both intra class similarity and inter class ambiguity visual subcategories which correspond to the dense sub graph are detected by the graph shift algorithm and seamlessly integrated into the state of the art detection assisted classification framework finally the response from subcategory model are aggregated by subcategory aware kernel regression the extensive experiment over the pascal voc and pascal voc database show the state of the art performance from our framework 
online dictionary learning is particularly useful for processing large scale and dynamic data in computer vision it however face the major difficulty to incorporate robust function rather than the square data fitting term to handle outlier in training data in this paper we propose a new online framework enabling the use of sparse data fitting term in robust dictionary learning notably enhancing the usability and practicality of this important technique extensive experiment have been carried out to validate our new framework 
in this paper we address a challenging image segmentation problem called multiple foreground cosegmentation mfc which concern a realistic scenario in general webuser photo set where a finite number of k foreground of interest repeatedly occur cross the entire photo set but only an unknown subset of them is presented in each image this contrast the classical cosegmentation problem dealt with by most existing algorithm which assume a much simpler but le realistic setting where the same set of foreground recurs in every image we propose a novel optimization method for mfc which make no assumption on foreground configuration and doe not suffer from the aforementioned limitation while still leverage all the benefit of having co occurring or partially recurring content across image our method build on an iterative scheme that alternate between a foreground modeling module and a region assignment module both highly efficient and scalable in particular our approach is flexible enough to integrate any advanced region classifier for foreground modeling and our region assignment employ a combinatorial auction framework that enjoys several intuitively good property such a optimality guarantee and linear complexity we show the superior performance of our method in both segmentation quality and scalability in comparison with other state of the art technique on a newly introduced flickrmfc dataset and the standard imagenet dataset 
in this paper we consider the challenging problem of articulated human pose estimation in still image we observe that despite high variability of the body articulation human motion and activity often simultaneously constrain the position of multiple body part modelling such higher order part dependency seemingly come at a cost of more expensive inference which resulted in their limited use in state of the art method in this paper we propose a model that incorporates higher order part dependency while remaining efficient we achieve this by defining a conditional model in which all body part are connected a priori but which becomes a tractable tree structured pictorial structure model once the image observation are available in order to derive a set of conditioning variable we rely on the poselet based feature that have been shown to be effective for people detection but have so far found limited application for articulated human pose estimation we demonstrate the effectiveness of our approach on three publicly available pose estimation benchmark improving or being on par with state of the art in each case 
estimating dense d scene flow from stereo sequence remains a challenging task despite much progress in both classical disparity and d optical flow estimation to overcome the limitation of existing technique we introduce a novel model that represents the dynamic d scene by a collection of planar rigidly moving local segment scene flow estimation then amount to jointly estimating the pixel to segment assignment and the d position normal vector and rigid motion parameter of a plane for each segment the proposed energy combine an occlusion sensitive data term with appropriate shape motion and segmentation regularizers optimization proceeds in two stage starting from an initial super pixelization we estimate the shape and motion parameter of all segment by assigning a proposal from a set of moving plane then the pixel to segment assignment is updated while holding the shape and motion parameter of the moving plane fixed we demonstrate the benefit of our model on different real world image set including the challenging kitti benchmark we achieve leading performance level exceeding competing d scene flow method and even yielding better d motion estimate than all tested dedicated optical flow technique 
a panoramic stereo or omnistereo pair of image provides depth information from stereo up to degree around a central observer because omnistereo lens or mirror do not yet exist synthesizing omnistereo image requires multiple stereo camera position and baseline orientation recent omnistereo method stitch together many small field of view image called slit which are captured by one or two camera following a circular motion however these method produce omnistereo image for static scene only the situation is much more challenging for dynamic scene since stitching need to occur over both space and time and should synchronize the motion between left and right view a much a possible this paper present the first ever method for synthesizing panoramic stereo video texture the method us full frame rather than slit and us blending across seam rather than smoothing or matching based on graph cut the method produce loopable panoramic stereo video that can be displayed up to degree around a viewer 
we propose an agent based behavioral model of pedestrian to improve tracking performance in realistic scenario in this model we view pedestrian a decision making agent who consider a plethora of personal social and environmental factor to decide where to go next we formulate prediction of pedestrian behavior a an energy minimization on this model two of our main contribution are simple yet effective estimate of pedestrian destination and social relationship group our final contribution is to incorporate these hidden property into an energy formulation that result in accurate behavioral prediction we evaluate both our estimate of destination and grouping a well a our accuracy at prediction and tracking against state of the art behavioral model and show improvement especially in the challenging observational situation of infrequent appearance observation something that might occur in thousand of webcam available on the internet 
the launch of xbox kinect ha built a very successful computer vision product and made a big impact to the gaming industry this shed light onto a wide variety of potential application related to action recognition the accurate estimation of human pose from the depth image is universally a critical step however existing pose estimation system exhibit failure when faced severe occlusion in this paper we propose an exemplar based method to learn to correct the initially estimated pose we learn an inhomogeneous systematic bias by leveraging the exemplar information within specific human action domain our algorithm is illustrated on both joint based skeleton correction and tag prediction in the experiment significant improvement is observed over the contemporary approach including what is delivered by the current kinect system 
while boltzmann machine have been successful at unsupervised learning and density modeling of image and speech data they can be very sensitive to noise in the data in this paper we introduce a novel model the robust boltzmann machine robm which allows boltzmann machine to be robust to corruption in the domain of visual recognition the robm is able to accurately deal with occlusion and noise by using multiplicative gating to induce a scale mixture of gaussians over pixel image denoising and in painting correspond to posterior inference in the robm our model is trained in an unsupervised fashion with unlabeled noisy data and can learn the spatial structure of the occluders compared to standard algorithm the robm is significantly better at recognition and denoising on several face database 
this paper investigates how to boost region based image segmentation by pursuing a new solution to fuse multiple type of image feature a collaborative image segmentation framework called multi task low rank affinity pursuit is presented for such a purpose given an image described with multiple type of feature we aim at inferring a unified affinity matrix that implicitly encodes the segmentation of the image this is achieved by seeking the sparsity consistent low rank affinity from the joint decomposition of multiple feature matrix into pair of sparse and low rank matrix the latter of which is expressed a the production of the image feature matrix and it corresponding image affinity matrix the inference process is formulated a a constrained nuclear norm and l norm minimization problem which is convex and can be solved efficiently with the augmented lagrange multiplier method compared to previous method which are usually based on a single type of feature the proposed method seamlessly integrates multiple type of feature to jointly produce the affinity matrix within a single inference step and produce more accurate and reliable segmentation result experiment on the msrc dataset and berkeley segmentation dataset well validate the superiority of using multiple feature over single feature and also the superiority of our method over conventional method for feature fusion moreover our method is shown to be very competitive while comparing to other state of the art method 
both appearance and shape play important role in object localization and object detection in this paper we propose a new superedge grouping method for object localization by incorporating both boundary shape and appearance information of object compared with the previous edge grouping method the proposed method doe not subdivide detected edge into short edgels before grouping such long unsubdivided superedges not only facilitate the incorporation of object shape information into localization but also increase the robustness against image noise and reduce computation we identify and address several important problem in achieving the proposed superedge grouping including gap filling for connecting superedges accurate encoding of region based information into individual edge and the incorporation of object shape information into object localization in this paper we use the bag of visual word technique to quantify the region based appearance feature of the object of interest we find that the proposed method by integrating both boundary and region information can produce better localization performance than previous subwindow search and edge grouping method on most of the object category from the voc database experiment also show that the proposed method is roughly time faster than the previous edge grouping method 
a new method for highly efficient min hash generation for document collection is proposed it exploit the inverted file structure which is available in many application based on a bag or a set of word fast min hash generation is important in application such a image clustering where good recall and precision requires a large number of min hash signature using the set of word represenation the novel exact min hash generation algorithm achieves approximately a fold speed up on two dataset with and image respectively we also propose an approximate min hash assignment process which reach a more than fold speed up at the cost of missing about of match we also experimentally show that the method generalizes to other modality with significantly different statistic 
in this paper we propose a new and effective scheme for applying frequent itemset mining to image classification task we refer to the new set of obtained pattern a frequent local histogram or flhs during the construction of the flhs we pay special attention to keep all the local histogram information during the mining process and to select the most relevant reduced set of flh pattern for classification the careful choice of the visual primitive and some proposed extension to exploit other visual cue such a colour or global spatial information allow u to build powerful bag of flh based image representation we show that these bag of flhs are more discriminative than traditional bag of word and yield state of the art result on various image classification benchmark 
the mean is often the most important statistic of a dataset a it provides a single point that summarizes the entire set while the mean is readily defined and computed in euclidean space no commonly accepted solution are currently available in more complicated space such a space of tree structured data in this paper we study the notion of mean both generally in gromov s cat space metric space of non positive curvature but also specifically in the space of tree like shape we prove local existence and uniqueness of mean in such space and discus three different algorithm for computing mean we make an experimental evaluation of the three algorithm through experiment on three different set of data with tree like structure a synthetic dataset a leaf morphology dataset from image and a set of human airway subtrees from medical ct scan this experimental study provides great insight into the behavior of the different method and how they relate to each other more importantly it also provides mathematically well founded tractable and robust average tree this statistic is of utmost importance due to the ever presence of tree like structure in human anatomy e g airway and vascularization system 
in theory the precision of structure from motion estimation is known to increase a camera motion increase in practice larger camera motion induce motion blur particularly in low light where longer exposure are needed if the camera center move during exposure the trajectory trace in a motion blurred image encode the underlying d structure of point and the motion of the camera in this paper we propose an algorithm to explicitly estimate the d structure of point light source and camera motion from a motion blurred image in a low light scene with point light source the algorithm identifies extremal point of the trace mapped out by the point source in the image and classifies them into start and end set each trace is charted out incrementally using local curvature providing correspondence between start and end point we use these correspondence to obtain an initial estimate of the epipolar geometry embedded in a motion blurred image the reconstruction and the d trace are used to estimate the motion of the camera during the interval of capture and multiple view bundle adjustment is applied to refine the estimate 
in this paper we are interested in understanding the semantics of outdoor scene in the context of autonomous driving towards this goal we propose a generative model of d urban scene which is able to reason not only about the geometry and object present in the scene but also about the high level semantics in the form of traffic pattern we found that a small number of pattern is sufficient to model the vast majority of traffic scene and show how these pattern can be learned a evidenced by our experiment this high level reasoning significantly improves the overall scene estimation a well a the vehicle to lane association when compared to state of the art approach 
limiting factor of fast and effective classifier for large set of image are their dependence on the number of image analyzed and the dimensionality of the image representation considering the growing number of image a a given we aim to reduce the image feature dimensionality in this paper we propose reduced linear kernel that use only a portion of the dimension to reconstruct a linear kernel we formulate the search for these dimension a a convex optimization problem which can be solved efficiently different from existing kernel reduction method our reduced kernel are faster and maintain the accuracy benefit from non linear embedding method that mimic non linear svms we show these property on both the scene and pascal voc datasets in addition we demonstrate how our reduced kernel allow to compress fisher vector for use with non linear embeddings leading to high accuracy what is more without using any labeled example the selected and weighed kernel dimension appear to correspond to visually meaningful patch in the image 
this paper address the problem of d motion reconstruction from a series of d projection under low reconstructibility reconstructibility defines the accuracy of a d reconstruction from d projection given a particular trajectory basis d point trajectory and d camera center trajectory reconstructibility accuracy is inherently related to the correlation between point and camera trajectory poor correlation lead to good reconstruction high correlation lead to poor reconstruction unfortunately in most real world situation involving non rigid object e g body camera and point motion are highly correlated i e slow and smooth resulting in poor reconstructibility in this paper we propose a novel approach for d motion reconstruction of non rigid body motion in the presence of real world camera motion specifically we i propose the inclusion of a small number of keyframes in the video sequence from which d coordinate are inferred estimated to circumvent ambiguity between point and camera motion and ii employ a l penalty term to enforce a sparsity constraint on the trajectory basis coefficient so a to ensure our reconstruction are consistent with the natural compressibility of human motion we demonstrate impressive d motion reconstruction for d projection sequence with hitherto low reconstructibility 
in this paper we exploit a novel ranking mechanism that process query sample with noisy label motivated by the practical application of web image search re ranking where the originally highest ranked image are usually posed a pseudo query for subsequent re ranking availing ourselves of the low frequency spectrum of a neighborhood graph built on the sample we propose a graph theoretical framework amenable to noise resistant ranking the proposed framework consists of two component spectral filtering and graph based ranking the former leverage sparse base progressively selected from a pool of smooth eigenvectors of the graph laplacian to reconstruct the noisy label vector associated with the query sample set and accordingly filter out the query sample with le authentic positive label the latter applies a canonical graph ranking algorithm with respect to the filtered query sample set quantitative image re ranking experiment carried out on two public web image database bear out that our re ranking approach compare favorably with the state of the art and improves web image search engine by a large margin though we harvest the noisy query from the top ranked image returned by these search engine 
we seek to obtain a pixel wise segmentation and pose estimation of multiple people in a stereoscopic video this involves challenge such a dealing with unconstrained stereoscopic video non stationary camera and complex indoor and outdoor dynamic scene the contribution of our work are two fold first we develop a segmentation model incorporating person detection pose estimation a well a colour motion and disparity cue our new model explicitly represents depth ordering and occlusion second we introduce a stereoscopic dataset with frame extracted from feature length movie street dance d and pina the dataset contains realistic stereo pair and includes annotation of human pose person bounding box and pixel wise segmentation for hundred of people the dataset is composed of indoor and outdoor scene depicting multiple people with frequent occlusion we demonstrate result on our new challenging dataset a well a on the h view dataset from sheasby et al accv 
this paper address the problem of simultaneous tracking of multiple target in a video we first apply object detector to every video frame pair of detection response from every two consecutive frame are then used to build a graph of tracklets the graph help transitively link the best matching tracklets that do not violate hard and soft contextual constraint between the resulting track we prove that this data association problem can be formulated a finding the maximum weight independent set mwis of the graph we present a new polynomial time mwis algorithm and prove that it converges to an optimum similarity and contextual constraint between object detection used for data association are learned online from object appearance and motion property long term occlusion are addressed by iteratively repeating mwis to hierarchically merge smaller track into longer one our result demonstrate advantage of simultaneously accounting for soft and hard contextual constraint in multitarget tracking we outperform the state of the art on the benchmark datasets 
existing mobile image instance retrieval application assume a network based usage where image feature are sent to a server to query an online visual database in this scenario there are no restriction on the size of the visual database this paper however examines how to perform this same task offline where the entire visual index must reside on the mobile device itself within a small memory footprint such solution have application on location recognition and product recognition mobile instance retrieval requires a significant reduction in the visual index size to achieve this we describe a set of strategy that can reduce the visual index up to time compared to a standard instance retrieval implementation found on desktop or server while our proposed reduction step affect the overall mean average precision map they are able to maintain a good precision for the top k result p k we argue that for such offline application maintaining a good p k is sufficient the effectiveness of this approach is demonstrated on several standard database a working application designed for a remote historical site is also presented this application is able to reduce an image index structure to mb while providing a precision of for p and for p 
we propose a framework for large scale learning and annotation of structured model the system interleaf interactive labeling where the current model is used to semi automate the labeling of a new example and online learning where a newly labeled example is used to update the current model parameter this framework is scalable to large datasets and complex image model and is shown to have excellent theoretical and practical property in term of train time optimality guarantee and bound on the amount of annotation effort per image we apply this framework to part based detection and introduce a novel algorithm for interactive labeling of deformable part model the labeling tool update and display in real time the maximum likelihood location of all part a the user click and drag the location of one or more part we demonstrate that the system can be used to efficiently and robustly train part and pose detector on the cub bird a challenging dataset of bird in unconstrained pose and environment 
in this paper an automatic approach for d pose reconstruction from a single image is proposed the presence of human body articulation hallucinated part and cluttered background lead to ambiguity during the pose inference which make the problem non trivial researcher have explored various method based on motion and shading in order to reduce the ambiguity and reconstruct the d pose the key idea of our algorithm is to impose both kinematic and orientation constraint the former is imposed by projecting a d model onto the input image and pruning the part which are incompatible with the anthropomorphism the latter is applied by creating synthetic view via regressing the input view to multiple oriented view after applying the constraint the d model is projected onto the initial and synthetic view which further reduces the ambiguity finally we borrow the direction of the unambiguous part from the synthetic view to the initial one which result in the d pose quantitative experiment are performed on the human eva i dataset and qualitatively on unconstrained image from the image parse dataset the result show the robustness of the proposed approach to accurately reconstruct the d pose form a single image 
we present an approach for modeling the human body by sum of spatial gaussians sog allowing u to perform fast and high quality markerless motion capture from multi view video sequence the sog model is equipped with a color model to represent the shape and appearance of the human and can be reconstructed from a sparse set of image similar to the human body we also represent the image domain a sog that model color consistent image blob based on the sog model of the image and the human body we introduce a novel continuous and differentiable model to image similarity measure that can be used to estimate the skeletal motion of a human at frame per second even for many camera view in our experiment we show that our method which doe not rely on silhouette or training data offer an good balance between accuracy and computational cost 
data sparsity ha been a thorny issue for manifold based image synthesis and in this paper we address this critical problem by leveraging idea from transfer learning specifically we propose method based on generating auxiliary data in the form of synthetic sample using transformation of the original sparse sample to incorporate the auxiliary data we propose a weighted data synthesis method which adaptively selects from the generated sample for inclusion during the manifold learning process via a weighted iterative algorithm to demonstrate the feasibility of the proposed method we apply it to the problem of face image synthesis from sparse sample compared with existing method the proposed method show encouraging result with good performance improvement 
many application involve multiple modality such a text and image that describe the problem of interest in order to leverage the information present in all the modality one must model the relationship between them while some technique have been proposed to tackle this problem they either are restricted to word describing visual object only or require full correspondence between the different modality a a consequence they are unable to tackle more realistic scenario where a narrative text is only loosely related to an image and where only a few image text pair are available in this paper we propose a model that address both these challenge our model can be seen a a markov random field of topic model which connects the document based on their similarity a a consequence the topic learned with our model are shared across connected document thus encoding the relation between different modality we demonstrate the effectiveness of our model for image retrieval from a loosely related text 
this paper proposes novel spectral method for learning latent semantics i e high level feature from a large vocabulary of abundant mid level feature i e visual keywords which can help to bridge the semantic gap in the challenging task of action recognition to discover the manifold structure hidden among mid level feature we develop spectral embedding approach based on graph and hypergraphs without the need to tune any parameter for graph construction which is a key step of manifold learning in particular the traditional graph are constructed by linear reconstruction with sparse coding in the new embedding space we learn high level latent semantics automatically from abundant mid level feature through spectral clustering the learnt latent semantics can be readily used for action recognition with svm by defining a histogram intersection kernel different from the traditional latent semantic analysis based on topic model our two spectral method for semantic learning can discover the manifold structure hidden among mid level feature which result in compact but discriminative high level feature the experimental result on two standard action datasets have shown the superior performance of our spectral method 
feature extraction deformation handling occlusion handling and classification are four important component in pedestrian detection existing method learn or design these component either individually or sequentially the interaction among these component is not yet well explored this paper proposes that they should be jointly learned in order to maximize their strength through cooperation we formulate these four component into a joint deep learning framework and propose a new deep network architecture by establishing automatic mutual interaction among component the deep model achieves a reduction in the average miss rate compared with the current best performing pedestrian detection approach on the largest caltech benchmark dataset 
we tackle the problem of jointly increasing the spatial resolution and apparent measurement accuracy of an input low resolution noisy and perhaps heavily quantized depth map in stark contrast to earlier work we make no use of ancillary data like a color image at the target resolution multiple aligned depth map or a database of high resolution depth exemplar instead we proceed by identifying and merging patch correspondence within the input depth map itself exploiting patch wise scene self similarity across depth such a repetition of geometric primitive or object symmetry while the notion of single image super resolution ha successfully been applied in the context of color and intensity image we are to our knowledge the first to present a tailored analogue for depth image rather than reason in term of patch of d pixel a others have before u our key contribution is to proceed by reasoning in term of patch of d point with matched patch pair related by a respective dof rigid body motion in d in support of obtaining a dense correspondence field in reasonable time we introduce a new d variant of patch match a third contribution is a simple yet effective patch up scaling and merging technique which predicts sharp object boundary at the target resolution we show that our result are highly competitive with those of alternative technique leveraging even a color image at the target resolution or a database of high resolution depth exemplar 
we propose a novel multi task learning framework fega mtl for classifying the head pose of a person who move freely in an environment monitored by multiple large field of view surveillance camera a the target person move distortion in facial appearance owing to camera perspective and scale severely impede performance of traditional head pose classification method fega mtl operates on a dense uniform spatial grid and learns appearance relationship across partition a well a partition specific appearance variation for a given head pose to build region specific classifier guided by two graph which a priori model appearance similarity among i grid partition based on camera geometry and ii head pose class the learner efficiently cluster appearance wise related grid partition to derive the optimal partitioning for pose classification upon determining the target s position using a person tracker the appropriate region specific classifier is invoked experiment confirm that fega mtl achieves state of the art classification with few training data 
age invariant face recognition ha received increasing attention due to it great potential in real world application in spite of the great progress in face recognition technique reliably recognizing face across age remains a difficult task the facial appearance of a person change substantially over time resulting in significant intra class variation hence the key to tackle this problem is to separate the variation caused by aging from the person specific feature that are stable specifically we propose a new method called hidden factor analysis hfa this method capture the intuition above through a probabilistic model with two latent factor an identity factor that is age invariant and an age factor affected by the aging process then the observed appearance can be modeled a a combination of the component generated based on these factor we also develop a learning algorithm that jointly estimate the latent factor and the model parameter using an em procedure extensive experiment on two well known public domain face aging datasets morph the largest public face aging database and fgnet clearly show that the proposed method achieves notable improvement over state of the art algorithm 
we formulate a model for multi class object detection in a multi camera environment from our knowledge this is the first time that this problem is addressed taken into account different object class simultaneously given several image of the scene taken from different angle our system estimate the ground plane location of the object from the output of several object detector applied at each viewpoint we cast the problem a an energy minimization modeled with a conditional random field crf instead of predicting the presence of an object at each image location independently we simultaneously predict the labeling of the entire scene our crf is able to take into account occlusion between object and contextual constraint among them we propose an effective iterative strategy that render tractable the underlying optimization problem and learn the parameter of the model with the max margin paradigm we evaluate the performance of our model on several challenging multi camera pedestrian detection datasets namely pet and epfl terrace sequence we also introduce a new dataset in which multiple class of object appear simultaneously in the scene it is here where we show that our method effectively handle occlusion in the multi class case 
user often have very specific visual content in mind that they are searching for the most natural way to communicate this content to an image search engine is to use key word that specify various property or attribute of the content a naive way of dealing with such multi attribute query is the following train a classifier for each attribute independently and then combine their score on image to judge their fit to the query we argue that this may not be the most effective or efficient approach conjunction of attribute often correspond to very characteristic appearance it would thus be beneficial to train classifier that detect these conjunction a a whole but not all conjunction result in such tight appearance cluster so given a multi attribute query which conjunction should we model an exhaustive evaluation of all possible conjunction would be time consuming hence we propose an optimization approach that identifies beneficial conjunction without explicitly training the corresponding classifier it reason about geometric quantity that capture notion similar to intraand inter class variance we exploit a discriminative binary space to compute these geometric quantity efficiently experimental result on two challenging datasets of object and bird show that our proposed approach can improve performance significantly over several strong base line while being an order of magnitude faster than exhaustively searching through all possible conjunction 
in this paper we propose a method for learning a class representation that can return a continuous value for the pose of an unknown class instance using only d data and weak d labeling information our method is based on generative feature model i e regression function learned from local descriptor of the same patch collected under different viewpoint the individual generative model are then clustered in order to create class generative model which form the class representation at run time the pose of the query image is estimated in a maximum a posteriori fashion by combining the regression function belonging to the matching cluster we evaluate our approach on the epfl car dataset and the pointing face dataset experimental result show that our method outperforms by the state of the art in the first dataset and by in the second 
linear subspace learning lsl is a popular approach to image recognition and it aim to reveal the essential feature of high dimensional data e g facial image in a lower dimensional space by linear projection most lsl method compute directly the statistic of original training sample to learn the subspace however these method do not effectively exploit the different contribution of different image component to image recognition we propose a novel lsl approach by sparse coding and feature grouping a dictionary is learned from the training dataset and it is used to sparsely decompose the training sample the decomposed image component are grouped into a more discriminative part mdp and a le discriminative part ldp an unsupervised criterion and a supervised criterion are then proposed to learn the desired subspace where the mdp is preserved and the ldp is suppressed simultaneously the experimental result on benchmark face image database validated that the proposed method outperform many state of the art lsl scheme 
many computer vision problem can be accounted for or properly approximated by linearity and the robust model fitting parameter estimation problem in presence of outlier is actually to find the maximum feasible subsystem maxfs of a set of infeasible linear constraint we propose a deterministic branch and bound method to solve the maxfs problem with guaranteed global optimality it can be used in a wide class of computer vision problem in which the model variable are subject to the unit norm constraint in contrast to the convex and concave relaxation in existing work we introduce a piecewise linear relaxation to build very tight underand over estimator for square term by partitioning variable bound into smaller segment based on this novel relaxation technique our branch and bound method can converge in a few iteration for homogeneous linear system which correspond to some quasi convex problem based on l l norm our method is non iterative and certainly reach the globally optimal solution at the root node by partitioning each variable range into two segment with equal length throughout this work we rely on the so called big m method and successfully avoid potential numerical problem by exploiting proper parametrization and problem structure experimental result demonstrate the stability and efficiency of our proposed method 
the objective of this work is to detect all instance of a class such a cell or people in an image the instance may be partially overlapping and clustered and hence quite challenging for traditional detector which aim at localizing individual instance our approach is to propose a set of candidate region and then select region based on optimizing a global classification score subject to the constraint that the selected region are non overlapping our novel contribution is to extend standard object detection by introducing separate class for tuples of object into the detection process for example our detector can pick a region containing two or three object instance while assigning such region an appropriate label we show that this formulation can be learned within the structured output svm framework and that the inference in such model can be accomplished using dynamic programming on a tree structured region graph furthermore the learning only requires weak annotation a dot on each instance the improvement resulting from the addition of the capability to detect tuples of object is demonstrated on quite disparate data set fluorescence microscopy image and ucsd pedestrian 
in contrast to the current motion segmentation paradigm that assumes independence between the motion subspace we approach the motion segmentation problem by seeking the parsimonious basis set that can represent the data our formulation explicitly look for the overlap between subspace in order to achieve a minimal basis representation this parsimonious basis set is important for the performance of our model selection scheme because the sharing of basis result in saving of model complexity cost we propose the use of affinity propagation based method to determine the number of motion the key lie in the incorporation of a global cost model into the factor graph serving the role of model complexity the introduction of this global cost model requires additional message update in the factor graph we derive an efficient update for the new message associated with this global cost model an important step in the use of affinity propagation is the subspace hypothesis generation we use the row sparse convex proxy solution a an initialization strategy we further encourage the selection of subspace hypothesis with shared basis by integrating a discount scheme that lower the factor graph facility cost based on shared basis we verified the model selection and classification performance of our proposed method on both the original hopkins dataset and the more balanced hopkins dataset 
the inclusion of shape and appearance prior have proven useful for obtaining more accurate and plausible segmentation especially for complex object with multiple part in this paper we augment the popular mum ford shah model to incorporate two important geometrical constraint termed containment and detachment between different region with a specified minimum distance between their boundary our method is able to handle multiple instance of multi part object defined by these geometrical constraint using a single labeling function while maintaining global optimality we demonstrate the utility and advantage of these two constraint and show that the proposed convex continuous method is superior to other state of the art method including it discrete counterpart in term of memory usage and metrication error 
many blind motion deblur method model the motion blur a a spatially invariant convolution process however motion blur caused by the camera movement in d space during shutter time often lead to spatially varying blurring effect over the image in this paper we proposed an efficient two stage approach to remove spatially varying motion blurring from a single photo there are three main component in our approach i a minimization method of estimating region wise blur kernel by using both image information and correlation among neighboring kernel ii an interpolation scheme of constructing pixel wise blur matrix from region wise blur kernel and iii a non blind deblurring method robust to kernel error the experiment showed that the proposed method outperformed the existing software based approach on tested real image 
in this paper we study the salient object detection problem for image we formulate this problem a a binary labeling task where we separate the salient object from the background we propose a set of novel feature including multiscale contrast center surround histogram and color spatial distribution to describe a salient object locally regionally and globally a conditional random field is learned to effectively combine these feature for salient object detection further we extend the proposed approach to detect a salient object from sequential image by introducing the dynamic salient feature we collected a large image database containing ten of thousand of carefully labeled image by multiple user and a video segment database and conducted a set of experiment over them to demonstrate the effectiveness of the proposed approach 
in this paper we address the problem of image retrieval from million of database image we improve the vocabulary tree based approach by introducing contextual weighting of local feature in both descriptor and spatial domain specifically we propose to incorporate efficient statistic of neighbor descriptor both on the vocabulary tree and in the image spatial domain into the retrieval these contextual cue substantially enhance the discriminative power of individual local feature with very small computational overhead we have conducted extensive experiment on benchmark datasets i e the ukbench holiday and our new mobile dataset which show that our method reach state of the art performance with much le computation furthermore the proposed method demonstrates excellent scalability in term of both retrieval accuracy and efficiency on large scale experiment using million image from the imagenet database a distractors 
this paper address the problem of similar image retrieval especially in the setting of large scale datasets with million to billion of image the core novel contribution is an approach that can exploit prior knowledge of a semantic hierarchy when semantic label and a hierarchy relating them are available during training significant improvement over the state of the art in similar image retrieval are attained while some of this advantage come from the ability to use additional information experiment exploring a special case where no additional data is provided show the new approach can still outperform oasis the current state of the art for similarity learning exploiting hierarchical relationship is most important for larger scale problem where scalability becomes crucial the proposed learning approach is fundamentally parallelizable and a a result scale more easily than previous work an additional contribution is a novel hashing scheme for bilinear similarity on vector of probability optionally taking into account hierarchy that is able to reduce the computational cost of retrieval experiment are performed on caltech and the larger imagenet dataset 
an accurate labeling of a multi part complex anatomical structure e g brain is required in order to compare data across image for spatial analysis it can be achieved by fitting an object specific geometric atlas that is constructed using a partitioned high resolution deformable mesh and tagging each of it polygon with a region label subdivision mesh have been used to construct such an atlas because they can provide a compact representation of a partitioned multi resolution object specific mesh structure using only a few control point however automated fitting of a subdivision mesh based geometric atlas to an anatomical structure in an image is a difficult problem and ha not been sufficiently addressed in this paper we propose a novel markov random field based method for fitting a planar multi part subdivision mesh to anatomical data the optimal fitting of the atlas is obtained by determining the optimal location of the control point we also tackle the problem of landmark matching in tandem with atlas fitting by constructing a single graphical model to impose pose invariant landmark based geometric constraint on atlas deformation the atlas deformation is also governed by additional constraint imposed by the mesh s geometric property and the object boundary we demonstrate the potential of the proposed method on the difficult problem of segmenting a mouse brain and it interior region in gene expression image which exhibit large intensity and shape variability we obtain promising result when compared with manual annotation and prior method 
human salience is distinctive and reliable information in matching pedestrian across disjoint camera view in this paper we exploit the pair wise salience distribution relationship between pedestrian image and solve the person re identification problem by proposing a salience matching strategy to handle the misalignment problem in pedestrian image patch matching is adopted and patch salience is estimated matching patch with inconsistent salience brings penalty image of the same person are recognized by minimizing the salience matching cost furthermore our salience matching is tightly integrated with patch matching in a unified structural rank svm learning framework the effectiveness of our approach is validated on the viper dataset and the cuhk campus dataset it outperforms the state of the art method on both datasets 
we propose a method that relies on markerless visual observation to track the full articulation of two hand that interact with each other in a complex unconstrained manner we formulate this a an optimization problem whose dimensional parameter space represents all possible configuration of two hand each represented a a kinematic structure with degree of freedom dofs to solve this problem we employ particle swarm optimization pso an evolutionary stochastic optimization method with the objective of finding the two hand configuration that best explains observation provided by an rgb d sensor to the best of our knowledge the proposed method is the first to attempt and achieve the articulated motion tracking of two strongly interacting hand extensive quantitative and qualitative experiment with simulated and real world image sequence demonstrate that an accurate and efficient solution of this problem is indeed feasible 
in this paper we propose a novel method to reduce the magnitude of d ct artifact by stitching two image with a data driven regularization constrain which help preserve the local anatomy structure our method first computes an interface seam for the stitching in the overlapping region of the first image which pass through the smoothest region to reduce the structure complexity along the stitching interface then we compute the displacement of the seam by matching the corresponding interface seam in the second image we use sparse d feature a the structure cue to guide the seam matching in which a regularization term is incorporated to keep the structure consistency the energy function is minimized by solving a multiple label problem in markov random field with an anatomical structure preserving regularization term the displacement are propagated to the rest of second image and the two image are stitched along the interface seam based on the computed displacement field the method wa tested on both simulated data and clinical d ct image the experiment on simulated data demonstrated that the proposed method wa able to reduce the landmark distance error on average from mm to mm outperforming the registration based method by about for clinical d ct image data the image quality wa evaluated by three medical expert and all identified much fewer artifact from the resulting image by our method than from those by the compared method 
in this paper we show how to reconstruct both d shape and d texture of a class of surface from a single perspective image we consider the so called the generalized cylindrical surface that are wrapped with low rank texture they can be used to model most curved building facade in urban area or deformed book page scanned for text recognition our method leverage on the recent new technique for low rank matrix recovery and sparse error correction and it generalizes existing technique from planar surface to a much larger class of important d surface a we will show with extensive simulation and experiment the proposed algorithm can precisely rectify deformation of texture caused by both perspective projection and surface shape it work for a wide range of symmetric or regular texture that are ubiquitous in image of urban environment object or text and it is very robust to sparse occlusion noise and saturation 
we present a markov random field model for the analysis of lattice e g image or d mesh in term of the discriminative information of their vertex the proposed method provides a measure field that estimate the probability of each vertex to be discriminative or non discriminative a an application of the proposed framework we present a method for the selection of compact and robust feature for d face recognition the resulting signature consists of coefficient based on which we are able to build a classifier yielding better recognition rate than currently reported in the literature the main contribution of this work lie in the development of a novel framework for feature selection in scenario in which the most discriminative information is known to be concentrated along piece wise smooth region of a lattice 
complex human activity occurring in video can be defined in term of temporal configuration of primitive action prior work typically hand pick the primitive their total number and temporal relation e g allow only followed by and then only estimate their relative significance for activity recognition we advance prior work by learning what activity part and their spatiotemporal relation should be captured to represent the activity and how relevant they are for enabling efficient inference in realistic video we represent video by spatiotemporal graph where node correspond to multiscale video segment and edge capture their hierarchical temporal and spatial relationship access to video segment is provided by our new multiscale segmenter given a set of training spatiotemporal graph we learn their archetype graph and pdf s associated with model node and edge the model adaptively learns from data relevant video segment and their relation addressing the what and how inference and learning are formulated within the same framework that of a robust least square optimization which is invariant to arbitrary permutation of node in spatiotemporal graph the model is used for parsing new video in term of detecting and localizing relevant activity part we out perform the state of the art on benchmark olympic and ut human interaction datasets under a favorable complexity v accuracy trade off 
the problem of determining the absolute position and orientation of a camera from a set of d to d point correspondence is one of the most important problem in computer vision with a broad range of application in this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five d to d point correspondence our new solver is numerically more stable more accurate and significantly faster than the existing state of the art minimal four point absolute pose solver for this problem moreover our solver result in le solution and can handle larger radial distortion the new solver is straightforward and us only simple concept from linear algebra therefore it is simpler than the state of the art groebner basis solver we compare our new solver with the existing state of the art solver and show it usefulness on synthetic and real datasets 
given a unlabelled set of point x in r n belonging to k group we propose a method to identify cluster assignment that provides maximum separating margin among the cluster we address this problem by exploiting sparsity in data point inherent to margin region which a max margin classifier would produce under a supervised setting to separate point belonging to different group by analyzing the projection of x on the set of all possible line l in r n we first establish some basic result that are satisfied only by those line interval lying outside a cluster under assumption of linear separability of cluster and absence of outlier we then encode these result into a pair wise similarity measure to determine cluster assignment where we accommodate non linearly separable cluster using the kernel trick we validate our method on several uci datasets and on some computer vision problem and empirically show it robustness to outlier and in case where the exact number of cluster is not available the proposed approach offer an improvement in clustering accuracy of about on the average and up to when compared with several existing method 
unsupervised learning can be used to extract image representation that are useful for various and diverse vision task after noticing that most biological vision system for interpreting static image are trained using disparity information we developed an analogous framework for unsupervised learning the output of our method is a model that can generate a vector representation or descriptor from any static image however the model is trained using pair of consecutive video frame which are used to find representation that are consistent with optical flow derived object or flobjects to demonstrate the flobject analysis framework we extend the latent dirichlet allocation bag of word model to account for real valued word specific flow vector and image specific probabilistic association between flow cluster and topic we show that the static image representation extracted using our method can be used to achieve higher classification rate and better generalization than standard topic model spatial pyramid matching and gist descriptor 
we present an approach to synthesize the subtle d relief and texture of oil painting brush stroke from a single photograph this task is unique from traditional synthesize algorithm due to it mixed modality between the input and output i e our goal is to synthesize surface normal given an intensity image input to accomplish this task we propose a framework that first applies intrinsic image decomposition to produce a pair of initial normal map these map are combined into a conditional random field crf optimization framework that incorporates additional information derived from a training set consisting of normal captured using photometric stereo on oil painting with similar brush style additional constraint are incorporated into the crf framework to further ensures smoothness and preserve brush stroke edge our result show that this approach can produce compelling relief that are often indistinguishable from result captured using photometric stereo 
repeated pattern such a window tile balcony and door are prominent and significant feature in urban scene therefore detection of these repeated pattern becomes very important for city scene analysis this paper attack the problem of repeated pattern detection in a precise efficient and automatic way by combining traditional feature extraction followed by a kronecker product low rank modeling approach our method is tailored for d image of building facade we have developed algorithm for automatic selection of a representative texture within facade image using vanishing point and harris corner after rectifying the input image we describe novel algorithm that extract repeated pattern by using kronecker product based modeling that is based on a solid theoretical foundation our approach is unique and ha not ever been used for facade analysis we have tested our algorithm in a large set of image 
in this paper we propose a novel alpha matting method with local and nonlocal smooth prior we observe that the manifold preserving editing propagation essentially introduced a nonlocal smooth prior on the alpha matte this nonlocal smooth prior and the well known local smooth prior from matting laplacian complement each other so we combine them with a simple data term from color sampling in a graph model for nature image matting our method ha a closed form solution and can be solved efficiently compared with the state of the art method our method produce more accurate result according to the evaluation on standard benchmark datasets 
with volumetric data from wide field fluorescence microscopy many emerging question in biological and biomedical research are being investigated data can be recorded with high temporal resolution while the specimen is only exposed to a low amount of photo toxicity these advantage come at the cost of strong recording blur caused by the infinitely extended point spread function psf for wide field microscopy it magnitude only decay with the square of the distance to the focal point and consists of an airy bessel pattern which is intricate to describe in the spatial domain however the fourier transform of the incoherent psf denoted a optical transfer function otf is well localized and smooth in this paper we present a blind deconvolution method that improves result of state of the art deconvolution method on wide field data by exploiting the property of the wide field otf 
state of the art image and action classification system often employ vocabulary based representation the classification accuracy achieved with such vocabulary based representation depends significantly on the chosen histogram distance in particular when the decision function is a support vector machine svm the classification accuracy depends on the chosen histogram kernel in this paper we focus on smoothly parameterized kernel in the space of histogram such a but not limited to kernel that are derived from smoothly parameterized histogram distance function we learn parameter of histogram kernel so that the svm accuracy is improved this is accomplished by simultaneously maximizing the svm s geometric margin and minimizing an estimate of it generalization error we validate our approach on a previously published two class synthetic dataset and three real world multi class datasets oxford k kth and ucf on these datasets our approach yield result that compare favorably to or exceed the state of the art 
speedy abnormal event detection meet the growing demand to process an enormous number of surveillance video based on inherent redundancy of video structure we propose an efficient sparse combination learning framework it achieves decent performance in the detection phase without compromising result quality the short running time is guaranteed because the new method effectively turn the original complicated problem to one in which only a few costless small scale least square optimization step are involved our method reach high detection rate on benchmark datasets at a speed of frame per second on average when computing on an ordinary desktop pc using matlab 
this paper introduces an efficient approach to integrating non local statistic into the higher order markov random field mrfs framework motivated by the observation that many non local statistic e g shape prior color distribution can usually be represented by a small number of parameter we reformulate the higher order mrf model by introducing additional latent variable to represent the intrinsic dimension of the higher order clique the resulting new model called nc mrf not only provides the flexibility in representing the configuration of higher order clique but also automatically decomposes the energy function into le coupled term allowing u to design an efficient algorithmic framework for maximum a posteriori map inference based on this novel modeling inference framework we achieve state of the art solution to the challenging problem of class specific image segmentation and template based d facial expression tracking which demonstrate the potential of our approach 
in this paper we present a new approach for text localization in natural image by discriminating text and non text region at three level pixel component and text line level firstly a powerful low level filter called the stroke feature transform sft is proposed which extends the widely used stroke width transform swt by incorporating color cue of text pixel leading to significantly enhanced performance on inter component separation and intra component connection secondly based on the output of sft we apply two classifier a text component classifier and a text line classifier sequentially to extract text region eliminating the heuristic procedure that are commonly used in previous approach the two classifier are built upon two novel text covariance descriptor tcds that encode both the heuristic property and the statistical characteristic of text stokes finally text region are located by simply thresholding the text line confident map our method wa evaluated on two benchmark datasets icdar and icdar and the corresponding f measure value are and respectively surpassing previous method in accuracy by a large margin 
this paper present an active learning algorithm for piecewise planar d reconstruction of a scene while previous interactive algorithm require the user to provide tedious interaction to identify all the plane in the scene we build on successful idea from the automatic algorithm and introduce the idea of active learning thereby improving the reconstruction while considerably reducing the effort our algorithm first attempt to obtain a piecewise planar reconstruction of the scene automatically through an energy minimization framework the proposed active learning algorithm then us intuitive cue to quantify the uncertainty of the algorithm and suggest region querying the user to provide support for the uncertain region via simple scribble these interaction are used to suitably update the algorithm leading to better reconstruction we show through machine experiment and a user study that the proposed approach can intelligently query user for interaction on informative region and user can achieve better reconstruction of the scene faster especially for scene with texture le surface lacking cue like line which automatic algorithm rely on 
sparse representation ha been applied to visual tracking by finding the best candidate with minimal reconstruction error using target template however most sparse representation based tracker only consider the holistic representation and do not make full use of the sparse coefficient to discriminate between the target and the background and hence may fail with more possibility when there is similar object or occlusion in the scene in this paper we develop a simple yet robust tracking method based on the structural local sparse appearance model this representation exploit both partial information and spatial information of the target based on a novel alignment pooling method the similarity obtained by pooling across the local patch help not only locate the target more accurately but also handle occlusion in addition we employ a template update strategy which combine incremental subspace learning and sparse representation this strategy adapts the template to the appearance change of the target with le possibility of drifting and reduces the influence of the occluded target template a well both qualitative and quantitative evaluation on challenging benchmark image sequence demonstrate that the proposed tracking algorithm performs favorably against several state of the art method 
correspondence matching is one of the most common problem in computer vision and it is often solved using photo consistency of local region these approach typically assume that the frequency content in the local region is consistent in the image pair such that matching is performed on similar signal however in many practical situation this is not the case for example with low depth of field camera a scene point may be out of focus in one view and in focus in the other causing a mismatch of frequency signal furthermore this mismatch can vary spatially over the entire image in this paper we propose a local signal equalization approach for correspondence matching using a measure of local image frequency we equalize local signal using an efficient scale space image representation such that their frequency content are optimally suited for matching our approach allows better correspondence matching which we demonstrate with a number of stereo reconstruction example on synthetic and real datasets 
despite many advance made in the area deformable target and partial occlusion continue to represent key problem in visual tracking structured learning ha shown good result when applied to tracking whole target but applying this approach to a part based target model is complicated by the need to model the relationship between part and to avoid lengthy initialisation process we thus propose a method which model the unknown part using latent variable in doing so we extend the online algorithm pegasos to the structured prediction case i e predicting the location of the bounding box with latent part variable to better estimate the part and to avoid over fitting caused by the extra model complexity capacity introduced by the part we propose a two stage training process based on the primal rather than the dual form we then show that the method outperforms the state of the art linear and non linear kernel tracker 
two problem occur when bundle adjustment ba is applied on long image sequence the large calculation time and the drift or error accumulation in recent work the calculation time is reduced by local ba applied in an incremental scheme the drift may be reduced by fusion of gps and structure from motion an existing fusion method is ba minimizing a weighted sum of image and gps error this paper introduces two constrained ba for fusion which enforce an upper bound for the reprojection error these ba are alternative to the existing fusion ba which doe not guarantee a small reprojection error and requires a weight a input then the three fusion ba are integrated in an incremental structure from motion method based on local ba lastly we will compare the fusion result on a long monocular image sequence and a low cost gps 
a recently introduced latent feature learning technique for time varying dynamic phenomenon analysis is the so called slow feature analysis sfa sfa is a deterministic component analysis technique for multi dimensional sequence that by minimizing the variance of the first order time derivative approximation of the input signal find uncorrelated projection that extract slowly varying feature ordered by their temporal consistency and constancy in this paper we propose a number of extension in both the deterministic and the probabilistic sfa optimization framework in particular we derive a novel deterministic sfa algorithm that is able to identify linear projection that extract the common slowest varying feature of two or more sequence in addition we propose an expectation maximization em algorithm to perform inference in a probabilistic formulation of sfa and similarly extend it in order to handle two and more time varying data sequence moreover we demonstrate that the probabilistic sfa emsfa algorithm that discovers the common slowest varying latent space of multiple sequence can be combined with dynamic time warping technique for robust sequence time alignment the proposed sfa algorithm were applied for facial behavior analysis demonstrating their usefulness and appropriateness for this task 
layered representation for object recognition are important due to their increased invariance biological plausibility and computational benefit however most of existing approach to hierarchical representation are strictly feedforward and thus not well able to resolve local ambiguity we propose a probabilistic model that learns and infers all layer of the hierarchy jointly specifically we suggest a process of recursive probabilistic factorization and present a novel generative model based on latent dirichlet allocation to this end the approach is tested on a standard recognition dataset outperforming existing hierarchical approach and demonstrating performance on par with current single feature state of the art model we demonstrate two important property of our proposed model adding an additional layer to the representation increase performance over the flat model a full bayesian approach outperforms a feedforward implementation of the model 
in this paper we propose a multi scale topological feature representation for automatic analysis of hand posture such topological feature have the advantage of being posture dependent while being preserved under certain variation of illumination rotation personal dependency etc our method study the topology of the hole between the hand region and it convex hull inspired by the principle of persistent homology which is the theory of computational topology for topological feature analysis over multiple scale we construct the multi scale betti number matrix msbnm for the topological feature representation in our experiment we used different hand posture and compared our feature with three popular feature hog mct and shape context on different data set in addition to hand posture we also extend the feature representation to arm posture the result demonstrate the feasibility and reliability of the proposed method 
we focus on the detection of orthogonal vanishing point using line segment extracted from a single view and using these for camera self calibration recent method view this problem a a two stage process vanishing point are extracted through line segment clustering and subsequently likely orthogonal candidate are selected for calibration unfortunately such an approach is easily distracted by the presence of clutter furthermore geometric constraint imposed by the camera and scene orthogonality are not enforced during detection leading to inaccurate result which are often inadmissible for calibration to overcome these limitation we present a ransac based approach using a minimal solution for estimating three orthogonal vanishing point and focal length from a set of four line aligned with either two or three orthogonal direction in addition we propose to refine the estimate using an efficient and robust maximum likelihood estimator extensive experiment on standard datasets show that our contribution result in significant improvement over the state of the art 
hyper spectral reflectance data allows for highly accurate spectral relighting under arbitrary illumination which is invaluable to application ranging from archiving cultural e heritage to consumer product design past method for capturing the spectral reflectance of scene ha proven successful in relighting but they all share a common assumption all the method do not consider the effect of fluorescence despite fluorescence being found in many everyday object in this paper we describe the very different way that reflectance and fluorescence interact with illuminant and show the need to explicitly consider fluorescence in the relighting problem we then propose a robust method based on well established theory of reflectance and fluorescence for imaging each of these component finally we show that we can relight real scene of reflective fluorescent surface with much higher accuracy in comparison to only considering the reflective component 
human action and role recognition play an important part in complex event understanding state of the art method learn action and role model from detailed spatio temporal annotation which requires extensive human effort in this work we propose a method to learn such model based on natural language description of the training video which are easier to collect and scale with the number of action and role there are two challenge with using this form of weak supervision first these description only provide a high level summary and often do not directly mention the action and role occurring in a video second natural language description do not provide spatio temporal annotation of action and role to tackle these challenge we introduce a topic based semantic relatedness sr measure between a video description and an action and role label and incorporate it into a posterior regularization objective our event recognition system based on these action and role model match the state of the art method on the trecvid med event kit despite weaker supervision 
various visual task such a the recognition of human action gesture facial expression and classification of dynamic texture require modeling and the representation of spatio temporal information in this paper we propose representing space time pattern using directional spatio temporal oriented gradient in the proposed approach a d video patch is represented by a histogram of oriented gradient over nine symmetric spatio temporal plane video comparison is achieved through a positive definite similarity kernel that is learnt by multiple kernel learning a rich spatio temporal descriptor with a simple trade off between discriminatory power and invariance property is thereby obtained to evaluate the proposed approach we consider three challenging visual recognition task namely the classification of dynamic texture human gesture and human action our evaluation indicate that the proposed approach attains significant classification improvement in recognition accuracy in comparison to state of the art method such a lbp top d sift hog d tensor canonical correlation analysis and dynamical fractal analysis 
we present an integrated probabilistic model for layered object tracking that combine dynamic on implicit shape representation topological shape constraint adaptive appearance model and layered flow the generative model combine the evolution of appearance and layer shape with a gaussian process flow and explicit layer ordering efficient mcmc sampling algorithm are developed to enable a particle filtering approach while reasoning about the distribution of object boundary in video we demonstrate the utility of the proposed tracking algorithm on a wide variety of video source while achieving state of the art result on a boundary accurate tracking dataset 
we introduce the problem of scene viewpoint recognition the goal of which is to classify the type of place shown in a photo and also recognize the observer s viewpoint within that category of place we construct a database of panoramic image organized into place category for each category our algorithm automatically aligns the panorama to build a full view representation of the surrounding place we also study the symmetry property and canonical viewpoint of each place category at test time given a photo of a scene the model can recognize the place category produce a compass like indication of the observer s most likely viewpoint within that place and use this information to extrapolate beyond the available view filling in the probable visual layout that would appear beyond the boundary of the photo 
weakly supervised image segmentation is a challenging problem in computer vision field in this paper we present a new weakly supervised image segmentation algorithm by learning the distribution of spatially structured super pixel set from image level label specifically we first extract graph let from each image where a graph let is a small sized graph consisting of super pixel a it node and it encapsulates the spatial structure of those super pixel then a manifold embedding algorithm is proposed to transform graph let of different size into equal length feature vector thereafter we use gmm to learn the distribution of the post embedding graph let finally we propose a novel image segmentation algorithm called graph let cut that leverage the learned graph let distribution in measuring the homogeneity of a set of spatially structured super pixel experimental result show that the proposed approach outperforms state of the art weakly supervised image segmentation method and it performance is comparable to those of the fully supervised segmentation model 
in this paper we study the problem of online aligning a newly arrived image to previously well aligned image inspired by recent advance in batch image alignment using low rank decomposition we treat the newly arrived image after alignment a being linearly and sparsely reconstructed by the well aligned one the task is accomplished by a sequence of convex optimization that minimizes the l norm after that online basis updating is pursued in two different way a two stage incremental alignment for joint registration of a large image dataset which is known a prior and a greedy online alignment of dynamically increasing image sequence such a in the tracking scenario in we first sequentially collect basis image that are easily aligned by checking their reconstruction residual followed by the second stage where all image are re aligned one by one using the collected basis set in during the tracking process we dynamically enrich the image basis set by the new target if it significantly distinguishes itself from existing basis image while inheriting the benefit of sparsity our method enjoys the great time efficiency and therefore be capable of dealing with large image set and real time task such a visual tracking the efficacy of the proposed online robust alignment algorithm is verified with extensive experiment on image set alignment and visual tracking in reference with state of the art method 
we introduce a new discriminative learning method for image classification we assume that the image are represented by unordered multi dimensional finite set of feature vector and that these set might have different cardinality this allows u to use consistent nonparametric divergence estimator to define new kernel over these set and then apply them in kernel classifier our numerical result demonstrate that in many case this approach can outperform state of the art competitor on both simulated and challenging real world datasets 
we present d constrained local model clm z for robust facial feature tracking under varying pose our approach integrates both depth and intensity information in a common framework we show the benefit of our clm z method in both accuracy and convergence rate over regular clm formulation through experiment on publicly available datasets additionally we demonstrate a way to combine a rigid head pose tracker with clm z that benefit rigid head tracking we show better performance than the current state of the art approach in head pose tracking with our extension of the generalised adaptive view based appearance model gavam 
many recent work have attempted to improve object recognition by exploiting temporal dynamic an intrinsic property of video sequence in this paper a new spatio temporal hierarchical agglomerative clustering sthac method is proposed for automatic extraction of face exemplar for face recognition in video sequence two variant of sthac are presented a global variety that unifies spatial and temporal distance between point and a local variety that introduces perturbation of distance based on a local spatio temporal neighborhood criterion face that are nearest to the cluster mean are chosen a exemplar for the testing stage where subject in the test video sequence are recognized using a probabilistic based classifier extensive evaluation on a face video database demonstrates the effectiveness of our proposed method and the significance of incorporating temporal information for exemplar extraction 
markerless d human pose detection from a single image is a severely underconstrained problem because different d pose can have similar image projection in order to handle this ambiguity current approach rely on prior shape model that can only be correctly adjusted if d image feature are accurately detected unfortunately although current d part detector algorithm have shown promising result they are not yet accurate enough to guarantee a complete disambiguation of the d inferred shape in this paper we introduce a novel approach for estimating d human pose even when observation are noisy we propose a stochastic sampling strategy to propagate the noise from the image plane to the shape space this provides a set of ambiguous d shape which are virtually undistinguishable from their image projection disambiguation is then achieved by imposing kinematic constraint that guarantee the resulting pose resembles a d human shape we validate the method on a variety of situation in which state of the art d detector yield either inaccurate estimation or partly miss some of the body part 
in this paper we address multi view reconstruction of urban environment using d shape grammar our formulation express the solution to the problem a a shape grammar parse tree where both the tree and the corresponding derivation parameter are unknown besides the grammar constraint the solution is guided by an image support that is twofold first we seek for a derivation that induces optimal semantic partition in the different view second using structure from motion noisy depth map can be determined towards minimizing their distance from to the one predicted by any potential solution we show how the underlying data structure can be efficiently optimized using evolutionary algorithm with automatic parameter selection to the best of our knowledge it is the first time that the multi view d procedural modeling problem is tackled promising result demonstrate the potential of the method towards producing a compact representation of urban environment 
human motion capturing hmc from multiview image sequence is an extremely difficult problem due to depth and orientation ambiguity and the high dimensionality of the state space in this paper we introduce a novel hybrid hmc system that combine video input with sparse inertial sensor input employing an annealing particle based optimization scheme our idea is to use orientation cue derived from the inertial input to sample particle from the manifold of valid pose then visual cue derived from the video input are used to weight these particle and to iteratively derive the final pose a our main contribution we propose an efficient sampling procedure where the particle are derived analytically using inverse kinematics on the orientation cue additionally we introduce a novel sensor noise model to account for uncertainty based on the von mi fisher distribution doing so orientation constraint are naturally fulfilled and the number of needed particle can be kept very small more generally our method can be used to sample pose that fulfill arbitrary orientation or positional kinematic constraint in the experiment we show that our system can track even highly dynamic motion in an outdoor environment with changing illumination background clutter and shadow 
in this paper we consider the weighted graph matching problem with partially disclosed correspondence between a number of anchor node our construction exploit recently introduced node signature based on graph laplacians namely the laplacian family signature lf on the node and the pair wise heat kernel map on the edge in this paper without assuming an explicit form of parametric dependence nor a distance metric between node signature we formulate an optimization problem which incorporates the knowledge of anchor node solving this problem give u an optimized proximity measure specific to the graph under consideration using this a a first order compatibility term we then set up an integer quadratic program iqp to solve for a near optimal graph matching our experiment demonstrate the superior performance of our approach on randomly generated graph and on two widely used image sequence when compared with other existing signature and adjacency matrix based graph matching method 
the aim of this work is to extract the road network from aerial image what make the problem challenging is the complex structure of the prior road form a connected network of smooth thin segment which meet at junction and crossing this type of a priori knowledge is more difficult to turn into a tractable model than standard smoothness or co occurrence assumption we develop a novel crf formulation for road labeling in which the prior is represented by higher order clique that connect set of super pixel along straight line segment these long range clique have asymmetric p n potential which express a preference to assign all rather than just some of their constituent super pixel to the road class thus the road likelihood is amplified for thin chain of super pixel while the crf is still amenable to optimization with graph cut since the number of such clique of arbitrary length is huge we furthermore propose a sampling scheme which concentrate on those clique which are most relevant for the optimization in experiment on two different database the model significantly improves both the per pixel accuracy and the topological correctness of the extracted road and outperforms both a simple smoothness prior and heuristic rule based road completion 
we propose a model to combine per frame and per track cue for action recognition with multiple target in a scene our model simultaneously capture the natural harmony of an individual s action in a scene and the flow of action of an individual in a video sequence inferring valid track in the process our motivation is based on the unlikely discordance of an action in a structured scene both at the track level and the frame level e g a person dancing in a crowd of jogger while we can utilize sampling approach for inference in our model we instead devise a global inference algorithm by decomposing the problem and solving the subproblems exactly and efficiently recovering a globally optimal joint solution in several case finally we improve on the state of the art action recognition result for two publicly available datasets 
we propose a new deep decompositional network ddn for parsing pedestrian image into semantic region such a hair head body arm and leg where the pedestrian can be heavily occluded unlike existing method based on template matching or bayesian inference our approach directly map low level visual feature to the label map of body part with ddn which is able to accurately estimate complex pose variation with good robustness to occlusion and background clutter ddn jointly estimate occluded region and segment body part by stacking three type of hidden layer occlusion estimation layer completion layer and decomposition layer the occlusion estimation layer estimate a binary mask indicating which part of a pedestrian is invisible the completion layer synthesize low level feature of the invisible part from the original feature and the occlusion mask the decomposition layer directly transform the synthesized visual feature to label map we devise a new strategy to pre train these hidden layer and then fine tune the entire network using the stochastic gradient descent experimental result show that our approach achieves better segmentation accuracy than the state of the art method on pedestrian image with or without occlusion another important contribution of this paper is that it provides a large scale benchmark human parsing dataset that includes annotated sample collected from surveillance video it is time larger than existing public datasets 
in this paper we propose a novel method for cross view action recognition via a continuous virtual path which connects the source view and the target view each point on this virtual path is a virtual view which is obtained by a linear transformation of the action descriptor all the virtual view are concatenated into an infinite dimensional feature to characterize continuous change from the source to the target view however these infinite dimensional feature cannot be used directly thus we propose a virtual view kernel to compute the value of similarity between two infinite dimensional feature which can be readily used to construct any kernelized classifier in addition there are a lot of unlabeled sample from the target view which can be utilized to improve the performance of classifier thus we present a constraint strategy to explore the information contained in the unlabeled sample the rationality behind the constraint is that any action video belongs to only one class our method is verified on the ixmas dataset and the experimental result demonstrate that our method achieves better performance than the state of the art method 
in this paper we propose a new technique for learning a discriminative codebook for local feature descriptor specifically designed for scalable landmark classification the key contribution lie in exploiting the knowledge of correspondence within set of feature descriptor during code book learning feature correspondence are obtained using structure from motion sfm computation on internet photo collection which serve a the training data our codebook is defined by a random forest that is trained to map corresponding feature descriptor into identical code unlike prior forest based codebook learning method we utilize fine grained descriptor label and address the challenge of training a forest with an extremely large number of label our codebook is used with various existing feature encoding scheme and also a variant we propose for importance weighted aggregation of local feature we evaluate our approach on a public dataset of landmark and our new dataset of landmark k image our approach significantly outperforms the state of the art in landmark classification furthermore our method is memory efficient and scalable 
this paper present a novel structure gradient and texture decor relating regularization sgtd for image decomposition the motivation of the idea is under the assumption that the structure gradient and texture component should be properly decor related for a successful decomposition the proposed model consists of the data fidelity term total variation regularization and the sgtd regularization an augmented lagrangian method is proposed to address this optimization issue by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the sub problem experimental result demonstrate that the proposed method present better or comparable performance a state of the art method do 
we present a distributed representation of pose and appearance of people called the poselet activation vector first we show that this representation can be used to estimate the pose of people defined by the d orientation of the head and torso in the challenging pascal voc person detection dataset our method is robust to clutter aspect and viewpoint variation and work even when body part like face and limb are occluded or hard to localize we combine this representation with other source of information like interaction with object and other people in the image and use it for action recognition we report competitive result on the pascal voc static image action classification challenge 
multiple instance learning mil ha been widely exploited in many computer vision task such a image retrieval object tracking and so on to handle ambiguity of instance label in positive bag the training process of traditional mil method is usually computationally expensive which limit the application of mil in more computer vision task in this paper we propose a novel batch mode framework namely batch mode adaptive multiple instance learning bamil to accelerate the instance level mil method specifically instead of using all training bag at once we divide the training bag into several set of bag i e batch at each time we use one batch of training bag to train a new classifier which is adapted from the latest pre learned classifier such batch mode framework significantly accelerates the traditional mil method for large scale application and can be also used in dynamic environment such a object tracking the experimental result show that our bamil is much faster than the recently developed mil with constrained positive bag while achieves comparable performance for text based web image retrieval in dynamic setting bamil also achieves the better overall performance for object tracking when compared with other online mil method 
in this work we address the multi label mumford shah problem i e the problem of jointly estimating a partitioning of the domain of the image and function defined within region of the partition we create algorithm that are efficient robust to undesirable local minimum and are easy to implement our algorithm are formulated by slightly modifying the underlying statistical model from which the multi label mumford shah functional is derived the advantage of this statistical model is that the underlying variable the label and the function are le coupled than in the original formulation and the label can be computed from the function with more global update the resulting algorithm can be tuned to the desired level of locality of the solution from fully global update to more local update we demonstrate our algorithm on two application joint multi label segmentation and denoising and joint multi label motion segmentation and flow estimation we compare to the state of the art in multi label mumford shah problem and show that we achieve more promising result 
recent progress in the field of human action recognition point towards the use of spatio temporal interest point stips for local descriptor based recognition strategy in this paper we present a new approach for stip detection by applying surround suppression combined with local and temporal constraint our method is significantly different from existing stip detector and improves the performance by detecting more repeatable stable and distinctive stips for human actor while suppressing unwanted background stips for action representation we use a bag of visual word bov model of local n jet feature to build a vocabulary of visual word to this end we introduce a novel vocabulary building strategy by combining spatial pyramid and vocabulary compression technique resulting in improved performance and efficiency action class specific support vector machine svm classifier are trained for categorization of human action a comprehensive set of experiment on existing benchmark datasets and more challenging datasets of complex scene validate our approach and show state of the art performance 
head pose estimation from image ha recently attracted much attention in computer vision due to it diverse application in face recognition driver monitoring and human computer interaction most successful approach to head pose estimation formulate the problem a a nonlinear regression between image feature and continuous d angle i e yaw pitch and roll however regression like method suffer from three main drawback they typically lack generalization and overfit when trained using a few sample they fail to get reliable estimate over some region of the output space angle when the training set is not uniformly sampled for instance if the training data contains under sampled area for some angle they are not robust to image noise or occlusion to address these problem this paper present supervised local subspace learning sl a method that learns a local linear model from a sparse and non uniformly sampled training set sl learns a mixture of local tangent space that is robust to under sampled region and due to it regularization property it is also robust to over fitting moreover because sl is a generative model it can deal with image noise experimental result on the cmu multi pie and bu dfe database show the effectiveness of our approach in term of accuracy and computational complexity 
a plenoptic camera capture the d radiance about a scene recent practical solution mount a microlens array on top of a commodity slr to directly acquire these ray however they suffer from low resolution a hundred of thousand of view need to be captured in a single shot in this paper we develop a simple but effective technique for improving the image resolution of the plenoptic camera by maneuvering the demosaicing process we first show that the traditional solution by demosaicing each individual microlens image and then blending them for view synthesis is suboptimal in particular this demosaicing process often suffers from aliasing artifact and it damage high frequency information recorded by each microlens image hence degrades the image quality we instead propose to de mosaic the synthesized view at the rendering stage specifically we first transform the radiance to the desired focal plane and then apply frequency domain plenoptic resampling a full resolution color filtered image is then created by performing a d integral projection from the reparam eterized radiance finally we conduct demosacing to obtain the color result we show that our solution can achieve visible resolution enhancement on dynamic refocusing and depth assisted deep focus rendering 
though many task in computer vision can be formulated elegantly a pixel labeling problem a typical challenge discouraging such a discrete formulation is often due to computational efficiency recent study on fast cost volume filtering based on efficient edge aware filter have provided a fast alternative to solve discrete labeling problem with the complexity independent of the support window size however these method still have to step through the entire cost volume exhaustively which make the solution speed scale linearly with the label space size when the label space is huge which is often the case for sub pixel accurate stereo and optical flow estimation their computational complexity becomes quickly unacceptable developed to search approximate nearest neighbor rapidly the patch match method can significantly reduce the complexity dependency on the search space size but it pixel wise randomized search and fragmented data access within the d cost volume seriously hinder the application of efficient cost slice filtering this paper present a generic and fast computational framework for general multi labeling problem called patch match filter pmf for the very first time we explore effective and efficient strategy to weave together these two fundamental technique developed in isolation i e based based randomized search and efficient edge aware image filtering by decompositing an image into compact super pixel we also propose super pixel based novel search strategy that generalize and improve the original patch match method focusing on dense correspondence field estimation in this paper we demonstrate pmf s application in stereo and optical flow our pmf method achieve state of the art correspondence accuracy but run much faster than other competing method often giving over time speedup for large label space case 
we describe a method to efficiently generate a model map of small scale object from video the map encodes sparse geometry a well a coarse photometry and could be used to initialize dense reconstruction scheme a well a to support recognition and localization of three dimensional object self occlusion and the predominance of outlier present a challenge to existing online structure from motion and simultaneous localization and mapping system we propose a unified inference criterion that encompasses map building and localization object detection relative to the map in a coupled fashion we establish correspondence in a computationally efficient way without resorting to combinatorial matching or random sampling technique instead we use a simpler m estimator that exploit putative correspondence from tracking after photometric and topological validation we have collected a new dataset to benchmark model building in the small scale which we test our algorithm on in comparison to others although our system is significantly leaner than previous one it compare favorably to the state of the art in term of accuracy and robustness 
non blind deconvolution is a key component in image deblurring system previous deconvolution method assume a linear blur model where the blurred image is generated by a linear convolution of the latent image and the blur kernel this assumption often doe not hold in practice due to various type of outlier in the imaging process without proper outlier handling previous method may generate result with severe ringing artifact even when the kernel is estimated accurately in this paper we analyze a few common type of outlier that cause previous method to fail such a pixel saturation and non gaussian noise we propose a novel blur model that explicitly take these outlier into account and build a robust non blind deconvolution method upon it which can effectively reduce the visual artifact caused by outlier the effectiveness of our method is demonstrated by experimental result on both synthetic and real world example 
we introduce global regularity in the d building modeling problem to reflect the orientation and placement similarity between planar element in building structure given a d point cloud scan we present an automatic approach that simultaneously detects locally fitted plane primitive and global regularity while global regularity are extracted by analyzing the plane primitive they adjust the plane in return and effectively correct local fitting error we explore a broad variety of global regularity between d planar element including both planer roof patch and planar facade patch by aligning planar element to global regularity our method significantly improves the model quality in term of both geometry and human judgement 
non negative data factorization ha been widely used recently however existing technique such a non negative graph embedding nge often suffer from noisy data unreliable graph and noisy label which are commonly encountered in real world application to address these issue in this paper we propose a robust non negative graph embedding rnge framework the joint sparsity in both graph embedding and reconstruction endues the robustness of rnge we develop an elegant multiplicative updating solution that can solve rnge efficiently and prove the convergence rigourously rnge is robust to unreliable graph a well a both sample and label noise in training data moreover rnge provides a general formulation such that all the algorithm unified with the graph embedding framework can be easily extended to obtain their robust non negative solution we conduct extensive experiment on four real world datasets and compared the proposed rnge to nge and other representative non negative data factorization and subspace learning method the experimental result demonstrate the effectiveness and robustness of rnge 
effective segmentation prior to recognition ha been shown to improve recognition performance however most segmentation algorithm adopt method which are not explicitly linked to the goal of object recognition here we solve a related but slightly different problem in order to assist object recognition more directly the extraction of a foreground mask which identifies the location of object in the image we propose a novel foreground background segmentation algorithm that attempt to segment the interesting object from the rest of the image while maximizing an objective function which is tightly related to object recognition we do this in a manner which requires no class specific knowledge of object category using a probabilistic formulation which is derived from manually segmented image the model includes a geometric prior and an appearance prior whose parameter are learnt on the fly from image that are similar to the query image we use graph cut based energy minimization to enforce spatial coherence on the model s output the method is tested on the challenging voc and voc segmentation datasets achieving excellent result in providing a foreground mask we also provide comparison to the recent segmentation method of 
we present a method to capture both d shape and spatially varying reflectance with a multi view photometric stereo technique that work for general isotropic material our data capture setup is simple which consists of only a digital camera and a handheld light source from a single viewpoint we use a set of photometric stereo image to identify surface point with the same distance to the camera we collect this information from multiple viewpoint and combine it with structure from motion to obtain a precise reconstruction of the complete d shape the spatially varying isotropic bidirectional reflectance distribution function brdf is captured by simultaneously inferring a set of basis brdfs and their mixing weight at each surface point according to our experiment the captured shape are accurate to millimeter the captured reflectance ha relative root mean square error rmse of 
current light field lf camera offer fixed resolution in space time and angle which is decided a priori and is independent of the scene these camera either trade off spatial resolution to capture single shot lf or tradeoff temporal resolution by assuming a static scene to capture high spatial resolution lf thus capturing high spatial resolution lf video for dynamic scene remains an open and challenging problem we present the concept design and implementation of a lf video camera that allows capturing high resolution lf video the spatial angular and temporal resolution are not fixed a priori and we exploit the scene specific redundancy in space time and angle our reconstruction is motion aware and offer a continuum of resolution tradeoff with increasing motion in the scene the key idea is a to design efficient multiplexing matrix that allow resolution tradeoff b use dictionary learning and sparse representation for robust reconstruction and c perform local motion aware adaptive reconstruction we perform extensive analysis and characterize the performance of our motion aware reconstruction algorithm we show realistic simulation using a graphic simulator a well a real result using a lcos based programmable camera we demonstrate novel result such a high resolution digital refocusing for dynamic moving object 
we present an algorithm that carry out alternate hough transform and inverted hough transform to establish feature correspondence and enhances the quality of matching in both precision and recall inspired by the fact that nearby feature on the same object share coherent homographies in matching we cast the task of feature matching a a density estimation problem in the hough space spanned by the hypothesis of homographies specifically we project all the correspondence into the hough space and determine the correctness of the correspondence by their respective density in this way mutual verification of relevant correspondence is activated and the precision of matching is boosted on the other hand we infer the concerted homographies propagated from the locally grouped feature and enrich the correspondence candidate for each feature the recall is hence increased the two process are tightly coupled through iterative optimization plausible enrichment are gradually revealed while more correct correspondence are detected promising experimental result on three benchmark datasets manifest the effectiveness of the proposed approach 
in this paper we propose technique to make use of two complementary bottom up feature image edge and texture patch to guide top down object segmentation towards higher precision we build upon the part based pose let detector which can predict mask for numerous part of an object for this purpose we extend poselets to other category apart from person we non rigidly align these part detection to potential object contour in the image both to increase the precision of the predicted object mask and to sort out false positive we spatially aggregate object information via a variational smoothing technique while ensuring that object region do not overlap finally we propose to refine the segmentation based on self similarity defined on small image patch we obtain competitive result on the challenging pascal voc benchmark on four class we achieve the best number to date 
the popular bag of word approach for action recognition is based on the classifying quantized local feature density this approach focus excessively on the local feature but discard all information about the interaction among them local feature themselves may not be discriminative enough but combined with their context they can be very useful for the recognition of some action in this paper we present a novel representation that capture contextual interaction between interest point based on the density of all feature observed in each interest point s mutliscale spatio temporal contextual domain we demonstrate that augmenting local feature with our contextual feature significantly improves the recognition performance 
we present an approach to jointly learn a set of view specific dictionary and a common dictionary for cross view action recognition the set of view specific dictionary is learned for specific view while the common dictionary is shared across different view our approach represents video in each view using both the corresponding view specific dictionary and the common dictionary more importantly it encourages the set of video taken from different view of the same action to have similar sparse representation in this way we can align view specific feature in the sparse feature space spanned by the view specific dictionary set and transfer the view shared feature in the sparse feature space spanned by the common dictionary meanwhile the incoherence between the common dictionary and the view specific dictionary set enables u to exploit the discrimination information encoded in view specific feature and view shared feature separately in addition the learned common dictionary not only ha the capability to represent action from unseen view but also make our approach effective in a semi supervised setting where no correspondence video exist and only a few label exist in the target view extensive experiment using the multi view ixmas dataset demonstrate that our approach outperforms many recent approach for cross view action recognition 
we present a probabilistic generative model for simultaneously recognizing daily action and predicting gaze location in video recorded from an egocentric camera we focus on activity requiring eye hand coordination and model the spatio temporal relationship between the gaze point the scene object and the action label our model capture the fact that the distribution of both visual feature and object occurrence in the vicinity of the gaze point is correlated with the verb object pair describing the action it explicitly incorporates known property of gaze behavior from the psychology literature such a the temporal delay between fixation and manipulation event we present an inference method that can predict the best sequence of gaze location and the associated action label from an input sequence of image we demonstrate improvement in action recognition rate and gaze prediction accuracy relative to state of the art method on two new datasets that contain egocentric video of daily activity and gaze 
we present an approach to reconstruction of detailed scene geometry from range video range data produced by commodity handheld camera suffers from high frequency error and low frequency distortion our approach deal with both source of error by reconstructing locally smooth scene fragment and letting these fragment deform in order to align to each other we develop a volumetric registration formulation that leverage the smoothness of the deformation to make optimization practical for large scene experimental result demonstrate that our approach substantially increase the fidelity of complex scene geometry reconstructed with commodity handheld camera 
the analysis of d shape mesh is a fundamental problem in computer vision graphic and medical imaging frequently the need of the application require that our analysis take a multi resolution view of the shape s local and global topology and that the solution is consistent across multiple scale unfortunately the preferred mathematical construct which offer this behavior in classical image signal processing wavelet is no longer applicable in this general setting data with non uniform topology in particular the traditional definition doe not allow writing out an expansion for graph that do not correspond to the uniformly sampled lattice e g image in this paper we adapt recent result in harmonic analysis to derive non euclidean wavelet based algorithm for a range of shape analysis problem in vision and medical imaging we show how descriptor derived from the dual domain representation offer native multi resolution behavior for characterizing local global topology around vertex with only minor modification the framework yield a method for extracting interest key point from shape a surprisingly simple algorithm for d shape segmentation competitive with state of the art and a method for surface alignment without landmark we give an extensive set of comparison result on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem 
we introduce topocut a new way to integrate knowledge about topological property tps into random field image segmentation model instead of including tps a additional constraint during minimization of the energy function we devise an efficient algorithm for modifying the unary potential such that the resulting segmentation is guaranteed with the desired property our method is more flexible in the sense that it handle more topology constraint than previous method which were only able to enforce pairwise or global connectivity in particular our method is very fast making it for the first time possible to enforce global topological property in practical image segmentation task 
road scene segmentation is important in computer vision for different application such a autonomous driving and pedestrian detection recovering the d structure of road scene provides relevant contextual information to improve their understanding in this paper we use a convolutional neural network based algorithm to learn feature from noisy label to recover the d scene layout of a road image the novelty of the algorithm relies on generating training label by applying an algorithm trained on a general image dataset to classify on board image further we propose a novel texture descriptor based on a learned color plane fusion to obtain maximal uniformity in road area finally acquired off line and current on line information are combined to detect road area in single image from quantitative and qualitative experiment conducted on publicly available datasets it is concluded that convolutional neural network are suitable for learning d scene layout from noisy label and provides a relative improvement of compared to the baseline furthermore combining color plane provides a statistical description of road area that exhibit maximal uniformity and provides a relative improvement of compared to the baseline finally the improvement is even bigger when acquired and current information from a single image are combined 
several recent work on action recognition have attested the importance of explicitly integrating motion characteristic in the video description this paper establishes that adequately decomposing visual motion into dominant and residual motion both in the extraction of the space time trajectory and for the computation of descriptor significantly improves action recognition algorithm then we design a new motion descriptor the dc descriptor based on differential motion scalar quantity divergence curl and shear feature it capture additional information on the local motion pattern enhancing result finally applying the recent vlad coding technique proposed in image retrieval provides a substantial improvement for action recognition our three contribution are complementary and lead to outperform all reported result by a significant margin on three challenging datasets namely hollywood hmdb and olympic sport 
the performance of part based object detector generally degrades for highly flexible object the limited topological structure of model and pre specified part shape are two main factor preventing these detector from fully capturing large deformation to better capture the deformation we propose a novel approach to integrate the detection from a family of part based detector with patch of object that have irregular shape this integration is formulated a map inference in a conditional random field crf the energy function defined over the crf take into account the information provided by an object patch classifier and the object detector and the goal is to augment the partial detection with missing patch and also to refine the detection that include background clutter the proposed method is evaluated on the object detection task of pascal voc our experimental result show significant improvement over a base part based detector which is among the current state of the art method especially for the deformable object class 
the co occurrence pattern a combination of binary or local feature is more discriminative than individual feature and ha shown it advantage in object scene and action recognition we discus two type of co occurrence pattern that are complementary to each other the conjunction and and disjunction or of binary feature the necessary condition of identifying discriminative co occurrence pattern is firstly provided then we propose a novel data mining method to efficiently discover the optimal co occurrence pattern with minimum empirical error despite the noisy training dataset this mining procedure of and and or pattern is readily integrated to boosting which improves the generalization ability over the conventional boosting decision tree and boosting decision stump our versatile experiment on object scene and action categorization validate the advantage of the discovered discriminative co occurrence pattern 
the success of any graph based clustering algorithm depends heavily on the quality of the similarity matrix being clustered which is itself highly dependent on point wise scaling parameter we propose a novel technique for finding point wise scaling parameter based on ripley s k function which enables data clustering at different density scale within the same dataset additionally we provide a method for enhancing the spatial similarity matrix by including a density metric between neighborhood we show how our proposed method for building similarity matrix can improve the result attained by traditional approach for several well known clustering algorithm on a variety of datasets 
entry level category the label people will use to name an object were originally defined and studied by psychologist in the s in this paper we study entry level category at a large scale and learn the first model for predicting entry level category for image our model combine visual recognition prediction with proxy for word naturalness mined from the enormous amount of text on the web we demonstrate the usefulness of our model for predicting noun entry level word associated with image by people we also learn mapping between concept predicted by existing visual recognition system and entry level concept that could be useful for improving human focused application such a natural language image description or retrieval 
we introduce multiclass kernel projection machine mkpm a new formalism that extends the kernel projection machine framework to the multiclass case our formulation is based on the use of output code and it implement a co regularization scheme by simultaneously constraining the projection dimension associated with the individual predictor that constitute the global classifier in order to solve the optimization problem posed by our formulation we propose an efficient dynamic programming approach numerical simulation conducted on a few pattern recognition problem illustrate the soundness of our approach 
the ubiquitous availability of internet video offer the vision community the exciting opportunity to directly learn localized visual concept from real world imagery unfortunately most such attempt are doomed because traditional approach are ill suited both in term of their computational characteristic and their inability to robustly contend with the label noise that plague uncurated internet content we present crane a weakly supervised algorithm that is specifically designed to learn under such condition first we exploit the asymmetric availability of real world training data where small number of positive video tagged with the concept are supplemented with large quantity of unreliable negative data second we ensure that crane is robust to label noise both in term of tagged video that fail to contain the concept a well a occasional negative video that do finally crane is highly parallelizable making it practical to deploy at large scale without sacrificing the quality of the learned solution although crane is general this paper focus on segment annotation where we show state of the art pixel level segmentation result on two datasets one of which includes a training set of spatiotemporal segment from more than video 
this paper address the problem of learning object model from egocentric video of household activity using extremely weak supervision for each activity sequence we know only the name of the object which are present within it and have no other knowledge regarding the appearance or location of object the key to our approach is a robust unsupervised bottom up segmentation method which exploit the structure of the egocentric domain to partition each frame into hand object and background category by using multiple instance learning to match object instance across sequence we discover and localize object occurrence object representation are refined through transduction and object level classifier are trained we demonstrate encouraging result in detecting novel object instance using model produced by weakly supervised learning 
bag of word bow method are a popular class of object recognition method that use image feature e g sift to form visual dictionary and subsequent histogram vector to represent object image in the recognition process the accuracy of the bow classifier however is often limited by the presence of uninformative feature extracted from the background or irrelevant image segment most existing solution to prune out uninformative feature rely on enforcing pairwise epipolar geometry via an expensive structure from motion sfm procedure such solution are known to break down easily when the camera transformation is large or when the feature are extracted from low resolution low quality image in this paper we propose a novel method to select informative object feature using a more efficient algorithm called sparse pca first we show that using a large scale multiple view object database informative feature can be reliably identified from a highdimensional visual dictionary by applying sparse pca on the histogram of each object category our experiment show that the new algorithm improves recognition accuracy compared to the traditional bow method and sfm method second we present a new solution to sparse pca a a semidefinite programming problem using the augmented lagrangian method the new solver outperforms the state of the art for estimating sparse principal vector a a basis for a low dimensional subspace model 
we propose a novel statistical manifold modeling approach that is capable of classifying pose of object category from video sequence by simultaneously minimizing the intra class variability and maximizing inter pose distance following the intuition that an object part based representation and a suitable part selection process may help achieve our purpose we formulate the part selection problem from a statistical manifold modeling perspective and treat part selection a adjusting the manifold of the object parameterized by pose by mean of the manifold alignment and expansion operation we show that manifold alignment and expansion are equivalent to minimizing the intra class distance given a pose while increasing the inter pose distance given an object instance respectively we formulate and solve this otherwise intractable part selection problem a a combinatorial optimization problem using graph analysis technique quantitative and qualitative experimental analysis validates our theoretical claim 
in this paper we propose a novel solution to uncalibrated photometric stereo our approach is to eliminate the so called generalized ba relief gbr ambiguity by exploiting point where the lambertian reflection is maximal we demonstrate several noteworthy property of these maximum closed form solution a single diffuse maximum constrains the gbr ambiguity to a semi circle in d space efficiency a few a two diffuse maximum in different image identify a unique solution gbr invariance the estimation error of the gbr parameter is completely independent of the true parameter furthermore our algorithm is remarkably robust it can obtain an accurate estimate of the gbr parameter even with extremely high level of outlier in the detected maximum up to of the observation the method is validated on real data and achieves state of the art result 
we propose a novel linear method to match cuboid in indoor scene using rgbd image from kinect beyond depth map these cuboid reveal important structure of a scene instead of directly fitting cuboid to d data we first construct cuboid candidate using super pixel pair on a rgbd image and then we optimize the configuration of the cuboid to satisfy the global structure constraint the optimal configuration ha low local matching cost small object intersection and occlusion and the cuboid tend to project to a large region in the image the number of cuboid is optimized simultaneously we formulate the multiple cuboid matching problem a a mixed integer linear program and solve the optimization efficiently with a branch and bound method the optimization guarantee the global optimal solution our experiment on the kinect rgbd image of a variety of indoor scene show that our proposed method is efficient accurate and robust against object appearance variation occlusion and strong clutter 
a novel component level dictionary learning framework which exploit image group characteristic within sparse coding is introduced in this work unlike previous method which select the dictionary that best reconstruct the data we present an energy minimization formulation that jointly optimizes the learning of both sparse dictionary and component level importance within one unified framework to give a discriminative representation for image group the importance measure how well each feature component represents the image group property with the dictionary by using histogram information then dictionary are updated iteratively to reduce the influence of unimportant component thus refining the sparse representation for each image group in the end by keeping the top k important component a compact representation is derived for the sparse coding dictionary experimental result on several public datasets are shown to demonstrate the superior performance of the proposed algorithm compared to the state of the art method 
we propose a novel framework for reconstructing homogenous transparent refractive height field from a single viewpoint the height field is imaged against a known planar background or sequence of background unlike existing approach that do a point by point reconstruction which is known to have intractable ambiguity our method estimate and optimizes for the entire height field at the same time the formulation support shape recovery from measured distortion deflection or directly from the image themselves including from a single image we report result for a variety of refractive height field showing significant improvement over prior art 
visual tracking play an important role in many computer vision task a common assumption in previous method is that the video frame are blur free in reality motion blur are pervasive in the real video in this paper we present a novel blur driven tracker blut framework for tracking motion blurred target blut actively us the information from blur without performing debluring specifically we integrate the tracking problem with the motion from blur problem under a unified sparse approximation framework we further use the motion information inferred by blur to guide the sampling process in the particle filter based tracking to evaluate our method we have collected a large number of video sequence with significant motion blur and compared blut with state of the art tracker experimental result show that while many previous method are sensitive to motion blur blut can robustly and reliably track severely blurred target 
in the past few year there ha been a growing interest on geometric framework to learn supervised classification model on riemannian manifold a popular framework valid over any riemannian manifold wa proposed in for binary classification once moving from binary to multi class classification this paradigm is not valid anymore due to the spread of multiple positive class on the manifold it is then natural to ask whether the multi class paradigm could be extended to operate on a large class of riemannian manifold we propose a mathematically well founded classification paradigm that allows to extend the work in to multi class model taking into account the structure of the space the idea is to project all the data from the manifold onto an affine tangent space at a particular point to mitigate the distortion induced by local diffeomorphisms we introduce for the first time in the computer vision community a well founded mathematical concept so called rolling map the novelty in this alternate school of thought is that the manifold will be firstly rolled without slipping or twisting a a rigid body then the given data is unwrapped onto the affine tangent space where the classification is performed 
this paper proposes a novel method for recognition and classification of event represented by mixture distribution of location and flow the main idea is to classify observed event into semantically meaningful group even when motion is observed from distinct viewpoint event in the proposed framework are modeled a motion pattern which are represented by mixture of multivariate gaussians and are obtained by hierarchical clustering of optical flow in the four dimensional space x y u v such motion pattern observed from varying viewpoint and in distinct location or datasets can be compared using different family of divergence between statistical distribution given that a transformation between the view is known one of the major contribution of this paper is to compare and match two motion pattern mixture distribution by estimating the similarity transformation between them that minimizes their kullback leibler kl divergence the kl divergence between gaussian mixture is approximated by monte carlo sampling and the minimization is accomplished by employing an iterative nonlinear least square estimation method which bear close resemblance to the iterative closest point icp algorithm we present a robust framework for matching of high dimensional sampled point set representing statistical distribution by defining similarity measure between them for global energy minimization the proposed approach is tested for classification of event observed across several datasets captured from both static and moving camera involving real world pedestrian a well a vehicular motion encouraging result are obtained which demonstrate the feasibility and validity of the proposed approach 
despite decade of study robust shadow detection remains difficult especially within a single color image we describe a new approach to detect shadow boundary in image of outdoor scene lit only by the sun and sky the method first extract visual feature of candidate edge that are motivated by physical model of illumination and occluders we feed these feature into a support vector machine svm that wa trained to discriminate between most likely shadow edge candidate and le likely one finally we connect edge to help reject non shadow edge candidate and to encourage closed connected shadow boundary on benchmark shadow edge data set from lalonde et al and zhu et al our method showed substantial improvement when compared to other recent shadow detection method based on statistical learning 
what do people care about in an image to drive computational visual recognition toward more human centric output we need a better understanding of how people perceive and judge the importance of content in image in this paper we explore how a number of factor relate to human perception of importance proposed factor fall into broad type factor related to composition e g size location factor related to semantics e g category of object or scene and contextual factor related to the likelihood of attribute object or object scene pair we explore these factor using what people describe a a proxy for importance finally we build model to predict what will be described about an image given either known image content or image content estimated automatically by recognition system 
the still to video s v face recognition system typically need to match face in low quality video captured under unconstrained condition against high quality still face image which is very challenging because of noise image blur low face resolution varying head pose complex lighting and alignment difficulty to address the problem one solution is to select the frame of best quality from video hereinafter called quality alignment in this paper meanwhile the face in the selected frame should also be geometrically aligned to the still face offline well aligned in the gallery in this paper we discover that the interaction among the three task quality alignment geometric alignment and face recognition can benefit from each other thus should be performed jointly with this in mind we propose a coupling alignment with recognition car method to tightly couple these task via low rank regularized sparse representation in a unified framework our method make the three task promote mutually by a joint optimization in an augmented lagrange multiplier routine extensive experiment on two challenging s v datasets demonstrate that our method outperforms the state of the art method impressively 
markov random field mrfs have been successfully applied to human activity modelling largely due to their ability to model complex dependency and deal with local uncertainty however the underlying graph structure is often manually specified or automatically constructed by heuristic we show instead that learning an mrf graph and performing map inference can be achieved simultaneously by solving a bilinear program equipped with the bilinear program based map inference for an unknown graph we show how to estimate parameter efficiently and effectively with a latent structural svm we apply our technique to predict sport move such a serve volley in tennis and human activity in tv episode such a kiss hug and hi five experimental result show the proposed method outperforms the state of the art 
existing approach to contextual reasoning for enhanced object detection typically utilize other labeled category in the image to provide contextual information a a consequence they inadvertently commit to the granularity of information implicit in the label moreover large portion of the image may not belong to any of the manually chosen category and these unlabeled region are typically neglected in this paper we overcome both these drawback and propose a contextual cue that exploit unlabeled region in image our approach adaptively determines the granularity scene inter object intra object etc at which contextual information is captured in order to extract the proposed contextual cue we consider a scene to be a structured configuration of object and region just a an object is a composition of part we thus learn our proposed contextual meta object using any off the shelf object detector which make our proposed cue widely accessible to the community our result show that incorporating our proposed cue provides a relative improvement of over a state of the art object detector on the challenging pascal dataset 
we propose a novel algorithm to reconstruct the d geometry of human hair in wide baseline setup using strand based refinement the hair strand are first extracted in each d view and projected onto the d visual hull for initialization the d position of these strand are then refined by optimizing an objective function that take into account cross view hair orientation consistency the visual hull constraint and smoothness constraint defined at the strand wisp and global level based on the refined strand the algorithm can reconstruct an approximate hair surface experiment with synthetic hair model achieve an accuracy of mm we also show real world example to demonstrate the capability to capture full head hair style a well a hair in motion with a few a camera 
we present a new approach to matching graph embedded in r or r unlike earlier method our approach doe not rely on the similarity of local appearance feature doe not require an initial alignment can handle partial match and can cope with non linear deformation and topological difference to handle arbitrary non linear deformation we represent them a gaussian process in the absence of appearance information we iteratively establish correspondence between graph node update the structure accordingly and use the current mapping estimate to find the most likely correspondence that will be used in the next iteration this make the computation tractable we demonstrate the effectiveness of our approach first on synthetic case and then on angiography data retinal fundus image and microscopy image stack acquired at very different resolution 
recent year have witnessed the active development of hashing technique for nearest neighbor search over big datasets however to apply hashing technique successfully there are several important issue remaining open in selecting feature hashing algorithm parameter setting kernel etc in this work we unify all these selection problem into a hash bit selection framework i e selecting the most informative hash bit from a pool of candidate bit generated by different type of hashing method using different feature space and or parameter setting etc we represent the bit pool a a vertexand edge weighted graph with the candidate bit a vertex the vertex weight represents the bit quality in term of similarity preservation and the edge weight reflects independence non redundancy between bit then we formulate the bit selection problem a quadratic programming on the graph and solve it efficiently by replicator dynamic moreover a theoretical study is provided to reveal a very interesting insight the selected bit actually are the normalized dominant set of the candidate bit graph we conducted extensive large scale experiment for three important application scenario of hash technique i e hashing with multiple feature multiple hashing algorithm and multiple bit hashing we demonstrate that our bit selection approach can achieve superior performance over both naive selection method and state of the art hashing method under each scenario with significant accuracy gain ranging from to relatively 
while activity recognition is a current focus of research the challenging problem of fine grained activity recognition is largely overlooked we thus propose a novel database of cooking activity continuously recorded in a realistic setting activity are distinguished by fine grained body motion that have low inter class variability and high intra class variability due to diverse subject and ingredient we benchmark two approach on our dataset one based on articulated pose track and the second using holistic video feature while the holistic approach outperforms the pose based approach our evaluation suggests that fine grained activity are more difficult to detect and the body model can help in those case providing high resolution video a well a an intermediate pose representation we hope to foster research in fine grained activity recognition 
most feature selection method for object tracking assume that the labeled sample obtained in the next frame follow the similar distribution with the sample in the previous frame however this assumption is not true in some scenario a a result the selected feature are not suitable for tracking and the drift problem happens in this paper we consider data s distribution in tracking from a new perspective we classify the sample into three category auxiliary sample sample in the previous frame target sample collected in the current frame and unlabeled sample obtained in the next frame to make the best use of them for tracking we propose a novel semi supervised transfer learning approach specifically we assume only target sample follow the same distribution a the unlabeled sample and develop a novel semi supervised covboost method it could utilize auxiliary sample and unlabeled sample effectively when training the best strong classifier for tracking furthermore we develop a new online updating algorithm for semi supervised covboost making our tracker handle with significant variation of the tracked target and background successfully we demonstrate the excellent performance of the proposed tracker on several challenging test video 
many computer vision problem have an asymmetric distribution of information between training and test time in this work we study the case where we are given additional information about the training data which however will not be available at test time this situation is called learning using privileged information lupi we introduce two maximum margin technique that are able to make use of this additional source of information and we show that the framework is applicable to several scenario that have been studied in computer vision before experiment with attribute bounding box image tag and rationale a additional information in object classification show promising result 
the use of statistical pattern recognition model to segment the left ventricle of the heart in ultrasound image ha gained substantial attention over the last few year the main obstacle for the wider exploration of this methodology lie in the need for large annotated training set which are used for the estimation of the statistical model parameter in this paper we present a new on line co training methodologythat reduces the need for large training set for such parameter estimation our approach learns the initial parameter of two different model using a small manually annotated training set then given each frame of a test sequence the methodology not only produce the segmentation of the current frame but it also us the result of both classifier to retrain each other incrementally this on line aspect of our approach ha the advantage of producing segmentation result and retraining the classifier on the fly a frame of a test sequence are presented but it introduces a harder learning setting compared to the usual off line co training where the algorithm ha access to the whole set of un annotated training sample from the beginning moreover we introduce the use of the following new type of classifier in the co training framework deep belief network and multiple model probabilistic data association we show that our method lead to a fully automatic left ventricle segmentation system that achieves state of the art accuracy on a public database with training set containing at least twenty annotated image 
large scale recognition problem with thousand of class pose a particular challenge because applying the classifier requires more computation a the number of class grows the label tree model integrates classification with the traversal of the tree so that complexity grows logarithmically in this paper we show how the parameter of the label tree can be found using maximum likelihood estimation this new probabilistic learning technique produce a label tree with significantly improved recognition accuracy 
computer vision analysis of cell in phase contrast microscopy image enables long term continuous monitoring of live cell which ha not been feasible using the existing cellular staining method due to the use of fluorescence reagent or fixative in cell culture analysis accurate detection of mitosis or cell division is critical for quantitative study of cell proliferation in this work we present an approach that can detect mitosis within a cell population of high cell confluence or high cell density which ha proven challenging because of the difficulty in separating individual cell we first detect the candidate for birth event that are defined a the time and location at which mitosis is complete and two daughter cell first appear each candidate is then examined whether it is real or not after incorporating spatio temporal information by tracking the candidate in the neighboring frame for the examination we design a probabilistic model named two labeled hidden conditional random field tl hcrf that can use the information on the timing of the candidate birth event in addition to the visual change of cell over time applied to two cell population of high cell confluence our method considerably outperforms previous method comparison with related statistical model also show the superiority of tl hcrf on the proposed task 
we propose a mid level statistical model for image segmentation that composes multiple figure ground hypothesis fg obtained by applying constraint at different location and scale into larger interpretation tiling of the entire image inference is cast a optimization over set of maximal clique sampled from a graph connecting all non overlapping figure ground segment hypothesis potential function over clique combine unary gestalt based figure quality and pairwise compatibility among spatially neighboring segment constrained by t junction and the boundary interface statistic of real scene learning the model parameter is based on maximum likelihood alternating between sampling image tiling and optimizing their potential function parameter state of the art result are reported on the berkeley and stanford segmentation datasets a well a voc where a improvement wa achieved 
sentence that describe visual scene contain a wide variety of information pertaining to the presence of object their attribute and their spatial relation in this paper we learn the visual feature that correspond to semantic phrase derived from sentence specifically we extract predicate tuples that contain two noun and a relation the relation may take several form such a a verb preposition adjective or their combination we model a scene using a conditional random field crf formulation where each node corresponds to an object and the edge to their relation we determine the potential of the crf using the tuples extracted from the sentence we generate novel scene depicting the sentence visual meaning by sampling from the crf the crf is also used to score a set of scene for a text based image retrieval task our result show we can generate retrieve scene that convey the desired semantic meaning even when scene query are described by multiple sentence significant improvement is found over several baseline approach 
the present work describes an active stereo apparatus that can not only recover scene geometry but also resolve spatial detail beyond the camera optical cutoff the apparatus is comprised of a camera and a projector whose center of perspective is located in the camera pupil plane 
we present a local feature detector that is able to detect region of arbitrary scale and shape without scale space construction we compute a weighted distance map on image gradient using our exact linear time algorithm a variant of group marching for euclidean space we find the weighted medial axis by extending residue typically used in voronoi skeleton we decompose the medial axis into a graph representing image structure in term of peak and saddle point a duality property enables reconstruction of region using the same marching method we greedily group region taking both contrast and shape into account on the way we select region according to our shape fragmentation factor favoring those well enclosed by boundary even incomplete we achieve state of the art performance in matching and retrieval experiment with reduced memory and computational requirement 
we present a model for gaze prediction in egocentric video by leveraging the implicit cue that exist in camera wearer s behavior specifically we compute the camera wearer s head motion and hand location from the video and combine them to estimate where the eye look we further model the dynamic behavior of the gaze in particular fixation a latent variable to improve the gaze prediction our gaze prediction result outperform the state of the art algorithm by a large margin on publicly available egocentric vision datasets in addition we demonstrate that we get a significant performance boost in recognizing daily action and segmenting foreground object by plugging in our gaze prediction into state of the art method 
image captured in foggy weather condition often suffer from bad visibility in this paper we propose an efficient regularization method to remove haze from a single input image our method benefit much from an exploration on the inherent boundary constraint on the transmission function this constraint combined with a weighted l norm based contextual regularization is modeled into an optimization problem to estimate the unknown scene transmission a quite efficient algorithm based on variable splitting is also presented to solve the problem the proposed method requires only a few general assumption and can restore a high quality haze free image with faithful color and fine image detail experimental result on a variety of haze image demonstrate the effectiveness and efficiency of the proposed method 
a novel approach to d gaze estimation for wearable multi camera device is proposed and it effectiveness is demonstrated both theoretically and empirically the proposed approach firmly grounded on the geometry of the multiple view introduces a calibration procedure that is efficient accurate highly innovative but also practical and easy thus it can run online with little intervention from the user the overall gaze estimation model is general a no particular complex model of the human eye is assumed in this work this is made possible by a novel approach that can be sketched a follows each eye is imaged by a camera two conic are fitted to the imaged pupil and a calibration sequence consisting in the subject gazing a known d point while moving his her head provides information to estimate the optical axis in d world compute the geometry of the multi camera system estimate the point of regard in d world the resultant model is being used effectively to study visual attention by mean of gaze estimation experiment involving people performing natural task in wide field unstructured scenario 
spatio temporal interest point serve a an elementary building block in many modern action recognition algorithm and most of them exploit the local spatio temporal volume feature using a bag of visual word bovw representation such representation however ignores potentially valuable information about the global spatio temporal distribution of interest point in this paper we propose a new global feature to capture the detailed geometrical distribution of interest point it is calculated by using the r transform which is defined a an extended d discrete radon transform followed by applying a two directional two dimensional principal component analysis such r feature capture the geometrical information of the interest point and keep invariant to geometry transformation and robust to noise in addition we propose a new fusion strategy to combine the r feature with the bovw representation for further improving recognition accuracy we utilize a context aware fusion method to capture both the pairwise similarity and higher order contextual interaction of the video experimental result on several publicly available datasets demonstrate the effectiveness of the proposed approach for action recognition 
in this paper we address the problem of learning discriminative part detector from image set with category label we propose a novel latent svm model regularized by group sparsity to learn these part detector starting from a large set of initial part the group sparsity regularizer force the model to jointly select and optimize a set of discriminative part detector in a max margin framework we propose a stochastic version of a proximal algorithm to solve the corresponding optimization problem we apply the proposed method to image classification and co segmentation and quantitative experiment with standard benchmark show that it match or improves upon the state of the art 
we present a new approach to general activity human pose estimation from depth image building on hough forest we extend existing technique in several way real time prediction of multiple d joint explicit learning of voting weight vote compression to allow larger training set and a comparison of several decision tree training objective key aspect of our work include regression directly from the raw depth image without the use of an arbitrary intermediate representation applicability to general motion not constrained to particular activity and the ability to localize occluded a well a visible body joint experimental result demonstrate that our method produce state of the art result on several data set including the challenging msrc pose estimation test set at a speed of about frame per second result on silhouette suggest broader applicability to other imaging modality 
within the field of urban reconstruction and city modeling shape grammar have emerged a a powerful tool for both synthesizing novel design and reconstructing building traditionally a human expert wa required to write grammar for specific building style which limited the scope of method applicability we present an approach to automatically learn two dimensional attributed stochastic context free grammar d ascfgs from a set of labeled building facade to this end we use bayesian model merging a technique originally developed in the field of natural language processing which we extend to the domain of two dimensional language given a set of labeled positive example we induce a grammar which can be sampled to create novel instance of the same building style in addition we demonstrate that our learned grammar can be used for parsing existing facade imagery experiment conducted on the dataset of haussmannian building in paris show that our parsing with learned grammar not only outperforms bottom up classifier but is also on par with approach that use a manually designed style grammar 
human action recognition in video draw strong research interest in computer vision because of it promising application for video surveillance video annotation interactive gaming etc however the amount of video data containing human action is increasing exponentially which make the management of these resource a challenging task given a database with huge volume of unlabeled video it is prohibitive to manually assign specific action type to these video considering that it is much easier to obtain a small number of labeled video a practical solution for organizing them is to build a mechanism which is able to conduct action annotation automatically by leveraging the limited labeled video motivated by this intuition we propose an automatic video annotation algorithm by integrating semi supervised learning and shared structure analysis into a joint framework for human action recognition we apply our algorithm on both synthetic and realistic video datasets including kth caremedia dataset youtube action and it extended version ucf extensive experiment demonstrate that the proposed algorithm outperforms the compared algorithm for action recognition most notably our method ha a very distinct advantage over other compared algorithm when we have only a few labeled sample 
reconstruction from structured light can be greatly affected by interreflection between surface in the scene this paper introduces band pas white noise pattern designed specifically to reduce interreflection and still be robust to standard challenge in scanning system such a scene depth discontinuity defocus and low camera projector pixel ratio while this approach us unstructured light pattern that increase the number of required projected image it is up to our knowledge the first method that is able to recover scene disparity in the presence of both scene discontinuity and interreflection furthermore the method doe not require calibration geometric nor photometric or post processing such a dynamic programming or phase unwrapping we show result for a challenging scene and compare them to correspondence obtained with the well known gray code and phase shift method 
multiple object tracking ha been formulated recently a a global optimization problem and solved efficiently with optimal method such a the hungarian algorithm a severe limitation is the inability to model multiple object that are merged into a single measurement and track them a a group while retaining optimality this work present a new graph structure that encodes these multiple match event a standard one to one match allowing computation of the solution in polynomial time since identity are lost when object merge an efficient method to identify group is also presented a a flow circulation problem the problem of tracking individual object across group is then posed a a standard optimal assignment experiment show increased performance on the pet and datasets compared to state of the art algorithm 
automatic facial action unit afa detection from video is a long standing problem in facial expression analysis most approach emphasize choice of feature and classifier they neglect individual difference in target person people vary markedly in facial morphology e g heavy versus delicate brow smooth versus deeply etched wrinkle and behavior individual difference can dramatically influence how well generic classifier generalize to previously unseen person while a possible solution would be to train person specific classifier that often is neither feasible nor theoretically compelling the alternative that we propose is to personalize a generic classifier in an unsupervised manner no additional label for the test subject are required we introduce a transductive learning method which we refer to selective transfer machine stm to personalize a generic classifier by attenuating person specific bias stm achieves this effect by simultaneously learning a classifier and re weighting the training sample that are most relevant to the test subject to evaluate the effectiveness of stm we compared stm to generic classifier and to cross domain learning method in three major database ck gemep fera and ru facs stm outperformed generic classifier in all 
this paper present a method for quasi rigid object modeling from a sequence of depth scan captured at different time instance a quasi rigid object such a human body usually have shape motion during the capture procedure it is difficult to reconstruct their geometry we represent the shape motion by a deformation graph and propose a model to part method to gradually integrate sampled point of depth scan into the deformation graph under an a rigid a possible assumption the model to part method can adjust the deformation graph non rigidly so a to avoid error accumulation in alignment which also implicitly achieves loop closure to handle the drift and topological error for the deformation graph two algorithm are introduced first we use a two stage registration to largely keep the rigid motion part second in the step of graph integration we topology adaptively integrate new part and dynamically control the regularization effect of the deformation graph we demonstrate the effectiveness and robustness of our method by several depth sequence of quasi rigid object and an application in human shape modeling 
equivariance and invariance are often desired property of a computer vision system however currently available strategy generally rely on virtual sampling leaving open the question of how many sample are necessary on the use of invariant feature representation which can mistakenly discard information relevant to the vision task or on the use of latent variable model which result in non convex training and expensive inference at test time we propose here a generalization of structured output svm regressors that can incorporate equivariance and invariance into a convex training procedure enabling the incorporation of large family of transformation while maintaining optimality and tractability importantly test time inference doe not require the estimation of latent variable resulting in highly efficient objective function this result in a natural formulation for treating equivariance and invariance that is easily implemented a an adaptation of off the shelf optimization software obviating the need for ad hoc sampling strategy theoretical result relating to vicinal risk and experiment on challenging aerial car and pedestrian detection task show the effectiveness of the proposed solution 
polar object representation have proven to be a powerful shape model for many medical a well a other computer vision application such a interactive image segmentation or tracking inspired by recent work on sobolev active contour we derive a sobolev type function space for polar curve this so called polar space is endowed with a metric that allows u to favor origin translation and scale change over smooth deformation of the curve moreover the resulting curve flow inherits the coarse to fine behavior of sobolev active contour and is thus very robust to local minimum these property make the resulting polar active contour a powerful segmentation tool for many medical application such a cross sectional vessel segmentation aneurysm analysis or cell tracking 
we investigate the contour detection task in complex natural image we propose a novel contour detection algorithm which locally track small piece of edge called edgelets the combination of the bayesian modeling and the edgelets enables the use of semi local prior information and image dependent likelihood we use a mixed offline and online learning strategy to detect the most relevant edgelets the detection problem is then modeled a a sequential bayesian tracking task estimated using a particle filtering technique experiment on the berkeley segmentation datasets show that the proposed particle filter contour detector method performs well compared to competing state of the art method 
this paper address real world challenge in the motion segmentation problem including perspective effect missing data and unknown number of motion it first formulates the d motion segmentation from two perspective view a a subspace clustering problem utilizing the epipolar constraint of an image pair it then combine the point correspondence information across multiple image frame via a collaborative clustering step in which tight integration is achieved via a mixed norm optimization scheme for model selection we propose an over segment and merge approach where the merging step is based on the property of the ell norm of the mutual sparse representation of two over segmented group the resulting algorithm can deal with incomplete trajectory and perspective effect substantially better than state of the art two frame and multi frame method experiment on a clip dataset show the significant superiority of the proposed idea in both segmentation accuracy and model selection 
in material science and engineering the grain structure inside a super alloy sample determines it mechanical and physical property in this paper we develop a new multichannel edge weighted centroidal voronoi tessellation mcewcvt algorithm to automatically segment all the d grain from microscopic image of a super alloy sample built upon the classical k mean cvt algorithm the proposed algorithm considers both the voxel intensity similarity within each cluster and the compactness of each cluster in addition the same slice of a super alloy sample can produce multiple image with different grain appearance using different setting of the microscope we call this multichannel imaging and in this paper we further adapt the proposed segmentation algorithm to handle such multichannel image to achieve higher grain segmentation accuracy we test the proposed mcewcvt algorithm on a channel ni based d super alloy image consisting of slice the segmentation performance is evaluated against the manually annotated ground truth segmentation and quantitatively compared with other six image segmentation edge detection method the experimental result demonstrate the higher accuracy of the proposed algorithm than the comparison method 
in the last year intrinsic image decomposition ha gained attention most of the state of the art method are based on the assumption that reflectance change come along with strong image edge recently user intervention in the recovery problem ha proved to be a remarkable source of improvement in this paper we propose a novel approach that aim to overcome the shortcoming of pure edge based method by introducing strong surface descriptor such a the color name descriptor which introduces high level consideration resembling top down intervention we also use a second surface descriptor termed color shade which allows u to include physical consideration derived from the image formation model capturing gradual color surface variation both color cue are combined by mean of a markov random field the method is quantitatively tested on the mit ground truth dataset using different error metric achieving state of the art performance 
despite the success of current state of the art object class detector severe occlusion remains a major challenge this is particularly true for more geometrically expressive d object class representation while these representation have attracted renewed interest for precise object pose estimation the focus ha mostly been on rather clean datasets where occlusion is not an issue in this paper we tackle the challenge of modeling occlusion in the context of a d geometric object class model that is capable of fine grained part level d object reconstruction following the intuition that d modeling should facilitate occlusion reasoning we design an explicit representation of likely geometric occlusion pattern robustness is achieved by pooling image evidence from of a set of fixed part detector a well a a non parametric representation of part configuration in the spirit of pose let we confirm the potential of our method on car in a newly collected data set of inner city street scene with varying level of occlusion and demonstrate superior performance in occlusion estimation and part localization compared to baseline that are unaware of occlusion 
we recast the cosegmentation problem using random walker rw segmentation a the core segmentation algorithm rather than the traditional mrf approach adopted in the literature so far our formulation is similar to previous approach in the sense that it also permit cosegmentation constraint which impose consistency between the extracted object from image using a nonparametric model however several previous nonparametric cosegmentation method have the serious limitation that they require adding one auxiliary node or variable for every pair of pixel that are similar which effectively limit such method to describing only those object that have high entropy appearance model in contrast our proposed model completely eliminates this restrictive dependence the resulting improvement are quite significant our model further allows an optimization scheme exploiting quasiconvexity for model based segmentation with no dependence on the scale of the segmented foreground finally we show that the optimization can be expressed in term of linear algebra operation on sparse matrix which are easily mapped to gpu architecture we provide a highly specialized cuda library for cosegmentation exploiting this special structure and report experimental result showing these advantage 
in this paper we make three main contribution in the area of action recognition i we introduce the concept of joint self similarity volume joint ssv for modeling dynamical system and show that by using a new optimized rank tensor approximation of joint ssv one can obtain compact low dimensional descriptor that very accurately preserve the dynamic of the original system e g an action video sequence ii the descriptor vector derived from the optimized rank approximation make it possible to recognize action without explicitly aligning the action sequence of varying speed of execution or different frame rate iii the method is generic and can be applied using different low level feature such a silhouette histogram of oriented gradient etc hence it doe not necessarily require explicit tracking of feature in the space time volume our experimental result on three public datasets demonstrate that our method produce remarkably good result and outperforms all baseline method 
visual attribute expose human defined semantics to object recognition model but existing work largely restricts their influence to mid level cue during classifier training rather than treat attribute a intermediate feature we consider how learning visual property in concert with object category can regularize the model for both given a low level visual feature space together with attribute and object labeled image data we learn a shared lower dimensional representation by optimizing a joint loss function that favor common sparsity pattern across both type of prediction task we adopt a recent kernelized formulation of convex multi task feature learning in which one alternate between learning the common feature and learning task specific classifier parameter on top of those feature in this way our approach discovers any structure among the image descriptor that is relevant to both task and allows the top down semantics to restrict the hypothesis space of the ultimate object classifier we validate the approach on datasets of animal and outdoor scene and show significant improvement over traditional multi class object classifier and direct attribute prediction model 
despite significant progress most existing visual dictionary learning method rely on image descriptor alone or together with class label however web image are often associated with text data which may carry substantial information regarding image semantics and may be exploited for visual dictionary learning this paper explores this idea by leveraging relational information between image descriptor and textual word via co clustering in addition to information of image descriptor existing co clustering method are not optimal for this problem because they ignore the structure of image descriptor in the continuous space which is crucial for capturing visual characteristic of image we propose a novel bayesian co clustering model to jointly estimate the underlying distribution of the continuous image descriptor a well a the relationship between such distribution and the textual word through a unified bayesian inference extensive experiment on image categorization and retrieval have validated the substantial value of the proposed joint modeling in improving visual dictionary learning where our model show superior performance over several recent method 
we present an efficient deterministic hypothesis generation algorithm for robust fitting of multiple structure based on the maximum feasible subsystem maxfs framework despite it advantage a global optimization method such a maxfs ha two main limitation for geometric model fitting first it performance is much influenced by the user specified inlier scale second it is computationally inefficient for large data the presented algorithm called iterative maxfs with inlier scale imaxfs ise iteratively estimate model parameter and inlier scale and also overcomes the second limitation by reducing data for the maxfs problem the imaxfs ise algorithm generates hypothesis only with top n ranked subset based on matching score and data fitting residual this reduction of data for the maxfs problem make the algorithm computationally realistic a sequential fitting and removing procedure is repeated until overall energy function doe not decrease experimental result demonstrate that our method can generate more reliable and consistent hypothesis than random sampling based method for estimating multiple structure from data with many outlier 
we address the problem of d d pose estimation in difficult viewing condition such a low illumination cluttered background and large highlight and shadow that appear on the object of interest in such challenging condition conventional feature used for establishing correspondence are unreliable we show that under the assumption of a dominant light source specular highlight produced by a known object can be used to establish correspondence between it image and the d model and to verify the hypothesized pose these idea are incorporated in an efficient method for pose estimation from a monocular image of an object using only highlight produced by the object a it input the proposed method us no knowledge of lighting direction and no calibration object for estimating the lighting in the scene the evaluation of the method show good accuracy on numerous synthetic image and good robustness on real image of complex shiny object with shadow and difficult background 
in this paper we present a method for accurately estimating the shape of an object by integrating the surface orientation measured by photometric stereo and the position measured by some range measuring method we first show that even if the knowledge of the reflectance illumination is inaccurate the first derivative of the photometrically measured orientation can be accurately estimated at the surface point where they have small value we propose a probabilistic framework to quantitate the in accuracy of the knowledge and connect it to the estimation accuracy of these derivative based on this framework we consider optimally integrating the surface orientation and position to obtain the object shape with higher accuracy the integration reduces to an optimization problem and it is efficiently solved by belief propagation we present several experimental result showing the effectiveness of the proposed approach 
a general formulation of bayesian adaptation for generative and discriminative classification in the topic model framework is proposed a generic topic independent gaussian mixture model known a the background gmm is learned using all available training data and adapted to the individual topic in the generative framework a gaussian variant of the spatial pyramid model is used with a bayes classifier for the discriminative case a novel predictive histogram representation for an image is presented this build upon the adapted topic model structure using the individual class dictionary and bayesian weighting the resulting histogram representation is evaluated for classification using a support vector machine svm a comparative evaluation of the proposed image model with the standard one in the image classification literature is provided on three benchmark datasets 
we introduce an online learning approach to produce discriminative part based appearance model dpams for tracking multiple human in real scene by incorporating association based and category free tracking method detection response are gradually associated into tracklets in multiple level to produce final track unlike most previous multi target tracking approach which do not explicitly consider occlusion in appearance modeling we introduce a part based model that explicitly find unoccluded part by occlusion reasoning in each frame so that occluded part are removed in appearance modeling then dpams for each tracklet is online learned to distinguish a tracklet with others a well a the background and is further used in a conservative category free tracking approach to partially overcome the missed detection problem a well a to reduce difficulty in tracklet association under long gap we evaluate our approach on three public data set and show significant improvement compared with state of art method 
we are interested in the problem of automatic tracking and identification of player in broadcast sport video shot with a moving camera from a medium distance while there are many good tracking system there are fewer method that can identify the tracked player player identification is challenging in such video due to blurry facial feature due to fast camera motion and low resolution and rarely visible jersey number which when visible are deformed due to player movement we introduce a new system consisting of three component a robust tracking system a robust person identification system and a conditional random field crf model that can perform joint probabilistic inference about the player identity the resulting system is able to achieve a player recognition accuracy up to on unlabeled nba basketball clip 
we propose a novel approach for human pose estimation in real world cluttered scene and focus on the challenging problem of predicting the pose of both arm for each person in the image for this purpose we build on the notion of poselets and train highly discriminative classifier to differentiate among arm configuration which we call armlet we propose a rich representation which in addition to standard hog feature integrates the information of strong contour skin color and contextual cue in a principled manner unlike existing method we evaluate our approach on a large subset of image from the pascal voc detection dataset where critical visual phenomenon such a occlusion truncation multiple instance and clutter are the norm our approach outperforms yang and ramanan the state of the art technique with an improvement from to pcp accuracy on the arm keypoint prediction task on this new pose estimation dataset 
we study fine grained categorization the task of distinguishing among sub category of the same generic object class e g bird focusing on determining botanical specie leaf and orchid from scanned image the strategy is to focus attention around several vantage point which is the approach taken by botanist but using feature dedicated to the individual category our implementation of the strategy is based on it vantage feature frame a novel object representation consisting of two component a set of coordinate system centered at the most discriminating local viewpoint for the generic object class and a set of category dependent feature computed in these frame the feature are pooled over frame to build the classifier categorization then proceeds from coarse grained finding the frame to fine grained finding the category and hence the vantage feature frame must be both detectable and discriminating the proposed method outperforms state of the art algorithm in particular those using more distributed representation on standard database of leaf 
the low resolution of image ha been one of the major limitation in recognising human from a distance using their biometric trait such a face and iris superresolution ha been employed to improve the resolution and the recognition performance simultaneously however the majority of technique employed operate in the pixel domain such that the biometric feature vector are extracted from a super resolved input image feature domain superresolution ha been proposed for face and iris and is shown to further improve recognition performance by capitalising on direct super resolving the feature which are used for recognition however current feature domain superresolution approach are limited to simple linear feature such a principal component analysis pca and linear discriminant analysis lda which are not the most discriminant feature for biometrics gabor based feature have been shown to be one of the most discriminant feature for biometrics including face and iris this paper proposes a framework to conduct super resolution in the non linear gabor feature domain to further improve the recognition performance of biometric system experiment have confirmed the validity of the proposed approach demonstrating superior performance to existing linear approach for both face and iris biometrics 
a having multiple image of an object is practically convenient nowadays to jointly align them is important for subsequent study and a wide range of application in this paper we propose a model based approach to jointly align a batch of image of a face undergoing a variety of geometric and appearance variation the principal idea is to model the non rigid deformation of a face by mean of a learned deformable model different from existing model based method such a active appearance model the proposed one doe not rely on an accurate appearance model built from a training set we propose a robust fitting method that simultaneously identifies the appearance space of the input face and brings the image into alignment the experiment conducted on image in the wild in comparison with competing method demonstrate the effectiveness of our method in joint alignment of complex object like human face 
this paper address view invariant object detection and pose estimation from a single image while recent work focus on object centered representation of point based object feature we revisit the viewer centered framework and use image contour a basic feature given training example of arbitrary view of an object we learn a sparse object model in term of a few view dependent shape template the shape template are jointly used for detecting object occurrence and estimating their d pose in a new image instrumental to this is our new mid level feature called bag of boundary bob aimed at lifting from individual edge toward their more informative summary for identifying object boundary amidst the background clutter in inference bob are placed on deformable grid both in the image and the shape template and then matched this is formulated a a convex optimization problem that accommodates invariance to non rigid locally affine shape deformation evaluation on benchmark datasets demonstrates our competitive result relative to the state of the art 
in computer vision there ha been increasing interest in learning hashing code whose hamming distance approximates the data similarity the hashing function play role in both quantizing the vector space and generating similarity preserving code most existing hashing method use hyper plane or kernelized hyper plane to quantize and encode in this paper we present a hashing method adopting the k mean quantization we propose a novel affinity preserving k mean algorithm which simultaneously performs k mean clustering and learns the binary index of the quantized cell the distance between the cell is approximated by the hamming distance of the cell index we further generalize our algorithm to a product space for learning longer code experiment show our method named a k mean hashing kmh outperforms various state of the art hashing encoding method 
dense motion field estimation typically optical flow stereo disparity and surface registration is a key computer vision problem many solution have been proposed to compute small or large displacement narrow or wide baseline stereo disparity but a unified methodology is still lacking we here introduce a general framework that robustly combine direct and feature based matching the feature based cost is built around a novel robust distance function that handle key point and weak feature such a segment it allows u to use putative feature match which may contain mismatch to guide dense motion estimation out of local minimum our framework us a robust direct data term ad census it is implemented with a powerful second order total generalized variation regularization with external and self occlusion reasoning our framework achieves state of the art performance in several case standard optical flow benchmark wide baseline stereo and non rigid surface registration our framework ha a modular design that customizes to specific application need 
we introduce a novel type of total variation regularizer tv s for cyclic structure such a angle or hue value the method handle the periodicity of value in a simple and consistent way and is invariant to value shift the regularizer is integrated in a recent functional lifting framework which allows for arbitrary nonconvex data term result are superior and more natural than with the simple total variation without special care about wrapping interval end point in addition we propose an equivalent formulation which can be minimized with the same time and memory efficiency a the standard total variation 
this paper present an approach to localizing functional object in surveillance video without domain knowledge about semantic object class that may appear in the scene functional object do not have discriminative appearance and shape but they affect behavior of people in the scene for example they attract people to approach them for satisfying certain need e g vending machine could quench thirst or repel people to avoid them e g grass lawn therefore functional object can be viewed a dark matter emanating dark energy that affect people s trajectory in the video to detect dark matter and infer their dark energy field we extend the lagrangian mechanic people are treated a particle agent with latent intent to approach dark matter and thus satisfy their need where their motion are subject to a composite dark energy field of all functional object in the scene we make the assumption that people take globally optimal path toward the intended dark matter while avoiding latent obstacle a bayesian framework is used to probabilistically model people s trajectory and intent constraint map of the scene and location of functional object a data driven markov chain monte carlo mcmc process is used for inference our evaluation on video of public square and courtyard demonstrates our effectiveness in localizing functional object and predicting people s trajectory in unobserved part of the video footage 
in this paper we propose a novel framework to jointly recover the illumination environment and an estimate of the cast shadow in a scene from a single image given coarse d geometry we describe a higher order markov random field mrf illumination model which combine low level shadow evidence with high level prior knowledge for the joint estimation of cast shadow and the illumination environment first a rough illumination estimate and the structure of the graphical model in the illumination space is determined through a voting procedure then a higher order approach is considered where illumination source are coupled with the observed image and the latent variable corresponding to the shadow detection we examine two inference method in order to effectively minimize the mrf energy of our model experimental evaluation show that our approach is robust to rough knowledge of geometry and reflectance and inaccurate initial shadow estimate we demonstrate the power of our mrf illumination model on various datasets and show that we can estimate the illumination in image of object belonging to the same class using the same coarse d model to represent all instance of the class 
in this paper we present a visual ego motion estimation algorithm for a self driving car equipped with a close to market multi camera system by modeling the multi camera system a a generalized camera and applying the non holonomic motion constraint of a car we show that this lead to a novel point minimal solution for the generalized essential matrix where the full relative motion including metric scale can be obtained we provide the analytical solution for the general case with at least one inter camera correspondence and a special case with only intra camera correspondence we show that up to a maximum of solution exist for both case we identify the existence of degeneracy when the car undergoes straight motion in the special case with only intra camera correspondence where the scale becomes unobservable and provide a practical alternative solution our formulation can be efficiently implemented within ransac for robust estimation we verify the validity of our assumption on the motion model by comparing our result on a large real world dataset collected by a car equipped with camera with minimal overlapping field of view against the gps in ground truth 
in this paper we address the challenging problem of categorizing video sequence composed of dynamic natural scene contrarily to previous method that rely on handcrafted descriptor we propose here to represent video using unsupervised learning of motion feature our method encompasses three main contribution based on the slow feature analysis principle we introduce a learned local motion descriptor which represents the principal and more stable motion component of training video we integrate our local motion feature into a global coding pooling architecture in order to provide an effective signature for each video sequence we report state of the art classification performance on two challenging natural scene data set in particular an outstanding improvement of in classification score is reached on a data set introduced in 
although multi frame super resolution ha been extensively studied in past decade super resolving real world video sequence still remains challenging in existing system either the motion model are oversimplified or important factor such a blur kernel and noise level are assumed to be known such model cannot deal with the scene and imaging condition that vary from one sequence to another in this paper we propose a bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion blur kernel and noise level while reconstructing the original high re frame a a result our system not only produce very promising super resolution result that outperform the state of the art but also adapts to a variety of noise level and blur kernel theoretical analysis of the relationship between blur kernel noise level and frequency wise reconstruction rate is also provided consistent with our experimental result 
we propose a branch and cut strategy for efficient region based object detection given an oversegmented image our method determines the subset of spatially contiguous region whose collective feature will maximize a classifier s score we formulate the objective a an instance of the prize collecting steiner tree problem and show that for a family of additive classifier this enables fast search for the optimal object region via a branch and cut algorithm unlike existing branch and bounddetection method designed for bounding box our approach allows scoring of irregular shape which is especially critical for object that do not conform to a rectangular window we provide result on three challenging object detection datasets and demonstrate the advantage of rapidly seeking best scoring region rather than subwindow rectangle 
we present a method for learning image representation using a two layer sparse coding scheme at the pixel level the first layer encodes local patch of an image after pooling within local region the first layer code are then passed to the second layer which jointly encodes signal from the region unlike traditional sparse coding method that encode local patch independently this approach account for high order dependency among pattern in a local image neighborhood we develop algorithm for data encoding and codebook learning and show in experiment that the method lead to more invariant and discriminative image representation the algorithm give excellent result for hand written digit recognition on mnist and object recognition on the caltech benchmark this mark the first time that such accuracy have been achieved using automatically learned feature from the pixel level rather than using hand designed descriptor 
recent advance in d shape recognition have shown that kernel based on diffusion geometry can be effectively used to describe local feature of deforming surface in this paper we introduce a new framework that allows using these kernel on d local patch yielding a novel feature point descriptor that is both invariant to non rigid image deformation and illumination change in order to build the descriptor d image patch are embedded a d surface by multiplying the intensity level by an arbitrarily large and constant weight that favor anisotropic diffusion and retains the gradient magnitude information patch are then described in term of a heat kernel signature which is made invariant to intensity change rotation and scaling the resulting feature point descriptor is proven to be significantly more discriminative than state of the art one even those which are specifically designed for describing non rigid image deformation 
in this paper we present a novel robust multi view normal field integration technique for reconstructing the full d shape of mirroring object we employ a turntable based setup with several camera and display these are used to display illumination pattern which are reflected by the object surface the pattern information observed in the camera enables the calculation of individual volumetric normal field for each combination of camera display and turntable angle a the pattern information might be blurred depending on the surface curvature or due to non perfect mirroring surface characteristic we locally adapt the decoding to the finest still resolvable pattern resolution in complex real world scenario the normal field contain region without observation due to occlusion and outlier due to interreflection and noise therefore a robust reconstruction using only normal information is challenging via a non parametric clustering of normal hypothesis derived for each point in the scene we obtain both the most likely local surface normal and a local surface consistency estimate this information is utilized in an iterative min cut based variational approach to reconstruct the surface geometry 
recent work in computer vision ha addressed zero shot learning or unseen class detection which involves categorizing object without observing any training example however these problem assume that attribute or defining characteristic of these unobserved class are known leveraging this information at test time to detect an unseen class we address the more realistic problem of detecting category that do not appear in the dataset in any form we denote such a category a an unfamiliar class it is neither observed at train time nor do we posse any knowledge regarding it relationship to attribute this problem is one that ha received limited attention within the computer vision community in this work we propose a novel approach to the unfamiliar class detection task that build on attribute based classification method and we empirically demonstrate how classification accuracy is impacted by attribute noise and dataset difficulty a quantified by the separation of class in the attribute space we also present a method for incorporating human user to overcome deficiency in attribute detection we demonstrate result superior to existing method on the challenging cub dataset 
we consider the problem of rotation averaging under the l norm this problem is related to the classic fermat weber problem for finding the geometric median of a set of point in ir n we apply the classical weiszfeld algorithm to this problem adapting it iteratively in tangent space of so to obtain a provably convergent algorithm for finding the l mean this result in an extremely simple and rapid averaging algorithm without the need for line search the choice of l mean also called geometric median is motivated by it greater robustness compared with rotation averaging under the l norm the usual averaging process we apply this problem to both single rotation averaging under which the algorithm provably find the global l optimum and multiple rotation averaging for which no such proof exists the algorithm is demonstrated to give markedly improved result compared with l averaging we achieve a median rotation error of degree on the image of the notre dame image set 
we posit that user behavior during natural viewing of image contains an abundance of information about the content of image a well a information related to user intent and user defined content importance in this paper we conduct experiment to better understand the relationship between image the eye movement people make while viewing image and how people construct natural language to describe image we explore these relationship in the context of two commonly used computer vision datasets we then further relate human cue with output of current visual recognition system and demonstrate prototype application for gaze enabled detection and annotation 
training of conditional random field often take the form of a double loop procedure with message passing inference in the inner loop this can be very expensive a the need to solve the inner loop to high accuracy can require many message passing iteration this paper seek to reduce the expense of such training by redefining the training objective in term of the approximate marginals obtained after message passing is truncated to a fixed number of iteration an algorithm is derived to efficiently compute the exact gradient of this objective on a common pixel labeling benchmark this procedure improves training speed by an order of magnitude and slightly improves inference accuracy if a very small number of message passing iteration are used at test time 
we relax the long held and problematic assumption in shape from shading sfs that albedo must be uniform or known and address the problem of shape and albedo from shading safs using model normally reserved for natural image statistic we impose naturalness prior over the albedo and shape of a scene which allows u to simultaneously recover the most likely albedo and shape that explain a single image a simplification of our algorithm solves classic sfs and our safs algorithm can solve the intrinsic image decomposition problem a it solves a superset of that problem we present result for safs sfs and intrinsic image decomposition on real lunar imagery from the apollo mission on our own pseudo synthetic lunar dataset and on a subset of the mit intrinsic image dataset our one unified technique appears to outperform the previous best individual algorithm for all three task our technique allows a coarse observation of shape from a laser rangefinder or a stereo algorithm etc to be incorporated a priori we demonstrate that even a small amount of low frequency information dramatically improves performance and motivate the usage of shading for high frequency shape and albedo recovery 
given the knowledge that the same or similar object appear in a set of image our goal is to simultaneously segment that object from the set of image to solve this problem known a the cosegmentation problem we present a method based upon hierarchical clustering our framework first eliminates intra class heterogeneity in a dataset by clustering similar image together into smaller group then from each image our method extract multiple level of segmentation and creates connection between region e g superpixel across level to establish intra image multi scale constraint next we take advantage of the information available from other image in our group we design and present an efficient method to create inter image relationship e g connection between image region from one image to all other image in an image cluster given the intra inter image connection we perform a segmentation of the group of image into foreground and background region finally we compare our segmentation accuracy to several other state of the art segmentation method on standard datasets and also demonstrate the robustness of our method on real world data 
image segmentation is often performed via the minimization of an energy function over a domain of possible segmentation the effectiveness and applicability of such method depends greatly on the property of the energy function and it domain and on what information can be encoded by it here we propose an energy function that achieves several important goal specifically our energy function is convex and incorporates shape prior information while simultaneously generating a probabilistic segmentation for multiple region our energy function represents multi region probabilistic segmentation a element of a vector space using the isometric log ratio ilr transformation to our knowledge these four goal convex with shape prior multi region and probabilistic do not exist together in any other method and this is the first time ilr is used in an image segmentation method we provide example demonstrating the usefulness of these feature 
metric learning is a fundamental problem in computer vision different feature and algorithm may tackle a problem from different angle and thus often provide complementary information in this paper we propose a fusion algorithm which output enhanced metric by combining multiple given metric similarity measure unlike traditional co training style algorithm where multi view feature or multiple data subset are used for classification or regression we focus on fusing multiple given metric through diffusion process in an unsupervised way our algorithm ha it particular advantage when the input similarity matrix are the output from diverse algorithm we provide both theoretical and empirical explanation to our method significant improvement over the state of the art result have been observed on various benchmark datasets for example we have achieved accuracy no longer the bull s eye measure on the mpeg shape dataset our method ha a wide range of application in machine learning and computer vision 
this paper proposes a method for detecting temporal change of the three dimensional structure of an outdoor scene from it multi view image captured at two separate time for the image we consider those captured by a camera mounted on a vehicle running in a city street the method estimate scene structure probabilistically not deterministically and based on their estimate it evaluates the probability of structural change in the scene where the input are the similarity of the local image patch among the multi view image the aim of the probabilistic treatment is to maximize the accuracy of change detection behind which there is our conjecture that although it is difficult to estimate the scene structure deterministically it should be easier to detect their change the proposed method is compared with the method that use multi view stereo mv to reconstruct the scene structure of the two time point and then differentiate them to detect change the experimental result show that the proposed method outperforms such mv based method 
attribute are an intermediate representation which enables parameter sharing between class a must when training data is scarce we propose to view attribute based image classification a a label embedding problem each class is embedded in the space of attribute vector we introduce a function which measure the compatibility between an image and a label embedding the parameter of this function are learned on a training set of labeled sample to ensure that given an image the correct class rank higher than the incorrect one result on the animal with attribute and caltech ucsd bird datasets show that the proposed framework outperforms the standard direct attribute prediction baseline in a zero shot learning scenario the label embedding framework offer other advantage such a the ability to leverage alternative source of information in addition to attribute e g class hierarchy or to transition smoothly from zero shot learning to learning with large quantity of data 
in this paper we present the first large scale scene attribute database first we perform crowd sourced human study to find a taxonomy of discriminative attribute next we build the sun attribute database on top of the diverse sun categorical database our attribute database span more than category and image and ha potential for use in high level scene understanding and fine grained scene recognition we use our dataset to train attribute classifier and evaluate how well these relatively simple classifier can recognize a variety of attribute related to material surface property lighting function and affordances and spatial envelope property 
this paper present an approach for large scale event retrieval given a video clip of a specific event eg the wedding of prince william and kate middleton the goal is to retrieve other video representing the same event from a dataset of over k video our approach encodes the frame descriptor of a video to jointly represent their appearance and temporal order it exploit the property of circulant matrix to compare the video in the frequency domain this offer a significant gain in complexity and accurately localizes the matching part of video furthermore we extend product quantization to complex vector in order to compress our descriptor and to compare them in the compressed domain our method outperforms the state of the art both in search quality and query time on two large scale video benchmark for copy detection trecvid and ccweb finally we introduce a challenging dataset for event retrieval evve and report the performance on this dataset 
we propose a working set based approximate sub gradient descent algorithm to minimize the margin sensitive hinge loss arising from the soft constraint in max margin learning framework such a the structured svm we focus on the setting of general graphical model such a loopy mrfs and crfs commonly used in image segmentation where exact inference is intractable and the most violated constraint can only be approximated voiding the optimality guarantee of the structured svm s cutting plane algorithm a well a reducing the robustness of existing sub gradient based method we show that the proposed method obtains better approximate sub gradient through the use of working set leading to improved convergence property and increased reliability furthermore our method allows new constraint to be randomly sampled instead of computed using the more expensive approximate inference technique such a belief propagation and graph cut which can be used to reduce learning time at only a small cost of performance we demonstrate the strength of our method empirically on the segmentation of a new publicly available electron microscopy dataset a well a the popular msrc data set and show state of the art result 
graph cut are widely used in many field of computer vision in order to minimize in small polynomial time complexity certain class of energy these specific class depend on the way chosen to build the graph representing the problem to solve we study here all possible way of building graph and the associated energy minimized leading to the exhaustive family of energy minimizable exactly by a graph cut to do this we consider the issue of coding pixel label a state of the graph i e the choice of state interpretation the family obtained comprises many new class in particular energy that do not satisfy the submodularity condition including energy that are even not permuted submodular a generating subfamily is studied in detail in particular we propose a canonical form to represent markov random field which prof useful to recognize energy in this subfamily in linear complexity almost surely and then to build the associated graph in quasilinear time a few experiment are performed to illustrate the new possibility offered 
most successful object classification and detection method rely on classifier trained on large labeled datasets however for domain where label are limited simply borrowing labeled data from existing datasets can hurt performance a phenomenon known a dataset bias we propose a general framework for adapting classifier from borrowed data to the target domain using a combination of available labeled and unlabeled example specifically we show that imposing smoothness constraint on the classifier score over the unlabeled data can lead to improved adaptation result such constraint are often available in the form of instance correspondence e g when the same object or individual is observed simultaneously from multiple view or tracked between video frame in these case the object label are unknown but can be constrained to be the same or similar we propose technique that build on existing domain adaptation method by explicitly modeling these relationship and demonstrate empirically that they improve recognition accuracy in two scenario multicategory image classification and object detection in video 
in many image video web classification problem we have access to a large number of unlabeled sample however it is typically expensive and time consuming to obtain label for the sample active learning is the problem of progressively selecting and annotating the most informative unlabeled sample in order to obtain a high classification performance most existing active learning algorithm select only one sample at a time prior to retraining the classifier hence they are computationally expensive and cannot take advantage of parallel labeling system such a mechanical turk on the other hand algorithm that allow the selection of multiple sample prior to retraining the classifier may select sample that have significant information overlap or they involve solving a non convex optimization more importantly the majority of active learning algorithm are developed for a certain classifier type such a svm in this paper we develop an efficient active learning framework based on convex programming which can select multiple sample at a time for annotation unlike the state of the art our algorithm can be used in conjunction with any type of classifier including those of the family of the recently proposed sparse representation based classification src we use the two principle of classifier uncertainty and sample diversity in order to guide the optimization program towards selecting the most informative unlabeled sample which have the least information overlap our method can incorporate the data distribution in the selection process by using the appropriate dissimilarity between pair of sample we show the effectiveness of our framework in person detection scene categorization and face recognition on real world datasets 
we introduce regression tree field rtfs a fully conditional random field model for image labeling problem rtfs gain their expressive power from the use of non parametric regression tree that specify a tractable gaussian random field thereby ensuring globally consistent prediction our approach improves on the recently introduced decision tree field dtf model in three key way i rtfs have tractable test time inference making efficient optimal prediction feasible and order of magnitude faster than for dtfs ii rtfs can be applied to both discrete and continuous vector valued labeling task and hi the entire model including the structure of the regression tree and energy function parameter can be efficiently and jointly learned from training data we demonstrate the expressive power and flexibility of the rtf model on a wide variety of task including inpainting colorization denoising and joint detection and registration we achieve excellent predictive performance which is on par with or even surpassing dtfs on all task where a comparison is possible 
many computer vision task can be formulated a labeling problem the desired solution is often a spatially smooth labeling where label transition are aligned with color edge of the input image we show that such solution can be efficiently achieved by smoothing the label cost with a very fast edge preserving filter in this paper we propose a generic and simple framework comprising three step i constructing a cost volume ii fast cost volume filtering and iii winner take all label selection our main contribution is to show that with such a simple framework state of the art result can be achieved for several computer vision application in particular we achieve i disparity map in real time whose quality exceeds those of all other fast local approach on the middlebury stereo benchmark and ii optical flow field with very fine structure a well a large displacement to demonstrate robustness the few parameter of our framework are set to nearly identical value for both application also competitive result for interactive image segmentation are presented with this work we hope to inspire other researcher to leverage this framework to other application area 
we deal with an image jigsaw puzzle problem which is defined a reconstructing an image from a set of square and non overlapping image patch it is known that a general instance of this problem is np complete and it is also challenging for human since in the considered setting the original image is not given recently a graphical model ha been proposed to solve this and related problem the target label probability function is then maximized using loopy belief propagation we also formulate the problem a maximizing a label probability function and use exactly the same pairwise potential our main contribution is a novel inference approach in the sampling framework of particle filter pf usually in the pf framework it is assumed that the observation arrive sequentially e g the observation are naturally ordered by their time stamp in the tracking scenario based on this assumption the posterior density over the corresponding hidden state is estimated in the jigsaw puzzle problem all observation puzzle piece are given at once without any particular order therefore we relax the assumption of having ordered observation and extend the pf framework to estimate the posterior density by exploring different order of observation and selecting the most informative permutation of observation this significantly broadens the scope of application of the pf inference our experimental result demonstrate that the proposed inference framework significantly outperforms the loopy belief propagation in solving the image jigsaw puzzle problem in particular the extended pf inference triple the accuracy of the label assignment compared to that using loopy belief propagation 
in this paper we present a novel approach for human interaction recognition from video we introduce high level description called interactive phrase to express binary semantic motion relationship between interacting people interactive phrase naturally exploit human knowledge to describe interaction and allow u to construct a more descriptive model for recognizing human interaction we propose a novel hierarchical model to encode interactive phrase based on the latent svm framework where interactive phrase are treated a latent variable the interdependency between interactive phrase are explicitly captured in the model to deal with motion ambiguity and partial occlusion in interaction we evaluate our method on a newly collected bit interaction dataset and ut interaction dataset promising result demonstrate the effectiveness of the proposed method 
a simple seed growing algorithm for estimating scene flow in a stereo setup is presented two calibrated and synchronized camera observe a scene and output a sequence of image pair the algorithm simultaneously computes a disparity map between the image pair and optical flow map between consecutive image this together with calibration data is an equivalent representation of the d scene flow i e a d velocity vector is associated with each reconstructed point the proposed method start from correspondence seed and propagates these correspondence to their neighborhood it is accurate for complex scene with large motion and produce temporally coherent stereo disparity and optical flow result the algorithm is fast due to inherent search space reduction an explicit comparison with recent method of spatiotemporal stereo and variational optical and scene flow is provided 
we present an optical flow algorithm for large displacement motion most existing optical flow method use the standard coarse to fine framework to deal with large displacement motion which ha intrinsic limitation instead we formulate the motion estimation problem a a motion segmentation problem we use approximate nearest neighbor field to compute an initial motion field and use a robust algorithm to compute a set of similarity transformation a the motion candidate for segmentation to account for deviation from similarity transformation we add local deformation in the segmentation process we also observe that small object can be better recovered using translation a the motion candidate we fuse the motion result obtained under similarity transformation and under translation together before a final refinement experimental validation show that our method can successfully handle large displacement motion although we particularly focus on large displacement motion in this work we make no sacrifice in term of overall performance in particular our method rank at the top of the middlebury benchmark 
we present a novel method for aligning image in an hdr high dynamic range image stack to produce a new exposure stack where all the image are aligned and appear a if they were taken simultaneously even in the case of highly dynamic scene our method produce plausible result even where the image used a a reference is either too dark or bright to allow for an accurate registration 
most common approach for object detection collect thousand of training example and train a detector in an offline setting using supervised learning method with the objective of obtaining a generalized detector that would give good performance on various test datasets however when an offline trained detector is applied on challenging test datasets it may fail in some case by not being able to detect some object or by producing false alarm we propose an unsupervised multiple instance learning mil based incremental solution to deal with this issue we introduce an mil loss function for real adaboost and present a tracking based effective unsupervised online sample collection mechanism to collect the online sample for incremental learning experiment demonstrate the effectiveness of our approach by improving the performance of a state of the art offline trained detector on the challenging datasets for pedestrian category 
this paper present a novel system to estimate body pose configuration from a single depth map it combine both pose detection and pose refinement the input depth map is matched with a set of pre captured motion exemplar to generate a body configuration estimation a well a semantic labeling of the input point cloud the initial estimation is then refined by directly fitting the body configuration with the observation e g the input depth in addition to the new system architecture our other contribution include modifying a point cloud smoothing technique to deal with very noisy input depth map a point cloud alignment and pose search algorithm that is view independent and efficient experiment on a public dataset show that our approach achieves significantly higher accuracy than previous state of art method 
many vision task require a multi class classifier to discriminate multiple category on the order of hundred or thousand in this paper we propose sparse output coding a principled way for large scale multi class classification by turning high cardinality multi class categorization into a bit by bit decoding problem specifically sparse output coding is composed of two step efficient coding matrix learning with scalability to thousand of class and probabilistic decoding empirical result on object recognition and scene classification demonstrate the effectiveness of our proposed approach 
corpus callosum cc is an important structure in human brain anatomy in this work we propose a fully automated and robust approach to extract corpus callosum from t weighted structural mr image the novelty of our method is composed of two key step in the first step we find an initial guess for the curve representation of cc by using the zero level set of the first nontrivial laplace beltrami lb eigenfunction on the white matter surface in the second step the initial curve is deformed toward the final solution with a geodesic curvature flow on the white matter surface for numerical solution of the geodesic curvature flow on surface we represent the contour implicitly on a triangular mesh and develop efficient numerical scheme based on finite element method because our method depends only on the intrinsic geometry of the white matter surface it is robust to orientation difference of the brain across population in our experiment we validate the proposed algorithm on brain from a clinical study of multiple sclerosis disease and demonstrate that the accuracy of our result 
inverted index in image retrieval not only allow fast access to database image but also summarize all knowledge about the database so that their discriminative capacity largely determines the retrieval performance in this paper for vocabulary tree based image retrieval we propose a semantic aware co indexing algorithm to jointly embed two strong cue into the inverted index local invariant feature that are robust to delineate low level image content and semantic attribute from large scale object recognition that may reveal image semantic meaning for an initial set of inverted index of local feature we utilize semantic attribute to filter out isolated image and insert semantically similar image to the initial set encoding these two distinct cue together effectively enhances the discriminative capability of inverted index such co indexing operation are totally off line and introduce small computation overhead to online query cause only local feature but no semantic attribute are used for query experiment and comparison with recent retrieval method on datasets i e ukbench holiday oxford k and million image from flickr a distractors manifest the competitive performance of our method 
traditional computer vision and machine learning algorithm have been largely studied in a centralized setting where all the processing is performed at a single central location however a distributed approach might be more appropriate when a network with a large number of camera is used to analyze a scene in this paper we show how centralized algorithm based on linear algebraic operation can be made distributed by using simple distributed average we cover algorithm such a svd least square pca gpca d point triangulation pose estimation and affine sfm 
the symmetric positive definite spd matrix have been widely used in image and vision problem recently there are growing interest in studying sparse representation sr of spd matrix motivated by the great success of sr for vector data though the space of spd matrix is well known to form a lie group that is a riemannian manifold existing work fails to take full advantage of it geometric structure this paper attempt to tackle this problem by proposing a kernel based method for sr and dictionary learning dl of spd matrix we disclose that the space of spd matrix with the operation of logarithmic multiplication and scalar logarithmic multiplication defined in the log euclidean framework is a complete inner product space we can thus develop a broad family of kernel that satisfies mercer s condition these kernel characterize the geodesic distance and can be computed efficiently we also consider the geometric structure in the dl process by updating atom matrix in the riemannian space instead of in the euclidean space the proposed method is evaluated with various vision problem and show notable performance gain over state of the art 
human pose detector although successful in localising face and torso of people often fail with lower arm with fast movement body motion estimation is often inaccurate we build a segmentation detection algorithm that mediates the information between body part recognition and multi frame motion grouping to improve both pose detection and tracking motion of body part though not accurate is often sufficient to segment them from their background such segmentation are crucial for extracting hard to detect body part out of their interior body clutter by matching these segment to exemplar we obtain pose labeled body segment the pose labeled segment and corresponding articulated joint are used to improve the motion flow field by proposing kinematically constrained affine displacement on body part the pose based articulated motion model is shown to handle large limb rotation and displacement our algorithm can detect people under rare pose frequently missed by pose detector showing the benefit of jointly reasoning about pose segmentation and motion in video 
in this paper we propose a novel semantic bundle adjustment framework whereby known rigid stationary object are detected while tracking the camera and mapping the environment the system build on established tracking and mapping technique to exploit incremental d reconstruction in order to validate hypothesis on the presence and pose of sought object then detected object are explicitly taken into account for a global semantic optimization of both camera and object pose thus unlike all system proposed so far our approach allows for solving jointly the detection and slam problem so a to achieve object detection together with improved slam accuracy 
we describe a probabilistic method for identifying character in tv series or movie we aim at labeling every character appearance and not only those where a face can be detected consequently our basic unit of appearance is a person track a opposed to a face track we model each tv series episode a a markov random field integrating face recognition clothing appearance speaker recognition and contextual constraint in a probabilistic manner the identification task is then formulated a an energy minimization problem in order to identify track without face we learn clothing model by adapting available face recognition result within a scene a indicated by prior analysis of the temporal structure of the tv series clothing feature are combined by agglomerative clustering we evaluate our approach on the first episode of the big bang theory and achieve an absolute improvement of for person identification and for face recognition 
in this paper we formulate multi target tracking mtt a a rank tensor approximation problem and propose an norm tensor power iteration solution in particular a high order tensor is constructed based on trajectory in the time window with each tensor element a the affinity of the corresponding trajectory candidate the local assignment variable are the normalized vector which are used to approximate the rank tensor our approach provides a flexible and effective formulation where both pairwise and high order association energy can be used expediently we also show the close relation between our formulation and the multi dimensional assignment mda model to solve the optimization in the rank tensor approximation we propose an algorithm that iteratively power the intermediate solution followed by an normalization aside from effectively capturing high order motion information the proposed solver run efficiently with proved convergence the experimental validation are conducted on two challenging datasets and our method demonstrates promising performance on both 
hashing technique have been intensively investigated in the design of highly efficient search engine for large scale computer vision application compared with prior approximate nearest neighbor search approach like tree based indexing hashing based search scheme have prominent advantage in term of both storage and computational efficiency moreover the procedure of devising hash function can be easily incorporated into sophisticated machine learning tool leading to data dependent and task specific compact hash code therefore a number of learning paradigm ranging from unsupervised to supervised have been applied to compose appropriate hash function however most of the existing hash function learning method either treat hash function design a a classification problem or generate binary code to satisfy pair wise supervision and have not yet directly optimized the search accuracy in this paper we propose to leverage list wise supervision into a principled hash function learning framework in particular the ranking information is represented by a set of rank triplet that can be used to ass the quality of ranking simple linear projection based hash function are solved efficiently through maximizing the ranking quality over the training data we carry out experiment on large image datasets with size up to one million and compare with the state of the art hashing technique the extensive result corroborate that our learned hash code via list wise supervision can provide superior search accuracy without incurring heavy computational overhead 
with the aim to improve accuracy of stereo confidence measure we apply the random decision forest framework to a large set of diverse stereo confidence measure learning and testing set were drawn from the recently introduced kitti dataset which currently pose higher challenge to stereo solver than other benchmark with ground truth for stereo evaluation we experiment with semi global matching stereo sgm and a census data term which is the best performing real time capable stereo method known to date on kitti image sgm still produce a significant amount of error we obtain consistently improved area under curve value of sparsification measure in comparison to best performing single stereo confidence measure where number of stereo error are large more specifically our method performs best in all but one out of frame of the kitti dataset 
one of the trend of action recognition consists in extracting and comparing mid level feature which encode visual and motion aspect of object into scene however when scene contain high level semantic action with many interacting part these mid level feature are not sufficient to capture high level structure a well a high order causal relationship between moving object resulting into a clear drop in performance in this paper we address this issue and we propose an alternative action recognition method based on a novel graph kernel in the main contribution of this work we first describe action in video using directed a cyclic graph dag that naturally encode pair wise interaction between moving object part and then we compare these dag by analyzing the spectrum of their sub pattern that capture complex higher order interaction this extraction and comparison process is computationally tractable resulting from the a cyclic property of dag and it also defines a positive semi definite kernel when plugging the latter into support vector machine we obtain an action recognition algorithm that overtakes related work including graph based method on a standard evaluation dataset 
this paper present a system for image parsing or labeling each pixel in an image with it semantic category aimed at achieving broad coverage across hundred of object category many of them sparsely sampled the system combine region level feature with per exemplar sliding window detector per exemplar detector are better suited for our parsing task than traditional bounding box detector they perform well on class with little training data and high intra class variation and they allow object mask to be transferred into the test image for pixel level segmentation the proposed system achieves state of the art accuracy on three challenging datasets the largest of which contains image and label 
given a pair of video having a common action our goal is to simultaneously segment this pair of video to extract this common action a a preprocessing step we first remove background trajectory by a motion based figure ground segmentation to remove the remaining background and those extraneous action we propose the trajectory co saliency measure which capture the notion that trajectory recurring in all the video should have their mutual saliency boosted this requires a trajectory matching process which can compare trajectory with different length and not necessarily spatiotemporally aligned and yet be discriminative enough despite significant intra class variation in the common action we further leverage the graph matching to enforce geometric coherence between region so a to reduce feature ambiguity and matching error finally to classify the trajectory into common action and action outlier we formulate the problem a a binary labeling of a markov random field in which the data term is measured by the trajectory co saliency and the smoothness term is measured by the spatiotemporal consistency between trajectory to evaluate the performance of our framework we introduce a dataset containing clip that have animal action a well a human action experimental result show that the proposed method performs well in common action extraction 
we propose a convex multilabel framework for image sequence segmentation which allows to impose proportion prior on object part in order to preserve their size ratio across multiple image the key idea is that for strongly deformable object such a a gymnast the size ratio of respective region head versus torso leg versus full body etc is typically preserved we propose different way to impose such prior in a bayesian framework for image segmentation we show that near optimal solution can be computed using convex relaxation technique extensive qualitative and quantitative evaluation demonstrate that the proportion prior allow for highly accurate segmentation avoiding seeping out of region and preserving semantically relevant small scale structure such a hand or foot they naturally apply to multiple object instance such a player in sport scene and they can relate different object instead of object part e g organ in medical imaging the algorithm is efficient and easily parallelized leading to proportion consistent segmentation at runtimes around one second 
in this paper we propose a new approach to compute the scale space of any omnidirectional image acquired with a central catadioptric system when these camera are central they are explained using the sphere camera model which unifies in a single model conventional paracatadioptric and hypercatadioptric system scale space is essential in the detection and matching of interest point in particular scale invariant point based on laplacian of gaussians like the well known sift we combine the sphere camera model and the partial differential equation framework on manifold to compute the laplace beltrami lb operator which is a second order differential operator required to perform the gaussian smoothing on catadioptric image we perform experiment with synthetic and real image to validate the generalization of our approach to any central catadioptric system 
spatial temporal relation among facial muscle carry crucial information about facial expression yet have not been thoroughly exploited one contributing factor for this is the limited ability of the current dynamic model in capturing complex spatial and temporal relation existing dynamic model can only capture simple local temporal relation among sequential event or lack the ability for incorporating uncertainty to overcome these limitation and take full advantage of the spatio temporal information we propose to model the facial expression a a complex activity that consists of temporally overlapping or sequential primitive facial event we further propose the interval temporal bayesian network to capture these complex temporal relation among primitive facial event for facial expression modeling and recognition experimental result on benchmark database demonstrate the feasibility of the proposed approach in recognizing facial expression based purely on spatio temporal relation among facial muscle a well a it advantage over the existing method 
despite a considerable amount of previous work on bottom up saliency modeling for predicting human fixation over static and dynamic stimulus few study have thus far attempted to model top down and task driven influence of visual attention here taking advantage of the sequential nature of real world task we propose a unified bayesian approach for modeling task driven visual attention several source of information including global context of a scene previous attended location and previous motor action are integrated over time to predict the next attended location recording eye movement while subject engage in contemporary d and d video game a modest counterpart of everyday task we show that our approach is able to predict human attention and gaze better than the state of the art with a large margin about increase in prediction accuracy the advantage of our approach is that it is automatic and applicable to arbitrary visual task 
we argue for the importance of explicit semantic modelling in human centred texture analysis task such a retrieval annotation synthesis and zero shot learning to this end low level attribute are selected and used to define a semantic space for texture texture class varying in illumination and rotation are positioned within this semantic space using a pair wise relative comparison procedure low level visual feature used by existing texture descriptor are then assessed in term of their correspondence to the semantic space texture with strong presence of attribute connoting randomness and complexity are shown to be poorly modelled by existing descriptor in a retrieval experiment semantic descriptor are shown to outperform visual descriptor semantic modelling of texture is thus shown to provide considerable value in both feature selection and in analysis task 
we present local naive bayes nearest neighbor an improvement to the nbnn image classification algorithm that increase classification accuracy and improves it ability to scale to large number of object class the key observation is that only the class represented in the local neighborhood of a descriptor contribute significantly and reliably to their posterior probability estimate instead of maintaining a separate search structure for each class s training descriptor we merge all of the reference data together into one search structure allowing quick identification of a descriptor s local neighborhood we show an increase in classification accuracy when we ignore adjustment to the more distant class and show that the run time grows with the log of the number of class rather than linearly in the number of class a did the original local nbnn give a time speed up over the original nbnn on the caltech dataset we also provide the first head to head comparison of nbnn against spatial pyramid method using a common set of input feature we show that local nbnn outperforms all previous nbnn based method and the original spatial pyramid model however we find that local nbnn while competitive with doe not beat state of the art spatial pyramid method that use local soft assignment and max pooling 
this paper focus on the problem of word detection and recognition in natural image the problem is significantly more challenging than reading text in scanned document and ha only recently gained attention from the computer vision community sub component of the problem such a text detection and cropped image word recognition have been studied in isolation however what is unclear is how these recent approach contribute to solving the end to end problem of word recognition we fill this gap by constructing and evaluating two system the first representing the de facto state of the art is a two stage pipeline consisting of text detection followed by a leading ocr engine the second is a system rooted in generic object recognition an extension of our previous work in we show that the latter approach achieves superior performance while scene text recognition ha generally been treated with highly domain specific method our result demonstrate the suitability of applying generic computer vision method adopting this approach open the door for real world scene text recognition to benefit from the rapid advance that have been taking place in object recognition 
we present a method for detecting d object using multi modality while it is generic we demonstrate it on the combination of an image and a dense depth map which give complementary object information it work in real time under heavy clutter doe not require a time consuming training stage and can handle untextured object it is based on an efficient representation of template that capture the different modality and we show in many experiment on commodity hardware that our approach significantly outperforms state of the art method on single modality 
this paper address the problem of category level image classification the underlying image model is a graph whose node correspond to a dense set of region and edge reflect the underlying grid structure of the image and act a spring to guarantee the geometric consistency of nearby region during matching a fast approximate algorithm for matching the graph associated with two image is presented this algorithm is used to construct a kernel appropriate for svm based image classification and experiment with the caltech caltech and scene datasets demonstrate performance that match or exceeds the state of the art for method using a single type of feature 
deblurring camera based document image is an important task in digital document processing since it can improve both the accuracy of optical character recognition system and the visual quality of document image traditional deblurring algorithm have been proposed to work for natural scene image however the natural scene image are not consistent with document image in this paper the distinct characteristic of document image are investigated we propose a content aware prior for document image deblurring it is based on document image foreground segmentation besides an upper bound constraint combined with total variation based method is proposed to suppress the ring in the deblurred image comparing with the traditional general purpose deblurring method the proposed deblurring algorithm can produce more pleasing result on document image encouraging experimental result demonstrate the efficacy of the proposed method 
we consider the problem of human parsing with part based model most previous work in part based model only considers rigid part e g torso head half limb guided by human anatomy we argue that this representation of part is not necessarily appropriate for human parsing in this paper we introduce hierarchical poselets a new representation for human parsing hierarchical poselets can be rigid part but they can also be part that cover large portion of human body e g torso left arm in the extreme case they can be the whole body we develop a structured model to organize poselets in a hierarchical way and learn the model parameter in a max margin framework we demonstrate the superior performance of our proposed approach on two datasets with aggressive pose variation 
light field are image based representation that use densely sampled ray a a scene description in this paper we explore geometric structure of d line in ray space for improving light field triangulation and stereo matching the triangulation problem aim to fill in the ray space with continuous and non overlapping simplices anchored at sampled point ray such a triangulation provides a piecewise linear interpolant useful for light field super resolution we show that the light field space is largely bilinear due to d line segment in the scene and direct triangulation of these bilinear subspace lead to large error we instead present a simple but effective algorithm to first map bilinear subspace to line constraint and then apply constrained delaunay triangulation cdt based on our analysis we further develop a novel line assisted graph cut lagc algorithm that effectively encodes d line constraint into light field stereo matching experiment on synthetic and real data show that both our triangulation and lagc algorithm outperform state of the art solution in accuracy and visual quality 
recent work ha demonstrated the effectiveness of domain adaptation method for computer vision application in this work we propose a new multiple source domain adaptation method called domain selection machine dsm for event recognition in consumer video by leveraging a large number of loosely labeled web image from different source e g flickr com and photosig com in which there are no labeled consumer video specifically we first train a set of svm classifier referred to a source classifier by using the sift feature of web image from different source domain we propose a new parametric target decision function to effectively integrate the static sift feature from web image video keyframes and the spacetime st feature from consumer video in order to select the most relevant source domain we further introduce a new data dependent regularizer into the objective of support vector regression svr using the insensitive loss which enforces the target classifier share similar decision value on the unlabeled consumer video with the selected source classifier moreover we develop an alternating optimization algorithm to iteratively solve the target decision function and a domain selection vector which indicates the most relevant source domain extensive experiment on three real world datasets demonstrate the effectiveness of our proposed method dsm over the state of the art by a performance gain up to 
how best to efficiently establish correspondence among a large set of image or video frame is an interesting unanswered question for large database the high computational cost of performing pair wise image matching is a major problem however for many application image are inherently sparsely connected and so current technique try to correctly estimate small potentially matching subset of database upon which to perform expensive pair wise matching our contribution is to pose the identification of potential match a a link prediction problem in an image correspondence graph and to propose an effective algorithm to solve this problem our algorithm facilitates incremental image matching initially the match graph is very sparse but it becomes dense a we alternate between link prediction and verification we demonstrate the effectiveness of our algorithm by comparing it with several existing alternative on large scale database our resulting match graph is useful for many different application a an example we show the benefit of our graph construction method to a label propagation application which propagates user provided sparse object label to other instance of that object in large image collection 
reconstructing realistic d hair geometry is challenging due to omnipresent occlusion complex discontinuity and specular appearance to address these challenge we propose a multi view hair reconstruction algorithm based on orientation field with structure aware aggregation our key insight is that while hair s color appearance is view dependent the response to oriented filter that capture the local hair orientation is more stable we apply the structure aware aggregation to the mrf matching energy to enforce the structural continuity implied from the local hair orientation multiple depth map from the mrf optimization are then fused into a globally consistent hair geometry with a template refinement procedure compared to the state of the art color based method our method faithfully reconstructs detailed hair structure we demonstrate the result for a number of hair style ranging from straight to curly and show that our framework is suitable for capturing hair in motion 
in this paper we deal with the estimation of body and head pose i e orientation in surveillance video and we make three main contribution first we address this issue a a joint model adaptation problem in a semi supervised framework second we propose to leverage the adaptation on multiple information source external labeled datasets weak label provided by the motion direction data structure manifold and in particular on the coupling at the output level of the head and body classifier accounting for the restriction in the configuration that the head and body pose can jointly take third we propose a kernel formulation of this principle that can be efficiently solved using a global optimization scheme the method is applied to body and head feature computed from automatically extracted body and head location track thorough experiment on several datasets demonstrate the validity of our approach the benefit of the coupled adaptation and that the method performs similarly or better than a state of the art algorithm 
we address the problem of robust face recognition in which both training and test image data might be corrupted due to occlusion and disguise from standard face recognition algorithm such a eigenfaces to recently proposed sparse representation based classification src method most prior work did not consider possible contamination of data during training and thus the associated performance might be degraded based on the recent success of low rank matrix recovery we propose a novel low rank matrix approximation algorithm with structural incoherence for robust face recognition our method not only decomposes raw training data into a set of representative basis with corresponding sparse error for better modeling the face image we further advocate the structural incoherence between the basis learned from different class these basis are encouraged to be a independent a possible due to the regularization on structural incoherence we show that this provides additional discriminating ability to the original low rank model for improved performance experimental result on public face database verify the effectiveness and robustness of our method which is also shown to outperform state of the art src based approach 
we describe a novel max margin parameter learning approach for structured prediction problem under certain non decomposable performance measure structured prediction is a common approach in many vision problem non decomposable performance measure are also commonplace however efficient general method for learning parameter against non decomposable performance measure do not exist in this paper we develop such a method based on dual decomposition that is applicable to a large class of non decomposable performance measure we exploit dual decomposition to factorize the original hard problem into two smaller problem and show how to optimize each factor efficiently we show experimentally that the proposed approach significantly outperforms alternative which either sacrifice the model structure or approximate the performance measure and is an order of magnitude faster than a previous approach with comparable result 
application based on stereo vision are becoming increasingly common ranging from gaming over robotics to driver assistance while stereo algorithm have been investigated heavily both on the pixel and the application level far le attention ha been dedicated to the use of stereo confidence cue mostly a threshold is applied to the confidence value for further processing which is essentially a sparsified disparity map this is straightforward but it doe not take full advantage of the available information in this paper we make full use of the stereo confidence cue by propagating all confidence value along with the measured disparity in a bayesian manner before using this information a mapping from confidence value to disparity outlier probability rate is performed based on gathered disparity statistic from labeled video data we present an extension of the so called stixel world a generic d intermediate representation that can serve a input for many of the application mentioned above this scheme is modified to directly exploit stereo confidence cue in the underlying sensor model during a maximum a posteriori estimation process the effectiveness of this step is verified in an in depth evaluation on a large real world traffic data base of which part are made publicly available we show that using stereo confidence cue allows both reducing the number of false object detection by a factor of six while keeping the detection rate at a near constant level 
sparse bundle adjustment is widely used in many computer vision application in this paper we propose a method for performing bundle adjustment using the l norm after linearizing the mapping function in bundle adjustment on it first order the kernel step is to compute the l norm equation considering the sparsity of the jacobian matrix in linearizing we find two practical method to solve the l norm equation the first one is an interior point method which transfer the original problem to a problem of solving a sequence of l norm equation and the second one is a decomposition method which us the differentiability of linear program and represents the optimal updating of parameter of d point by the updating variable of camera parameter the experiment show that the method performs better for both synthetically generated and real data set in the presence of outlier or laplacian noise compared with the l norm bundle adjustment and the method is efficient among the state of the art l minimization method 
we study unsupervised learning of occluding object in image of visual scene the derived learning algorithm is based on a probabilistic generative model which parameterizes object shape object feature and the background no assumption are made for the object order in depth or the object planar position parameter optimization is thus subject to the large combinatorics of depth order and position previous approach constrained this combinatorics but were still only able to learn a very small number of object by applying a novel variational em approach we show that even without constraint on the object combinatorics a relatively large number of object can be learned in different numerical experiment our unsupervised approach extract explicit object representation with object mask and object feature closely aligned with the true object in the scene we investigate the robustness of the approach and the use of the learned representation for inference furthermore we demonstrate generality of the approach by applying it to grayscale image color vector image and gabor vector image a well a to motion trajectory data for which the extracted component correspond to motion primitive 
catadioptric camera are widely used to increase the field of view using mirror central catadioptric system having an effective single viewpoint are easy to model and use but severely constraint the camera positioning with respect to the mirror on the other hand non central catadioptric system allow greater flexibility in camera placement but are often approximated using central or linear model due to the lack of an exact model we bridge this gap and describe an exact projection model for non central catadioptric system we derive an analytical forward projection equation for the projection of a d point reflected by a quadric mirror on the imaging plane of a perspective camera with no restriction on the camera placement and show that it is an th degree equation in a single unknown while previous non central catadioptric camera primarily use an axial configuration where the camera is placed on the axis of a rotationally symmetric mirror we allow off axis any camera placement using this analytical model a non central catadioptric camera can be used for sparse a well a dense d reconstruction similar to perspective camera using well known algorithm such a bundle adjustment and plane sweeping our paper is the first to show such result for off axis placement of camera with multiple quadric mirror simulation and real result using parabolic mirror and an off axis perspective camera are demonstrated 
we describe a vehicle tracking algorithm using input from a network of nonoverlapping camera our algorithm is based on a novel statistical formulation that us joint kinematic and image appearance information to link local track of the same vehicle into global track with longer persistence the algorithm can handle significant spatial separation between the camera and is robust to challenging tracking condition such a high traffic density or complex road infrastructure in these case traditional tracking formulation based on mht or jpda algorithm may fail to produce track association across camera due to the weak predictive model employed we make several new contribution in this paper firstly we model kinematic constraint between any two local track using road network and transit time distribution the transit time distribution are calculated dynamically a convolution of normalized transit time distribution that are learned and adapted separately for individual road secondly we present a complete statistical tracker formulation which combine kinematic and appearance likelihood within a multi hypothesis framework we have extensively evaluated the algorithm proposed using a network of ground based camera with narrow field of view the tracking result obtained on a large ground truthed dataset demonstrate the effectiveness of the algorithm proposed 
shape matching ha many application in computer vision such a shape classification object recognition object detection and localization in d case shape instance are d closed contour and matching two shape contour can usually be formulated a finding a one to one dense point correspondence between them however in practice many shape contour are extracted from real image and may contain partial occlusion this lead to the challenging partial shape matching problem where we need to identify and match a subset of segment of the two shape contour in this paper we propose a new mcmc markov chain monte carlo based algorithm to handle partial shape matching with mildly non rigid deformation specifically we represent each shape contour by a set of ordered landmark point the selection of a subset of these landmark point into the shape matching is evaluated and updated by a posterior distribution which is composed of both a matching likelihood and a prior distribution this prior distribution favor the inclusion of more and consecutive landmark point into the matching to better describe the matching likelihood we develop a contour subdivision technique to highlight the contour segment with highest matching cost from the selected subsequence of the point in our experiment we construct test shape instance by introducing partial occlusion to the shape chosen from different category in mpeg dataset we evaluate the performance of the proposed algorithm by comparing with three well known partial shape matching method 
color information is leveraged by color sampling based matting method to find the best known sample for foreground and background color of unknown pixel such method do not perform well if there is an overlap in the color distribution of foreground and background region because color cannot distinguish between these region and hence the selected sample cannot reliably estimate the matte similarly alpha propagation based matting method may fail when the affinity among neighboring pixel is reduced by strong edge in this paper we overcome these two problem by considering texture a a feature that can complement color to improve matting the contribution of texture and color is automatically estimated by analyzing the content of the image an objective function containing color and texture component is optimized to choose the best foreground and background pair among a set of candidate pair experiment are carried out on a benchmark data set and an independent evaluation of the result show that the proposed method is ranked first among all other image matting method 
this paper present a general multi view feature extraction approach that we call generalized multiview analysis or gma gma ha all the desirable property required for cross view classification and retrieval it is supervised it allows generalization to unseen class it is multi view and kernelizable it affords an efficient eigenvalue based solution and is applicable to any domain gma exploit the fact that most popular supervised and unsupervised feature extraction technique are the solution of a special form of a quadratic constrained quadratic program qcqp which can be solved efficiently a a generalized eigenvalue problem gma solves a joint relaxed qcqp over different feature space to obtain a single non linear subspace intuitively gma is a supervised extension of canonical correlational analysis cca which is useful for cross view classification and retrieval the proposed approach is general and ha the potential to replace cca whenever classification or retrieval is the purpose and label information is available we outperform previous approach for textimage retrieval on pascal and wiki text image data we report state of the art result for pose and lighting invariant face recognition on the multipie face dataset significantly outperforming other approach 
this paper present a method for vote based d shape recognition and registration in particular using mean shift on d pose vote in the space of direct similarity transforms for the first time we introduce a new distance between pose in this space the srt distance it is left invariant unlike euclidean distance and ha a unique closed form mean in contrast to riemannian distance so is fast to compute we demonstrate improved performance over the state of the art in both recognition and registration on a real and challenging dataset by comparing our distance with others in a mean shift framework a well a with the commonly used hough voting approach 
patch based method such a non local mean nlm and bm d have become the de facto gold standard for image denoising the core of these approach is to use similar patch within the image a cue for denoising the operation usually requires expensive pair wise patch comparison in this paper we present a novel fast patch based denoising technique based on patch geodesic path patchgp patchgps treat image patch a node and patch difference a edge weight for computing the shortest geodesic path the path length can then be used a weight of the smoothing denoising kernel we first show that for natural image patchgps can be effectively approximated by minimum hop path mhps that generally correspond to euclidean line path connecting two patch node to construct the denoising kernel we further discretize the mhp search direction and use only patch along the search direction along each mhp we apply a weight propagation scheme to robustly and efficiently compute the path distance to handle noise at multiple scale we conduct wavelet image decomposition and apply patchgp scheme at each scale comprehensive experiment show that our approach achieves comparable quality a the state of the art method such a nlm and bm d but is a few order of magnitude faster 
this paper investigates the problem of semi supervised classification unlike previous method to regularize classifying boundary with unlabeled data our method learns a new image representation from all available data labeled and unlabeled and performs plain supervised learning with the new feature in particular an ensemble of image prototype set are sampled automatically from the available data to represent a rich set of visual category attribute discriminative function are then learned on these prototype set and image are represented by the concatenation of their projected value onto the prototype similarity to them for further classification experiment on four standard datasets show three interesting phenomenon our method consistently outperforms previous method for semi supervised image classification our method let itself combine well with these method and our method work well for self taught image classification where unlabeled data are not coming from the same distribution a labeled one but rather from a random collection of image 
we consider a special type of multi label learning where class assignment of training example are incomplete a an example an instance whose true class assignment is c c c is only assigned to class c when it is used a a training sample we refer to this problem a multi label learning with incomplete class assignment incompletely labeled data is frequently encountered when the number of class is very large hundred a in mir flickr dataset or when there is a large ambiguity between class e g jet v plane in both case it is difficult for user to provide complete class assignment for object we propose a ranking based multi label learning framework that explicitly address the challenge of learning from incompletely labeled data by exploiting the group lasso technique to combine the ranking error we present a learning algorithm that is empirically shown to be efficient for solving the related optimization problem our empirical study show that the proposed framework is more effective than the state of the art algorithm for multi label learning in dealing with incompletely labeled data 
binary hashing ha been widely used for efficient similarity search due to it query and storage efficiency in most existing binary hashing method the high dimensional data are embedded into hamming space and the distance or similarity of two point are approximated by the hamming distance between their binary code the hamming distance calculation is efficient however in practice there are often lot of result sharing the same hamming distance to a query which make this distance measure ambiguous and pose a critical issue for similarity search where ranking is important in this paper we propose a weighted hamming distance ranking algorithm whrank to rank the binary code of hashing method by assigning different bit level weight to different hash bit the returned binary code are ranked at a finer grained binary code level we give an algorithm to learn the data adaptive and query sensitive weight for each hash bit evaluation on two large scale image data set demonstrate the efficacy of our weighted hamming distance for binary code ranking 
we propose cloud motion a a natural scene cue that enables geometric calibration of static outdoor camera this work introduces several new method that use observation of an outdoor scene over day and week to estimate radial distortion focal length and geo orientation cloud based cue provide strong constraint and are an important alternative to method that require specific form of static scene geometry or clear sky condition our method make simple assumption about cloud motion and build upon previous work on motion based and line based calibration we show result on real scene that highlight the effectiveness of our proposed method 
automatic face photo sketch recognition ha important application for law enforcement recent research ha focused on transforming photo and sketch into the same modality for matching or developing advanced classification algorithm to reduce the modality gap between feature extracted from photo and sketch in this paper we propose a new inter modality face recognition approach by reducing the modality gap at the feature extraction stage a new face descriptor based on coupled information theoretic encoding is used to capture discriminative local face structure and to effectively match photo and sketch guided by maximizing the mutual information between photo and sketch in the quantized feature space the coupled encoding is achieved by the proposed coupled information theoretic projection tree which is extended to the randomized forest to further boost the performance we create the largest face sketch database including sketch of people from the feret database experiment on this large scale dataset show that our approach significantly outperforms the state of the art method 
we propose a new family of non submodular global energy function that still use submodularity internally to couple edge in a graph cut we show it is possible to develop an efficient approximation algorithm that thanks to the internal submodularity can use standard graph cut a a subroutine we demonstrate the advantage of edge coupling in a natural setting namely image segmentation in particular for fine structured object and object with shading variation our structured edge coupling lead to significant improvement over standard approach 
local spatio temporal feature and bag of feature representation have become popular for action recognition a recent trend is to use dense sampling for better performance while many method claimed to use dense feature set most of them are just denser than approach based on sparse interest point detector in this paper we explore sampling with high density on action recognition we also investigate the impact of random sampling over dense grid for computational efficiency we present a real time action recognition system which integrates fast random sampling method with local spatio temporal feature extracted from a local part model a new method based on histogram intersection kernel is proposed to combine multiple channel of different descriptor our technique show high accuracy on the simple kth dataset and achieves state of the art on two very challenging real world datasets namely on kth on ucf and on hmdb 
this paper proposes novel density modulated binary pattern for depth acquisition similar to kinect the illumination pattern do not need a projector for generation and can be emitted by infrared laser and diffraction grating our key idea is to use the density of light spot in the pattern to carry phase information two technical problem are addressed here first we propose an algorithm to design the pattern to carry more phase information without compromising the depth reconstruction from a single captured image a with kinect second since the carried phase is not strictly sinusoidal the depth reconstructed from the phase contains a systematic error we further propose a pixel based phase matching algorithm to reduce the error experimental result show that the depth quality can be greatly improved using the phase carried by the density of light spot furthermore our scheme can achieve fps depth reconstruction with gpu assistance 
this paper present a novel schema to address the polysemy of visual word in the widely used bag of word model a a visual word may have multiple meaning we show it is possible to use semantic context to disambiguate these meaning and therefore improve the performance of bag of word model on one hand for an image multiple context specific bag of word histogram are constructed each of which corresponds to a semantic context then these histogram are merged by selecting only the most discriminative context for each visual word resulting in a compact image representation on the other hand an image is represented by the occurrence probability of semantic context finally when classifying an image two image representation are combined at decision level to utilize the complementary information embedded in them experiment on three challenging image database pascal voc scene and msrcv show that our method significantly outperforms state of the art classification method 
despite significant recent progress the best available visual saliency model still lag behind human performance in predicting eye fixation in free viewing of natural scene majority of model are based on low level visual feature and the importance of top down factor ha not yet been fully explored or modeled here we combine low level feature such a orientation color intensity saliency map of previous best bottom up model with top down cognitive visual feature e g face human car etc and learn a direct mapping from those feature to eye fixation using regression svm and adaboost classifier by extensive experimenting over three benchmark eye tracking datasets using three popular evaluation score we show that our boosting model outperforms state of the art model and is so far the closest model to the accuracy of human model for fixation prediction furthermore our model successfully detects the most salient object in a scene without sophisticated image processing such a region segmentation 
fine grained categorization refers to the task of classifying object that belong to the same basic level class e g different bird specie and share similar shape or visual appearance most of the state of the art basic level object classification algorithm have difficulty in this challenging problem one reason for this can be attributed to the popular codebook based image representation often resulting in loss of subtle image information that are critical for fine grained classification another way to address this problem is to introduce human annotation of object attribute or key point a tedious process that is also difficult to generalize to new task in this work we propose a codebook free and annotation free approach for fine grained image categorization instead of using vector quantized codewords we obtain an image representation by running a high throughput template matching process using a large number of randomly generated image template we then propose a novel bagging based algorithm to build a final classifier by aggregating a set of discriminative yet largely uncorrelated classifier experimental result show that our method outperforms state of the art classification approach on the caltech ucsd bird dataset 
exposure bracketing for high dynamic range hdr imaging involves capturing several image of the scene at different exposure if either the camera or the scene move during capture the captured image must be registered large exposure difference between bracketed image lead to inaccurate registration resulting in artifact such a ghosting multiple copy of scene object and blur we present two technique one for image capture fibonacci exposure bracketing and one for image registration generalized registration to prevent such motion related artifact fibonacci bracketing involves capturing a sequence of image such that each exposure time is the sum of the previous n n exposure generalized registration involves estimating motion between sum of contiguous set of frame instead of between individual frame together the two technique ensure that motion is always estimated between frame of the same total exposure time this result in hdr image and video which have both a large dynamic range and minimal motion related artifact we show by result for several real world indoor and outdoor scene that the proposed approach significantly outperforms several existing bracketing scheme 
illumination model of the image set of an object e g human face under varying lighting condition have been either empirically or analytically explored however the theoretical dimensionality of video brick of an object under varying illumination is still unknown in this paper we focus on this question concretely and give both analytical and empirical result we derive the theoretical upper bound of the dimensionality of video brick by investigating the analytical formula of appearance change due to motion variable of light source theoretical result show in real world scene video brick of an object under varying illumination could be expressed well by a low dimensional linear subspace empirical result of the principal component analysis on the yaleb face database and our video database are consistent with the theoretical result completely the application of the low dimensional linear model of video brick is demonstrated by the foreground detection task in visual surveillance with drastic illumination change 
we propose a novel unsupervised method for discovering recurring pattern from a single view a key contribution of our approach is the formulation and validation of a joint assignment optimization problem where multiple visual word and object instance of a potential recurring pattern are considered simultaneously the optimization is achieved by a greedy randomized adaptive search procedure grasp with move specifically designed for fast convergence we have quantified systematically the performance of our approach under stressed condition of the input missing feature geometric distortion we demonstrate that our proposed algorithm outperforms state of the art method for recurring pattern discovery on a diverse set of real world and synthesized test image 
the fast radial symmetry fr transform ha been very popular for detecting interest point based on local radial symmetry although fr delivers good performance at a relatively low computational cost and is very well suited for a variety of real time computer vision application it is not invariant to perspective distortion moreover even perfectly radially symmetric visual pattern in the real world are perceived by u after a perspective projection in this paper we propose a systematic extension to the fr transform to make it invariant to bounded case of perspective projection we call this transform the generalized fr or gfrs transform we show that gfrs inherits the basic characteristic of fr and retains it computational efficiency we demonstrate the wide applicability of gfrs by applying it to a variety of natural image to detect radially symmetric pattern that have undergone significant perspective distortion subsequently we build a nucleus detector based on the gfrs transform and apply it to the important problem of digital histopathology we demonstrate superior performance over state of the art nucleus detection algorithm validated using roc curve 
current state of the art object classification system are trained using large amount of hand labeled image in this paper we present an approach that show how to use unlabeled video sequence comprising weakly related object category towards the target class to learn better classifier for tracking and detection the underlying idea is to exploit the space time consistency of moving object to learn classifier that are robust to local transformation in particular we use dense optical flow to find moving object in video in order to train part based random forest that are insensitive to natural transformation our method which is called video forest can be used in two setting first labeled training data can be regularized to force the trained classifier to generalize better towards small local transformation second a part of a tracking by detection approach it can be used to train a general codebook solely on pair wise data that can then be applied to tracking of instance of a priori unknown object category in the experimental part we show on benchmark datasets for both tracking and detection that incorporating unlabeled video into the learning of visual classifier lead to improved result 
a variety of method have been developed for visual saliency analysis these method often complement each other this paper address the problem of aggregating various saliency analysis method such that the aggregation result outperforms each individual one we have two major observation first different method perform differently in saliency analysis second the performance of a saliency analysis method varies with individual image our idea is to use data driven approach to saliency aggregation that appropriately consider the performance gap among individual method and the performance dependence of each method on individual image this paper discus various data driven approach and find that the image dependent aggregation method work best specifically our method us a conditional random field crf framework for saliency aggregation that not only model the contribution from individual saliency map but also the interaction between neighboring pixel to account for the dependence of aggregation on an individual image our approach selects a subset of image similar to the input image from a training data set and train the crf aggregation model only using this subset instead of the whole training set our experiment on public saliency benchmark show that our aggregation method outperforms each individual saliency method and is robust with the selection of aggregated method 
this paper introduces a novel approach for reassembling pot sherd found at archaeological excavation site for the purpose of reconstructing clay pot that had been made on a wheel these pot and the sherd into which they have broken are axially symmetric the reassembly process can be viewed a d puzzle solving or generalized cylinder learning from broken fragment the estimation exploit both local and semi global geometric structure thus making it a fundamental problem of geometry estimation from noisy fragment in computer vision and pattern recognition the data used are densely digitized d laser scan of each fragment s outer surface the proposed reassembly system is automatic and function when the pile of available fragment is from one or multiple pot and even when piece are missing from any pot the geometric structure used are curve on the pot along which the surface had broken and the silhouette of a pot with respect to an axis called axis profile curve apc for reassembling multiple pot with or without missing piece our algorithm estimate the apc from each fragment then reassembles into configuration the one having distinctive apc further growth of configuration is based on adding remaining fragment such that their apc and break curve are consistent with those of a configuration the method is novel more robust and handle the largest number of fragment to date 
sparsity model have recently shown great promise in many vision task using a learned dictionary in sparsity model can in general outperform predefined base in clean data in practice both training and testing data may be corrupted and contain noise and outlier although recent study attempted to cope with corrupted data and achieved encouraging result in testing phase how to handle corruption in training phase still remains a very difficult problem in contrast to most existing method that learn the dictionary from clean data this paper is targeted at handling corruption and outlier in training data for dictionary learning we propose a general method to decompose the reconstructive residual into two component a non sparse component for small universal noise and a sparse component for large outlier respectively in addition further analysis reveals the connection between our approach and the partial dictionary learning approach updating only part of the prototype or informative code word with remaining or noisy code word fixed experiment on synthetic data a well a real application have shown satisfactory performance of this new robust dictionary learning approach 
context ha been playing an increasingly important role to improve the object detection performance in this paper we propose an effective representation multi order contextual co occurrence moco to implicitly model the high level context using solely detection response from a baseline object detector the so called st order context feature is computed a a set of randomized binary comparison on the response map of the baseline object detector the statistic of the st order binary context feature are further calculated to construct a high order co occurrence descriptor combining the moco feature with the original image feature we can evolve the baseline object detector to a stronger context aware detector with the updated detector we can continue the evolution till the contextual improvement saturate using the successful deformable part model detector a the baseline detector we test the proposed moco evolution framework on the pascal voc dataset and caltech pedestrian dataset the proposed moco detector outperforms all known state of the art approach contextually boosting deformable part model ver by in mean average precision on the pascal dataset for the caltech pedestrian dataset our method further reduces the log average miss rate from to and the miss rate at fppi from to compared with the best prior art 
higher order markov random field which can capture important property of natural image have become increasingly important in computer vision while graph cut work well for first order mrf s until recently they have rarely been effective for higher order mrf s ishikawa s graph cut technique show great promise for many higher order mrf s his method transforms an arbitrary higher order mrf with binary label into a first order one with the same minimum if all the term are submodular the exact solution can be easily found otherwise pseudo boolean optimization technique can produce an optimal labeling for a subset of the variable we present a new transformation with better performance than both theoretically and experimentally while transforms each higher order term independently we transform a group of term at once for n binary variable each of which appears in term with k other variable at worst we produce n non submodular term while produce o nk we identify a local completeness property that make our method perform even better and show that under certain assumption several important vision problem including common variant of fusion move have this property running on the same field of expert dataset used in we optimally label significantly more variable versus and converge more rapidly to a lower energy preliminary experiment suggest that some other higher order mrf s used in stereo and segmentation are also locally complete and would thus benefit from our work 
photograph taken through a window are often compromised by dirt or rain present on the window surface common case of this include picture taken from inside a vehicle or outdoor security camera mounted inside a protective enclosure at capture time defocus can be used to remove the artifact but this relies on achieving a shallow depth of field and placement of the camera close to the window instead we present a post capture image processing solution that can remove localized rain and dirt artifact from a single image we collect a dataset of clean corrupted image pair which are then used to train a specialized form of convolutional neural network this learns how to map corrupted image patch to clean one implicitly capturing the characteristic appearance of dirt and water droplet in natural image our model demonstrate effective removal of dirt and rain in outdoor test condition 
in this paper we reformulate the d reconstruction of deformable surface from monocular video sequence a a labeling problem we solve simultaneously for the assignment of feature point to multiple local deformation model and the fitting of model to point to minimize a geometric cost subject to a spatial constraint that neighboring point should also belong to the same model piecewise reconstruction method rely on feature shared between model to enforce global consistency on the d surface to account for this overlap between region we consider a super set of the classic labeling problem in which a set of label instead of a single one is assigned to each variable we propose a mathematical formulation of this new model and show how it can be efficiently optimized with a variant of a expansion we demonstrate how this framework can be applied to non rigid structure from motion and lead to simpler explanation of the same data compared to existing method run on the same data our approach ha up to half the reconstruction error and is more robust to over fitting and outlier 
an important modeling decision made while designing conditional random field crfs is the choice of the potential function over the clique of variable laplacian potential are useful because they are robust potential and match image statistic better than gaussians moreover energy with laplacian term remain convex which simplifies inference this make laplacian potential an ideal modeling choice for some application in this paper we study max margin parameter learning in crfs with laplacian potential lcrfs we first show that structured hinge loss is non convex for lcrfs and thus technique used by previous work are not applicable we then present the first approximate max margin algorithm for lcrfs finally we make our learning algorithm scalable in the number of training image by using dual decomposition technique our experiment on single image depth estimation show that even with simple feature our approach achieves comparable to state of art result 
we propose a method for estimating the d structure and the dense d motion scene flow of a dynamic nonrigid d scene using a camera array the core idea is to use a dense multi camera array to construct a novel dense d volumetric representation of the d space where each voxel hold an estimated intensity value and a confidence measure of this value the problem of d structure and d motion estimation of a scene is thus reduced to a nonrigid registration of two volume hence the term scene registration registering two dense d scalar volume doe not require recovering the d structure of the scene a a preprocessing step nor doe it require explicit reasoning about occlusion from this nonrigid registration we accurately extract the d scene flow and the d structure of the scene and successfully recover the sharp discontinuity in both time and space we demonstrate the advantage of our method on a number of challenging synthetic and real data set 
subspace clustering and feature extraction are two of the most commonly used unsupervised learning technique in computer vision and pattern recognition state of the art technique for subspace clustering make use of recent advance in sparsity and rank minimization however existing technique are computationally expensive and may result in degenerate solution that degrade clustering performance in the case of insufficient data sampling to partially solve these problem and inspired by existing work on matrix factorization this paper proposes fixed rank representation frr a a unified framework for unsupervised visual learning frr is able to reveal the structure of multiple subspace in closed form when the data is noiseless furthermore we prove that under some suitable condition even with insufficient observation frr can still reveal the true subspace membership to achieve robustness to outlier and noise a sparse regularizer is introduced into the frr framework beyond subspace clustering frr can be used for unsupervised feature extraction a a non trivial byproduct a fast numerical solver is developed for frr experimental result on both synthetic data and real application validate our theoretical analysis and demonstrate the benefit of frr for unsupervised visual learning 
structure from motion sfm aim at jointly recovering the structure of a scene a a collection of d point and estimating the camera pose from a number of input image in this paper we generalize this concept not only do we want to recover d point but also recognize and estimate the location of high level semantic scene component such a region and object in d a a key ingredient for this joint inference problem we seek to model various type of interaction between scene component such interaction help regularize our solution and obtain more accurate result than solving these problem in isolation experiment on public datasets demonstrate that our framework estimate camera pose more robustly than sfm algorithm that use point only our framework is capable of accurately estimating pose and location of object region and point in the d scene our framework recognizes object and region more accurately than state of the art single image recognition method 
we propose an unsupervised detector adaptation algorithm to adapt any offline trained face detector to a specific collection of image and hence achieve better accuracy the core of our detector adaptation algorithm is a probabilistic elastic part pep model which is offline trained with a set of face example it produce a statistically aligned part based face representation namely the pep representation to adapt a general face detector to a collection of image we compute the pep representation of the candidate detection from the general face detector and then train a discriminative classifier with the top positive and negative then we re rank all the candidate detection with this classifier this way a face detector tailored to the statistic of the specific image collection is adapted from the original detector we present extensive result on three datasets with two state of the art face detector the significant improvement of detection accuracy over these state of the art face detector strongly demonstrates the efficacy of the proposed face detector adaptation algorithm 
current object class recognition system typically target d bounding box localization encouraged by benchmark data set such a pascal voc while this seems suitable for the detection of individual object higher level application such a d scene understanding or d object tracking would benefit from more fine grained object hypothesis incorporating d geometric information such a viewpoint or the location of individual part in this paper we help narrowing the representational gap between the ideal input of a scene understanding system and object class detector output by designing a detector particularly tailored towards d geometric reasoning in particular we extend the successful discriminatively trained deformable part model to include both estimate of viewpoint and d part that are consistent across viewpoint we experimentally verify that adding d geometric information come at minimal performance loss w r t d bounding box localization but outperforms prior work in d viewpoint estimation and ultra wide baseline matching 
in this work we present a direct least square dl method for computing all solution of the perspective n point camera pose determination pnp problem in the general case n specifically based on the camera measurement equation we formulate a nonlinear least square cost function whose optimality condition constitute a system of three third order polynomial subsequently we employ the multiplication matrix to determine all the root of the system analytically and hence all minimum of the l without requiring iteration or an initial guess of the parameter a key advantage of our method is scalability since the order of the polynomial system that we solve is independent of the number of point we compare the performance of our algorithm with the leading pnp approach both in simulation and experimentally and demonstrate that dl consistently achieves accuracy close to the maximum likelihood estimator mle 
state of the art method for human detection and pose estimation require many training sample for best performance while large manually collected datasets exist the captured variation w r t appearance shape and pose are often uncontrolled thus limiting the overall performance in order to overcome this limitation we propose a new technique to extend an existing training set that allows to explicitly control pose and shape variation for this we build on recent advance in computer graphic to generate sample with realistic appearance and background while modifying body shape and pose we validate the effectiveness of our approach on the task of articulated human detection and articulated pose estimation we report close to state of the art result on the popular image parsing human pose estimation benchmark and demonstrate superior performance for articulated human detection in addition we define a new challenge of combined articulated human detection and pose estimation in real world scene 
source camera identification find many application in real world although many identification method have been proposed they work with only a small set of camera and are weak at identifying camera of the same model based on the observation that a digital image would not change if the same auto white balance awb algorithm is applied for the second time this paper proposes to identify the source camera by approximating the awb algorithm used inside the camera to the best of our knowledge this is the first time that a source camera identification method based on awb ha been reported experiment show near perfect accuracy in identifying camera of different brand and model besides proposed method performance quite well in distinguishing among camera device of the same model a awb is done at the end of imaging pipeline any small difference induced earlier will lead to different type of awb output furthermore the performance remains stable a the number of camera grows large 
we present a method to predict primary gaze behavior in a social scene inspired by the study of electric field we posit social charge latent quantity that drive the primary gaze behavior of member of a social group these charge induce a gradient field that defines the relationship between the social charge and the primary gaze direction of member in the scene this field model is used to predict primary gaze behavior at any location or time in the scene we present an algorithm to estimate the time varying behavior of these charge from the primary gaze behavior of measured observer in the scene we validate the model by evaluating it predictive precision via cross validation in a variety of social scene 
we present swig a swift and efficient guided sampling method for robust model estimation from image feature correspondence our method leverage the accuracy of our new confidence measure mr rayleigh which assigns a correctness confidence to a putative correspondence in an online fashion mr rayleigh is inspired by meta recognition mr an algorithm that aim to predict when a classifier s outcome is correct we demonstrate that by using a rayleigh distribution the prediction accuracy of mr can be improved considerably our experiment show that mr rayleigh tends to predict better than the often used lowe s ratio brown s ratio and the standard mr under a range of imaging condition furthermore our homography estimation experiment demonstrates that swig performs similarly or better than other guided sampling method while requiring fewer iteration leading to fast and accurate model estimate 
classification cascade have been very effective for object detection such a cascade fails to perform well in data domain with variation in appearance that may not be captured in the training example this limited generalization severely restricts the domain for which they can be used effectively a common approach to address this limitation is to train a new cascade of classifier from scratch for each of the new domain building separate detector for each of the different domain requires huge annotation and computational effort making it not scalable to a large number of data domain here we present an algorithm for quickly adapting a pre trained cascade of classifier using a small number of labeled positive instance from a different yet similar data domain in our experiment with image of human baby and human like character from movie we demonstrate that the adapted cascade significantly outperforms both of the original cascade and the one trained from scratch using the given training example 
we present an algorithm to simultaneously recover non rigid shape and camera pose from point correspondence between a reference shape and a sequence of input image the key novel contribution of our approach is in bringing the tool of the probabilistic slam methodology from a rigid to a deformable domain under the assumption that the shape may be represented a a weighted sum of deformation mode we show that the problem of estimating the modal weight along with the camera pose may be probabilistically formulated a a maximum a posterior estimate and solved using an iterative least square optimization an extensive evaluation on synthetic and real data show that our approach ha several significant advantage over current approach such a performing robustly under large amount of noise and outlier and neither requiring to track point over the whole sequence nor initialization close from the ground truth solution 
we introduce a method to jointly estimate the brdf and geometry of an object from a single image under known but uncontrolled natural illumination we show that this previously unexplored problem becomes tractable when one exploit the orientation clue embedded in the lighting environment intuitively unique region in the lighting environment act analogously to the point light source of traditional photometric stereo they strongly constrain the orientation of the surface patch that reflect them the reflectance which act a a bandpass filter on the lighting environment determines the necessary scale of such region accurate reflectance estimation however relies on accurate surface orientation information thus these two factor must be estimated jointly to do so we derive a probabilistic formulation and introduce prior to address situation where the reflectance and lighting environment do not sufficiently constrain the geometry of the object through extensive experimentation we show what this space look like and offer insight into what problem become solvable in various category of real world natural illumination environment 
we present an approach to d scene flow estimation which exploit that in realistic scenario image motion is frequently dominated by observer motion and independent but rigid object motion we cast the dense estimation of both scene structure and d motion from sequence of two or more view a a single energy minimization problem we show that agnostic smoothness prior such a the popular total variation are biased against motion discontinuity in viewing direction instead we propose to regularize by encouraging local rigidity of the d scene we derive a local rigidity constraint of the d scene flow and define a smoothness term that penalizes deviation from that constraint thus favoring solution that consist largely of rigidly moving part our experiment show that the new rigid motion prior reduces the d flow error by compared to standard tv regularization with the same data term 
we propose a novel graphical model for probabilistic image segmentation that contributes both to aspect of perceptual grouping in connection with image segmentation and to globally optimal inference with higher order graphical model we represent image partition in term of cellular complex in order to make the duality between connected region and their contour explicit this allows u to formulate a graphical model with higher order factor that represent the requirement that all contour must be closed the model induces a probability measure on the space of all partition concentrated on perceptually meaningful segmentation we give a complete polyhedral characterization of the resulting global inference problem in term of the multicut polytope and efficiently compute global optimum by a cutting plane method competitive result for the berkeley segmentation benchmark confirm the consistency of our approach 
computing accurate and robust organizational pattern of chromosome territory inside the cell nucleus is critical for understanding several fundamental genomic process such a co regulation of gene activation gene silencing x chromosome inactivation and abnormal chromosome rearrangement in cancer cell the usage of advanced fluorescence labeling and image processing technique ha enabled researcher to investigate interaction of chromosome territory at large spatial resolution the resulting high volume of generated data demand for high throughput and automated image analysis method in this paper we introduce a novel algorithmic tool for investigating association pattern of chromosome territory in a population of cell our method take a input a set of graph one for each cell containing information about spatial interaction of chromosome territory and yield a single graph that contains essential information for the whole population and stand a it structural representative we formulate this combinatorial problem a a semi definite programming and present novel technique to efficiently solve it we validate our approach on both artificial and real biological data the experimental result suggest that our approach yield a near optimal solution and can handle large size datasets which are significant improvement over existing technique 
we address the problem of localizing and estimating the fine pose of object in the image with exact d model our main focus is to unify contribution from the s with recent advance in object detection use local keypoint detector to find candidate pose and score global alignment of each candidate pose to the image moreover we also provide a new dataset containing fine aligned object with their exactly matched d model and a set of model for widely used object we also evaluate our algorithm both on object detection and fine pose estimation and show that our method outperforms state of the art algorithm 
in various computer vision application often we need to convert an image in one style into another style for better visualization interpretation and recognition for example up convert a low resolution image to a high resolution one and convert a face sketch into a photo for matching etc a semi coupled dictionary learning scdl model is proposed in this paper to solve such cross style image synthesis problem under scdl a pair of dictionary and a mapping function will be simultaneously learned the dictionary pair can well characterize the structural domain of the two style of image while the mapping function can reveal the intrinsic relationship between the two style domain in scdl the two dictionary will not be fully coupled and hence much flexibility can be given to the mapping function for an accurate conversion across style moreover clustering and image nonlocal redundancy are introduced to enhance the robustness of scdl the proposed scdl model is applied to image super resolution and photo sketch synthesis and the experimental result validated it generality and effectiveness in cross style image synthesis 
cancer tissue in histopathology image exhibit abnormal pattern it is of great clinical importance to label a histopathology image a having cancerous region or not and perform the corresponding image segmentation however the detailed annotation of cancer cell is often an ambiguous and challenging task in this paper we propose a new learning method multiple clustered instance learning mcil to classify segment and cluster cancer cell in colon histopathology image the proposed mcil method simultaneously performs image level classification cancer v non cancer image pixel level segmentation cancer v non cancer tissue and patch level clustering cancer subclass we embed the clustering concept into the multiple instance learning mil setting and derive a principled solution to perform the above three task in an integrated framework experimental result demonstrate the efficiency and effectiveness of mcil in analyzing colon cancer 
in this paper we address invariant keypoint based texture characterization and recognition viewing keypoint set associated with visual texture a realization of point process we investigate probabilistic texture model from multivariate log gaussian cox process these model are parameterized by the covariance structure of the spatial pattern their implementation initially rely on the construction of a codebook of the visual signature of keypoints we discus invariance property of the proposed model for texture recognition application and report a quantitative evaluation for three texture datasets namely uiuc kth tip and brodatz these experiment include a comparison of the performance reached using different method for keypoint detection and characterization and demonstrate the relevance of the proposed model w r t state of the art method we further discus the main contribution of proposed approach including the key feature of a statistical model and complexity aspect 
this article proposes a novel image based method to transfer illumination from a reference face image to a target face image through edge preserving filter according to our method only a single reference image without any knowledge of the d geometry or material information of the target face is needed we first decompose the lightness layer of the reference and the target image into large scale and detail layer through weighted least square wls filter after face alignment the large scale layer of the reference image is filtered with the guidance of the target image adaptive parameter selection scheme for the edge preserving filter is proposed in the above two filtering step the final relit result is obtained by replacing the large scale layer of the target image with that of the reference image we acquire convincing relit result on numerous target and reference face image with different lighting effect and gender comparison with previous work show that our method is le affected by geometry difference and can preserve better the identification structure and skin color of the target face 
an approach to learn a structured low rank representation for image classification is presented we use a supervised learning method to construct a discriminative and reconstructive dictionary by introducing an ideal regularization term we perform low rank matrix recovery for contaminated training data from all category simultaneously without losing structural information a discriminative low rank representation for image with respect to the constructed dictionary is obtained with semantic structure information and strong identification capability this representation is good for classification task even using a simple linear multi classifier experimental result demonstrate the effectiveness of our approach 
the saliency of region or object in an image can be significantly boosted if they recur in multiple image leveraging this idea cosegmentation jointly segment common region from multiple image in this paper we propose cosand a distributed cosegmentation approach for a highly variable large scale image collection the segmentation task is modeled by temperature maximization on anisotropic heat diffusion of which the temperature maximization with finite k heat source corresponds to a k way segmentation that maximizes the segmentation confidence of every pixel in an image we show that our method take advantage of a strong theoretic property in that the temperature under linear anisotropic diffusion is a submodular function therefore a greedy algorithm guarantee at least a constant factor approximation to the optimal solution for temperature maximization our theoretic result is successfully applied to scalable cosegmentation a well a diversity ranking and single image segmentation we evaluate cosand on msrc and imagenet datasets and show it competence both in competitive performance over previous work and in much superior scalability 
transparent gas flow are difficult to reconstruct the refractive index field rif within the gas volume is uneven and rapidly evolving and correspondence matching under distortion is challenging we present a novel computational imaging solution by exploiting the light field probe lf probe a lf probe resembles a view dependent pattern where each pixel on the pattern map to a unique ray by observing the lf probe through the gas flow we acquire a dense set of ray ray correspondence and then reconstruct their light path to recover the rif we use fermat s principle to correlate each light path with the rif via a partial differential equation pde we then develop an iterative optimization scheme to solve for all light path pdes in conjunction specifically we initialize the light path by fitting hermite spline to ray ray correspondence discretize their pdes onto voxels and solve a large over determined pde system for the rif the rif can then be used to refine the light path finally we alternate the rif and light path estimation to improve the reconstruction experiment on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flow in particular when the flow is acquired by a small number of camera the use of ray ray correspondence can greatly improve the reconstruction 
we propose a formulation of monocular slam which combine live dense reconstruction with shape prior based d tracking and reconstruction current live dense slam approach are limited to the reconstruction of visible surface moreover most of them are based on the minimisation of a photo consistency error which usually make them sensitive to specularities in the d pose recovery literature problem caused by imperfect and ambiguous image information have been dealt with by using prior shape knowledge at the same time the success of depth sensor ha shown that combining joint image and depth information drastically increase the robustness of the classical monocular d tracking and d reconstruction approach in this work we link dense slam to d object pose and shape recovery more specifically we automatically augment our slam system with object specific identity together with d pose and additional shape degree of freedom for the object s of known class in the scene combining image data em and depth information for the pose and shape recovery this lead to a system that allows for full scaled d reconstruction with the known object s segmented from the scene the segmentation enhances the clarity accuracy and completeness of the map built by the dense slam system while the dense d data aid the segmentation process yielding faster and more reliable convergence than when using d image data alone 
we propose a novel unifying framework using a markov network to learn the relationship between multiple classifier in face recognition we assume that we have several complementary classifier and assign observation node to the feature of a query image and hidden node to the feature of gallery image we connect each hidden node to it corresponding observation node and to the hidden node of other neighboring classifier for each observation hidden node pair we collect a set of gallery candidate that are most similar to the observation instance and the relationship between the hidden node is captured in term of the similarity matrix between the collected gallery image posterior probability in the hidden node are computed by the belief propagation algorithm the novelty of the proposed framework is the method that take into account the classifier dependency using the result of each neighboring classifier we present extensive result on two different evaluation protocol known and unknown image variation test using three different database which show that the proposed framework always lead to good accuracy in face recognition 
a new method is proposed to detect abnormal behavior in human group activity this approach effectively model group activity based on social behavior analysis different from previous work that us independent local feature our method explores the relationship between the current behavior state of a subject and it action an interaction energy potential function is proposed to represent the current behavior state of a subject and velocity is used a it action our method doe not depend on human detection or segmentation so it is robust to detection error instead tracked spatio temporal interest point are able to provide a good estimation of modeling group interaction svm is used to find abnormal event we evaluate our algorithm in two datasets umn and behave experimental result show it promising performance against the state of art method 
we consider a parametrized relaxation of the widely adopted quadratic assignment problem qap formulation for minimum distortion correspondence between deformable shape in order to control the accuracy sparsity trade off we introduce a weighting parameter on the combination of two existing relaxation namely spectral and game theoretic this lead to the introduction of the elastic net penalty function into shape matching problem in combination with an efficient algorithm to project onto the elastic net ball we obtain an approach for deformable shape matching with controllable sparsity experiment on a standard benchmark confirm the effectiveness of the approach 
there exists an abundance of system and algorithm for multiple target detection and tracking in video and many measure for evaluating the quality of their output have been proposed the contribution of this paper lie in the following first it argues that such performance measure should have two fundamental property monotonicity and error type differentiability second it show that the recently proposed measure do not have either of these property and are thus le usable third it composes a set of simple measure partly built on common practice that doe have these property the informativeness of the proposed set of performance measure is demonstrated through their application on face detection and tracking result 
this paper present a method to synthesize a realistic facial animation of a target person driven by a facial performance video of another person different from traditional facial animation approach our system take advantage of an existing facial performance database of the target person and generates the final video by retrieving frame from the database that have similar expression to the input one to achieve this we develop an expression similarity metric for accurately measuring the expression difference between two video frame to enforce temporal coherence our system employ a shortest path algorithm to choose the optimal image for each frame from a set of candidate frame determined by the similarity metric finally our system adopts an expression mapping method to further minimize the expression difference between the input and retrieved frame experimental result show that our system can generate high quality facial animation using the proposed data driven approach 
in recent year knowledge transfer algorithm have become one of most the active research area in learning visual concept most of the existing learning algorithm focus on leveraging the knowledge transfer process which is specific to a given category however in many case such a process may not be very effective when a particular target category ha very few sample in such case it is interesting to examine whether it is feasible to use cross category knowledge for improving the learning process by exploring the knowledge in correlated category such a task can be quite challenging due to variation in semantic similarity and difference between category which could either help or hinder the cross category learning process in order to address this challenge we develop a cross category label propagation algorithm which can directly propagate the inter category knowledge at instance level between the source and the target category furthermore this algorithm can automatically detect condition under which the transfer process can be detrimental to the learning process this provides u a way to know when the transfer of cross category knowledge is both useful and desirable we present experimental result on real image and video data set in order to demonstrate the effectiveness of our approach 
the paradox of visual polysemia and concept polymorphism ha been a great challenge in the large scale semantic image search to address this problem our paper proposes a new method to generate image vicept representation vicept characterizes the membership distribution between elementary visual appearance and semantic concept and form a hierarchical representation of image semantic from local to global to obtain discriminative vicept description with structural sparsity we adopt mixed norm regularization in the optimization problem for learning the concept membership distribution of visual word furthermore considering the structure of bov in image visual descriptor is encoded a a weighted sum of dictionary element using group sparse coding which could obtain sparse representation at the image level the wide application of vicept are validated in our experiment including large scale semantic image search image annotation and semantic image re ranking 
aerial imagery of an urban environment is often characterized by significant occlusion sharp edge and textureless region leading to poor d reconstruction using conventional multi view stereo method in this paper we propose a novel approach to d reconstruction of urban area from a set of uncalibrated aerial image a very general structural prior is assumed that urban scene consist mostly of planar surface oriented either in a horizontal or an arbitrary vertical orientation in addition most structural edge associated with such surface are also horizontal or vertical these two assumption provide powerful constraint on the underlying d geometry the main contribution of this paper is to translate the two constraint on d structure into intra image column and inter image column constraint respectively and to formulate the dense reconstruction a a pas dynamic programming problem which is solved in complete parallel on a gpu the result is an accurate cloud of d dense point of the underlying urban scene our algorithm completes the reconstruction of m point with available discrete height level in under a hundred second result on multiple datasets show that we are capable of preserving a high level of structural detail and visual quality 
with the wide spread of consumer d tv technology stereoscopic videoconferencing system are emerging however the special glass participant wear to see d can create distracting image this paper present a computational framework to reduce undesirable artifact in the eye region caused by these d glass more specifically we add polarized filter to the stereo camera so that partial image of reflection can be captured a novel bayesian model is then developed to describe the imaging process of the eye region including darkening and reflection and infer the eye region based on classification expectation maximization em the recovered eye region under the glass are brighter and with little reflection leading to a more nature videoconferencing experience qualitative evaluation and user study are conducted to demonstrate the substantial improvement our approach can achieve 
we present a novel method for analyzing social behavior continuous video are segmented into action bout by building a temporal context model that combine feature from spatio temporal energy and agent trajectory the method is tested on an unprecedented dataset of video of interacting pair of mouse which wa collected a part of a state of the art neurophysiological study of behavior the dataset comprises over hour million frame of annotated video we find that our novel trajectory feature used in a discriminative framework are more informative than widely used spatio temporal feature furthermore temporal context play an important role for action recognition in continuous video our approach may be seen a a baseline method on this dataset reaching a mean recognition rate of compared to the expert s agreement rate of about 
we present a new multi view d euclidean reconstruction method for arbitrary uncalibrated radially symmetric camera which need no calibration or any camera model parameter other than radial symmetry it is built on the radial d camera model a unified mathematical abstraction to different type of radially symmetric camera we formulate the problem of multi view reconstruction for radial d camera a a matrix rank minimization problem efficient implementation based on alternating direction continuation is proposed to handle scalability issue for real world application our method applies to a wide range of omni directional camera including both dioptric and catadioptric central and non central camera additionally our method deal with complete and incomplete measurement under a unified framework elegantly experiment on both synthetic and real image from various type of camera validate the superior performance of our new method in term of numerical accuracy and robustness 
in this paper we present an inference procedure for the semantic segmentation of image different from many crf approach that rely on dependency modeled with unary and pairwise pixel or super pixel potential our method is entirely based on estimate of the overlap between each of a set of mid level object segmentation proposal and the object present in the image we define continuous latent variable on super pixel obtained by multiple intersection of segment then output the optimal segment from the inferred super pixel statistic the algorithm is capable of recombine and refine initial mid level proposal a well a handle multiple interacting object even from the same class all in a consistent joint inference framework by maximizing the composite likelihood of the underlying statistical model using an em algorithm in the pascal voc segmentation challenge the proposed approach obtains high accuracy and successfully handle image of complex object interaction 
we address the problem of multi person data association based tracking dat in semi crowded environment from a single camera existing tracklet association based method using purely visual cue like appearance and motion information show impressive result but rely on heavy training a number of tuned parameter and sophisticated detector to cope with visual ambiguity within the video and low level processing error in this work we consider clustering dynamic to mitigate such ambiguity this lead to a general optimization framework that add social grouping behavior sgb to any basic affinity model we formulate this a a nonlinear global optimization problem to maximize the consistency of visual and grouping cue for trajectory in both tracklet tracklet linking space and tracklet grouping assignment space we formulate the lagrange dual and solve it using a two stage iterative algorithm employing the hungarian algorithm and k mean clustering we build sgb upon a simple affinity model and show very promising performance on two publicly available real world datasets with different tracklet extraction method 
we tackle the practical problem of hand pose estimation from a single noisy depth image a dedicated three step pipeline is proposed initial estimation step provides an initial estimation of the hand in plane orientation and d location candidate generation step produce a set of d pose candidate from the hough voting space with the help of the rotational invariant depth feature verification step delivers the final d hand pose a the solution to an optimization problem we analyze the depth noise and suggest tip to minimize their negative impact on the overall performance our approach is able to work with kinect type noisy depth image and reliably produce pose estimation of general motion efficiently frame per second extensive experiment are conducted to qualitatively and quantitatively evaluate the performance with respect to the state of the art method that have access to additional rgb image our approach is shown to deliver on par or even better result 
real world surface such a clothing water and human body deform in complex way the image distortion observed are high dimensional and non linear making it hard to estimate these deformation accurately the recent data driven descent approach applies nearest neighbor estimator iteratively on a particular distribution of training sample to obtain a globally optimal and dense deformation field between a template and a distorted image in this work we develop a hierarchical structure for the nearest neighbor estimator each of which can have only a local image support we demonstrate in both theory and practice that this algorithm ha several advantage over the non hierarchical version it guarantee global optimality with significantly fewer training sample is several order faster provides a metric to decide whether a given image is hard or easy requiring more or le sample and can handle more complex scene that include both global motion and local deformation the proposed algorithm successfully track a broad range of non rigid scene including water clothing and medical image and compare favorably against several other deformation estimation and tracking approach that do not provide optimality guarantee 
one of the most challenging task in face recognition is to identify people with varied pose namely the test face have significantly different pose compared with the registered face in this paper we propose a high level feature learning scheme to extract pose invariant identity feature for face recognition first we build a single hidden layer neural network with sparse constraint to extract pose invariant feature in a supervised fashion second we further enhance the discriminative capability of the proposed feature by using multiple random face a the target value for multiple encoders by enforcing the target value to be unique for input face over different pose the learned high level feature that is represented by the neuron in the hidden layer is pose free and only relevant to the identity information finally we conduct face identification on cmu multi pie and verification on labeled face in the wild lfw database where identification rank accuracy and face verification accuracy with roc curve are reported these experiment demonstrate that our model is superior to other state of the art approach on handling pose variation 
this paper introduces a new idea in describing people using their first name i e the name assigned at birth we show that describing people in term of similarity to a vector of possible first name is a powerful description of facial appearance that can be used for face naming and building facial attribute classifier we build model for common first name used in the united state and for each pair construct a pair wise first name classifier these classifier are built using training image downloaded from the internet with no additional user interaction this give our approach important advantage in building practical system that do not require additional human intervention for labeling we use the score from each pair wise name classifier a a set of facial attribute we show several surprising result our name attribute predict the correct first name of test face at rate far greater than chance the name attribute are applied to gender recognition and to age classification outperforming state of the art method with all training image automatically gathered from the internet 
analysis of gene expression pattern in brain image obtained from high throughput in situ hybridization requires accurate and consistent annotation of anatomical region subregions such annotation are obtained by mapping an anatomical atlas onto the gene expression image through intensityand or landmark based registration method or deformable model based segmentation method due to the complex appearance of the gene expression image these approach require a pre processing step to determine landmark correspondence in order to incorporate landmark based geometric constraint in this paper we propose a novel method for landmark constrained intensity based registration without determining landmark correspondence a priori the proposed method performs dense image registration and identifies the landmark correspondence simultaneously using a single higher order markov random field model in addition a machine learning technique is used to improve the discriminating property of local descriptor for landmark matching by projecting them in a hamming space of lower dimension we qualitatively show that our method achieves promising result and also compare well quantitatively with the expert s annotation outperforming previous method 
low cost cmos camera can have an acquisition mode called rolling shutter which sequentially expose the scan line when a single object move with respect to the camera this creates image distortion assuming d d correspondence known previous work showed that the object pose and kinematics can be estimated from a single rolling shutter image this wa achieved using a suboptimal initialization followed by local iterative optimization we propose a polynomial projection model for rolling shutter camera and a constrained global optimization of it parameter this is done by mean of a semidefinite programming problem obtained from the generalized problem of moment method contrarily to previous work our optimization doe not require an initialization and ensures that the global minimum is achieved this allows u to build automatically robust d d correspondence using a template to provide an initial set of correspondence experiment show that our method slightly improves previous work on both simulated and real data this is due to local minimum into which previous method get trapped we also successfully experimented building d d correspondence automatically with both simulated and real data 
this paper present an approach to text recognition in natural scene image unlike most existing work which assume that text are horizontal and frontal parallel to the image plane our method is able to recognize perspective text of arbitrary orientation for individual character recognition we adopt a bag of key point approach in which scale invariant feature transform sift descriptor are extracted densely and quantized using a pre trained vocabulary following the context information is utilized through lexicon we formulate word recognition a finding the optimal alignment between the set of character and the list of lexicon word furthermore we introduce a new dataset called streetviewtext perspective which contains text in street image with a great variety of viewpoint experimental result on public datasets and the proposed dataset show that our method significantly outperforms the state of the art on perspective text of arbitrary orientation 
this paper proposes a novel sparse representation model called centralized sparse representation csr for image restoration task in order for faithful image reconstruction it is expected that the sparse coding coefficient of the degraded image should be a close a possible to those of the unknown original image with the given dictionary however since the available data are the degraded noisy blurred and or down sampled version of the original image the sparse coding coefficient are often not accurate enough if only the local sparsity of the image is considered a in many existing sparse representation model to make the sparse coding more accurate a centralized sparsity constraint is introduced by exploiting the nonlocal image statistic the local sparsity and the nonlocal sparsity constraint are unified into a variational framework for optimization extensive experiment on image restoration validated that our csr model achieves convincing improvement over previous state of the art method 
dense optical flow estimation in image is a challenging problem because the algorithm must coordinate the estimated motion across large region in the image while avoiding inappropriate smoothing over motion boundary recent work have advocated for the use of nonlocal regularization to model long range correlation in the flow however incorporating nonlocal regularization into an energy optimization framework is challenging due to the large number of pairwise penalty term existing technique either substitute intermediate filtering of the flow field for direct optimization of the nonlocal objective or suffer substantial performance penalty when the range of the regularizer increase in this paper we describe an optimization algorithm that efficiently handle a general type of nonlocal regularization objective for optical flow estimation the computational complexity of the algorithm is independent of the range of the regularizer we show that nonlocal regularization improves estimation accuracy at longer range than previously reported and is complementary to intermediate filtering of the flow field our algorithm is simple and is compatible with many optical flow model 
this paper study the visual tracking problem in video sequence and present a novel robust sparse tracker under the particle filter framework in particular we propose an online robust non negative dictionary learning algorithm for updating the object template so that each learned template can capture a distinctive aspect of the tracked object another appealing property of this approach is that it can automatically detect and reject the occlusion and cluttered background in a principled way in addition we propose a new particle representation formulation using the huber loss function the advantage is that it can yield robust estimation without using trivial template adopted by previous sparse tracker leading to faster computation we also reveal the equivalence between this new formulation and the previous one which us trivial template the proposed tracker is empirically compared with state of the art tracker on some challenging video sequence both quantitative and qualitative comparison show that our proposed tracker is superior and more stable 
we consider the problem of image representation for visual analysis when representing image a vector the feature space is of very high dimensionality which make it difficult for applying statistical technique for visual analysis to tackle this problem matrix factorization technique such a singular vector decomposition svd and non negative matrix factorization nmf received an increasing amount of interest in recent year matrix factorization is an unsupervised learning technique which find a basis set capturing high level semantics in the data and learns coordinate in term of the basis set however the representation obtained by them are highly dense and can not capture the intrinsic geometric structure in the data in this paper we propose a novel method called sparse concept coding scc for image representation and analysis inspired from the recent development on manifold learning and sparse coding scc provides a sparse representation which can capture the intrinsic geometric structure of the image space extensive experimental result on image clustering have shown that the proposed approach provides a better representation with respect to the semantic structure 
we address the problem of articulated human pose estimation in video using an ensemble of tractable model with rich appearance shape contour and motion cue in previous articulated pose estimation work on unconstrained video using temporal coupling of limb position ha made little to no difference in performance over parsing frame individually one crucial reason for this is that joint parsing of multiple articulated part over time involves intractable inference and learning problem and previous work ha resorted to approximate inference and simplified model we overcome these computational and modeling limitation using an ensemble of tractable submodels which couple location of body joint within and across frame using expressive cue each submodel is responsible for tracking a single joint through time e g left elbow and also model the spatial arrangement of all joint in a single frame because of the tree structure of each submodel we can perform efficient exact inference and use rich temporal feature that depend on image appearance e g color tracking and optical flow contour we propose and experimentally investigate a hierarchy of submodel combination method and we find that a highly efficient max marginal combination method outperforms much slower by order of magnitude approximate inference using dual decomposition we apply our pose model on a new video dataset of highly varied and articulated pose from tv show we show significant quantitative and qualitative improvement over state of the art single frame pose estimation approach 
salient object detection ha been attracting a lot of interest and recently various heuristic computational model have been designed in this paper we regard saliency map computation a a regression problem our method which is based on multi level image segmentation us the supervised learning approach to map the regional feature vector to a saliency score and finally fuse the saliency score across multiple level yielding the saliency map the contribution lie in two fold one is that we show our approach which integrates the regional contrast regional property and regional background ness descriptor together to form the master saliency map is able to produce superior saliency map to existing algorithm most of which combine saliency map heuristically computed from different type of feature the other is that we introduce a new regional feature vector background ness to characterize the background which can be regarded a a counterpart of the objectness descriptor the performance evaluation on several popular benchmark data set validates that our approach outperforms existing state of the art 
this paper present a middle level video representation named video primal sketch vps which integrates two regime of model i sparse coding model using static or moving primitive to explicitly represent moving corner line feature point etc ii frame mrf model with spatio temporal filter to implicitly represent textured motion such a water and fire by matching feature statistic i e histogram this paper make three contribution i learning a dictionary of video primitive a parametric generative model ii studying the spatio temporal frame st frame model for modeling and synthesizing textured motion and iii developing a parsimonious hybrid model for generic video representation vps selects the proper representation automatically and is compatible with high level action representation in the experiment we synthesize a series of dynamic texture reconstruct real video and show varying vps over the change of density causing by the scale transition in video 
establishing correspondence between two feature set is a fundamental issue in computer vision pattern recognition and machine learning this problem can be well formulated a graph matching in which node represent feature point while edge describe pairwise relation between feature point recently several research have tried to embed higher order relation of feature point by hyper graph matching formulation in this paper we generalize the previous hyper graph matching formulation to cover relation of feature in arbitrary order and propose a novel state of the art algorithm by reinterpreting the random walk concept on the hyper graph in a probabilistic manner adopting personalized jump with a reweighting scheme the algorithm effectively reflects the one to one matching constraint during the random walk process comparative experiment on synthetic data and real image show that the proposed method clearly outperforms existing algorithm especially in the presence of noise and outlier 
we present a new approach to capture video at high spatial and spectral resolution using a hybrid camera system composed of an rgb video camera a grayscale video camera and several optical element the hybrid camera system simultaneously record two video stream an rgb video with high spatial resolution and a multispectral video with low spatial resolution after registration of the two video stream our system propagates the multispectral information into the rgb video to produce a video with both high spectral and spatial resolution this propagation between video is guided by color similarity of pixel in the spectral domain proximity in the spatial domain and the consistent color of each scene point in the temporal domain the propagation algorithm is designed for rapid computation to allow real time video generation at the original frame rate and can thus facilitate real time video analysis task such a tracking and surveillance hardware implementation detail and design tradeoff are discussed we evaluate the proposed system using both simulation with ground truth data and on real world scene the utility of this high resolution multispectral video data is demonstrated in dynamic white balance adjustment and tracking 
in this paper we propose a robust object tracking algorithm using a collaborative model a the main challenge for object tracking is to account for drastic appearance change we propose a robust appearance model that exploit both holistic template and local representation we develop a sparsity based discriminative classifier sd c and a sparsity based generative model sgm in the s dc module we introduce an effective method to compute the confidence value that assigns more weight to the foreground than the background in the sgm module we propose a novel histogram based method that take the spatial information of each patch into consideration with an occlusion handing scheme furthermore the update scheme considers both the latest observation and the original template thereby enabling the tracker to deal with appearance change effectively and alleviate the drift problem numerous experiment on various challenging video demonstrate that the proposed tracker performs favorably against several state of the art algorithm 
in this paper we study the problem of landmark recognition and propose to leverage d visual phrase to improve the performance a d visual phrase is a triangular facet on the surface of a reconstructed d landmark model in contrast to existing d visual phrase which are mainly based on co occurrence statistic in d image plane such d visual phrase explicitly characterize the spatial structure of a d object landmark and are highly robust to projective transformation due to viewpoint change we present an effective solution to discover describe and detect d visual phrase the experiment on landmark have achieved promising result which demonstrate that our approach provides a good balance between precision and recall of landmark recognition while reducing the dependence on post verification to reject false positive 
a large number of problem in computer vision can be modeled a energy minimization problem in a markov random field mrf framework many method have been developed over the year for efficient inference especially in pairwise mrfs in general there is a trade off between the complexity efficiency of the algorithm and it convergence property with certain problem requiring more complex inference to handle general pairwise potential graphcuts based expansion performs well on certain class of energy and sequential tree reweighted message passing trws and loopy belief propagation lbp can be used for non submodular case these method though suffer from poor convergence and often oscillate between solution in this paper we propose a tiered move making algorithm which is an iterative method each move to the next configuration is based on the current labeling and an optimal tiered move where each tiered move requires one application of the dynamic programming based tiered labeling method introduced in felzenszwalb et al the algorithm converges to a local minimum for any general pairwise potential and we give a theoretical analysis of the property of the algorithm characterizing the situation in which we can expect good performance we evaluate the algorithm on many benchmark labeling problem such a stereo image segmentation image stitching and image denoising a well a random energy minimization our method consistently get better energy value than expansion lbp quadratic pseudo boolean optimization qpbo and is competitive with trws 
in this paper we present a novel non rigid optical flow algorithm for dense image correspondence and non rigid registration the algorithm us a unique laplacian mesh energy term to encourage local smoothness whilst simultaneously preserving non rigid deformation laplacian deformation approach have become popular in graphic research a they enable mesh deformation to preserve local surface shape in this work we propose a novel laplacian mesh energy formula to ensure such sensible local deformation between image pair we express this wholly within the optical flow optimization and show it application in a novel coarse to fine pyramidal approach our algorithm achieves the state of the art performance in all trial on the garg et al dataset and top tier performance on the middlebury evaluation 
optical flow estimation is a fundamental and ill posed problem in computer vision to recover a dense flow field appropriate spatial constraint have to be enforced recent advance exploit higher order spatial regularization and achieve the top performance on the middlebury benchmark in this work we revisit learning based approach and propose a learned sparse model to patch wisely regularize the flow field in particular our method is based on multi scale spatial regularization which benefit from first order spatial regularity and our learned higher order sparse model to obtain accurate flow estimation we propose a sequential optimization scheme to solve the corresponding energy minimization problem moreover a the error in intermediate flow estimate are usually dense with large variation we further propose flow driven and image driven approach to address the problem of outlier experiment on the middlebury benchmark show that our method is competitive with the state of the art 
image taken from scene under water suffer distortion due to refraction while refraction cause magnification with mild distortion on the observed image severe distortion in geometry reconstruction would be resulted if the refractive distortion is not properly handled different from the radial distortion model the refractive distortion depends on the scene depth seen from each light ray a well a the camera pose relative to the refractive surface therefore it s crucial to obtain a good estimate of scene depth camera pose and optical center to alleviate the impact of refractive distortion in this work we formulate the forward and back projection of light ray involving a refractive plane for the perspective camera model by explicitly modeling refractive distortion a a function of depth furthermore for camera with an inertial measurement unit imu we show that a linear solution to the relative pose and a closed form solution to the absolute pose can be derived with known camera vertical direction we incorporate our formulation with the general structure from motion framework followed by the patch based multiview stereo algorithm to obtain a d reconstruction of the scene we show through experiment that the explicit modeling of depth dependent refractive distortion physically lead to more accurate scene reconstruction 
we characterize a class of video consisting of very small but potentially complicated motion we find that in these scene linear appearance variation have a direct relationship to scene motion we show how to interpret appearance variation captured through a pca decomposition of the image set a a scene specific non parametric motion basis we propose fast robust tool for dense flow estimate that are effective in scene with small motion and potentially large image noise we show example result in a variety of application including motion segmentation and long term point tracking 
matching the visual appearance of the target over consecutive image frame is the most critical issue in video based object tracking choosing an appropriate distance metric for matching determines it accuracy and robustness and significantly influence the tracking performance this paper present a new tracking approach that incorporates adaptive metric into differential tracking method this new approach automatically learns an optimal distance metric for more accurate matching and obtains a closed form analytical solution to motion estimation and differential tracking extensive experiment validate the effectiveness of adaptive metric and demonstrate the improved performance of the proposed new tracking method 
current method learn monolithic attribute predictor with the assumption that a single model is sufficient to reflect human understanding of a visual attribute however in reality human vary in how they perceive the association between a named property and image content for example two people may have slightly different internal model for what make a shoe look formal or they may disagree on which of two scene look more cluttered rather than discount these difference a noise we propose to learn user specific attribute model we adapt a generic model trained with annotation from multiple user tailoring it to satisfy user specific label furthermore we propose novel technique to infer user specific label based on transitivity and contradiction in the user s search history we demonstrate that adapted attribute improve accuracy over both existing monolithic model a well a model that learn from scratch with user specific data alone in addition we show how adapted attribute are useful to personalize image search whether with binary or relative attribute 
with recent advance in mobile computing the demand for visual localization or landmark identification on mobile device is gaining interest we advance the state of the art in this area by fusing two popular representation of street level image data facade aligned and viewpoint aligned and show that they contain complementary information that can be exploited to significantly improve the recall rate on the city scale we also improve feature detection in low contrast part of the street level data and discus how to incorporate prior on a user s position e g given by noisy gps reading or network cell which previous approach often ignore finally and maybe most importantly we present our result according to a carefully designed repeatable evaluation scheme and make publicly available a set of million image with ground truth label geotags and calibration data a well a a difficult set of cell phone query image we provide these resource a a benchmark to facilitate further research in the area 
recently active learning ha attracted a lot of attention in computer vision field a it is time and cost consuming to prepare a good set of labeled image for vision data analysis most existing active learning approach employed in computer vision adopt most uncertainty measure a instance selection criterion although most uncertainty query selection strategy are very effective in many circumstance they fail to take information in the large amount of unlabeled instance into account and are prone to querying outlier in this paper we present a novel adaptive active learning approach that combine an information density measure and a most uncertainty measure together to select critical instance to label for image classification our experiment on two essential task of computer vision object recognition and scene recognition demonstrate the efficacy of the proposed approach 
low level appearance a well a spatio temporal feature appropriately quantized and aggregated into bag of word bow descriptor have been shown to be effective in many detection and recognition task however their effcacy for complex event recognition in unconstrained video have not been systematically evaluated in this paper we use the nist trecvid multimedia event detection med open source dataset containing annotated data for high level event a the standardized test bed for evaluating the low level feature this dataset contains a large number of user generated video clip we consider different low level feature both static and dynamic using bow descriptor within an svm approach for event detection we present performance result on the med event for each of the feature a well a their combination using a number of early and late fusion strategy and discus their strength and limitation 
this paper address the data assignment problem in multi frame multi object tracking in video sequence traditional method employing maximum weight bipartite matching offer limited temporal modeling it ha recently been shown that incorporating higher order temporal constraint improves the assignment solution finding maximum weight matching with higher order constraint is however np hard and the solution proposed until now have either been greedy or rely on greedy rounding of the solution obtained from spectral technique we propose a novel algorithm to find the approximate solution to data assignment problem with higher order temporal constraint using the method of dual decomposition and the mplp message passing algorithm we compare the proposed algorithm with an implementation of and and show that proposed technique provides better solution with a bound on approximation factor for each inferred solution 
matching cost aggregation is one of the oldest and still popular method for stereo correspondence while effective and efficient cost aggregation method typically aggregate the matching cost by summing averaging over a user specified local support region this is obviously only locally optimal and the computational complexity of the full kernel implementation usually depends on the region size in this paper the cost aggregation problem is re examined and a non local solution is proposed the matching cost value are aggregated adaptively based on pixel similarity on a tree structure derived from the stereo image pair to preserve depth edge the node of this tree are all the image pixel and the edge are all the edge between the nearest neighboring pixel the similarity between any two pixel is decided by their shortest distance on the tree the proposed method is non local a every node receives support from all other node on the tree a can be expected the proposed non local solution outperforms all local cost aggregation method on the standard middlebury benchmark besides it ha great advantage in extremely low computational complexity only a total of addition subtraction operation and multiplication operation are required for each pixel at each disparity level it is very close to the complexity of unnormalized box filtering using integral image which requires addition subtraction operation unnormalized box filter is the fastest local cost aggregation method but blur across depth edge the proposed method wa tested on a macbook air laptop computer with a ghz intel core i cpu and gb memory the average runtime on the middlebury data set is about millisecond and is only about slower than unnormalized box filter a non local disparity refinement method is also proposed based on the non local cost aggregation method 
given the facial point extracted from an image of a face in an arbitrary pose the goal of facial point based head pose normalization is to obtain the corresponding facial point in a predefined pose e g frontal this involves inference of complex and high dimensional mapping due to the large number of the facial point employed and due to difference in head pose and facial expression most regression based approach for learning such mapping focus on modeling correlation only between the input i e the facial point in a non frontal pose and the output i e the facial point in the frontal pose but not within the input and the output of the model this make these model prone to error due to noise and outlier in test data often resulting in anatomically impossible facial configuration formed by their prediction to address this we propose shape constrained gaussian process sc gp regression for facial point based head pose normalization specifically a deformable face shape model is used to learn a face shape prior which is placed on both the input and the output of gp regression in order to constrain the model prediction to anatomically feasible facial configuration our extensive experiment on both synthetic and real image data show that the proposed approach generalizes well across pose and handle successfully noise and outlier in test data in addition the proposed model outperforms previously proposed approach to facial point based head pose normalization 
we propose max margin riffled independence model mmrim a new method for image tag ranking modeling the structured preference among tag the goal is to predict a ranked tag list for a given image where tag are ordered by their importance or relevance to the image content our model integrates the max margin formalism with riffled independence factorization proposed in which naturally allows for structured learning and efficient ranking experimental result on the sun attribute and label me datasets demonstrate the superior performance of the proposed model compared with baseline tag ranking method we also apply the predicted rank list of tag to several higher level computer vision application in image understanding and retrieval and demonstrate that mmrim significantly improves the accuracy of these application 
domain adaptation address the problem where data instance of a source domain have different distribution from that of a target domain which occurs frequently in many real life scenario this work focus on unsupervised domain adaptation where labeled data are only available in the source domain we propose to interpolate subspace through dictionary learning to link the source and target domain these subspace are able to capture the intrinsic domain shift and form a shared feature representation for cross domain recognition further we introduce a quantitative measure to characterize the shift between two domain which enables u to select the optimal domain to adapt to the given multiple source domain we present experiment on face recognition across pose illumination and blur variation cross dataset object recognition and report improved performance over the state of the art 
relevant and irrelevant image collected from the web e g flickr com have been employed a loosely labeled training data for image categorization and retrieval in this work we propose a new approach to learn a robust classifier for text based image retrieval tbir using relevant and irrelevant training web image in which we explicitly handle noise in the loose label of training image specifically we first partition the relevant and irrelevant training web image into cluster by treating each cluster a a bag and the image in each bag a instance we formulate this task a a multi instance learning problem with constrained positive bag in which each positive bag contains at least a portion of positive instance we present a new algorithm called mil cpb to effectively exploit such constraint on positive bag and predict the label of test instance image observing that the constraint on positive bag may not always be satisfied in our application we additionally propose a progressive scheme referred to a progressive mil cpb or pmil cpb to further improve the retrieval performance in which we iteratively partition the top ranked training web image from the current mil cpb classifier to construct more confident positive bag and then add these new bag a training data to learn the subsequent mil cpb classifier comprehensive experiment on two challenging real world web image data set demonstrate the effectiveness of our approach 
distortion in image of document such a the page of book adversely affect the performance of optical character recognition ocr system removing such distortion requires the d deformation of the document that is often measured using special and precisely calibrated hardware stereo laser range scanning or structured light in this paper we introduce a new approach that automatically reconstructs the d shape and rectifies a deformed text document from a single image we first estimate the d distortion grid in an image by exploiting the line structure and stroke statistic in text document this approach doe not rely on more noise sensitive operation such a image binarization and character segmentation the regularity in the text pattern is used to constrain the d distortion grid to be a perspective projection of a d parallelogram mesh based on this constraint we present a new shape from texture method that computes the d deformation up to a scale factor using svd unlike previous work this formulation imposes no restriction on the shape e g a developable surface the estimated shape is then used to remove both geometric distortion and photometric shading effect in the image we demonstrate our technique on document containing a variety of language font and size 
in this paper we develop a new model for recognizing human action an action is modeled a a very sparse sequence of temporally local discriminative key frame collection of partial key pose of the actor s depicting key state in the action sequence we cast the learning of key frame in a max margin discriminative framework where we treat key frame a latent variable this allows u to jointly learn a set of most discriminative key frame while also learning the local temporal context between them key frame are encoded using a spatially localizable pose let like representation with hog and bow component learned from weak annotation we rely on structured svm formulation to align our component and mine for hard negative to boost localization performance this result in a model that support spatio temporal localization and is insensitive to dropped frame or partial observation we show classification performance that is competitive with the state of the art on the benchmark ut interaction dataset and illustrate that our model outperforms prior method in an on line streaming setting 
visual tracking ha witnessed growing method in object representation which is crucial to robust tracking the dominant mechanism in object representation is using image feature encoded in a vector a observation to perform tracking without considering that an image is intrinsically a matrix or a nd order tensor thus approach following this mechanism inevitably lose a lot of useful information and therefore cannot fully exploit the spatial correlation within the d image ensemble in this paper we address an image a a nd order tensor in it original form and find a discriminative linear embedding space approximation to the original nonlinear sub manifold embedded in the tensor space based on the graph embedding framework we specially design two graph for characterizing the intrinsic local geometrical structure of the tensor space so a to retain more discriminant information when reducing the dimension along certain tensor dimension however spatial correlation within a tensor are not limited to the element along these dimension this mean that some part of the discriminant information may not be encoded in the embedding space we introduce a novel technique called semi supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information hence improving the performance of our tracker experimental result on challenging video demonstrate the effectiveness and robustness of the proposed tracker 
we address the problem of semantic segmentation classifying each pixel in an image according to the semantic class it belongs to e g dog road car most existing method train from fully supervised image where each pixel is annotated by a class label to reduce the annotation effort recently a few weakly supervised approach emerged these require only image label indicating which class are present although their performance reach a satisfactory level there is still a substantial gap between the accuracy of fully and weakly supervised method we address this gap with a novel active learning method specifically suited for this setting we model the problem a a pairwise crf and cast active learning a finding it most informative node these node induce the largest expected change in the overall crf state after revealing their true label our criterion is equivalent to maximizing an upper bound on accuracy gain experiment on two data set show that our method achieves percent of the accuracy of the corresponding fully supervised model while querying le than of the super pixel label 
most map inference algorithm for crfs optimize an energy function knowing all the potential in this paper we focus on crfs where the computational cost of instantiating the potential is order of magnitude higher than map inference this is often the case in semantic image segmentation where most potential are instantiated by slow classifier fed with costly feature we introduce active map inference to on the fly select a subset of potential to be instantiated in the energy function leaving the rest of the parameter of the potential unknown and to estimate the map labeling from such incomplete energy function result for semantic segmentation benchmark namely pascal voc and msrc show that active map inference achieves similar level of accuracy but with major efficiency gain 
we consider the problem of content based automated tag learning in particular we address semantic variation sub tag of the tag each video in the training set is assumed to be associated with a sub tag label and we treat this sub tag label a latent information a latent learning framework based on logitboost is proposed which jointly considers both the tag label and the latent sub tag label the latent sub tag information is exploited in our framework to assist the learning of our end goal i e tag prediction we use the cowatch information to initialize the learning process in experiment we show that the proposed method achieves significantly better result over baseline on a large scale testing video set which contains about million youtube video 
many computer vision system approximate target shape with rectangular bounding box this choice trade localization accuracy for efficient computation we propose twisted window search a strict generalization over rectangular window search for the globally optimal localization of a target s shape despite it generality we show that the new algorithm run in o n an asymptotic time complexity that is no greater than that of rectangular window search on an image of resolution n n we demonstrate improved result of twisted window search for localizing and tracking non rigid object with significant orientation scale and shape change twisted window search run at nearly frame per second in our matlab c implementation on image of resolution on a quad core laptop 
camera shake lead to non uniform image blur state of the art method for removing camera shake model the blur a a linear combination of homographically transformed version of the true image while this is conceptually interesting the resulting algorithm are computationally demanding in this paper we develop a forward model based on the efficient filter flow framework incorporating the particularity of camera shake and show how an efficient algorithm for blur removal can be obtained comprehensive comparison on a number of real world blurry image show that our approach is not only substantially faster but it also lead to better deblurring result 
part based model have demonstrated their merit in object detection however there is a key issue to be solved on how to integrate the inaccurate score of part detector when there are occlusion or large deformation to handle the imperfectness of part detector this paper present a probabilistic pedestrian detection framework in this framework a deformable part based model is used to obtain the score of part detector and the visibility of part are modeled a hidden variable unlike previous occlusion handling approach that assume independence among visibility probability of part or manually define rule for the visibility relationship a discriminative deep model is used in this paper for learning the visibility relationship among overlapping part at multiple layer experimental result on three public datasets caltech eth and daimler and a new cuhk occlusion dataset specially designed for the evaluation of occlusion handling approach show the effectiveness of the proposed approach 
we propose an approach for cross view action recognition by way of virtual view that connect the action descriptor extracted from one source view to those extracted from another target view each virtual view is associated with a linear transformation of the action descriptor and the sequence of transformation arising from the sequence of virtual view aim at bridging the source and target view while preserving discrimination among action category our approach is capable of operating without access to labeled action sample in the target view and without access to corresponding action instance in the two view and it also naturally incorporate and exploit corresponding instance or partial labeling in the target view when they are available the proposed approach achieves improved or competitive performance relative to existing method when instance correspondence or target label are available and it go beyond the capability of these method by providing some level of discrimination even when neither correspondence nor target label exist 
face recognition fr with a single training sample per person stspp is a very challenging problem due to the lack of information to predict the variation in the query sample sparse representation based classification ha shown interesting result in robust fr however it performance will deteriorate much for fr with stspp to address this issue in this paper we learn a sparse variation dictionary from a generic training set to improve the query sample representation by stspp instead of learning from the generic training set independently w r t the gallery set the proposed sparse variation dictionary learning svdl method is adaptive to the gallery set by jointly learning a projection to connect the generic training set with the gallery set the learnt sparse variation dictionary can be easily integrated into the framework of sparse representation based classification so that various variation in face image including illumination expression occlusion pose etc can be better handled experiment on the large scale cmu multi pie frgc and lfw database demonstrate the promising performance of svdl on fr with stspp 
visual saliency ha been an increasingly active research area in the last ten year with dozen of saliency model recently published nowadays one of the big challenge in the field is to find a way to fairly evaluate all of these model in this paper on human eye fixation we compare the ranking of state of the art saliency model using similarity metric the comparison is done on jian li s database containing several hundred of natural image based on kendall concordance coefficient it is shown that some of the metric are strongly correlated leading to a redundancy in the performance metric reported in the available benchmark on the other hand other metric provide a more diverse picture of model overall performance a a recommendation three similarity metric should be used to obtain a complete point of view of saliency model performance 
we extract heart rate and beat length from video by measuring subtle head motion caused by the newtonian reaction to the influx of blood at each beat our method track feature on the head and performs principal component analysis pca to decompose their trajectory into a set of component motion it then chooses the component that best corresponds to heartbeat based on it temporal frequency spectrum finally we analyze the motion projected to this component and identify peak of the trajectory which correspond to heartbeat when evaluated on subject our approach reported heart rate nearly identical to an electrocardiogram device additionally we were able to capture clinically relevant information about heart rate variability 
detection of line in raster image is often performed using hough transform this paper present a new parameterization of line and a modification of the hough transform pclines pclines are based on parallel coordinate a coordinate system used mostly or solely for high dimensional data visualization the pclines algorithm is described in the paper it accuracy is evaluated numerically and compared to the commonly used line detector based on the hough transform the result show that pclines outperform the existing approach in term of accuracy besides pclines are computationally extremely efficient require no floating point operation and can be easily accelerated by different hardware architecture 
despite a recent push towards large scale object recognition activity recognition remains limited to narrow domain and small vocabulary of action in this paper we tackle the challenge of recognizing and describing activity in the wild we present a solution that take a short video clip and output a brief sentence that sum up the main activity in the video such a the actor the action and it object unlike previous work our approach work on out of domain action it doe not require training video of the exact activity if it cannot find an accurate prediction for a pre trained model it find a le specific answer that is also plausible from a pragmatic standpoint we use semantic hierarchy learned from the data to help to choose an appropriate level of generalization and prior learned from web scale natural language corpus to penalize unlikely combination of actor action object we also use a web scale language model to fill in novel verb i e when the verb doe not appear in the training set we evaluate our method on a large youtube corpus and demonstrate it is able to generate short sentence description of video clip better than baseline approach 
global light transport is composed of direct and indirect component in this paper we take the first step toward analyzing light transport using high temporal resolution information via time of flight tof image the time profile at each pixel encodes complex interaction between the incident light and the scene geometry with spatially varying material property we exploit the time profile to decompose light transport into it constituent direct subsurface scattering and interreflection component we show that the time profile is well modelled using a gaussian function for the direct and interreflection component and a decaying exponential function for the subsurface scattering component we use our direct subsurface scattering and interreflection separation algorithm for four computer vision application recovering projective depth map identifying subsurface scattering object measuring parameter of analytical subsurface scattering model and performing edge detection using tof image 
classification based on image set ha recently attracted great research interest a it hold more promise than single image based classification in this paper we propose an efficient and robust algorithm for image set classification an image set is represented a a triplet a number of image sample their mean and an affine hull model the affine hull model is used to account for unseen appearance in the form of affine combination of sample image we introduce a novel between set distance called sparse approximated nearest point sanp distance unlike existing method the dissimilarity of two set is measured a the distance between their nearest point which can be sparsely approximated from the image sample of their respective set different from standard sparse modeling of a single image this novel sparse formulation for the image set enforces sparsity on the sample coefficient rather than the model coefficient and jointly optimizes the nearest point a well a their sparse approximation a convex formulation for searching the optimal sanp between two set is proposed and the accelerated proximal gradient method is adapted to efficiently solve this optimization experimental evaluation wa performed on the honda mobo and youtube datasets comparison with existing technique show that our method consistently achieves better result 
this paper present a method for learning d object template from view labeled object image the d template is defined in a joint appearance and geometry space composed of deformable planar part template placed at different d position and orientation appearance of each part template is represented by gabor filter which are hierarchically grouped into line segment and geometric shape and or tree are further used to quantize the possible geometry and appearance of part template so that learning can be done on a subsampled discrete space using information gain a a criterion the best d template can be searched through the and or tree using one bottom up pas and one top down pas experiment on a new car dataset with diverse view show that the proposed method can learn meaningful d car template and give satisfactory detection and view estimation performance experiment are also performed on a public car dataset which show comparable performance with recent method 
a novel boolean map based saliency bm model is proposed an image is characterized by a set of binary image which are generated by randomly thresholding the image s color channel based on a gestalt principle of figure ground segregation bm computes saliency map by analyzing the topological structure of boolean map bm is simple to implement and efficient to run despite it simplicity bm consistently achieves state of the art performance compared with ten leading method on five eye tracking datasets furthermore bm is also shown to be advantageous in salient object detection 
this paper address a challenging problem of regularizing arbitrary super pixel into an optimal grid structure which may significantly extend current low level vision algorithm by allowing them to use super pixel sps conveniently a using pixel for this purpose we aim at constructing maximum cohesive sp grid which is composed of real node i e sps and dummy node that are meaningless in the image with only position taking function in the grid for a given formation of image sps and proper number of dummy node we first dynamically align them into a grid based on the centroid locality of sps we then define the sp grid coherence a the sum of edge weight with sp locality and appearance encoded along all direct path connecting any two nearest neighboring real node in the grid we finally maximize the sp grid coherence via cascade dynamic programming our approach can take the regional objectness a an optional constraint to produce more semantically reliable sp grid experiment on object localization show that our approach outperforms state of the art method in term of both detection accuracy and speed we also find that with the same searching strategy and feature object localization at sp level is about time faster than pixel level with usually better detection accuracy 
in recent object scene recognition research image or large image region are often represented a disorganized bag of image feature this representation allows direct application of model of word count in text however the image feature count are likely to be constrained in different way than word count in text a a camera pan upwards from a building entrance over it first few floor and then above the penthouse to the backdrop formed by the mountain and then further up into the sky some feature count in the image drop while others rise only to drop again giving way to feature found more often at higher elevation fig the space of all possible feature count combination is constrained by the property of the larger scene a well a the size and the location of the window into it accordingly our model is based on a grid of feature count considerably larger than any of the modeled image and considerably smaller than the real estate needed to tile the image next to each other tightly each modeled image is assumed to have a representative window in the grid in which the sum of feature count mimic the distribution in the image we provide learning procedure that jointly map all image in the training set to the counting grid and estimate the appropriate local count in it experimentally we demonstrate that the resulting representation capture the space of feature count combination more accurately than the traditional model such a latent dirichlet allocation even when modeling image of different scene from the same category 
recent state of the art algorithm have achieved good performance on normal pedestrian detection task however pedestrian detection in crowded scene is still challenging due to the significant appearance variation caused by heavy occlusion and complex spatial interaction in this paper we propose a unified probabilistic framework to globally describe multiple pedestrian in crowded scene in term of appearance and spatial interaction we utilize a mixture model where every pedestrian is assumed in a special subclass and described by the sub model score of pedestrian part are used to represent appearance and quadratic kernel is used to represent relative spatial interaction for efficient inference multi pedestrian detection is modeled a a map problem and we utilize greedy algorithm to get an approximation for discriminative parameter learning we formulate it a a learning to rank problem and propose latent rank svm for learning from weakly labeled data experiment on various database validate the effectiveness of the proposed approach 
while saliency in image ha been extensively studied in recent year there is very little work on saliency of point set this is despite the fact that point set and range data are becoming ever more widespread and have myriad application in this paper we present an algorithm for detecting the salient point in unorganized d point set our algorithm is designed to cope with extremely large set which may contain ten of million of point such data is typical of urban scene which have recently become commonly available on the web no previous work ha handled such data for general data set we show that our result are competitive with those of saliency detection of surface although we do not have any connectivity information we demonstrate the utility of our algorithm in two application producing a set of the most informative viewpoint and suggesting an informative city tour given a city scan 
we present a multispectral photometric stereo method for capturing geometry of deforming surface a novel photometric calibration technique allows calibration of scene containing multiple piecewise constant chromaticity this method estimate per pixel photometric property then us a ransac based approach to estimate the dominant chromaticity in the scene a likelihood term is developed linking surface normal image intensity and photometric property which allows estimating the number of chromaticity present in a scene to be framed a a model estimation problem the bayesian information criterion is applied to automatically estimate the number of chromaticity present during calibration a two camera stereo system provides low resolution geometry allowing the likelihood term to be used in segmenting new image into region of constant chromaticity this segmentation is carried out in a markov random field framework and allows the correct photometric property to be used at each pixel to estimate a dense normal map result are shown on several challenging real world sequence demonstrating state of the art result using only two camera and three light source quantitative evaluation is provided against synthetic ground truth data 
natural image statistic indicate that we should use non convex norm for most regularization task in image processing and computer vision still they are rarely used in practice due to the challenge to optimize them recently iteratively reweighed minimization ha been proposed a a way to tackle a class of non convex function by solving a sequence of convex problem here we extend the problem class to linearly constrained optimization of a lipschitz continuous function which is the sum of a convex function and a function being concave and increasing on the non negative orthant possibly non convex and non concave on the whole space this allows to apply the algorithm to many computer vision task we show the effect of non convex regularizers on image denoising deconvolution optical flow and depth map fusion non convexity is particularly interesting in combination with total generalized variation and learned image prior efficient optimization is made possible by some important property that are shown to hold 
in this paper we examine the effect of receptive field design on classification accuracy in the commonly adopted pipeline of image classification while existing algorithm usually use manually defined spatial region for pooling we show that learning more adaptive receptive field increase performance even with a significantly smaller codebook size at the coding layer to learn the optimal pooling parameter we adopt the idea of over completeness by starting with a large number of receptive field candidate and train a classifier with structured sparsity to only use a sparse subset of all the feature an efficient algorithm based on incremental feature selection and retraining is proposed for fast learning with this method we achieve the best published performance on the cifar dataset using a much lower dimensional feature space than previous method 
a greedy based approach to learn a compact and discriminative dictionary for sparse representation is presented we propose an objective function consisting of two component entropy rate of a random walk on a graph and a discriminative term dictionary learning is achieved by finding a graph topology which maximizes the objective function by exploiting the monotonicity and submodularity property of the objective function and the matroid constraint we present a highly efficient greedy based optimization algorithm it is more than an order of magnitude faster than several recently proposed dictionary learning approach moreover the greedy algorithm give a near optimal solution with a approximation bound our approach yield dictionary having the property that feature point from the same class have very similar sparse code experimental result demonstrate that our approach outperforms several recently proposed dictionary learning technique for face action and object category recognition 
d object detection and importance regression ranking are at the core for semantically interpreting d medical image of computer aided diagnosis cad in this paper we propose effective image segmentation feature and a novel multiple instance regression method for solving the above challenge we perform supervised learning based segmentation algorithm on numerous lesion candidate a d vois volume of interest in ct image which can be true or false by assessing the statistical property in the joint space of segmentation output e g a d class specific probability map or cloud and original image appearance descriptive feature in six subgroup are derived the new feature set show excellent performance on effectively classifying ambiguous positive and negative vois for our cad system of detecting colonic polyp using ct image the proposed regression model on our segmentation derived feature behaves a a robust object polyp size importance estimator and ranking module with high reliability which is critical for automatic clinical reporting and cancer staging extensive evaluation is executed on a large clinical dataset of ct scan from medical site for validation with the best state of the art result 
we revisit the problem of matching a set of line in the d image to a set of corresponding line in the d model for the following reason a existing algorithm that treat line a infinitely long contain a flaw namely the solution found are not invariant with respect to the choice of the coordinate frame the source of this flaw is in the way line are represented we propose a frame independent representation for set of infinite line that remove the non invariance flaw b algorithm for finding the best rigid transform are nonlinear optimization that are sensitive to initialization and may result in unreliable and expensive solution we present a new recipe for initialization that exploit the d geometry of the problem and is applicable to all algorithm that perform the matching in the d scene experiment show that with this initialization all algorithm find the best transform c we present a new efficient matching algorithm that is significantly faster than existing alternative since it doe not require explicit evaluation of the cost function and it derivative 
salient object detection is not a pure low level bottom up process higher level knowledge is important even for task independent image saliency we propose a unified model to incorporate traditional low level feature with higher level guidance to detect salient object in our model an image is represented a a low rank matrix plus sparse noise in a certain feature space where the non salient region or background can be explained by the low rank matrix and the salient region are indicated by the sparse noise to ensure the validity of this model a linear transform for the feature space is introduced and need to be learned given an image it low level saliency is then extracted by identifying those sparse noise when recovering the low rank matrix furthermore higher level knowledge is fused to compose a prior map and is treated a a prior term in the objective function to improve the performance extensive experiment show that our model can comfortably achieves comparable performance to the existing method even without the help from high level knowledge the integration of top down prior further improves the performance and achieves the state of the art moreover the proposed model can be considered a a prototype framework not only for general salient object detection but also for potential task dependent saliency application 
many of contextual correlation co exist within the segmented region among image like the visual context and semantic context the appropriate integration and utilization of such context are very important to boost the performance of region tagging inspired by the recent advance of sparse reconstruction method this paper proposes an approach called graph guided sparse reconstruction for region tagging g srrt the g srrt consists of two step sparse reconstruction for testing region and tag propagation from training region to testing region in g srrt graph is conducted to flexibly model the contextual correlation among region to integrate the graph structure learned from training region into the sparse reconstruction we define a graph guided fusion g f penalty over the graph to encourage the sparsity of difference between two reconstruction coefficient which corresponds to the linked region in the graph guided by this g f penalty the highly correlated region tend to be jointly selected for the reconstruction which result in a better performance of region tagging experiment on three open benchmark image datasets demonstrate the effectiveness of the proposed algorithm 
we introduce a framework for defining a distance on the non euclidean space of linear dynamical system ldss the proposed distance is induced by the action of the group of orthogonal matrix on the space of statespace realization of ldss this distance can be efficiently computed for large scale problem hence it is suitable for application in the analysis of dynamic visual scene and other high dimensional time series based on this distance we devise a simple lds averaging algorithm which can be used for classification and clustering of time series data we test the validity a well a the performance of our group action based distance on synthetic a well a real data and provide comparison with state of the art method 
in this paper we present a method which permit the creation of user colour preference for object material and light in the scene making use of imaging spectroscopy data to do this we build upon the heterogeneous nature of the scene by imposing consistency over object material so a to allow for small compositional variation across object in the image once the consistency ha been imposed we aim at maximising the quality of the image under consideration based upon user input this provides the flexibility necessary to utilise user profile for the automatic processing of real world imagery while avoiding undesirable effect encountered when colour image are produced we provide result on real world imagery and illustrate how the method can be used to produce material specific colour based upon user input 
this paper proposes scene warping a layer based stereoscopic image resizing method using image warping the proposed method decomposes the input stereoscopic image pair into layer according to the depth and color information a quad mesh is placed onto each layer to guide the image warping for resizing the warped layer are composited by their depth order to synthesize the resized stereoscopic image we formulate an energy function to guide the warping for each layer so that the composited image avoids distortion and hole maintains good stereoscopic property and contains a many important pixel a possible in the reduced image space the proposed method offer the advantage of le discontinuous artifact le distorted object correct depth ordering and enhanced stereoscopic quality experiment show that our method compare favorably with existing method 
we present a video summarization approach that discovers the story of an egocentric video given a long input video our method selects a short chain of video sub shot depicting the essential event inspired by work in text analysis that link news article over time we define a random walk based metric of influence between sub shot that reflects how visual object contribute to the progression of event using this influence metric we define an objective for the optimal k sub hot summary whereas traditional method optimize a summary s diversity or representative ness ours explicitly account for how one sub event lead to another which critically capture event connectivity beyond simple object co occurrence a a result our summary provide a better sense of story we apply our approach to over hour of daily activity video taken from unique camera wearer and systematically evaluate it quality compared to multiple baseline with human subject 
this paper present a method for joint stereo matching and object segmentation in our approach a d scene is represented a a collection of visually distinct and spatially coherent object each object is characterized by three different aspect a color model a d plane that approximates the object s disparity distribution and a novel d connectivity property inspired by markov random field model of image segmentation we employ object level color model a a soft constraint which can aid depth estimation in powerful way in particular our method is able to recover the depth of region that are fully occluded in one input view which to our knowledge is new for stereo matching our model is formulated a an energy function that is optimized via fusion move we show high quality disparity and object segmentation result on challenging image pair a well a standard benchmark we believe our work not only demonstrates a novel synergy between the area of image segmentation and stereo matching but may also inspire new work in the domain of automatic and interactive object level scene manipulation 
in this paper we formulate saliency detection via absorbing markov chain on an image graph model we jointly consider the appearance divergence and spatial distribution of salient object and the background the virtual boundary node are chosen a the absorbing node in a markov chain and the absorbed time from each transient node to boundary absorbing node is computed the absorbed time of transient node measure it global similarity with all absorbing node and thus salient object can be consistently separated from the background when the absorbed time is used a a metric since the time from transient node to absorbing node relies on the weight on the path and their spatial distance the background region on the center of image may be salient we further exploit the equilibrium distribution in an ergodic markov chain to reduce the absorbed time in the long range smooth background region extensive experiment on four benchmark datasets demonstrate robustness and efficiency of the proposed method against the state of the art method 
scene understanding is an important yet very challenging problem in computer vision in the past few year researcher have taken advantage of the recent diffusion of depth rgb rgb d camera to help simplify the problem of inferring scene semantics however while the added d geometry is certainly useful to segment out object with different depth value it also add complication in that the d geometry is often incorrect because of noisy depth measurement and the actual d extent of the object is usually unknown because of occlusion in this paper we propose a new method that allows u to jointly refine the d reconstruction of the scene raw depth value while accurately segmenting out the object or scene element from the d reconstruction this is achieved by introducing a new model which we called voxel crf the voxel crf model is based on the idea of constructing a conditional random field over a d volume of interest which capture the semantic and d geometric relationship among different element voxels of the scene such model allows to jointly estimate a dense voxel based d reconstruction and the semantic label associated with each voxel even in presence of partial occlusion using an approximate yet efficient inference strategy we evaluated our method on the challenging nyu depth dataset version and experimental result show that our method achieves competitive accuracy in inferring scene semantics and visually appealing result in improving the quality of the d reconstruction we also demonstrate an interesting application of object removal and scene completion from rgb d image 
the most popular way to use probabilistic model in vision is first to extract some descriptor of small image patch or object part using well engineered feature and then to use statistical learning tool to model the dependency among these feature and eventual label learning probabilistic model directly on the raw pixel value ha proved to be much more difficult and is typically only used for regularizing discriminative method in this work we use one of the best pixel level generative model of natural image a gated mrf a the lowest level of a deep belief network dbn that ha several hidden layer we show that the resulting dbn is very good at coping with occlusion when predicting expression category from face image and it can produce feature that perform comparably to sift descriptor for discriminating different type of scene the generative ability of the model also make it easy to see what information is captured and what is lost at each level of representation 
this paper is concerned with the inference of marginal density based on mrf model the optimization algorithm for continuous variable are only applicable to a limited number of problem whereas those for discrete variable are versatile thus it is quite common to convert the continuous variable into discrete one for the problem that ideally should be solved in the continuous domain such a stereo matching and optical flow estimation in this paper we show a novel formulation for this continuous discrete conversion the key idea is to estimate the marginal density in the continuous domain by approximating them with mixture of rectangular density based on this formulation we derive a mean field mf algorithm and a belief propagation bp algorithm these algorithm can correctly handle the case where the variable space is discretized in a non uniform manner by intentionally using such a non uniform discretization a higher balance between computational efficiency and accuracy of marginal density estimate could be achieved we present a method for actually doing this which dynamically discretizes the variable space in a coarse to fine manner in the course of the computation experimental result show the effectiveness of our approach 
this paper is concerned with a novel problem learning temporal model using only relative information such a problem arises naturally in many application involving motion or video data our focus in this paper is on videobased surgical training in which a key task is to rate the performance of a trainee based on a video capturing his motion compared with the conventional method of relying on rating from senior surgeon an automatic approach to this problem is desirable for it potential lower cost better objectiveness and real time availability to this end we propose a novel formulation termed relative hidden markov model and develop an algorithm for obtaining a solution under this model the proposed method utilizes only a relative ranking based on an attribute of interest between pair of the input which is easier to obtain and often more consistent especially for the chosen application domain the proposed algorithm effectively learns a model from the training data so that the attribute under consideration is linked to the likelihood of the input under the learned model hence the model can be used to compare new sequence synthetic data is first used to systematically evaluate the model and the algorithm and then we experiment with real data from a surgical training system the experimental result suggest that the proposed approach provides a promising solution to the real world problem of motion skill evaluation from video 
how do you tell a blackbird from a crow there ha been great progress toward automatic method for visual recognition including fine grained visual categorization in which the class to be distinguished are very similar in a task such a bird specie recognition automatic recognition system can now exceed the performance of non expert most people are challenged to name a couple dozen bird specie let alone identify them this lead u to the question can a recognition system show human what to look for when identifying class in this case bird in the context of fine grained visual categorization we show that we can automatically determine which class are most visually similar discover what visual feature distinguish very similar class and illustrate the key feature in a way meaningful to human running these method on a dataset of bird image we can generate a visual field guide to bird which includes a tree of similarity that display the similarity relation between all specie page for each specie showing the most similar other specie and page for each pair of similar specie illustrating their difference 
automatic image categorization ha become increasingly important with the development of internet and the growth in the size of image database although the image categorization can be formulated a a typical multi class classification problem two major challenge have been raised by the real world image on one hand though using more labeled training data may improve the prediction performance obtaining the image label is a time consuming a well a biased process on the other hand more and more visual descriptor have been proposed to describe object and scene appearing in image and different feature describe different aspect of the visual characteristic therefore how to integrate heterogeneous visual feature to do the semi supervised learning is crucial for categorizing large scale image data in this paper we propose a novel approach to integrate heterogeneous feature by performing multi modal semi supervised classification on unlabeled a well a unsegmented image considering each type of feature a one modality taking advantage of the large amount of unlabeled data information our new adaptive multi modal semi supervised classification ammss algorithm learns a commonly shared class indicator matrix and the weight for different modality image feature simultaneously 
watershed cut are among the fastest segmentation algorithm and therefore well suited for interactive segmentation of very large d data set to minimize the number of user interaction seed required until the result is correct we want the computer to actively query the human for input at the most critical location in analogy to active learning these location are found by mean of suitable uncertainty measure we propose various such measure for watershed cut along with a theoretical analysis of some of their property extensive evaluation on two type of d electron microscopic volume of neural tissue show that measure which estimate the non local consequence of new user input achieve performance close to an oracle endowed with complete knowledge of the ground truth 
we analyze the computational problem of multi object tracking in video sequence we formulate the problem using a cost function that requires estimating the number of track a well a their birth and death state we show that the global solution can be obtained with a greedy algorithm that sequentially instantiates track using shortest path computation on a flow network greedy algorithm allow one to embed pre processing step such a nonmax suppression within the tracking algorithm furthermore we give a near optimal algorithm based on dynamic programming which run in time linear in the number of object and linear in the sequence length our algorithm are fast simple and scalable allowing u to process dense input data this result in state of the art performance 
the conditional random field crf is a popular tool for object based image segmentation crfs used in practice typically have edge only between adjacent image pixel to represent object relationship statistic beyond adjacent pixel prior work either represents only weak spatial information using the segmented region or encodes only global object co occurrence in this paper we propose a unified model that augments the pixel wise crfs to capture object spatial relationship to this end we use a fully connected crf which ha an edge for each pair of pixel the edge potential are defined to capture the spatial information and preserve the object boundary at the same time traditional inference method such a belief propagation and graph cut are impractical in such a case where billion of edge are defined under only one assumption that the spatial relationship among different object only depend on their relative position spatially stationary we develop an efficient inference algorithm that converges in a few second on a standard resolution image where belief propagation take more than one hour for a single iteration 
while knowledge transfer kt between object class ha been accepted a a promising route towards scalable recognition most experimental kt study are surprisingly limited in the number of object class considered to support claim of kt w r t scalability we thus advocate to evaluate kt in a large scale setting to this end we provide an extensive evaluation of three popular approach to kt on a recently proposed large scale data set the imagenet large scale visual recognition competition data set in a first setting they are directly compared to one v all classification often neglected in kt paper and in a second setting we evaluate their ability to enable zero shot learning while none of the kt method can improve over one v all classification they prove valuable for zero shot learning especially hierarchical and direct similarity based kt we also propose and describe several extension of the evaluated approach that are necessary for this large scale study 
visual object retrieval aim at retrieving from a collection of image all those in which a given query object appears it is inherently asymmetric the query object is mostly included in the database image while the converse is not necessarily true however existing approach mostly compare the image with symmetrical measure without considering the different role of query and database this paper first measure the extent of asymmetry on large scale public datasets reflecting this task considering the standard bag of word representation we then propose new asymmetrical dissimilarity accounting for the different inlier ratio associated with query and database image these asymmetrical measure depend on the query yet they are compatible with an inverted file structure without noticeably impacting search efficiency our experiment show the benefit of our approach and show that the visual object retrieval task is better treated asymmetrically in the spirit of state of the art text retrieval 
given the enormous growth in user generated video it is becoming increasingly important to be able to navigate them efficiently a these video are generally of poor quality summarization method designed for well produced video do not generalize to them to address this challenge we propose to use web image a a prior to facilitate summarization of user generated video our main intuition is that people tend to take picture of object to capture them in a maximally informative way such image could therefore be used a prior information to summarize video containing a similar set of object in this work we apply our novel insight to develop a summarization algorithm that us the web image based prior information in an unsupervised manner moreover to automatically evaluate summarization algorithm on a large scale we propose a framework that relies on multiple summary obtained through crowdsourcing we demonstrate the effectiveness of our evaluation framework by comparing it performance to that of multiple human evaluator finally we present result for our framework tested on hundred of user generated video 
many new application are enabled by combining a multi camera system with a time of flight tof camera which is able to simultaneously record intensity and depth image classical approach for self calibration of a multi camera system fail to calibrate such a system due to the very different image modality in addition the typical environment of multi camera system are man made and consist primary of only low textured object however at the same time they satisfy the manhattan world assumption we formulate the multi modal sensor network calibration a a maximum a posteriori map problem and solve it by minimizing the corresponding energy function first we estimate two separate d reconstruction of the environment one using the pan tilt unit mounted tof camera and one using the multi camera system we exploit the manhattan world assumption and estimate multiple initial calibration hypothesis by registering the three dominant orientation of plane these hypothesis are used a prior knowledge of a subsequent map estimation aiming to align edge that are parallel to these dominant direction to our knowledge this is the first self calibration approach that is able to calibrate a tof camera with a multi camera system quantitative experiment on real data demonstrate the high accuracy of our approach 
color infrared and flash image captured in different field can be employed to effectively eliminate noise and other visual artifact we propose a two image restoration framework considering input image in different field for example one noisy color image and one dark flashed near infrared image the major issue in such a framework is to handle structure divergence and find commonly usable edge and smooth transition for visually compelling image reconstruction we introduce a scale map a a competent representation to explicitly model derivative level confidence and propose new function and a numerical solver to effectively infer it following new structural observation our method is general and show a principled way for cross field restoration 
we study the task of learning to rank image given a text query a problem that is complicated by the issue of multiple sens that is the sens of interest are typically the visually distinct concept that a user wish to retrieve in this paper we propose to learn a ranking function that optimizes the ranking cost of interest and simultaneously discovers the disambiguated sens of the query that are optimal for the supervised task note that no supervised information is given about the sens experiment performed on web image and the imagenet dataset show that using our approach lead to a clear gain in performance 
this paper present a complete solution to estimating a scene s d geometry and appearance from multiple d image by using a statistical inverse ray tracing method instead of matching image feature pixel across image the inverse ray tracing approach model the image generation process directly and search for the best d geometry and surface reflectance model to explain all the observation here the image generation process is modeled through volumetric ray tracing where the occlusion visibility is exactly modeled all the constraint including ray constraint and prior knowledge about the geometry are put into the ray markov random field ray mrf formulation developed in differently from where the voxel color are estimated independently of the voxel occupancy in this work both voxel occupancy and color i e both geometry and appearance are modeled and estimated jointly in the same inversey ray tracing framework ray mrf deep belief propagation and implemented in a common message passing scheme which improves the accuracy significantly a verified by extensive experiment the complete inverse ray tracing approach can better handle difficult problem in multi view stereo than do traditional method including large camera baseline occlusion matching ambiguity color constant or slowly changing region etc without additional information and assumption such a initial surface estimate or simple background assumption a prototype system is built and tested over several challenging datasets and compared with the state of the art system which demonstrates it good performance and wide applicability 
the most popular approach to large scale image retrieval is based on the bag of visual word bov representation of image the spatial information is usually re introduced a a post processing step to re rank the retrieved image through a spatial verification like ransac since the spatial verification technique are computationally expensive they can be applied only to the top image in the initial ranking in this paper we propose an approach that can encode more spatial information into bov representation and that is efficient enough to be applied to large scale database other work pursuing the same purpose have proposed exploring the word co occurrence in the neighborhood area our approach encodes more spatial information through the geometry preserving visual phrase gvp in addition to co occurrence the gvp method also capture the local and long range spatial layout of the word our gvp based searching algorithm increase little memory usage or computational time compared to the bov method moreover we show that our approach can also be integrated to the min hash method to improve it retrieval accuracy the experiment result on oxford k and flicker m dataset show that our approach outperforms the bov method even following a ransac verification 
we present a novel and general optimisation framework for visual slam which scale for both local highly accurate reconstruction and large scale motion with long loop closure we take a two level approach that combine accurate pose point constraint in the primary region of interest with a stabilising periphery of pose pose soft constraint our algorithm automatically build a suitable connected graph of keyposes and constraint dynamically selects inner and outer window membership and optimises both simultaneously we demonstrate in extensive simulation experiment that our method approach the accuracy of offline bundle adjustment while maintaining constant time operation even in the hard case of very loopy monocular camera motion furthermore we present a set of real experiment for various type of visual sensor and motion including large scale slam with both monocular and stereo camera loopy local browsing with either monocular or rgb d camera and dense rgb d object model building 
though widely utilized for facilitating image management user provided image tag are usually incomplete and insufficient to describe the whole semantic content of corresponding image resulting in performance degradation in tag dependent application and thus necessitating effective tag completion method in this paper we propose a novel scheme denoted a lsr for automatic image tag completion via image specific and tag specific linear sparse reconstruction given an incomplete initial tagging matrix with each row representing an image and each column representing a tag lsr optimally reconstructs each image i e row and each tag i e column with remaining one under constraint of sparsity considering image image similarity image tag association and tag tag concurrence then both image specific and tag specific reconstruction value are normalized and merged for selecting missing related tag extensive experiment conducted on both benchmark dataset and web image well demonstrate the effectiveness of the proposed lsr 
this paper present a novel approach for dense reconstruction from a single view of a repetitive scene structure given an image and it detected repetition region we model the shape recovery a the dense pixel correspondence within a single image the correspondence are represented by an interval map that tell the distance of each pixel to it matched pixel within the single image in order to obtain dense repetitive structure we develop a new repetition constraint that penalizes the inconsistency between the repetition interval of the dynamically corresponding pixel pair we deploy a graph cut to balance between the high level constraint of geometric repetition and the low level constraint of photometric consistency and spatial smoothness we demonstrate the accurate reconstruction of dense d repetitive structure through a variety of experiment which prove the robustness of our approach to outlier such a structure variation illumination change and occlusion 
owning to it clinical accessibility t weighted mri ha been extensively studied for the prediction of mild cognitive impairment mci and alzheimer s disease ad the tissue volume of gm wm and csf are the most commonly used measure for mci and ad prediction we note that disease induced structural change may not happen at isolated spot but in several inter related region therefore in this paper we propose to directly extract the inter region connectivity based feature for mci prediction this involves constructing a brain network for each subject with each node representing an roi and each edge representing regional interaction this network is also built hierarchically to improve the robustness of classification compared with conventional method our approach produce a significant larger pool of feature which if improperly dealt with will result in intractability when used for classifier training therefore based on the characteristic of the network feature we employ partial least square analysis to efficiently reduce the feature dimensionality to a manageable level while at the same time preserving discriminative information a much a possible our experiment demonstrates that without requiring any new information in addition to t weighted image the prediction accuracy of mci is statistically improved 
human eye can recognize person identity based on some small salient region however such valuable salient information is often hidden when computing similarity of image with existing approach moreover many existing approach learn discriminative feature and handle drastic viewpoint change in a supervised way and require labeling new training data for a different pair of camera view in this paper we propose a novel perspective for person re identification based on unsupervised salience learning distinctive feature are extracted without requiring identity label in the training procedure first we apply adjacency constrained patch matching to build dense correspondence between image pair which show effectiveness in handling misalignment caused by large viewpoint and pose variation second we learn human salience in an unsupervised manner to improve the performance of person re identification human salience is incorporated in patch matching to find reliable and discriminative matched patch the effectiveness of our approach is validated on the widely used viper dataset and ethz dataset 
we address the problem of person detection and tracking in crowded video scene while the detection of individual object ha been improved significantly over the recent year crowd scene remain particularly challenging for the detection and tracking task due to heavy occlusion high person density and significant variation in people s appearance to address these challenge we propose to leverage information on the global structure of the scene and to resolve all detection jointly in particular we explore constraint imposed by the crowd density and formulate person detection a the optimization of a joint energy function combining crowd density estimation and the localization of individual people we demonstrate how the optimization of such an energy function significantly improves person detection and tracking in crowd we validate our approach on a challenging video dataset of crowded scene 
this paper present a novel approach to utilizing high level knowledge for the problem of scene recognition in an active vision framework which we call active scene recognition in traditional approach high level knowledge is used in the post processing to combine the output of the object detector to achieve better classification performance in contrast the proposed approach employ high level knowledge actively by implementing an interaction between a reasoning module and a sensory module figure following this paradigm we implemented an active scene recognizer and evaluated it with a dataset of scene and object we also extended it to the analysis of dynamic scene for activity recognition with attribute experiment demonstrate the effectiveness of the active paradigm in introducing attention and additional constraint into the sensing process 
a great variety of computer vision task such a rigid nonrigid structure from motion and photometric stereo can be unified into the problem of approximating a low rank data matrix in the presence of missing data and outlier to improve robustness the l norm measurement ha long been recommended unfortunately existing method usually fail to minimize the l based nonconvex objective function sufficiently in this work we propose to add a convex trace norm regularization term to improve convergence without introducing too much heterogenous information we also customize a scalable first order optimization algorithm to solve the regularized formulation on the basis of the augmented lagrange multiplier alm method extensive experimental result verify that our regularized formulation is reasonable and the solving algorithm is very efficient insensitive to initialization and robust to high percentage of missing data and or outlier 
domain invariant representation are key to addressing the domain shift problem where the training and test example follow different distribution existing technique that have attempted to match the distribution of the source and target domain typically compare these distribution in the original feature space this space however may not be directly suitable for such a comparison since some of the feature may have been distorted by the domain shift or may be domain specific in this paper we introduce a domain invariant projection approach an unsupervised domain adaptation method that overcomes this issue by extracting the information that is invariant across the source and target domain more specifically we learn a projection of the data to a low dimensional latent space where the distance between the empirical distribution of the source and target example is minimized we demonstrate the effectiveness of our approach on the task of visual object recognition and show that it outperforms state of the art method on a standard domain adaptation benchmark dataset 
in this paper we consider the problem of recovering the free space of an indoor scene from it single image we show that exploiting the box like geometric structure of furniture and constraint provided by the scene allows u to recover the extent of major furniture object in d our boxy detector localizes box shaped object oriented parallel to the scene across different scale and object type and thus block out the occupied space in the scene to localize the object more accurately in d we introduce a set of specially designed feature that capture the floor contact point of the object image based metric are not very indicative of performance in d we make the first attempt to evaluate single view based occupancy estimate for d error and propose several task driven performance measure towards it on our dataset of indoor image marked with full d geometry of the scene we show that a our detector work well using image based metric b our refinement method produce significant improvement in localization in d and c if one evaluates using d metric our method offer major improvement over other single view based scene geometry estimation method 
finding minimal cut on graph with a grid like structure ha become a core task for solving many computer vision and graphic related problem however computation speed and memory consumption oftentimes limit the effective use in application requiring high resolution grid or interactive response in particular memory bandwidth represents one of the major bottleneck even in today s most efficient implementation we propose a compact data structure with cache efficient memory layout for the representation of graph instance that are based on regular n d grid with topologically identical neighborhood system for this common class of graph our data structure allows for to time higher grid resolution and a to fold speedup compared to existing approach our design is agnostic to the underlying algorithm and hence orthogonal to other optimization such a parallel and hierarchical processing we evaluate the performance gain on a variety of typical problem including d d segmentation colorization and stereo all experiment show an unconditional improvement in term of speed and memory consumption with graceful performance degradation for graph with increasing topological irregularity 
occlusion present a challenge for detecting object in real world application to address this issue this paper model object occlusion with an and or structure which i represents occlusion at semantic part level and ii capture the regularity of different occlusion configuration i e the different combination of object part visibility this paper focus on car detection on street since annotating part occlusion on real image is time consuming and error prone we propose to learn the the and or structure automatically using synthetic image of cad model placed at different relative position the model parameter are learned from real image under the latent structural svm lssvm framework in inference an efficient dynamic programming dp algorithm is utilized in experiment we test our method on both car detection and car view estimation experimental result show that i our cad simulation strategy is capable of generating occlusion pattern for real scenario ii the proposed and or structure model is effective for modeling occlusion which outperforms the deformable part based model dpm dpm voc in car detection on both our self collected street parking dataset and the pascal voc car dataset pascal voc iii the learned model is on par with the state of the art method on car view estimation tested on two public datasets 
we propose a novel approach for dense non rigid d surface registration which brings together riemannian geometry and graphical model to this end we first introduce a generic deformation model called canonical distortion coefficient cdc by characterizing the deformation of every point on a surface using the distortion along it two principle direction this model subsumes the deformation group commonly used in surface registration such a isometry and conformality and is able to handle more complex deformation we also derive it discrete counterpart which can be computed very efficiently in a closed form based on these we introduce a higher order markov random field mrf model which seamlessly integrates our deformation model and a geometry texture similarity metric then we jointly establish the optimal correspondence for all the point via maximum a posteriori map inference moreover we develop a parallel optimization algorithm to efficiently perform the inference for the proposed higher order mrf model the resulting registration algorithm outperforms state of the art method in both dense non rigid d surface registration and tracking 
we propose a novel algorithmic solution for estimating a three dimensional model of an object observed in a single image based on a minimal user input the algorithm interactively determines the object silhouette and subsequently computes a silhouette consistent d model which is precisely the globally minimal surface with user specified volume in contrast to a recently published approach to single view reconstruction the proposed algorithm doe not constrain the resolution in the depth direction it assures the global optimum and is faster by about an order of magnitude experiment demonstrate that plausible highresolution d model can be generated in fraction of a second and compare favorably with other method 
without specialized sensor technology or custom multi chip camera high dynamic range imaging typically involves time sequential capture of multiple photograph the obvious downside to this approach is that it cannot easily be applied to image with moving object especially if the motion are complex in this paper we take a novel view of hdr capture which is based on a computational photography approach we propose to first optically encode both the low dynamic range portion of the scene and highlight information into a low dynamic range image that can be captured with a conventional image sensor this step is achieved using a cross screen or star filter second we decode in software both the low dynamic range image and the highlight information lastly these two portion can be combined to form an image of a higher dynamic range than the regular sensor dynamic range 
this paper extends to surface the multi scale approach of edge detection on image the common practice for detecting curve on surface requires the user to first select the scale of the feature apply an appropriate smoothing and detect the edge on the smoothed surface this approach suffers from two drawback first it relies on a hidden assumption that all the feature on the surface are of the same scale second manual user intervention is required in this paper we propose a general framework for automatically detecting the optimal scale for each point on the surface we smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface our multi scale algorithm solves the two disadvantage of the single scale approach mentioned above we demonstrate how to realize our approach on two commonly used special case ridge valley and relief edge in each case the optimal scale is found in accordance with the mathematical definition of the curve 
d ct play an important role in lung cancer treatment however due to the inherent high dose exposure associated with ct dense sampling along superior inferior direction is often not practical a a result artifact such a lung vessel discontinuity and partial volume are typical in d ct image and might mislead dose administration in radiation therapy in this paper we present a novel patch based technique for super resolution enhancement of the d ct image along the superior inferior direction our working premise is that the anatomical information that is missing at one particular phase can be recovered from other phase based on this assumption we employ a patch based mechanism for guided reconstruction of super resolution axial slice specifically to reconstruct each targeted super resolution slice for a ct image at a particular phase we agglomerate a dictionary of patch from image of all other phase in the d ct sequence then we perform a sparse combination of the patch in this dictionary to reconstruct detail of a super resolution patch under constraint of similarity to the corresponding patch in the neighboring slice by iterating this procedure over all possible patch location a superresolution d ct image sequence with enhanced anatomical detail can be eventually reconstructed our method wa extensively evaluated using a public dataset in all experiment our method outperforms the conventional linear and cubic spline interpolation method in term of preserving image detail and suppressing misleading artifact 
we propose a novel nonlinear probabilistic and variational method for adding shape information to level set based segmentation and tracking unlike previous work we represent shape with elliptic fourier descriptor and learn their lower dimensional latent space using gaussian process latent variable model segmentation is done by a nonlinear minimisation of an image driven energy function in the learned latent space we combine it with a d pose recovery stage yielding a single one shot optimisation of both shape and pose we demonstrate the performance of our method both qualitatively and quantitatively with multiple image video sequence and latent space capturing both shape kinematics and object class variance 
colorization refers to the process of adding color to black and white image or video this paper extends the term to handle surface in three dimension this is important for application in which the color of an object need to be restored and no relevant image exists for texturing it we focus on surface with pattern and propose a novel algorithm for adding color to these surface the user need only to scribble a few color stroke on one instance of each pattern and the system proceeds to automatically colorize the whole surface for this scheme to work we address not only the problem of colorization but also the problem of pattern detection on surface 
this paper address the problem of learning similarity preserving binary code for efficient retrieval in large scale image collection we propose a simple and efficient alternating minimization scheme for finding a rotation of zero centered data so a to minimize the quantization error of mapping this data to the vertex of a zero centered binary hypercube this method dubbed iterative quantization itq ha connection to multi class spectral clustering and to the orthogonal procrustes problem and it can be used both with unsupervised data embeddings such a pca and supervised embeddings such a canonical correlation analysis cca our experiment show that the resulting binary coding scheme decisively outperform several other state of the art method 
low rank model have been widely used for the representation of shape appearance or motion in computer vision problem traditional approach to fit low rank model make use of an explicit bilinear factorization these approach benefit from fast numerical method for optimization and easy kernelization however they suffer from serious local minimum problem depending on the loss function and the amount type of missing data recently these low rank model have alternatively been formulated a convex problem using the nuclear norm regularizer unlike factorization method their numerical solver are slow and it is unclear how to kernelize them or to impose a rank a priori this paper proposes a unified approach to bilinear factorization and nuclear norm regularization that inherits the benefit of both we analyze the condition under which these approach are equivalent moreover based on this analysis we propose a new optimization algorithm and a rank continuation strategy that outperform state of the art approach for robust pca structure from motion and photometric stereo with outlier and missing data 
a new family of boosting algorithm denoted taylor boost is proposed it support any combination of loss function and first or second order optimization and includes classical algorithm such a adaboost gradient boost or logitboost a special case it restriction to the set of canonical loss make it possible to have boosting algorithm with explicit margin control a new large family of loss with this property based on the set of cumulative distribution of zero mean random variable is then proposed a novel loss function in this family the laplace loss is finally derived the combination of this loss and second order taylorboost produce a boosting algorithm with explicit margin control 
we propose a novel and an efficient method for reconstructing the d arrangement of line extracted from a single image using vanishing point orthogonal structure and an optimization procedure that considers all plausible connectivity constraint between line line detection identifies a large number of salient line that intersect or nearly intersect in an image but relatively a few of these apparent junction correspond to real intersection in the d scene we use linear programming lp to identify a minimal set of least violated connectivity constraint that are sufficient to unambiguously reconstruct the d line in contrast to prior solution that primarily focused on well behaved synthetic line drawing with severely restricting assumption we develop an algorithm that can work on real image the algorithm produce line reconstruction by identifying correct connectivity constraint in york urban database with a total computation time of second per image 
dictionary learning is a challenging theme in computer vision the basic goal is to learn a sparse representation from an overcomplete basis set most existing approach employ a convex relaxation scheme to tackle this challenge due to the strong ability of convexity in computation and theoretical analysis in this paper we propose a non convex online approach for dictionary learning to achieve the sparseness our approach treat a so called minimax concave mc penalty a a nonconvex relaxation of the penalty this treatment expects to obtain a more robust and sparse representation than existing convex approach in addition we employ an online algorithm to adaptively learn the dictionary which make the non convex formulation computationally feasible experimental result on the sparseness comparison and the application in image denoising and image inpainting demonstrate that our approach is more effective and flexible 
many cue have been proposed for contour detection or image segmentation these include low level image gradient to high level information such a the identity of the object in the scene or d depth understanding while state of the art approach have been incorporating more cue the relative importance of the cue is unclear in this paper we examine the relative importance of low midand high level cue to gain a better understanding of their role in detecting object contour in an image to accomplish this task we conduct numerous human study and compare their performance to several popular segmentation and contour detection machine approach our finding suggest that the current state of the art contour detection algorithm perform a well a human using low level cue we also find evidence that the recognition of object but not occlusion information lead to improved human performance moreover when object are recognized by human their contour detection performance increase over current machine algorithm finally mid level cue appear to offer a larger performance boost than high level cue such a recognition 
existing scene understanding datasets contain only a limited set of view of a place and they lack representation of complete d space in this paper we introduce sun d a large scale rgb d video database with camera pose and object label capturing the full d extent of many place the task that go into constructing such a dataset are difficult in isolation hand labeling video is painstaking and structure from motion sfm is unreliable for large space but if we combine them together we make the dataset construction task much easier first we introduce an intuitive labeling tool that us a partial reconstruction to propagate label from one frame to another then we use the object label to fix error in the reconstruction for this we introduce a generalization of bundle adjustment that incorporates object to object correspondence this algorithm work by constraining point for the same object from different frame to lie inside a fixed size bounding box parameterized by it rotation and translation the sun d database the source code for the generalized bundle adjustment and the web based d annotation tool are all available at http sun d c princeton edu 
multi view stereo method reconstruct d geometry from image well for sufficiently textured scene but often fail to recover high frequency surface detail particularly for smoothly shaded surface on the other hand shape from shading method can recover fine detail from shading variation unfortunately it is non trivial to apply shape from shading alone to multi view data and most shading based estimation method only succeed under very restricted or controlled illumination we present a new algorithm that combine multi view stereo and shading based refinement for high quality reconstruction of d geometry model from image taken under constant but otherwise arbitrary illumination we have tested our algorithm on several scene that were captured under several general and unknown lighting condition and we show that our final reconstruction rival laser range scan 
we present a general technique for improving space time reconstruction of deforming surface which are captured in an video based reconstruction scenario under uniform illumination our approach simultaneously improves both the acquired shape a well a the tracked motion of the deforming surface the method is based on factoring out surface shading computed by a fast approximation to global illumination called ambient occlusion this allows u to improve the performance of optical flow tracking that mainly relies on constancy of image feature such a intensity while cancelling the local shading we also optimize the surface shape to minimize the residual between the ambient occlusion of the d geometry and that of the image yielding more accurate surface detail in the reconstruction our enhancement is independent of the actual space time reconstruction algorithm we experimentally measure the quantitative improvement produced by our algorithm using a synthetic example of deforming skin where ground truth shape and motion is available we further demonstrate our enhancement on a real world sequence of human face reconstruction 
facial feature tracking is an active area in computer vision due to it relevance to many application it is a nontrivial task since face may have varying facial expression pose or occlusion in this paper we address this problem by proposing a face shape prior model that is constructed based on the restricted boltzmann machine rbm and their variant specifically we first construct a model based on deep belief network to capture the face shape variation due to varying facial expression for near frontal view to handle pose variation the frontal face shape prior model is incorporated into a way rbm model that could capture the relationship between frontal face shape and non frontal face shape finally we introduce method to systematically combine the face shape prior model with image measurement of facial feature point experiment on benchmark database show that with the proposed method facial feature point can be tracked robustly and accurately even if face have significant facial expression and pose 
recovering a deformable surface s d shape from a single view registered to a d template requires one to provide additional constraint a recent approach ha been to constrain the surface to deform quasi isometrically this is applicable to surface of material such a paper and cloth current closed form solution solve a convex approximation of the original problem whereby the surface s depth is maximized under the isometry constraint this is known a the maximum depth heuristic no such convex approximation ha yet been proposed for the conformal case we give a unified problem formulation a a system of pdes for developable isometric and conformal surface that we solve analytically this ha important consequence first it give the first analytical algorithm to solve this type of reconstruction problem second it give the first algorithm to solve for the exact constraint third it allows u to study the well posedness of this type of reconstruction we establish that isometric surface can be reconstructed unambiguously and that conformal surface can be reconstructed up to a few discrete ambiguity and a global scale in the latter case the candidate solution surface are obtained analytically experimental result on simulated and real data show that our method generally perform a well a or outperform state of the art approach in term of reconstruction accuracy 
this paper present an algorithm that automatically corrects the distortion caused by multipath interference mpi in depth measurement obtained with time of flight camera tof camera a radiometric model that explains under some mild simplification the working principle of a tof camera including a model for mpi is proposed using this model we demonstrate that all the information needed for compensating the influence of mpi on the scene captured by the camera is self contained in the measurement depth and amplitude of infrared signal we propose an iterative optimization method that based on the measurement contaminated with mpi give depth correction for each pixel result are shown in artificially generated time of flight scene using the radiometric model in addition the system ha been validated in real scene using a commercial tof camera providing good result 
handling intra personal variation is a major challenge in face recognition it is difficult how to appropriately measure the similarity between human face under significantly different setting e g pose illumination and expression in this paper we propose a new model called associate predict ap model to address this issue the associate predict model is built on an extra generic identity data set in which each identity contains multiple image with large intra personal variation when considering two face under significantly different setting e g non frontal and frontal we first associate one input face with alike identity from the generic identity date set using the associated face we generatively predict the appearance of one input face under the setting of another input face or discriminatively predict the likelihood whether two input face are from the same person or not we call the two proposed prediction method a appearance prediction and likelihood prediction by leveraging an extra data set memory and the associate predict model the intra personal variation can be effectively handled to improve the generalization ability of our model we further add a switching mechanism we directly compare the appearance of two face if they have close intra personal setting otherwise we use the associate predict model for the recognition experiment on two public face benchmark multi pie and lfw demonstrated that our final model can substantially improve the performance of most existing face recognition method 
attribute were recently shown to give excellent result for category recognition in this paper we demonstrate their performance in the context of image retrieval first we show that retrieving image of particular object based on attribute vector give result comparable to the state of the art second we demonstrate that combining attribute and fisher vector improves performance for retrieval of particular object a well a category third we implement an efficient coding technique for compressing the combined descriptor to very small code experimental result on the holiday dataset show that our approach significantly outperforms the state of the art even for a very compact representation of byte per image retrieving category image is evaluated on the web query dataset we show that attribute feature combined with fisher vector improve the performance and that combined image feature can supplement text feature 
tracking low resolution lr target is a practical yet quite challenging problem in real application the loss of discriminative detail in the visual appearance of the l r target confronts most existing visual tracking method although the resolution of the lr video input may be enhanced by super resolution sr technique the large computational cost for high quality sr doe not make it an attractive option this paper present a novel solution to track lr target without performing explicit sr this new approach is based on discriminative metric preservation that preserve the structure in the high resolution feature space for lr matching in addition we integrate metric preservation with differential tracking to derive a closed form solution to motion estimation for lr video extensive experiment have demonstrated the effectiveness and efficiency of the proposed approach 
this paper extends the classical warping based optical flow method to achieve accurate flow in the presence of spatially varying motion blur our idea is to parameterize the appearance of each frame a a function of both the pixel motion and the motion induced blur we search for the flow that best match two consecutive frame which amount to finding the derivative of a blurred frame with respect to both the motion and the blur where the blur itself is a function of the motion we propose an efficient technique to calculate the derivative using prefiltering our technique avoids performing spatially varying filtering which can be computationally expensive during the optimization iteration in the end our derivative calculation technique can be easily incorporated with classical flow code to handle video with non uniform motion blur with little performance penalty our method is evaluated on both synthetic and real video and outperforms conventional flow method in the presence of motion blur 
we present a novel quadratic program qp formulation for robust multi model fitting of geometric structure in vision data our objective function enforces both the fidelity of a model to the data and the similarity between it associated inliers departing from most previous optimization based approach the outcome of our method is a ranking of a given set of putative model instead of a pre specified number of good candidate or an attempt to decide the right number of model this is particularly useful when the number of structure in the data is a priori unascertainable due to unknown intent and purpose another key advantage of our approach is that it operates in a unified optimization framework and the standard qp form of our problem formulation permit globally convergent optimization technique we tested our method on several geometric multi model fitting problem on both synthetic and real data experiment show that our method consistently achieves state of the art result 
we present a method for fusing two acquisition mode d photograph and d lidar scan for depth layer decomposition of urban facade the two mode have complementary characteristic point cloud scan are coherent and inherently d but are often sparse noisy and incomplete photograph on the other hand are of high resolution easy to acquire and dense but view dependent and inherently d lacking critical depth information in this paper we use photograph to enhance the acquired lidar data our key observation is that with an initial registration of the d and d datasets we can decompose the input photograph into rectified depth layer we decompose the input photograph into rectangular planar fragment and diffuse depth information from the corresponding d scan onto the fragment by solving a multi label assignment problem our layer decomposition enables accurate repetition detection in each planar layer using which we propagate geometry remove outlier and enhance the d scan finally the algorithm produce an enhanced layered textured model we evaluate our algorithm on complex multi planar building facade where direct autocorrelation method for repetition detection fail we demonstrate how d photograph help improve the d scan by exploiting data redundancy and transferring high level structural information to plausibly complete large missing region 
a manhattan world mw is composed of planar surface and parallel line aligned with three mutually orthogonal principal ax traditional mw understanding algorithm rely on geometry prior such a the vanishing point and reference ground plane for grouping coplanar structure in this paper we present a novel single image mw reconstruction algorithm from the perspective of non pinhole camera we show that by acquiring the mw using an xslit camera we can instantly resolve co planarity ambiguity specifically we prove that parallel d line map to d curve in an xslit image and they converge at an xslit vanishing point xvp in addition if the line are coplanar their curved image will intersect at a second common pixel that we call coplanar common point ccp ccp is a unique image feature in xslit camera that doe not exist in pinhole we present a comprehensive theory to analyze xvps and ccps in a mw scene and study how to recover d geometry in a complex mw scene from xvps and ccps finally we build a prototype xslit camera by using two layer of cylindrical lens experimental result on both synthetic and real data show that our new xslit camera based solution provides an effective and reliable solution for mw understanding 
in this paper we propose the first effective automated genetic algorithm ga based jigsaw puzzle solver we introduce a novel procedure of merging two parent solution to an improved child solution by detecting extracting and combining correctly assembled puzzle segment the solver proposed exhibit state of the art performance solving previously attempted puzzle faster and far more accurately and also puzzle of size never before attempted other contribution include the creation of a benchmark of large image previously unavailable we share the data set and all of our result for future testing and comparative evaluation of jigsaw puzzle solver 
real time unusual event detection in video stream ha been a difficult challenge due to the lack of sufficient training information volatility of the definition for both normality and abnormality time constraint and statistical limitation of the fitness of any parametric model we propose a fully unsupervised dynamic sparse coding approach for detecting unusual event in video based on online sparse re constructibility of query signal from an atomically learned event dictionary which form a sparse coding base based on an intuition that usual event in a video are more likely to be reconstructible from an event dictionary whereas unusual event are not our algorithm employ a principled convex optimization formulation that allows both a sparse reconstruction code and an online dictionary to be jointly inferred and updated our algorithm is completely un supervised making no prior assumption of what unusual event may look like and the setting of the camera the fact that the base dictionary is updated in an online fashion a the algorithm observes more data avoids any issue with concept drift experimental result on hour of real world surveillance video and several youtube video show that the proposed algorithm could reliably locate the unusual event in the video sequence outperforming the current state of the art method 
we propose a novel mode of feedback for image search where a user describes which property of exemplar image should be adjusted in order to more closely match his her mental model of the image s sought for example perusing image result for a query black shoe the user might state show me shoe image like these but sportier offline our approach first learns a set of ranking function each of which predicts the relative strength of a nameable attribute in an image sportiness furriness etc at query time the system present an initial set of reference image and the user selects among them to provide relative attribute feedback using the resulting constraint in the multi dimensional attribute space our method update it relevance function and re rank the pool of image this procedure iterates using the accumulated constraint until the top ranked image are acceptably close to the user s envisioned target in this way our approach allows a user to efficiently whittle away irrelevant portion of the visual feature space using semantic language to precisely communicate her preference to the system we demonstrate the technique for refining image search for people product and scene and show it outperforms traditional binary relevance feedback in term of search speed and accuracy 
the vast majority of transfer learning method proposed in the visual recognition domain over the last year address the problem of object category detection assuming a strong control over the prior from which transfer is done this is a strict condition a it concretely limit the use of this type of approach in several setting for instance it doe not allow in general to use off the shelf model a prior moreover the lack of a multiclass formulation for most of the existing transfer learning algorithm prevents using them for object categorization problem where their use might be beneficial especially when the number of category grows and it becomes harder to get enough annotated data for training standard learning method this paper present a multiclass transfer learning algorithm that allows to take advantage of prior built over different feature and with different learning method than the one used for learning the new task we use the prior a expert and transfer their output to the new incoming sample a additional information we cast the learning problem within the multi kernel learning framework the resulting formulation solves efficiently a joint optimization problem that determines from where and how much to transfer with a principled multiclass formulation extensive experiment illustrate the value of this approach 
we propose a novel background subtraction algorithm for the video captured by a moving camera in our technique foreground and background appearance model in each frame are constructed and propagated sequentially by bayesian filtering we estimate the posterior of appearance which is computed by the product of the image likelihood in the current frame and the prior appearance propagated from the previous frame the motion which transfer the previous appearance model to the current frame is estimated by nonparametric belief propagation the initial motion field is obtained by optical flow and noisy and incomplete motion are corrected effectively through the inference procedure our framework is represented by a graphical model where the sequential inference of motion and appearance is performed by the combination of belief propagation and bayesian filtering we compare our algorithm with the existing state of the art technique and evaluate it performance quantitatively and qualitatively in several challenging video 
we propose a correlation based approach to parametric object alignment particularly suitable for face analysis application which require efficiency and robustness against occlusion and illumination change our algorithm register two image by iteratively maximizing their correlation coefficient using gradient ascent we compute this correlation coefficient from complex gradient which capture the orientation of image structure rather than pixel intensity the maximization of this gradient correlation coefficient result in an algorithm which is a computationally efficient a l norm based algorithm can be extended within the inverse compositional framework without the need for hessian re computation and is robust to outlier to the best of our knowledge no other algorithm ha been proposed so far having all three feature we show the robustness of our algorithm for the problem of face alignment in the presence of occlusion and non uniform illumination change the code that reproduces the result of our paper can be found at http ibug doc ic ac uk resource 
contemporary life bombard u with many new image of face every day which pose non trivial constraint on human memory the vast majority of face photograph are intended to be remembered either because of personal relevance commercial interest or because the picture were deliberately designed to be memorable can we make a portrait more memorable or more forgettable automatically here we provide a method to modify the memorability of individual face photograph while keeping the identity and other facial trait e g age attractiveness and emotional magnitude of the individual fixed we show that face photograph manipulated to be more memorable or more forgettable are indeed more often remembered or forgotten in a crowd sourcing experiment with an accuracy of quantifying and modifying the memorability of a face lends itself to many useful application in computer vision and graphic such a mnemonic aid for learning photo editing application for social network and tool for designing memorable advertisement 
we present a model for intrinsic decomposition of rgb d image our approach analyzes a single rgb d image and estimate albedo and shading field that explain the input to disambiguate the problem our model estimate a number of component that jointly account for the reconstructed shading by decomposing the shading field we can build in assumption about image formation that help distinguish reflectance variation from shading these assumption are expressed a simple nonlocal regularizers we evaluate the model on real world image and on a challenging synthetic dataset the experimental result demonstrate that the presented approach outperforms prior model for intrinsic decomposition of rgb d image 
we propose a novel method for computing a geometrically consistent and spatially dense matching between two d shape rather than mapping point to point we match infinitesimal surface patch while preserving the geometric structure in this spirit we consider matchings a diffeomorphisms between the object surface which are by definition geometrically consistent based on the observation that such diffeomorphisms can be represented a closed and continuous surface in the product space of the two shape we are led to a minimal surface problem in this product space the proposed discrete formulation describes the search space with linear constraint computationally our approach lead to a binary linear program whose relaxed version can be solved efficiently in a globally optimal manner a cost function for matching we consider a thin shell energy measuring the physical energy necessary to deform one shape into the other experimental result demonstrate that the proposed lp relaxation allows to compute highquality matchings which reliably put into correspondence articulated d shape moreover a quantitative evaluation show improvement over existing work 
despite the fact that temporal coherence is undeniably one of the key aspect when processing video data this concept ha hardly been exploited in recent optical flow method in this paper we will present a novel parametrization for multi frame optical flow computation that naturally enables u to embed the assumption of a temporally coherent spatial flow structure a well a the assumption that the optical flow is smooth along motion trajectory while the first assumption is realized by expanding spatial regularization over multiple frame the second assumption is imposed by two novel firstand second order trajectorial smoothness term with respect to the latter we investigate an adaptive decision scheme that make a local per pixel or global per sequence selection of the most appropriate model possible experiment show the clear superiority of our approach when compared to existing strategy for imposing temporal coherence moreover we demonstrate the state of the art performance of our method by achieving top result at the widely used middlebury benchmark 
eye movement study have confirmed that overt attention is highly biased towards face and text region in image in this paper we explore a novel problem of predicting face and text region in image using eye tracking data from multiple subject the problem is challenging a we aim to predict the semantics face text background only from eye tracking data without utilizing any image information the proposed algorithm spatially cluster eye tracking data obtained in an image into different coherent group and subsequently model the likelihood of the cluster containing face and text using a fully connected markov random field mrf given the eye tracking data from a test image it predicts potential face head human dog and cat and text location reliably furthermore the approach can be used to select region of interest for further analysis by object detector for face and text the hybrid eye position object detector approach achieves better detection performance and reduced computation time compared to using only the object detection algorithm we also present a new eye tracking dataset on image selected from icdar street view flickr and oxford iiit pet dataset from subject 
the serious performance decline with decreasing resolution is the major bottleneck for current pedestrian detection technique in this paper we take pedestrian detection in different resolution a different but related problem and propose a multi task model to jointly consider their commonness and difference the model contains resolution aware transformation to map pedestrian in different resolution to a common space where a shared detector is constructed to distinguish pedestrian from background for model learning we present a coordinate descent procedure to learn the resolution aware transformation and deformable part model dpm based detector iteratively in traffic scene there are many false positive located around vehicle therefore we further build a context model to suppress them according to the pedestrian vehicle relationship the context model can be learned automatically even when the vehicle annotation are not available our method reduces the mean miss rate to for pedestrian taller than pixel on the caltech pedestrian benchmark which noticeably outperforms previous state of the art 
object vary in their visual complexity yet existing discovery method perform batch clustering paying equal attention to all instance simultaneously regardless of the strength of their appearance or context cue we propose a self paced approach that instead focus on the easiest instance first and progressively expands it repertoire to include more complex object easier region are defined a those with both high likelihood of generic objectness and high familiarity of surrounding object at each cycle of the discovery process we re estimate the easiness of each subwindow in the pool of unlabeled image and then retrieve a single prominent cluster from among the easiest instance critically a the system gradually accumulates model each new more difficult discovery benefit from the context provided by earlier discovery our experiment demonstrate the clear advantage of self paced discovery relative to conventional batch approach including both more accurate summarization a well a stronger predictive model for novel data 
pedestrian detection is a problem of considerable practical interest adding to the list of successful application of deep learning method to vision we report state of the art and competitive result on all major pedestrian datasets with a convolutional network model the model us a few new twist such a multi stage feature connection that skip layer to integrate global shape information with local distinctive motif information and an unsupervised method based on convolutional sparse coding to pre train the filter at each stage 
inverse problem are abundant in vision a common way to deal with their inherent ill posedness is reformulating them within the framework of the calculus of variation this always lead to partial differential equation a condition of local optimality in this paper we propose solving such equation numerically by isogeometric analysis a special kind of finite element method we will expose it main advantage including superior computational performance a natural ability to facilitate multi scale reconstruction and a high degree of compatibility with the spline geometry encountered in modern computer aided design system to animate these fairly general argument their impact on the well known depth from gradient problem is discussed which amount to solving a poisson equation on the image plane experiment suggest that by the isogeometry principle reconstruction of unprecedented quality can be obtained without any prefiltering of the data 
recognition of motion and activity of object in video requires effective representation for analysis and matching of motion trajectory in this paper we introduce a new representation specifically aimed at matching motion trajectory we model a trajectory a a continuous dense flow field from a sparse set of vector sequence using gaussian process regression furthermore we introduce a random sampling strategy for learning stable class of motion from limited data our representation allows for incrementally predicting possible path and detecting anomalous event from online trajectory this representation also support matching of complex motion with acceleration change and pause or stop within a trajectory we use the proposed approach for classifying and predicting motion trajectory in traffic monitoring domain and test on several data set we show that our approach work well on various type of complete and incomplete trajectory from a variety of video data set with different frame rate 
plenoptic camera are gaining attention for their unique light gathering and post capture processing capability we describe a decoding calibration and rectification procedure for lenselet based plenoptic camera appropriate for a range of computer vision application we derive a novel physically based d intrinsic matrix relating each recorded pixel to it corresponding ray in d space we further propose a radial distortion model and a practical objective function based on ray reprojection our parameter camera model is of much lower dimensionality than camera array model and more closely represents the physic of lenselet based camera result include calibration of a commercially available camera using three calibration grid size over five datasets typical rms ray reprojection error are and mm for and mm calibration grid respectively rectification example include calibration target and real world imagery 
with the proliferation of digital camera and automatic acquisition system scientist can acquire vast number of image for quantitative analysis however much image analysis is conducted manually which is both time consuming and prone to error a a result valuable scientific data from many domain sit dormant in image library awaiting annotation this work address one such domain coral reef coverage estimation in this setting the goal a defined by coral reef ecologist is to determine the percentage of the reef surface covered by rock sand algae and coral it is often desirable to resolve these taxon at the genus level or below this is challenging since the data exhibit significant within class variation the border between class are complex and the viewpoint and image quality vary we introduce moorea labeled coral a large multi year dataset with expert annotation to the computer vision community and argue that this type of ecological data provides an excellent opportunity for performance benchmarking we also propose a novel algorithm using texture and color descriptor over multiple scale that outperforms commonly used technique from the texture classification literature we show that the proposed algorithm accurately estimate coral coverage across location and year thereby taking a significant step towards reliable automated coral reef image annotation 
detecting face in uncontrolled environment continues to be a challenge to traditional face detection method due to the large variation in facial appearance a well a occlusion and clutter in order to overcome these challenge we present a novel and robust exemplar based face detector that integrates image retrieval and discriminative learning a large database of face with bounding rectangle and facial landmark location is collected and simple discriminative classifier are learned from each of them a voting based method is then proposed to let these classifier cast vote on the test image through an efficient image retrieval technique a a result face can be very efficiently detected by selecting the mode from the voting map without resorting to exhaustive sliding window style scanning moreover due to the exemplar based framework our approach can detect face under challenging condition without explicitly modeling their variation evaluation on two public benchmark datasets show that our new face detection approach is accurate and efficient and achieves the state of the art performance we further propose to use image retrieval for face validation in order to remove false positive and for face alignment landmark localization the same methodology can also be easily generalized to other face related task such a attribute recognition a well a general object detection 
in this paper we present a new method to encode the spatial information of local image feature which is a natural extension of shape context sc so we call it feature context fc given a position in a image sc computes histogram of other point belonging to the target binary shape based on their distance and angle to the position the value of each histogram bin of sc is the number of the shape point in the region assigned to the bin thus sc requires knowing the location of the point of the target shape in other word an image point can have only two label it belongs to the shape or not in contrast fc can be applied to the whole image without knowing the location of the target shape in the image each image point can have multiple label depending on it local feature the value of each histogram bin of fc is a histogram of various feature assigned to point in the bin region we also introduce an efficient coding method to encode the local image feature call radial basis coding rbc combining rbc and fc together and using a linear svm classifier our method is suitable for both image classification and object detection 
generating coherent synopsis for surveillance video stream remains a formidable challenge due to the ambiguity and uncertainty inherent to visual observation in contrast to existing video synopsis approach that rely on visual cue alone we propose a novel multi source synopsis framework capable of correlating visual data and independent non visual auxiliary information to better describe and summarise subtle physical event in complex scene specifically our unsupervised framework is capable of seamlessly uncovering latent correlation among heterogeneous type of data source despite the non trivial heteroscedasticity and dimensionality discrepancy problem additionally the proposed model is robust to partial or missing non visual information we demonstrate the effectiveness of our framework on two crowded public surveillance datasets 
in this paper we propose an approach to holistic scene understanding that reason jointly about region location class and spatial extent of object presence of a class in the image a well a the scene type learning and inference in our model are efficient a we reason at the segment level and introduce auxiliary variable that allow u to decompose the inherent high order potential into pairwise potential between a few variable with small number of state at most the number of class inference is done via a convergent message passing algorithm which unlike graph cut inference ha no submodularity restriction and doe not require potential specific move we believe this is very important a it allows u to encode our idea and prior knowledge about the problem without the need to change the inference engine every time we introduce a new potential our approach outperforms the state of the art on the msrc benchmark while being much faster importantly our holistic model is able to improve performance in all task 
we propose a novel approach to boost the performance of generic object detector on video by learning video specific feature using a deep neural network the insight behind our proposed approach is that an object appearing in different frame of a video clip should share similar feature which can be learned to build better detector unlike many supervised detector adaptation or detection by tracking method our method doe not require any extra annotation or utilize temporal correspondence we start with the high confidence detection from a generic detector then iteratively learn new video specific feature and refine the detection score in order to learn discriminative and compact feature we propose a new feature learning method using a deep neural network based on auto en coder it differs from the existing unsupervised feature learning method in two way first it optimizes both discriminative and generative property of the feature simultaneously which give our feature better discriminative ability second our learned feature are more compact while the unsupervised feature learning method usually learn a redundant set of over complete feature extensive experimental result on person and horse detection show that significant performance improvement can be achieved with our proposed method 
we propose in this work a patch based segmentation method relying on a label propagation framework based on image intensity similarity between the input image and a learning dataset an original strategy which doe not require any non rigid registration is presented following recent development in non local image denoising the similarity between image is represented by a weighted graph computed from intensity based distance between patch experiment on simulated and in vivo mr image show that the proposed method is very successful in providing automated human brain labeling 
this paper proposes a reconfigurable model to recognize and detect multiclass or multiview object with large variation in appearance compared with well acknowledged hierarchical model we study two advanced capability in hierarchy for object modeling i switch variable i e or node for specifying alternative composition and ii making local classifier i e leaf node shared among different class these capability enable u to account well for structural variability while preserving the model compact our model in the form of an and or graph comprises four layer a batch of leaf node with collaborative edge in bottom for localizing object part the or node over bottom to activate their child leaf node the and node to classify object a a whole one root node on the top for switching multiclass classification which is also an or node for model training we present an em type algorithm namely dynamical structural optimization dso to iteratively determine the structural configuration e g leaf node generation associated with their parent or node and shared across other class along with optimizing multi layer parameter the proposed method is valid on challenging database e g pascal voc and uiuc people and it achieves state of the art performance 
we present an algorithm and implementation for distributed parallel training of single machine multiclass svms while there is ongoing and healthy debate about the best strategy for multiclass classification there are some feature of the single machine approach that are not available when training alternative such a one v all and that are quite complex for tree based method one obstacle to exploring single machine approach on large datasets is that they are usually limited to running on a single machine we build on a framework borrowed from parallel convex optimization the alternating direction method of multiplier admm to develop a new consensus based algorithm for distributed training of single machine approach this is demonstrated with an implementation of our novel sequential dual algorithm dcmsvm which allows distributed parallel training with small communication requirement benchmark result show significant reduction in wall clock time compared to current state of the art multiclass svm implementation liblinear on a single node experiment are performed on large scale image classification including result with modern high dimensional feature 
algorithm based on ransac that estimate model using feature correspondence between image can slow down tremendously when the percentage of correct correspondence inliers is small in this paper we present a probabilistic parametric model that allows u to assign confidence value for each matching correspondence and therefore accelerates the generation of hypothesis model for ransac under these condition our framework leverage extreme value theory to accurately model the statistic of matching score produced by a nearest neighbor feature matcher using a new algorithm based on this model we are able to estimate accurate hypothesis with ransac at low inlier ratio significantly faster than previous state of the art approach while still performing comparably when the number of inliers is large we present result of homography and fundamental matrix estimation experiment for both sift and surf match that demonstrate that our method lead to accurate and fast model estimation 
understanding the nature of data is the key to building good representation in domain such a natural image the data come from very complex distribution which are hard to capture feature learning intends to discover or best approximate these underlying distribution and use their knowledge to weed out irrelevant information preserving most of the relevant information feature learning can thus be seen a a form of dimensionality reduction in this paper we describe a feature learning scheme for natural image we hypothesize that image patch do not all come from the same distribution they lie in multiple non linear subspace we propose a framework that us k restricted boltzmann machine k rbms to learn multiple non linear subspace in the raw image space projection of the image patch into these subspace give u feature which we use to build image representation our algorithm solves the coupled problem of finding the right non linear subspace in the input space and associating image patch with those subspace in an iterative em like algorithm to minimize the overall reconstruction error extensive empirical result over several popular image classification datasets show that representation based on our framework outperform the traditional feature representation such a the sift based bag of word bow and convolutional deep belief network 
the appearance of an object change profoundly with pose camera view and interaction of the object with other object in the scene this make it challenging to learn detector based on an object level label e g car we postulate that having a richer set of labelings at different level of granularity for an object including finer grained subcategories consistent in appearance and view and higher order composite contextual grouping of object consistent in their spatial layout and appearance can significantly alleviate these problem however obtaining such a rich set of annotation including annotation of an exponentially growing set of object grouping is simply not feasible we propose a weakly supervised framework for object detection where we discover subcategories and the composite automatically with only traditional object level category label a input to this end we first propose an exemplar svm based clustering approach with latent svm refinement that discovers a variable length set of discriminative subcategories for each object class we then develop a structured model for object detection that capture interaction among object subcategories and automatically discovers semantically meaningful and discriminatively relevant visual composite we show that this model produce state of the art performance on uiuc phrase object detection benchmark 
in this paper we propose a framework for learning a regression function form a set of local feature in an image the regression is learned from an embedded representation that reflects the local feature and their spatial arrangement a well a enforces supervised manifold constraint on the data we applied the approach for viewpoint estimation on a multiview car dataset a head pose dataset and arm posture dataset the experimental result show that this approach ha superior result up to improvement to the state of the art approach in very challenging datasets 
the choice of the over complete dictionary that sparsely represents data is of prime importance for sparse coding based image super resolution sparse coding is a typical unsupervised learning method to generate an over complete dictionary however most of the sparse coding method for image super resolution fail to simultaneously consider the geometrical structure of the dictionary and corresponding coefficient which may result in noticeable super resolution reconstruction artifact in this paper a novel sparse coding method is proposed to preserve the geometrical structure of the dictionary and the sparse coefficient of the data moreover the proposed method can preserve the incoherence of dictionary entry which is critical for sparse representation inspired by the development on non local self similarity and manifold learning the proposed sparse coding method can provide the sparse coefficient and learned dictionary from a new perspective which have both reconstruction and discrimination property to enhance the learning performance extensive experimental result on image super resolution have demonstrated the effectiveness of the proposed method 
fitting an articulated model to image data is often approached a an optimization over both model pose and model to image correspondence for complex model such a human previous work ha required a good initialization or an alternating minimization between correspondence and pose in this paper we investigate one shot pose estimation can we directly infer correspondence using a regression function trained to be invariant to body size and shape and then optimize the model pose just once we evaluate on several challenging single frame data set containing a wide variety of body pose shape torso rotation and image cropping our experiment demonstrate that one shot pose estimation achieves state of the art result and run in real time 
many computer vision problem can be formulated a binary quadratic program bqps two classic relaxation method are widely used for solving bqps namely spectral method and semi definite programming sdp each with their own advantage and disadvantage spectral relaxation is simple and easy to implement but it bound is loose semi definite relaxation ha a tighter bound but it computational complexity is high for large scale problem we present a new sdp formulation for bqps with two desirable property first it ha a similar relaxation bound to conventional sdp formulation second compared with conventional sdp method the new sdp formulation lead to a significantly more efficient and scalable dual optimization approach which ha the same degree of complexity a spectral method extensive experiment on various application including clustering image segmentation co segmentation and registration demonstrate the usefulness of our sdp formulation for solving large scale bqps 
the similarity or distance measure between gaussian mixture model gmms play a crucial role in content based image matching though the earth mover s distance emd ha shown it advantage in matching histogram feature it potential in matching gmms remain unclear and are not fully explored to address this problem we propose a novel emd methodology for gmm matching we first present a sparse representation based emd called sr emd by exploiting the sparse property of the underlying problem sr emd is more efficient and robust than the conventional emd second we present two novel ground distance between component gaussians based on the information geometry the perspective from the riemannian geometry distinguishes the proposed ground distance from the classical entropy or divergence based one furthermore motivated by the success of distance metric learning of vector data we make the first attempt to learn the emd distance metric between gmms by using a simple yet effective supervised pair wise based method it can adapt the distance metric between gmms to specific classification task the proposed method is evaluated on both simulated data and benchmark real database and achieves very promising performance 
we present a novel clustering algorithm for tagging a face dataset e g a personal photo album the core of the algorithm is a new dissimilarity called rank order distance which measure the dissimilarity between two face using their neighboring information in the dataset the rank order distance is motivated by an observation that face of the same person usually share their top neighbor specifically for each face we generate a ranking order list by sorting all other face in the dataset by absolute distance e g l or l distance between extracted face recognition feature then the rank order distance of two face is calculated using their ranking order using the new distance a rank order distance based clustering algorithm is designed to iteratively group all face into a small number of cluster for effective tagging the proposed algorithm outperforms competitive clustering algorithm in term of both precision recall and efficiency 
the goal of single image super resolution is to generate a high quality high resolution image based on a given low resolution input it is an ill posed problem which requires exemplar or prior to better reconstruct the missing high resolution image detail in this paper we propose to split the feature space into numerous subspace and collect exemplar to learn prior for each subspace thereby creating effective mapping function the use of split input space facilitates both feasibility of using simple function for super resolution and efficiency of generating high resolution result high quality high resolution image are reconstructed based on the effective learned prior experimental result demonstrate that the proposed algorithm performs efficiently and effectively over state of the art method 
consumer digital camera use tone mapping to produce compact narrow gamut image that are nonetheless visually pleasing in doing so they discard or distort substantial radiometric signal that could otherwise be used for computer vision existing method attempt to undo these effect through deterministic map that de render the reported narrow gamut color back to their original wide gamut sensor measurement deterministic approach are unreliable however because the reverse narrow to wide mapping is one to many and ha inherent uncertainty our solution is to use probabilistic map providing uncertainty estimate useful to many application we use a non parametric bayesian regression technique local gaussian process regression to learn for each pixel s narrow gamut color a probability distribution over the scene color that could have created it using a variety of consumer camera we show that these distribution once learned from training data are effective in simple probabilistic adaptation of two popular application multi exposure imaging and photometric stereo our result on these application are better than those of corresponding deterministic approach especially for saturated and out of gamut color 
how to measure the perceptual quality of natural image is an important problem in low level vision it is known that the mean squared error mse is not an effective index to describe the perceptual fidelity of image numerous perceptual fidelity index have been developed while the representative include the structural similarity ssim index and it variant however most of those perceptual measure are nonlinear and they cannot be easily dopted a an objective function to minimize in various low level vision task can mse be perceptual fidelity aware after some minor adaptation in this paper we propose a simple framework to enhance the perceptual fidelity awareness of mse by introducing an l norm structural error term to it such a structural mse smse can lead to very competitive image quality assessment iqa result more surprisingly we show that by using certain structure extractor smse can be further turned into a gaussian smoothed mse i e the euclidean distance between the original and distorted image after gaussian smooth filtering which is much simpler to calculate but achieves rather better iqa performance than ssim the so called perceptual fidelity aware mse pamse can have great potential in application such a perceptual image coding and perceptual image restoration 
many computer vision application can be formulated a labeling problem however multilabeling problem are usually very challenging to solve especially when some ordering constraint are enforced we solve in this paper a five part labeling problem proposed in in this model one want to find an optimal labeling for an image with five possible part left right top bottom and center the geometric ordering constraint can be read naturally from the name no previous method can solve the problem with globally optimal solution in a linear space complexity we propose an efficient dynamic programming based algorithm which guarantee the global optimal labeling for the five part model the time complexity is o n and the space complexity is o n with n being the number of pixel in the image in practice it run faster than previous method moreover it work for both neighborhood and neighborhood setting and can be easily parallelized for gpu 
human action recognition under low observational latency is receiving a growing interest in computer vision due to rapidly developing technology in human robot interaction computer gaming and surveillance in this paper we propose a fast simple yet powerful non parametric moving pose mp framework for low latency human action and activity recognition central to our methodology is a moving pose descriptor that considers both pose information a well a differential quantity speed and acceleration of the human body joint within a short time window around the current frame the proposed descriptor is used in conjunction with a modified knn classifier that considers both the temporal location of a particular frame within the action sequence a well a the discrimination power of it moving pose descriptor compared to other frame in the training set the resulting method is non parametric and enables low latency recognition one shot learning and action detection in difficult unsegmented sequence moreover the framework is real time scalable and outperforms more sophisticated approach on challenging benchmark like msr action d or msr dailyactivities d 
object in a real world image cannot have arbitrary appearance size and location due to geometric constraint in d space such a d geometric context play an important role in resolving visual ambiguity and achieving coherent object detection in this paper we develop a ransac crf framework to detect object that are geometrically coherent in the d world different from existing method we propose a novel generalized ransac algorithm to generate global d geometry hypothesis from local entity such that outlier suppression and noise reduction is achieved simultaneously in addition we evaluate those hypothesis using a crf which considers both the compatibility of individual object under global d geometric context and the compatibility between adjacent object under local d geometric context experiment result show that our approach compare favorably with the state of the art 
non negative matrix factorization nmf ha previously been shown to be a useful decomposition tool for multivariate data non negative base allow strictly additive combination which have been shown to be part based a well a relatively sparse we pursue a discriminative decomposition by coupling nmf objective with a maximum margin classifier specifically a support vector machine svm conversely we propose an nmf based regularizer for svm we formulate the joint update equation and propose a new method which identifies the decomposition a well a the classification parameter we present classification result on synthetic a well a real datasets 
in this paper we propose a physically based dynamical model for tracking our model relies on newton s second law of motion which governs any real world dynamical system a a consequence it can be generally applied to very different tracking problem furthermore since the equation describing newton s second law are simple linear equality they can be incorporated in any tracking framework at very little cost leveraging this let u introduce a convex formulation of d tracking from monocular image we demonstrate the strength of our approach on various type of motion such a billiards and acrobatics 
image appearance cue are often used to derive object shape which is usually one of the key step of image understanding task however when image appearance cue are weak or misleading shape prior become critical to infer and refine the shape derived by these appearance cue effective modeling of shape prior is challenging because shape variation is complex and cannot always be modeled by a parametric probability distribution a shape instance derived from image appearance cue input shape may have gross error and local detail of the input shape are difficult to preserve if they are not statistically significant in the training data in this paper we propose a novel sparse shape composition model ssc to deal with these three challenge in a unified framework in our method training shape are adaptively composed to infer refine an input shape the a priori information is thus implicitly incorporated on the fly our model leverage two sparsity observation of the input shape instance the input shape can be approximately represented by a sparse linear combination of training shape part of the input shape may contain gross error but such error are usually sparse using l norm relaxation our model is formulated a a convex optimization problem which is solved by an efficient alternating minimization framework our method is extensively validated on two real world medical application d lung localization in x ray image and d liver segmentation in low dose ct scan compared to state of the art method our model exhibit better performance in both study 
a convenient way of dealing with image set is to represent them a point on grassmannian manifold while several recent study explored the applicability of discriminant analysis on such manifold the conventional formalism of discriminant analysis suffers from not considering the local structure of the data we propose a discriminant analysis approach on grassmannian manifold based on a graph embedding framework we show that by introducing within class and between class similarity graph to characterise intra class compactness and inter class separability the geometrical structure of data can be exploited experiment on several image datasets pie banca mobo eth show that the proposed algorithm obtains considerable improvement in discrimination accuracy in comparison to three recent method grassmann discriminant analysis gda kernel gda and the kernel version of affine hull image set distance we further propose a grassmannian kernel based on canonical correlation between subspace which can increase discrimination accuracy when used in combination with previous grassmannian kernel 
d scene understanding is key for the success of application such a autonomous driving and robot navigation however existing approach either produce a mild level of understanding e g segmentation object detection or are not accurate enough for these application e g d pop ups in this paper we propose a principled generative model of d urban scene that take into account dependency between static and dynamic feature we derive a reversible jump mcmc scheme that is able to infer the geometric e g street orientation and topological e g number of intersecting street property of the scene layout a well a the semantic activity occurring in the scene e g traffic situation at an intersection furthermore we show that this global level of understanding provides the context necessary to disambiguate current state of the art detector we demonstrate the effectiveness of our approach on a dataset composed of short stereo video sequence of different scene captured by a car driving around a mid size city 
we present a new framework in which image segmentation figure ground organization and object detection all appear a the result of solving a single grouping problem this framework serf a a perceptual organization stage that integrates information from low level image cue with that of high level part detector pixel and part each appear a node in a graph whose edge encode both affinity and ordering relationship we derive a generalized eigen problem from this graph and read off an interpretation of the image from the solution eigenvectors combining an off the shelf top down part based person detector with our low level cue and grouping formulation we demonstrate improvement to object detection and segmentation 
we study the problem of automatically learning event and or grammar from video of a certain environment e g an office where student conduct daily activity we propose to learn the event grammar under the information projection and minimum description length principle in a coherent probabilistic framework without manual supervision about what event happen and when they happen firstly a predefined set of unary and binary relation are detected for each video frame e g agent s position pose and interaction with environment then their co occurrence are clustered into a dictionary of simple and transient atomic action recursively these action are grouped into longer and complexer event resulting in a stochastic event grammar by modeling time constraint of successive event the learned grammar becomes context sensitive we introduce a new dataset of surveillance style video in office and present a prototype system for video analysis integrating bottom up detection grammatical learning and parsing on this dataset the learning algorithm is able to automatically discover important event and construct a stochastic grammar which can be used to accurately parse newly observed video the learned grammar can be used a a prior to improve the noisy bottom up detection of atomic action it can also be used to infer semantics of the scene in general the event grammar is an efficient way for common knowledge acquisition from video 
image patch can be factorized into shapelets that describe segmentation pattern called structural element stels and palette that describe how to paint the shapelets we introduce local palette for patch global palette for entire image and universal palette for image collection using a learned shapelet library patch from a test image can be analyzed using a variational technique to produce an image descriptor that represents local shape and color separately we show that the shapelet model performs better than sift gist and the standard stel method on caltech and is very competitive with other method on caltech 
in multi label image annotation because each image is associated to multiple category the semantic term label class are not mutually exclusive previous research showed that such label correlation can largely boost the annotation accuracy however all existing method only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among class in this paper we model the label correlation using the relational graph and propose a novel graph structured sparse learning model to incorporate the topological constraint of relation graph in multi label classification a a result our new method will capture and utilize the hidden class structure in relational graph to improve the annotation result in proposed objective a large number of structured sparsity inducing norm are utilized thus the optimization becomes difficult to solve this problem we derive an efficient optimization algorithm with proved convergence we perform extensive experiment on six multi label image annotation benchmark data set in all empirical result our new method show better annotation result than the state of the art approach 
we present an iterative approximate solution to the multidimensional assignment problem under general cost function the method maintains a feasible solution at every step and is guaranteed to converge it is similar to the iterated conditional mode icm algorithm but applied at each step to a block of variable representing correspondence between two adjacent frame with the optimal conditional mode being calculated exactly a the solution to a two frame linear assignment problem experiment with ground truthed trajectory data show that the method outperforms both network flow data association and greedy recursive filtering using a constant velocity motion model 
we present a markerless motion capture approach that reconstructs the skeletal motion and detailed time varying surface geometry of two closely interacting people from multi view video due to ambiguity in feature to person assignment and frequent occlusion it is not feasible to directly apply single person capture approach to the multi person case we therefore propose a combined image segmentation and tracking approach to overcome these difficulty a new probabilistic shape and appearance model is employed to segment the input image and to assign each pixel uniquely to one person thereafter a single person markerless motion and surface capture approach can be applied to each individual either one by one or in parallel even under strong occlusion we demonstrate the performance of our approach on several challenging multi person motion including dance and martial art and also provide a reference dataset for multi person motion capture with ground truth 
we present a solution for generating high quality stereo panorama at mega pixel resolution while previous approach introduced the basic principle we show that those technique do not generalise well to today s high image resolution and lead to disturbing visual artefact a our first contribution we describe the necessary correction step and a compact representation for the input image in order to achieve a highly accurate approximation to the required ray space our second contribution is a flow based up sampling of the available input ray which effectively resolve known aliasing issue like stitching artefact the required ray are generated on the fly to perfectly match the desired output resolution even for small number of input image in addition the up sampling is real time and enables direct interactive control over the desired stereoscopic depth effect in combination our contribution allow the generation of stereoscopic panorama at high output resolution that are virtually free of artefact such a seam stereo discontinuity vertical parallax and other mono stereoscopic shape distortion our process is robust and other type of multiperspective panorama such a linear panorama can also benefit from our contribution we show various comparison and high resolution result 
alzheimer s disease ad is the most common form of dementia that cause progressive impairment of memory and other cognitive function multivariate regression model have been studied in ad for revealing relationship between neuroimaging measure and cognitive score to understand how structural change in brain can influence cognitive status existing regression method however do not explicitly model dependence relation among multiple score derived from a single cognitive test it ha been found that such dependence can deteriorate the performance of these method to overcome this limitation we propose an efficient sparse bayesian multi task learning algorithm which adaptively learns and exploit the dependence to achieve improved prediction performance the proposed algorithm is applied to a real world neuroimaging study in ad to predict cognitive performance using mri scan the effectiveness of the proposed algorithm is demonstrated by it superior prediction performance over multiple state of the art competing method and accurate identification of compact set of cognition relevant imaging biomarkers that are consistent with prior knowledge 
alzheimer s disease ad is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive function which make regression analysis a suitable model to study whether neuroimaging measure can help predict memory performance and track the progression of ad existing memory performance prediction method via regression however do not take into account either the interconnected structure within imaging data or those among memory score which inevitably restricts their predictive capability to bridge this gap we propose a novel sparse multi task regression and feature selection smart method to jointly analyze all the imaging and clinical data under a single regression framework and with shared underlying sparse representation two convex regularization are combined and used in the model to enable sparsity a well a facilitate multi task learning the effectiveness of the proposed method is demonstrated by both clearly improved prediction performance in all empirical test case and a compact set of selected ravlt relevant mri predictor that accord with prior study 
finding a good binary sequence is critical in determining the performance of the coded exposure imaging but previous method mostly rely on a random search for finding the binary code which could easily fail to find good long sequence due to the exponentially growing search space in this paper we present a new computationally efficient algorithm for generating the binary sequence which is especially well suited for longer sequence we show that the concept of the low autocorrelation binary sequence that ha been well exploited in the information theory community can be applied for generating the fluttering pattern of the shutter propose a new measure of a good binary sequence and present a new algorithm by modifying the legendre sequence for the coded exposure imaging experiment using both synthetic and real data show that our new algorithm consistently generates better binary sequence for the coded exposure problem yielding better deblurring and resolution enhancement result compared to the previous method for generating the binary code 
hyperspectral imaging is a promising tool for application in geosensing cultural heritage and beyond however compared to current rgb camera existing hyperspectral camera are severely limited in spatial resolution in this paper we introduce a simple new technique for reconstructing a very high resolution hyperspectral image from two readily obtained measurement a lower resolution hyper spectral image and a high resolution rgb image our approach is divided into two stage we first apply an unmixing algorithm to the hyperspectral input to estimate a basis representing reflectance spectrum we then use this representation in conjunction with the rgb input to produce the desired result our approach to unmixing is motivated by the spatial sparsity of the hyperspectral input and cast the unmixing problem a the search for a factorization of the input into a basis and a set of maximally sparse coefficient experiment show that this simple approach performs reasonably well on both simulation and real data example 
multiview object detection method achieve robustness in adverse imaging condition by exploiting projective consistency across view in this paper we present an algorithm that achieves performance comparable to multiview method from a single camera by employing geometric primitive a proxy for the true d shape of object such a pedestrian or vehicle our key insight is that for a calibrated camera geometric primitive produce predetermined location specific pattern in occupancy map we use these to define spatially varying kernel function of projected shape this lead to an analytical formation model of occupancy map a the convolution of location and projected shape kernel we estimate object location by deconvolving the occupancy map using an efficient template similarity scheme the number of object and their position are determined using the mean shift algorithm the approach is highly parallel because the occupancy probability of a particular geometric primitive at each ground location is an independent computation the algorithm extends to multiple camera without requiring significant bandwidth we demonstrate comparable performance to multiview method and show robust realtime object detection on full resolution hd video in a variety of challenging imaging condition 
in recent year how to learn a dictionary from input image for sparse modelling ha been one very active topic in image processing and recognition most existing dictionary learning method consider an over complete dictionary e g the k svd method often they require solving some minimization problem that is very challenging in term of computational feasibility and efficiency however if the correlation among dictionary atom are not well constrained the redundancy of the dictionary doe not necessarily improve the performance of sparse coding this paper proposed a fast orthogonal dictionary learning method for sparse image representation with comparable performance on several image restoration task the proposed method is much more computationally efficient than the over complete dictionary based learning method 
a typical collection of presentation and lecture recording may contain hundred or thousand of recording making it difficult to retrieve particular presentation and find specific point in a presentation this paper describes a retrieval system where the digital camera picture taken during presentation can be used to retrieve presentation slide image and the associated video clip 
in many problem in computer vision data in multiple class lie in multiple low dimensional subspace of a high dimensional ambient space however most of the existing classification method do not explicitly take this structure into account in this paper we consider the problem of classification in the multi sub space setting using sparse representation technique we exploit the fact that the dictionary of all the training data ha a block structure where the training data in each class form few block of the dictionary we cast the classification a a structured sparse recovery problem where our goal is to find a representation of a test example that us the minimum number of block from the dictionary we formulate this problem using two different class of non convex optimization program we propose convex relaxation for these two non convex program and study condition under which the relaxation are equivalent to the original problem in addition we show that the proposed optimization program can be modified properly to also deal with corrupted data to evaluate the proposed algorithm we consider the problem of automatic face recognition we show that casting the face recognition problem a a structured sparse recovery problem can improve the result of the state of the art face recognition algorithm especially when we have relatively small number of training data for each class in particular we show that the new class of convex program can improve the state of the art face recognition result by with only of the training data in addition we show that the algorithm are robust to occlusion corruption and disguise 
most modern face recognition system rely on a feature representation given by a hand crafted image descriptor such a local binary pattern lbp and achieve improved performance by combining several such representation in this paper we propose deep learning a a natural source for obtaining additional complementary representation to learn feature in high resolution image we make use of convolutional deep belief network moreover to take advantage of global structure in an object class we develop local convolutional restricted boltzmann machine a novel convolutional learning model that exploit the global structure by not assuming stationarity of feature across the image while maintaining scalability and robustness to small misalignment we also present a novel application of deep learning to descriptor other than pixel intensity value such a lbp in addition we compare performance of network trained using unsupervised learning against network with random filter and empirically show that learning weight not only is necessary for obtaining good multilayer representation but also provides robustness to the choice of the network architecture parameter finally we show that a recognition system using only representation obtained from deep learning can achieve comparable accuracy with a system using a combination of hand crafted image descriptor moreover by combining these representation we achieve state of the art result on a real world face verification database 
we propose compact and real time descriptor card which can be computed very rapidly and be expressed by short binary code an efficient algorithm based on lookup table is presented for extracting histogram of oriented gradient which result in approximately time faster computation time per descriptor than that of sift our lookup table based approach can handle arbitrary layout of bin such a the grid binning of sift and the log polar binning of gloh thus yielding sufficient discrimination power in addition we introduce learning based sparse hashing to convert the extracted descriptor to short binary code this conversion is achieved very rapidly by multiplying a very sparse integer weight matrix by the descriptor and aggregating sign of their multiplication the weight matrix is optimized in a training phase so a to make hamming distance between encoded training pair reflect visual dissimilarity between them experimental result demonstrate that card outperforms previous method in term of both computation time and memory usage 
in this paper we propose a novel object matching method to match an object to it instance in an input scene image where both the object template and the input scene image are represented by group of feature point we relax each template point s discrete feature cost function to create a convex function that can be optimized efficiently such continuous and convex function with different regularization term are able to create different convex optimization model handling object undergoing i global transformation ii locally affine transformation and iii articulated transformation these model can better constrain each template point s transformation and therefore generate more robust matching result unlike traditional object or feature matching method with hard node to node result our proposed method allows template point to be transformed to any location in the image plane such a property make our method robust to feature point occlusion or mi detection our extensive experiment demonstrate the robustness and flexibility of our method 
understanding natural human activity involves not only identifying the action being performed but also locating the semantic element of the scene and describing the person s interaction with them we present a system that is able to recognize complex fine grained human action involving the manipulation of object in realistic action sequence our method take advantage of recent advance in sensor and pose tracker in learning an action model that draw on successful discriminative technique while explicitly modeling both pose trajectory and object manipulation by combining these element in a single model we are able to simultaneously recognize action and track the location and manipulation of object to showcase this ability we introduce a novel cooking action dataset that contains video depth reading and pose track from a kinect sensor we show that our model outperforms existing state of the art technique on this dataset a well a the visint dataset with only video sequence 
exact recovery from contaminated visual data play an important role in various task by assuming the observed data matrix a the addition of a low rank matrix and a sparse matrix theoretic guarantee exists under mild condition for exact data recovery practically matrix nuclear norm is adopted a a convex surrogate of the non convex matrix rank function to encourage low rank property and serf a the major component of recently proposed robust principal component analysis r pca recent endeavor have focused on enhancing the scalability of r pca to large scale datasets especially mitigating the computational burden of frequent large scale singular value decomposition svd inherent with the nuclear norm optimization in our proposed scheme the nuclear norm of an auxiliary matrix is minimized instead which is related to the original low rank matrix by random projection by design the modified optimization entail svd on matrix of much smaller scale a compared to the original optimization problem theoretic analysis well justifies the proposed scheme along with greatly reduced optimization complexity both qualitative and quantitative study are provided on various computer vision benchmark to validate it effectiveness including facial shadow removal surveillance background modeling and large scale image tag transduction it is also highlighted that the proposed solution can serve a a general principal to accelerate many other nuclear norm oriented problem in numerous task 
modeling data by multiple low dimensional plane is an important problem in many application such a computer vision and pattern recognition in the most general setting where only coordinate of the data are given the problem asks to determine the optimal model parameter i e number of plane and their dimension estimate the model plane and cluster the data accordingly though many algorithm have been proposed most of them need to assume prior knowledge of the model parameter and thus address only the last two component of the problem in this paper we propose an efficient algorithm based on multiscale svd analysis and spectral method to tackle the problem in full generality we also demonstrate it state of the art performance on both synthetic and real data 
owing to visual ambiguity and disparity person re identification method inevitably produce sub optimal rank list which still requires exhaustive human eyeballing to identify the correct target from hundred of different likely candidate existing re identification study focus on improving the ranking performance but rarely look into the critical problem of optimising the time consuming and error prone post rank visual search at the user end in this study we present a novel one shot post rank optimization pop method which allows a user to quickly refine their search by either one shot or a couple of sparse negative selection during a re identification process we conduct systematic behavioural study to understand user s searching behaviour and show that the proposed method allows correct re identification to converge time faster than the conventional exhaustive search importantly through extensive evaluation we demonstrate that the method is capable of achieving significant improvement over the state of the art distance metric learning based ranking model even with just one shot feedback optimisation by a much a over performance improvement for rank re identification on the viper and i lid datasets 
regularized linear representation learning ha led to interesting result in image classification while how the object should be represented is a critical issue to be investigated considering the fact that the different feature in a sample should contribute differently to the pattern representation and classification in this paper we present a novel relaxed collaborative representation rcr model to effectively exploit the similarity and distinctiveness of feature in rcr each feature vector is coded on it associated dictionary to allow flexibility of feature coding while the variance of coding vector is minimized to address the similarity among feature in addition the distinctiveness of different feature is exploited by weighting it distance to other feature in the coding domain the proposed rcr is simple while our extensive experimental result on benchmark image database e g various face and flower database show that it is very competitive with state of the art image classification method 
we propose an approach to improve the detection performance of a generic detector when it is applied to a particular video the performance of offline trained object detector are usually degraded in unconstrained video environment due to variant illumination background and camera viewpoint moreover most object detector are trained using haar like feature or gradient feature but ignore video specific feature like consistent color pattern in our approach we apply a super pixel based bag of word bow model to iteratively refine the output of a generic detector compared to other related work our method build a video specific detector using super pixel hence it can handle the problem of appearance variation most importantly using conditional random field crf along with our super pixel based bow model we develop and algorithm to segment the object from the background therefore our method generates an output of the exact object region instead of the bounding box generated by most detector in general our method take detection bounding box of a generic detector a input and generates the detection output with higher average precision and precise object region the experiment on four recent datasets demonstrate the effectiveness of our approach and significantly improves the state of art detector by in average precision 
registration is a fundamental task in computer vision the iterative closest point icp algorithm is one of the widely used method for solving the registration problem based on local iteration icp is however well known to suffer from local minimum it performance critically relies on the quality of initialization and only local optimality is guaranteed this paper provides the very first globally optimal solution to euclidean registration of two d point set or two d surface under the l error our method is built upon icp but combine it with a branch and bound bnb scheme which search the d motion space se efficiently by exploiting the special structure of the underlying geometry we derive novel upper and lower bound for the icp error function the integration of local icp and global bnb enables the new method to run efficiently in practice and it optimality is exactly guaranteed we also discus extension addressing the issue of outlier robustness 
in this article we focus on the problem of large scale instance level image retrieval for efficiency reason it is common to represent an image by a fixed length descriptor which is subsequently encoded into a small number of bit we note that most encoding technique include an unsupervised dimensionality reduction step our goal in this work is to learn a better subspace in a supervised manner we especially raise the following question can category level label be used to learn such a subspace to answer this question we experiment with four learning technique the first one is based on a metric learning framework the second one on attribute representation the third one on canonical correlation analysis cca and the fourth one on joint subspace and classifier learning jscl while the first three approach have been applied in the past to the image retrieval problem we believe we are the first to show the usefulness of jscl in this context in our experiment we use imagenet a a source of category level label and report retrieval result on two standard dataseis inria holiday and the university of kentucky benchmark our experimental study show that metric learning and attribute do not lead to any significant improvement in retrieval accuracy a opposed to cca and jscl a an example we report on holiday an increase in accuracy from to with dimensional representation overall jscl is shown to yield the best result 
d reconstruction of transparent refractive object like a plastic bottle is challenging they lack appearance related visual cue and merely reflect and refract light from the surrounding environment amongst several approach to reconstruct such object the seminal work of light path triangulation is highly popular because of it general applicability and analysis of minimal scenario a light path is defined a the piece wise linear path taken by a ray of light a it pass from source through the object and into the camera transparent refractive object not only affect the geometric configuration of light path but also their radiometric property in this paper we describe a method that combine both geometric and radiometric information to do reconstruction we show two major consequence of the addition of radiometric cue to the light path setup firstly we extend the case of scenario in which reconstruction is plausible while reducing the minimal requirement for a unique reconstruction this happens a a consequence of the fact that radiometric cue add an additional known variable to the already existing system of equation secondly we present a simple algorithm for reconstruction owing to the nature of the radiometric cue we present several synthetic experiment to validate our theory and show high quality reconstruction in challenging scenario 
in this work we propose a contour and region detector for video data that exploit motion cue and distinguishes occlusion boundary from internal boundary based on optical flow this detector outperforms the state of the art on the benchmark of stein and hebert improving average precision from to moreover the optical flow on and near occlusion boundary allows u to assign a depth ordering to the adjacent region to evaluate performance on this edge based figure ground labeling task we introduce a new video dataset that we believe will support further research in the field by allowing quantitative comparison of computational model for occlusion boundary detection depth ordering and segmentation in video sequence 
this paper tackle the novel challenging problem of d object phenotype recognition from a single d silhouette to bridge the large pose articulation or deformation and camera viewpoint change between the gallery image and query image we propose a novel probabilistic inference algorithm based on d shape prior our approach combine both generative and discriminative learning we use latent probabilistic generative model to capture d shape and pose variation from a set of d mesh model based on these d shape prior we generate a large number of projection for different phenotype class pose and camera viewpoint and implement random forest to efficiently solve the shape and pose inference problem by model selection in term of the silhouette coherency between the query and the projection of d shape synthesized using the gallery we achieve the phenotype recognition result a well a a fast approximate d reconstruction of the query to verify the efficacy of the proposed approach we present new datasets which contain over image of various human and shark phenotype and motion the experimental result clearly show the benefit of using the d prior in the proposed method over previous d based method 
the aim of this paper is to leverage foreground segmentation to improve classification performance on weakly annotated datasets those with no additional annotation other than class label we introduce tricos a new co segmentation algorithm that look at all training image jointly and automatically segment out the most class discriminative foreground for each image ultimately those foreground segmentation are used to train a classification system tricos solves the co segmentation problem by minimizing loss at three different level the category level for foreground background consistency across image belonging to the same category the image level for spatial continuity within each image and the dataset level for discrimination between class in an extensive set of experiment we evaluate the algorithm on three benchmark datasets the ucsd caltech bird the stanford dog and the oxford flower with the help of a modern image classifier we show superior performance compared to previously published classification method and other co segmentation method 
we describe an approach to category level detection and viewpoint estimation for rigid d object from single d image in contrast to many existing method we directly integrate d reasoning with an appearance based voting architecture our method relies on a nonparametric representation of a joint distribution of shape and appearance of the object class our voting method employ a novel parametrization of joint detection and viewpoint hypothesis space allowing efficient accumulation of evidence we combine this with a re scoring and refinement mechanism using an ensemble of view specific support vector machine we evaluate the performance of our approach in detection and pose estimation of car on a number of benchmark datasets 
this paper present a new approach for image set classification where each training and testing example contains a set of image instance of an object captured from varying viewpoint or under varying illumination while a number of image set classification method have been proposed in recent year most of them model each image set a a single linear subspace or mixture of linear subspace which may lose some discriminative information for classification to address this we propose exploring multiple order statistic a feature of image set and develop a localized multi kernel metric learning lmkml algorithm to effectively combine different order statistic information for classification our method achieves the state of the art performance on four widely used database including the honda ucsd cmu mobo and youtube face datasets and the eth object dataset 
this paper present an algorithm for order reduction of factor in high order markov random field homrfs standard technique for transforming arbitrary high order factor into pairwise one have been known for a long time in this work we take a fresh look at this problem with the following motivation it is important to keep in mind that order reduction is followed by an inference procedure on the order reduced mrf since there are many possible way of performing order reduction a technique that generates easier pairwise inference problem is a better reduction with this motivation in mind we introduce a new algorithm called order reduction inference ori that search over a space of order reduction method to minimize the difficulty of the resultant pairwise inference problem we set up this search problem a an energy minimization problem we show that application of ori for order reduction outperforms known order reduction technique both in simulated problem and in real world vision application 
achieving computer vision on micro scale device is a challenge on these platform the power and mass constraint are severe enough for even the most common computation matrix manipulation convolution etc to be difficult this paper proposes and analyzes a class of miniature vision sensor that can help overcome these constraint these sensor reduce power requirement through template based optical convolution and they enable a wide field of view within a small form through a novel optical design we describe the trade offs between the field of view volume and mass of these sensor and we provide analytic tool to navigate the design space we also demonstrate milli scale prototype for computer vision task such a locating edge tracking target and detecting face 
despite the ubiquitous use of distance transforms in the shape analysis literature and the popularity of fast marching and fast sweeping method essentially hamilton jacobi solver there is very little recent work leveraging the hamilton jacobi to schr dinger connection for representational and computational purpose in this work we exploit the linearity of the schr dinger equation to i design fast discrete convolution method using the fft to compute the distance transform ii derive the histogram of oriented gradient hog via the squared magnitude of the fourier transform of the wave function iii extend the schr dinger formalism to cover the case of curve parametrized a line segment a opposed to point set iv demonstrate that the schr dinger formalism permit the addition of wave function an operation that is not allowed for distance transforms and finally v construct a fundamentally new schr dinger equation and show that it can represent both the distance transform and it gradient density not possible in earlier effort 
light field camera have recently become available to the consumer market an array of micro lens capture enough information that one can refocus image after acquisition a well a shift one s viewpoint within the sub aperture of the main lens effectively obtaining multiple view thus depth cue from both defocus and correspondence are available simultaneously in a single capture previously defocus could be achieved only through multiple image exposure focused at different depth while correspondence cue needed multiple exposure at different viewpoint or multiple camera moreover both cue could not easily be obtained together in this paper we present a novel simple and principled algorithm that computes dense depth estimation by combining both defocus and correspondence depth cue we analyze the x u d epipolar image epi where by convention we assume the spatial x coordinate is horizontal and the angular u coordinate is vertical our final algorithm us the full d epi we show that defocus depth cue are obtained by computing the horizontal spatial variance after vertical angular integration and correspondence depth cue by computing the vertical angular variance we then show how to combine the two cue into a high quality depth map suitable for computer vision application such a matting full control of depth of field and surface reconstruction 
most effective particular object and image retrieval approach are based on the bag of word bow model all state of the art retrieval result have been achieved by method that include a query expansion that brings a significant boost in performance we introduce three extension to automatic query expansion i a method capable of preventing tf idf failure caused by the presence of set of correlated feature confusers ii an improved spatial verification and re ranking step that incrementally build a statistical model of the query object and iii we learn relevant spatial context to boost retrieval performance the three improvement of query expansion were evaluated on standard paris and oxford datasets according to a standard protocol and state of the art result were achieved 
this paper demonstrates a system for the automatic extraction of novelty in image captured from a small video camera attached to a subject s chest replicating his visual perspective while performing activity which are repeated daily novelty is detected when a sub sequence cannot be registered to previously stored sequence captured while performing the same daily activity sequence registration is performed by measuring appearance and geometric similarity of individual frame and exploiting the invariant temporal order of the activity experimental result demonstrate that this is a robust way to detect novelty induced by variation in the wearer s ego motion such a stopping and talking to a person this is an essentially new and generic way of automatically extracting information of interest to the camera wearer and can be used a input to a system for life logging or memory support 
in this paper we propose a novel approach for bird part localization targeting fine grained category with wide variation in appearance due to different pose including aspect and orientation and subcategories a it is challenging to represent such variation across a large set of diverse sample with tractable parametric model we turn to individual exemplar specifically we extend the exemplar based model in by enforcing pose and subcategory consistency at the part during training we build pose specific detector scoring part pose across subcategories and subcategory specific detector scoring part appearance across pose at the testing stage likely exemplar are matched to the image suggesting part location whose pose and subcategory consistency are well supported by the image cue from these hypothesis part configuration can be predicted with very high accuracy experimental result demonstrate significant performance gain from our method on an extensive dataset cub for both localization and classification task 
recent advance in visual recognition indicate that to achieve good retrieval and classification accuracy on large scale datasets like image net extremely high dimensional visual descriptor e g fisher vector are needed we present a novel method for converting such descriptor to compact similarity preserving binary code that exploit their natural matrix structure to reduce their dimensionality using compact bilinear projection instead of a single large projection matrix this method achieves comparable retrieval and classification accuracy to the original descriptor and to the state of the art product quantization approach while having order of magnitude faster code generation time and smaller memory footprint 
visual tracking ha been typically solved a a binary classification problem most existing tracker only consider the pairwise interaction between sample and thereby ignore the higher order contextual interaction which may lead to the sensitivity to complicated factor such a noise outlier background clutter and so on in this paper we propose a visual tracker based on support vector machine svms for which a novel graph mode based contextual kernel is designed to effectively capture the higher order contextual information from sample to do so we first create a visual graph whose similarity matrix is determined by a baseline visual kernel second a set of high order context are discovered in the visual graph the problem of discovering these high order context is solved by seeking mode of the visual graph each graph mode corresponds to a vertex community termed a a high order context third we construct a contextual kernel that effectively capture the interaction information between the high order context finally this contextual kernel is embedded into svms for robust tracking experimental result on challenging video demonstrate the effectiveness and robustness of the proposed tracker 
the binary split grammar is powerful to parse fa ade in a broad range of type whose structure is characterized by repetitive pattern with different layout we notice that a far a two label are concerned bsg parsing is equivalent to approximating a fa ade by a matrix with multiple rank one pattern then we propose an efficient algorithm to decompose an arbitrary matrix into a rank one matrix and a residual matrix whose magnitude is small in the sense of l norm next we develop a block wise partition method to parse a more general fa ade our method leverage on the recent breakthrough in convex optimization that can effectively decompose a matrix into a low rank and sparse matrix pair the rank one block wise parsing not only lead to the detection of repetitive pattern but also give an accurate fa ade segmentation experiment on intensive fa ade data set have demonstrated that our method outperforms the state of the art technique and benchmark both in robustness and efficiency 
in this work we propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph in this case a geodesic shortest path tree specifically we make two contribution first we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree second we include a connectivity prior in our segmentation model that allows to segment not only a single elongated structure but instead a whole connected branching tree because both our segmentation model and the connectivity constraint are convex a global optimal solution can be found to this end we generalize a recent primal dual algorithm for continuous convex optimization to an arbitrary graph structure to validate our method we present result on data from medical imaging in angiography and retinal blood vessel segmentation 
maximum a posteriori map inference in markov random field mrf is an important topic in machine learning computer vision and other field message passing algorithm based on linear programming lp relaxation are powerful tool for the map mrf problem however current message passing algorithm are usually based on simple subgraphs resulting in slow convergence local optimum and untightness of the lp relaxation for many problem by extending the junction tree representation we propose a general convergent message passing algorithm which can work on arbitrary tractable bounded treewidth subgraphs in the extended junction tree representation the minimization and summation operator are commutable so that the proposed algorithm based on the extended junction tree is guaranteed to converge based on the treewidth decomposition better performance of the proposed algorithm is demonstrated on stereo matching optical flow and panorama 
we propose and evaluate improvement in motion field estimation in order to cope with challenge in real world scenario to build a real time stereo based three dimensional vision system which is able to handle illumination change textureless region and fast moving object observed by a moving platform we introduce a new approach to support the variational optical flow computation scheme with stereo and feature information the improved flow result is then used a input for a temporal integrated robust three dimensional motion field estimation technique we evaluate the result of our optical flow algorithm and the resulting three dimensional motion field against approach known from literature test on both synthetic realistic and real stereo sequence show that our approach is superior to approach known from literature with respect to density accuracy and robustness 
super pixel and objectness algorithm are broadly used a a pre processing step to generate support region and to speed up further computation recently many algorithm have been extended to video in order to exploit the temporal consistency between frame however most method are computationally too expensive for real time application we introduce an online real time video super pixel algorithm based on the recently proposed seed super pixel a new capability is incorporated which delivers multiple diverse sample hypothesis of super pixel in the same image or video sequence the multiple sample are shown to provide a strong cue to efficiently measure the objectness of image window and we introduce the novel concept of objectness in temporal window experiment show that the video super pixel achieve comparable performance to state of the art offline method while running at fps on a single ghz i cpu state of the art performance on objectness is also demonstrated yet order of magnitude faster and extended to temporal window in video 
mode seeking ha been widely used a a powerful data analysis technique for clustering and filtering in a metric feature space we introduce a versatile and efficient modeseeking method for graph representation where general embedding of relational data is possible beyond metric space exploiting the global structure of the graph by random walk our method intrinsically combine modeseeking with ranking on the graph and performs robust analysis by seeking high ranked authoritative data and suppressing low ranked noise and outlier this enables modeseeking to be applied to a large class of challenging real world problem involving graph representation which frequently arises in computer vision we demonstrate our method on various synthetic experiment and real application dealing with noisy and complex data such a scene summarization and object based image matching 
we introduce a novel approach to automatically recover d human pose from a single image most previous work follows a pipelined approach initially a set of d feature such a edge joint or silhouette are detected in the image and then these observation are used to infer the d pose solving these two problem separately may lead to erroneous d pose when the feature detector ha performed poorly in this paper we address this issue by jointly solving both the d detection and the d inference problem for this purpose we propose a bayesian framework that integrates a generative model based on latent variable and discriminative d part detector based on hog and perform inference using evolutionary algorithm real experimentation demonstrates competitive result and the ability of our methodology to provide accurate d and d pose estimation even when the d detector are inaccurate 
three dimensional object shape is commonly represented in term of deformation of a triangular mesh from an exemplar shape existing model however are based on a euclidean representation of shape deformation in contrast we argue that shape ha a manifold structure for example summing the shape deformation for two people doe not necessarily yield a deformation corresponding to a valid human shape nor doe the euclidean difference of these two deformation provide a meaningful measure of shape dissimilarity consequently we define a novel manifold for shape representation with emphasis on body shape using a new lie group of deformation this ha several advantage first we define triangle deformation exactly removing non physical deformation and redundant degree of freedom common to previous method second the riemannian structure of lie body enables a more meaningful definition of body shape similarity by measuring distance between body on the manifold of body shape deformation third the group structure allows the valid composition of deformation this is important for model that factor body shape deformation into multiple cause or represent shape a a linear combination of basis shape finally body shape variation is modeled using statistic on manifold instead of modeling euclidean shape variation with principal component analysis we capture shape variation on the manifold using principal geodesic analysis our experiment show consistent visual and quantitative advantage of lie body over traditional euclidean model of shape deformation and our representation can be easily incorporated into existing method 
this paper proposes a hybrid convolutional network convnet restricted boltzmann machine rbm model for face verification in wild condition a key contribution of this work is to directly learn relational visual feature which indicate identity similarity from raw pixel of face pair with a hybrid deep network the deep convnets in our model mimic the primary visual cortex to jointly extract local relational visual feature from two face image compared with the learned filter pair these relational feature are further processed through multiple layer to extract high level and global feature multiple group of convnets are constructed in order to achieve robustness and characterize face similarity from different aspect the top layer rbm performs inference from complementary high level feature extracted from different convnet group with a two level average pooling hierarchy the entire hybrid deep network is jointly fine tuned to optimize for the task of face verification our model achieves competitive face verification performance on the lfw dataset 
in this paper we describe a technique to automatically enhance the perceptual quality of an image unlike previous technique where global statistic of the image are used to determine enhancement operation our method is local and relies on local scene descriptor and context in addition to high level image statistic we cast the problem of image enhancement a searching for the best transformation for each pixel in the given image and then discovering the enhanced image using a formulation based on gaussian random field the search is done in a coarse to fine manner namely by finding the best candidate image followed by pixel our experiment indicate that such context based local enhancement is better than global enhancement scheme a user study using mechanical turk show that the subject prefer contextual and local enhancement over the one provided by existing scheme 
many state of the art optical flow estimation algorithm optimize the data and regularization term to solve ill posed problem in this paper in contrast to the conventional optical flow framework that us a single or fixed data model we study a novel framework that employ locally varying data term that adaptively combine different multiple type of data model the locally adaptive data term greatly reduces the matching ambiguity due to the complementary nature of the multiple data model the optimal number of complementary data model is learnt by minimizing the redundancy among them under the minimum description length constraint mdl from these chosen data model a new optical flow estimation energy model is designed with the weighted sum of the multiple data model and a convex optimization based highly effective and practical solution that find the optical flow a well a the weight is proposed comparative experimental result on the middlebury optical flow benchmark show that the proposed method using the complementary data model outperforms the state of the art method 
this paper present an end to end video face recognition system addressing the difficult problem of identifying a video face track using a large dictionary of still face image of a few hundred people while rejecting unknown individual a straightforward application of the popular l minimization for face recognition on a frame by frame basis is prohibitively expensive so we propose a novel algorithm mean sequence src mssrc that performs video face recognition using a joint optimization leveraging all of the available video data and the knowledge that the face track frame belong to the same individual by adding a strict temporal constraint to the l minimization that force individual frame in a face track to all reconstruct a single identity we show the optimization reduces to a single minimization over the mean of the face track we also introduce a new movie trailer face dataset collected from movie trailer on youtube finally we show that our method match or outperforms the state of the art on three existing datasets youtube celebrity youtube face and buffy and our unconstrained movie trailer face dataset more importantly our method excels at rejecting unknown identity by at least in average precision 
most sparse linear representation based tracker need to solve a computationally expensive ii regularized optimization problem to address this problem we propose a visual tracker based on non sparse linear representation which admit an efficient closed form solution without sacrificing accuracy moreover in order to capture the correlation information between different feature dimension we learn a mahalanobis distance metric in an online fashion and incorporate the learned metric into the optimization problem for obtaining the linear representation we show that online metric learning using proximity comparison significantly improves the robustness of the tracking especially on those sequence exhibiting drastic appearance change furthermore in order to prevent the unbounded growth in the number of training sample for the metric learning we design a time weighted reservoir sampling method to maintain and update limited sized foreground and background sample buffer for balancing sample diversity and adaptability experimental result on challenging video demonstrate the effectiveness and robustness of the proposed tracker 
we address the problem of long term object tracking where the object may become occluded or leave the view in this setting we show that an accurate appearance model is considerably more effective than a strong motion model we develop simple but effective algorithm that alternate between tracking and learning a good appearance model given a track we show that it is crucial to learn from the right frame and use the formalism of self paced curriculum learning to automatically select such frame we leverage technique from object detection for learning accurate appearance based template demonstrating the importance of using a large negative training set typically not used for tracking we describe both an offline algorithm that process frame in batch and a linear time on line i e causal algorithm that approach real time performance our model significantly outperform prior art reducing the average error on benchmark video by a factor of 
this paper present an approach for sequence alignment based on canonical correlation analysis cca we show that a novel set of constraint imposed on traditional cca lead to canonical solution with the time warping property i e non decreasing monotonicity in time this formulation generalizes the more traditional dynamic time warping dtw solution to case where the alignment is accomplished on arbitrary subsequence segment optimally determined from data instead on individual sequence sample we then introduce a robust and efficient algorithm to find such alignment using non negative least square reduction experimental result show that this new method when applied to mocap activity recognition problem can yield improved recognition accuracy 
the performance of state of the art image retrieval system using bag of word representation degrade quickly in the face image domain mainly because they produce visual word with low discriminative power and ignore the special property of face the leading feature for face recognition are not suitable for inverted indexing a they are high dimensional and global thus not scalable in either computational or storage cost in this paper we aim to build a scalable face image retrieval system for this purpose we develop a new scalable face representation using both local and global feature in the indexing stage we exploit special property of face to design new component based local feature which are subsequently quantized into visual word using a novel identity based quantization scheme we also use a small hamming signature to encode the discriminative global feature for each face in the retrieval stage candidate image are firstly retrieved from the inverted index of visual word we then use a new multi reference distance to re rank the candidate image using the hamming signature on a one millon face database we show that our local feature and global hamming signature are complementary x the inverted index based on local feature provides candidate image with good recall while the multi reference re ranking with global hamming signature lead to good precision 
generic imaging model can be used to represent any camera these model are specially suited for non central camera for which closed form model do not exist current model are discrete and define a mapping between each pixel in the image and a straight line in d space due to difficulty in the calibration procedure and model complexity these method have not been used in practice the focus of our work wa to relax these drawback in this paper we modify the general imaging model using radial basis function to interpolate image coordinate and d line allowing both an increase in resolution due to their continuous nature and a more compact representation using this new variation of the general imaging model we also develop a new linear calibration procedure in this process it is only required to match one d point to each image pixel also it is not required the calibration of every image pixel a a result the complexity of the procedure is significantly decreased 
we present a method for automatically extracting salient object from a single image which is cast in an energy minimization framework unlike most previous method that only leverage appearance cue we employ an auto context cue a a complementary data term benefitting from a generic saliency model for bootstrapping the segmentation of the salient object and the learning of the auto context model are iteratively performed without any user intervention upon convergence we obtain not only a clear separation of the salient object but also an auto context classifier which can be used to recognize the same type of object in other image our experiment on four benchmark demonstrated the efficacy of the added contextual cue it is shown that our method compare favorably with the state of the art some of which even embraced user interaction 
in this paper we propose a computational model of visual representative ness by integrating cognitive theory of representative ness heuristic with computer vision and machine learning technique unlike previous model that build their representative ness measure based on the visible data our model take the initial input a explicit positive reference and extend the measure by exploring the implicit negative given a group of image that contains obvious visual concept we create a customized image ontology consisting of both positive and negative instance by mining the most related and confusable neighbor of the positive concept in ontological semantic knowledge base the representative ness of a new item is then determined by it likelihood for both the positive and negative reference to ensure the effectiveness of probability inference a well a the cognitive plausibility we discover the potential prototype and treat them a an intermediate representation of semantic concept in the experiment we evaluate the performance of representative ness model based on both human judgement and user click log of commercial image search engine experimental result on both image net and image set of general concept demonstrate the superior performance of our model against the state of the art 
this paper introduces to use semi supervised learning for large scale image co segmentation different from traditional unsupervised cosegmentation that doe not use any segmentation ground truth semi supervised cosegmentation exploit the similarity from both the very limited training image foreground a well a the common object shared between the large number of unsegmented image this would be a much practical way to effectively co segment a large number of related image simultaneously where previous unsupervised co segmentation work poorly due to the large variance in appearance between different image and the lack of segmentation ground truth for guidance in co segmentation for semi supervised co segmentation in large scale we propose an effective method by minimizing an energy function which consists of the inter image distance the intra image distance and the balance term we also propose an iterative updating algorithm to efficiently solve this energy function which decomposes the original energy minimization problem into sub problem and update each image alternatively to reduce the number of variable in each sub problem for computation efficiency experiment result on icoseg and pascal voc datasets show that the proposed co segmentation method can effectively co segment hundred of image in le than one minute and our semi supervised co segmentation is able to outperform both unsupervised co segmentation a well a fully supervised single image segmentation especially when the training data is limited 
analyzing brain network from neuroimages is becoming a promising approach in identifying novel connectivity based biomarkers for the alzheimer s disease ad in this regard brain effective connectivity analysis which study the causal relationship among brain region is highly challenging and of many research opportunity most of the existing work in this field use generative method despite their success in data representation and other important merit generative method are not necessarily discriminative which may cause the ignorance of subtle but critical disease induced change in this paper we propose a learning based approach that integrates the benefit of generative and discriminative method to recover effective connectivity in particular we employ fisher kernel to bridge the generative model of sparse bayesian network sbn and the discriminative classifier of svms and convert the sbn parameter learning to fisher kernel learning via minimizing a generalization error bound of svms our method is able to simultaneously boost the discrimination power of both the generative sbn model and the sbn induced svm classifier via fisher kernel the proposed method is tested on analyzing brain effective connectivity for ad from adni data it demonstrates significant improvement over the state of the art classification accuracy increased above by our sbn model and above by our sbn induced svm classifier with a simple feature selection 
this paper proposes a new method for estimating the symmetric axis of a pottery from it small fragment using surface geometry for the automatic assembly of broken sherd the axis estimation is an important measure when a fragment is small it is difficult to estimate axis orientation since it look like a patch of a sphere and conventional method mostly fail but the proposed method provides reliable axis estimation by using multiple constraint the computational cost is also much lowered to estimate the symmetric axis the proposed algorithm us three constraint the curvature is constant on a circumference ch the curvature is invariant in any scale also the principal curvature doe not vary on ch ch is a planar circle which is one of all the possible circumference of a pottery or sherd a hypothesis test for axis is performed using maximum likelihood the variance of curvature multi scale curvature and principal curvature are computed in the likelihood function we also show that the principal curvature can be used for grouping of sherd the grouping of sherd will reduce the computation significantly by omitting impossible configuration in pottery assembly 
human face captured in real world condition present large variation in shape and occlusion due to difference in pose expression use of accessory such a sunglass and hat and interaction with object e g food current face landmark estimation approach struggle under such condition since they fail to provide a principled way of handling outlier we propose a novel method called robust cascaded pose regression rcpr which reduces exposure to outlier by detecting occlusion explicitly and using robust shape indexed feature we show that rcpr improves on previous landmark estimation method on three popular face datasets lfpw lfw and helen we further explore rcpr s performance by introducing a novel face dataset focused on occlusion composed of face presenting a wide range of occlusion pattern rcpr reduces failure case by half on all four datasets at the same time a it detects face occlusion with a precision recall 
we study the task of cleaning scanned text document that are strongly corrupted by dirt such a manual line stroke spilled ink etc we aim at autonomously removing dirt from a single letter size page based only on the information the page contains our approach therefore ha to learn character representation without supervision and requires a mechanism to distinguish learned representation from irregular pattern to learn character representation we use a probabilistic generative model parameterizing pattern feature feature variance the feature planar arrangement and pattern frequency the latent variable of the model describe pattern class pattern position and the presence or absence of individual pattern feature the model parameter are optimized using a novel variational em approximation after learning the parameter represent independently of their absolute position planar feature arrangement and their variance a quality measure defined based on the learned representation then allows for an autonomous discrimination between regular character pattern and the irregular pattern making up the dirt the irregular pattern can thus be removed to clean the document for a full latin alphabet we found that a single page doe not contain sufficiently many character example however even if heavily corrupted by dirt we show that a page containing a lower number of character type can efficiently and autonomously be cleaned solely based on the structural regularity of the character it contains in different example using character from different alphabet we demonstrate generality of the approach and discus it implication for future development 
the problem of simultaneous feature extraction and selection for classifier design is considered a new framework is proposed based on boosting algorithm that can either select existing feature or assemble a combination of these feature this framework is simple and mathematically sound derived from the statistical view of boosting and taylor series approximation in functional space unlike classical boosting which is limited to linear feature combination the new algorithm support more sophisticated combination of weak learner such a sum of product or product of sum this is shown to enable the design of fairly complex predictor structure with few weak learner in a fully automated manner leading to faster and more accurate classifier based on more informative feature extensive experiment on synthetic data uci datasets object detection and scene recognition show that these predictor consistently lead to more accurate classifier than classical boosting algorithm 
we introduce a fast deformable spatial pyramid dsp matching algorithm for computing dense pixel correspondence dense matching method typically enforce both appearance agreement between matched pixel a well a geometric smoothness between neighboring pixel whereas the prevailing approach operate at the pixel level we propose a pyramid graph model that simultaneously regularizes match consistency at multiple spatial extent ranging from an entire image to coarse grid cell to every single pixel this novel regularization substantially improves pixel level matching in the face of challenging image variation while the deformable aspect of our model overcomes the strict rigidity of traditional spatial pyramid result on label me and caltech show our approach outperforms state of the art method sift flow and patch match both in term of accuracy and run time 
late fusion address the problem of combining the prediction score of multiple classifier in which each score is predicted by a classifier trained with a specific feature however the existing method generally use a fixed fusion weight for all the score of a classifier and thus fail to optimally determine the fusion weight for the individual sample in this paper we propose a sample specific late fusion method to address this issue specifically we cast the problem into an information propagation process which propagates the fusion weight learned on the labeled sample to individual unlabeled sample while enforcing that positive sample have higher fusion score than negative sample in this process we identify the optimal fusion weight for each sample and push positive sample to top position in the fusion score rank list we formulate our problem a a l norm constrained optimization problem and apply the alternating direction method of multiplier for the optimization extensive experiment result on various visual categorization task show that the proposed method consistently and significantly beat the state of the art late fusion method to the best knowledge this is the first method supporting sample specific fusion weight learning 
in this paper we propose a novel depth measurement method by fusing depth from defocus dfd and stereo one of the problem of passive stereo method is the difficulty of finding correct correspondence between image when an object ha a repetitive pattern or edge parallel to the epipolar line on the other hand the accuracy of dfd method is inherently limited by the effective diameter of the lens therefore we propose the fusion of stereo method and dfd by giving different focus distance for left and right camera of a stereo camera with coded aperture two type of depth cue defocus and disparity are naturally integrated by the magnification and phase shift of a single point spread function psf per camera in this paper we give the proof of the proportional relationship between the diameter of defocus and disparity which make the calibration easy we also show the outstanding performance of our method which ha both advantage of two depth cue through simulation and actual experiment 
d model based object recognition ha been a noticeable research trend in recent year common method find d to d correspondence and make recognition decision by pose estimation whose efficiency usually suffers from noisy correspondence caused by the increasing number of target object to overcome this scalability bottleneck we propose an efficient d to d correspondence filtering approach which combine a light weight neighborhood based step with a finer grained pairwise step to remove spurious correspondence based on d d geometric cue on a dataset of d object our solution achieves time speed improvement over the baseline with a comparable recognition accuracy a parallel implementation on a quad core cpu can run at fps for image 
we present a generic efficient and iterative algorithm for interactively clustering class of image and video the approach move away from the use of large hand labelled training datasets instead allowing the user to find natural group of similar content based upon a handful of seed example two efficient data mining tool originally developed for text analysis min hash and apriori are used and extended to achieve both speed and scalability on large image and video datasets inspired by the bag of word bow architecture the idea of an image signature is introduced a a simple descriptor on which nearest neighbour classification can be performed the image signature is then dynamically expanded to identify common feature amongst sample of the same class the iterative approach us apriori to identify common and distinctive element of a small set of labelled true and false positive signature these element are then accentuated in the signature to increase similarity between example and pull positive class together by repeating this process the accuracy of similarity increase dramatically despite only a few training example only of the labelled groundtruth is needed compared to other approach it is tested on two image datasets including the caltech dataset and on three state of the art action recognition datasets on the youtube video dataset the accuracy increase from to using only labelled example from a dataset of over video the approach is both scalable and efficient with an iteration on the full youtube dataset taking around minute on a standard desktop machine 
the selection of optimal camera configuration camera location orientation etc for multi camera network remains an unsolved problem previous approach largely focus on proposing various objective function to achieve different task most of them however do not generalize well to large scale network to tackle this we introduce a statistical formulation of the optimal selection of camera configuration a well a propose a trans dimensional simulated annealing tdsa algorithm to effectively solve the problem we compare our approach with a state of the art method based on binary integer programming bip and show that our approach offer similar performance on small scale problem however we also demonstrate the capability of our approach in dealing with large scale problem and show that our approach produce better result than alternative heuristic designed to deal with the scalability issue of bip 
the majority of existing pedestrian tracker concentrate on maintaining the identity of target however system for remote biometric analysis or activity recognition in surveillance video often require stable bounding box around pedestrian rather than approximate location we present a multi target tracking system that is designed specifically for the provision of stable and accurate head location estimate by performing data association over a sliding window of frame we are able to correct many data association error and fill in gap where observation are missed the approach is multi threaded and combine asynchronous hog detection with simultaneous klt tracking and markov chain monte carlo data association mcm cda to provide guaranteed real time tracking in high definition video where previous approach have used ad hoc model for data association we use a more principled approach based on a minimal description length mdl objective which accurately model the affinity between observation we demonstrate by qualitative and quantitative evaluation that the system is capable of providing precise location estimate for large crowd of pedestrian in real time to facilitate future performance comparison we make a new dataset with hand annotated ground truth head location publicly available 
the earth mover s distance emd is an intuitive and natural distance metric for comparing two histogram or probability distribution it provides a distance value a well a a flow network indicating how the probability mass is optimally transported between the bin in traditional emd the ground distance between the bin is pre defined instead we propose to jointly optimize the ground distance matrix and the emd flow network based on a partial ordering of histogram distance in an optimization framework our method is further extended to accept information from general labeled pair the trained ground distance better reflects the cross bin relationship hence produce more accurate emd value and flow network two computer vision application are used to demonstrate the effectiveness of the algorithm first we apply the optimized emd value to face verification and achieve state of the art performance on the pubfig and the lfw data set second the learned emd flow network is used to analyze face attribute change obtaining consistent path that demonstrate intuitive transition on certain facial attribute 
image cropping is a common operation used to improve the visual quality of photograph in this paper we present an automatic cropping technique that account for the two primary consideration of people when they crop removal of distracting content and enhancement of overall composition our approach utilizes a large training set consisting of photo before and after cropping by expert photographer to learn how to evaluate these two factor in a crop in contrast to the many method that exist for general assessment of image quality ours specifically examines difference between the original and cropped photo in solving for the crop parameter to this end several novel image feature are proposed to model the change in image content and composition when a crop is applied our experiment demonstrate improvement of our method over recent cropping algorithm on a broad range of image 
this paper address the discovery of activity and learns the underlying process that govern their occurrence over time in complex surveillance scene to this end we propose a novel topic model that account for the two main factor that affect these occurrence the existence of global scene state that regulate which of the activity can spontaneously occur local rule that link past activity occurrence to current one with temporal lag these complementary factor are mixed in the probabilistic generative process thanks to the use of a binary random variable that selects for each activity occurrence which one of the above two factor is applicable all model parameter are efficiently inferred using a collapsed gibbs sampling inference scheme experiment on various datasets from the literature show that the model is able to capture temporal process at multiple scale the scene level first order markovian process and causal relationship amongst activity that can be used to predict which activity can happen after another one and after what delay thus providing a rich interpretation of the scene s dynamical content 
we present a novel framework to estimate detailed shape of diffuse object with uniform albedo from a single rgb d image to estimate accurate lighting in natural illumination environment we introduce a general lighting model consisting of two component global and local model the global lighting model is estimated from the rgb d input using the low dimensional characteristic of a diffuse reflectance model the local lighting model represents spatially varying illumination and it is estimated by using the smoothly varying characteristic of illumination with both the global and local lighting model we can estimate complex lighting variation in uncontrolled natural illumination condition accurately for high quality shape capture a shape from shading approach is applied with the estimated lighting model since the entire process is done with a single rgb d input our method is capable of capturing the high quality shape detail of a dynamic object under natural illumination experimental result demonstrate the feasibility and effectiveness of our method that dramatically improves shape detail of the rough depth input 
local photometric descriptor are a crucial low level component of numerous computer vision algorithm in practice these descriptor are constructed to be invariant to a class of transformation however the development of a descriptor that is simultaneously robust to noise and invariant under general deformation ha proven difficult in this paper we introduce the topological attributed relational graph t arg a new local photometric descriptor constructed from homology that is provably invariant to locally bounded deformation this new robust topological descriptor is backed by a formal mathematical framework we apply t arg to a set of benchmark image to evaluate it performance result indicate that t arg significantly outperforms traditional descriptor for noisy deforming image 
we address the problem of recovering camera motion from video data which doe not require the establishment of feature correspondence or computation of optical flow but from normal flow directly we have designed an imaging system that ha a wide field of view by fixating a number of camera together to form an approximate spherical eye with a substantially widened visual field we discover that estimating the direction of translation and rotation component of the motion separately are possible and particularly efficient in addition the inherent ambiguity between translation and rotation also disappear magnitude of rotation is recovered subsequently experimental result on synthetic and real image data are provided the result show that not only the accuracy of motion estimation is comparable to those of the state of the art method that require explicit feature correspondence or optical flow but also a faster computation time 
this paper considers the problem of finding low order nonlinear embeddings of dynamic data that is data characterized by a temporal ordering example where this problem arises include among others appearance based multi frame tracking activity recognition from video and dynamic texture analysis synthesis our main result is a semi definite programming based manifold embedding algorithm that exploit the dynamical information encapsulated in the temporal ordering of the sequence to obtain embeddings with lower complexity that those produced by existing algorithm at a comparable computational cost in addition the use of spatio temporal information allows for minimizing the effect of outlier on the manifold structure and for handling fragmented sequence where some of the data is missing for instance due to occlusion 
we present a novel method for translational symmetry detection optimization and symmetry object segmentation in fa ade image unlike most previous method our detection algorithm accumulates pixel level correspondence in translation space thus it doe not rely on feature point detection and handle pattern with low repetition count to improve the robustness with multiple interfering symmetry we introduce an image space global optimization which resolve multiple per pixel symmetry lattice we then propose a learning based method that generates refined segmentation of foreground symmetry object of arbitrary shape with the aid of the per pixel symmetry information our proposed method is accurate robust and efficient a demonstrated by an extensive evaluation using a large fa ade image database 
we address action recognition in video by modeling the spatial temporal structure of human pose we start by improving a state of the art method for estimating human joint location from video more precisely we obtain the k best estimation output by the existing method and incorporate additional segmentation cue and temporal constraint to select the best one then we group the estimated joint into five body part e g the left arm and apply data mining technique to obtain a representation for the spatial temporal structure of human action this representation capture the spatial configuration of body part in one frame by spatial part set a well a the body part movement by temporal part set which are characteristic of human action it is interpretable compact and also robust to error on joint estimation experimental result first show that our approach is able to localize body joint more accurately than existing method next we show that it outperforms state of the art action recognizers on the ucf sport the keck gesture and the msr action d datasets 
local classifier have obtained great success in classification task due to it powerful discriminating ability on local region however most of them still have restricted generalization in twofold each local classifier is sensitive to noise in local region which lead to overfitting phenomenon in local classifier the local classifier also ignore the local correlation determined by the sample distribution in each local region to overcome the above two problem we present a novel locality sensitive support vector machine lssvm in this paper for image retrieval problem this classifier applies locality sensitive hashing lsh to divide the whole feature space into a number of local region on each of them a local model can be better constructed due to smaller within class variation on it to avoid these local model from overfitting into locality sensitive structure it imposes a global regularizer across local region so that local classifier are smoothly glued together to form a regularized overall classifier local correlation is modeled to capture the sample distribution that determines the locality structure of each local region which can increase the discriminating ability of the algorithm to evaluate the performance we apply the proposed algorithm into image retrieval task and competitive result are obtained on the real world web image data set 
in real world application what you saw during training is often not what you get during deployment the distribution and even the type and dimensionality of feature can change from one dataset to the next in this paper we address the problem of visual domain adaptation for transferring object model from one dataset or visual domain to another we introduce arc t a flexible model for supervised learning of non linear transformation between domain our method is based on a novel theoretical result demonstrating that such transformation can be learned in kernel space unlike existing work our model is not restricted to symmetric transformation nor to feature of the same type and dimensionality making it applicable to a significantly wider set of adaptation scenario than previous method furthermore the method can be applied to category that were not available during training we demonstrate the ability of our method to adapt object recognition model under a variety of situation such a differing imaging condition feature type and codebooks 
boosting is a well known machine learning technique used to improve the performance of weak learner and ha been successfully applied to computer vision medical image analysis computational biology and other field a critical step in boosting algorithm involves update of the data sample distribution however most existing boosting algorithm use updating mechanism that lead to overfitting and instability during evolution of the distribution which in turn result in classification inaccuracy regularized boosting ha been proposed in literature a a mean to overcome these difficulty in this paper we propose a novel total bregman divergence tbd regularized lpboost termed tbrlpboost tbd is a recently proposed divergence in literature which is statistically robust and we prove that tbrlpboost requires a constant number of iteration to learn a strong classifier and hence is computationally more efficient compared to other regularized boosting algorithm also unlike other boosting method that are only effective on a handful of datasets tbrlpboost work well on a variety of datasets we present result of testing our algorithm on many public domain database and comparison to several other state of the art method numerical result show that the proposed algorithm ha much improved performance in efficiency and accuracy over other method 
in this paper we address the problem of using boosting e g adaboost to classify a target class with significant intra class variation against a large background class this situation occurs for example when we want to recognize a visual object class against all other image patch the boosting algorithm produce a strong classifier which is a linear combination of weak classifier we observe that we often have set of weak classifier that individually fire on many example of the target class but never fire together on those example i e their output are anti correlated on the target class motivated by this observation we suggest a family of derived weak classifier termed gated classifier that suppress such combination of weak classifier gated classifier can be used on top of any original weak learner we run experiment on two popular datasets showing that our method reduces the required number of weak classifier by almost an order of magnitude which in turn yield faster detector we experiment on synthetic data showing that gated classifier enables more complex distribution to be represented we hope that gated classifier will extend the usefulness of boosted classifier cascade 
how hard are geometric vision problem with outlier we show that for most fitting problem a solution that minimizes the number of outlier can be found with an algorithm that ha polynomial time complexity in the number of point independent of the rate of outlier further and perhaps more interestingly other cost function such a the truncated l norm can also be handled within the same framework with the same time complexity we apply our framework to triangulation relative pose problem and stitching and give several other example that fulfill the required condition based on efficient polynomial equation solver it is experimentally demonstrated that these problem can be solved reliably in particular for low dimensional model comparison to standard random sampling solver are also given 
the objective of this work is object retrieval in large scale image datasets where the object is specified by an image query and retrieval should be immediate at run time in the manner of video google we make the following three contribution i a new method to compare sift descriptor rootsift which yield superior performance without increasing processing or storage requirement ii a novel method for query expansion where a richer model for the query is learnt discriminatively in a form suited to immediate retrieval through efficient use of the inverted index iii an improvement of the image augmentation method proposed by turcot and lowe where only the augmenting feature which are spatially consistent with the augmented image are kept we evaluate these three method over a number of standard benchmark datasets oxford building k and k and paris k and demonstrate substantial improvement in retrieval performance whilst maintaining immediate retrieval speed combining these complementary method achieves a new state of the art performance on these datasets 
in this paper a novel approach based on a non linear manifold learning technique is proposed to recover d non rigid structure from d image sequence captured by a single camera most of the existing approach assume that d shape can be accurately modelled in a linear subspace these technique perform well when the deformation are relatively small or simple but fail when more complex deformation need to be recovered the non linear deformation are often observed in highly flexible object for which the use of the linear model is impractical a specific type of shape variation might be governed by only a small number of parameter therefore can be well represented in a low dimensional manifold we learn a non linear shape prior using diffusion map method the key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shape to lie in the learned manifold the proposed methodology ha been validated quantitatively and qualitatively on d point sequence projected from the d motion capture data and real d video sequence the comparison of the proposed manifold based method against several state of the art technique are shown on different type of deformable object 
in this paper we investigate the property of lp norm p within a projection framework we start with the kkt equation of the non linear optimization problem and then use it key property to arrive at an algorithm for lp norm projection on the non negative simplex we compare with l projection which need prior knowledge of the true norm a well a hard thresholding based sparsification proposed in recent compressed sensing literature we show performance improvement compared to these technique across different vision application 
in this paper we raise important issue concerning the evaluation complexity of existing mahalanobis metric learning method the complexity scale linearly with the size of the dataset this is especially cumbersome on large scale or for real time application with limited time budget to alleviate this problem we propose to represent the dataset by a fixed number of discriminative prototype in particular we introduce a new method that jointly chooses the positioning of prototype and also optimizes the mahalanobis distance metric with respect to these we show that choosing the positioning of the prototype and learning the metric in parallel lead to a drastically reduced evaluation effort while maintaining the discriminative essence of the original dataset moreover for most problem our method performing k nearest prototype k np classification on the condensed dataset lead to even better generalization compared to k nn classification using all data result on a variety of challenging benchmark demonstrate the power of our method these include standard machine learning datasets a well a the challenging public figure face database on the competitive machine learning benchmark we are comparable to the state of the art while being more efficient on the face benchmark we clearly outperform the state of the art in mahalanobis metric learning with drastically reduced evaluation effort 
most image understanding algorithm begin with the extraction of information thought to be relevant to the particular task this is commonly known a feature extraction and ha up to this date been a largely manual process where a reasonable method is chosen through validation on the experimented dataset in this work we propose a data driven local histogram based feature extraction method that reduces the manual intervention during the feature computation process and improves on the performance of widely used gradient histogram based feature e g hog we demonstrate favorable object detection result against hog on the inria pedestrian pascal data 
in many vision problem rotation invariant analysis is necessary or preferred popular solution are mainly based on pose normalization or brute force learning neglecting the intrinsic property of rotation in this paper we present a rotation invariant detection approach built on the equivariant filter framework with a new model for learning the filtering behavior the special property of the harmonic basis which is related to the irreducible representation of the rotation group directly guarantee rotation invariance of the whole approach the proposed kernel weighted mapping ensures high learning capability while respecting the invariance constraint we demonstrate it performance on d object detection with in plane rotation and a d application on rotation invariant landmark detection in microscopic volumetric data 
discovering object class from image in a fully unsupervised way is an intrinsically ambiguous task saliency detection approach however ease the burden on unsupervised learning we develop an algorithm for simultaneously localizing object and discovering object class via bottom up saliency guided multiple class learning bmcl and make the following contribution saliency detection is adopted to convert unsupervised learning into multiple instance learning formulated a bottom up multiple class learning bmcl we utilize the discriminative em discem to solve our bmcl problem and show discem s connection to the mil boost method localizing object discovering object class and training object detector are performed simultaneously in an integrated framework significant improvement over the existing method for multi class object discovery are observed in addition we show single class localization a a special case in our bmcl framework and we also demonstrate the advantage of bmcl over purely data driven saliency method 
the bounding box representation employed by many popular object detection model implicitly assumes all pixel inside the box belong to the object this assumption make this representation le robust to the object with occlusion in this paper we augment the bounding box with a set of binary variable each of which corresponds to a cell indicating whether the pixel in the cell belong to the object this segmentation aware representation explicitly model and account for the supporting pixel for the object within the bounding box thus more robust to occlusion we learn the model in a structured output framework and develop a method that efficiently performs both inference and learning using this rich representation the method is able to use segmentation reasoning to achieve improved detection result with richer output cell level segmentation on the street scene and pascal voc datasets finally we present a globally coherent object model using our rich representation to account for object object occlusion resulting in a more coherent image understanding 
the objective of this paper is the unsupervised segmentation of image training set into foreground and background in order to improve image classification performance to this end we introduce a new scalable alternation based algorithm for co segmentation bicos which is simpler than many of it predecessor and yet ha superior performance on standard benchmark image datasets 
online learned tracking is widely used for it s adaptive ability to handle appearance change however it introduces potential drifting problem due to the accumulation of error during the self updating especially for occluded scenario the recent literature demonstrates that appropriate combination of tracker can help balance stability and flexibility requirement we have developed a robust tracking algorithm using a local sparse appearance model spt a static sparse dictionary and a dynamically online updated basis distribution model the target appearance a novel sparse representation based voting map and sparse constraint regularized mean shift support the robust object tracking besides these contribution we also introduce a new dictionary learning algorithm with a locally constrained sparse representation called k selection based on a set of comprehensive experiment our algorithm ha demonstrated better performance than alternative reported in the recent literature 
the realization that we see line known to be parallel in space a line that appear to converge in a corresponding vanishing point ha led to technique employed by artist since at least the renaissance to render a credible impression of perspective more recently it ha also led to technique for recovering information embedded in image pertaining to the geometry of their underlying scene in this paper we explore the extraction of vanishing point in the aim of facilitating the reconstruction of manhattan world scene in departure from most vanishing point extraction method ours extract a constellation of vanishing point corresponding respectively to the scene s two or three dominant pairwise orthogonal orientation by integrating information across multiple view rather than from a single image alone what make a multiple view approach attractive is that in addition to increasing robustness to segment that do not correspond to any of the three dominant orientation robustness is also increased with respect to inaccuracy in the extracted segment themselves 
current landmark recognition engine are typically aimed at recognizing building scale landmark but miss interesting detail like portal statue or window this is because they use a flat clustering that summarizes all photo of a building facade in one cluster we propose hierarchical iconoid shift a novel landmark clustering algorithm capable of discovering such detail instead of just a collection of cluster the output of his is a set of dendrograms describing the detail hierarchy of a landmark his is based on the novel hierarchical medoid shift clustering algorithm that performs a continuous mode search over the complete scale space hm is completely parameter free ha the same complexity a medoid shift and is easy to parallelize we evaluate his on k image of landmark and show that it can extract an often surprising amount of detail and structure that can be applied e g to provide a mobile user with more detailed information on a landmark or even to extend the landmark s wikipedia article 
recognizing human activity in partially observed video is a challenging problem and ha many practical application when the unobserved subsequence is at the end of the video the problem is reduced to activity prediction from unfinished activity streaming which ha been studied by many researcher however in the general case an unobserved subsequence may occur at any time by yielding a temporal gap in the video in this paper we propose a new method that can recognize human activity from partially observed video in the general case specifically we formulate the problem into a probabilistic framework dividing each activity into multiple ordered temporal segment using spatiotemporal feature of the training video sample in each segment a base and applying sparse coding sc to derive the activity likelihood of the test video sample at each segment and finally combining the likelihood at each segment to achieve a global posterior for the activity we further extend the proposed method to include more base that correspond to a mixture of segment with different temporal length mssc which can better represent the activity with large intra class variation we evaluate the proposed method sc and mssc on various real video we also evaluate the proposed method on two special case activity prediction where the unobserved subsequence is at the end of the video and human activity recognition on fully observed video experimental result show that the proposed method outperform existing state of the art comparison method 
most of the current metric learning method are proposed for point to point distance ppd based classification in many computer vision task however we need to measure the point to set distance psd and even set to set distance ssd for classification in this paper we extend the ppd based mahalanobis distance metric learning to psd and ssd based one namely point to set distance metric learning psdml and set to set distance metric learning ssdml and solve them under a unified optimization framework first we generate positive and negative sample pair by computing the psd and ssd between training sample then we characterize each sample pair by it covariance matrix and propose a covariance kernel based discriminative function finally we tackle the psdml and ssdml problem by using standard support vector machine solver making the metric learning very efficient for multiclass visual classification task experiment on gender classification digit recognition object categorization and face recognition show that the proposed metric learning method can effectively enhance the performance of psd and ssd based classification 
in this paper we present an event parsing algorithm based on stochastic context sensitive grammar scsg for understanding event inferring the goal of agent and predicting their plausible intended action the scsg represents the hierarchical composition of event and the temporal relation between the sub event the alphabet of the scsg are atomic action which are defined by the pose of agent and their interaction with object in the scene the temporal relation are used to distinguish event with similar structure interpolate missing portion of event and are learned from the training data in comparison with existing method our paper make the following contribution i we define atomic action by a set of relation based on the fluents of agent and their interaction with object in the scene ii our algorithm handle event insertion and multi agent event keep all possible interpretation of the video to preserve the ambiguity and achieves the globally optimal parsing solution in a bayesian framework iii the algorithm infers the goal of the agent and predicts their intent by a top down process iv the algorithm improves the detection of atomic action by event context we show satisfactory result of event recognition and atomic action detection on the data set we captured which contains event category in both indoor and outdoor video 
for object recognition the current state of the art is based on exhaustive search however to enable the use of more expensive feature and classifier and thereby progress beyond the state of the art a selective search strategy is needed therefore we adapt segmentation a a selective search by reconsidering segmentation we propose to generate many approximate location over few and precise object delineation because an object whose location is never generated can not be recognised and appearance and immediate nearby context are most effective for object recognition our method is class independent and is shown to cover of all object in the pascal voc test set using only location per image our selective search enables the use of the more expensive bag of word method which we use to substantially improve the state of the art by up to for out of class on the pascal voc detection challenge 
it is known that purely low level saliency cue such a frequency doe not lead to a good salient object detection result requiring high level knowledge to be adopted for successful discovery of task independent salient object in this paper we propose an efficient way to combine such high level saliency prior and low level appearance model we obtain the high level saliency prior with the objectness algorithm to find potential object candidate without the need of category information and then enforce the consistency among the salient region using a gaussian mrf with the weight scaled by diverse density that emphasizes the influence of potential foreground pixel our model obtains saliency map that assign high score for the whole salient object and achieves state of the art performance on benchmark datasets covering various foreground statistic 
this paper present a novel and generic approach for metric learning random ensemble metric remetric to improve generalization performance we introduce the concept of ensemble learning to the metric learning scheme unlike previous method our method doe not optimize the global objective function for the whole training data it learns multiple discriminative projection vector obtained from linear support vector machine svm using randomly subsampled training data the final metric matrix is then obtained by integrating these vector a a result of using svm the learned metric ha an excellent scalability for the dimensionality of feature therefore it doe not require any prior dimensionality reduction technique such a pca moreover our method allows u to unify dimensionality reduction and metric learning by controlling the number of the projection vector we demonstrate through experiment that our method can avoid overfitting even though a relatively small number of training data is provided the experiment are performed with three different datasets the viewpoint invariant pedestrian recognition viper dataset the labeled face in the wild lfw dataset and the oxford category flower dataset the result show that our method achieves equivalent or superior performance compared to existing state of the art metric learning method 
face verification involves determining whether a pair of facial image belongs to the same or different subject this problem can prove to be quite challenging in many important application where labeled training data is scarce e g family album photo organization software herein we propose a principled transfer learning approach for merging plentiful source domain data with limited sample from some target domain of interest to create a classifier that ideally performs nearly a well a if rich target domain data were present based upon a surprisingly simple generative bayesian model our approach combine a kl divergence based regularizer prior with a robust likelihood function leading to a scalable implementation via the em algorithm a justification for our design choice we later use principle from convex analysis to recast our algorithm a an equivalent structured rank minimization problem leading to a number of interesting insight related to solution structure and feature transform invariance these insight help to both explain the effectiveness of our algorithm a well a elucidate a wide variety of related bayesian approach experimental testing with challenging datasets validate the utility of the proposed algorithm 
estimating a dense correspondence field between successive video frame under large displacement is important in many visual learning and recognition task we propose a novel sparse to dense matching method for motion field estimation and occlusion detection a an alternative to the current coarse to fine approach from the optical flow literature we start from the higher level of sparse matching with rich appearance and geometric constraint collected over extended neighborhood using an occlusion aware locally affine model then we move towards the simpler but denser classic flow field model with an interpolation procedure that offer a natural transition between the sparse and the dense correspondence field we experimentally demonstrate that our appearance feature and our complex geometric constraint permit the correct motion estimation even in difficult case of large displacement and significant appearance change we also propose a novel classification method for occlusion detection that work in conjunction with the sparse to dense matching model we validate our approach on the newly released sintel dataset and obtain state of the art result 
recent year have witnessed the success of large scale image classification system that are able to identify object among thousand of possible label however it is yet unclear how general classifier such a one trained on image net can be optimally adapted to specific task each of which only cover a semantically related subset of all the object in the world it is inefficient and sub optimal to retrain classifier whenever a new task is given and is inapplicable when task are not given explicitly but implicitly specified a a set of image query in this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a linear time probabilistic inference algorithm given a set of query image from a latent task we present efficient way to estimate parameter for the model and an open source toolbox to train classifier distributedly at a large scale empirical result based on the image net data showed significant performance increase over several baseline algorithm 
we introduce a robust estimator called generalized projection based m estimator gpbm which doe not require the user to specify any scale parameter for multiple inlier structure with different noise covariance the estimator iteratively determines one inlier structure at a time unlike pbm where the scale of the inlier noise is estimated simultaneously with the model parameter gpbm ha three distinct stage scale estimation robust model estimation and inlier outlier dichotomy we evaluate our performance on challenging synthetic data face image clustering upto ten different face from yale face database b and multi body projective motion segmentation problem on hopkins dataset result of state of the art method are presented for comparison 
one of the challenge in radiotherapy of moving tumor is to determine the location of the tumor accurately existing solution to the problem are either invasive or inaccurate we introduce a non invasive solution to the problem by tracking the tumor in d using bi plane ultrasound image sequence we present crosstrack a novel tracking algorithm in this framework we pose the problem a recursive inference of d location and tumor boundary segmentation in the two ultrasound view using the tumor d model a a prior for the segmentation task a robust graph based approach is deployed a follows first robust segmentation prior are obtained through the tumor d model second a unified graph combining information across time and multiple view is constructed with a robust weighting function for the tracking task an effective mechanism for recovery from respiration induced occlusion is introduced our experiment show the robustness of crosstrack in handling challenging tumor shape and disappearance scenario with sub voxel accuracy and almost precision and recall significantly outperforming baseline solution 
we address the problem of detecting action such a drinking or opening a door in hour of challenging video data we propose a model based on a sequence of atomic action unit termed actoms that are characteristic for the action our model represents the temporal structure of action a a sequence of histogram of actom anchored visual feature our representation which can be seen a a temporally structured extension of the bag of feature is flexible sparse and discriminative we refer to our model a actom sequence model asm training requires the annotation of actoms for action clip at test time actoms are detected automatically based on a non parametric model of the distribution of actoms which also act a a prior on an action s temporal structure we present experimental result on two recent benchmark for temporal action detection coffee and cigarette and the dataset of we show that our asm method outperforms the current state of the art in temporal action detection 
graph matching is widely used in a variety of scientific field including computer vision due to it powerful performance robustness and generality it computational complexity however limit the permissible size of input graph in practice therefore in real world application the initial construction of graph to match becomes a critical factor for the matching performance and often lead to unsatisfactory result in this paper to resolve the issue we propose a novel progressive framework which combine probabilistic progression of graph with matching of graph the algorithm efficiently re estimate in a bayesian manner the most plausible target graph based on the current matching result and guarantee to boost the matching objective at the subsequent graph matching experimental evaluation demonstrates that our approach effectively handle the limit of conventional graph matching and achieves significant improvement in challenging image matching problem 
we address the problem of estimating the latent image of a static bilayer scene consisting of a foreground and a background at different depth from motion blurred observation captured with a handheld camera the camera motion is considered to be composed of in plane rotation and translation since the blur at an image location depends both on camera motion and depth deblurring becomes a difficult task we initially propose a method to estimate the transformation spread function tsf corresponding to one of the depth layer the estimated tsf which reveals the camera motion during exposure is used to segment the scene into the foreground and background layer and determine the relative depth value the deblurred image of the scene is finally estimated within a regularization framework by accounting for blur variation due to camera motion a well a depth 
in this paper we present a new method for facial age estimation based on ordinal discriminative feature learning considering the temporally ordinal and continuous characteristic of aging process the proposed method not only aim at preserving the local manifold structure of facial image but also it want to keep the ordinal information among aging face moreover we try to remove redundant information from both the locality information and ordinal information a much a possible by minimizing nonlinear correlation and rank correlation finally we formulate these two issue into a unified optimization problem of feature selection and present an efficient solution the experiment are conducted on the public available image of group dataset and the fg net dataset and the experimental result demonstrate the power of the proposed method against the state of the art method 
in this paper we present an analytical method for computing the globally optimal estimate of orthogonal vanishing point in a manhattan world with a calibrated camera we formulate this a constrained least square problem whose optimality condition form a multivariate polynomial system we solve this system analytically to compute all the critical point of the least square cost function and hence the global minimum i e the globally optimal estimate for the orthogonal vanishing point the same optimal estimator is used in conjunction with ransac to generate orthogonal vanishing point hypothesis from triplet of line and thus classify line into parallel and mutually orthogonal group the proposed method is validated experimentally on the york urban database 
we present a novel framework for creating and ranking plausible object hypothesis in an image using bottom up generation process and mid level selection cue the object hypothesis are represented a figure ground segmentation and are extracted automatically without prior knowledge about the property of individual object class by solving a sequence of constrained parametric min cut problem cpmc on a regular image grid in a subsequent step we learn to rank the corresponding segment by training a continuous model to predict their plausibility putative overlap with ground truth based on their mid level region property then diversify the estimated overlap using maximum marginal relevance measure we show that this algorithm significantly outperforms the state of the art for low level segmentation in the voc and datasets it achieves the same average best segmentation covering on voc a the best performing technique to date when using just the top ranked segment instead of the full hierarchy in our method achieves average best covering using segment an extended version of the basic algorithm achieves average per class object recall using segment per image on the voc segmentation dataset 
shadow the common phenomenon in most outdoor scene are illuminated by diffuse skylight whereas shaded from direct sunlight generally shadow take place in sunny weather when the spectral power distribution spd of sunlight skylight and daylight show strong regularity they principally vary with sun angle in this paper we first deduce that the pixel value of a surface illuminated by skylight in shadow region and by daylight in non shadow region have a linear relationship and the linearity is independent of surface reflectance and hold in each color channel we then use six simulated image that contain surface and two real captured image to test the linearity the result validate the linearity based on the deduced linear relationship we develop three shadow processing application include intrinsic image deriving shadow verification and shadow removal the result of the application demonstrate that the linear relationship have practical value 
we present a bottom up aggregation approach to image segmentation beginning with an image we execute a sequence of step in which pixel are gradually merged to produce larger and larger region in each step we consider pair of adjacent region and provide a probability measure to ass whether or not they should be included in the same segment our probabilistic formulation take into account intensity and texture distribution in a local area around each region it further incorporates prior based on the geometry of the region finally posterior based on intensity and texture cue are combined using a mixture of expert formulation this probabilistic approach is integrated into a graph coarsening scheme providing a complete hierarchical segmentation of the image the algorithm complexity is linear in the number of the image pixel and it requires almost no user tuned parameter in addition we provide a novel evaluation scheme for image segmentation algorithm attempting to avoid human semantic consideration that are out of scope for segmentation algorithm using this novel evaluation scheme we test our method and provide a comparison to several existing segmentation algorithm 
we present a novel method to separate specular reflection from a single image separating an image into diffuse and specular component is an ill posed problem due to lack of observation existing method rely on a specular free image to detect and estimate specularity which however may confuse diffuse pixel with the same hue but a different saturation value a specular pixel our method is based on a novel observation that for most natural image the dark channel can provide an approximate specular free image we also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue saturation ambiguity we demonstrate the effectiveness of the proposed algorithm on real and synthetic example experimental result show that our method significantly outperforms the state of the art method in separating specular reflection 
existing approach to indoor scene understanding formulate the problem a a structured prediction task focusing on estimating the d bounding box which best describes the scene layout unfortunately these approach utilize high order potential which are computationally intractable and rely on ad hoc approximation for both learning and inference in this paper we show that the potential commonly used in the literature can be decomposed into pair wise potential by extending the concept of integral image to geometry a a consequence no heuristic reduction of the search space is required in practice this result in large improvement in performance over the state of the art while being order of magnitude faster 
we introduce a computationally efficient algorithm for multi object tracking by detection that address four main challenge appearance similarity among target missing data due to target being out of the field of view or occluded behind other object crossing trajectory and camera motion the proposed method us motion dynamic a a cue to distinguish target with similar appearance minimize target mi identification and recover missing data computational efficiency is achieved by using a generalized linear assignment gla coupled with efficient procedure to recover missing data and estimate the complexity of the underlying dynamic the proposed approach work with track let of arbitrary length and doe not assume a dynamical model a priori yet it capture the overall motion dynamic of the target experiment using challenging video show that this framework can handle complex target motion non stationary camera and long occlusion on scenario where appearance cue are not available or poor 
in this paper we develop a generative model to describe the layout of outdoor scene the spatial configuration of region specifically the layout of an image is represented a a composite of region each associated with a semantic topic at the heart of this model is a novel stochastic process called spatial topic process which generates a spatial map of topic from a set of coupled gaussian process thus allowing the distribution of topic to vary continuously across the image plane a key aspect that distinguishes this model from previous one consists in it capability of capturing dependency across both location and topic while allowing substantial variation in the layout we demonstrate the practical utility of the proposed model by testing it on scene classification semantic segmentation and layout hallucination 
we present a robust method for modeling city from unstructured point data our algorithm provides a more complete description than existing approach by reconstructing simultaneously building tree and topologically complex ground building are modeled by an original approach which guarantee a high generalization level while having semantized and compact representation geometric d primitive such a plane cylinder sphere or cone describe regular roof section and are combined with mesh patch that represent irregular roof component the various urban component interact through a non convex energy minimization problem in which they are propagated under arrangement constraint over a planimetric map we experimentally validate the approach on complex urban structure and large urban scene of million of point 
this paper investigates how to parse segment facial component from face image which may be partially occluded we propose a novel face parser which recasts segmentation of face component a a cross modality data transformation problem i e transforming an image patch to a label map specifically a face is represented hierarchically by part component and pixel wise label with this representation our approach first detects face at both the partand component level and then computes the pixel wise label map fig our part based and component based detector are generatively trained with the deep belief network dbn and are discriminatively tuned by logistic regression the segmentators transform the detected face component to label map which are obtained by learning a highly nonlinear mapping with the deep autoencoder the proposed hierarchical face parsing is not only robust to partial occlusion but also provide richer information for face analysis and face synthesis compared with face keypoint detection and face alignment the effectiveness of our algorithm is shown through several task on image selected from three datasets e g lfw bioid and cufsf 
visual scene understanding is a difficult problem interleaving object detection geometric reasoning and scene classification we present a hierarchical scene model for learning and reasoning about complex indoor scene which is computationally tractable can be learned from a reasonable amount of training data and avoids oversimplification at the core of this approach is the d geometric phrase model which capture the semantic and geometric relationship between object which frequently co occur in the same d spatial configuration experiment show that this model effectively explains scene semantics geometry and object grouping from a single image while also improving individual object detection 
we introduce a new large scale video dataset designed to ass the performance of diverse visual event recognition algorithm with a focus on continuous visual event recognition cver in outdoor area with wide coverage previous datasets for action recognition are unrealistic for real world surveillance because they consist of short clip showing one action by one individual datasets have been developed for movie and sport but these action and scene condition do not apply effectively to surveillance video our dataset consists of many outdoor scene with action occurring naturally by non actor in continuously captured video of the real world the dataset includes large number of instance for event type distributed throughout hour of video this data is accompanied by detailed annotation which include both moving object track and event example which will provide solid basis for large scale evaluation additionally we propose different type of evaluation mode for visual recognition task and evaluation metric along with our preliminary experimental result we believe that this dataset will stimulate diverse aspect of computer vision research and help u to advance the cver task in the year ahead 
human pose estimation in a static image is a challenging problem in computer vision in that body part configuration are often subject to severe deformation and occlusion moreover efficient pose estimation is often a desirable requirement in many application the trade off between accuracy and efficiency ha been explored in a large number of approach on the one hand model with simple representation like tree or star model can be efficiently applied in pose estimation problem however these model are often prone to body part misclassification error on the other hand model with rich representation i e loopy graphical model are theoretically more robust but their inference complexity may increase dramatically in this work we propose an efficient and exact inference algorithm based on branch and bound to solve the human pose estimation problem on loopy graphical model we show that our method is empirically much faster about time than the state of the art exact inference algorithm by extending a state of the art tree model to a loopy graphical model we show that the estimation accuracy improves for most of the body part especially lower arm on popular datasets such a buffy and stickmen datasets finally our method can be used to exactly solve most of the inference problem on stretchable model which contains a few hundred of variable in just a few minute 
driven by recent vision and graphic application such a image segmentation and object recognition assigning pixel accurate saliency value to uniformly highlight foreground object becomes increasingly critical more often such fine grained saliency detection is also desired to have a fast runtime motivated by these we propose a generic and fast computational framework called pisa pixel wise image saliency aggregating complementary saliency cue based on color and structure contrast with spatial prior holistically overcoming the limitation of previous method often using homogeneous super pixel based and color contrast only treatment our pisa approach directly performs saliency modeling for each individual pixel and make use of densely overlapping feature adaptive observation for saliency measure computation we further impose a spatial prior term on each of the two contrast measure which constrains pixel rendered salient to be compact and also centered in image domain by fusing complementary contrast measure in such a pixel wise adaptive manner the detection effectiveness is significantly boosted without requiring reliable region segmentation or post relaxation pisa exploit an efficient edge aware image representation and filtering technique and produce spatially coherent yet detail preserving saliency map extensive experiment on three public datasets demonstrate pisa s superior detection accuracy and competitive runtime speed over the state of the art approach 
subspace clustering ha important and wide application in computer vision and pattern recognition it is a challenging task to learn low dimensional subspace structure due to the possible error e g noise and corruption existing in high dimensional data recent subspace clustering method usually assume a sparse representation of corrupted error and correct the error iteratively however large corruption in real world application can not be well addressed by these method a novel optimization model for robust subspace clustering is proposed in this paper the objective function of our model mainly includes two part the first part aim to achieve a sparse representation of each high dimensional data point with other data point the second part aim to maximize the correntropy between a given data point and it low dimensional representation with other point correntropy is a robust measure so that the influence of large corruption on subspace clustering can be greatly suppressed an extension of our method with explicit introduction of representation error term into the model is also proposed half quadratic minimization is provided a an efficient solution to the proposed robust subspace clustering formulation experimental result on hopkins dataset and extended yale database b demonstrate that our method outperforms state of the art subspace clustering method 
several recent study demonstrated that higher order non linear functionals can yield outstanding performance in the context of segmentation co segmentation and tracking in general higher order functionals result in difficult problem that are not amenable to standard optimizers and most of the existing work investigated particular form of such functionals in this study we derive general bound for a broad class of higher order functionals by introducing auxiliary variable and invoking the jensen s inequality a well a some convexity argument we prove that these bound are auxiliary functionals for various non linear term which include but are not limited to several affinity measure on the distribution or moment of segment appearance and shape a well a soft constraint on segment volume from these general form bound we state various non linear problem a the optimization of auxiliary functionals by graph cut the proposed bound optimizers are derivative free and consistently yield very steep functional decrease thereby converging within a few graph cut we report several experiment on color and medical data along with quantitative comparison to state of the art method the result demonstrate competitive performance of the proposed algorithm in regard to accuracy and convergence speed and confirm their potential in various vision and medical application 
we propose a co detection and labeling codel framework to identify person that contain self consistent appearance in multiple image our codel model build upon the deformable part based model to detect human hypothesis and exploit cross image correspondence via a matching classifier relying on a gaussian process this matching classifier model the similarity of two hypothesis and efficiently capture the relative importance contributed by various visual feature reducing the adverse effect of scattered occlusion further the detector and matching classifier together make our model fit into a semi supervised co training framework which can get enhanced result with a small amount of labeled training data our codel model achieves decent performance on existing and new benchmark datasets 
despite much research on patch based descriptor sift remains the gold standard for finding correspondence across image and recent descriptor focus primarily on improving speed rather than accuracy in this paper we propose descriptor net d net a computationally efficient method that significantly improves the accuracy of image matching by going beyond patch based approach d net construct a network in which node correspond to traditional sparsely or densely sampled keypoints and where image content is sampled from selected edge in this net not only is our proposed representation invariant to cropping translation scale reflection and rotation but it is also significantly more robust to severe perspective and non linear distortion we present several variant of our algorithm including one that tune itself to the image complexity and an efficient parallelized variant that employ a fixed grid comprehensive direct comparison against sift and orb on standard datasets demonstrate that d net dominates existing approach in term of precision and recall while retaining computational efficiency 
longitudinal data arises in many application in which the goal is to understand change in individual entity over time in this paper we present a method for analyzing longitudinal data that take value in a riemannian manifold a driving application is to characterize anatomical shape change and to distinguish between trend in anatomy that are healthy versus those that are due to disease we present a generative hierarchical model in which each individual is modeled by a geodesic trend which in turn is considered a a perturbation of the mean geodesic trend for the population each geodesic in the model can be uniquely parameterized by a starting point and velocity i e a point in the tangent bundle comparison between these parameter is achieved through the sasaki metric which provides a natural distance metric on the tangent bundle we develop a statistical hypothesis test for difference between two group of longitudinal data by generalizing the hotelling t statistic to manifold we demonstrate the ability of these method to distinguish difference in shape change in a comparison of longitudinal corpus callosum data in subject with dementia versus healthily aging control 
the problem of rigid motion segmentation of trajectory data under orthography ha been long solved for non degenerate motion in the absence of noise but because real trajectory data often incorporates noise outlier motion degeneracy and motion dependency recently proposed motion segmentation method resort to non trivial representation to achieve state of the art segmentation accuracy at the expense of a large computational cost this paper proposes a method that dramatically reduces this cost by two or three order of magnitude with minimal accuracy loss from achieved by the state of the art to achieved by our method on the standard hopkins dataset computational efficiency come from the use of a simple but powerful representation of motion that explicitly incorporates mechanism to deal with noise outlier and motion degeneracy subset of motion model with the best balance between prediction accuracy and model complexity are chosen from a pool of candidate which are then used for segmentation 
we propose a novel discriminative learning approach to image set classification by modeling the image set with it natural second order statistic i e covariance matrix since nonsingular covariance matrix a k a symmetric positive definite spd matrix lie on a riemannian manifold classical learning algorithm cannot be directly utilized to classify point on the manifold by exploring an efficient metric for the spd matrix i e log euclidean distance led we derive a kernel function that explicitly map the covariance matrix from the riemannian manifold to a euclidean space with this explicit mapping any learning method devoted to vector space can be exploited in either it linear or kernel formulation linear discriminant analysis lda and partial least square pls are considered in this paper for their feasibility for our specific problem we further investigate the conventional linear subspace based set modeling technique and cast it in a unified framework with our covariance matrix based modeling the proposed method is evaluated on two task face recognition and object categorization extensive experimental result show not only the superiority of our method over state of the art one in both accuracy and efficiency but also it stability to two real challenge noisy set data and varying set size 
we present a novel structure called a subspace forest designed to provide an efficient approximate nearest neighbor query of subspace represented a point on grassmann manifold we apply this structure to action recognition by representing action a subspace spanning a sequence of thumbnail image tile extracted from a tracked entity the subspace forest lift the concept of randomized decision forest from classifying vector to classifying subspace and employ a splitting method that respect the underlying manifold geometry the subspace forest is an inherently parallel structure and is highly scalable due to o log n recognition time complexity our experimental result demonstrate state of the art classification accuracy on the well known kth action and ucf sport benchmark and a competitive score on cambridge gesture in addition to being both highly accurate and scalable the subspace forest is built without supervision and requires no extensive validation stage for model selection conceptually the subspace forest could be used anywhere set to set feature matching is desired 
in recent year significant progress ha been made learning generic pedestrian detector from manually labeled large scale training set however when a generic pedestrian detector is applied to a specific scene where the testing data doe not match with the training data because of variation of viewpoint resolution illumination and background it accuracy may decrease greatly in this paper we propose a new framework of adapting a pre trained generic pedestrian detector to a specific traffic scene by automatically selecting both confident positive and negative example from the target scene to re train the detector iteratively an important feature of the proposed framework is to utilize unsupervisedly learned model of vehicle and pedestrian path together with multiple other cue such a location size appearance and motion to select new training sample the information of scene structure increase the reliability of selected sample and is complementary to the appearance based detector however it wa not well explored in previous study in order to further improve the reliability of selected sample outlier are removed through multiple hierarchical clustering step the effectiveness of different cue and clustering step is evaluated through experiment the proposed approach significantly improves the accuracy of the generic pedestrian detector and also outperforms the scene specific detector retrained using background subtraction it result are comparable with the detector trained using a large number of manually labeled frame from the target scene 
we use a simple modification to a conventional slr camera to capture image of several hundred scene in colour rgb and near infrared nir we show that the addition of near infrared information lead to significantly improved performance in a scene recognition task and that the improvement are greater still when an appropriate dimensional colour representation is used in particular we propose msift a multispectral sift descriptor that when combined with a kernel based classifier exceeds the performance of state of the art scene recognition technique e g gist and their multispectral extension we extensively test our algorithm using a new dataset of several hundred rgb nir scene image a well a benchmarking against torralba s scene categorization dataset 
in this paper we propose an efficient technique to detect change in the geometry of an urban environment using some image observing it current state the proposed method can be used to significantly optimize the process of updating the d model of a city changing over time by restricting this process to only those area where change are detected with this application in mind we designed our algorithm to specifically detect only structural change in the environment ignoring any change in it appearance and ignoring also all the change which are not relevant for update purpose such a car people etc a a by product the algorithm also provides a coarse geometry of the detected change the performance of the proposed method wa tested on four different kind of urban environment and compared with two alternative technique 
background subtraction ha been widely investigated in recent year most previous work ha focused on stationary camera recently moving camera have also been studied since video from mobile device have increased significantly in this paper we propose a unified and robust framework to effectively handle diverse type of video e g video from stationary or moving camera our model is inspired by two observation background motion caused by orthographic camera lie in a low rank subspace and pixel belonging to one trajectory tend to group together based on these two observation we introduce a new model using both low rank and group sparsity constraint it is able to robustly decompose a motion trajectory matrix into foreground and background one after obtaining foreground and background trajectory the information gathered on them is used to build a statistical model to further label frame at the pixel level extensive experiment demonstrate very competitive performance on both synthetic data and real video 
recognizing object in fine grained domain can be extremely challenging due to the subtle difference between subcategories discriminative marking are often highly localized leading traditional object recognition approach to struggle with the large pose variation often present in these domain pose normalization seek to align training exemplar either piecewise by part or globally for the whole object effectively factoring out difference in pose and in viewing angle prior approach relied on computationally expensive filter ensemble for part localization and required extensive supervision this paper proposes two pose normalized descriptor based on computationally efficient deformable part model the first leverage the semantics inherent in strongly supervised dpm part the second exploit weak semantic annotation to learn cross component correspondence computing pose normalized descriptor from the latent part of a weakly supervised dpm these representation enable pooling across pose and viewpoint in turn facilitating task such a fine grained recognition and attribute prediction experiment conducted on the caltech ucsd bird dataset and berkeley human attribute dataset demonstrate significant improvement of our approach over state of art algorithm 
we present a new algorithm to jointly track multiple object in multi view image while this ha been typically addressed separately in the past we tackle the problem a a single global optimization we formulate this assignment problem a a min cost problem by defining a graph structure that capture both temporal correlation between object a well a spatial correlation enforced by the configuration of the camera this lead to a complex combinatorial optimization problem that we solve using dantzig wolfe decomposition and branching our formulation allows u to solve the problem of reconstruction and tracking in a single step by taking all available evidence into account in several experiment on multiple people tracking and d human pose tracking we show our method outperforms state of the art approach 
we study the d reconstruction of plant root from multiple d image to meet the challenge caused by the delicate nature of thin branch we make three innovation to cope with the sensitivity to image quality and calibration first we model the background a a harmonic function to improve the segmentation of the root in each d image second we develop the concept of the regularized visual hull which reduces the effect of jittering and refraction by ensuring consistency with one d image third we guarantee connectedness through adjustment to the d reconstruction that minimize global error our software is part of a biological phenotype genotype study of agricultural root system it ha been tested on more than plant root and result are promising in term of reconstruction quality and efficiency 
significant recent progress ha been made in developing high quality saliency model however le effort ha been undertaken on fair assessment of these model over large standardized datasets and correctly addressing confounding factor in this study we pursue a critical and quantitative look at challenge e g center bias map smoothing in saliency modeling and the way they affect model accuracy we quantitatively compare state of the art model using the shuffled auc score to discount center bias on benchmark eye movement datasets for prediction of human fixation location and scan path sequence we also account for the role of map smoothing we find that although model ranking vary some e g aws lg aim and hounips consistently outperform other model over all datasets some model work well for prediction of both fixation location and scan path sequence e g judd gbvs our result show low prediction accuracy for model over emotional stimulus from the nusef dataset our last benchmark for the first time gauge the ability of model to decode the stimulus category from statistic of fixation saccade and model saliency value at fixated location in this test itti and aim model win over other model our benchmark provides a comprehensive high level picture of the strength and weakness of many popular model and suggests future research direction in saliency modeling 
we propose a novel way to induce a random field from an energy function on discrete label it amount to locally injecting noise to the energy potential followed by finding the global minimum of the perturbed energy function the resulting perturb and map random field harness the power of modern discrete energy minimization algorithm effectively transforming them into efficient random sampling algorithm thus extending their scope beyond the usual deterministic setting in this fashion we can enjoy the benefit of a sound probabilistic framework such a the ability to represent the solution uncertainty or learn model parameter from training data while completely bypassing costly markov chain monte carlo procedure typically associated with discrete label gibbs markov random field mrfs we study some interesting theoretical property of the proposed model in juxtaposition to those of gibbs mrfs and address the issue of principled design of the perturbation process we present experimental result in image segmentation and scene labeling that illustrate the new qualitative aspect and the potential of the proposed model for practical computer vision application 
this paper address a new person re identification problem without the label information of person under non overlapping target camera given the matched positive and unmatched negative image pair from source domain camera a well a unmatched negative image pair which can be easily generated from target domain camera we propose a domain transfer ranked support vector machine dtrsvm method for re identification under target domain camera to overcome the problem introduced due to the absence of matched positive image pair in target domain we relax the discriminative constraint to a necessary condition only relying on the positive mean in target domain by estimating the target positive mean using source and target domain data a new discriminative model with high confidence in target positive mean and low confidence in target negative image pair is developed since the necessary condition may not truly preserve the discriminability multi task support vector ranking is proposed to incorporate the training data from source domain with label information experimental result show that the proposed dtrsvm outperforms existing method without using label information in target camera and the top rank accuracy can be improved by the proposed method upto on publicly available person re identification datasets 
we propose a novel linearly augmented tree method for efficient scale and rotation invariant object matching the proposed method enforces pairwise matching consistency defined on tree and high order constraint on all the site of a template the pairwise constraint admit arbitrary metric while the high order constraint use l norm and therefore can be linearized such a linearly augmented tree formulation introduces hyperedges and loop into the basic tree structure but different from a general loopy graph it special structure allows u to relax and decompose the optimization into a sequence of tree matching problem efficiently solvable by dynamic programming the proposed method also work on continuous scale and rotation parameter we can match with a scale up to any large number with the same efficiency our experiment on ground truth data and a variety of real image and video show that the proposed method is efficient accurate and reliable 
we present a novel computational model to explore the relatedness of objectness and saliency each of which play an important role in the study of visual attention the proposed framework conceptually integrates these two concept via constructing a graphical model to account for their relationship and concurrently improves their estimation by iteratively optimizing a novel energy function realizing the model specifically the energy function comprises the objectness the saliency and the interaction energy respectively corresponding to explain their individual regularity and the mutual effect minimizing the energy by fixing one or the other would elegantly transform the model into solving the problem of objectness or saliency estimation while the useful information from the other concept can be utilized through the interaction term experimental result on two benchmark datasets demonstrate that the proposed model can simultaneously yield a saliency map of better quality and a more meaningful objectness output for salient object detection 
this paper proposes a new supervised semantic edge and gradient extraction approach which allows the user to roughly scribble over the desired region to extract semantically dominant and coherent edge in it our approach first extract low level edge let small edge cluster from the input image a primitive and build a graph upon them by jointly considering both the geometric and appearance compatibility of edge let given the characteristic of the graph it cannot be effectively optimized by commonly used energy minimization tool such a graph cut we thus propose an efficient linear algorithm for precise graph optimization by taking advantage of the special structure of the graph optimal parameter setting of the model are learnt from a dataset objective evaluation show that the proposed method significantly outperforms previous semantic edge detection algorithm finally we demonstrate the effectiveness of the system in various image editing task 
object recognition ha made great stride recently however the best method such a those based on kernel svms are highly computationally intensive the problem of how to accelerate the evaluation process without decreasing accuracy is thus of current interest in this paper we deal with this problem by using the idea of ranking we propose a cascaded architecture which using the ranking svm generates an ordered set of proposal for window containing object instance the top ranking window may then be fed to a more complex detector our experiment demonstrate that our approach is robust achieving higher overlap recall value using fewer output proposal than the state of the art our use of simple gradient feature and linear convolution indicates that our method is also faster than the state of the art 
in this paper we introduce unique publicly available dense an isotropic brdf data measurement we use this dense data a a reference for performance evaluation of the proposed brdf sparse angular sampling and interpolation approach the method is based on sampling of brdf subspace at fixed elevation by mean of several adaptively represented uniformly distributed perpendicular slice although this proposed method requires only a sparse sampling of material the interpolation provides a very accurate reconstruction visually and computationally comparable to densely measured reference due to the simple slice measurement and method s robustness it allows for a highly accurate acquisition of brdfs this in comparison with standard uniform angular sampling is considerably faster yet us far le sample 
given a video we would like to recognize group activity localize video part where these activity occur and detect actor involved in them this advance prior work that typically focus only on video classification we make a number of contribution first we specify a new mid level video feature aimed at summarizing local visual cue into bag of the right detection bords bords seek to identify the right people who participate in a target group activity among many noisy people detection second we formulate a new generative chain model of group activity inference of the chain model identifies a subset of bords in the video that belong to occurrence of the activity and organizes them in an ensemble of temporal chain the chain extend over and thus localize the time interval occupied by the activity we formulate a new map inference algorithm that iterates two step i warp the chain of bords in space and time to their expected location so the transformed bords can better summarize local visual cue and ii maximizes the posterior probability of the chain we outperform the state of the art on benchmark ut human interaction and collective activity datasets under reasonable running time 
in this paper we propose a novel cascaded face shape space pruning algorithm for robust facial landmark detection through progressively excluding the incorrect candidate shape our algorithm can accurately and efficiently achieve the globally optimal shape configuration specifically individual landmark detector are firstly applied to eliminate wrong candidate for each landmark then the candidate shape space is further pruned by jointly removing incorrect shape configuration to achieve this purpose a discriminative structure classifier is designed to ass the candidate shape configuration based on the learned discriminative structure classifier an efficient shape space pruning strategy is proposed to quickly reject most incorrect candidate shape while preserve the true shape the proposed algorithm is carefully evaluated on a large set of real world face image in addition comparison result on the publicly available bioid and lfw face database demonstrate that our algorithm outperforms some state of the art algorithm 
many human action recognition task involve data that can be factorized into multiple view such a body posture and hand shape these view often interact with each other over time providing important cue to understanding the action we present multi view latent variable discriminative model that jointly learn both view shared and view specific sub structure to capture the interaction between view knowledge about the underlying structure of the data is formulated a a multi chain structured latent conditional model explicitly learning the interaction between multiple view using disjoint set of hidden variable in a discriminative manner the chain are tied using a predetermined topology that repeat over time we present three topology linked coupled and linked coupled that differ in the type of interaction between view that they model we evaluate our approach on both segmented and unsegmented human action recognition task using the armgesture the natops and the armgesture continuous data experimental result show that our approach outperforms previous state of the art action recognition model 
supervoxel segmentation ha strong potential to be incorporated into early video analysis a superpixel segmentation ha in image analysis however there are many plausible supervoxel method and little understanding a to when and where each is most appropriate indeed we are not aware of a single comparative study on supervoxel segmentation to that end we study five supervoxel algorithm in the context of what we consider to be a good supervoxel namely spatiotemporal uniformity object region boundary detection region compression and parsimony for the evaluation we propose a comprehensive suite of d volumetric quality metric to measure these desirable supervoxel characteristic we use three benchmark video data set with a variety of content type and varying amount of human annotation our finding have led u to conclusive evidence that the hierarchical graph based and segmentation by weighted aggregation method perform best and almost equally well on nearly all the metric and are the method of choice given our proposed assumption 
node splitting is an important issue in random forest but robust splitting requires a large number of training sample existing solution fail to properly partition the feature space if there are insufficient training data in this paper we present semi supervised splitting to overcome this limitation by splitting node with the guidance of both labeled and unlabeled data in particular we derive a nonparametric algorithm to obtain an accurate quality measure of splitting by incorporating abundant unlabeled data to avoid the curse of dimensionality we project the data point from the original high dimensional feature space onto a low dimensional subspace before estimation a unified optimization framework is proposed to select a coupled pair of subspace and separating hyper plane such that the smoothness of the subspace and the quality of the splitting are guaranteed simultaneously the proposed algorithm is compared with state of the art supervised and semi supervised algorithm for typical computer vision application such a object categorization and image segmentation experimental result on publicly available datasets demonstrate the superiority of our method 
we present a method to estimate the coarse gaze direction of people from surveillance data unlike previous work we aim to do this without recourse to a large hand labelled corpus of training data in contrast we propose a method for learning a classifier without any hand labelled data using only the output from an automatic tracking system a conditional random field is used to model the interaction between the head motion walking direction and appearance to recover the gaze direction and simultaneously train randomised decision tree classifier experiment demonstrate performance exceeding that of conventionally trained classifier on two large surveillance datasets 
camera shake during long exposure is ineluctable in light limited situation and result in a blurry observation recovering the blur kernel and the latent image from the blurred image is an inherently ill posed problem in this paper we analyze the image acquisition model to capture two blurred image simultaneously with different blur kernel the image pair is well aligned and the kernel have a certain relationship such strategy overcomes the challenge of blurry image alignment and reduces the ambiguity of blind deblurring thanks to the aided hardware the algorithm based on such image pair can give high quality kernel estimation and image restoration the experiment on both synthetic and real image demonstrate the effectiveness of our image capture strategy and show that the kernel estimation is accurate enough to restore superior latent image which contains more detail and fewer ringing artifact 
this paper introduces a low rank prior for small oriented noise free image patch considering an oriented patch a a matrix a low rank matrix approximation is enough to preserve the texture detail in the properly oriented patch based on this prior we propose a single patch method within a generalized joint low rank and sparse matrix recovery framework to simultaneously detect and remove non point wise random valued impulse noise e g very small blob a weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution an accelerated proximal gradient method is adapted to estimate the optimal noise free image patch experiment show the effectiveness of our framework in removing non point wise random valued impulse noise 
we propose a powerful pipeline for determining the pose of a query image relative to a point cloud reconstruction of a large scene consisting of more than one million d point the key component of our approach is an efficient and effective search method to establish match between image feature and scene point needed for pose estimation our main contribution is a framework for actively searching for additional match based on both d to d and d to d search a unified formulation of search in both direction allows u to exploit the distinct advantage of both strategy while avoiding their weakness due to active search the resulting pipeline is able to close the gap in registration performance observed between efficient search method and approach that are allowed to run for multiple second without sacrificing run time efficiency our method achieves the best registration performance published so far on three standard benchmark datasets with run time comparable or superior to the fastest state of the art method 
motion blur and rolling shutter deformation both inhibit visual motion registration whether it be due to a moving sensor or a moving target whilst both deformation exist simultaneously no model have been proposed to handle them together furthermore neither deformation ha been considered previously in the context of monocular full image degree of freedom registration or rgb d structure and motion a will be shown rolling shutter deformation is observed when a camera move faster than a single pixel in parallax between subsequent scan line blur is a function of the pixel exposure time and the motion vector in this paper a complete dense d registration model will be derived to account for both motion blur and rolling shutter deformation simultaneously various approach will be compared with respect to ground truth and live real time performance will be demonstrated for complex scenario where both blur and shutter deformation are dominant 
this paper proposes a unified probabilistic model to model the relationship between attribute and object for attribute prediction and object recognition a a list of semantically meaningful property of object attribute generally relate to each other statistically in this paper we propose a unified probabilistic model to automatically discover and capture both the object dependent and object independent attribute relationship the model utilizes the captured relationship to benefit both attribute prediction and object recognition experiment on four benchmark attribute datasets demonstrate the effectiveness of the proposed unified model for improving attribute prediction a well a object recognition in both standard and zero shot learning case 
light transport ha been analyzed extensively in both the primal domain and the frequency domain the latter provides intuition of effect introduced by free space propagation and by optical element and allows for optimal design of computational camera for tailored efficient information capture here we relax the common assumption that the speed of light is infinite and analyze free space propagation in the frequency domain considering spatial temporal and angular light variation using this analysis we derive analytic expression for cross dimensional information transfer and show how this can be exploited for designing a new time resolved bare sensor imaging system 
we propose a new stereo technique using a pair of flash and no flash stereo image that is both efficient and robust in handling occlusion boundary our work is motivated by the observation that the brightness variation introduced by the flash can provide a robust cue for establishing stereo match at occlusion boundary this photometric cue is computed per pixel and though on it own is not robust to reliably resolve depth it can provide a new discriminant to support patch based stereo matching algorithm our experiment using a hand held fujifilm w d camera show satisfying stereo performance over a variety of scene including several outdoor scene 
we present two thesis in this paper first performance of most existing face recognition algorithm improves if instead of the whole image smaller patch are individually classified followed by label aggregation using voting second weighted plurality 
the projection of world parallel line in an image intersect at a single point called the vanishing point vp vps are a key ingredient for various vision task including rotation estimation and d reconstruction urban environment generally exhibit some dominant orthogonal vps given a set of line extracted from a calibrated image this paper aim to determine the line clustering i e find which line belongs to which vp and estimate the associated orthogonal vps none of the existing method is fully satisfactory because of the inherent difficulty of the problem such a the local minimum and the chicken and egg aspect in this paper we present a new algorithm that solves the problem in a mathematically guaranteed globally optimal manner and can inherently enforce the vp orthogonality specifically we formulate the task a a consensus set maximization problem over the rotation search space and further solve it efficiently by a branch and bound procedure based on the interval analysis theory our algorithm ha been validated successfully on set of challenging real image a well a synthetic data set 
we propose to bridge the gap between random field rf formulation for joint categorization and segmentation jcas which model local interaction among pixel and superpixels and bag of feature categorization algorithm which use global descriptor for this purpose we introduce new higher order potential that encode the classification cost of a histogram extracted from all the object in an image that belong to a particular category where the cost is given a the output of a classifier when applied to the histogram the potential efficiently encode the classification cost of several histogram resulting from the different possible segmentation of an image they can be integrated with existing potential hence providing a natural unification of global and local interaction the potential parameter can be treated a parameter of the rf and hence be jointly learnt along with the other parameter of the rf experiment show that our framework can be used to improve the performance of existing jcas algorithm 
dimensionality reduction for vector in sequence is challenging since label are attached to sequence a a whole this paper present a model based dimensionality reduction method for vector sequence namely linear sequence discriminant analysis lsda which attempt to find a subspace in which sequence of the same class are projected together while those of different class are projected a far a possible for each sequence class an hmm is built from state of which statistic are extracted mean of these state are linked in order to form a mean sequence and the variance of the sequence class is defined a the sum of all variance of component state lsda then learns a transformation by maximizing the separability between sequence class and at the same time minimizing the within sequence class scatter dtw distance between mean sequence is used to measure the separability between sequence class we show that the optimization problem can be approximately transformed into an eigen decomposition problem lda can be seen a a special case of lsda by considering non sequential vector a sequence of length one the effectiveness of the proposed lsda is demonstrated on two individual sequence datasets from uci machine learning repository a well a two concatenate sequence datasets apti arabic printed text database and ifn enit arabic handwriting database 
attribute are visual concept that can be detected by machine understood by human and shared across category they are particularly useful for fine grained domain where category are closely related to one other e g bird specie recognition in such scenario relevant attribute are often local e g white belly but the question of how to choose these local attribute remains largely unexplored in this paper we propose an interactive approach that discovers local attribute that are both discriminative and semantically meaningful from image datasets annotated only with fine grained category label and object bounding box our approach us a latent conditional random field model to discover candidate attribute that are detectable and discriminative and then employ a recommender system that selects attribute likely to be semantically meaningful human interaction is used to provide semantic name for the discovered attribute we demonstrate our method on two challenging datasets caltech ucsd bird and leeds butterfly and find that our discovered attribute outperform those generated by traditional approach 
we address image classification on a large scale i e when a large number of image and class are involved first we study classification accuracy a a function of the image signature dimensionality and the training set size we show experimentally that the larger the training set the higher the impact of the dimensionality on the accuracy in other word high dimensional signature are important to obtain state of the art result on large datasets second we tackle the problem of data compression on very large signature on the order of dimension using two lossy compression strategy a dimensionality reduction technique known a the hash kernel and an encoding technique based on product quantizers we explain how the gain in storage can be traded against a loss in accuracy and or an increase in cpu cost we report result on two large database imagenet and a dataset of lm flickr image showing that we can reduce the storage of our signature by a factor to with little loss in accuracy integrating the decompression in the classifier learning yield an efficient and scalable training algorithm on ilsvrc we report a accuracy at top which corresponds to a absolute improvement with respect to the state of the art on a subset of k class of imagenet we report a top accuracy of a relative improvement of with respect to the state of the art 
in this paper we aim for segmentation and classification of object we propose codemaps that are a joint formulation of the classification score and the local neighborhood it belongs to in the image we obtain the codemap by reordering the encoding pooling and classification step over lattice element other than existing linear decomposition who emphasize only the efficiency benefit for localized search we make three novel contribution a a preliminary we provide a theoretical generalization of the sufficient mathematical condition under which image encoding and classification becomes locally decomposable a first novelty we introduce l normalization for arbitrarily shaped image region which is fast enough for semantic segmentation using our fisher codemaps second using the same lattice across image we propose kernel pooling which embeds nonlinearities into codemaps for object classification by explicit or approximate feature mapping result demonstrate that l normalized fisher codemaps improve the state of the art in semantic segmentation for pascal voc for object classification the addition of nonlinearities brings u on par with the state of the art but is x faster because of the codemaps inherent efficiency we can reach significant speed ups for localized search a well we exploit the efficiency gain for our third novelty object segment retrieval using a single query image only 
in this paper we address the problem of producing a high resolution image from a single low resolution image without any external training set we propose a framework for both magnification and deblurring using only the original low resolution image and it blurred version in our method each pixel is predicted by it neighbor through the gaussian process regression we show that when using a proper covariance function the gaussian process regression can perform soft clustering of pixel based on their local structure we further demonstrate that our algorithm can extract adequate information contained in a single low resolution image to generate a high resolution image with sharp edge which is comparable to or even superior in quality to the performance of other edge directed and example based super resolution algorithm experimental result also show that our approach maintains high quality performance at large magnification 
recent work on background subtraction ha shown development on two major front in one there ha been increasing sophistication of probabilistic model from mixture of gaussians at each pixel to kernel density estimate at each pixel and more recently to joint domainrange density estimate that incorporate spatial information another line of work ha shown the benefit of increasingly complex feature representation including the use of texture information local binary pattern and recently scale invariant local ternary pattern in this work we use joint domain range based estimate for background and foreground score and show that dynamically choosing kernel variance in our kernel estimate at each individual pixel can significantly improve result we give a heuristic method for selectively applying the adaptive kernel calculation which is nearly a accurate a the full procedure but run much faster we combine these modeling improvement with recently developed complex feature and show significant improvement on a standard backgrounding benchmark 
we propose a detection free system for segmenting multiple interacting and deforming people in a video people detector often fail under close agent interaction limiting the performance of detection based tracking method motion information often fails to separate similarly moving agent or to group distinctly moving articulated body part we formulate video segmentation a graph partitioning in the trajectory domain we classify trajectory a foreground or background based on trajectory saliency and use foreground trajectory a graph node we incorporate object connectedness constraint into our trajectory weight matrix based on topology of foreground we set repulsive weight between trajectory that belong to different connected component in any frame of their time intersection attractive weight are set between similarly moving trajectory information from foreground topology complement motion information and our spatiotemporal segment can be interpreted a connected moving entity rather than just trajectory group of similar motion all our cue are computed on trajectory and naturally encode large temporal context which is crucial for resolving local in time ambiguity we present result of our approach on challenging datasets outperforming by far the state of the art 
the first main contribution of this paper is a novel method for representing image based on a dictionary of shape epitome these shape epitome represent the local edge structure of the image and include hidden variable to encode shift and rotation they are learnt in an unsupervised manner from ground truth edge this dictionary is compact but is also able to capture the typical shape of edge in natural image in this paper we illustrate the shape epitome by applying them to the image labeling task in other work described in the supplementary material we apply them to edge detection and image modeling we apply shape epitome to image labeling by using conditional random field crf model they are alternative to the super pixel or pixel representation used in most crfs in our approach the shape of an image patch is encoded by a shape epitome from the dictionary unlike the super pixel representation our method avoids making early decision which cannot be reversed our resulting hierarchical crfs efficiently capture both local and global class co occurrence property we demonstrate it quantitative and qualitative property of our approach with image labeling experiment on two standard datasets msrc and stanford background 
visual domain adaptation address the problem of adapting the sample distribution of the source domain to the target domain where the recognition task is intended but the data distribution are different in this paper we present a low rank reconstruction method to reduce the domain distribution disparity specifically we transform the visual sample in the source domain into an intermediate representation such that each transformed source sample can be linearly reconstructed by the sample of the target domain unlike the existing work our method capture the intrinsic relatedness of the source sample during the adaptation process while uncovering the noise and outlier in the source domain that cannot be adapted making it more robust than previous method we formulate our problem a a constrained nuclear norm and norm minimization objective and then adopt the augmented lagrange multiplier alm method for the optimization extensive experiment on various visual adaptation task show that the proposed method consistently and significantly beat the state of the art domain adaptation method 
to better understand search and classify image and video information many visual feature descriptor have been proposed to describe elementary visual characteristic such a the shape the color the texture etc how to integrate these heterogeneous visual feature and identify the important one from them for specific vision task ha become an increasingly critical problem in this paper we propose a novel sparse multimodal learning smml approach to integrate such heterogeneous feature by using the joint structured sparsity regularization to learn the feature importance of for the vision task from both group wise and individual point of view a new optimization algorithm is also introduced to solve the non smooth objective with rigorously proved global convergence we applied our smml method to five broadly used object categorization and scene understanding image data set for both single label and multi label image classification task for each data set we integrate six different type of popularly used image feature compared to existing scene and object categorization method using either single modality or multi modality of feature our approach always achieves better performance measured 
the problem of graph matching in general is np hard and approach have been proposed for it sub optimal solution most focusing on finding the one to one node mapping between two graph a more general and challenging problem arises when one aim to find consistent mapping across a number of graph more than two conventional graph pair matching method often result in mapping inconsistency since the mapping between two graph can either be determined by pair mapping or by an additional anchor graph to address this issue a novel formulation is derived which is maximized via alternating optimization our method enjoys several advantage the mapping are jointly optimized rather than sequentially performed by applying pair matching allowing the global affinity information across graph can be propagated and explored the number of concerned variable to optimize is in linear with the number of graph being superior to local pair matching resulting in o n variable the mapping consistency constraint are analytically satisfied during optimization and off the shelf graph pair matching solver can be reused under the proposed framework in an out of the box fashion competitive result on both the synthesized data and the real data are reported by varying the level of deformation outlier and edge density 
reconstructionand example based super resolution sr method are promising for restoring a high resolution hr image from low resolution lr image s under large magnification reconstruction based method usually fail to hallucinate visual detail while example based method sometimes introduce unexpected detail given a generic lr image to reconstruct a photo realistic sr image and to suppress artifact in the reconstructed sr image we introduce a multi scale dictionary to a novel sr method that simultaneously integrates local and non local prior the local prior suppresses artifact by using steering kernel regression to predict the target pixel from a small local area the non local prior enriches visual detail by taking a weighted average of a large neighborhood a an estimate of the target pixel essentially these two prior are complementary to each other experimental result demonstrate that the proposed method can produce high quality sr recovery both quantitatively and perceptually 
object in scene interact with each other in complex way a key observation is that these interaction manifest themselves a predictable visual pattern in the image discovering and detecting these structured pattern is an important step towards deeper scene understanding it go beyond using either individual object or the scene a a whole a the semantic unit in this work we promote group of object they are high order composite of object that demonstrate consistent spatial scale and viewpoint interaction with each other these group of object are likely to correspond to a specific layout of the scene they can thus provide cue for the scene category and can also prime the likely location of other object in the scene it is not feasible to manually generate a list of all possible grouping of object we find in our visual world hence we propose an algorithm that automatically discovers group of arbitrary number of participating object from a collection of image labeled with object category our approach build a dimensional transform space of location scale and viewpoint and efficiently identifies all recurring composition of object across image we then model the discovered group of object using the deformable part based model our experiment on a variety of datasets show that using group of object can significantly boost the performance of object detection and scene categorization 
in this paper we study the problem of fine grained image categorization the goal of our method is to explore fine image statistic and identify the discriminative image patch for recognition we achieve this goal by combining two idea discriminative feature mining and randomization discriminative feature mining allows u to model the detailed information that distinguishes different class of image while randomization allows u to handle the huge feature space and prevents over fitting we propose a random forest with discriminative decision tree algorithm where every tree node is a discriminative classifier that is trained by combining the information in this node a well a all upstream node our method is tested on both subordinate categorization and activity recognition datasets experimental result show that our method identifies semantically meaningful visual information and outperforms state of the art algorithm on various datasets 
we describe a directed bilinear model that learns higher order grouping among feature of natural image the model represents image in term of two set of latent variable one set of variable represents which feature group are active while the other specifies the relative activity within group such a factorized representation is beneficial because it is stable in response to small variation in the placement of feature while still preserving information about relative spatial relationship when trained on mnist digit the resulting representation provides state of the art performance in classification using a simple classifier when trained on natural image the model learns to group feature according to proximity in position orientation and scale the model achieves high log likelihood nats surpassing the current state of the art for natural image achievable with an mcrbm model 
in this paper we develop an algorithm for action recognition and localization in video the algorithm us a figure centric visual word representation different from previous approach it doe not require reliable human detection and tracking a input instead the person location is treated a a latent variable that is inferred simultaneously with action recognition a spatial model for an action is learned in a discriminative fashion under a figure centric representation temporal smoothness over video sequence is also enforced we present result on the ucf sport dataset verifying the effectiveness of our model in situation where detection and tracking of individual is challenging 
this paper considers the problem of reconstructing the shape of thin texture le object such a leafless tree when there is noise or deterministic error in the silhouette extraction step or there are small error in camera calibration traditional intersection based technique such a the visual hull are not robust to error because they penalize false negative and false positive error unequally we provide a voxel based formalism that penalizes false negative and positive error equally by casting the reconstruction problem a a pseudo boolean minimization problem where voxels are the variable of a pseudo boolean function and are labeled occupied or empty since the pseudo boolean minimization problem is np hard for nonsubmodular function we developed an algorithm for an approximate solution using local minimum search our algorithm treat input binary probability map in other word silhouette or continuously valued probability map identically and place no constraint on camera placement the algorithm wa tested on three different leafless tree and one metal object where the number of voxels is million voxel side measure mm result show that our approach reconstructs the complicated branching structure of thin texture le object in the presence of error where intersection based approach currently fail 
many object class are primarily defined by their function however this fact ha been left largely unexploited by visual object categorization or detection system we propose a method to learn an affordance detector it identifies location in the d space which support the particular function our novel approach imago an actor performing an action typical for the target object class instead of relying purely on the visual object appearance so function is handled a a cue complementary to appearance rather than being a consideration after appearance based detection experimental result are given for the functional category sitting such affordance is tested on a d representation of the scene a can be realistically obtained through sfm or depth camera in contrast to appearance based object detector affordance detection requires only very few training example and generalizes very well to other sittable object like bench or sofa when trained on a few chair 
the double opponent color sensitive cell in the primary visual cortex v of the human visual system hvs have long been recognized a the physiological basis of color constancy we introduce a new color constancy model by imitating the functional property of the hvs from the retina to the double opponent cell in v the idea behind the model originates from the observation that the color distribution of the response of double opponent cell to the input color biased image coincides well with the light source direction then the true illuminant color of a scene is easily estimated by searching for the maximum of the separate rgb channel of the response of double opponent cell in the rgb space our systematical experimental evaluation on two commonly used image datasets show that the proposed model can produce competitive result in comparison to the complex state of the art approach but with a simple implementation and without the need for training 
we address the problem of reconstructing d face model from large unstructured photo collection e g obtained by google image search or from personal photo collection in iphoto this problem is extremely challenging due to the high degree of variability in pose illumination facial expression non rigid change in face shape and reflectance over time and occlusion in light of this extreme variability no single reconstruction can be consistent with all of the image instead we define a the goal of reconstruction to recover a model that is locally consistent with the image set i e each local region of the model is consistent with a large set of photo resulting in a model that capture the dominant trend in the input data for different part of the face our approach leverage multi image shading but unlike traditional photometric stereo approach allows for change in viewpoint and shape we optimize over pose shape and lighting in an iterative approach that seek to minimize the rank of the transformed image this approach produce high quality shape model for a wide range of celebrity from photo available on the internet 
latent variable model have been applied to a number of computer vision problem however the complexity of the latent space is typically left a a free design choice a larger latent space result in a more expressive model but such model are prone to over fitting and are slower to perform inference with the goal of this paper is to regularize the complexity of the latent space and learn which hidden state are really relevant for prediction specifically we propose using group sparsity inducing regularizers such a l l to estimate the parameter of structured svms with unstructured latent variable our experiment on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model 
trust region is a well known general iterative approach to optimization which offer many advantage over standard gradient descent technique in particular it allows more accurate nonlinear approximation model in each iteration this approach computes a global optimum of a suitable approximation model within a fixed radius around the current solution a k a trust region in general this approach can be used only when some efficient constrained optimization algorithm is available for the selected non linear more accurate approximation model in this paper we propose a fast trust region ftr approach for optimization of segmentation energy with non linear regional term which are known to be challenging for existing algorithm these energy include but are not limited to kl divergence and bhattacharyya distance between the observed and the target appearance distribution volume constraint on segment size and shape prior constraint in a form of l distance from target shape moment our method is order of magnitude faster than the existing state of the art method while converging to comparable or better solution 
progress in action recognition ha been in large part due to advance in the feature that drive learning based method however the relative sparsity of training data and the risk of overfitting have made it difficult to directly search for good feature in this paper we suggest using synthetic data to search for robust feature that can more easily take advantage of limited data rather than using the synthetic data directly a a substitute for real data we demonstrate that the feature discovered by our selection method which we call seeding improve performance on an action classification task on real data even though the synthetic data from which the feature are seeded differs significantly from the real data both in term of appearance and the set of action class 
in this paper we propose a novel approach to extract primary object segment in video in the object proposal domain the extracted primary object region are then used to build object model for optimized video segmentation the proposed approach ha several contribution first a novel layered directed acyclic graph dag based framework is presented for detection and segmentation of the primary object in video we exploit the fact that in general object are spatially cohesive and characterized by locally smooth motion trajectory to extract the primary object from the set of all available proposal based on motion appearance and predicted shape similarity across frame second the dag is initialized with an enhanced object proposal set where motion based proposal prediction from adjacent frame are used to expand the set of object proposal for a particular frame last the paper present a motion scoring function for selection of object proposal that emphasizes high optical flow gradient at proposal boundary to discriminate between moving object and the background the proposed approach is evaluated using several challenging benchmark video and it outperforms both unsupervised and supervised state of the art method 
spectral clustering is an elegant and powerful approach for clustering however the underlying eigen decomposition take cubic time and quadratic space w r t the data set size these can be reduced by the nystro m method which sample only a subset of column from the matrix however the manipulation and storage of these sampled column can still be expensive when the data set is large in this paper we propose a timeand space efficient spectral clustering algorithm which can scale to very large data set a general procedure to orthogonalize the approximated eigenvectors is also proposed extensive spectral clustering experiment on a number of data set ranging in size from a few thousand to several million demonstrate the accuracy and scalability of the proposed approach we further apply it to the task of image segmentation for image with more than million pixel this algorithm can obtain the eigenvectors in minute on a single machine 
having a sensible prior of human pose is a vital ingredient for many computer vision application including tracking and pose estimation while the application of global non parametric approach and parametric model ha led to some success finding the right balance in term of flexibility and tractability a well a estimating model parameter from data ha turned out to be challenging in this work we introduce a sparse bayesian network model of human pose that is non parametric with respect to the estimation of both it graph structure and it local distribution we describe an efficient sampling scheme for our model and show it tractability for the computation of exact log likelihood we empirically validate our approach on the human m dataset and demonstrate superior performance to global model and parametric network we further illustrate our model s ability to represent and compose pose not present in the training set compositionality and describe a speed accuracy trade off that allows real time scoring of pose 
we are interested in holistic scene understanding where image are accompanied with text in the form of complex sentential description we propose a holistic conditional random field model for semantic parsing which reason jointly about which object are present in the scene their spatial extent a well a semantic segmentation and employ text a well a image information a input we automatically parse the sentence and extract object and their relationship and incorporate them into the model both via potential a well a by re ranking candidate detection we demonstrate the effectiveness of our approach in the challenging uiuc sentence dataset and show segmentation improvement of over the visual only model and detection improvement of ap over deformable part based model 
trajectory basis non rigid structure from motion nrsfm currently face two problem the limit of reconstructability and the need to tune the basis size for different sequence this paper provides a novel theoretical bound on d reconstruction error arguing that the existing definition of reconstructability is fundamentally flawed in that it fails to consider system condition this insight motivates a novel strategy whereby the trajectory s response to a set of high pas filter is minimised the new approach eliminates the need to tune the basis size and is more efficient for long sequence additionally the truncated dct basis is shown to have a dual interpretation a a high pas filter the success of trajectory filter reconstruction is demonstrated quantitatively on synthetic projection of real motion capture sequence and qualitatively on real image sequence 
recent attempt of integrating metric learning in visual tracking have produced encouraging result instead of using fixed and pre specified metric in visual appearance matching these method are able to learn and adjust the metric adaptively by finding the best projection of the feature space such learned metric is by design the best to discriminate the target of interest and it distracters from the background however an important issue remained unaddressed is how we can determine the optimal dimensionality of the projection to achieve best discrimination using inappropriate dimension for the projection is likely to result in larger classification error or higher computational cost and over fitting this paper present a novel solution to this structural order determination problem by introducing sparsity regularization for metric learning or srml this regularization lead to the lowest possible dimensionality of the projection and thus determining the best order this can actually be viewed a the minimum description length regularization in metric learning the experiment validate this new approach on standard benchmark datasets and demonstrate it effectiveness in visual tracking application 
graph and hypergraph matching are important problem in computer vision they are successfully used in many application requiring d or d feature matching such a d reconstruction and object recognition while graph matching is limited to using pairwise relationship hypergraph matching permit the use of relationship between set of feature of any order consequently it carry the promise to make matching more robust to change in scale deformation and outlier in this paper we make two contribution first we present a first semi supervised algorithm for learning the parameter that control the hypergraph matching model and demonstrate experimentally that it significantly improves the performance of current state of the art method second we propose a novel efficient hypergraph matching algorithm which outperforms the state of the art and when used in combination with other higher order matching algorithm it consistently improves their performance 
hidden markov model hmms are among the most important and widely used technique to deal with sequential or temporal data their application in computer vision range from action gesture recognition to videosurveillance through shape analysis although hmms are often embedded in complex framework this paper focus on theoretical aspect of hmm learning we propose a regularized algorithm for learning hmms in the spectral framework whose computation have no local minimum compared with recently proposed spectral algorithm for hmms our method is guaranteed to produce probability value which are always physically meaningful and which on synthetic mathematical model give very good approximation to true probability value furthermore we place no restriction on the number of symbol and the number of state on various pattern recognition data set our algorithm consistently outperforms classical hmms both in accuracy and computational speed this and the fact that hmms are used in vision a building block for more powerful classification approach such a generative embedding approach or more complex generative model strongly support spectral hmms shmms a a new basic tool for pattern recognition 
this paper introduces simultaneous globally optimal hand eye self calibration in both it rotational and translational component the main contribution are new feasibility test to integrate the hand eye calibration problem into a branch and bound parameter space search the presented method constitutes the first guaranteed globally optimal estimator for simultaneous optimization of both component with respect to a cost function based on reprojection error the system is evaluated in both synthetic and real world scenario the employed benchmark dataset is published online to create a common point of reference for evaluation of hand eye self calibration algorithm 
aesthetic quality classification play an important role in how people organize large photo collection in particular color harmony is a key factor in the various aspect that determine the perceived quality of a photo and it should be taken into account to improve the performance of automatic aesthetic quality classification however the existing model of color harmony take only simple color pattern into consideration e g patch consisting of a few color and thus cannot be used to ass photo with complicated color arrangement in this work we tackle the challenging problem of evaluating the color harmony of photo with a particular focus on aesthetic quality classification a key point is that a photograph can be seen a a collection of local region with color variation that are relatively simple this led u to develop a method for assessing the aesthetic quality of a photo based on the photo s color harmony we term the method bag of color pattern result of experiment on a large photo collection with user provided aesthetic quality score show that our aesthetic quality classification method which explicitly take into account the color harmony of a photo outperforms the existing method result also show that the classification performance is improved by combining our color harmony feature with blur edge and saliency feature that reflect the aesthetic of the photo 
recovering arbitrarily corrupted low rank matrix arises in computer vision application including bioinformatic data analysis and visual tracking the method used involve minimizing a combination of nuclear norm and l norm we show that by replacing the l norm on error item with nonconvex m estimator exact recovery of densely corrupted low rank matrix is possible the robustness of the proposed method is guaranteed by the m estimator theory the multiplicative form of half quadratic optimization is used to simplify the nonconvex optimization problem so that it can be efficiently solved by iterative regularization scheme simulation result corroborate our claim and demonstrate the efficiency of our proposed method under tough condition 
this paper address the problem of estimating the pose of a reference plane in specular shape recovery unlike existing method which require an extra mirror or an extra reference plane and camera our proposed method recovers the pose of the reference plane directly from it reflection on the specular surface by establishing reflection correspondence on the reference plane in three distinct pose our method estimate the pose of the reference plane in two step first by applying a colinearity constraint to the reflection correspondence a simple closed form solution is derived for recovering the pose of the reference plane relative to it initial pose second by applying a ray incidence constraint to the incident ray formed by the reflection correspondence and the visual ray cast from the image a closed form solution is derived for recovering the pose of the reference plane relative to the camera the shape of the specular surface then follows experimental result on both synthetic and real data are presented which demonstrate the feasibility and accuracy of our proposed method 
d volumetric reasoning is important for truly understanding a scene human are able to both segment each object in an image and perceive a rich d interpretation of the scene e g the space an object occupies which object support other object and which object would if moved cause other object to fall we propose a new approach for parsing rgb d image using d block unit for volumetric reasoning the algorithm fit image segment with d block and iteratively evaluates the scene based on block interaction property we produce a d representation of the scene based on jointly optimizing over segmentation block fitting supporting relation and object stability our algorithm incorporates the intuition that a good d representation of the scene is the one that fit the data well and is a stable self supporting i e one that doe not topple arrangement of object we experiment on several datasets including controlled and real indoor scenario result show that our stability reasoning framework improves rgb d segmentation and scene volumetric representation 
visual attribute are powerful feature for many different application in computer vision such a object detection and scene recognition visual attribute present another application that ha not been examined a rigorously verbal communication from a computer to a human since many attribute are nameable the computer is able to communicate these concept through language however this is not a trivial task given a set of attribute selecting a subset to be communicated is task dependent moreover because attribute classifier are noisy it is important to find way to deal with this uncertainty we address the issue of communication by examining the task of composing an automatic description of a person in a group photo that distinguishes him from the others we introduce an efficient principled method for choosing which attribute are included in a short description to maximize the likelihood that a third party will correctly guess to which person the description refers we compare our algorithm to computer baseline and human describers and show the strength of our method in creating effective description 
an informative and discriminative graph play an important role in the graph based semi supervised learning method this paper introduces a nonnegative sparse algorithm and it approximated algorithm based on the l l equivalence theory to compute the nonnegative sparse weight of a graph hence the sparse probability graph spg is termed for representing the proposed method the nonnegative sparse weight in the graph naturally serve a clustering indicator benefiting for semi supervised learning more important our approximation algorithm speed up the computation of the nonnegative sparse coding which is still a bottle neck for any previous attempt of sparse non negative graph learning and it is much more efficient than using l norm sparsity technique for learning large scale sparse graph finally for discriminative semi supervised learning an adaptive label propagation algorithm is also proposed to iteratively predict the label of data on the spg promising experimental result show that the nonnegative sparse coding is efficient and effective for discriminative semi supervised learning 
image retargeting algorithm attempt to adapt the image content to the screen without distorting the important object in the scene existing method address retargeting of a single image in this paper we propose a novel method for retargeting a pair of stereo image naively retargeting each image independently will distort the geometric structure and make it impossible to perceive the d structure of the scene we show how to extend a single image seam carving to work on a pair of image our method minimizes the visual distortion in each of the image a well a the depth distortion a key property of the proposed method is that it take into account the visibility relation between pixel in the image pair occluded and occluding pixel a a result our method guarantee a we formally prove that the retargeted pair is geometrically consistent with a feasible d scene similar to the original one hence the retargeted stereo pair can be viewed on a stereoscopic display or processed by any computer vision algorithm we demonstrate our method on a number of challenging indoor and outdoor stereo image 
wiberg matrix factorization break a matrix y into low rank factor u and v by solving for v in closed form given u linearizing v u about u and iteratively minimizing y uv u with respect to u only this approach factor the matrix while effectively removing v from the minimization recently eriksson and van den hengel extended this approach to l minimizing y uv u we generalize their approach beyond factorization to minimize an arbitrary function that is nonlinear in each of two set of variable we demonstrate the idea with a practical wiberg algorithm for l bundle adjustment we also show that one wiberg minimization can be nested inside another effectively removing two of three set of variable from a minimization we demonstrate this idea with a nested wiberg algorithm for l projective bundle adjustment solving for camera matrix point and projective depth we also revisit l factorization giving a greatly simplified presentation of wiberg l factorization and presenting a successive linear programming factorization algorithm successive linear programming outperforms l wiberg for most large input establishing a new state of the art for for those case 
this paper discus the problem of recognizing interaction level human activity from a first person viewpoint the goal is to enable an observer e g a robot or a wearable camera to understand what activity others are performing to it from continuous video input these include friendly interaction such a a person hugging the observer a well a hostile interaction like punching the observer or throwing object to the observer whose video involve a large amount of camera ego motion caused by physical interaction the paper investigates multi channel kernel to integrate global and local motion information and present a new activity learning recognition methodology that explicitly considers temporal structure displayed in first person activity video in our experiment we not only show classification result with segmented video but also confirm that our new approach is able to detect activity from continuous video reliably 
this paper present an automatic and robust approach that accurately capture high quality d facial performance using a single rgbd camera the key of our approach is to combine the power of automatic facial feature detection and image based d nonrigid registration technique for d facial reconstruction in particular we develop a robust and accurate image based nonrigid registration algorithm that incrementally deforms a d template mesh model to best match observed depth image data and important facial feature detected from single rgbd image the whole process is fully automatic and robust because it is based on single frame facial registration framework the system is flexible because it doe not require any strong d facial prior such a blend shape model we demonstrate the power of our approach by capturing a wide range of d facial expression using a single rgbd camera and achieve state of the art accuracy by comparing against alternative method 
this paper present an efficient method to tell what happens e g recognize action in a video sequence from only a couple of frame in real time for the sake of instantaneity we employ two type of computationally efficient but perceptually important feature optical flow and edge to capture motion and shape structure information in video sequence it is known that the two type of feature are not sparse and can be unreliable or ambiguous at certain part of a video in order to endow them with strong discriminative power we extend an efficient contrast set mining technique the emerging pattern ep mining method to learn joint feature from video to differentiate action class experimental result show that the combination of the two type of feature achieves superior performance in differentiating action than that of using each single type of feature alone the learned feature are discriminative statistically significant reliable and display semantically meaningful shape motion structure of human action besides the instant action recognition we also extend the proposed approach to anomaly detection and sequential event detection the experiment demonstrate encouraging result 
we address the task of pixel level hand detection in the context of ego centric camera extracting hand region in ego centric video is a critical step for understanding hand object manipulation and analyzing hand eye coordination however in contrast to traditional application of hand detection such a gesture interface or sign language recognition ego centric video present new challenge such a rapid change in illumination significant camera motion and complex hand object manipulation to quantify the challenge and performance in this new domain we present a fully labeled indoor outdoor ego centric hand detection benchmark dataset containing over million labeled pixel which contains hand image taken under various illumination condition using both our dataset and a publicly available ego centric indoors dataset we give extensive analysis of detection performance using a wide range of local appearance feature our analysis highlight the effectiveness of sparse feature and the importance of modeling global illumination we propose a modeling strategy based on our finding and show that our model outperforms several baseline approach 
the success of sparse representation based classification src ha largely boosted the research of sparsity based face recognition in recent year a prevailing view is that the sparsity based face recognition performs well only when the training image have been carefully controlled and the number of sample per class is sufficiently large this paper challenge the prevailing view by proposing a prototype plus variation representation model for sparsity based face recognition based on the new model a superposed src ssrc in which the dictionary is assembled by the class centroid and the sample to centroid difference lead to a substantial improvement on src the experiment result on ar feret and frgc database validate that if the proposed prototype plus variation representation model is applied sparse coding play a crucial role in face recognition and performs well even when the dictionary base are collected under uncontrolled condition and only a single sample per class is available 
in this paper we revisit the classical perspective n point pnp problem and propose the first non iterative o n solution that is fast generally applicable and globally optimal our basic idea is to formulate the pnp problem into a functional minimization problem and retrieve all it stationary point by using the gr obner basis technique the novelty lie in a non unit quaternion representation to parameterize the rotation and a simple but elegant formulation of the pnp problem into an unconstrained optimization problem interestingly the polynomial system arising from it first order optimality condition assumes two fold symmetry a nice property that can be utilized to improve speed and numerical stability of a grobner basis solver experiment result have demonstrated that in term of accuracy our proposed solution is definitely better than the state of the art o n method and even comparable with the reprojection error minimization method 
we address the problem of multi person tracking in a complex scene from a single camera although tracklet association method have shown impressive result in several challenging datasets discriminability of the appearance model remains a limitation inspired by the work of person identity recognition we obtain discriminative appearance based affinity model by a novel framework to incorporate the merit of person identity recognition which help multi person tracking performance during off line learning a small set of local image descriptor is selected to be used in on line learned appearance based affinity model effectively and efficiently given short but reliable track let generated by frame to frame association of detection response we identify them a query tracklets and gallery tracklets for each gallery tracklet a target specific appearance model is learned from the on line training sample collected by spatio temporal constraint both gallery tracklets and query tracklets are fed into hierarchical association framework to obtain final tracking result we evaluate our proposed system on several public datasets and show significant improvement in term of tracking evaluation metric 
we introduce an algorithm svm is for structured svm learning that is computationally scalable to very large datasets and complex structural representation we show that structured learning is at least a fast and often much faster than method based on binary classification for problem such a deformable part model object detection and multiclass classification while achieving accuracy that are at least a good our method allows problem specific structural knowledge to be exploited for faster optimization by integrating with a user defined importance sampling function we demonstrate fast train time on two challenging large scale datasets for two very different problem image net for multiclass classification and cub for deformable part model training our method is shown to be time faster than mathrm svm mathrm struct for cost sensitive multiclass classification while being about a fast a the fastest v all method for multiclass classification for deformable part model training it is shown to be time faster than method based on svm struct mining hard negative and pegasos style stochastic gradient descent source code of our method is publicly available 
in this paper we propose a novel video foreground detection method that exploit the statistic of d spacetime patch d space time patch are characterized by mean of the subspace they span a the complexity of real time system prohibits performing this modeling directly on the raw pixel data we propose a novel framework in which spatiotemporal data is sequentially reduced in two stage the first stage reduces the data using a cascade of linear projection of d space time patch onto a small set of d walsh hadamard wh basis function known for it energy compaction of natural image and video this stage is efficiently implemented using the gray code filtering scheme requiring only operation per projection in the second stage the data is further reduced by applying pca directly to the wh coefficient exploiting the local statistic in an adaptive manner unlike common technique this spatiotemporal adaptive projection exploit window appearance a well a it dynamic characteristic test show that the proposed method outperforms recent foreground detection method and is suitable for real time implementation on streaming video 
scene text recognition ha gained significant attention from the computer vision community in recent year recognizing such text is a challenging problem even more so than the recognition of scanned document in this work we focus on the problem of recognizing text extracted from street image we present a framework that exploit both bottom up and top down cue the bottom up cue are derived from individual character detection from the image we build a conditional random field model on these detection to jointly model the strength of the detection and the interaction between them we impose top down cue obtained from a lexicon based prior i e language statistic on the model the optimal word represented by the text image is obtained by minimizing the energy function corresponding to the random field model we show significant improvement in accuracy on two challenging public datasets namely street view text over and icdar nearly 
d shape matching is an important problem in computer vision one of the major difficulty in finding dense correspondence between d shape is related to the topological discrepancy that often arise due to complex kinematic motion in this paper we propose a shape matching method that is robust to such change in topology the algorithm start from a sparse set of seed match and output dense matching we propose to use a shape descriptor based on property of the heat kernel and which provides an intrinsic scale space representation this descriptor incorporates i heat flow from already matched point and ii self diffusion at small scale the descriptor behaves locally and hence it is robust to global change in topology therefore it can be used to build a vertex to vertex matching score conditioned by an initial correspondence set this score is then used to iteratively add new correspondence based on a novel seed growing method that iteratively propagates the seed correspondence to nearby vertex the matching is farther densified via an em like method that explores the congruency between the two shape embeddings our method is compared with two recently proposed algorithm and we show that we can deal with substantial topological difference between the two shape 
while the detection of the interesting region in image ha been extensively studied relatively few paper have addressed surface this paper proposes an algorithm for detecting the region of interest of surface it look for region that are distinct both locally and globally and account for the distance to the focus of attention many application can utilize these region in this paper we explore one such application viewpoint selection the most informative view are those that collectively provide the most descriptive presentation of the surface we show that our result compete favorably with the state of the art result 
we address the problem of learning view invariant d model of human motion from motion capture data in order to recognize human action from a monocular video sequence with arbitrary viewpoint we propose a spatio temporal manifold stm model to analyze non linear multivariate time series with latent spatial structure and apply it to recognize action in the joint trajectory space based on stm a novel alignment algorithm dynamic manifold warping dmw and a robust motion similarity metric are proposed for human action sequence both in d and d dmw extends previous work on spatio temporal alignment by incorporating manifold learning we evaluate and compare the approach to state of the art method on motion capture data and realistic video experimental result demonstrate the effectiveness of our approach which yield visually appealing alignment result produce higher action recognition accuracy and can recognize action from arbitrary view with partial occlusion 
human visual system hvs can perceive constant color under varying illumination condition while digital image record information of both reflectance physical color of object and illumination retinex theory formulated by edwin h land aimed to simulate and explain this feature of hvs however to recover the reflectance from a given image is in general an ill posed problem in this paper we establish an l based variational model for retinex theory that can be solved by a fast computational approach based on bregman iteration compared with previous work our l retinex method is more accurate for recovering the reflectance which is illustrated by example and statistic in medical image such a magnetic resonance imaging mri intensity inhomogeneity is often encountered due to bias field this is a similar formulation to retinex theory while the mri ha some specific property we then modify the l retinex method and develop a new algorithm for mri data we demonstrate the performance of our method by comparison with previous work on simulated and real data 
in this paper we study the problem of how to segment a freehand sketch at the object level by carefully considering the basic principle of human perceptual organization a real time solution is presented to automatically segment a user s sketch during his her drawing first a graph based sketch segmentation algorithm is proposed to segment a cluttered sketch into multiple part based on the factor of proximity then to improve the ability of detecting semantically meaningful object a semantic based approach is introduced to simulate the past experience in the perceptual system by leveraging a web scale clipart database finally other important factor learnt from past experience such a similarity symmetry direction and closure are also taken into account to make the approach more robust and practical the proposed sketch segmentation framework ha ability to handle complex sketch with overlapped object extensive experimental result show the effectiveness of the proposed framework and algorithm 
we present a linear method for global camera pose registration from pair wise relative pose encoded in essential matrix our method minimizes an approximate geometric error to enforce the triangular relationship in camera triplet this formulation doe not suffer from the typical unbalanced scale problem in linear method relying on pair wise translation direction constraint i e an algebraic error nor the system degeneracy from collinear motion in the case of three camera our method provides a good linear approximation of the trifocal tensor it can be directly scaled up to register multiple camera the result obtained are accurate for point triangulation and can serve a a good initialization for final bundle adjustment we evaluate the algorithm performance with different type of data and demonstrate it effectiveness our system produce good accuracy robustness and outperforms some well known system on efficiency 
kernel method have been popular over the last decade to solve many computer vision statistic and machine learning problem an important both theoretically and practically open problem in kernel method is the pre image problem the pre image problem consists of finding a vector in the input space whose mapping is known in the feature space induced by a kernel to solve the pre image problem this paper proposes a framework that computes an isomorphism between local gram matrix in the input and feature space unlike existing method that rely on analytic property of kernel our framework derives closed form solution to the pre image problem in the case of non differentiable and application specific kernel experiment on the pre image problem for visualizing cluster center computed by kernel k mean and denoising high dimensional image show that our algorithm outperforms state of the art method 
the aim of this paper is fine grained categorization without human interaction different from prior work which relies on detector for specific object part we propose to localize distinctive detail by roughly aligning the object using just the overall shape since implicit to fine grained categorization is the existence of a super class shape shared among all class the alignment are then used to transfer part annotation from training image to test image supervised alignment or to blindly yet consistently segment the object in a number of region unsupervised alignment we furthermore argue that in the distinction of fine grained sub category classification oriented encoding like fisher vector are better suited for describing localized information than popular matching oriented feature like hog we evaluate the method on the cu bird and stanford dog fine grained datasets outperforming the state of the art 
recent technological advance have allowed for a proliferation of digital evidence image using these image a evidence in legal case e g child sexual abuse child pornography and masked gunman can be very challenging because the face of criminal or victim are not visible although large skin mark and tattoo have been used they are ineffective in some legal case because the skin exposed in evidence image neither have unique tattoo nor enough skin mark for identification the blood vessel between the skin and the muscle covering most part of the human body is a powerful biometric trait because of it universality permanence and distinctiveness traditionally it wa impossible to use vein pattern for forensic identification because they were not visible in color image this paper proposes an algorithm to uncover vein pattern from the skin exposed in color image for personal identification based on the principle of optic and skin biophysics we modeled the inverse process of skin color formation in an image and derived spatial distribution of biophysical parameter from color image where vein pattern can be observed experimental result are very encouraging the clarity of the vein pattern in resultant image is comparable to or even better than that in near infrared image 
computing a faithful affinity map is essential to the clustering and segmentation task in this paper we propose a graph based affinity metric learning method and show it application to image clustering and segmentation our method self diffusion sd performs a diffusion process by propagating the similarity mass along the intrinsic manifold of data point theoretical analysis is given to the sd algorithm and we provide a way of deriving the critical time stamp t our method therefore ha nearly no parameter tuning and lead to significantly improved affinity map which help to greatly enhance the quality of clustering in addition we show that much improved image segmentation result can be obtained by combining sd with e g the normalized cut algorithm the proposed method can be used to deliver robust affinity map for a range of problem 
this paper present a simple and highly effective system for robust texture classification based on random local feature a simple global bag of word bow representation and support vector machine svms based classification the key contribution in this work is to apply a sorting strategy to a universal yet information preserving random projection rp technique then comparing two different texture image representation histogram and signature with various kernel in the svms we have tested our texture classification system on six popular and challenging texture database for exemplar based texture classification comparing with recent state of the art method experimental result show that our texture classification system yield the best classification rate of which we are aware of for curet for brodatz for umd and for kth tip moreover combining random feature significantly outperforms the state of the art descriptor in material categorization 
over the last year several author have signaled that state of the art categorization method fail to perform well when trained and tested on data from different database the general consensus in the literature is that this issue known a domain adaptation and or dataset bias is due to a distribution mismatch between data collection method addressing it go from max margin classifier to learning how to modify the feature and obtain a more robust representation the large majority of these work use bow feature descriptor and learning method based on image to image distance function following the seminal work of in this paper we challenge these two assumption we experimentally show that using the nbnn classifier over existing domain adaptation database achieves always very strong performance we build on this result and present an nbnn based domain adaptation algorithm that learns iteratively a class metric while inducing for each sample a large margin separation among class to the best of our knowledge this is the first work casting the domain adaptation problem within the nbnn framework experiment show that our method achieves the state of the art both in the unsupervised and semi supervised setting 
we propose a method for removing marked dynamic object from video captured with a free moving camera so long a the object occlude part of the scene with a static background our approach take a input a video a mask marking the object to be removed and a mask marking the dynamic object to remain in the scene to inpaint a frame we align other candidate frame in which part of the missing region are visible among these candidate a single source is chosen to fill each pixel so that the final arrangement is color consistent intensity difference between source are smoothed using gradient domain fusion our frame alignment process assumes that the scene can be approximated using piecewise planar geometry a set of homographies is estimated for each frame pair and one each is selected for aligning pixel such that the color discrepancy is minimized and the epipolar constraint are maintained we provide experimental validation with several real world video sequence to demonstrate that unlike in previous work inpainting video shot with free moving camera doe not necessarily require estimation of absolute camera position and per frame per pixel depth map 
the performance of current state of the art computer vision algorithm at image classification fall significantly short a compared to human ability to reduce this gap it is important for the community to know what problem to solve and not just how to solve them towards this goal via the use of jumbled image we strip apart two widely investigated aspect local and global information in image and identify the performance bottleneck interestingly human have been shown to reliably recognize jumbled image the goal of our paper is to determine a functional model that mimic how human recognize jumbled image i e exploit local information alone and further evaluate if existing implementation of this computational model suffice to match human performance surprisingly in our series of human study and machine experiment we find that a simple bag of word based majority vote like strategy is an accurate functional model of how human recognize jumbled image moreover a straightforward machine implementation of this model achieves accuracy similar to human subject at classifying jumbled image this indicates that perhaps existing machine vision technique already leverage local information from image effectively and future research effort should be focused on more advanced modeling of global information 
we present a new algorithm dnn d nearest neighbor which is capable of matching an image with d data independently of the viewpoint from which the image wa captured by leveraging rich annotation associated with each image our algorithm can automatically produce precise and detailed d model of a scene from a single image moreover we can transfer information across image to accurately label and segment object in a scene the true benefit of dnn compared to a traditional d nearest neighbor approach is that by generalizing across viewpoint we free ourselves from the need to have training example captured from all possible viewpoint thus we are able to achieve comparable result using order of magnitude le data and recognize object from never before seen viewpoint in this work we describe the dnn algorithm and rigorously evaluate it performance for the task of geometry estimation and object detection segmentation by decoupling the viewpoint and the geometry of an image we develop a scene matching approach which is truly viewpoint invariant yielding state of the art performance on challenging data 
we show how to incorporate a statistical shape model into the nonrigid icp framework and propose a robust nonrigid icp algorithm in the nonrigid icp framework a template surface is represented by a set of point and the shape of the template is parametrized by a transformation matrix per one template point in the proposed method the statistic of the matrix are estimated based on a set of training surface and the statistical shape model is incorporated into the nonrigid icp framework by modifying the representation of the stiffness of the template the statistical shape model and a noise model make it possible to discriminate outlier from inliers in given target our proposed method detects the outlier which are not represented by the model appropriately based on their sparseness the detected outlier are automatically excluded from the target to be registered and the template is deformed to fit the inliers only a the result the accuracy of the registration is improved the performance of the proposed method is evaluated qualitatively and quantitatively using synthetic data and clinical ct image 
a conventional approach to learning object detector us fully supervised learning technique which assumes that a training image set with manual annotation of object bounding box are provided the manual annotation of object in large image set is tedious and unreliable therefore a weakly supervised learning approach is desirable where the training set need only binary label regarding whether an image contains the target object class in the weakly supervised approach a detector is used to iteratively annotate the training set and learn the object model we present a novel weakly supervised learning framework for learning an object detector our framework incorporates a new initial annotation model to start the iterative learning of a detector and a model drift detection method that is able to detect and stop the iterative learning when the detector start to drift away from the object of interest we demonstrate the effectiveness of our approach on the challenging pascal dataset 
effective reduction of false alarm in large scale video surveillance is rather challenging especially for application where abnormal event of interest rarely occur such a abandoned object detection we develop an approach to prioritize alert by ranking them and demonstrate it great effectiveness in reducing false positive while keeping good detection accuracy our approach benefit from a novel representation of abandoned object alert by relative attribute namely static ness foreground ness and abandonment the relative strength of these attribute are quantified using a ranking function learnt on suitably designed low level spatial and temporal feature these attribute of varying strength are not only powerful in distinguishing abandoned object from false alarm such a people and light artifact but also computationally efficient for large scale deployment with these feature we apply a linear ranking algorithm to sort alert according to their relevance to the end user we test the effectiveness of our approach on both public data set and large one collected from the real world 
video provides not only rich visual cue such a motion and appearance but also much le explored long range temporal interaction among object we aim to capture such interaction and to construct a powerful intermediate level video representation for subsequent recognition motivated by this goal we seek to obtain spatio temporal oversegmentation of a video into region that respect object boundary and at the same time associate object pixel over many video frame the contribution of this paper are two fold first we develop an efficient spatiotemporal video segmentation algorithm which naturally incorporates long range motion cue from the past and future frame in the form of cluster of point track with coherent motion second we devise a new track clustering cost function that includes occlusion reasoning in the form of depth ordering constraint a well a motion similarity along the track we evaluate the proposed approach on a challenging set of video sequence of office scene from feature length movie 
active learning is an effective way of engaging user to interactively train model for visual recognition the vast majority of previous work if not all of them focused on active learning with a single human oracle the problem of active learning with multiple oracle in a collaborative setting ha not been well explored moreover most of the previous work assume that the label provided by the human oracle are noise free which may often be violated in reality we present a collaborative computational model for active learning with multiple human oracle it lead to not only an ensemble kernel machine that is robust to label noise but also a principled label quality measure to online detect irresponsible labelers instead of running independent active learning process for each individual human oracle our model capture the inherent correlation among the labelers through shared data among them our simulation experiment and experiment with real crowd sourced noisy label demonstrated the efficacy of our model 
this paper present a novel intrinsic d surface distance and it use in a complete probabilistic tracking framework for dynamic d data registering two frame of a deforming d shape relies on accurate correspondence between all point across the two frame in the general case such correspondence search is computationally intractable common prior assumption on the nature of the deformation such a near rigidity isometry or learning from a training set reduce the search space but often at the price of loss of accuracy when it come to deformation not in the prior assumption if we consider the set of all possible d surface matchings defined by specifying triplet of correspondence in the uniformization domain then we introduce a new matching cost between two d surface the lowest feature difference across this set of matchings that cause two point to correspond become the matching cost of that particular correspondence we show that for surface tracking application the matching cost can be efficiently computed in the uniformization domain this matching cost is then combined with regularization term that enforce spatial and temporal motion consistency into a maximum a posteriori map problem which we approximate using a markov random field mrf compared to previous d surface tracking approach that either assume isometric deformation or consistent feature our method achieves dense accurate tracking result which we demonstrate through a series of dense anisometric d surface tracking experiment 
in this paper we propose an approach to jointly infer the room layout a well a the object present in the scene towards this goal we propose a branch and bound algorithm which is guaranteed to retrieve the global optimum of the joint problem the main difficulty resides in taking into account occlusion in order to not over count the evidence we introduce a new decomposition method which generalizes integral geometry to triangular shape and allows u to bound the different term in constant time we exploit both geometric cue and object detector a image feature and show large improvement in d and d object detection over state of the art deformable part based model 
regularizing motion field is critical to achieve accurate estimation of the motion field a the motion field may include discontinuity e g at the motion boundary traditional smoothness regularization may not work well among many approach to handling motion discontinuity recent attempt pursued a sparse representation of the motion field for regularization and achieved quite encouraging result however statistic show that these method tend to over sparsify the motion field and thus confronted by the non sparse noise in practice in this paper we propose to decompose the motion field into sparse and non sparse component for the motion boundary and small universal noise respectively this separation approach regularizes these two source differently we propose a novel and efficient optimization algorithm to solve this problem in addition our study reveals the in depth connection between this noise separation approach and the influence function approach in robust statistic we validate and evaluate our new approach on the middlebury benchmark and have achieved outstanding testing performance 
this paper present a novel approach to characterize deformable surface using intrinsic property dynamic d dynamic surface representing human in motion can be obtained using multiple view stereo reconstruction method or depth camera nowadays these technology have become capable to capture surface variation in real time and give detail such a clothing wrinkle and deformation assuming repetitive pattern in the deformation we propose to model complex surface variation using set of linear dynamical system lds where observation across time are given by surface intrinsic property such a local curvature we introduce an approach based on bag of dynamical system where each surface feature to be represented in the codebook is modeled by a set of lds equipped with timing structure experiment are performed on datasets of real world dynamical surface and show compelling result for description classification and segmentation 
we estimate illuminant chromaticity from temporal sequence for scene illuminated by either one or two dominant illuminant while there are many method for illuminant estimation from a single image few work so far have focused on video and even fewer on multiple light source our aim is to leverage information provided by the temporal acquisition where either the object or the camera or the light source are is in motion in order to estimate illuminant color without the need for user interaction or using strong assumption and heuristic we introduce a simple physically based formulation based on the assumption that the incident light chromaticity is constant over a short space time domain we show that a deterministic approach is not sufficient for accurate and robust estimation however a probabilistic formulation make it possible to implicitly integrate away hidden factor that have been ignored by the physical model experimental result are reported on a dataset of natural video sequence and on the gray ball benchmark indicating that we compare favorably with the state of the art 
content aware image retargeting ha attracted a lot of interest recently the key and most challenging issue for this task is how to balance the tradeoff between preserving the important content and minimizing the visual distortion on the consistency of the image structure in this paper we present a novel filtering based technique to tackle this issue called importance filtering specifically we first filter the image saliency guided by the image itself to achieve a structure consistent importance map we then use the pixel importance a the key constraint to compute the gradient map of pixel shift from the original resolution to the target finally we integrate the shift gradient across the image using a weighted filter to construct a smooth shift map and render the target image the weight is again controlled by the pixel importance the two filtering process enforce to maintain the structural consistency and yet preserve the important content in the target image furthermore the simple nature of filter operation allows highly efficient implementation for real time application and easy extension to video retargeting a the structural constraint from the original image naturally convey the temporal coherence between frame the effectiveness and efficiency of our importance filtering algorithm are confirmed in extensive experiment 
bag of word model for feature extraction have demonstrated top notch performance in image classification these representation are usually accompanied by a coding method recently method that code a descriptor giving regard to it nearby base have proved efficacious these method take into account the nonlinear structure of descriptor since local similarity are a good approximation of global similarity however they confine their usage of the global similarity to nearby base in this paper we propose a coding scheme that brings into focus the manifold structure of descriptor and devise a method to compute the global similarity of descriptor to the base given a local similarity measure between base a global measure is computed exploiting the local similarity of a descriptor and it nearby base a global measure of association of a descriptor to all the base is computed unlike the locality based and sparse coding method the proposed coding varies smoothly with respect to the underlying manifold experiment on benchmark image classification datasets substantiate the superiority of the proposed method over it locality and sparsity based rival 
anomaly in many video surveillance application have local spatio temporal signature namely they occur over a small time window or a small spatial region the distinguishing feature of these scenario is that outside this spatio temporal anomalous region activity appear normal we develop a probabilistic framework to account for such local spatio temporal anomaly we show that our framework admits elegant characterization of optimal decision rule a key insight of the paper is that if anomaly are local optimal decision rule are local even when the nominal behavior exhibit global spatial and temporal statistical dependency this insight help collapse the large ambient data dimension for detecting local anomaly consequently consistent data driven local empirical rule with provable performance can be derived with limited training data our empirical rule are based on score function derived from local nearest neighbor distance these rule aggregate statistic across spatio temporal location scale and produce a single composite score for video segment we demonstrate the efficacy of our scheme on several video surveillance datasets and compare with existing work 
we introduce algorithm to visualize feature space used by object detector the tool in this paper allow a human to put on hog goggles and perceive the visual world a a hog based object detector see it we found that these visualization allow u to analyze object detection system in new way and gain new insight into the detector s failure for example when we visualize the feature for high scoring false alarm we discovered that although they are clearly wrong in image space they do look deceptively similar to true positive in feature space this result suggests that many of these false alarm are caused by our choice of feature space and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these error by visualizing feature space we can gain a more intuitive understanding of our detection system 
this paper present a novel method for performing an efficient cost aggregation in stereo matching the cost aggregation problem is re formulated with a perspective of a histogram and it give u a potential to reduce the complexity of the cost aggregation significantly different from the previous method which have tried to reduce the complexity in term of the size of an image and a matching window our approach focus on reducing the computational redundancy which exists among the search range caused by a repeated filtering for all disparity hypothesis moreover we also reduce the complexity of the window based filtering through an efficient sampling scheme inside the matching window the trade off between accuracy and complexity is extensively investigated into parameter used in the proposed method experimental result show that the proposed method provides high quality disparity map with low complexity this work provides new insight into complexity constrained stereo matching algorithm design 
this paper present a comparative evaluation of feature embeddings for classification and ranking in large scale internet image datasets we follow a popular framework for scalable visual learning in which the data is first transformed by a nonlinear embedding and then an efficient linear classifier is trained in the resulting space our study includes data dependent embeddings inspired by the semi supervised learning literature and data independent one based on approximating specific kernel such a the gaussian kernel for gist feature and the histogram intersection kernel for bag of word perhaps surprisingly we find that data dependent embeddings despite being computed from large amount of unlabeled data do not have any advantage over data independent one in the regime of scarce labeled data on the other hand we find that several data dependent embeddings are competitive with popular data independent choice for large scale classification 
shaky stereoscopic video is not only unpleasant to watch but may also cause d fatigue stabilizing the left and right view of a stereoscopic video separately using a monocular stabilization method tends to both introduce undesirable vertical disparity and damage horizontal disparity which may destroy the stereoscopic viewing experience in this paper we present a joint subspace stabilization method for stereoscopic video we prove that the low rank subspace constraint for monocular video also hold for stereoscopic video particularly the feature trajectory from the left and right video share the same subspace based on this proof we develop a stereo subspace stabilization method that jointly computes a common subspace from the left and right video and us it to stabilize the two video simultaneously our method meet the stereoscopic constraint without d reconstruction or explicit left right correspondence we test our method on a variety of stereoscopic video with different scene content and camera motion the experiment show that our method achieves high quality stabilization for stereoscopic video in a robust and efficient way 
this paper proposes a new template matching method that is robust to outlier and fast enough for real time operation the template and image are densely transformed in binary code form by projecting and quantizing histogram of oriented gradient the binary code are matched by a generic method of robust similarity applicable to additive match measure such a l pand hamming distance the robust similarity map is computed efficiently via a proposed inverted location index structure that store pixel location indexed by their value the method is experimentally justified in large image patch datasets challenging application such a intra category object detection object tracking and multimodal image matching are demonstrated 
this paper proposes a sparse image representation using deformable template of simple geometric structure that are commonly observed in image of natural scene these deformable template include active curve template and active corner template an active curve template is a composition of gabor wavelet element placed with equal spacing on a straight line segment or a circular arc segment of constant curvature where each gabor wavelet element is allowed to locally shift it location and orientation so that the original line and arc segment of the active curve template can be deformed to fit the observed image an active corner or angle template is a composition of two active curve template that share a common end point and the active curve template are allowed to vary their overall length and curvature so that the original corner template can deform to match the observed image this paper then proposes a hierarchical computational architecture of summax map that pursues a sparse representation of an image by selecting a small number of active curve and corner template from a dictionary of all such template experiment show that the proposed method is capable of finding sparse representation of natural image it is also shown that object template can be learned by selecting and composing active curve and corner template 
we describe a novel image representation termed spatial pyramid co occurrence which characterizes both the photometric and geometric aspect of an image specifically the co occurrence of visual word are computed with respect to spatial predicate over a hierarchical spatial partitioning of an image the representation capture both the absolute and relative spatial arrangement of the word and through the choice and combination of the predicate can characterize a variety of spatial relationship our representation is motivated by the analysis of overhead imagery such a from satellite or aircraft this imagery generally doe not have an absolute reference frame and thus the relative spatial arrangement of the image element often becomes the key discriminating feature we validate this hypothesis using a challenging ground truth image dataset of land use class manually extracted from high resolution aerial imagery our approach is shown to result in higher classification rate than a non spatial bagofvisual word approach a well a a popular approach for characterizing the absolute spatial arrangement of visual word the spatial pyramid representation of lazebnik et al while our primary objective is analyzing overhead imagery we demonstrate that our approach achieves state of the art performance on the graz object class dataset and performs competitively on the scene dataset 
we present an approach for the text to image retrieval problem based on textual content present in image given the recent development in understanding text in image an appealing approach to address this problem is to localize and recognize the text and then query the database a in a text retrieval problem we show that such an approach despite being based on state of the art method is insufficient and propose a method where we do not rely on an exact localization and recognition pipeline we take a query driven search approach where we find approximate location of character in the text query and then impose spatial constraint to generate a ranked list of image in the database the retrieval performance is evaluated on public scene text datasets a well a three large datasets namely iiit scene text retrieval sport k and tv series m we introduce 
sparse projection ha been shown to be highly effective in several domain including image denoising and scene object classification however practical application to large scale problem such a video analysis requires efficient version of sparse projection algorithm such a orthogonal matching pursuit omp in particular random projection based locality sensitive hashing lsh ha been proposed for omp in this paper we propose a novel technique called comparison hadamard random projection chrp for further improving the efficiency of lsh within omp chrp combine two technique the fast johnson lindenstrauss transform fjlt which us a randomized hadamard transform and sparse projection matrix for lsh and achlioptas random projection that us only addition and comparison operation our approach provides the robustness of fjlt while completely avoiding multiplication we empirically validate chrp s efficacy by performing a suite of experiment for image denoising scene classification and video categorization our experiment indicate that chrp significantly speed up omp with negligible loss in classification accuracy 
in underwater environment camera need to be confined in an underwater housing viewing the scene through a piece of glass in case of flat port underwater housing light ray entering the camera housing are refracted twice due to different medium density of water glass and air this cause the usually linear ray of light to bend and the commonly used pinhole camera model to be invalid when using the pinhole camera model without explicitly modeling refraction in structure from motion sfm method a systematic model error occurs therefore in this paper we propose a system for computing camera path and d point with explicit incorporation of refraction using new method for pose estimation additionally a new error function is introduced for non linear optimization especially bundle adjustment the proposed method allows to increase reconstruction accuracy and is evaluated in a set of experiment where the proposed method s performance is compared to sfm with the perspective camera model 
in this paper we propose a novel low rank appearance model for removing rain streak different from previous work our method need neither rain pixel detection nor time consuming dictionary learning stage instead a rain streak usually reveal similar and repeated pattern on imaging scene we propose and generalize a low rank model from matrix to tensor structure in order to capture the spatio temporally correlated rain streak with the appearance model we thus remove rain streak from image video and also other high order image structure in a unified way our experimental result demonstrate competitive or even better visual quality and efficient run time in comparison with state of the art 
in this work we seek to move away from the traditional paradigm for d object recognition whereby object are identified in the image a d bounding box we focus instead on i detecting object ii identifying their d pose iii characterizing the geometrical and topological property of the object in term of their aspect configuration in d we call such characterization an object s aspect layout see fig we propose a new model for solving these problem in a joint fashion from a single image for object category our model is constructed upon a novel framework based on conditional random field with maximal margin parameter estimation extensive experiment are conducted to evaluate our model s performance in determining object pose and layout from image we achieve superior viewpoint accuracy result on three public datasets and show extensive quantitative analysis to demonstrate the ability of accurately recovering the aspect layout of object 
in spite of intensive endeavor over decade rigid and nonrigid factorization under metric constraint possibly in the presence of missing component remain to be very challenging in this work we try to break the hard nut by generalizing to these problem the wiberg algorithm one of the most successful solution for unconstrained bilinear factorization to properly handle missing component we advocate a bilinear factorization formulation with an extra mean vector in spirit of the wiberg algorithm we first propose an efficient and initialization insensitive algorithm for unconstrained factorization posterior correction of whose solution offer reasonable initialization for metric upgrade for factorization with metric constraint we reformulate it into an unconstrained problem through quaternion parametrization which merges elegantly into our unconstrained factorization algorithm extensive experiment result verify that our proposed method are fast accurate and robust to high percentage of missing component 
during recent year remarkable progress ha been made in visual saliency modeling our interest is in video saliency since video are fundamentally different from still image they are viewed differently by human observer for example the time each video frame is observed is a fraction of a second while a still image can be viewed leisurely therefore video saliency estimation method should differ substantially from image saliency method in this paper we propose a novel method for video saliency estimation which is inspired by the way people watch video we explicitly model the continuity of the video by predicting the saliency map of a given frame conditioned on the map from the previous frame furthermore accuracy and computation speed are improved by restricting the salient location to a carefully selected candidate set we validate our method using two gaze tracked video datasets and show we outperform the state of the art 
many problem in computer vision can be posed a recovering a low dimensional subspace from high dimensional visual data factorization approach to low rank subspace estimation minimize a loss function between the observed measurement matrix and a bilinear factorization most popular loss function include the l and l loss while l is optimal for laplacian distributed noise l is optimal for gaussian noise however real data is often corrupted by an unknown noise distribution which is unlikely to be purely gaussian or laplacian to address this problem this paper proposes a low rank matrix factorization problem with a mixture of gaussians mog noise the mog model is a universal approximator for any continuous distribution and hence is able to model a wider range of real noise distribution the parameter of the mog model can be estimated with a maximum likelihood method while the subspace is computed with standard approach we illustrate the benefit of our approach in extensive synthetic structure from motion face modeling and background subtraction experiment 
a key problem in visual tracking is to represent the appearance of an object in a way that is robust to visual change to attain this robustness increasingly complex model are used to capture appearance variation however such model can be difficult to maintain accurately and efficiently in this paper we propose a visual tracker in which object are represented by compact and discriminative binary code this representation can be processed very efficiently and is capable of effectively fusing information from multiple cue an incremental discriminative learner is then used to construct an appearance model that optimally separate the object from it surround furthermore we design a hyper graph propagation method to capture the contextual information on sample which further improves the tracking accuracy experimental result on challenging video demonstrate the effectiveness and robustness of the proposed tracker 
combining multiple observation view ha proven beneficial for tracking in this paper we cast tracking a a novel multi task multi view sparse learning problem and exploit the cue from multiple view including various type of visual feature such a intensity color and edge where each feature observation can be sparsely represented by a linear combination of atom from an adaptive feature dictionary the proposed method is integrated in a particle filter framework where every view in each particle is regarded a an individual task we jointly consider the underlying relationship between task across different view and different particle and tackle it in a unified robust multi task formulation in addition to capture the frequently emerging outlier task we decompose the representation matrix to two collaborative component which enable a more robust and accurate approximation we show that the proposed formulation can be efficiently solved using the accelerated proximal gradient method with a small number of closed form update the presented tracker is implemented using four type of feature and is tested on numerous benchmark video sequence both the qualitative and quantitative result demonstrate the superior performance of the proposed approach compared to several state of the art tracker 
since the seminal work of thrun the learning to learn paradigm ha been defined a the ability of an agent to improve it performance at each task with experience with the number of task within the object categorization domain the visual learning community ha actively declined this paradigm in the transfer learning setting almost all proposed method focus on category detection problem addressing how to learn a new target class from few sample by leveraging over the known source but if one think of learning over multiple task there is a need for multiclass transfer learning algorithm able to exploit previous source knowledge when learning a new class while at the same time optimizing their overall performance this is an open challenge for existing transfer learning algorithm the contribution of this paper is a discriminative method that address this issue based on a least square support vector machine formulation our approach is designed to balance between transferring to the new class and preserving what ha already been learned on the source model extensive experiment on subset of publicly available datasets prove the effectiveness of our approach 
a a special topic in computer vision fine grained visual categorization fgvc ha been attracting growing attention these year different with traditional image classification task in which object have large inter class variation the visual concept in the fine grained datasets such a hundred of bird specie often have very similar semantics due to the large inter class similarity it is very difficult to classify the object without locating really discriminative feature therefore it becomes more important for the algorithm to make full use of the part information in order to train a robust model in this paper we propose a powerful flowchart named hierarchical part matching hpm to cope with fine grained classification task we extend the bag of feature bof model by introducing several novel module to integrate into image representation including foreground inference and segmentation hierarchical structure learning hsl and geometric phrase pooling gpp we verify in experiment that our algorithm achieves the state of the art classification accuracy in the caltech ucsd bird dataset by making full use of the ground truth part annotation 
the solution for the top down segmentation of non rigid visual object using machine learning technique is generally regarded a too complex to be solved in it full generality given the large dimensionality of the search space of the explicit representation of the segmentation contour in order to reduce this complexity the problem is usually divided into two stage rigid detection and non rigid segmentation the rationale is based on the fact that the rigid detection can be run in a lower dimensionality space i e le complex and faster than the original contour space and it result is then used to constrain the non rigid segmentation in this paper we propose the use of sparse manifold to reduce the dimensionality of the rigid detection search space of current state of the art top down segmentation methodology the main goal targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detector these goal are attainable given that both the search and training complexity are function of the dimensionality of the rigid search space we test our approach in the segmentation of the left ventricle from ultrasound image and lip from frontal face image compared to the performance of state of the art non rigid segmentation system our experiment show that the use of sparse manifold for the rigid detection lead to the two goal mentioned above 
top down visual saliency facility object localization by providing a discriminative representation of target object and a probability map for reducing the search space in this paper we propose a novel top down saliency model that jointly learns a conditional random field crf and a discriminative dictionary the proposed model is formulated based on a crf with latent variable by using sparse code a latent variable we train the dictionary modulated by crf and meanwhile a crf with sparse coding we propose a max margin approach to train our model via fast inference algorithm we evaluate our model on the graz and pascal voc datasets experimental result show that our model performs favorably against the state of the art top down saliency method we also observe that the dictionary update significantly improves the model performance 
most nonrigid object exhibit temporal regularity in their deformation recently it wa proposed that these regularity can be parameterized by assuming that the nonrigid structure lie in a small dimensional trajectory space in this paper we propose a factorization approach for d reconstruction from multiple static camera under the compact trajectory subspace representation proposed factorization is analogous to rank factorization of rigid structure from motion problem in transformed space the benefit of our approach is that the d trajectory basis can be directly learned from the image observation this also allows u to impute missing observation and denoise tracking error without explicit estimation of the d structure in contrast to standard triangulation based method which require point to be visible in at least two camera our approach can reconstruct point which remain occluded even in all the camera for quite a long time this make our solution especially suitable for occlusion handling in motion capture system we demonstrate robustness of our method on challenging real and synthetic scenario 
motion segmentation based on point trajectory can integrate information of a whole video shot to detect and separate moving object commonly similarity are defined between pair of trajectory however pairwise similarity restrict the motion model to translation non translational motion such a rotation or scaling is penalized in such an approach we propose to define similarity on higher order tuples rather than pair which lead to hypergraphs to apply spectral clustering the hypergraph is transferred to an ordinary graph an operation that can be interpreted a a projection we propose a specific nonlinear projection via a regularized maximum operator and show that it yield significant improvement both compared to pairwise similarity and alternative hypergraph projection 
we propose a method to expand the visual coverage of training set that consist of a small number of labeled example using learned attribute our optimization formulation discovers category specific attribute a well a the image that have high confidence in term of the attribute in addition we propose a method to stably capture example specific attribute for a small sized training set our method add image to a category from a large unlabeled image pool and lead to significant improvement in category recognition accuracy evaluated on a large scale dataset image net 
integrating generative model and discriminative model in a hybrid scheme ha shown some success in recognition task in such scheme generative model are used to derive feature map for outputting a set of fixed length feature that are used by discriminative model to perform classification in this paper we present a method called posterior divergence to derive feature map from the log likelihood function implied in the incremental expectation maximization algorithm these feature map evaluate a sample in three complementary measure how much the sample affect the model how well the sample fit the model how uncertain the fit is we prove that the linear classification error rate using the output of the derived feature map is at least a low a that of plug in estimation we present efficient algorithm for computing these feature map for semi supervised learning and supervised learning we evaluate the proposed method on three typical application i e scene recognition face and non face classification and protein sequence analysis and demonstrate improvement over related method 
this paper address the problem of general purpose no reference image quality assessment nr iqa with the goal of developing a real time cross domain model that can predict the quality of distorted image without prior knowledge of non distorted reference image and type of distortion present in these image the contribution of our work are two fold first the proposed method is highly efficient nr iqa measure are often used in real time imaging or communication system therefore it is important to have a fast nr iqa algorithm that can be used in these real time application second the proposed method ha the potential to be used in multiple image domain previous work on nr iqa focus primarily on predicting quality of natural scene image with respect to human perception yet in other image domain the final receiver of a digital image may not be a human the proposed method consists of the following component a local feature extractor a global feature extractor and a regression model while previous approach usually treat local feature extraction and regression model training independently we propose a supervised method based on back projection which link the two step by learning a compact set of filter which can be applied to local image patch to obtain discriminative local feature using a small set of filter the proposed method is extremely fast we have tested this method on various natural scene and document image datasets and obtained state of the art result 
simultaneously segmenting and labeling image is a fundamental problem in computer vision in this paper we introduce a hierarchical crf model to deal with the problem of labeling image of street scene by several distinctive object class in addition to learning a crf model from all the labeled image we group image into cluster of similar image and learn a crf model from each cluster separately when labeling a new image we pick the closest cluster and use the associated crf model to label this image experimental result show that this hierarchical image labeling method is comparable to and in many case superior to previous method on benchmark data set in addition to segmentation and labeling result we also showed how to apply the image labeling result to rerank google similar image 
our goal is to segment a video sequence into moving object and the world scene in recent work spectral embedding of point trajectory based on d motion cue accumulated from their lifespan ha shown to outperform factorization and per frame segmentation method for video segmentation the scale and kinematic nature of the moving object and the background scene determine how close or far apart trajectory are placed in the spectral embedding such density variation may confuse clustering algorithm causing over fragmentation of object interior therefore instead of clustering in the spectral embedding we propose detecting discontinuity of embedding density between spatially neighboring trajectory detected discontinuity are strong indicator of object boundary and thus valuable for video segmentation we propose a novel embedding discretization process that recovers from over fragmentation by merging cluster according to discontinuity evidence along inter cluster boundary for segmenting articulated object we combine motion grouping cue with a center surround saliency operation resulting in context aware spatially coherent saliency map figure ground segmentation obtained from saliency thresholding provides object connectedness constraint that alter motion based trajectory affinity by keeping articulated part together and separating disconnected in time object finally we introduce gabriel graph a effective per frame superpixel map for converting trajectory clustering to dense image segmentation gabriel edge bridge large contour gap via geometric reasoning without over segmenting coherent image region we present experimental result of our method that outperform the state of the art in challenging motion segmentation datasets 
we propose a notion of double discrete wavelet transform ddwt that is designed to sparsify the blurred image and the blur kernel simultaneously ddwt greatly enhances our ability to analyze detect and process blur kernel and blurry image the proposed framework handle both global and spatially varying blur kernel seamlessly and unifies the treatment of blur caused by object motion optical defocus and camera shake to illustrate the potential of ddwt in computer vision and image processing we develop example application in blur kernel estimation deblurring and near blur invariant image feature extraction 
from a set of image in a particular domain labeled with part location and class we present a method to automatically learn a large and diverse set of highly discriminative intermediate feature that we call part based one v one feature poof each of these feature specializes in discrimination between two particular class based on the appearance at a particular part we demonstrate the particular usefulness of these feature for fine grained visual categorization with new state of the art result on bird specie identification using the caltech ucsd bird cub dataset and parity with the best existing result in face verification on the labeled face in the wild lfw dataset finally we demonstrate the particular advantage of poof when training data is scarce 
online learning ha shown to be successful in tracking of previously unknown object however most approach are limited to a bounding box representation with fixed aspect ratio thus they provide a le accurate foreground background separation and cannot handle highly non rigid and articulated object this in turn increase the amount of noise introduced during online self training 
detecting partially occluded pedestrian is challenging a common practice to maximize detection quality is to train a set of occlusion specific classifier each for a certain amount and type of occlusion since training classifier is expensive only a handful are typically trained we show that by using many occlusion specific classifier we outperform previous approach on three pedestrian datasets inria eth and caltech usa we present a new approach to train such classifier by reusing computation among different training stage occlusion specific classifier can be trained at only one tenth the cost of one full training we show that also test time cost grows sub linearly 
we describe a system that build quantitative structural description of spiral galaxy this enables translation of sky survey image into data needed to help address fundamental astrophysical question such a the origin of spiral structure a phenomenon that ha eluded full theoretical description despite year of study the difficulty of automated measurement is underscored by the fact that to date only manually guided effort such a the citizen science project galaxy zoo have been able to extract structural information about spiral galaxy an automated approach is needed to eliminate measurement subjectivity and handle the otherwise overwhelming image quantity up to billion of image from near future survey our approach automatically describes spiral galaxy structure a a set of arc fit to pixel cluster precisely characterizing spiral arm segment arrangement while retaining the flexibility needed to accommodate the observed wide variety of spiral galaxy structure the largest existing quantitative measurement were manually guided and encompassed fewer than galaxy while we have already applied our method to nearly galaxy our output is consistent with previous information both quantitatively over small existing sample and qualitatively with human classification 
we describe an imaging architecture for compressive video sensing termed programmable pixel compressive camera p c p c allows u to capture fast phenomenon at frame rate higher than the camera sensor in p c each pixel ha an independent shutter that is modulated at a rate higher than the camera frame rate the observed intensity at a pixel is an integration of the incoming light modulated by it specific shutter we propose a reconstruction algorithm that us the data from p c along with additional prior about video to perform temporal super resolution we model the spatial redundancy of video using sparse representation and the temporal redundancy using brightness constancy constraint inferred via optical flow we show that by modeling such spatio temporal redundancy in a video volume one can faithfully recover the underlying high speed video frame from the observed low speed coded video the imaging architecture and the reconstruction algorithm allows u to achieve temporal super resolution without loss in spatial resolution we implement a prototype of p c using an lcos modulator and recover several video at fps using a fps camera 
contextual information play an important role in solving vision problem such a image segmentation however extracting contextual information and using it in an effective way remains a difficult problem to address this challenge we propose a multi resolution contextual framework called cascaded hierarchical model chm which learns contextual information in a hierarchical framework for image segmentation at each level of the hierarchy a classifier is trained based on downsampled input image and output of previous level our model then incorporates the resulting multi resolution contextual information into a classifier to segment the input image at original resolution we repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy multiple classifier are learned in the chm therefore a fast and accurate classifier is required to make the training tractable the classifier also need to be robust against overfitting due to the large number of parameter learned during training we introduce a novel classification scheme called logistic disjunctive normal network ldnn which consists of one adaptive layer of feature detector implemented by logistic sigmoid function followed by two fixed layer of logical unit that compute conjunction and disjunction respectively we demonstrate that ldnn outperforms state of theart classifier and can be used in the chm to improve object segmentation performance 
we consider the problem of finding distinctive social interaction involving group of agent embedded in larger social gathering given a pre defined gallery of short exemplar interaction video and a long input video of a large gathering with approximately tracked agent we identify within the gathering small sub group of agent exhibiting social interaction that resemble those in the exemplar the participant of each detected group interaction are localized in space the extent of their interaction is localized in time and when the gallery of exemplar is annotated with group interaction category each detected interaction is classified into one of the pre defined category our approach represents group behavior by dichotomous collection of descriptor for a individual action and b pair wise interaction and it includes efficient algorithm for optimally distinguishing participant from by stander in every temporal unit and for temporally localizing the extent of the group interaction most importantly the method is generic and can be applied whenever numerous interacting agent can be approximately tracked over time we evaluate the approach using three different video collection two that involve human and one that involves mouse 
a novel method is proposed for matching articulated object in cluttered video the method need only a single exemplar image of the target object instead of using a small set of large part to represent an articulated object the proposed model us hundred of small unit to represent walk along path of pixel between key point on an articulated object matching directly on dense pixel is key to achieving reliable matching when motion blur occurs the proposed method fit the model to local image property conforms to structure constraint and remembers the step taken along a pixel path the model formulation handle variation in object scaling rotation and articulation recovery of the optimal pixel walk is posed a a special shortest path problem which can be solved efficiently via dynamic programming further speedup is achieved via factorization of the path cost an efficient method is proposed to find multiple walk and simultaneously match multiple key point experiment show that the proposed method is efficient and reliable and can be used to match articulated object in fast motion video with strong clutter and blurry imagery 
in this work we propose a system for automatic classification of drosophila embryo into developmental stage while the system is designed to solve an actual problem in biological research we believe that the principle underlying it is interesting not only for biologist but also for researcher in computer vision the main idea is to combine two orthogonal source of information one is a classifier trained on strongly invariant feature which make it applicable to image of very different condition but also lead to rather noisy prediction the other is a label propagation step based on a more powerful similarity measure that however is only consistent within specific subset of the data at a time in our biological setup the information source are the shape and the staining pattern of embryo image we show experimentally that while neither of the method can be used by itself to achieve satisfactory result their combination achieves prediction quality comparable to human performance 
updating a global d model with live rgb d measurement ha proven to be successful for d reconstruction of indoor scene recently a truncated signed distance function tsdf volumetric model and a fusion algorithm have been introduced kinectfusion showing significant advantage such a computational speed and accuracy of the reconstructed scene this algorithm however is expensive in memory when constructing and updating the global model a a consequence the method is not well scalable to large scene we propose a new flexible d scene representation using a set of plane that is cheap in memory use and nevertheless achieves accurate reconstruction of indoor scene from rgb d image sequence projecting the scene onto different plane reduces significantly the size of the scene representation and thus it allows u to generate a global textured d model with lower memory requirement while keeping accuracy and easiness to update with live rgb d measurement experimental result demonstrate that our proposed flexible d scene representation achieves accurate reconstruction while keeping the scalability for large indoor scene 
in this paper we propose a rank minimization method to fuse the predicted confidence score of multiple model each of which is obtained based on a certain kind of feature specifically we convert each confidence score vector obtained from one model into a pairwise relationship matrix in which each entry characterizes the comparative relationship of score of two test sample our hypothesis is that the relative score relation are consistent among component model up to certain sparse deviation despite the large variation that may exist in the absolute value of the raw score then we formulate the score fusion problem a seeking a shared rank pairwise relationship matrix based on which each original score matrix from individual model can be decomposed into the common rank matrix and sparse deviation error a robust score vector is then extracted to fit the recovered low rank score relation matrix we formulate the problem a a nuclear norm and norm optimization objective function and employ the augmented lagrange multiplier alm method for the optimization our method is isotonic i e scale invariant to the numeric scale of the score originated from different model we experimentally show that the proposed method achieves significant performance gain on various task including object categorization and video event detection 
in this work we propose a novel video representation for activity recognition that model video dynamic with attribute of activity a video sequence is decomposed into short term segment which are characterized by the dynamic of their attribute these segment are modeled by a dictionary of attribute dynamic template which are implemented by a recently introduced generative model the binary dynamic system bd we propose method for learning a dictionary of bd from a training corpus and for quantizing attribute sequence extracted from video into these bd code word this procedure produce a representation of the video a a histogram of bd code word which is denoted the bag of word for attribute dynamic bowad an extensive experimental evaluation reveals that this representation outperforms other state of the art approach in temporal structure modeling for complex activity recognition 
in this paper we present a new image matting algorithm that achieves state of the art performance on a benchmark dataset of image this is achieved by solving two major problem encountered by current sampling based algorithm the first is that the range in which the foreground and background are sampled is often limited to such an extent that the true foreground and background color are not present here we describe a method by which a more comprehensive and representative set of sample is collected so a not to miss out on the true sample this is accomplished by expanding the sampling range for pixel farther from the foreground or background boundary and ensuring that sample from each color distribution are included the second problem is the overlap in color distribution of foreground and background region this cause sampling based method to fail to pick the correct sample for foreground and background our design of an objective function force those foreground and background sample to be picked that are generated from well separated distribution comparison on the dataset at and evaluation by www alphamatting com show that the proposed method rank first in term of error measure used in the website 
covariance matrix provide compact informative feature descriptor for use in several computer vision application such a people appearance tracking diffusion tensor imaging activity recognition among others a key task in many of these application is to compare different covariance matrix using a dis similarity function a natural choice here is the riemannian metric corresponding to the manifold inhabited by covariance matrix but computation involving this metric are expensive especially for large matrix and even more so in gradient based algorithm to alleviate these difficulty we advocate a novel dissimilarity measure for covariance matrix the jensen bregman logdet divergence this divergence enjoys several useful theoretical property but it greatest benefit are i lower computational cost compared to standard approach and ii amenability for use in nearest neighbor retrieval we show numerous experiment to substantiate these claim 
we address the problem of d scene labeling in a structured learning framework unlike previous work which us structured support vector machine we employ the recently described decision tree field and regression tree field framework which learn the unary and binary term of a conditional random field from training data we show this ha significant advantage in term of inference speed while maintaining similar accuracy we also demonstrate empirically the importance for overall labeling accuracy of feature that make use of prior knowledge about the coarse scene layout such a the location of the ground plane we show how this coarse layout can be estimated by our framework automatically and that this information can be used to bootstrap improved accuracy in the detailed labeling 
propagating similarity information along the data manifold requires careful selection of local neighborhood selecting a good neighborhood in an unsupervised setting given an affinity graph ha been a difficult task the most common way to select a local neighborhood ha been to use the k nearest neighborhood k nn selection criterion however it ha the tendency to include noisy edge in this paper we propose a way to select a robust neighborhood using the consensus of multiple round of k nns we explain how using consensus information can give better control over neighborhood selection we also explain in detail the problem with another recently proposed neighborhood selection criterion i e dominant neighbor and show that our method is immune to those problem finally we show the result from experiment in which we compare our method to other neighborhood selection approach the result corroborate our claim that consensus of k nns doe indeed help in selecting more robust and stable locality 
we present a novel dataset and novel algorithm for the problem of detecting activity of daily living adl in firstperson camera view we have collected a dataset of million frame of dozen of people performing unscripted everyday activity the dataset is annotated with activity object track hand position and interaction event adls differ from typical action in that they can involve long scale temporal structure making tea can take a few minute and complex object interaction a fridge look different when it door is open we develop novel representation including temporal pyramid which generalize the well known spatial pyramid to approximate temporal correspondence when scoring a model and composite object model that exploit the fact that object look different when being interacted with we perform an extensive empirical evaluation and demonstrate that our novel representation produce a two fold improvement over traditional approach our analysis suggests that real world adl recognition is all about the object and in particular all about the object being interacted with 
clothing is one of the most informative cue of human appearance in this paper we propose a novel multi person clothing segmentation algorithm for highly occluded image the key idea is combining blocking model to address the person wise occlusion in contrary to the traditional layered model that try to solve the full layer ranking problem the proposed blocking model partition the problem into a series of pair wise one and then determines the local blocking relationship based on individual and contextual information thus it is capable of dealing with case with a large number of people additionally we propose a layout model formulated a markov network which incorporates the blocking relationship to pursue an approximately optimal clothing layout for group people experiment demonstrated on a group image dataset show the effectiveness of our algorithm 
we propose a fundamentally novel approach to real time visual odometry for a monocular camera it allows to benefit from the simplicity and accuracy of dense tracking which doe not depend on visual feature while running in real time on a cpu the key idea is to continuously estimate a semi dense inverse depth map for the current frame which in turn is used to track the motion of the camera using dense image alignment more specifically we estimate the depth of all pixel which have a non negligible image gradient each estimate is represented a a gaussian probability distribution over the inverse depth we propagate this information over time and update it with new measurement a new image arrive in term of tracking accuracy and computational speed the proposed method compare favorably to both state of the art dense and feature based visual odometry and slam algorithm a our method run in real time on a cpu it is of large practical value for robotics and augmented reality application 
human motion analysis in image and video is a central computer vision problem yet there are no study that reveal how human perceive other people in image and how accurate they are in this paper we aim to unveil some of the processing a well a the level of accuracy involved in the d perception of people from image by assessing the human performance our contribution are the construction of an experimental apparatus that relates perception and measurement in particular the visual and kinematic performance with respect to d ground truth when the human subject is presented an image of a person in a given pose the creation of a dataset containing image articulated d and d pose ground truth a well a synchronized eye movement recording of human subject shown a variety of human body configuration both easy and difficult a well a their re enacted d pose quantitative analysis revealing the human performance in d pose re enactment task the degree of stability in the visual fixation pattern of human subject and the way it correlate with different pose we also discus the implication of our finding for the construction of visual human sensing system 
given a set of plausible detection detected at each time instant independently we investigate how to associate them across time this is done by propagating label on a set of graph that capture how the spatio temporal and the appearance cue promote the assignment of identical or distinct label to a pair of node the graph construction is driven by the locally linear embedding lle of either the spatio temporal or the appearance feature associated to the detection interestingly the neighborhood of a node in each appearance graph is defined to include all node for which the appearance feature is available except the one that coexist at the same time this allows to connect the node that share the same appearance even if they are temporally distant which give our framework the uncommon ability to exploit the appearance feature that are available only sporadically along the sequence of detection once the graph have been defined the multi object tracking is formulated a the problem of finding a label assignment that is consistent with the constraint captured by each of the graph this result into a difference of convex program that can be efficiently solved experiment are performed on a basketball and several well known pedestrian datasets in order to validate the effectiveness of the proposed solution 
this paper study the problem of simultaneously aligning a batch of linearly correlated image despite gross corruption such a occlusion our method seek an optimal set of image domain transformation such that the matrix of transformed image can be decomposed a the sum of a sparse matrix of error and a low rank matrix of recovered aligned image we reduce this extremely challenging optimization problem to a sequence of convex program that minimize the sum of l norm and nuclear norm of the two component matrix which can be efficiently solved by scalable convex optimization technique we verify the efficacy of the proposed robust alignment algorithm with extensive experiment on both controlled and uncontrolled real data demonstrating higher accuracy and efficiency than existing method over a wide range of realistic misalignment and corruption 
we develop a bayesian modeling approach for tracking people in d from monocular video with unknown camera modeling in d provides natural explanation for occlusion and smoothness discontinuity that result from projection and allows prior on velocity and smoothness to be grounded in physical quantity meter and second v pixel and frame we pose the problem in the context of data association in which observation are assigned to track a correct application of bayesian inference to multi target tracking must address the fact that the model s dimension change a track are added or removed and thus posterior density of different hypothesis are not comparable we address this by marginalizing out the trajectory parameter so the resulting posterior over data association ha constant dimension this is made tractable by using a gaussian process prior for smooth trajectory and b approximately gaussian likelihood function our approach provides a principled method for incorporating multiple source of evidence we present result using both optical flow and object detector output result are comparable to recent work on d tracking and unlike others our method requires no pre calibrated camera 
action recognition ha often been posed a a classification problem which assumes that a video sequence only have one action class label and different action are independent however a single human body can perform multiple concurrent action at the same time and different action interact with each other this paper proposes a concurrent action detection model where the action detection is formulated a a structural prediction problem in this model an interval in a video sequence can be described by multiple action label an detected action interval is determined both by the unary local detector and the relation with other action we use a wavelet feature to represent the action sequence and design a composite temporal logic descriptor to describe the action relation the model parameter are trained by structural svm learning given a long video sequence a sequential decision window search algorithm is designed to detect the action experiment on our new collected concurrent action dataset demonstrate the strength of our method 
this paper describes an application framework to perform high quality upsampling on depth map captured from a low resolution and noisy d time of flight d tof camera that ha been coupled with a high resolution rgb camera our framework is inspired by recent work that us nonlocal mean filtering to regularize depth map in order to maintain fine detail and structure our framework extends this regularization with an additional edge weighting scheme based on several image feature based on the additional high resolution rgb input quantitative and qualitative result show that our method outperforms existing approach for d tof upsampling we describe the complete process for this system including device calibration scene warping for input alignment and even how the result can be further processed using simple user markup 
co segmentation refers to the problem of segmenting multiple image simultaneously by exploiting the similarity between the foreground and background region in these image the key issue in co segmentation is to align common object between these image to address this issue we propose an unsupervised learning framework for co segmentation by coupling co segmentation with what we call co sketch the goal of co sketch is to automatically discover a codebook of deformable shape template shared by the input image these shape template capture distinct image pattern and each template is matched to similar image patch in different image thus the co sketch of the image help to align foreground object thereby providing crucial information for co segmentation we present a statistical model whose energy function couple co sketch and co segmentation we then present an unsupervised learning algorithm that performs co sketch and co segmentation by energy minimization experiment show that our method outperforms state of the art method for co segmentation on the challenging msrc and iciest datasets we also illustrate our method on a new dataset called coseg rep where co segmentation can be performed within a single image with repetitive pattern 
we present a unified occlusion model for object instance detection under arbitrary viewpoint whereas previous approach primarily modeled local coherency of occlusion or attempted to learn the structure of occlusion from data we propose to explicitly model occlusion by reasoning about d interaction of object our approach accurately represents occlusion under arbitrary viewpoint without requiring additional training data which can often be difficult to obtain we validate our model by extending the state of the art line d method for object instance detection and demonstrate significant improvement in recognizing textureless object under severe occlusion 
the problem of estimating human gaze from eye appearance is regarded a mapping high dimensional feature to low dimensional target space conventional method require densely obtained training sample on the eye appearance manifold which result in a tedious calibration stage in this paper we introduce an adaptive linear regression alr method for accurate mapping via sparsely collected training sample the key idea is to adaptively find the subset of training sample where the test sample is most linearly representable we solve the problem via l optimization and thoroughly study the key issue to seek for the best solution for regression the proposed gaze estimation approach based on alr is naturally sparse and low dimensional giving the ability to infer human gaze from variant resolution eye image using much fewer training sample than existing method especially the optimization procedure in alr is extended to solve the subpixel alignment problem simultaneously for low resolution test eye image performance of the proposed method is evaluated by extensive experiment against various factor such a number of training sample feature dimensionality and eye image resolution to verify it effectiveness 
matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning task in recent year enhancing the robustness of matrix factorization method ha attracted much attention in the research community to benefit from the strength of full bayesian treatment over point estimation we propose here a full bayesian approach to robust matrix factorization for the generative process the model parameter have conjugate prior and the likelihood or noise model take the form of a laplace mixture for bayesian inference we devise an efficient sampling algorithm by exploiting a hierarchical view of the laplace distribution besides the basic model we also propose an extension which assumes that the outlier exhibit spatial or temporal proximity a encountered in many computer vision application the proposed method give competitive experimental result when compared with several state of the art method on some benchmark image and video processing task 
identifying the surface of three dimensional static object or of two dimensional object over time are key to a variety of application throughout computer vision active surface technique have been widely applied to such task such that a deformable spline surface evolves by the influence of internal and external typically opposing energy until the model converges to the desired surface present deformable model surface extraction technique are computationally expensive and are not able to reliably identify surface in the presence of noise high curvature or clutter this paper proposes a novel active surface technique decoupled active surface with the specific objective of robustness and computational efficiency motivated by recent result in two dimensional object segmentation the internal and external energy are treated separately which lead to much faster convergence a truncated maximum likelihood estimator is applied to generate a surface consistent with the measurement external energy and a bayesian linear least square estimator is asserted to enforce the prior internal energy to maintain tractability for typical three dimensional problem the density of vertex is dynamically resampled based on curvature a novel quasi random search is used a a substitute for the ml estimator and sparse conjugate gradient is used to execute the bayesian estimator the performance of the proposed method is presented using two natural and two synthetic image volume 
we present a very efficient highly accurate explicit shape regression approach for face alignment unlike previous regression based approach we directly learn a vectorial regression function to infer the whole facial shape a set of facial landmark from the image and explicitly minimize the alignment error over the training data the inherent shape constraint is naturally encoded into the regressor in a cascaded learning framework and applied from coarse to fine during the test without using a fixed parametric shape model a in most previous method to make the regression more effective and efficient we design a two level boosted regression shape indexed feature and a correlation based feature selection method this combination enables u to learn accurate model from large training data in a short time minute for training image and run regression extremely fast in test m for a landmark shape experiment on challenging data show that our approach significantly outperforms the state of the art in term of both accuracy and efficiency 
we show in this paper that the success of previous maximum a posterior map based blur removal method partly stem from their respective intermediate step which implicitly or explicitly create an unnatural representation containing salient image structure we propose a generalized and mathematically sound l sparse expression together with a new effective method for motion deblurring our system doe not require extra filtering during optimization and demonstrates fast energy decreasing making a small number of iteration enough for convergence it also provides a unified framework for both uniform and non uniform motion deblurring we extensively validate our method and show comparison with other approach with respect to convergence speed running time and result quality 
we address the problem of learning a joint model of actor and action in movie using weak supervision provided by script specifically we extract actor action pair from the script and use them a constraint in a discriminative clustering framework the corresponding optimization problem is formulated a a quadratic program under linear constraint people in video are represented by automatically extracted and tracked face together with corresponding motion feature first we apply the proposed framework to the task of learning name of character in the movie and demonstrate significant improvement over previous method used for this task second we explore the joint actor action constraint and show it advantage for weakly supervised action learning we validate our method in the challenging setting of localizing and recognizing character and their action in feature length movie casablanca and american beauty 
natural scene classification is a fundamental challenge in computer vision by far the majority of study have limited their scope to scene from single image still and thereby ignore potentially informative temporal cue the current paper is concerned with determining the degree of performance gain in considering short video for recognizing natural scene towards this end the impact of multiscale orientation measurement on scene classification is systematically investigated a related to i spatial appearance ii temporal dynamic and iii joint spatial appearance and dynamic these measurement in visual space x y and spacetime x y t are recovered by a bank of spatiotemporal oriented energy filter in addition a new data set is introduced that contains image sequence spanning fourteen scene category with temporal scene information due to object and surface decoupled from camera induced one this data set is used to evaluate classification performance of the various orientation related representation a well a state of the art alternative it is shown that a notable performance increase is realized by spatiotemporal approach in comparison to purely spatial or purely temporal method 
this paper proposes a conceptually simple but surprisingly powerful method which combine the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest neighbor approach the method is based on training a separate linear svm classifier for every exemplar in the training set each of these exemplar svms is thus defined by a single positive instance and million of negative while each detector is quite specific to it exemplar we empirically observe that an ensemble of such exemplar svms offer surprisingly good generalization our performance on the pascal voc detection task is on par with the much more complex latent part based model of felzenszwalb et al at only a modest computational cost increase but the central benefit of our approach is that it creates an explicit association between each detection and a single training exemplar because most detection show good alignment to their associated exemplar it is possible to transfer any available exemplar meta data segmentation geometric structure d model etc directly onto the detection which can then be used a part of overall scene understanding 
this paper present a novel approach for analyzing human action in non scripted unconstrained video setting based on volumetric x y t patch classifier termed actemes unlike previous action related work the discovery of patch classifier is posed a a strongly supervised process specifically key point label e g position across space time are used in a data driven training process to discover patch that are highly clustered in the space time key point configuration space to support this process a new human action dataset consisting of challenging consumer video is introduced where notably the action label the d position of a set of key point and their visibility are provided for each video frame on a novel input video each acteme is used in a sliding volume scheme to yield a set of sparse non overlapping detection these detection provide the intermediate substrate for segmenting out the action for action classification the proposed representation show significant improvement over state of the art low level feature while providing spatiotemporal localization a additional output which shed further light into detailed action understanding 
in this paper we present an efficient alternative to the traditional vocabulary based on bag of visual word bow used for visual classification task our representation is both conceptually and computationally superior to the bag of visual word we iteratively generate a maximum likelihood estimate of an image given a set of characteristic feature in contrast to the bow method where an image is represented a a histogram of visual word we randomly sample a set of characteristic feature instead of employing computation intensive clustering algorithm used during the vocabulary generation step of bow method our performance compare favorably to the state of the art on experiment over three challenging human action and a scene categorization dataset demonstrating the universal applicability of our method 
in this paper we propose an approach to jointly estimate the layout of room a well a the clutter present in the scene using rgb d data towards this goal we propose an effective model that is able to exploit both depth and appearance feature which are complementary furthermore our approach is efficient a we exploit the inherent decomposition of additive potential we demonstrate the effectiveness of our approach on the challenging nyu v dataset and show that employing depth reduces the layout error by and the clutter estimation by 
the deformable part based model dpm proposed by felzenszwalb et al ha demonstrated state of the art result in object localization the model offer a high degree of learnt invariance by utilizing viewpoint dependent mixture component and movable part in each mixture component one might hope to increase the accuracy of the dpm by increasing the number of mixture component and part to give a more faithful model but limited training data prevents this from being effective we propose an extension to the dpm which allows for sharing of object part model among multiple mixture component a well a object class this result in more compact model and allows training example to be shared by multiple component ameliorating the effect of a limited size training set we i reformulate the dpm to incorporate part sharing and ii propose a novel energy function allowing for coupled training of mixture component and object class we report state of the art result on the pascal voc dataset 
we present a new method to combine possibly inconsistent locally piecewise trained conditional model p ya xa into pseudo sample from a global model our method doe not require training of a crf but instead generates sample by iterating forward a weakly chaotic dynamical system the new method is illustrated on image segmentation task where classifier based on local appearance cue are combined with pairwise boundary cue 
this paper present a novel convexity measurement for d mesh the new convexity measure is calculated by minimizing the ratio of the summed area of valid region in a mesh s six view which are projected on face of the bounding box whose edge are parallel to the coordinate ax to the sum of three orthogonal projected area of the mesh the complete definition theoretical analysis and a computing algorithm of our convexity measure are explicitly described this paper also proposes a new d shape descriptor cd i e convexity distribution based on the distribution of above mentioned ratio which are computed by randomly rotating the mesh around it center to better describe the object s convexity related property compared to existing convexity measurement our experiment not only show that the proposed convexity measure corresponds well with human intuition but also demonstrate the effectiveness of the new convexity measure and the new shape descriptor by significantly improving the performance of other method in the application of d shape retrieval 
one fundamental assumption in object recognition a well a in other computer vision and pattern recognition problem is that the data generation process lie on a manifold and that it respect the intrinsic geometry of the manifold this assumption is held in several successful algorithm for diffusion and regularization in particular in graph laplacian based algorithm we claim that the performance of existing algorithm can be improved if we additionally account for how the manifold is embedded within the ambient space i e if we consider the extrinsic geometry of the manifold we present a procedure for characterizing the extrinsic a well a intrinsic curvature of a manifold m which is described by a sampled point cloud in a high dimensional euclidean space once estimated we use this characterization in general diffusion and regularization on m and form a new regularizer on a point cloud the resulting re weighted graph laplacian demonstrates superior performance over classical graph laplacian in semi supervised learning and spectral clustering 
visual speech recognition is a challenging problem due to confusion between visual speech feature the speaker identification problem is usually coupled with speech recognition moreover speaker identification is important to several application such a automatic access control biometrics authentication and personal privacy issue in this paper we propose a novel approach for lip reading and speaker identification we propose a new approach for manifold parameterization in a low dimensional latent space where each manifold is represented a a point in that space we initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation we then factorize the parameter space using kernel partial least square kpls to achieve a low dimension manifold latent space we use two way projection to achieve two manifold latent space one for the speech content and one for the speaker we apply our approach on two public database avletters and ouluvs we show the result for three different setting of lip reading speaker independent speaker dependent and speaker semi dependent our approach outperforms for the speaker semi dependent setting by at least of the baseline and competes in the other two setting 
sharing knowledge for multiple related machine learning task is an effective strategy to improve the generalization performance in this paper we investigate knowledge sharing across category for action recognition in video the motivation is that many action category are related where common motion pattern are shared among them e g diving and high jump share the jump motion we propose a new multi task learning method to learn latent task shared across category and reconstruct a classifier for each category from these latent task compared to previous method our approach ha two advantage the learned latent task correspond to basic motion pattern instead of full action thus enhancing discrimination power of the classifier category are selected to share information with a sparsity regularizer avoiding falsely forcing all category to share knowledge experimental result on multiple public data set show that the proposed approach can effectively transfer knowledge between different action category to improve the performance of conventional single task learning method 
we present a novel framework for tree structure embedded density estimation and it fast approximation for mode seeking the proposed method could find diverse application in computer vision and feature space analysis given any undirected connected and weighted graph the density function is defined a a joint representation of the feature space and the distance domain on the graph s spanning tree since the distance domain of a tree is a constrained one mode seeking can not be directly achieved by traditional mean shift in both domain we address this problem by introducing node shifting with force competition and it fast approximation our work is closely related to the previous literature of nonparametric method one shall see however that the new formulation of this problem can lead to many advantage and new characteristic in it application a will be illustrated later in this paper 
previously flobject analysis wa introduced a a method for using motion or stereo disparity information to train better model of static image during training but not during testing optic flow is used a a cue for factorizing appearance based image feature into those belonging to different flow defined object or flobjects here we describe how the image epitome can be extended to model flobjects and introduce a suitable learning algorithm using the citycars and city f edestrians datasets we study the task of object classification and localization our method performs significantly better than the original lda based flobject analysis technique sift based method with and without spatial pyramid matching and gist descriptor 
the automatic extraction of line network from image is a well known computer vision issue appearance and shape consideration have been deeply explored in the literature to improve accuracy in presence of occlusion shadow and a wide variety of irrelevant object however most existing work have ignored the structural aspect of the problem we present an original method which provides structurally coherent solution contrary to the pixel based and object based method our result is a graph in which each node represents either a connection or an ending in the line network based on stochastic geometry we develop a new family of point process consisting in sampling junction point in the input image by using a monte carlo mechanism the quality of a configuration is measured by a probability density which take into account both image consistency and shape prior our experiment on a variety of problem illustrate the potential of our approach in term of accuracy flexibility and efficiency 
sensing surface texture by touch is a valuable capability for robot until recently it wa difficult to build a compliant sensor with high sensitivity and high resolution the gelsight sensor is compliant and offer sensitivity and resolution exceeding that of the human fingertip this open the possibility of measuring and recognizing highly detailed surface texture the gelsight sensor when pressed against a surface delivers a height map this can be treated a an image and processed using the tool of visual texture analysis we have devised a simple yet effective texture recognition system based on local binary pattern and enhanced it by the use of a multi scale pyramid and a hellinger distance metric we built a database with class of tactile texture using material such a fabric wood and sandpaper our system can correctly categorize material from this database with high accuracy this suggests that the gelsight sensor can be useful for material recognition by robot 
we propose the first tractable convex formulation of the vectorial mumford shah functional which allows to compute high quality solution independent of the initialization to this end we generalize recently introduced convex formulation for scalar functionals to the vector valued scenario in such a way that discontinuity in the different color channel preferably coincide furthermore we propose an efficient solution which make the overall optimization problem a tractable a in the scalar valued case numerous experimental comparison with the naive channel wise approach with the well known ambrosio tortorelli approximation and with the classical total variation confirm the advantage of the proposed relaxation for contrastpreserving and edge enhancing regularization 
sparse representation based classification ha led to interesting image recognition result while the dictionary used for sparse coding play a key role in it this paper present a novel dictionary learning dl method to improve the pattern classification performance based on the fisher discrimination criterion a structured dictionary whose dictionary atom have correspondence to the class label is learned so that the reconstruction error after sparse coding can be used for pattern classification meanwhile the fisher discrimination criterion is imposed on the coding coefficient so that they have small within class scatter but big between class scatter a new classification scheme associated with the proposed fisher discrimination dl fddl method is then presented by using both the discriminative information in the reconstruction error and sparse coding coefficient the proposed fddl is extensively evaluated on benchmark image database in comparison with existing sparse representation and dl based classification method 
we generalize the network flow formulation for multiobject tracking to multi camera setup in the past reconstruction of multi camera data wa done a a separate extension in this work we present a combined maximum a posteriori map formulation which jointly model multicamera reconstruction a well a global temporal data association a flow graph is constructed which track object in d world space the multi camera reconstruction can be efficiently incorporated a additional constraint on the flow graph without making the graph unnecessarily large the final graph is efficiently solved using binary linear programming on the pet dataset we achieve result that significantly exceed the current state of the art 
d scanning of moving object ha many application for example marker le motion capture analysis on fluid dynamic object explosion and so on one of the approach to acquire accurate shape is a projector camera system especially the method that reconstructs a shape by using a single image with static pattern is suitable for capturing fast moving object in this paper we propose a method that us a grid pattern consisting of set of parallel line the pattern is spatially encoded by a periodic color pattern while information are sparse in the camera image the proposed method extract the dense pixel wise phase information from the sparse pattern a the result continuous region in the camera image can be extracted by analyzing the phase since there remain one dof for each region we propose the linear solution to eliminate the dof by using geometric information of the device i e epipolar constraint in addition solution space is finite because projected pattern consists of parallel line with same interval the linear equation can be efficiently solved by integer least square method in this paper the formulation for both single and multiple projector are presented we evaluated the accuracy of correspondence and showed the comparison with respect to the number of projector by simulation finally the dense d reconstruction of moving object are presented in the experiment 
we describe a scalable approach to d smooth object retrieval which search for and localizes all the occurrence of a user outlined object in a dataset of image in real time the approach is illustrated on sculpture 
this paper show that an image can be approximately reconstructed based on the output of a blackbox local description software such a those classically used for image indexing our approach consists first in using an off the shelf image database to find patch that are visually similar to each region of interest of the unknown input image according to associated local descriptor these patch are then warped into input image domain according to interest region geometry and seamlessly stitched together final completion of still missing texture free region is obtained by smooth interpolation a demonstrated in our experiment visually meaningful reconstruction are obtained just based on image local descriptor like sift provided the geometry of region of interest is known the reconstruction most often allows the clear interpretation of the semantic image content a a result this work raise critical issue of privacy and right when local descriptor of photo or video are given away for indexing and search purpose 
how many people should you ask if you are not sure about your way we provide an answer to this question for random forest classification the presented method is based on the statistical formulation of confidence interval and conjugate prior for binomial a well a multinomial distribution we derive appealing decision rule to speed up the classification process by leveraging the fact that many sample can be clearly mapped to class result on test data are provided and we highlight the applicability of our method to a wide range of problem the approach introduces only one non heuristic parameter that allows to trade off accuracy and speed without any re training of the classifier the proposed method automatically adapts to the difficulty of the test data and make classification significantly faster without deteriorating the accuracy 
when we look at an image some property or attribute of the image stand out more than others when describing an image people are likely to describe these dominant attribute first attribute dominance is a result of a complex interplay between the various property present or absent in the image which attribute in an image are more dominant than others reveals rich information about the content of the image in this paper we tap into this information by modeling attribute dominance we show that this help improve the performance of vision system on a variety of human centric application such a zero shot learning image search and generating textual description of image 
global illumination effect such a inter reflection and subsurface scattering result in systematic and often significant error in scene recovery using active illumination recently it wa shown that the direct and global component could be separated efficiently for a scene illuminated with a single light source in this paper we study the problem of direct global separation for multiple light source we derive a theoretical lower bound for the number of required image and propose a multiplexed illumination scheme which achieves this lower bound we analyze the signal to noise ratio snr characteristic of the proposed illumination multiplexing method in the context of direct global separation we apply our method to several scene recovery technique requiring multiple light source including shape from shading structured light d scanning photometric stereo and reflectance estimation both simulation and experimental result show that the proposed method can accurately recover scene information with fewer image compared to sequentially separating direct global component for each light source 
time of flight camera provide high frame rate depth measurement within a limited range of distance these reading can be extremely noisy and display unique error for instance where scene contain depth discontinuity or material with low infrared reflectivity previous work have treated the amplitude of each time of flight sample a a measure of confidence in this paper we demonstrate the shortcoming of this common lone heuristic and propose an improved per pixel confidence measure using a random forest regressor trained with real world data using an industrial laser scanner for ground truth acquisition we evaluate our technique on data from two different time of flight camera we argue that an improved confidence measure lead to superior reconstruction in subsequent step of traditional scan processing pipeline at the same time data with confidence reduces the need for point cloud smoothing and median filtering 
the mean field mf method are an energy optimization method for markov random field mrfs these method which have their root in solid state physic estimate the marginal density of each site of an mrf graph by iterative computation similarly to loopy belief propagation lbp it appears that being shadowed by lbp the mf method have not been seriously considered in the computer vision community this study investigates whether these method are useful for practical problem particularly mpm maximum posterior marginal inference in computer vision to be specific we apply the naive mf equation and the tap thouless anderson palmer equation to interactive segmentation and stereo matching in this paper firstly we show implementation of these method for computer vision problem next we discus advantage of the mf method to lbp finally we present experimental result that the mf method are well comparable to lbp in term of accuracy and global convergence furthermore the rd order tap equation often outperforms lbp in term of accuracy 
latent variable model provide valuable compact representation for learning and inference in many computer vision task however most existing model cannot directly encode prior knowledge about the specific problem at hand in this paper we introduce a constrained latent variable model whose generated output inherently account for such knowledge to this end we propose an approach that explicitly imposes equality and inequality constraint on the model s output during learning thus avoiding the computational burden of having to account for these constraint at inference our learning mechanism can exploit non linear kernel while only involving sequential closed form update of the model parameter we demonstrate the effectiveness of our constrained latent variable model on the problem of non rigid d reconstruction from monocular image and show that it yield qualitative and quantitative improvement over several baseline 
active contour are widely used in image segmentation to cope with missing or misleading feature in image researcher have introduced various way to model the prior of shape and use the prior to constrain active contour however the shape prior is usually learnt from a large set of annotated data which is not always accessible in practice moreover it is often doubted that the existing shape in the training set will be sufficient to model the new instance in the testing image in this paper we propose to use the group similarity of object shape in multiple image a a prior to aid segmentation which can be interpreted a an unsupervised approach of shape prior modeling we show that the rank of the matrix consisting of multiple shape is a good measure of the group similarity of the shape and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour model moreover we develop a fast algorithm to solve the proposed model by using the accelerated proximal method experiment using echocardiographic image sequence acquired from acute canine experiment demonstrate that the proposed method can consistently improve the performance of active contour model and increase the robustness against image defect such a missing boundary 
activity recognition in video is dominated by lowand mid level feature and while demonstrably capable by nature these feature carry little semantic meaning inspired by the recent object bank approach to image representation we present action bank a new high level representation of video action bank is comprised of many individual action detector sampled broadly in semantic space a well a viewpoint space our representation is constructed to be semantically rich and even when paired with simple linear svm classifier is capable of highly discriminative performance we have tested action bank on four major activity recognition benchmark in all case our performance is better than the state of the art namely on kth better by on ucf sport better by on ucf baseline is and on hmdb baseline is furthermore when we analyze the classifier we find strong transfer of semantics from the constituent action detector to the bank classifier 
spectral clustering make use of spectral graph structure of an affinity matrix to partition data into disjoint meaningful group because of it elegance efficiency and good performance spectral clustering ha become one of the most popular clustering method traditional spectral clustering assumes a single affinity matrix however in many application there could be multiple potentially useful feature and thereby multiple affinity matrix to apply spectral clustering for these case a possible way is to aggregate the affinity matrix into a single one unfortunately affinity measure constructed from different feature could have different characteristic careless aggregation might make even worse clustering performance this paper proposes an affinity aggregation spectral clustering aasc algorithm which extends spectral clustering to a setting with multiple affinity available aasc seek for an optimal combination of affinity matrix so that it is more immune to ineffective affinity and irrelevant feature this enables the construction of similarity or distance metric measure for clustering le crucial experiment show that aasc is effective in simultaneous clustering and feature fusion thus enhancing the performance of spectral clustering by employing multiple affinity 
in many classification task the use of expert labeled data for training is often prohibitively expensive the use of weakly labeled data is an attractive solution but raise the problem of label noise multiple instance learning whereby training sample are bagged instead of treated a singleton offer a possible approach to mitigating the effect of label noise in this paper we propose the use of milboost in a large scale video taxonomic classification system comprised of hundred of binary classifier to handle noisy training data we test on data with both artificial and real world noise and compare against the state of the art classifier based on adaboost we also explore the effect of different bag size on different level of noise on the final classifier performance experiment show that when training classifier with noisy data milboost provides an improvement in performance 
triangulation of a three dimensional point from n two dimensional image can be formulated a a quadratically constrained quadratic program we propose an algorithm to extract candidate solution to this problem from it semidefinite programming relaxation we then describe a sufficient condition and a polynomial time test for certifying when such a solution is optimal this test ha no false positive experiment indicate that false negative are rare and the algorithm ha excellent performance in practice we explain this phenomenon in term of the geometry of the triangulation problem 
this paper address the novel and challenging problem of aligning camera view that are unsynchronized by low and or variable frame rate using object trajectory unlike existing trajectory based alignment method our method doe not require frame to frame synchronization instead we propose using the intersection of corresponding object trajectory to match view to find these intersection we introduce a novel trajectory matching algorithm based on matching spatio temporal context graph stcgs these graph represent the distance between trajectory in time and space within a view and are matched to an stcg from another view to find the corresponding trajectory to the best of our knowledge this is one of the first attempt to align view that are unsynchronized with variable frame rate the result on simulated and real world datasets show trajectory intersection are a viable feature for camera alignment and that the trajectory matching method performs well in real world scenario 
an ideal approach to the problem of pose invariant face recognition would handle continuous pose variation would not be database specific and would achieve high accuracy without any manual intervention most of the existing approach fail to match one or more of these goal in this paper we present a fully automatic system for pose invariant face recognition that not only meet these requirement but also outperforms other comparable method we propose a d pose normalization method that is completely automatic and leverage the accurate d facial feature point found by the system the current system can handle d pose variation up to in yaw and in pitch angle recognition experiment were conducted on the usf d multi pie cmu pie feret and facepix database our system not only show excellent generalization by achieving high accuracy on all database but also outperforms other method convincingly 
k mean a simple and effective clustering algorithm is one of the most widely used algorithm in computer vision community traditional k mean is an iterative algorithm in each iteration new cluster center are computed and each data point is re assigned to it nearest center the cluster re assignment step becomes prohibitively expensive when the number of data point and cluster center are large in this paper we propose a novel approximate k mean algorithm to greatly reduce the computational complexity in the assignment step our approach is motivated by the observation that most active point changing their cluster assignment at each iteration are located on or near cluster boundary the idea is to efficiently identify those active point by pre assembling the data into group of neighboring point using multiple random spatial partition tree and to use the neighborhood information to construct a closure for each cluster in such a way only a small number of cluster candidate need to be considered when assigning a data point to it nearest cluster using complexity analysis real data clustering and application to image retrieval we show that our approach out performs state of the art approximate k mean algorithm in term of clustering quality and efficiency 
portable high quality sport camera e g head or helmet mounted built for recording dynamic first person video footage are becoming a common item among many sport enthusiast we address the novel task of discovering first person action category which we call ego action which can be useful for such task a video indexing and retrieval in order to learn ego action category we investigate the use of motion based histogram and unsupervised learning algorithm to quickly cluster video content our approach assumes a completely unsupervised scenario where labeled training video are not available video are not pre segmented and the number of ego action category are unknown in our proposed framework we show that a stacked dirichlet process mixture model can be used to automatically learn a motion histogram codebook and the set of ego action category we quantitatively evaluate our approach on both in house and public youtube video and demonstrate robust ego action categorization across several sport genre comparative analysis show that our approach outperforms other state of the art topic model with respect to both classification accuracy and computational speed preliminary result indicate that on average the categorical content of a minute video sequence can be indexed in under second 
we propose a visual recognition system that is designed for fine grained visual categorization the system is composed of a machine and a human user the user who is unable to carry out the recognition task by himself is interactively asked to provide two heterogeneous form of information clicking on object part and answering binary question the machine intelligently selects the most informative question to pose to the user in order to identify the object s class a quickly a possible by leveraging computer vision and analyzing the user response the overall amount of human effort required measured in second is minimized we demonstrate promising result on a challenging dataset of uncropped image achieving a significant average reduction in human effort over previous method 
in this paper we propose a novel framework for modeling image dependent contextual relationship using graph based context model this approach enables u to selectively utilize the contextual relationship suitable for an input query image we introduce a context link view of contextual knowledge where the relationship between a pair of annotated region is represented a a context link on a similarity graph of region link analysis technique are used to estimate the pairwise context score of all pair of unlabeled region in the input image our system integrates the learned context score into a markov random field mrf framework in the form of pairwise cost and infers the semantic segmentation result by mrf optimization experimental result on object class segmentation show that the proposed graph based context model outperforms the current state of the art method 
we study the uncalibrated isometric shape from template problem that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown our method is the first that combine the following feature solving for both the d deformation and the camera s focal length involving only local analytical solution there is no numerical optimization being robust to mismatch handling general surface and running extremely fast this wa achieved through two key step first an uncalibrated d deformation is computed thanks to a novel piecewise weak perspective projection model second the camera s focal length is estimated and enables upgrading the d deformation to metric we use a variational framework implemented using a smooth function basis and sampled local deformation model the only degeneracy which we easily detectfor focal length estimation is a flat and fronto parallel surface experimental result on simulated and real datasets show that our method achieves a d shape accuracy slightly below state of the art method using a precalibrated or the true focal length and a focal length accuracy slightly below static calibration method 
category level object recognition ha improved significantly in the last few year but machine performance remains unsatisfactory for most real world application we believe this gap may be bridged using additional depth information obtained from range imaging which wa recently used to overcome similar problem in body shape interpretation this paper present a system which successfully fuse visual and range imaging for object category classification we explore fusion at multiple level using depth a an attention mechanism high level fusion at the classifier level and low level fusion of local descriptor and show that each mechanism make a unique contribution to performance for low level fusion we present a new algorithm for training of local descriptor the generalized image feature transform gift which generalizes current representation such a sift and spatial pyramid and allows for the creation of new representation based on multiple channel of information we show that our system improves state of the art visual only and depth only method on a diverse dataset of every day object 
aligning image pair with significant appearance change is a long standing computer vision challenge much of this problem stem from the local patch descriptor instability to appearance variation in this paper we suggest this instability is due le to descriptor corruption and more the difficulty in utilizing local information to canoni cally define the orientation scale and rotation at which a patch s descriptor should be computed we address this issue by jointly estimating correspondence and relative patch orientation within a hierarchical algorithm that utilizes a smoothly varying parameterization of geometric transformation by collectively estimating the correspondence and orientation of all the feature we can align and orient feature that cannot be stably matched with only local information at the price of smoothing over motion discontinuity due to independent motion or parallax this approach can align image pair that display significant inter image appearance variation 
background subtraction is one of the key technique for automatic video analysis especially in the domain of video surveillance although it importance evaluation of recent background subtraction method with respect to the challenge of video surveillance suffer from various shortcoming to address this issue we first identify the main challenge of background subtraction in the field of video surveillance we then compare the performance of nine background subtraction method with post processing according to their ability to meet those challenge therefore we introduce a new evaluation data set with accurate ground truth annotation and shadow mask this enables u to provide precise in depth evaluation of the strength and drawback of background subtraction method 
although specular object have gained interest in recent year virtually no approach exist for marker le reconstruction of reflective scene in the wild in this work we present a practical approach to capturing normal map in real world scene using video only we focus on nearly planar surface such a window facade from glass or metal or frame screen and other indoor object and show how normal map of these can be obtained without the use of an artificial calibration object rather we track the reflection of real world straight line while moving with a hand held or vehicle mounted camera in front of the object in contrast to error prone local edge tracking we obtain the reflection by a robust global segmentation technique of an ortho rectified d video cube that also naturally allows efficient user interaction then at each point of the reflective surface the resulting d curve to d line correspondence provides a novel quadratic constraint on the local surface normal this allows to globally solve for the shape by integrability and smoothness constraint and easily support the usage of multiple line we demonstrate the technique on several object and facade 
man made structure often appear to be distorted in photo captured by casual photographer a the scene layout often conflict with how it is expected by human perception in this paper we propose an automatic approach for straightening up slanted man made structure in an input image to improve it perceptual quality we call this type of correction upright adjustment we propose a set of criterion for upright adjustment based on human perception study and develop an optimization framework which yield an optimal homography for adjustment we also develop a new optimization based camera calibration method that performs favorably to previous method and allows the proposed system to work reliably for a wide variety of image the effectiveness of our system is demonstrated by both quantitative comparison and qualitative user study 
although binary hash code based image indexing method have been recently developed for large scale application the problem of ranking such hash code ha been barely studied in this paper we propose a query sensitive ranking algorithm qsrank to rank pca based hash code for the neighbor search problem the qsrank algorithm take the target neighborhood radius and the raw feature of a given query a input and model the statistical property of the target neighbor in the space of hash code unlike the hamming distance the proposed algorithm doe not compress query point to hash code therefore it suffers le information loss and is more effective than hamming distance based approach based on the qsrank method we developed an efficient indexing structure and retrieval algorithm for large scale neighbor search evaluation on two datasets of million web image and million sift descriptor demonstrate that the proposed retrieval system achieves higher accuracy with le memory cost and faster speed 
recently dense trajectory were shown to be an efficient video representation for action recognition and achieved state of the art result on a variety of datasets this paper improves their performance by taking into account camera motion to correct them to estimate camera motion we match feature point between frame using surf descriptor and dense optical flow which are shown to be complementary these match are then used to robustly estimate a homography with ransac human motion is in general different from camera motion and generates inconsistent match to improve the estimation a human detector is employed to remove these match given the estimated camera motion we remove trajectory consistent with it we also use this estimation to cancel out camera motion from the optical flow this significantly improves motion based descriptor such a hof and mbh experimental result on four challenging action datasets i e hollywood hmdb olympic sport and ucf significantly outperform the current state of the art 
template based object detector such a the deformable part model of felzenszwalb et al achieve state of the art performance for a variety of object category but are still outperformed by simpler bag of word model for highly flexible object such a cat and dog in these case we propose to use the template based model to detect a distinctive part for the class followed by detecting the rest of the object via segmentation on image specific information learnt from that part this approach is motivated by two observation i many object class contain distinctive part that can be detected very reliably by template based detector whilst the entire object cannot ii many class e g animal have fairly homogeneous coloring and texture that can be used to segment the object once a sample is provided in an image we show quantitatively that our method substantially outperforms whole body template based detector for these highly deformable object category and indeed achieves accuracy comparable to the state of the art on the pascal voc competition which includes other model such a bag of word 
optimization using the l infty norm ha been becoming an effective way to solve parameter estimation problem in multiview geometry but the computational cost increase rapidly with the size of measurement data although some strategy have been presented to improve the efficiency of l infty optimization it is still an open issue in the paper we propose a novel approach under the framework of enhanced continuous tabu search ect for generic parameter estimation in multiview geometry ect is an optimization method in the domain of artificial intelligence which ha an interesting ability of covering a wide solution space by promoting the search far away from current solution and consecutively decreasing the possibility of trapping in the local minimum taking the triangulation a an example we propose the corresponding way in the key step of ect diversification and intensification we also present theoretical proof to guarantee the global convergence of search with probability one experimental result have validated that the ect based approach can obtain global optimum efficiently especially for large scale dimension of parameter potentially the novel ect based algorithm can be applied in many application of multiview geometry 
feature trajectory have shown to be efficient for representing video typically they are extracted using the klt tracker or matching sift descriptor between frame however the quality a well a quantity of these trajectory is often not sufficient inspired by the recent success of dense sampling in image classification we propose an approach to describe video by dense trajectory we sample dense point from each frame and track them based on displacement information from a dense optical flow field given a state of the art optical flow algorithm our trajectory are robust to fast irregular motion a well a shot boundary additionally dense trajectory cover the motion information in video well we also investigate how to design descriptor to encode the trajectory information we introduce a novel descriptor based on motion boundary histogram which is robust to camera motion this descriptor consistently outperforms other state of the art descriptor in particular in uncontrolled realistic video we evaluate our video description in the context of action classification with a bag of feature approach experimental result show a significant improvement over the state of the art on four datasets of varying difficulty i e kth youtube hollywood and ucf sport 
traditional supervised visual learning simply asks annotator what label an image should have we propose an approach for image classification problem requiring subjective judgment that also asks why and us that information to enrich the learned model we develop two form of visual annotator rationale in the first the annotator highlight the spatial region of interest he found most influential to the label selected and in the second he comment on the visual attribute that were most important for either case we show how to map the response to synthetic contrast example and then exploit an existing large margin learning technique to refine the decision boundary accordingly result on multiple scene categorization and human attractiveness task show the promise of our approach which can more accurately learn complex category with the explanation behind the label choice 
we propose a new learning method which exploit temporal consistency to successfully learn a complex appearance model from a sparsely labeled training video our approach consists in iteratively improving an appearance based model built with a boosting procedure and the reconstruction of trajectory corresponding to the motion of multiple target we demonstrate the efficiency of our procedure on pedestrian detection in video and cell detection in microscopy image sequence in both case our method is demonstrated to reduce the labeling requirement by one to two order of magnitude we show that in some instance our method trained with sparse label on a video sequence is able to outperform a standard learning procedure trained with the fully labeled sequence 
in cross view action recognition what you saw in one view is different from what you recognize in another view the data distribution even the feature space can change from one view to another due to the appearance and motion of action drastically vary across different view in this paper we address the problem of transferring action model learned in one view source view to another different view target view where action instance from these two view are represented by heterogeneous feature a novel learning method called heterogeneous transfer discriminantanalysis of canonical correlation htdcc is proposed to learn a discriminative common feature space for linking source and target view to transfer knowledge between them two projection matrix that respectively map data from source and target view into the common space are optimized via simultaneously minimizing the canonical correlation of inter class sample and maximizing the intraclass canonical correlation our model is neither restricted to corresponding action instance in the two view nor restricted to the same type of feature and can handle only a few or even no labeled sample available in the target view to reduce the data distribution mismatch between the source and target view in the common feature space a nonparametric criterion is included in the objective function we additionally propose a joint weight learning method to fuse multiple source view action classifier for recognition in the target view different combination weight are assigned to different source view with each weight presenting how contributive the corresponding source view is to the target view the proposed method is evaluated on the ixmas multi view dataset and achieves promising result 
in this paper we present a novel approach to recognizing human action from different view by view knowledge transfer an action is originally modelled a a bag of visual word bovw which is sensitive to view change we argue that a opposed to visual word there exist some higher level feature which can be shared across view and enable the connection of action model for different view to discover these feature we use a bipartite graph to model two view dependent vocabulary then apply bipartite graph partitioning to co cluster two vocabulary into visual word cluster called bilingual word i e high level feature which can bridge the semantic gap across view dependent vocabulary consequently we can transfer a bovw action model into a bag of bilingual word bobw model which is more discriminative in the presence of view change we tested our approach on the ixmas data set and obtained very promising result moreover to further fuse view knowledge from multiple view we apply a locally weighted ensemble scheme to dynamically weight transferred model based on the local distribution structure around each test example this process can further improve the average recognition rate by about 
it is necessary to utilize visual information to improve the efficiency of retrieval in image search engine that use textual information for indexing one popular approach ha been to learn visual consistency between image returned by these search engine most state of the art method of learning visual consistency usually learn one specific classifier for each query to re rank the returned image the main drawback with these query specific based method is that they require computational cost and processing time that are unsuitable for handling a large number of query another approach ha been to learn one generic classifier once and then use for all query pursuing the generic classifier based approach we study the problem of re ranking face returned by existing search engine to improve retrieval performance learning a generic classifier involves finding good query dependent feature representation and collecting sufficient large number of training sample existing work study query dependent feature for general object rather than face in addition training sample are usually collected manually the key contribution of this research is to introduce a query dependent feature for face and an unsupervised method of automatically collecting training sample to learn the generic classifier the experimental result demonstrated that the proposed method performed very well in various datasets 
we introduce a generative model for learning person and costume specific detector from labeled example we demonstrate the model on the task of localizing and naming actor in long video sequence more specifically the actor s head and shoulder are each represented a a constellation of optional color region detection can proceed despite change in view point and partial occlusion we explain how to learn the model from a small number of labeled key frame or video track and how to detect novel appearance of the actor in a maximum likelihood framework we present result on a challenging movie example with recall in actor detection coverage and precision in actor identification naming 
many significant historical corpus contain leaf that are mixed up and no longer bound in their original state a multi page document the reconstruction of old manuscript from a mix of disjoint leaf can therefore be of paramount importance to historian and literary scholar previously it wa shown that visual similarity provides meaningful pair wise similarity between handwritten leaf here we go a step further and suggest a semiautomatic clustering tool that help reconstruct the original document the proposed solution is based on a graphical model that make inference based on catalog information provided for each leaf a well a on the pairwise similarity of handwriting several novel active clustering technique are explored and the solution is applied to a significant part of the cairo genizah where the problem of joining leaf remains unsolved even after a century of extensive study by hundred of scholar 
in this paper we present a pose based approach for locating and recognizing human action in video in our method human pose are detected and represented based on deformable part model to our knowledge this is the first work on exploring the effectiveness of deformable part model in combining human detection and pose estimation into action recognition comparing with previous method ours have three main advantage first our method doe not rely on any assumption on video preprocessing quality such a satisfactory foreground segmentation or reliable tracking second we propose a novel compact representation for human pose which work together with human detection and can well represent the spatial and temporal structure inside an action third with human detection taken into consideration in our framework our method ha the ability to locate and recognize multiple action in the same scene experiment on benchmark datasets and recorded cluttered video verified the efficacy of our method 
the human vision tends to recognize more variant of a distinctive exemplar this observation suggests that discriminative power of training exemplar could be utilized for shaping a desirable global classifier that generalizes maximally from a few exemplar we propose to derive classification uncertainty for each exemplar using a local classification task to separate the exemplar from those in other category we then design a global classifier by incorporating these uncertainty into constraint on the classifier margin we show through the dual form that the classification criterion can be interpreted a finding closest point between convex hull in the feature space augmented by classification uncertainty we call this scheme power svm a in power diagram since each exemplar is no longer a singular point in the feature space but a super point with it own governing power in the classifier space we test power svm on digit recognition indoor outdoor categorization and large scale scene classification task it show consistent improvement over svm and uncertainty weighted svm especially when the number of training exemplar is small 
vision problem ranging from image clustering to motion segmentation to semi supervised learning can naturally be framed a subspace segmentation problem in which one aim to recover multiple low dimensional subspace from noisy and corrupted input data low rank representation lrr a convex formulation of the subspace segmentation problem is provably and empirically accurate on small problem but doe not scale to the massive size of modern vision datasets moreover past work aimed at scaling up low rank matrix factorization is not applicable to lrr given it non decomposable constraint in this work we propose a novel divide and conquer algorithm for large scale subspace segmentation that can cope with lrr s non decomposable constraint and maintains lrr s strong recovery guarantee this ha immediate implication for the scalability of subspace segmentation which we demonstrate on a benchmark face recognition dataset and in simulation we then introduce novel application of lrr based subspace segmentation to large scale semi supervised learning for multimedia event detection concept detection and image tagging in each case we obtain state of the art result and order of magnitude speed ups 
the objective of this work is to learn descriptor suitable for the sparse feature detector used in viewpoint invariant matching we make a number of novel contribution towards this goal first it is shown that learning the pooling region for the descriptor can be formulated a a convex optimisation problem selecting the region using sparsity second it is shown that dimensionality reduction can also be formulated a a convex optimisation problem using the nuclear norm to reduce dimensionality both of these problem use large margin discriminative learning method the third contribution is a new method of obtaining the positive and negative training data in a weakly supervised manner and finally we employ a state of the art stochastic optimizer that is efficient and well matched to the non smooth cost function proposed here it is demonstrated that the new learning method improve over the state of the art in descriptor learning for large scale matching brown et al and large scale object retrieval philbin et al 
automatic video segmentation and action recognition ha been a long standing problem in computer vision much work in the literature treat video segmentation and action recognition a two independent problem while segmentation is often done without a temporal model of the activity action recognition is usually performed on pre segmented clip in this paper we propose a novel method that avoids the limitation of the above approach by jointly performing video segmentation and action recognition unlike standard approach based on extension of dynamic bayesian network our method is based on a discriminative temporal extension of the spatial bag of word model that ha been very popular in object recognition the classification is performed robustly within a multi class svm framework whereas the inference over the segment is done efficiently with dynamic programming experimental result on honeybee weizmann and hollywood datasets illustrate the benefit of our approach compared to state of the art method 
covariance matrix of multivariate data capture feature correlation compactly and being very robust to noise they have been used extensively a feature descriptor in many area in computer vision like people appearance tracking dti imaging face recognition etc since these matrix do not adhere to the euclidean geometry clustering algorithm using the traditional distance measure cannot be directly extended to them prior work in this area ha been restricted to using k mean type clustering over the rieman nian space using the riemannian metric a the application scale it is not practical to assume the number of component in a clustering model failing any soft clustering algorithm in this paper a novel application of the dirich let process mixture model framework is proposed towards unsupervised clustering of symmetric positive definite matrix we approach the problem by extending the existing k mean type clustering algorithm based on the logdet divergence measure and derive the counterpart of it in a bayesian framework which lead to the wishart inverse wishart conjugate pair alternative possibility based on the matrix frobenius norm and log euclidean measure are also proposed the model are extensively compared using two real world datasets against the state of the art algorithm and demonstrate superior performance 
dtam is a system for real time camera tracking and reconstruction which relies not on feature extraction but dense every pixel method a a single hand held rgb camera fly over a static scene we estimate detailed textured depth map at selected keyframes to produce a surface patchwork with million of vertex we use the hundred of image available in a video stream to improve the quality of a simple photometric data term and minimise a global spatially regularised energy functional in a novel non convex optimisation framework interleaved we track the camera s dof motion precisely by frame rate whole image alignment against the entire dense model our algorithm are highly parallelisable throughout and dtam achieves real time performance using current commodity gpu hardware we demonstrate that a dense model permit superior tracking performance under rapid motion compared to a state of the art method using feature and also show the additional usefulness of the dense model for real time scene interaction in a physic enhanced augmented reality application 
sparse model have proven to be extremely successful in image processing and computer vision and most effort have been focused on sparse representation of vector the success of sparse modeling and the popularity of region covariance have inspired the development of sparse coding approach for positive definite matrix while in earlier work the dictionary wa pre determined it is clearly advantageous to learn a concise dictionary adaptively from the data at hand in this paper we propose a novel approach for dictionary learning over positive definite matrix the dictionary is learned by alternating minimization between the sparse coding and dictionary update stage and two different atom update method are described the online version of the dictionary update technique are also outlined experimental result demonstrate that the proposed learning method yield better dictionary for positive definite sparse coding the learned dictionary are applied to texture and face data leading to improved classification accuracy and strong detection performance respectively 
object detection ha seen huge progress in recent year much thanks to the heavily engineered histogram of oriented gradient hog feature can we go beyond gradient and do better than hog we provide an affirmative answer by proposing and investigating a sparse representation for object detection histogram of sparse code hsc we compute sparse code with dictionary learned from data using k svd and aggregate per pixel sparse code to form local histogram we intentionally keep true to the sliding window framework with mixture and part and only change the underlying feature to keep training and testing efficient we apply dimension reduction by computing svd on learned model and adopt supervised training where latent position of root and part are given externally e g from a hog based detector by learning and using local representation that are much more expressive than gradient we demonstrate large improvement over the state of the art on the pascal benchmark for both root only and part based model 
this paper considers the problem of detecting causal interaction in video clip specifically the goal is to detect whether the action of a given target can be explained in term of the past action of a collection of other agent we propose to solve this problem by recasting it into a directed graph topology identification where each node corresponds to the observed motion of a given target and each link indicates the presence of a causal correlation a shown in the paper this lead to a block sparsification problem that can be efficiently solved using a modified group lasso type approach capable of handling missing data and outlier due for instance to occlusion and mi identified correspondence moreover this approach also identifies time instant where the interaction between agent change thus providing event detection capability these result are illustrated with several example involving non trivial interaction amongst several human subject 
navier s equation modelling linear elastic solid deformation are embedded within an extended kalman filter ekf to compute a sequential bayesian estimate for the non rigid structure from motion problem the algorithm process every single frame of a sequence gathered with a full perspective camera no prior data association is assumed because match are computed within the ekf prediction match update cycle scene is coded a a finite element method fem elastic thin plate solid where the discretization node are the sparse set of scene point salient in the image it is assumed a set of gaussian force acting on solid node to cause scene deformation the ekf combine in a feedback loop an approximate fem model and the frame rate measurement from the camera resulting in an efficient method to embed navier s equation without resorting to expensive non linear fem model classical fem modelling ha implied an interactive identification of boundary point to constrain the scene rigid motion in this work this dissatisfying prior knowledge is no longer needed the scene and camer rigid motion are combined in a unique pose vector and the estimation is coded relative to the camera additionally the deforming effect of the gaussian force on the thin plate is computed by mean of the moore penrose pseudoinverse of the fem stiffness matrix the proposed algorithm is validated with three real sequence gathered with hand held camera observing isometric and non isometric deformation it is also shown the consistency of the ekf estimation with respect to ground truth computed from stereo 
in this paper we revisit diffusion process on affinity graph for capturing the intrinsic manifold structure defined by pair wise affinity matrix such diffusion process have already proved the ability to significantly improve subsequent application like retrieval we give a thorough overview of the state of the art in this field and discus obvious similarity and difference based on our observation we are then able to derive a generic framework for diffusion process in the scope of retrieval application where the related work represents specific instance of our generic formulation we evaluate our framework on several retrieval task and are able to derive algorithm that e g achieve a bull eye score on the popular mpeg shape retrieval data set 
we present a novel global stereo model that make use of constraint from point with known depth i e the ground control point gcps a referred to in stereo literature our formulation explicitly model the influence of gcps in a markov random field a novel gcps based regularization term is naturally integrated into our global optimization framework in a principled way using the bayes rule the optimal solution of the inference problem can be approximated via existing energy minimization technique such a graph cut used in this paper our generic probabilistic framework allows gcps to be obtained from various modality and provides a natural way to integrate the information from multiple sensor quantitative evaluation demonstrate the effectiveness of the proposed formulation for regularizing the ill posed stereo matching problem and improving reconstruction accuracy 
motion blur frequently occurs in dense d reconstruction using a single moving camera and it degrades the quality of the d reconstruction to handle motion blur caused by rapid camera shake we propose a blur aware depth reconstruction method which utilizes a pixel correspondence that is obtained by considering the effect of motion blur motion blur is dependent on d geometry thus parameter zing blurred appearance of image with scene depth given camera motion is possible and a depth map can be accurately estimated from the blur considered pixel correspondence the estimated depth is then converted into pixel wise blur kernel and non uniform motion blur is easily removed with low computational cost the obtained blur kernel is depth dependent thus it effectively address scene depth variation which is a challenging problem in conventional non uniform deblurring method 
we present a novel system that is capable of generating live dense volumetric reconstruction based on input from a micro aerial vehicle the distributed reconstruction pipeline is based on state of the art approach to visual slam and variational depth map fusion and is designed to exploit the individual capability of the system component result are visualized in real time on a tablet interface which give the user the opportunity to interact we demonstrate the performance of our approach by capturing several indoor and outdoor scene on the fly and by evaluating our result with respect to a ground truth model 
spatial relationship between local feature are thought to play a vital role in representing object category however learning a compact set of higher order spatial feature based on visual word e g doublet and triplet remains a challenging problem a possible combination of visual word grow exponentially while the local pairwise codebook achieves a compact codebook of pair of spatially close local feature without feature selection it formulation is not scale invariant and is only suitable for densely sampled local feature in contrast the proximity distribution kernel is a scale invariant and robust representation capturing rich spatial proximity information between local feature but it representation grows quadratically in the number of visual word inspired by the two abovementioned technique this paper present the compact correlation coding that combine the strength of the two our method achieves a compact representation that is scaleinvariant and robust against object deformation in addition we adopt sparse coding instead of k mean clustering during the codebook construction to increase the discriminative power of our method we systematically evaluate our method against both the local pairwise codebook and proximity distribution kernel on several challenging object categorization datasets to show performance improvement 
we address the problem of inferring the pose of an rgb d camera relative to a known d scene given only a single acquired image our approach employ a regression forest that is capable of inferring an estimate of each pixel s correspondence to d point in the scene s world coordinate frame the forest us only simple depth and rgb pixel comparison feature and doe not require the computation of feature descriptor the forest is trained to be capable of predicting correspondence at any pixel so no interest point detector are required the camera pose is inferred using a robust optimization scheme this start with an initial set of hypothesized camera pose constructed by applying the forest at a small fraction of image pixel preemptive ransac then iterates sampling more pixel at which to evaluate the forest counting inliers and refining the hypothesized pose we evaluate on several varied scene captured with an rgb d camera and observe that the proposed technique achieves highly accurate relocalization and substantially out performs two state of the art baseline 
modern visual classification model generally include a feature pooling step which aggregate local feature over the region of interest into a statistic through a certain spatial pooling operation two commonly used operation are the average and max poolings however recent theoretical analysis ha indicated that neither of these two pooling technique may be qualified to be optimal besides we further reveal in this work that more severe limitation of these two pooling method are from the unrecoverable loss of the spatial information during the statistical summarization and the underlying over simplified assumption about the feature distribution we aim to address these inherent issue in this work and generalize previous pooling method a follows we define a weighted p norm spatial pooling function tailored for the class specific feature spatial distribution moreover a sensible prior for the feature spatial correlation is incorporated optimizing such pooling function towards optimal class separability yield a so called geometric p norm pooling glp method the described glp method is capable of preserving the class specific spatial geometric information in the pooled feature and significantly boost the discriminating capability of the resultant feature for image classification comprehensive evaluation on several image benchmark demonstrate that the proposed glp method can boost the image classification performance with a single type of feature to outperform or be comparable with the state of the art 
in many sparse coding based image restoration and image classification problem using non convex ip norm minimization p can often obtain better result than the convex l norm minimization a number of algorithm e g iteratively reweighted least square irls iteratively thresholding method itm ip and look up table lut have been proposed for non convex ip norm sparse coding while some analytic solution have been suggested for some specific value of p in this paper by extending the popular soft thresholding operator we propose a generalized iterated shrinkage algorithm gisa for ip norm non convex sparse coding unlike the analytic solution the proposed gisa algorithm is easy to implement and can be adopted for solving non convex sparse coding problem with arbitrary p value compared with lut gisa is more general and doe not need to compute and store the look up table compared with irls and itm ip gisa is theoretically more solid and can achieve more accurate solution experiment on image restoration and sparse coding based face recognition are conducted to validate the performance of gisa 
we present an approach for dictionary learning of action attribute via information maximization we unify the class distribution and appearance information into an objective function for learning a sparse dictionary of action attribute the objective function maximizes the mutual information between what ha been learned and what remains to be learned in term of appearance information and class distribution for each dictionary item we propose a gaussian process gp model for sparse representation to optimize the dictionary objective function the sparse coding property allows a kernel with a compact support in gp to realize a very efficient dictionary learning process hence we can describe an action video by a set of compact and discriminative action attribute more importantly we can recognize modeled action category in a sparse feature space which can be generalized to unseen and unmodeled action category experimental result demonstrate the effectiveness of our approach in action recognition application 
we propose two solution for both nearest neighbor and range search problem for the nearest neighbor problem we propose a c approximate solution for the restricted version of the decision problem with bounded radius which is then reduced to the nearest neighbor by a known reduction for range searching we propose a scheme that learns the parameter in a learning stage adopting them to the case of a set of point with low intrinsic dimension that are embedded in high dimensional space common scenario for image point descriptor we compare our algorithm to the best known method for these problem i e lsh ann and flann we show analytically and experimentally that we can do better for moderate approximation factor our algorithm are trivial to parallelize in the experiment conducted running on couple of million image our algorithm show meaningful speed ups when compared with the above mentioned method 
recognition of human action in a video acquired by a moving camera typically requires standard preprocessing step such a motion compensation moving object detection and object tracking the error from the motion compensation step propagate to the object detection stage resulting in miss detection which further complicates the tracking stage resulting in cluttered and incorrect track therefore action recognition from a moving camera is considered very challenging in this paper we propose a novel approach which doe not follow the standard step and accordingly avoids the aforementioned difficulty our approach is based on lagrangian particle trajectory which are a set of dense trajectory obtained by advecting optical flow over time thus capturing the ensemble motion of a scene this is done in frame of unaligned video and no object detection is required in order to handle the moving camera we propose a novel approach based on low rank optimization where we decompose the trajectory into their camera induced and object induced component having obtained the relevant object motion trajectory we compute a compact set of chaotic invariant feature which capture the characteristic of the trajectory consequently a svm is employed to learn and recognize the human action using the computed motion feature we performed intensive experiment on multiple benchmark datasets and two new aerial datasets called arg and aphill and obtained promising result 
this paper present a novel formulation which derives in a smooth minimization problem to tackle the rigid registration between a given point set and a model set unlike most of the existing work which are based on minimizing a point wise correspondence term we propose to describe the model set by mean of an implicit representation it allows a new definition of the registration error which work beyond the point level representation moreover it could be used in a gradient based optimization framework the proposed approach consists of two stage firstly a novel formulation is proposed that relates the registration parameter with the distance between the model and data set secondly the registration parameter are obtained by mean of the levengberg marquardt algorithm experimental result and comparison with state of the art show the validity of the proposed framework 
modeling representation of image patch that are quasi invariant to spatial deformation is an important problem in computer vision in this paper we propose a novel concept the texture trace that allows sparse patch representation which are quasi invariant to smooth deformation and robust against occlusion we first propose a continuous domain model the profile trace which is a function only of the topological property of an image and is by construction invariant to any homeomorphic transformation of the domain we analyze it theoretical property and then derive a discrete domain approximation the discrete texture trace dtt dtts are designed to be computationally practical and shown by a set of controlled experiment to be quasi invariant to smooth spatial deformation a well a common image perturbation we then show how dtts can be naturally adapted to the incremental tracking problem yielding highly precise result on par with the state of the art on challenging real data without using heavy machine learning tool indeed we show that with even just using one image at the start of a sequence i e no incremental updating our method already outperforms four of six state of the art method of the recent literature on challenging sequence 
classifying raw unpainted material metal plastic ceramic fabric etc is an important yet challenging task for computer vision previous work measure subset of surface spectral reflectance a feature for classification however acquiring the full spectral reflectance is time consuming and error prone in this paper we propose to use coded illumination to directly measure discriminative feature for material classification optimal illumination pattern which we call discriminative illumination are learned from training sample after projecting to which the spectral reflectance of different material are maximally separated this projection is automatically realized by the integration of incident light for surface reflection while a single discriminative illumination is capable of linear two class classification we show that multiple discriminative illumination can be used for nonlinear and multi class classification we also show theoretically the proposed method ha higher signal to noise ratio than previous method due to light multiplexing finally we construct a led based multi spectral dome and use the discriminative illumination method for classifying a variety of raw material including metal aluminum alloy steel stainless steel brass and copper plastic ceramic fabric and wood experimental result demonstrate the effectiveness of the proposed method 
sparse representation technique for robust face recognition have been widely studied in the past several year recently face recognition with simultaneous misalignment occlusion and other variation ha achieved interesting result via robust alignment by sparse representation rasr in rasr the best alignment of a testing sample is sought subject by subject in the database however such an exhaustive search strategy can make the time complexity of rasr prohibitive in large scale face database in this paper we propose a novel scheme namely misalignment robust representation mrr by representing the misaligned testing sample in the transformed face space spanned by all subject the mrr seek the best alignment via a two step optimization with a coarse to fine search strategy which need only two deformation recovery operation extensive experiment on representative face database show that mrr ha almost the same accuracy a rasr in various face recognition and verification task but it run ten to hundred of time faster than rasr the running time of mrr is le than second in the large scale multi pie face database demonstrating it great potential for real time face recognition 
this paper introduces an effective decolorization algorithm that preserve the appearance of the original color image guided by the original saliency the method blend the luminance and the chrominance information in order to conserve the initial color disparity while enhancing the chromatic contrast a a result our straightforward fusing strategy generates a new spatial distribution that discriminates better the illuminated area and color feature since we do not employ quantization or a per pixel optimization computationally expensive the algorithm ha a linear runtime and depending on the image resolution it could be used in real time application extensive experiment and a comprehensive evaluation against existing state of the art method demonstrate the potential of our grayscale operator furthermore since the method accurately preserve the finest detail while enhancing the chromatic contrast the utility and versatility of our operator have been proved for several other challenging application such a video decolorization detail enhancement single image dehazing and segmentation under different illuminant 
widespread current camera are part of multisensory system with an integrated computer smartphones computer vision thus start evolving to cross modal sensing where vision and other sensor cooperate this exists in human and animal reflecting nature where visual event are often accompanied with sound can vision assist in denoising another modality a a case study we demonstrate this principle by using video to denoise audio unimodal audio only denoising is very difficult when the noise source is non stationary complex e g another speaker or music in the background strong and not individually accessible in any modality unseen cross modal association can help a clear video can direct the audio estimator we show this using an example based approach a training movie having clear audio provides cross modal example in testing cross modal input segment having noisy audio rely on the example for denoising the video channel drive the search for relevant training example we demonstrate this in speech and music experiment 
in this paper we address the problem of object class retrieval in large image data set given a small set of training example defining a visual category the objective is to efficiently retrieve image of the same class from a large database we propose two contrasting retrieval scheme achieving good accuracy and high efficiency the first exploit sparse classification model expressed a linear combination of a small number of feature these sparse model can be efficiently evaluated using inverted file indexing furthermore we introduce a novel ranking procedure that provides a significant speedup over inverted file indexing when the goal is restricted to finding the top k i e the k highest ranked image in the data set we contrast these sparse retrieval model with a second scheme based on approximate ranking using vector quantization experimental result show that our algorithm for object class retrieval can search a million database in just a couple of second and produce categorization accuracy comparable to the best known class recognition system 
there is an increased interest in the efficient creation of city model be it virtual or a built we present a method for synthesizing complex photo realistic facade image from a single example after parsing the example image into it semantic component a tiling for it is generated novel tiling can then be created yielding facade texture with different dimension or with occluded part in painted a genetic algorithm guide the novel facade a well a in painted part to be consistent with the example both in term of their overall structure and their detailed texture promising result for multiple standard datasets in particular for the different building style they contain demonstrate the potential of the method 
there ha been growing interest in mapping image data onto compact binary code for fast near neighbor search in vision application although binary code are motivated by their use a direct index address into a hash table code longer than bit are not being used in this way a it wa thought to be ineffective we introduce a rigorous way to build multiple hash table on binary code substring that enables exact k nearest neighbor search in hamming space the algorithm is straightforward to implement storage efficient and it ha sub linear run time behavior for uniformly distributed code empirical result show dramatic speed ups over a linear scan baseline and for datasets with up to one billion item or bit code and search radius up to bit 
object recoloring is one of the most popular photo editing task the problem of object recoloring is highly under constrained and existing recoloring method limit their application to object lit by a white illuminant application of these method to real world scene lit by colored illuminant multiple illuminant or interreflection result in unrealistic recoloring of object in this paper we focus on the recoloring of single colored object presegmented from their background the single color constraint allows u to fit a more comprehensive physical model to the object we demonstrate that this permit u to perform realistic recoloring of object lit by non white illuminant and multiple illuminant moreover the model allows for more realistic handling of illuminant alteration of the scene recoloring result captured by uncalibrated camera demonstrate that the proposed framework obtains realistic recoloring for complex natural image furthermore we use the model to transfer color between object and show that the result are more realistic than existing color transfer method 
conditional random field crfs are used for diverse task ranging from image denoising to object recognition for image they are commonly defined a a graph with node corresponding to individual pixel and pairwise link that connect node to their immediate neighbor recent work ha shown that fully connected crfs where each node is connected to every other node can be solved efficiently under the restriction that the pairwise term is a gaussian kernel over a euclidean feature space in this paper we generalize the pairwise term to a non linear dissimilarity measure that is not required to be a distance metric to this end we propose a density estimation technique to derive conditional pairwise potential in a non parametric manner we then use an efficient embedding technique to estimate an approximate euclidean feature space for these potential in which the pairwise term can still be expressed a a gaussian kernel we demonstrate that the use of non parametric model for the pairwise interaction conditioned on the input data greatly increase expressive power whilst maintaining efficient inference 
recent trend in semantic image segmentation have pushed for holistic scene understanding model that jointly reason about various task such a object detection scene recognition shape analysis contextual reasoning in this work we are interested in understanding the role of these different task in aiding semantic segmentation towards this goal we plug in human subject for each of the various component in a state of the art conditional random field model crf on the msrc dataset comparison among various hybrid human machine crfs give u indication of how much head room there is to improve segmentation by focusing research effort on each of the task one of the interesting finding from our slew of study wa that human classification of isolated super pixel while being worse than current machine classifier provides a significant boost in performance when plugged into the crf fascinated by this finding we conducted in depth analysis of the human generated potential this inspired a new machine potential which significantly improves state of the art performance on the mrsc dataset 
recently the counting grid cg model wa developed to represent each input image a a point in a large grid of feature count this latent point is a corner of a window of grid point which are all uniformly combined to match the normalized feature count in the image being a bag of word model with spatial layout in the latent space the cg model ha superior handling of field of view change in comparison to other bag of word model but with the price of being essentially a mixture mapping each scene to a single window in the grid in this paper we introduce a family of componential model dubbed the componential counting grid whose member represent each input image by multiple latent location rather than just one in this way we make a substantially more flexible admixture model which capture layer or part of image and map them to separate window in a counting grid we tested the model on scene and place classification where their componential nature helped to extract object to capture parallax effect thus better fitting the data and outperforming counting grid and latent dirichlet allocation especially on sequence taken with wearable camera 
even year ago szeliski et al published an influential study on energy minimization method for markov random field mrf this study provided valuable insight in choosing the best optimization technique for certain class of problem while these insight remain generally useful today the phenominal success of random field model mean that the kind of inference problem we solve have changed significantly specifically the model today often include higher order interaction flexible connectivity structure large label space of different cardinality or learned energy table to reflect these change we provide a modernized and enlarged study we present an empirical comparison of state of art technique on a corpus of energy minimization instance from diverse computer vision application to ensure reproducibility we evaluate all method in the opengm framework and report extensive result regarding runtime and solution quality key insight from our study agree with the result of szeliski et al for the type of model they studied however on new and challenging type of model our finding disagree and suggest that polyhedral method and integer programming solver are competitive in term of runtime and solution quality over a large range of model type 
transformation between different color space and gamut are ubiquitous operation performed on image often these transformation involve information loss for example when mapping from color to grayscale for printing from multispectral or multiprimary data to tristimulus space or from one color gamut to another in all these application there exists a straightforward natural mapping from the source space to the target space but the mapping is not bijective resulting in information loss due to metamerism and similar effect we propose a cluster based approach for optimizing the transformation for individual image in a way that preserve a much of the information a possible from the source space while staying a faithful a possible to the natural mapping our approach can be applied to a host of color transformation problem including color to gray gamut mapping conversion of multispectral and multiprimary data to tristimulus color and image optimization for color deficient viewer 
pedestrian detection from image is an important and yet challenging task the conventional method usually identify human figure using image feature inside the local region in this paper we present that besides the local feature context cue in the neighborhood provide important constraint that are not yet well utilized we propose a framework to incorporate the context constraint for detection first we combine the local window with neighborhood window to construct a multi scale image context descriptor designed to represent the contextual cue in spatial scaling and color space second we develop an iterative classification algorithm called contextual boost at each iteration the classifier response from the previous iteration across the neighborhood and multiple image scale called classification context are incorporated a additional feature to learn a new classifier the number of iteration is determined in the training process when the error rate converges since the classification context incorporates contextual cue from the neighborhood through iteration it implicitly propagates to greater area and thus provides more global constraint we evaluate our method on the caltech benchmark dataset the result confirm the advantage of the proposed framework compared with state of the art our method reduces the miss rate from by to at false positive per image fppi 
this paper present a cross based framework of performing local multipoint filtering efficiently we formulate the filtering process a a local multipoint regression problem consisting of two main step multipoint estimation calculating the estimate for a set of point within a shape adaptive local support and aggregation fusing a number of multipoint estimate available for each point compared with the guided filter that applies the linear regression to all pixel covered by a fixed sized square window non adaptively the proposed filtering framework is a more generalized form two specific filtering method are instantiated from this framework based on piecewise constant and piecewise linear modeling respectively leveraging a cross based local support representation and integration technique the proposed filtering method achieve theoretically strong result in an efficient manner with the two main step complexity independent of the filtering kernel size we demonstrate the strength of the proposed filter in various application including stereo matching depth map enhancement edge preserving smoothing color image denoising detail enhancement and flash no flash denoising 
automatically assessing photo quality from the perspective of visual aesthetic is of great interest in high level vision research and ha drawn much attention in recent year in this paper we propose content based photo quality assessment using regional and global feature under this framework subject area which draw the most attention of human eye are first extracted then regional feature extracted from subject area and the background region are combined with global feature to ass the photo quality since professional photographer may adopt different photographic technique and may have different aesthetic criterion in mind when taking different type of photo e g landscape versus portrait we propose to segment region and extract visual feature in different way according to the categorization of photo content therefore we divide the photo into seven category based on their content and develop a set of new subject area extraction method and new visual feature which are specially designed for different category this argument is supported by extensive experimental comparison of existing photo quality assessment approach a well a our new regional and global feature over different category of photo our new feature significantly outperform the state of the art method another contribution of this work is to construct a large and diversified benchmark database for the research of photo quality assessment it includes photo with manually labeled ground truth 
we propose an approach to multi view object class detection and approximate d pose estimation it relies on cad model a positive training example and discriminatively learns photometric object part such that an optimal coverage of intra class and viewpoint variation is guaranteed in contrast to previous work the approach show a significantly reduced training set dependency while avoiding any manual training supervision or annotation since it is capable of deriving all relevant information exclusively from the provided set of d cad model and an arbitrary set of d negative image in entirely circumventing semantic or view based representation part symmetry and co occurrence between viewpoint can be efficiently exploited this in turn lead to a significantly lower complexity while still achieving state of the art performance on two current benchmark data set for two different object class 
a large number of problem arising in computer vision can be reduced to the problem of minimizing the nuclear norm of a matrix subject to additional structural and sparsity constraint on it element example of relevant application include among others robust tracking in the presence of outlier manifold embedding event detection in painting and tracklet matching across occlusion in principle these problem can be reduced to a convex semi definite optimization form and solved using interior point method however the poor scaling property of these method limit the use of this approach to relatively small sized problem the main result of this paper show that structured nuclear norm minimization problem can be efficiently solved by using an iterative augmented lagrangian type alm method that only requires performing at each iteration a combination of matrix thresholding and matrix inversion step a we illustrate in the paper with several example the proposed algorithm result in a substantial reduction of computational time and memory requirement when compared against interior point method opening up the possibility of solving realistic large sized problem 
state of the art object detector typically use shape information a a low level feature representation to capture the local structure of an object this paper show that early fusion of shape and color a is popular in image classification lead to a significant drop in performance for object detection moreover such approach also yield suboptimal result for object category with varying importance of color and shape in this paper we propose the use of color attribute a an explicit color representation for object detection color attribute are compact computationally efficient and when combined with traditional shape feature provide state of the art result for object detection our method is tested on the pascal voc and datasets and result clearly show that our method improves over state of the art technique despite it simplicity we also introduce a new dataset consisting of cartoon character image in which color play a pivotal role on this dataset our approach yield a significant gain of in mean ap over conventional state of the art method 
alignment of d object from d image is one of the most important and well studied problem in computer vision a typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization error since error in landmark initialization from the appearance model propagate through the shape model it is critical to have a robust landmark appearance model while there ha been much progress in designing sophisticated and robust shape model there ha been relatively le progress in designing robust landmark detection model in this paper we present an efficient and robust landmark detection model which is designed specifically to minimize localization error thereby leading to state of the art object alignment performance we demonstrate the efficacy and speed of the proposed approach on the challenging task of multi view car alignment 
we introduce a new approach to structure and motion recovery directly from one or more large plane in the scene when such a plane exists we demonstrate how to automatically detect and track it robustly and consistently over a long video sequence and how to efficiently self calibrate the camera using the homographies induced by this plane we build a complete structure from motion system which doe not use any additional off the plane information about the scene and show it advantage over conventional system in handling two important issue which often occur in real world video namely the plane degeneracy and the dynamic foreground problem experimental result on a variety of real video sequence verify the effectiveness and efficiency of our system 
flat refractive geometry corresponds to a perspective camera looking through single multiple parallel flat refractive medium we show that the underlying geometry of ray corresponds to an axial camera this realization while missing from previous work lead u to develop a general theory of calibrating such system using d d correspondence the pose of d point is assumed to be unknown and is also recovered calibration can be done even using a single image of a plane we show that the unknown orientation of the refracting layer corresponds to the underlying axis and can be obtained independently of the number of layer their distance from the camera and their refractive index interestingly the axis estimation can be mapped to the classical essential matrix computation and point algorithm can be used after computing the axis the thickness of layer can be obtained linearly when refractive index are known and we derive analytical solution when they are unknown we also derive the analytical forward projection afp equation to compute the projection of a d point via multiple flat refraction which allows non linear refinement by minimizing the reprojection error for two refraction afp is either th or th degree equation depending on the refractive index we analyze ambiguity due to small field of view stability under noise and show how a two layer system can be well approximated a a single layer system real experiment using a water tank validate our theory 
it ha been shown repeatedly that iterative relevance feedback is a very efficient solution for content based image retrieval however no existing system scale gracefully to hundred of thousand or million of image 
the tomographic reconstruction of a planar object from it projection taken at random unknown view angle is a problem that occurs often in medical imaging therefore there is a need to robustly estimate the view angle given random observation of the projection the widely used locally linear embedding lle technique provides nonlinear embedding of point on a flat manifold in our case the projection belong to a sphere therefore we extend lle and develop a spherical locally linear embedding slle algorithm which is capable of embedding data point on a non flat spherically constrained manifold our algorithm slle transforms the problem of the angle estimation to a spherically constrained embedding problem it considers each projection a a high dimensional vector with dimensionality equal to the number of sampling point on the projection the projection are then embedded onto a sphere which parametrizes the projection with respect to view angle in a globally consistent manner the image is reconstructed from parametrized projection through the inverse radon transform a number of experiment demonstrate that slle is particularly effective for the tomography application we consider we evaluate it performance in term of the computational efficiency and noise tolerance and show that slle can be used to shed light on the other constrained application of lle 
a texture descriptor based on the shape index and the accompanying curvedness measure is proposed and it is evaluated for the automated analysis of astronomical image data a representative sample of image of low red shift galaxy from the sloan digital sky survey sd serf a a test bed the goal of applying texture descriptor to these data is to extract novel information about galaxy information which is often lost in more traditional analysis in this study we build a regression model for predicting a spectroscopic quantity the specific star formation rate ssfr a texture feature we consider multi scale gradient orientation histogram a well a multi scale shape index histogram which lead to a new descriptor our result show that we can successfully predict spectroscopic quantity from the texture in optical multi band image we successfully recover the observed bi modal distribution of galaxy into quiescent and star forming the state of the art for predicting the ssfr is a color based physical model we significantly improve it accuracy by augmenting the model with texture information this study is the first step towards enabling the quantification of physical galaxy property from imaging data alone 
in this paper we study the problem of robust feature extraction based on l regularized correntropy in both theoretical and algorithmic manner in theoretical part we point out that an l norm minimization can be justified from the viewpoint of half quadratic hq optimization which facilitates convergence study and algorithmic development in particular a general formulation is accordingly proposed to unify l norm and l norm minimization within a common framework in algorithmic part we propose an l regularized correntropy algorithm to extract informative feature meanwhile to remove outlier from training data a new alternate minimization algorithm is also developed to optimize the non convex correntropy objective in term of face recognition we apply the proposed method to obtain an appearance based model called sparse fisherfaces extensive experiment show that our method can select robust and sparse feature and outperforms several state of the art subspace method on large scale and open face recognition datasets 
in this paper we investigate how to iteratively and mutually boost object classification and detection by taking the output from one task a the context of the other one first instead of intuitive feature and context concatenation or postprocessing with context the so called contextualized support vector machine context svm is proposed where the context take the responsibility of dynamically adjusting the classification hyperplane and thus the context adaptive classifier is achieved then an iterative training procedure is presented in each step context svm associated with the output context from one task object classification or detection is instantiated to boost the performance for the other task whose augmented output are then further used to improve the former task by context svm the proposed solution is evaluated on the object classification and detection task of pascal visual object challenge voc and and achieves the state of the art performance 
the number of application in computer vision that model higher order interaction ha exploded over the last few year the standard technique for solving such problem is to reduce the higher order objective function to a quadratic pseudo boolean function and then use roof duality for obtaining a lower bound roof duality work by constructing the tightest possible lower bounding submodular function and instead of optimizing the original objective function the relaxation is minimized we generalize this idea to polynomial of higher degree where quadratic roof duality appears a a special case optimal relaxation are defined to be the one that give the maximum lower bound we demonstrate that important property such a persistency still hold and how the relaxation can be efficiently constructed for general cubic and quartic pseudo boolean function from a practical point of view we show that our relaxation perform better than state of the art for a wide range of problem both in term of lower bound and in the number of assigned variable 
in many real world face recognition scenario face image can hardly be aligned accurately due to complex appearance variation or low quality image to address this issue we propose a new approach to extract robust face region descriptor specifically we divide each image resp video into several spatial block resp spatial temporal volume and then represent each block resp volume by sum pooling the nonnegative sparse code of position free patch sampled within the block resp volume whitened principal component analysis wpca is further utilized to reduce the feature dimension which lead to our spatial face region descriptor sfrd resp spatial temporal face region descriptor stfrd for image resp video moreover we develop a new distance metric learning method for face verification called pairwise constrained multiple metric learning pmml to effectively integrate the face region descriptor of all block resp volume from an image resp a video our work achieves the state of the art performance on two real world datasets lfw and youtube face ytf according to the restricted protocol 
while most existing enhancement tool for photograph have universal auto enhancement functionality recent research show that user can have personalized preference in this paper we explore whether such personalized preference in image enhancement tend to cluster and whether user can be grouped according to such preference to this end we analyze a comprehensive data set of image enhancement collected from user via amazon mechanical turk we find that such cluster do exist and can be used to derive method to learn statistical preference model from a group of user we also present a probabilistic framework that exploit the idea behind collaborative filtering to automatically enhance novel image for new user experiment show that inferring cluster in image enhancement preference result in better prediction of image enhancement preference and outperforms generic auto correction tool 
recently learning based hashing method have become popular for indexing large scale medium data hashing method map high dimensional feature to compact binary code that are efficient to match and robust in preserving original similarity however most of the existing hashing method treat video a a simple aggregation of independent frame and index each video through combining the index of frame the structure information of video e g discriminative local visual commonality and temporal consistency is often neglected in the design of hash function in this paper we propose a supervised method that explores the structure learning technique to design efficient hash function the proposed video hashing method formulates a minimization problem over a structure regularized empirical loss in particular the structure regularization exploit the common local visual pattern occurring in video frame that are associated with the same semantic class and simultaneously preserve the temporal consistency over successive frame from the same video we show that the minimization objective can be efficiently solved by an accelerated proximal gradient apg method extensive experiment on two large video benchmark datasets up to around k video clip with over million frame show that the proposed method significantly outperforms the state of the art hashing method 
early work in computer vision considered a host of geometric cue for both shape reconstruction and recognition however since then the vision community ha focused heavily on shading cue for reconstruction and moved towards data driven approach for recognition in this paper we reconsider these perhaps overlooked boundary cue such a self occlusion and fold in a surface a well a many other established constraint for shape reconstruction in a variety of user study and quantitative task we evaluate how well these cue inform shape reconstruction relative to each other in term of both shape quality and shape recognition our finding suggest many new direction for future research in shape reconstruction such a automatic boundary cue detection and relaxing assumption in shape from shading e g orthographic projection lambertian surface 
in this paper we design a novel mrf framework which is called non local range markov random field nlr mrf the local spatial range of clique in traditional mrf is extended to the non local range which is defined over the local patch and also it similar patch in a non local window then the traditional local spatial filter is extended to the non local range filter that convolves an image over the non local range of pixel in this framework we propose a gradient based discriminative learning method to learn the potential function and non local range filter bank a the gradient of loss function with respect to model parameter are explicitly computed efficient gradient based optimization method are utilized to train the proposed model we implement this framework for image denoising and in painting the result show that the learned nlr mrf model significantly outperforms the traditional mrf model and produce state of the art result 
we present a multi layer group sparse coding framework for concurrent image classification and annotation by leveraging the dependency between image class label and tag we introduce a multi layer group sparse structure of the reconstruction coefficient such structure fully encodes the mutual dependency between the class label which describes the image content a a whole and tag which describe the component of the image content then we propose a multi layer group based tag propagation method which combine the class label and subgroup of instance with similar tag distribution to annotate test image moreover we extend our multi layer group sparse coding in the reproducing kernel hilbert space rkhs which capture the nonlinearity of feature and further improves performance of image classification and annotation experimental result on the labelme uiuc sport and nu wide object database show that our method outperforms the baseline method and achieves excellent performance in both image classification and annotation task 
is the real problem in finding the relative orientation of two viewpoint the correspondence problem we argue that this is only one difficulty even with known correspondence popular method like the eight point algorithm and minimal solver may break down due to planar scene or small relative motion in this paper we derive a simple brute force algorithm which is both robust to outlier and ha no such algorithmic degeneracy several cost function are explored including maximizing the consensus set and robust norm like truncated least square our method is based on parameter search in a four dimensional space using a new epipolar parametrization in principle we do an exhaustive search of parameter space but the computation are very simple and easily parallelizable resulting in an efficient method further speed ups can be obtained by restricting the domain of possible motion to for example planar motion or small rotation experimental result are given for a variety of scenario including scene with a large portion of outlier further we apply our algorithm to d motion segmentation where we outperform state of the art on the well known hopkins benchmark database 
accurate prostate segmentation in ct image is a significant yet challenging task for image guided radiotherapy in this paper a novel semi automated prostate segmentation method is presented specifically to segment the prostate in the current treatment image the physician first take a few second to manually specify the first and last slice of the prostate in the image space then the prostate is segmented automatically by the proposed two step i the first step of prostate likelihood estimation to predict the prostate likelihood for each voxel in the current treatment image aiming to generate the d prostate likelihood map by the proposed spatial constrained transductive lasso scoto ii the second step of multi atlas based label fusion to generate the final segmentation result by using the prostate shape information obtained from the planning and previous treatment image the experimental result show that the proposed method outperforms several state of the art method on prostate segmentation in a real prostate ct dataset consisting of patient with image moreover it is also clinically feasible since our method just requires the physician to spend a few second on manual specification of the first and last slice of the prostate 
this paper present a robust photometric stereo method that effectively compensates for various non lambertian corruption such a specularities shadow and image noise we construct a constrained sparse regression problem that enforces both lambertian rank structure and sparse additive corruption a solution method is derived using a hierarchical bayesian approximation to accurately estimate the surface normal while simultaneously separating the non lambertian corruption extensive evaluation are performed that show state of the art performance using both synthetic and real world image 
we describe a generative model of the relationship between two image the model is defined a a factored three way boltzmann machine in which hidden variable collaborate to define the joint correlation matrix for image pair modeling the joint distribution over pair make it possible to efficiently match image that are the same according to a learned measure of similarity we apply the model to several face matching task and show that it learns to represent the input image using task specific basis function matching performance is superior to previous similar generative model including recent conditional model of transformation we also show that the model can be used a a plug in matching score to perform invariant classification 
recovering d geometry from a single d line drawing is an important and challenging problem in computer vision it ha wide application in interactive d modeling from image computer aided design and d object retrieval previous method of d reconstruction from line drawing are mainly based on a set of heuristic rule they are not robust to sketch error and often fail for object that do not satisfy the rule in this paper we propose a novel approach called example based d object reconstruction from line drawing which is based on the observation that a natural or man made complex d object normally consists of a set of basic d object given a line drawing a graphical model is built where each node denotes a basic object whose candidate are from a d model example database the d reconstruction is solved using a maximum a posteriori map estimation such that the reconstructed result best fit the line drawing our experiment show that this approach achieves much better reconstruction accuracy and are more robust to imperfect line drawing than previous method 
there is mounting evidence about the benefit of tailoring a biometric authentication system to each user by postprocessing the system output at the score level also known a client specific score normalisation example of these procedure are z norm and f norm these procedure can calibrate the uneven hypothesis space such that the dispropotionate false acceptance and false rejection error are reduced after the calibration the interest in studying these scheme is that they are applicable to any biometric authentication system regardless of the underlying biometric modality and furthermore potentially be extended to object recognition framed a a verification problem we propose to further improve these procedure by adding additional client specific term that cannot be incorporated easily in their respective existing form experiment carried out on face and speech system show that both variant systematically outperform their respective score normalisation scheme z norm or f norm 
we introduce a new problem domain for activity recognition the analysis of child s social and communicative behavior based on video and audio data we specifically target interaction between child aged year and an adult such interaction arise naturally in the diagnosis and treatment of developmental disorder such a autism we introduce a new publicly available dataset containing over session of a minute child adult interaction in each session the adult examiner followed a semi structured play interaction protocol which wa designed to elicit a broad range of social behavior we identify the key technical challenge in analyzing these behavior and describe method for decoding the interaction we present experimental result that demonstrate the potential of the dataset to drive interesting research question and show preliminary result for multi modal activity recognition 
we consider the problem of fitting one or more subspace to a collection of data point drawn from the subspace and corrupted by noise outlier we pose this problem a a rank minimization problem where the goal is to decompose the corrupted data matrix a the sum of a clean self expressive low rank dictionary plus a matrix of noise outlier our key contribution is to show that for noisy data this non convex problem can be solved very efficiently and in closed form from the svd of the noisy data matrix remarkably this is true for both one or more subspace an important difference with respect to existing method is that our framework result in a polynomial thresholding of the singular value with minimal shrinkage indeed a particular case of our framework in the case of a single subspace lead to classical pca which requires no shrinkage in the case of multiple subspace our framework provides an affinity matrix that can be used to cluster the data according to the sub space in the case of data corrupted by outlier a closed form solution appears elusive we thus use an augmented lagrangian optimization framework which requires a combination of our proposed polynomial thresholding operator with the more traditional shrinkage thresholding operator 
active learning technique have gained popularity to reduce human effort in labeling data instance for inducing a classifier when faced with large amount of unlabeled data such algorithm automatically identify the exemplar and representative instance to be selected for manual annotation more recently there have been attempt towards a batch mode form of active learning where a batch of data point is simultaneously selected from an unlabeled set real world application require adaptive approach for batch selection in active learning however existing work in this field ha primarily been heuristic and static in this work we propose a novel optimization based framework for dynamic batch mode active learning where the batch size a well a the selection criterion are combined in a single formulation the solution procedure ha the same computational complexity a existing state of the art static batch mode active learning technique our result on four challenging biometric datasets portray the efficacy of the proposed framework and also certify the potential of this approach in being used for real world biometric recognition application 
we aim to decompose a global histogram representation of an image into histogram of it associated object and region this task is formulated a an optimization problem given a set of linear classifier which can effectively discriminate the object category present in the image our decomposition bypass harder problem associated with accurately localizing and segmenting object we evaluate our method on a wide variety of composite histogram and also compare it with mrf based solution in addition to merely measuring the accuracy of decomposition we also show the utility of the estimated object and background histogram for the task of image classification on the pascal voc dataset 
statistical shape model such a active shape model asms suffer from their inability to represent a large range of variation of a complex shape and to account for the large error in detection of model point we propose a novel method dubbed pdm enlor that overcomes these limitation by locating each shape model point individually using an ensemble of local regression model and appearance cue from selected model point our method first detects a set of reference point which were selected based on their saliency during training for each model point an ensemble of regressors is built from the location of the detected reference point each regressor infers a candidate location for that model point using local geometric constraint encoded by a point distribution model pdm the final location of that point is determined a a weighted linear combination whose coefficient are learnt from the training data of candidate proposed from it ensemble s component regressors we use different subset of reference point a explanatory variable for the component regressors to provide varying degree of locality for the model in each ensemble this help our ensemble model to capture a larger range of shape variation a compared to a single pdm we demonstrate the advantage of our method on the challenging problem of segmenting gene expression image of mouse brain 
in this paper a robust regression method is proposed for human age estimation in which outlier sample are corrected by their neighbor through asymptotically increasing the correlation coefficient between the desired distance and the distance of sample label a another extension we adopt a nonlinear distance function and approximate it by neural network for fair comparison we also experiment on the regression problem of age estimation from face image and the result are very competitive among the state of the art 
we present an approach for automatic d human pose reconstruction from monocular image based on a discriminative formulation with latent segmentation input we advanced the field of structured prediction and human pose reconstruction on several front first by working with a pool of figure ground segment hypothesis the prediction problem is formulated in term of combined learning and inference over segment hypothesis and d human articular configuration beside constructing tractable formulation for the combined segment selection and pose estimation problem we propose new augmented kernel that can better encode complex dependency between output variable furthermore we provide primal linear re formulation based on fourier kernel approximation in order to scale up the non linear latent structured prediction methodology the proposed model are shown to be competitive in the humaneva benchmark and are also illustrated in a clip collected from a hollywood movie where the model can infer human pose from monocular image captured in complex environment 
an end to end real time scene text localization and recognition method is presented the real time performance is achieved by posing the character detection problem a an efficient sequential selection from the set of extremal region er the er detector is robust to blur illumination color and texture variation and handle low contrast text in the first classification stage the probability of each er being a character is estimated using novel feature calculated with o complexity per region tested only er with locally maximal probability are selected for the second stage where the classification is improved using more computationally expensive feature a highly efficient exhaustive search with feedback loop is then applied to group er into word and to select the most probable character segmentation finally text is recognized in an ocr stage trained using synthetic font the method wa evaluated on two public datasets on the icdar dataset the method achieves state of the art text localization result amongst published method and it is the first one to report result for end to end text recognition on the more challenging street view text dataset the method achieves state of the art recall the robustness of the proposed method against noise and low contrast of character is demonstrated by false positive caused by detected watermark text in the dataset 
our goal is to detect human and estimate their d pose in single image in particular handling case of partial visibility where some limb may be occluded or one person is partially occluding another two standard but disparate approach have developed in the field the first is the part based approach for layout type problem involving optimising an articulated pictorial structure the second is the pixel based approach for image labelling involving optimising a random field graph defined on the image our novel contribution is a formulation for pose estimation which combine these two model in a principled way in one optimisation problem and thereby inherits the advantage of both of them inference on this joint model find the set of instance of person in an image the location of their joint and a pixel wise body part labelling we achieve near or state of the art result on standard human pose data set and demonstrate the correct estimation for case of self occlusion person overlap and image truncation 
the performance of an offline trained classifier can be improved on site by adapting the classifier towards newly acquired data however the adaptation rate is a tuning parameter affecting the performance gain substantially poor selection of the adaptation rate may worsen the performance of the original classifier to solve this problem we propose a conservative model adaptation method by considering the worst case during the adaptation process we first construct a random cover of the set of the adaptation data from it partition for each element in the cover i e a portion of the whole adaptation data set we define the cross entropy error function in the form of logistic regression the element in the cover with the maximum cross entropy error corresponds to the worst case in the adaptation therefore we can convert the conservative model adaptation into the classic min max optimization problem finding the adaptation parameter that minimize the maximum of the cross entropy error of the cover taking the object detection a a testbed we implement an adapted object detector based on binary classification under different adaptation scenario and different datasets including pascal imagenet inria and tud pedestrian the proposed adaption method achieves significant performance gain and is compared favorably with the state of the art adaptation method with the fine tuned adaptation rate without the need of tuning the adaptation rate the proposed conservative model adaptation method can be extended to other adaptive classification task 
traditional method of computer vision and machine learning cannot match human performance on task such a the recognition of handwritten digit or traffic sign our biologically plausible wide and deep artificial neural network architecture can small often minimal receptive field of convolutional winner take all neuron yield large network depth resulting in roughly a many sparsely connected neural layer a found in mammal between retina and visual cortex only winner neuron are trained several deep neural column become expert on input preprocessed in different way their prediction are averaged graphic card allow for fast training on the very competitive mnist handwriting benchmark our method is the first to achieve near human performance on a traffic sign recognition benchmark it outperforms human by a factor of two we also improve the state of the art on a plethora of common image classification benchmark 
we introduce in this paper a novel approach to multi label image classification which incorporates a new type of context label exclusive context with linear representation and classification given a set of exclusive label group that describe the negative relationship among class label our method namely lelr for label exclusive linear representation enforces repulsive assignment of the label from each group to a query image the problem can be formulated a an exclusive lasso elasso model with group overlap and affine transformation since existing elasso solver are not directly applicable to solving such an variant of elasso in our setting we propose a nesterov s smoothing approximation algorithm for efficient optimization extensive comparing experiment on the challenging real world visual classification benchmark demonstrate the effectiveness of incorporating label exclusive context into visual classification 
we describe a method for generating n best configuration from part based model ensuring that they do not overlap according to some user provided definition of overlap we extend previous n best algorithm from the speech community to incorporate non maximal suppression cue such that pixel shifted copy of a single configuration are not returned we use approximate algorithm that perform nearly identical to their exact counterpart but are order of magnitude faster our approach outperforms standard method for generating multiple object configuration in an image we use our method to generate multiple pose hypothesis for the problem of human pose estimation from video sequence we present quantitative result that demonstrate that our framework significantly improves the accuracy of a state of the art pose estimation algorithm 
we describe a system to learn an object template from a video stream and localize and track the corresponding object in live video the template is decomposed into a number of local descriptor thus enabling detection and tracking in spite of partial occlusion each local descriptor aggregate contrast invariant statistic normalized intensity and gradient orientation across scale in a way that enables matching under significant scale variation low level tracking during the training video sequence enables capturing object specific variability due to the shape of the object which is encapsulated in the descriptor salient location on both the template and the target image are used a hypothesis to expedite matching 
we develop a fast effective algorithm for minimizing a well known objective function for robust multi model estimation our work introduces a combinatorial step belonging to a family of powerful move making method like expansion and fusion we also show that our subproblem can be quickly transformed into a comparatively small instance of minimum weighted vertex cover in practice these vertex cover subproblems are almost always bipartite and can be solved exactly by specialized network flow algorithm experiment indicate that our approach achieves the robustness of method like affinity propagation whilst providing the speed of fast greedy heuristic 
recently there have been significant advance in image up scaling or image super resolution based on a dictionary of low and high resolution exemplar the running time of the method is often ignored despite the fact that it is a critical factor for real application this paper proposes fast super resolution method while making no compromise on quality first we support the use of sparse learned dictionary in combination with neighbor embedding method in this case the nearest neighbor are computed using the correlation with the dictionary atom rather than the euclidean distance moreover we show that most of the current approach reach top performance for the right parameter second we show that using global collaborative coding ha considerable speed advantage reducing the super resolution mapping to a precomputed projective matrix third we propose the anchored neighborhood regression that is to anchor the neighborhood embedding of a low resolution patch to the nearest atom in the dictionary and to precompute the corresponding embedding matrix these proposal are contrasted with current state of the art method on standard image we obtain similar or improved quality and one or two order of magnitude speed improvement 
this paper make two complementary contribution to event retrieval in large collection of video first we propose hyper pooling strategy that encode the frame descriptor into a representation of the video sequence in a stable manner our best choice compare favorably with regular pooling technique based on k mean quantization second we introduce a technique to improve the ranking it can be interpreted either a a query expansion method or a a similarity adaptation based on the local context of the query video descriptor experiment on public benchmark show that our method are complementary and improve event retrieval result without sacrificing efficiency 
image denoising is a classical yet fundamental problem in low level vision a well a an ideal test bed to evaluate various statistical image modeling method one of the most challenging problem in image denoising is how to preserve the fine scale texture structure while removing noise various natural image prior such a gradient based prior nonlocal self similarity prior and sparsity prior have been extensively exploited for noise removal the denoising algorithm based on these prior however tend to smooth the detailed image texture degrading the image visual quality to address this problem in this paper we propose a texture enhanced image denoising teid method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image a novel gradient histogram preservation ghp algorithm is developed to enhance the texture structure while removing noise our experimental result demonstrate that the proposed ghp based teid can well preserve the texture feature of the denoised image making them look more natural 
we describe novel but simple motion feature for the problem of detecting object in video sequence previous approach either compute optical flow or temporal difference on video frame pair with various assumption about stabilization we describe a combined approach that us coarse scale flow and fine scale temporal difference feature our approach performs weak motion stabilization by factoring out camera motion and coarse object motion while preserving nonrigid motion that serve a useful cue for recognition we show result for pedestrian detection and human pose estimation in video sequence achieving state of the art result in both in particular given a fixed detection rate our method achieves a five fold reduction in false positive over prior art on the caltech pedestrian benchmark finally we perform extensive diagnostic experiment to reveal what aspect of our system are crucial for good performance proper stabilization long time scale feature and proper normalization are all critical 
many successful model for predicting attention in a scene involve three main step convolution with a set of filter a center surround mechanism and spatial pooling to construct a saliency map however integrating spatial information and justifying the choice of various parameter value remain open problem in this paper we show that an efficient model of color appearance in human vision which contains a principled selection of parameter a well a an innate spatial pooling mechanism can be generalized to obtain a saliency model that outperforms state of the art model scale integration is achieved by an inverse wavelet transform over the set of scale weighted center surround response the scale weighting function termed ecsf ha been optimized to better replicate psychophysical data on color appearance and the appropriate size of the center surround inhibition window have been determined by training a gaussian mixture model on eye fixation data thus avoiding ad hoc parameter selection additionally we conclude that the extension of a color appearance model to saliency estimation add to the evidence for a common low level visual front end for different visual task 
color is known to be highly discriminative for many object recognition task but is difficult to infer from uncontrolled image in which the illuminant is not known traditional method for color constancy can improve surface reflectance estimate from such uncalibrated image but their output depends significantly on the background scene in many recognition and retrieval application we have access to image set that contain multiple view of the same object in different environment we show in this paper that correspondence between these image provide important constraint that can improve color constancy we introduce the multi view color constancy problem and present a method to recover estimate of underlying surface reflectance based on joint estimation of these surface property and the illuminant present in multiple image the method can exploit image correspondence obtained by various alignment technique and we show example based on matching local region feature our result show that multi view constraint can significantly improve estimate of both scene illuminant and object color surface reflectance when compared to a baseline single view method 
adapting the classifier trained on a source domain to recognize instance from a new target domain is an important problem that is receiving recent attention in this paper we present one of the first study on unsupervised domain adaptation in the context of object recognition where we have labeled data only from the source domain and therefore do not have correspondence between object category across domain motivated by incremental learning we create intermediate representation of data between the two domain by viewing the generative subspace of same dimension created from these domain a point on the grassmann manifold and sampling point along the geodesic between them to obtain subspace that provide a meaningful description of the underlying domain shift we then obtain the projection of labeled source domain data onto these subspace from which a discriminative classifier is learnt to classify projected data from the target domain we discus extension of our approach for semi supervised adaptation and for case with multiple source and target domain and report competitive result on standard datasets 
we present a photometric stereo technique that operates on time lapse sequence captured by static outdoor webcam over the course of several month outdoor webcam produce a large set of uncontrolled image subject to varying lighting and weather condition we first automatically select a suitable subset of the captured frame for further processing reducing the dataset size by several order of magnitude a camera calibration step is applied to recover the camera response function the absolute camera orientation and to compute the light direction for each image finally we describe a new photometric stereo technique for non lambertian scene and unknown light source intensity to recover normal map and spatially varying material of the scene 
in this work we present a novel and efficient detector adaptation method which improves the performance of an offline trained classifier baseline classifier by adapting it to new test datasets we address two critical aspect of adaptation method generalizability and computational efficiency we propose an adaptation method which can be applied to various baseline classifier and is computationally efficient also for a given test video we collect online sample in an unsupervised manner and train a random fern adaptive classifier the adaptive classifier improves precision of the baseline classifier by validating the obtained detection response from baseline classifier a correct detection or false alarm experiment demonstrate generalizability computational efficiency and effectiveness of our method a we compare our method with state of the art approach for the problem of human detection and show good performance with high computational efficiency on two different baseline classifier 
human action can be recognised from a single still image by modelling human object interaction hoi which infers the mutual spatial structure information between human and object a well a their appearance existing approach rely heavily on accurate detection of human and object and estimation of human pose they are thus sensitive to large variation of human pose occlusion and unsatisfactory detection of small size object to overcome this limitation a novel exemplar based approach is proposed in this work our approach learns a set of spatial pose object interaction exemplar which are density function describing how a person is interacting with a manipulated object for different activity spatially in a probabilistic way a representation based on our hoi exemplar thus ha great potential for being robust to the error in human object detection and pose estimation a new framework consists of a proposed exemplar based hoi descriptor and an activity specific matching model that learns the parameter is formulated for robust human activity recognition experiment on two benchmark activity datasets demonstrate that the proposed approach obtains state of the art performance 
the classic bag of feature bof model and it extensional work use a single value to represent a visual code this strategy ignores the relation of visual code in this paper we explore this relation and propose a new algorithm for image classification it consists of two main part construct the codebook graph wherein a visual code is linked with other code describe each local feature using a pair of related code corresponding to an edge of the graph our approach contains richer information than previous bof model moreover we demonstrate that these model are special case of ours various coding and pooling algorithm can be embedded into our framework to obtain better performance experiment on different kind of image classification database demonstrate that our approach can stably achieve excellent performance compared with various bof model 
constructing a good graph to represent data structure is critical for many important machine learning task such a clustering and classification this paper proposes a novel non negative low rank and sparse nnlrs graph for semi supervised learning the weight of edge in the graph are obtained by seeking a nonnegative low rank and sparse matrix that represents each data sample a a linear combination of others the so obtained nnlrs graph can capture both the global mixture of subspace structure by the low rankness and the locally linear structure by the sparseness of the data hence is both generative and discriminative we demonstrate the effectiveness of nnlrs graph in semi supervised classification and discriminative analysis extensive experiment testify to the significant advantage of nnlrs graph over graph obtained through conventional mean 
we introduce a novel d extension to the hierarchical visual cortex model used for prior work in d object recognition prior work on the use of the visual cortex standard model for the explicit task of object class recognition ha solely concentrated on d imagery in this paper we discus the explicit d extension of each layer in this visual cortex model hierarchy for use in object recognition in d volumetric imagery we apply this extended methodology to the automatic detection of a class of threat item in computed tomography ct security baggage imagery the ct imagery suffers from poor resolution and a large number of artefact generated through the presence of metallic object in our examination of recognition performance we make a comparison to a codebook approach derived from a d sift descriptor and demonstrate that the visual cortex method out performs in this imagery recognition rate in excess of with minimal false positive rate are demonstrated in the detection of a range of threat item 
although fast and reliable real time template tracking using linear predictor requires a long training time the lack of the ability to learn new template online prevents their use in application that require fast learning this especially hold for application where the scene is not known a priori and multiple template have to be added online so far linear predictor had to be either learned offline or in an iterative manner by starting with a small sized template and growing it over time in this paper we propose a fast and simple reformulation of the learning procedure that allows learning new linear predictor online 
the inverse document frequency idf is prevalently utilized in the bag of word based image search the basic idea is to assign le weight to term with high frequency and vice versa however the estimation of visual word frequency is coarse and heuristic therefore the effectiveness of the conventional idf routine is marginal and far from optimal to tackle this problem this paper introduces a novel idf expression by the use of lp norm pooling technique carefully designed the proposed idf take into account the term frequency document frequency the complexity of image a well a the codebook information optimizing the idf function towards optimal balancing between tf and pidf weight yield the so called lp norm idf pidf we show that the conventional idf is a special case of our generalized version and two novel idf i e the average idf and the max idf can also be derived from our formula further by counting for the term frequency in each image the proposed lp norm idf help to alleviate the visual word burstiness phenomenon our method is evaluated through extensive experiment on three benchmark datasets oxford k paris k and flickr m we report a performance improvement of a large a over the baseline approach moreover since the lp norm idf is computed offline no extra computation or memory cost is introduced to the system at all 
we develop a comprehensive bayesian generative model for understanding indoor scene while it is common in this domain to approximate object with d bounding box we propose using strong representation with finer granularity for example we model a chair a a set of four leg a seat and a backrest we find that modeling detailed geometry improves recognition and reconstruction and enables more refined use of appearance for scene understanding we demonstrate this with a new likelihood function that reward d object hypothesis whose d projection is more uniform in color distribution such a measure would be confused by background pixel if we used a bounding box to represent a concave object like a chair complex object are modeled using a set or re usable d part and we show that this representation capture much of the variation among object instance with relatively few parameter we also designed specific data driven inference mechanism for each part that are shared by all object containing that part which help make inference transparent to the modeler further we show how to exploit contextual relationship to detect more object by for example proposing chair around and underneath table we present result showing the benefit of each of these innovation the performance of our approach often exceeds that of state of the art method on the two task of room layout estimation and object recognition a evaluated on two bench mark data set used in this domain 
it is often desirable to evaluate an image based on it quality for many computer vision application a perceptually meaningful measure is the most relevant for evaluation however most commonly used measure do not map well to human judgement of image quality a further complication of many existing image measure is that they require a reference image which is often not available in practice in this paper we present a blind image quality measure where potentially neither the groundtruth image nor the degradation process are known our method us a set of novel low level image feature in a machine learning framework to learn a mapping from these feature to subjective image quality score the image quality feature stem from natural image measure and texture statistic experiment on a standard image quality benchmark dataset show that our method outperforms the current state of art 
proxemics is the study of how people interact we present a computational formulation of visual proxemics by attempting to label each pair of people in an image with a subset of physically based touch code a baseline approach would be to first perform pose estimation and then detect the touch code based on the estimated joint location we found that this sequential approach doe not perform well because pose estimation step is too unreliable for image of interacting people due to difficulty with occlusion and limb ambiguity instead we propose a direct approach where we build an articulated model tuned for each touch code each such model contains two people connected in an appropriate manner for the touch code in question we fit this model to the image and then base classification on the fitting error experiment show that this approach significantly outperforms the sequential baseline a well a other related approches 
we propose a novel technique called bispectral photometric stereo that make effective use of fluorescence for shape reconstruction fluorescence is a common phenomenon occurring in many object from natural gem and coral to fluorescent dye used in clothing one of the important characteristic of fluorescence is it wavelength shifting behavior fluorescent material absorb light at a certain wavelength and then reemit it at longer wavelength due to the complexity of it emission process fluorescence tends to be excluded from most algorithm in computer vision and image processing in this paper we show that there is a strong similarity between fluorescence and ideal diffuse reflection and that fluorescence can provide distinct clue on how to estimate an object s shape moreover fluorescence s wavelength shifting property enables u to estimate the shape of an object by applying photometric stereo to emission only image without suffering from specular reflection this is the significant advantage of the fluorescence based method over previous method based on reflection 
human action recognition based on the depth information provided by commodity depth sensor is an important yet challenging task the noisy depth map different length of action sequence and free style in performing action may cause large intra class variation in this paper a new framework based on sparse coding and temporal pyramid matching tpm is proposed for depth based human action recognition especially a discriminative class specific dictionary learning algorithm is proposed for sparse coding by adding the group sparsity and geometry constraint feature can be well reconstructed by the sub dictionary belonging to the same class and the geometry relationship among feature are also kept in the calculated coefficient the proposed approach is evaluated on two benchmark datasets captured by depth camera experimental result show that the proposed algorithm repeatedly achieves superior performance to the state of the art algorithm moreover the proposed dictionary learning method also outperforms classic dictionary learning approach 
recently non negative matrix factorization nmf ha become increasingly popular for feature extraction in computer vision and pattern recognition nmf seek for two non negative matrix whose product can best approximate the original matrix the non negativity constraint lead to sparse part based representation which can be more robust than non sparse global feature to obtain more accurate control over the sparseness in this paper we propose a novel method called non negative local coordinate factorization nlcf for feature extraction nlcf add a local coordinate constraint into the standard nmf objective function specifically we require that the learned basis vector be a close to the original data point a possible in this way each data point can be represented by a linear combination of only few nearby basis vector which naturally lead to sparse representation extensive experimental result suggest that the proposed approach provides a better representation and achieves higher accuracy in image clustering 
we consider the problem of computing optical flow in monocular video taken from a moving vehicle in this setting the vast majority of image flow is due to the vehicle s ego motion we propose to take advantage of this fact and estimate flow along the epipolar line of the ego motion towards this goal we derive a slanted plane mrf model which explicitly reason about the ordering of plane and their physical validity at junction furthermore we present a bottom up grouping algorithm which produce over segmentation that respect flow boundary we demonstrate the effectiveness of our approach in the challenging kitti flow benchmark achieving half the error of the best competing general flow algorithm and one third of the error of the best epipolar flow algorithm 
we propose a new latent variable model for scene recognition our approach represents a scene a a collection of region model part arranged in a reconfigurable pattern we partition an image into a predefined set of region and use a latent variable to specify which region model is assigned to each image region in our current implementation we use a bag of word representation to capture the appearance of an image region the resulting method generalizes a spatial bag of word approach that relies on a fixed model for the bag of word in each image region our model can be trained using both generative and discriminative method in the generative setting we use the expectation maximization em algorithm to estimate model parameter from a collection of image with category label in the discriminative setting we use a latent structural svm lssvm we note that lssvms can be very sensitive to initialization and demonstrate that generative training with em provides a good initialization for discriminative training with lssvm 
graph cut algorithm commonly used in computer vision solve a first order mrf over binary variable the state of the art for this np hard problem is qpbo which find the value for a subset of the variable in the global minimum while qpbo is very effective overall there are still many difficult problem where it can only label a small subset of the variable we propose a new approach that instead of optimizing the original graphical model instead optimizes a tractable sub model defined a an energy function that us a subset of the pairwise interaction of the original but for which exact inference can be done efficiently our bounded treewidth subgraph k bts algorithm greedily computes a large weight treewidth k subgraph of the signed graph then solves the energy minimization problem for this subgraph by dynamic programming the edge omitted by our greedy method provide a per instance lower bound we demonstrate promising experimental result for binary deconvolution a challenging problem used to benchmark qpbo our algorithm performs an order of magnitude better than qpbo or it common variant both in term of energy and accuracy and the visual quality of our output is strikingly better a well we also obtain a significant improvement in energy and accuracy on a stereo benchmark with nd order prior although the improvement in visual quality is more modest our method s running time is comparable to qpbo 
we present a novel implementation friendly and occlusion aware semi supervised video segmentation algorithm using tree structured graphical model which delivers pixel label along with their uncertainty estimate our motivation to employ supervision is to tackle a task specific segmentation problem where the semantic object are pre defined by the user the video model we propose for this problem is based on a tree structured approximation of a patch based undirected mixture model which includes a novel time series and a soft label random forest classifier participating in a feedback mechanism we demonstrate the efficacy of our model in cutting out foreground object and multi class segmentation problem in lengthy and complex road scene sequence our result have wide applicability including harvesting labelled video data for training discriminative model shape pose articulation learning and large scale statistical analysis to develop prior for video segmentation 
we propose a novel tracking algorithm that robustly track the target by finding the state which minimizes uncertainty of the likelihood at current state the uncertainty of the likelihood is estimated by obtaining the gap between the lower and upper bound of the likelihood by minimizing the gap between the two bound our method find the confident and reliable state of the target in the paper the state that give the minimum uncertainty gap mug between likelihood bound is shown to be more reliable than the state which give the maximum likelihood only especially when there are severe illumination change occlusion and pose variation a rigorous derivation of the lower and upper bound of the likelihood for the visual tracking problem is provided to address this issue additionally an efficient inference algorithm using interacting markov chain monte carlo is presented to find the best state that maximizes the average of the lower and upper bound of the likelihood and minimizes the gap between two bound simultaneously experimental result demonstrate that our method successfully track the target in realistic video and outperforms conventional tracking method 
mobile platform such a smart phone and tablet computer have attained the technological capacity to perform task beyond their intended purpose the steady increase of processing power ha enticed researcher to attempt increasingly challenging task on mobile device with appropriate modification over their stationary counterpart in this work we present a novel multi frame object detection application for the mobile platform that is capable of object localization our work leverage the hough forest based object detector introduced by gall et al in in our experiment we demonstrate that our novel multi frame generalization of notably improves the detection performance we test the performance of the technique in variable resolution the applicability to several object category and different datasets we implement the multi frame detector on a mobile platform through a novel client server framework that present a sound and viable environment for the multi frame detector finally we study implementation of both single and multi frame object detector based on this client server framework on a mobile device running the android o 
in this paper we present a new method for object retrieval starting from multiple query image the use of multiple query allows for a more expressive formulation of the query object including e g different viewpoint and or viewing condition this in turn lead to more diverse and more accurate retrieval result when no query image are available to the user they can easily be retrieved from the internet using a standard image search engine in particular we propose a new method based on pattern mining using the minimal description length principle we derive the most suitable set of pattern to describe the query object with pattern corresponding to local feature configuration this result in a powerful object specific mid level image representation the archive can then be searched efficiently for similar image based on this representation using a combination of two inverted file system since the pattern already encode local spatial information good result on several standard image retrieval datasets are obtained even without costly re ranking based on geometric verification 
this paper proposes a new non reference image quality metric that can be adopted by the state of the art image video denoising algorithm for auto denoising the proposed metric is extremely simple and can be implemented in four line of matlab code the basic assumption employed by the proposed metric is that the noise should be independent of the original image a direct measurement of this dependence is however impractical due to the relatively low accuracy of existing denoising method the proposed metric thus aim at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous region and the structure similarity between the input noisy image and the denoised image around highly structured region and is computed a the linear correlation coefficient of the two corresponding structure similarity map numerous experimental result demonstrate that the proposed metric not only outperforms the current state of the art non reference quality metric quantitatively and qualitatively but also better maintains temporal coherence when used for video denoising 
cascade style approach to implementing ensemble classifier can deliver significant speed ups at test time while highly effective they remain challenging to tune and their overall performance depends on the availability of large validation set to estimate rejection threshold these characteristic are often prohibitive and thus limit their applicability we introduce an alternative approach to speeding up classifier evaluation which overcomes these limitation it involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough a a result the evaluation terminates early based on the sequence of response observed furthermore it doe so independently of the type of ensemble classifier used or the way it wa trained we show through extensive experimentation that our method provides to fold speed ups over existing state of the art method at almost no loss in accuracy on a number of object classification task 
it is commonly believed that higher order smoothness should be modeled using higher order interaction for example nd order derivative for deformable active contour are represented by triple clique similarly the nd order regularization method in stereo predominantly use mrf model with scalar d disparity label and triple clique interaction in this paper we advocate a largely overlooked alternative approach to stereo where nd order surface smoothness is represented by pairwise interaction with d label e g tangent plane this general paradigm ha been criticized due to perceived computational complexity of optimization in higher dimensional label space contrary to popular belief we demonstrate that representing nd order surface smoothness with d label lead to simpler optimization problem with nearly sub modular pairwise interaction our theoretical and experimental result demonstrate advantage over state of the art method for nd order smoothness stereo 
in this paper each image is viewed a a bag of local region a well a it is investigated globally a novel method is developed for achieving multi label multi instance image annotation where image level bag level label and region level instance level label are both obtained the association between semantic concept and visual feature are mined both at the image level and at the region level inter label correlation are captured by a co occurence matrix of concept pair the cross level label coherence encodes the consistency between the label at the image level and the label at the region level the association between visual feature and semantic concept the correlation among the multiple label and the cross level label coherence are sufficiently leveraged to improve annotation performance structural max margin technique is used to formulate the proposed model and multiple interrelated classifier are learned jointly to leverage the available image level labeled sample for the model training the region level label identification on the training set is firstly accomplished by building the correspondence between the multiple bag level label and the image region jec distance based kernel are employed to measure the similarity both between image and between region experimental result on real image datasets msrc and corel demonstrate the effectiveness of our method 
this paper present three new method for regularizing the least square solution of the reconstruction of a surface from it gradient field firstly the spectral regularization based on discrete generalized fourier series e g gram polynomial haar function etc secondly the tikhonov regularization applied directly to the d domain problem and thirdly the regularization via constraint such a arbitrary dirichlet boundary condition it is shown that the solution to the aforementioned problem all satisfy sylvester equation which lead to substantial computational gain specifically the solution of the sylvester equation is direct non iterative and for an m n surface is of the same complexity a computing an svd of the same size i e an o n algorithm in contrast state of the art algorithm are based on large scale linear solver and use iterative technique based on an o n linear sub step to emphasize this improvement it is demonstrated that the new algorithm are upwards of ten thousand time faster than the state of the art technique incorporating regularization in fact the new algorithm allow for the realtime regularized reconstruction of surface on the order of megapixels which is unprecedented for this computer vision problem 
in object recognition soft assignment coding enjoys computational efficiency and conceptual simplicity however it classification performance is inferior to the newly developed sparse or local coding scheme it would be highly desirable if it classification performance could become comparable to the state of the art leading to a coding scheme which perfectly combine computational efficiency and classification performance to achieve this we revisit soft assignment coding from two key aspect classification performance and probabilistic interpretation for the first aspect we argue that the inferiority of soft assignment coding is due to it neglect of the underlying manifold structure of local feature to remedy this we propose a simple modification to localize the soft assignment coding which surprisingly achieves comparable or even better performance than existing sparse or local coding scheme while maintaining it computational advantage for the second aspect based on our probabilistic interpretation of the soft assignment coding we give a probabilistic explanation to the magic max pooling operation which ha successfully been used by sparse or local coding scheme but still poorly understood this probability explanation motivates u to develop a new mix order max pooling operation which further improves the classification performance of the proposed coding scheme a experimentally demonstrated the localized soft assignment coding achieves the state of the art classification performance with the highest computational efficiency among the existing coding scheme 
facial micro expression are rapid involuntary facial expression which reveal suppressed affect to the best knowledge of the author there is no previous work that successfully recognises spontaneous facial micro expression in this paper we show how a temporal interpolation model together with the first comprehensive spontaneous micro expression corpus enable u to accurately recognise these very short expression we designed an induced emotion suppression experiment to collect the new corpus using a high speed camera the system is the first to recognise spontaneous facial micro expression and achieves very promising result that compare favourably with the human micro expression detection accuracy 
an anaglyph is a single image created by selecting complementary color from a stereo color pair the user can perceive depth by viewing it through color filtered glass we propose a technique to reconstruct the original color stereo pair given such an anaglyph we modified sift flow and use it to initially match the different color channel across the two view our technique then iteratively refines the match selects the good match which defines the anchor color and propagates the anchor color we use a diffusion based technique for the color propagation and added a step to suppress unwanted color result on a variety of input demonstrate the robustness of our technique we also extended our method to anaglyph video by using optic flow between time frame 
we propose a method for global multi target tracking that can incorporate higher order track smoothness constraint such a constant velocity our problem formulation readily lends itself to path estimation in a trellis graph but unlike previous method each node in our network represents a candidate pair of matching observation between consecutive frame extra constraint on binary flow variable in the graph result in a problem that can no longer be solved by min cost network flow we therefore propose an iterative solution method that relaxes these extra constraint using lagrangian relaxation resulting in a series of problem that are solvable by min cost flow and that progressively improve towards a high quality solution to our original optimization problem we present experimental result showing that our method outperforms the standard network flow formulation a well a other recent algorithm that attempt to incorporate higher order smoothness constraint 
an important topic in computer vision is d object reconstruction from line drawing previous algorithm either deal with simple general object or are limited to only manifold a subset of solid in this paper we propose a novel approach to d reconstruction of complex general object including manifold non manifold solid and nonsolids through developing some d object property we use the degree of freedom of object to decompose a complex line drawing into multiple simpler line drawing that represent meaningful building block of a complex object after d object are reconstructed from the decomposed line drawing they are merged to form a complex object from their touching face edge and vertex our experiment show a number of reconstruction example from both complex line drawing and image with line drawing superimposed comparison are also given to indicate that our algorithm can deal with much more complex line drawing of general object than previous algorithm 
we describe a method to construct a sparse lookup table lut that is effective in modeling the camera imaging pipeline that map a raw camera value to their srgb output this work build on the recent in camera color processing model proposed by kim et al that included a d gamut mapping function the major drawback in is the high computational cost of the d mapping function that us radial basis function rbf involving several thousand control point we show how to construct a lut using a novel nonuniform lattice regression method that adapts the lut lattice to better fit the d gamut mapping function our method offer not only a performance speedup of an order of magnitude faster than rbf but also a compact mechanism to describe the imaging pipeline 
using optical triangulation method to measure the shape of translucent object is difficult because subsurface scattering contaminates measurement of the direct reflection at the surface a number of recent paper have shown that high frequency sinusoidal illumination pattern allow isolating this direct component which in turn enables accurate estimation of the shape of translucent object despite these encouraging result there is currently no rigorous mathematical analysis of the expected error in the measured surface a it relates to the parameter of these system the frequency of the projected sinusoid the geometric configuration of the source and camera and the optical property of the target object we present such an analysis which confirms earlier empirical result and provides a much needed tool for designing d scanner for translucent object 
active learning aim to reduce the amount of label required for classification the main difficulty is to find a good trade off between exploration and exploitation of the labeling process that depends among other thing on the classification task the distribution of the data and the employed classification scheme in this paper we analyze different sampling criterion including a novel density based criterion and demonstrate the importance to combine exploration and exploitation sampling criterion we also show that a time varying combination of sampling criterion often improves performance finally by formulating the criterion selection a a markov decision process we propose a novel feedback driven framework based on reinforcement learning our method doe not require prior information on the dataset or the sampling criterion but rather is able to adapt the sampling strategy during the learning process by experience we evaluate our approach on three challenging object recognition datasets and show superior performance to previous active learning method 
the use of semantic attribute in computer vision problem ha been gaining increased popularity in recent year attribute provide an intermediate feature representation in between low level feature and the class category and offer several attractive property among which are improved learning of novel category based on few example a well a allowing for zero shot learning however the major caveat is that learning semantic attribute is a laborious task requiring a significant amount of time and human intervention to provide label in order to address this issue we propose a weakly supervised approach to learn mid level feature where the only supervision is provided by the category class of the training example we develop a novel extension of the restricted boltzmann machine rbm with beta bernoulli process prior unlike the standard rbm our model us the class label to promote more efficient sharing of information by different category this tends to improve the generalization performance by using semantic attribute for which annotation are available we show that we can find correspondence between the mid level feature that we learn and the labeled attribute therefore the mid level feature have distinct semantic characterization which is very similar to that given by the semantic attribute even though their labeling wa not used during the training process our experimental result in object recognition task show significant performance gain outperforming method which rely on manually labeled semantic attribute 
this paper introduces a novel similarity learning framework working with inequality constraint involving quadruplet of image our approach aim at efficiently modeling similarity from rich or complex semantic label relationship from these quadruplet wise constraint we propose a similarity learning framework relying on a convex optimization scheme we then study how our metric learning scheme can exploit specific class relationship such a class ranking relative attribute and class taxonomy we show that classification using the learned metric get improved performance over state of the art method on several datasets we also evaluate our approach in a new application to learn similarity between web page screenshots in a fully unsupervised way 
visual quality visq representation is a fundamental step in the learning of a visq prediction model for photo it not only reflects how we understand visq but also determines the label type existing study apply a scalar value i e a categorical label or a score to represent visq a visq is a subjective property only a scalar value is insufficient to represent human s perceived visq of a photo this study represents visq by a distribution on pre defined ordinal basic rating in order to capture the subjectivity of visq better when using the new representation the label type is structural instead of scalar conventional learning algorithm cannot be directly applied in model learning meanwhile for many photo the number of user involved in the evaluation are limited making some label unreliable in this study a new algorithm called support vector distribution regression svdr is presented to deal with the structural output learning two independent learning strategy reliability sensitive learning and label refinement are proposed to alleviate the difficulty of insufficient involved user for rating combining svdr with the two learning strategy two separate structural output regression algorithm i e reliability sensitive svdr and label refinement based svdr are produced experimental result demonstrate the effectiveness of our introduced learning strategy and learning algorithm 
in this paper we explore the idea of using high level semantic concept also called attribute to represent human action from video and argue that attribute enable the construction of more descriptive model for human action recognition we propose a unified framework wherein manually specified attribute are i selected in a discriminative fashion so a to account for intra class variability ii coherently integrated with data driven attribute to make the attribute set more descriptive data driven attribute are automatically inferred from the training data using an information theoretic approach our framework is built upon a latent svm formulation where latent variable capture the degree of importance of each attribute for each action class we also demonstrate that our attribute based action representation can be effectively used to design a recognition procedure for classifying novel action class for which no training sample are available we test our approach on several publicly available datasets and obtain promising result that quantitatively demonstrate our theoretical claim 
generic object detection is confronted by dealing with different degree of variation in distinct object class with tractable computation which demand for descriptive and flexible object representation that are also efficient to evaluate for many location in view of this we propose to model an object class by a cascaded boosting classifier which integrates various type of feature from competing local region named a region let a region let is a base feature extraction region defined proportionally to a detection window at an arbitrary resolution i e size and aspect ratio these region let are organized in small group with stable relative position to delineate fine grained spatial layout inside object their feature are aggregated to a one dimensional feature within one group so a to tolerate deformation then we evaluate the object bounding box proposal in selective search from segmentation cue limiting the evaluation location to thousand our approach significantly outperforms the state of the art on popular multi class detection benchmark datasets with a single method without any context it achieves the detection mean average precision of on the pascal voc dataset and on the voc for object category it achieves mean average precision on the image net dataset for object category outperforming the latest deformable part based model dpm by 
bag of word based image classification approach mostly rely on low level local shape feature however it ha been shown that combining multiple cue such a color texture or shape is a challenging and promising task which can improve the classification accuracy most of the state of the art feature fusion method usually aim to weight the cue without considering their statistical dependence in the application at hand in this paper we present a new logistic regression based fusion method called lrff which take advantage of the different cue without being tied to any of them we also design a new marginalized kernel by making use of the output of the regression model we show that such kernel surprisingly ignored so far by the computer vision community are particularly well suited to achieve image classification task we compare our approach with existing method that combine color and shape on three datasets the proposed learning based feature fusion process clearly outperforms the state of the art fusion method for image classification 
this paper tackle the supervised evaluation of image segmentation algorithm first it survey and structure the measure used to compare the segmentation result with a ground truth database and proposes a new measure the precision recall for object and part to compare the goodness of these measure it defines three quantitative meta measure involving six state of the art segmentation method the meta measure consist in assuming some plausible hypothesis about the result and assessing how well each measure reflects these hypothesis a a conclusion this paper proposes the precision recall curve for boundary and for object and part a the tool of choice for the supervised evaluation of image segmentation we make the datasets and code of all the measure publicly available 
recently group wise registration ha been investigated for simultaneous alignment of all image without selecting any individual image a the template thus avoiding the potential bias in image registration however none of current group wise registration method fully utilizes the image distribution to guide the registration thus the registration performance usually suffers from large inter subject variation across individual image to solve this issue we propose a novel group wise registration algorithm for large population dataset guided by the image distribution on the manifold specifically we first use a graph to model the distribution of all image data sitting on the image manifold with each node representing an image and each edge representing the geodesic pathway between two node or image then the procedure of warping all image to their population center turn to the dynamic shrinking of the graph node along their graph edge until all graph node become close to each other thus the topology of image distribution on the image manifold is always preserved during the group wise registration more importantly by modeling the distribution of all image via a graph we can potentially reduce registration error since every time each image is warped only according to it nearby image with similar structure in the graph we have evaluated our proposed group wise registration method on both synthetic and real datasets with comparison to the two state of the art group wise registration method all experimental result show that our proposed method achieves the best performance in term of registration accuracy and robustness 
reflection in image sequence consist of several layer superimposed over each other this phenomenon cause many image processing technique to fail a they assume the presence of only one layer at each examined site e g motion estimation and object recognition this work present an automated technique for detecting reflection in image sequence by analyzing motion trajectory of feature point it model reflection a region containing two different layer moving over each other we present a strong detector based on combining a set of weak detector we use novel prior generate sparse and dense detection map and our result show high detection rate with rejection to pathological motion and occlusion 
in this work we consider image of a scene with a moving object captured by a static camera a the object human or otherwise move about the scene it reveals pairwise depth ordering or occlusion cue the goal of this work is to use these sparse occlusion cue along with monocular depth occlusion cue to densely segment the scene into depth layer we cast the problem of depth layer segmentation a a discrete labeling problem on a spatio temporal markov random field mrf that us the motion occlusion cue along with monocular cue and a smooth motion prior for the moving object we quantitatively show that depth ordering produced by the proposed combination of the depth cue from object motion and monocular occlusion cue are superior to using either feature independently and using a naive combination of the feature 
fast match is a fast algorithm for approximate template matching under d affine transformation that minimizes the sum of absolute difference sad error measure there is a huge number of transformation to consider but we prove that they can be sampled using a density that depends on the smoothness of the image for each potential transformation we approximate the sad error using a sub linear algorithm that randomly examines only a small number of pixel we further accelerate the algorithm using a branch and bound scheme a image are known to be piecewise smooth the result is a practical affine template matching algorithm with approximation guarantee that take a few second to run on a standard machine we perform several experiment on three different datasets and report very good result to the best of our knowledge this is the first template matching algorithm which is guaranteed to handle arbitrary d affine transformation 
in this paper we raise important issue on scalability and the required degree of supervision of existing mahalanobis metric learning method often rather tedious optimization procedure are applied that become computationally intractable on a large scale further if one considers the constantly growing amount of data it is often infeasible to specify fully supervised label for all data point instead it is easier to specify label in form of equivalence constraint we introduce a simple though effective strategy to learn a distance metric from equivalence constraint based on a statistical inference perspective in contrast to existing method we do not rely on complex optimization problem requiring computationally expensive iteration hence our method is order of magnitude faster than comparable method result on a variety of challenging benchmark with rather diverse nature demonstrate the power of our method these include face in unconstrained environment matching before unseen object instance and person re identification across spatially disjoint camera in the latter two benchmark we clearly outperform the state of the art 
in this work we present a new part based object detection algorithm with hundred of part performing real time detection part based model are currently state of the art for object detection due to their ability to represent large appearance variation however due to their high computational demand such method are limited to several part only and are too slow for practical real time implementation our algorithm is an accelerated version of the feature synthesis f method which us multiple object part for detection and is among state of the art method on human detection benchmark but also suffers from a high computational cost the proposed accelerated feature synthesis afs us several strategy for reducing the number of location searched for each part the first strategy us a novel algorithm for approximate nearest neighbor search which we developed termed kd fern to compare each image location to only a subset of the model part candidate part location for a specific part are further reduced using spatial inhibition and using an object level coarse to fine strategy in our empirical evaluation on pedestrian detection benchmark afs maintains almost fully the accuracy performance of the original f while running more than x faster than existing part based method which use only several part afs is to our best knowledge the first part based object detection method achieving real time running performance nearly frame per second on x image on a regular cpu 
kernel have been a common tool of machine learning and computer vision application for modeling non linearity and or the design of robust robustness may refer to either the presence of outlier and noise or to the robustness to a class of transformation e g translation similarity measure between object arguably the class of positive semi definite psd kernel widely known a mercer s kernel constitutes one of the most well studied case for every psd kernel there exists an associated feature map to an arbitrary dimensional hilbert space mathcal h the so called feature space the main reason behind psd kernel popularity is the fact that classification regression technique such a support vector machine svms and component analysis algorithm such a kernel principal component analysis kpca can be devised in mathcal h without an explicit definition of the feature map only by using the kernel the so called kernel trick recently due to the development of very efficient solution for large scale linear svms and for incremental linear component analysis the research towards finding feature map approximation for class of kernel ha attracted significant interest in this paper we attempt the derivation of explicit feature map of a recently proposed class of kernel the so called one shot similarity kernel we show that for this class of kernel either there exists an explicit representation in feature space or the kernel can be expressed in such a form that allows for exact incremental learning we theoretically explore the property of these kernel and show how these kernel can be used for the development of robust visual tracking recognition and deformable fitting algorithm 
in blind deconvolution one aim to estimate from an input blurred image y a sharp image x and an unknown blur kernel k recent research show that a key to success is to consider the overall shape of the posterior distribution p x k y and not only it mode this lead to a distinction between map x k strategy which estimate the mode pair x k and often lead to undesired result and map k strategy which select the best k while marginalizing over all possible x image the map k principle is significantly more robust than the map x k one yet it involves a challenging marginalization over latent image a a result map k technique are considered complicated and have not been widely exploited this paper derives a simple approximated map k algorithm which involves only a modest modification of common map x k algorithm we show that map k can in fact be optimized easily with no additional computational complexity 
detecting sample from previously unknown class is a crucial task in object recognition especially when dealing with real world application where the closed world assumption doe not hold we present how to apply a null space method for novelty detection which map all training sample of one class to a single point beside the possibility of modeling a single class we are able to treat multiple known class jointly and to detect novelty for a set of class with a single model in contrast to modeling the support of each known class individually our approach make use of a projection in a joint subspace where training sample of all known class have zero intra class variance this subspace is called the null space of the training data to decide about novelty of a test sample our null space approach allows for solely relying on a distance measure instead of performing density estimation directly therefore we derive a simple yet powerful method for multi class novelty detection an important problem not studied sufficiently so far our novelty detection approach is assessed in comprehensive multi class experiment using the publicly available datasets caltech and image net the analysis reveals that our null space approach is perfectly suited for multi class novelty detection since it outperforms all other method 
we derive precise condition under which material reflectance property may be estimated from a single image of a homogeneous curved surface canonically a sphere lit by a directional source based on the observation that light is reflected along certain a priori unknown preferred direction such a the half angle we propose a semiparametric brdf abstraction that lie between purely parametric and purely data driven model formulating brdf estimation a a particular type of semiparametric regression both the preferred direction and the form of brdf variation along them can be estimated from data our approach ha significant theoretical algorithmic and empirical benefit lends insight into material behavior and enables novel application while it is well known that fitting multi lobe brdfs may be ill posed under certain condition prior to this work precise result for the well posedness of brdf estimation had remained elusive since our brdf representation is derived from physical intuition but relies on data we avoid pitfall of both parametric low generalizability and non parametric regression low interpretability curse of dimensionality finally we discus several application such a single image relighting light source estimation and physically meaningful brdf editing 
in this paper we propose a convex optimization framework for simultaneous estimation of super resolved depth map and image from a single moving camera the pixel measurement error in d reconstruction is directly related to the resolution of the image at hand in turn even a small measurement error can cause significant error in reconstructing d scene structure or camera pose therefore enhancing image resolution can be an effective solution for securing the accuracy a well a the resolution of d reconstruction in the proposed method depth map estimation and image super resolution are formulated in a single energy minimization framework with a convex function and solved efficiently by a first order primal dual algorithm explicit inter frame pixel correspondence are not required for our super resolution procedure thus we can avoid a huge computation time and obtain improved depth map in the accuracy and resolution a well a high resolution image with reasonable time the superiority of our algorithm is demonstrated by presenting the improved depth map accuracy image super resolution result and camera pose estimation 
this paper present a novel method for feature description based on intensity order specifically a local intensity order pattern liop is proposed to encode the local ordinal information of each pixel and the overall ordinal information is used to divide the local patch into subregions which are used for accumulating the liops respectively therefore both local and overall intensity ordinal information of the local patch are captured by the proposed liop descriptor so a to make it a highly discriminative descriptor it is shown that the proposed descriptor is not only invariant to monotonic intensity change and image rotation but also robust to many other geometric and photometric transformation such a viewpoint change image blur and jepg compression the proposed descriptor ha been evaluated on the standard oxford dataset and four additional image pair with complex illumination change the experimental result show that the proposed descriptor obtains a significant improvement over the existing state of the art descriptor 
we propose contour code a novel representation and binary hash table encoding for multispectral palmprint recognition we first present a reliable technique for the extraction of a region of interest roi from palm image acquired with non contact sensor the contour code representation is then derived from the nonsubsampled contourlet transform a uniscale pyramidal filter is convolved with the roi followed by the application of a directional filter bank the dominant directional subband establishes the orientation at each pixel and the index corresponding to this subband is encoded in the contour code representation unlike existing representation which extract orientation feature directly from the palm image the contour code us a two stage filtering to extract robust orientation feature the contour code is binarized into an efficient hash table structure that only requires indexing and summation operation for simultaneous one to many matching with an embedded score level fusion of multiple band we quantitatively evaluate the accuracy of the roi extraction by comparison with a manually produced ground truth multispectral palmprint verification result on the polyu and casia database show that the contour code achieves an eer reduction upto compared to state of the art method 
explosive growth of surveillance video data present formidable challenge to it browsing retrieval and storage video synopsis an innovation proposed by peleg and his colleague is aimed for fast browsing by shortening the video into a synopsis while keeping activity in video captured by a camera however the current technique are offline method requiring that all the video data be ready for the processing and are expensive in time and space in this paper we propose an online and efficient solution and it supporting algorithm to overcome the problem the method adopts an online content aware approach in a step wise manner hence applicable to endless video with le computational cost moreover we propose a novel tracking method called sticky tracking to achieve high quality visualization the system can achieve a faster than real time speed with a multi core cpu implementation the advantage are demonstrated by extensive experiment with a wide variety of video the proposed solution and algorithm could be integrated with surveillance camera and impact the way that surveillance video are recorded 
a device just like harry potter s marauder s map which pinpoint the location of each person of interest at all time provides invaluable information for analysis of surveillance video to make this device real a system would be required to perform robust person localization and tracking in real world surveillance scenario especially for complex indoor environment with many wall causing occlusion and long corridor with sparse surveillance camera coverage we propose a tracking by detection approach with nonnegative discretization to tackle this problem given a set of person detection output our framework take advantage of all important cue such a color person detection face recognition and non background information to perform tracking local learning approach are used to uncover the manifold structure in the appearance space with spatio temporal constraint nonnegative discretization is used to enforce the mutual exclusion constraint which guarantee a person detection output to only belong to exactly one individual experiment show that our algorithm performs robust localization and tracking of person of interest not only in outdoor scene but also in a complex indoor real world nursing home environment 
we develop a dictionary learning method which is i online ii enables overlapping group structure with iii non convex sparsity inducing regularization and iv handle the partially observable case structured sparsity and the related group norm have recently gained widespread attention in group sparsity regularized problem in the case when the dictionary is assumed to be known and fixed however when the dictionary also need to be learned the problem is much more difficult only a few method have been proposed to solve this problem and they can handle two of these four desirable property at most to the best of our knowledge our proposed method is the first one that posse all of these property we investigate several interesting special case of our framework such a the online structured sparse non negative matrix factorization and demonstrate the efficiency of our algorithm with several numerical experiment 
image re ranking a an effective way to improve the result of web based image search ha been adopted by current commercial search engine given a query keyword a pool of image are first retrieved by the search engine based on textual information by asking the user to select a query image from the pool the remaining image are re ranked based on their visual similarity with the query image a major challenge is that the similarity of visual feature do not well correlate with image semantic meaning which interpret user search intention on the other hand learning a universal visual semantic space to characterize highly diverse image from the web is difficult and inefficient in this paper we propose a novel image re ranking framework which automatically offline learns different visual semantic space for different query keywords through keyword expansion the visual feature of image are projected into their related visual semantic space to get semantic signature at the online stage image are re ranked by comparing their semantic signature obtained from the visual semantic space specified by the query keyword the new approach significantly improves both the accuracy and efficiency of image re ranking the original visual feature of thousand of dimension can be projected to the semantic signature a short a dimension experimental result show that relative improvement ha been achieved on re ranking precision compared with the state of the art method 
we present a framework for the automatic recognition of complex multi agent event in setting where structure is imposed by rule that agent must follow while performing activity given semantic spatio temporal description of what generally happens i e rule event description physical constraint and based on video analysis we determine the event that occurred knowledge about spatio temporal structure is encoded using first order logic using an approach based on allen s interval logic and robustness to low level observation uncertainty is provided by markov logic network mln our main contribution is that we integrate interval based temporal reasoning with probabilistic logical inference relying on an efficient bottom up grounding scheme to avoid combinatorial explosion applied to one on one basketball our framework detects and track player their hand and foot and the ball generates event observation from the resulting trajectory and performs probabilistic logical inference to determine the most consistent sequence of event we demonstrate our approach on hr frame of outdoor video 
the automatic extraction and labeling of the rib centerline is a useful yet challenging task in many clinical application in this paper we propose a new approach integrating rib seed point detection and template matching to detect and identify each rib in chest ct scan the bottom up learning based detection exploit local image cue and top down deformable template matching imposes global shape constraint to adapt to the shape deformation of different rib cage whereas maintain high computational efficiency we employ a markov random field mrf based articulated rigid transformation method followed by active contour model acm deformation compared with traditional method that each rib is individually detected traced and labeled the new approach is not only much more robust due to prior shape constraint of the whole rib cage but remove tedious post processing such a rib pairing and ordering step because each rib is automatically labeled during the template matching for experimental validation we create an annotated database of challenging volume with rib of various size shape and pathology such a metastasis and fracture the proposed approach show order of magnitude higher detection and labeling accuracy than state of the art solution and run about second for a complete rib cage on the average 
unsupervised over segmentation of an image into region of perceptually similar pixel known a super pixel is a widely used preprocessing step in segmentation algorithm super pixel method reduce the number of region that must be considered later by more computationally expensive algorithm with a minimal loss of information nevertheless a some information is inevitably lost it is vital that super pixel not cross object boundary a such error will propagate through later step existing method make use of projected color or depth information but do not consider three dimensional geometric relationship between observed data point which can be used to prevent super pixel from crossing region of empty space we propose a novel over segmentation algorithm which us voxel relationship to produce over segmentation which are fully consistent with the spatial geometry of the scene in three dimensional rather than projective space enforcing the constraint that segmented region must have spatial connectivity prevents label flow across semantic object boundary which might otherwise be violated additionally a the algorithm work directly in d space observation from several calibrated rgb d camera can be segmented jointly experiment on a large data set of human annotated rgb d image demonstrate a significant reduction in occurrence of cluster crossing object boundary while maintaining speed comparable to state of the art d method 
in this paper we address the problem of object segmentation in multiple view or video when two or more viewpoint of the same scene are available we propose a new approach that propagates segmentation coherence information in both space and time hence allowing evidence in one image to be shared over the complete set to this aim the segmentation is cast a a single efficient labeling problem over space and time with graph cut in contrast to most existing multi view segmentation method that rely on some form of dense reconstruction ours only requires a sparse d sampling to propagate information between viewpoint the approach is thoroughly evaluated on standard multi view datasets a well a on video with static view result compete with state of the art method but they are achieved with significantly fewer viewpoint with multiple video we report result that demonstrate the benefit of segmentation propagation through temporal cue 
in this paper we describe a method to represent and discover adversarial group behavior in a continuous domain in comparison to other type of behavior adversarial behavior is heavily structured a the location of a player or agent is dependent both on their teammate and adversary in addition to the tactic or strategy of the team we present a method which can exploit this relationship through the use of a spatiotemporal basis model a player constantly change role during a match we show that employing a role based representation instead of one based on player identity can best exploit the playing structure a vision based system currently do not provide perfect detection tracking e g missed or false detection we show that our compact representation can effectively denoise erroneous detection a well a enabling temporal analysis which wa previously prohibitive due to the dimensionality of the signal to evaluate our approach we used a fully instrumented field hockey pitch with fixed high definition hd camera and evaluated our approach on approximately frame of data from a state of the art real time player detector and compare it to manually labelled data 
light color estimation is crucial to the color constancy problem past decade have witnessed great progress in solving this problem contrary to traditional method many researcher propose a variety of combinational color constancy method through applying different color constancy mathematical model on an image simultaneously and then give out a final estimation in diverse way although many comprehensive evaluation or review about color constancy method are available few focus on combinational strategy in this paper we survey some prevailing combinational strategy systematically divide them into three category and compare them qualitatively on three real world image data set in term of the angular error and the perceptual euclidean distance the experimental result show that combinational strategy with training procedure always produce better performance 
current face image retrieval method achieve impressive result but lack efficient way to refine the search particularly for geometric face attribute user cannot easily find face with slightly more furrowed brow or specific leftward pose shift for example to address this problem we propose a new face search technique based on shape manipulation that is complementary to current search engine user drag one or a small number of contour point like the bottom of the chin or the corner of an eyebrow to search for face similar in shape to the current face but with updated geometric attribute specific to their edits for example the user can drag a mouth corner to find face with wider smile or the tip of the nose to find face with a specific pose a part of our system we propose a novel confidence score for face alignment result that automatically construct a contour aligned face database with reasonable alignment accuracy a simple and straightforward extension of pca with missing data to tensor analysis and a new regularized tensor model to compute shape feature vector for each aligned face all built upon previous work to the best of our knowledge our system demonstrates the first face retrieval approach based chiefly on shape manipulation we show compelling result on a sizable database of over face image captured in uncontrolled environment 
spatial context encode rich discriminative information for visual classification however a object shape and scale vary significantly among image spatial context with manually specified distance range are not guaranteed with optimality in this work we investigate how to automatically select discriminative and stable distance bin group for modeling image spatial context to improve classification performance we make two observation first the number of distance bin for context modeling can be arbitrarily large and discriminative context are only from a small subset of distance bin second adjacent distance bin for context modeling often show similar characteristic thus encouraging grouping them together can result in more stable representation utilizing these two observation we propose an omni range spatial context mining framework for image classification a sparse selection and grouping regularizer is employed along with an empirical risk to discover discriminative and stable distance bin group for context modeling to facilitate efficient optimization the objective function is approximated by a smooth convex function with theoretically guaranteed error bound the selected and grouped image spatial context which are applied in food and national flag recognition are demonstrated to be discriminative compact and robust 
the mode of manual annotation used in an interactive segmentation algorithm affect both it accuracy and ease of use for example bounding box are fast to supply yet may be too coarse to get good result on difficult image freehand outline are slower to supply and more specific yet they may be overkill for simple image whereas existing method assume a fixed form of input no matter the image we propose to predict the tradeoff between accuracy and effort our approach learns whether a graph cut segmentation will succeed if initialized with a given annotation mode based on the image s visual separability and foreground uncertainty using these prediction we optimize the mode of input requested on new image a user want segmented whether given a single image that should be segmented a quickly a possible or a batch of image that must be segmented within a specified time budget we show how to select the easiest modality that will be sufficiently strong to yield high quality segmentation extensive result with real user and three datasets demonstrate the impact 
recent research effort in semantic representation and context modeling are based on the principle of task expansion that vision problem such a object recognition scene classification or retrieval rcr cannot be solved in isolation the extended principle of modality expansion that rcr problem cannot be solved from visual information alone is investigated in this work a semantic image labeling system is augmented with text pair of image and text are mapped to a semantic space and the text feature used to regularize their image counterpart this is done with a new cross modal regularizer which learns the mapping of the image feature that maximizes their average similarity to those derived from text the proposed regularizer is class sensitive combining a set of class specific denoising transformation and nearest neighbor interpolation of text based class assignment regularization of a state of the art approach to image retrieval is then shown to produce substantial gain in retrieval accuracy outperforming recent image retrieval approach 
the confluence of robust algorithm for structure from motion along with high coverage mapping and imaging of the world around u suggests that it will soon be feasible to accurately estimate camera pose for a large class photograph taken in outdoor urban environment in this paper we investigate how such information can be used to improve the detection of dynamic object such a pedestrian and car first we show that when rough camera location is known we can utilize detector that have been trained with a scene specific background model in order to improve detection accuracy second when precise camera pose is available dense matching to a database of existing image using multi view stereo provides a way to eliminate static background such a building facade akin to background subtraction often used in video analysis we evaluate these idea using a dataset of tourist photo with estimated camera pose for template based pedestrian detection we achieve a percent boost in average precision over baseline 
a class of technique in computer vision and graphic is based on capturing multiple image of a scene under different illumination condition these technique explore variation in illumination from image to image to extract interesting information about the scene however their applicability to dynamic environment is limited due to the need for robust motion compensation algorithm to overcome this issue we propose a method to separate multiple illuminant from a single image given an image of a scene simultaneously illuminated by multiple light source our method generates individual image a if they had been illuminated by each of the light source separately to facilitate the illumination separation process we encode each light source with a distinct sinusoidal pattern strategically selected given the relative position of each light with respect to the camera such that the observed sinusoid become independent of the scene geometry the individual illuminant are then demultiplexed by analyzing local frequency we show application of our approach in image based relighting photometric stereo and multiflash imaging 
existing multi model approach for image set classification extract local model by clustering each image set individually only once with fixed cluster used for matching with other image set however this may result in the two closest cluster to represent different characteristic of an object due to different undesirable environmental condition such a variation in illumination and pose to address this problem we propose to constrain the clustering of each query image set by forcing the cluster to have resemblance to the cluster in the gallery image set we first define a frobenius norm distance between subspace over grassmann manifold based on reconstruction error we then extract local linear subspace from a gallery image set via sparse representation for each local linear subspace we adaptively construct the corresponding closest subspace from the sample of a probe image set by joint sparse representation we show that by minimising the sparse representation reconstruction error we approach the nearest point on a grassmann manifold experiment on honda eth and cambridge gesture datasets show that the proposed method consistently outperforms several other recent technique such a affine hull based image set distance ahisd sparse approximated nearest point sanp and manifold discriminant analysis mda 
over the past two decade a number of face recognition method have been proposed in the literature most of them use holistic face image to recognize people however human face are easily occluded by other object in many real world scenario and we have to recognize the person of interest from his her partial face in this paper we propose a new partial face recognition approach by using feature set matching which is able to align partial face patch to holistic gallery face automatically and is robust to occlusion and illumination change given each gallery image and probe face patch we first detect key point and extract their local feature then we propose a metric learned extended robust point matching mlerpm method to discriminatively match local feature set of a pair of gallery and probe sample lastly the similarity of two face is converted a the distance between two feature set experimental result on three public face database are presented to show the effectiveness of the proposed approach 
we propose a novel approach for ranking and retrieval of image based on multi attribute query existing image retrieval method train separate classifier for each word and heuristically combine their output for retrieving multiword query moreover these approach also ignore the interdependency among the query term in contrast we propose a principled approach for multi attribute retrieval which explicitly model the correlation that are present between the attribute given a multi attribute query we also utilize other attribute in the vocabulary which are not present in the query for ranking retrieval furthermore we integrate ranking and retrieval within the same formulation by posing them a structured prediction problem extensive experimental evaluation on the labeled face in the wild lfw facetracer and pascal voc datasets show that our approach significantly outperforms several state of the art ranking and retrieval method 
we explore a polar representation of optical flow in which each element of the brightness motion field is represented by it magnitude and orientation instead of it cartesian projection this seemingly small change in representation provides more direct access to the intrinsic structure of a flow field and when used with existing variational inference procedure it provides a framework in which regularizers can be intuitively tailored for very different class of motion our evaluation reveal that a flow estimation algorithm that is based on a polar representation can perform a well or better than the state of the art when applied to traditional optical flow problem concerning camera or rigid scene motion and at the same time it facilitates both qualitative and quantitative improvement for non traditional case such a fluid flow and specular flow whose structure is very different 
in this paper we address the problem of video object segmentation which is to automatically identify the primary object and segment the object out in every frame we propose a novel formulation of selecting object region candidate simultaneously in all frame a finding a maximum weight clique in a weighted region graph the selected region are expected to have high objectness score unary potential a well a share similar appearance binary potential since both unary and binary potential are unreliable we introduce two type of mutex mutual exclusion constraint on region in the same clique intra frame and inter frame constraint both type of constraint are expressed in a single quadratic form we propose a novel algorithm to compute the maximal weight clique that satisfy the constraint we apply our method to challenging benchmark video and obtain very competitive result that outperform state of the art method 
graph based method have become popular in recent year and have successfully addressed task like segmentation and deformable registration their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid like representation and the discrete nature of the quantized search space in this paper we introduce a novel approach for combined segmentation registration of brain tumor that adapts graph and sampling resolution according to the image content to this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space this information is considered in a hierarchical framework where uncertainty are propagated in a natural manner state of the art result in the joint segmentation registration of brain image with low grade glioma demonstrate the potential of our approach 
in this paper we study preconditioning technique for the first order primal dual algorithm proposed in in particular we propose simple and easy to compute diagonal preconditioners for which convergence of the algorithm is guaranteed without the need to compute any step size parameter a a by product we show that for a certain instance of the preconditioning the proposed algorithm is equivalent to the old and widely unknown alternating step method for monotropic programming we show numerical result on general linear programming problem and a few standard computer vision problem in all example the preconditioned algorithm significantly outperforms the algorithm of 
the tracker obtains robustness by seeking a sparse representation of the tracking object via norm minimization however the high computational complexity involved in the tracker may hamper it application in real time processing scenario here we propose real time com pressive sensing tracking rtcst by exploiting the signal recovery power of compressive sensing c dimensionality reduction and a customized orthogonal matching pursuit omp algorithm are adopted to accelerate the c tracking a a result our algorithm achieves a realtime speed that is up to time faster than that of the tracker meanwhile rtcst still produce competitive sometimes even superior tracking accuracy compared to the tracker furthermore for a stationary camera a refined tracker is designed by integrating a c based background model csbm into tracking this csbm equipped tracker termed rtcst b outperforms most state of the art tracker in term of both accuracy and robustness finally our experimental result on various video sequence which are verified by a new metric tracking success probability tsp demonstrate the excellence of the proposed algorithm 
an unconstrained end to end text localization and recognition method is presented the method introduces a novel approach for character detection and recognition which combine the advantage of sliding window and connected component method character are detected and recognized a image region which contain stroke of specific orientation in a specific relative position where the stroke are efficiently detected by convolving the image gradient field with a set of oriented bar filter additionally a novel character representation efficiently calculated from the value obtained in the stroke detection phase is introduced the representation is robust to shift at the stroke level which make it le sensitive to intra class variation and the noise induced by normalizing character size and positioning the effectiveness of the representation is demonstrated by the result achieved in the classification of real world character using an euclidian nearest neighbor classifier trained on synthetic data in a plain form the method wa evaluated on a standard dataset where it achieves state of the art result in both text localization and recognition 
contour completion play an important role in visual perception where the goal is to group fragmented low level edge element into perceptually coherent and salient contour this process is often considered a guided by some middle level gestalt principle most existing method for contour completion have focused on utilizing rather local gestalt law such a good continuity and proximity in contrast much fewer method have addressed the global contour closure effect despite that many psychological evidence have shown the usefulness of closure in perceptual grouping this paper proposes a novel higher order crf model to address the contour closure effect through local connectedness approximation this lead to a simplified problem structure where the higher order inference can be formulated a an integer linear program ilp and solved by an efficient cutting plane variant tested on the bsds benchmark our method achieves a comparable precision recall performance a superior contour grouping ability measured by rand index and more visually pleasing result compared with existing method 
appearance model is a key component of tracking algorithm most existing approach utilize the object information contained in the current and previous frame to construct the object appearance model and locate the object with the model in frame t this method may work well if the object appearance just fluctuates in short time interval nevertheless suboptimal location will be generated in frame t if the visual appearance change substantially from the model then continuous change would accumulate error and finally result in a tracking failure to copy with this problem in this paper we propose a novel algorithm online laplacian ranking support vector tracker lrsvt to robustly locate the object the lrsvt incorporates the labeled information of the object in the initial and the latest frame to resist the occlusion and adapt to the fluctuation of the visual appearance and the weakly labeled information from frame t to adapt to substantial change of the appearance extensive experiment on public benchmark sequence show the superior performance of lrsvt over some state of the art tracking algorithm 
in this paper we present a framework for d absolute scale motion and structure estimation of a multi camera system in challenging indoor environment it operates in real time and employ information from two camera with non overlapping field of view monocular visual odometry supplying up to scale d motion information is carried out in each of the camera and the metric scale is recovered via a linear solution by imposing the known static transformation between both sensor the redundancy in the motion estimate is finally exploited by a statistical fusion to an optimal d metric result the proposed technique is robust to outlier and able to continuously deliver a reasonable measurement of the scale factor the quality of the framework is demonstrated by a concise evaluation on indoor datasets including a comparison to accurate ground truth data provided by an external motion tracking system 
we study the problem of part discovery when partial correspondence between instance of a category are available for visual category that exhibit high diversity in structure such a building our approach can be used to discover part that are hard to name but can be easily expressed a a correspondence between pair of image part naturally emerge from point wise landmark match across many instance within a category we propose a learning framework for automatic discovery of part in such weakly supervised setting and show the utility of the rich part library learned in this way for three task object detection category specific saliency estimation and fine grained image parsing 
state of the art single image deblurring technique are sensitive to image noise even a small amount of noise which is inevitable in low light condition can degrade the quality of blur kernel estimation dramatically the recent approach of tai and lin try to iteratively denoise and deblur a blurry and noisy image however a we show in this work directly applying image denoising method often partially damage the blur information that is extracted from the input image leading to biased kernel estimation we propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insight our key observation is that applying a directional low pas filter to the input image greatly reduces the noise level while preserving the blur information in the orthogonal direction to the filter based on this observation our method applies a series of directional filter at different orientation to the input image and estimate an accurate radon transform of the blur kernel from each filtered image finally we reconstruct the blur kernel using inverse radon transform experimental result on synthetic and real data show that our algorithm achieves higher quality result than previous approach on blurry and noisy image 
how many labeled example are needed to estimate a classifier s performance on a new dataset we study the case where data is plentiful but label are expensive we show that by making a few reasonable assumption on the structure of the data it is possible to estimate performance curve with confidence bound using a small number of ground truth label our approach which we call semi supervised performance evaluation spe is based on a generative model for the classifier s confidence score in addition to estimating the performance of classifier on new datasets spe can be used to recalibrate a classifier by re estimating the class conditional confidence distribution 
energy with high order non sub modular interaction have been shown to be very useful in vision due to their high modeling power optimization of such energy however is generally np hard a naive approach that work for small problem instance is exhaustive search that is enumeration of all possible labelings of the underlying graph we propose a general minimization approach for large graph based on enumeration of labelings of certain small patch this partial enumeration technique reduces complex high order energy formulation to pair wise constraint satisfaction problem with unary cost ucsp which can be efficiently solved using standard method like trw s our approach outperforms a number of existing state of the art algorithm on well known difficult problem e g curvature regularization stereo deconvolution it give near global minimum and better speed our main application of interest is curvature regularization in the context of segmentation our partial enumeration technique allows to evaluate curvature directly on small patch using a novel integral geometry approach 
this paper considers the person verification problem in modern surveillance and video retrieval system the problem is to identify whether a pair of face or human body image is about the same person even if the person is not seen before traditional method usually look for a distance or similarity measure between image e g by metric learning algorithm and make decision based on a fixed threshold we show that this is nevertheless insufficient and sub optimal for the verification problem this paper proposes to learn a decision function for verification that can be viewed a a joint model of a distance metric and a locally adaptive thresholding rule we further formulate the inference on our decision function a a second order large margin regularization problem and provide an efficient algorithm in it dual from we evaluate our algorithm on both human body verification and face verification problem our method outperforms not only the classical metric learning algorithm including lmnn and itml but also the state of the art in the computer vision community 
we address the problem of action recognition in unconstrained video we propose a novel content driven pooling that leverage space time context while being robust toward global space time transformation being robust to such transformation is of primary importance in unconstrained video where the action localization can drastically shift between frame our pooling identifies region of interest using video structural cue estimated by differ ent saliency function to combine the different structural information we introduce an iterative structure learning algorithm wsvm weighted svm that determines the optimal saliency layout of an action model through a sparse regularizer a new optimization method is proposed to solve the wsvm highly non smooth objective function we evaluate our approach on standard action datasets kth ucf and hmdb most noticeably the accuracy of our algorithm reach on the challenging hmdb dataset which outperforms the state of the art of relatively 
in the real visual world the number of category a classifier need to discriminate is on the order of hundred or thousand for example the sun dataset contains scene category and imagenet ha synset designing a multiclass classifier that is both accurate and fast at test time is an extremely important problem in both machine learning and computer vision community to achieve a good trade off between accuracy and speed we adopt the relaxed hierarchy structure from where a set of binary classifier are organized in a tree or dag directed acyclic graph structure at each node class are colored into positive and negative group which are separated by a binary classifier while a subset of confusing class is ignored we color the class and learn the induced binary classifier simultaneously using a unified and principled max margin optimization we provide an analysis on generalization error to justify our design our method ha been tested on both caltech object recognition and the sun dataset scene classification and show significant improvement over existing method 
this paper proposes a novel part based representation for modeling object category our representation combine the effectiveness of deformable part based model with the richness of geometric representation by defining part based on consistent underlying d geometry our key hypothesis is that while the appearance and the arrangement of part might vary across the instance of object category the constituent part will still have consistent underlying d geometry we propose to learn this geometry driven deformable part based model gdpm from a set of labeled rgbd image we also demonstrate how the geometric representation of gdpm can help u leverage depth data during training and constrain the latent model learning problem but most importantly a joint geometric and appearance based representation not only allows u to achieve state of the art result on object detection but also allows u to tackle the grand challenge of understanding d object from d image 
in this paper we demonstrate an effective method for parsing clothing in fashion photograph an extremely challenging problem due to the large number of possible garment item variation in configuration garment appearance layering and occlusion in addition we provide a large novel dataset and tool for labeling garment item to enable future research on clothing estimation finally we present intriguing initial result on using clothing estimate to improve pose identification and demonstrate a prototype application for pose independent visual garment retrieval 
the vast majority of work on motion segmentation adopts the affine camera model due to it simplicity under the affine model the motion segmentation problem becomes that of subspace separation due to this assumption such method are mainly offline and exhibit poor performance when the assumption is not satisfied this is made evident in state of the art method that relax this assumption by using piecewise affine space and spectral clustering technique to achieve better result in this paper we formulate the problem of motion segmentation a that of manifold separation we then show how label propagation can be used in an online framework to achieve manifold separation the performance of our framework is evaluated on a benchmark dataset and achieves competitive performance while being online 
structured light based pattern provide a mean to capture the state of an object shape however it may be inefficient when the object is freely moving when it surface contains high curvature part or in out of depth of field situation for image based robotic guidance in unstructured and dynamic environment only one shot is required for capturing the shape of a moving region of interest then robust pattern and real time capability must be targeted to this end we have developed a novel technique for the generation of coded pattern directly driven by the hamming distance the counterpart is the big amount of code the coding decoding algorithm have to face with a high desired hamming distance we show that the mean hamming distance is a useful criterion for driving the pattern generation process and we give a way to predict it value furthermore to ensure local uniqueness of codewords with consideration of many incomplete one the perfect map theory is involved then we describe a pseudorandom exhaustive algorithm to build pattern with more than feature in a very short time thanks to a splitting strategy which performs the hamming test in the codeword space instead of the pattern array this lead to a significant reduction of the computational complexity and it may be applied to other purpose finally real time reconstruction from single image are reported and result are compared to the best known which are outperformed in many case 
we present a multi attributed dictionary learning algorithm for sparse coding considering training sample with multiple attribute a new distance matrix is proposed by jointly incorporating data and attribute similarity then an objective function is presented to learn category dependent dictionary that are compact closeness of dictionary atom based on data distance and attribute similarity reconstructive low reconstruction error with correct dictionary and label consistent encouraging the label of dictionary atom to be similar we have demonstrated our algorithm on action classification and face recognition task on several publicly available datasets experimental result with improved performance over previous dictionary learning method are shown to validate the effectiveness of the proposed algorithm 
this paper proposes to learn binary hash code within a statistical learning framework in which an upper bound of the probability of bayes decision error is derived for different form of hash function and a rigorous proof of the convergence of the upper bound is presented consequently minimizing such an upper bound lead to consistent performance improvement of existing hash code learning algorithm regardless of whether original algorithm are unsupervised or supervised this paper also illustrates a fast hash coding method that exploit simple binary test to achieve order of magnitude improvement in coding speed a compared to projection based method 
d parametric deformable model have been used to extract volumetric object boundary and they generate smooth boundary surface a result however in some segmentation case such a cerebral cortex with complex fold and crease and human lung with high curvature boundary parametric deformable model often suffer from over smoothing or decreased mesh quality during model deformation to address this problem we propose a d laplacian driven parametric deformable model with a new internal force derived from a mesh laplacian the internal force exerted on each control vertex can be decomposed into two orthogonal vector based on the vertex s tangential plane we then introduce a weighting function to control the contribution of the two vector based on the model mesh s geometry deforming the new model is solving a linear system so the new model can converge very efficiently to validate the model s performance we tested our method on various segmentation case and compared our model with finite element and level set deformable model 
this paper proposes motion atom and phrase a a mid level temporal part for representing and classifying complex action motion atom is defined a an atomic part of action and capture the motion information of action video in a short temporal scale motion phrase is a temporal composite of multiple motion atom with an and or structure which further enhances the discriminative ability of motion atom by incorporating temporal constraint in a longer scale specifically given a set of weakly labeled action video we firstly design a discriminative clustering method to automatically discover a set of representative motion atom then based on these motion atom we mine effective motion phrase with high discriminative and representative power we introduce a bottom up phrase construction algorithm and a greedy selection method for this mining task we examine the classification performance of the motion atom and phrase based representation on two complex action datasets olympic sport and ucf experimental result show that our method achieves superior performance over recent published method on both datasets 
capturing the essential characteristic of visual object by considering how their feature are inter related is a recent philosophy of object classification in this paper we embed this principle in a novel image descriptor dubbed heterogeneous auto similarity of characteristic hasc hasc is applied to heterogeneous dense feature map encoding linear relation by co variance and nonlinear association through information theoretic measure such a mutual information and entropy in this way highly complex structural information can be expressed in a compact scale invariant and robust manner the effectiveness of hasc is tested on many diverse detection and classification scenario considering object texture and pedestrian on widely known benchmark caltech brodatz daimler multi cue in all the case the result obtained with standard classifier demonstrate the superiority of hasc with respect to the most adopted local feature descriptor nowadays such a sift hog lbp and feature co variance in addition hasc set the state of the art on the brodatz texture dataset and the daimler multi cue pedestrian dataset without exploiting ad hoc sophisticated classifier 
it is often desirable to detect whether a surface ha been touched even when the change made to that surface are too subtle to see in a pair of before and after image to address this challenge we introduce a new imaging technique that combine computational photography and laser speckle imaging without requiring controlled laboratory condition our method is able to detect surface change that would be indistinguishable in regular photograph it is also mobile and doe not need to be present at the time of contact with the surface making it well suited for application where the surface of interest cannot be constantly monitored our approach take advantage of the fact that tiny surface deformation cause phase change in reflected coherent light which alter the speckle pattern visible under laser illumination we take before and after image of the surface under laser light and can detect subtle contact by correlating the speckle pattern in these image a key challenge we address is that speckle imaging is very sensitive to the location of the camera so removing and reintroducing the camera requires high accuracy viewpoint alignment to this end we use a combination of computational rephotog raphy and correlation analysis of the speckle pattern a a function of camera translation our technique provides a reliable way of detecting subtle surface contact at a level that wa previously only possible under laboratory condition with our system the detection of these subtle surface change can now be brought into the wild 
in this paper we deal with the problem of detecting the existence and the location of salient object for thumbnail image on which most search engine usually perform visual analysis in order to handle web scale image different from previous technique such a sliding window based or segmentation based scheme for detecting salient object we propose to use a learning approach random forest in our solution our algorithm exploit global feature from multiple saliency indicator to directly predict the existence and the position of the salient object to validate our algorithm we constructed a large image database collected from bing image search that contains hundred of thousand of manually labeled web image the experimental result using this new database and the resized msra database demonstrate that our algorithm outperforms previous state of the art method 
indoor functional object exhibit large view and appearance variation thus are difficult to be recognized by the traditional appearance based classification paradigm in this paper we present an algorithm to parse indoor image based on two observation i the functionality is the most essential property to define an indoor object e g a chair to sit on ii the geometry d shape of an object is designed to serve it function we formulate the nature of the object function into a stochastic grammar model this model characterizes a joint distribution over the function geometry appearance fga hierarchy the hierarchical structure includes a scene category functional group functional object functional part and d geometric shape we use a simulated annealing mcmc algorithm to find the maximum a posteriori map solution i e a parse tree we design four data driven step to accelerate the search in the fga space i group the line segment into d primitive shape ii assign functional label to these d primitive shape iii fill in missing object part according to the functional label and iv synthesize d segmentation map and verify the current parse tree by the metropolis hastings acceptance probability the experimental result on several challenging indoor datasets demonstrate the proposed approach not only significantly widens the scope of indoor scene parsing algorithm from the segmentation and the d recovery to the functional object recognition but also yield improved overall performance 
scale invariant feature detector often find stable scale in only a few image pixel consequently method for feature matching typically choose one of two extreme option matching a sparse set of scale invariant feature or dense matching using arbitrary scale in this paper we turn our attention to the overwhelming majority of pixel those where stable scale are not found by standard technique we ask is scale selection necessary for these pixel when dense scale invariant matching is required and if so how can it be achieved we make the following contribution i we show that feature computed over different scale even in low contrast area can be different selecting a single scale arbitrarily or otherwise may lead to poor match when the image have different scale ii we show that representing each pixel a a set of sifts extracted at multiple scale allows for far better match than single scale descriptor but at a computational price finally iii we demonstrate that each such set may be accurately represented by a low dimensional linear subspace a subspace to point mapping may further be used to produce a novel descriptor representation the scale le sift sl a an alternative to single scale descriptor these claim are verified by quantitative and qualitative test demonstrating significant improvement over existing method 
this paper proposes emph motion let a mid level and spatiotemporal part for human motion recognition motion let can be seen a a tight cluster in motion and appearance space corresponding to the moving process of different body part we postulate three key property of motion let for action recognition high motion saliency multiple scale representation and representative discriminative ability towards this goal we develop a data driven approach to learn motion let from training video first we extract d region with high motion saliency then we cluster these region and preserve the center a candidate template for motion let finally we examine the representative and discriminative power of the candidate and introduce a greedy method to select effective candidate with motion let we present a mid level representation for video called emph motion let activation vector we conduct experiment on three datasets kth hmdb and ucf the result show that the proposed method significantly outperform state of the art method 
most sky model only describe the cloudiness of the overall sky by a single category or parameter such a sky index which doe not account for the distribution of the cloud across the sky to capture variable cloudiness we extend the concept of sky index to a random field indicating the level of cloudiness of each sky pixel in our proposed sky representation based on the igawa sky model we formulate the problem of solving the sky index of every sky pixel a a labeling problem where an approximate solution can be efficiently found experimental result show that our proposed sky model ha better expressiveness stability with respect to variation in camera parameter and geo location estimation in outdoor image compared to the uniform sky index model potential application of our proposed sky model include sky image rendering where sky image can be generated with an arbitrary cloud distribution at any time and any location previously impossible with traditional sky model 
conventional subspace construction approach suffer from the need of large enough image ensemble rendering numerical method intractable in this paper we propose an analytic formulation for low dimensional subspace construction in which shading cue lie while preserving the natural structure of an image sample using the frequency space representation of the image irradiance equation the process of finding such subspace is cast a establishing a relation between it principal component and that of a deterministic set of basis function termed a irradiance harmonic representing image a matrix further lessen the number of parameter to be estimated to define a bilinear projection which map the image sample to a lower dimensional bilinear subspace result show significant impact on dimensionality reduction with minimal loss of information a well a robustness against noise 
in this paper we tackle the problem of indoor scene understanding using rgbd data towards this goal we propose a holistic approach that exploit d segmentation d geometry a well a contextual relation between scene and object specifically we extend the cpmc framework to d in order to generate candidate cuboid and develop a conditional random field to integrate information from different source to classify the cuboid with this formulation scene classification and d object recognition are coupled and can be jointly solved through probabilistic inference we test the effectiveness of our approach on the challenging nyu v dataset the experimental result demonstrate that through effective evidence integration and holistic reasoning our approach achieves substantial improvement over the state of the art 
in this paper we propose a weakly supervised method for simultaneously learning scene part and attribute from a collection of image associated with attribute in text where the precise localization of the each attribute left unknown our method includes three aspect i compositional scene configuration we learn the spatial layout of the scene by hierarchical space tiling hst representation which can generate an excessive number of scene configuration through the hierarchical composition of a relatively small number of part ii attribute association the scene attribute contain noun and adjective corresponding to the object and their appearance description respectively we assign the noun to the node part in hst using nonmaximum suppression of their correlation then train an appearance model for each noun adjective attribute pair iii joint inference and learning for an image we compute the most probable parse tree with the attribute a an instantiation of the hst by dynamic programming then update the hst and attribute association based on the inferred parse tree we evaluate the proposed method by i showing the improvement of attribute recognition accuracy and ii comparing the average precision of localizing attribute to the scene part 
object tracking is one of the most important component in numerous application of computer vision while much progress ha been made in recent year with effort on sharing code and datasets it is of great importance to develop a library and benchmark to gauge the state of the art after briefly reviewing recent advance of online object tracking we carry out large scale experiment with various evaluation criterion to understand how these algorithm perform the test image sequence are annotated with different attribute for performance evaluation and analysis by analyzing quantitative result we identify effective approach for robust tracking and provide potential future research direction in this field 
from conventional wisdom and empirical study of annotated data it ha been shown that visual statistic such a object frequency and segment size follow power law distribution previous work ha shown that both kind of power law behavior can be captured by using a hierarchical pitman yor process prior within a nonparametric bayesian approach to scene segmentation in this paper we add label information into the previously unsupervised model our approach exploit the labelled data by adding constraint on the parameter space during the variational learning phase we evaluate our formulation on the labelme natural scene dataset and show the effectiveness of our approach 
in this work we present a new crowd analysis algorithm powered by behavior prior that are learned on a large database of crowd video gathered from the internet the algorithm work by first learning a set of crowd behavior prior off line during testing crowd patch are matched to the database and behavior prior are transferred we adhere to the insight that despite the fact that the entire space of possible crowd behavior is infinite the space of distinguishable crowd motion pattern may not be all that large for many individual in a crowd we are able to find analogous crowd patch in our database which contain similar pattern of behavior that can effectively act a prior to constrain the difficult task of tracking an individual in a crowd our algorithm is data driven and unlike some crowd characterization method doe not require u to have seen the test video beforehand it performs like state of the art method for tracking people having common crowd behavior and outperforms the method when the tracked individual behaves in an unusual way 
in several hand object s interaction scenario the change in the object state is a direct consequence of the hand s motion this ha a straightforward representation in newtonian dynamic we present the first approach that exploit this observation to perform model based d tracking of a table top scene comprising passive object and an active hand our forward modelling of d hand object s interaction regard both the appearance and the physical state of the scene and is parameterized over the hand motion dofs between two successive instant in time we demonstrate that our approach manages to track the d pose of all object and the d pose and articulation of the hand by only searching for the parameter of the hand motion in the proposed framework covert scene state is inferred by connecting it to the overt state through the incorporation of physic thus our tracking approach treat a variety of challenging observability issue in a principled manner without the need to resort to heuristic 
feature matching is at the base of many computer vision problem such a object recognition or structure from motion current method rely on costly descriptor for detection and matching in this paper we propose a very fast binary descriptor based on brief called orb which is rotation invariant and resistant to noise we demonstrate through experiment how orb is at two order of magnitude faster than sift while performing a well in many situation the efficiency is tested on several real world application including object detection and patch tracking on a smart phone 
we propose an approach to improving the detection result of a generic offline trained detector on a specific video our method doe not leverage visual tracking a most detection by tracking method do instead the proposed detection by detection approach can serve a a more confident initialization for detection by tracking method different from other supervised detector adaptation method we constrain the task to video and no supervised label for the target video are required for the adaptation we intend to fill the gap between detection by tracking and pure detection by frame a a non parametric detector adaptation method confident detection are collected to re rank and to group other detection we focus on method with high precision detection result since it is necessitated in real application extensive experiment with two state of the art detector demonstrate the efficacy of our approach 
we propose an efficient algorithm to find the exact nearest neighbor based on the euclidean distance for large scale computer vision problem we embed data point nonlinearly onto a low dimensional space by simple computation and prove that the distance between two point in the embedded space is bounded by the distance in the original space instead of computing the distance in the high dimensional original space to find the nearest neighbor a lot of candidate are to be rejected based on the distance in the low dimensional embedded space due to this property our algorithm is well suited for high dimensional and large scale problem we also show that our algorithm is improved further by partitioning input vector recursively contrary to most of existing fast nearest neighbor search algorithm our technique report the exact nearest neighbor not an approximate one and requires a very simple preprocessing with no sophisticated data structure we provide the theoretical analysis of our algorithm and evaluate it performance in synthetic and real data 
recently study on sketch such a sketch retrieval and sketch classification have received more attention in the computer vision community one of it most fundamental and essential problem is how to more effectively describe a sketch image many existing descriptor such a shape context have achieved great success in this paper we propose a new descriptor namely symmetric aware flip invariant sketch histogram sym fish to refine the shape context feature it extraction process includes three step first the flip invariant sketch histogram fish descriptor is extracted on the input image which is a flip invariant version of the shape context feature then we explore the symmetry character of the image by calculating the kurtosis coefficient finally the sym fish is generated by constructing a symmetry table the new sym fish descriptor supplement the original shape context by encoding the symmetric information which is a pervasive characteristic of natural scene and object we evaluate the efficacy of the novel descriptor in two application i e sketch retrieval and sketch classification extensive experiment on three datasets well demonstrate the effectiveness and robustness of the proposed sym fish descriptor 
action recognition in uncontrolled video is an important and challenging computer vision problem recent progress in this area is due to new local feature and model that capture spatio temporal structure between local feature or human object interaction instead of working towards more complex model we focus on the low level feature and their encoding we evaluate the use of fisher vector a an alternative to bag of word histogram to aggregate a small set of state of the art low level descriptor in combination with linear classifier we present a large and varied set of evaluation considering i classification of short action in five datasets ii localization of such action in feature length movie and iii large scale recognition of complex event we find that for basic action recognition and localization mbh feature alone are enough for state of the art performance for complex event we find that sift and mfcc feature provide complementary cue on all three problem we obtain state of the art result while using fewer feature and le complex model 
video usually consist of activity involving interaction between multiple actor sometimes referred to a complex activity recognition of such activity requires modeling the spatio temporal relationship between the actor and their individual variability in this paper we consider the problem of recognition of complex activity in a video given a query example we propose a new feature model based on a string representation of the video which respect the spatio temporal ordering this ordered arrangement of local collection of feature e g cuboid stip which are the character in the string are initially matched using graph based spectral technique final recognition is obtained by matching the string representation of the query and the test video in a dynamic programming framework which allows for variability in sampling rate and speed of activity execution the method doe not require tracking or recognition of body part is able to identify the region of interest in a cluttered scene and give reasonable performance with even a single query example we test our approach in an example based video retrieval framework with two publicly available complex activity datasets and provide comparison against other method that have studied this problem 
we propose to detect abnormal event via a sparse reconstruction over the normal base given an over complete normal basis set e g an image sequence or a collection of local spatio temporal patch we introduce the sparse reconstruction cost src over the normal dictionary to measure the normalness of the testing sample to condense the size of the dictionary a novel dictionary selection method is designed with sparsity consistency constraint by introducing the prior weight of each basis during sparse reconstruction the proposed src is more robust compared to other outlier detection criterion our method provides a unified solution to detect both local abnormal event lae and global abnormal event gae we further extend it to support online abnormal event detection by updating the dictionary incrementally experiment on three benchmark datasets and the comparison to the state of the art method validate the advantage of our algorithm 
binary descriptor of image patch are increasingly popular given that they require le storage and enable faster processing this however come at a price of lower recognition performance to boost these performance we project the image patch to a more discriminative subspace and threshold their coordinate to build our binary descriptor however applying complex projection to the patch is slow which negates some of the advantage of binary descriptor hence our key idea is to learn the discriminative projection so that they can be decomposed into a small number of simple filter for which the response can be computed fast we show that with a few a bit per descriptor we outperform the state of the art binary descriptor in term of both accuracy and efficiency 
this paper address the problem of tracking object which undergo rapid and significant appearance change we propose a novel coupled layer visual model that combine the target s global and local appearance the local layer in this model is a set of local patch that geometrically constrain the change in the target s appearance this layer probabilistically adapts to the target s geometric deformation while it structure is updated by removing and adding the local patch the addition of the patch is constrained by the global layer that probabilistically model target s global visual property such a color shape and apparent local motion the global visual property are updated during tracking using the stable patch from the local layer by this coupled constraint paradigm between the adaptation of the global and the local layer we achieve a more robust tracking through significant appearance change indeed the experimental result on challenging sequence confirm that our tracker outperforms the related state of the art tracker by having smaller failure rate a well a better accuracy 
in this paper we developed a novel tool called dynamic fractal analysis for dynamic texture dt classification which not only provides a rich description of dt but also ha strong robustness to environmental change the resulting dynamic fractal spectrum dfs for dt sequence consists of two component one is the volumetric dynamic fractal spectrum component v dfs that capture the stochastic self similarity of dt sequence a d volume datasets the other is the multi slice dynamic fractal spectrum component s dfs that encodes fractal structure of dt sequence on d slice along different view of the d volume various type of measure of dt sequence are collected in our approach to analyze dt sequence from different perspective the experimental evaluation is conducted on three widely used benchmark datasets in all the experiment our method demonstrated excellent performance in comparison with state of the art approach 
we study a problem called digital facial anti aging which aim at making human face look younger in digital photo this novel problem is different from the traditional age synthesis where new face are synthesized at older age using other example face image in contrast our facial anti aging work on a single digital photo without using any other face the proposed system contains several module first an input color face image is decomposed into three layer face structure aging detail and color second the specular highlight in the original face image is recovered third the face structure color and the recovered specular highlight are combined to form an anti aging face image further the system can deal with hair coloring and eyebrow change if needed since these factor influence human judge of age our approach keep facial identity and delivers high quality output we show that the anti aging system can be built based on adapting and integrating the state of the art method that were originally proposed to solve other problem the anti aging face are evaluated by human to demonstrate the performance 
given an area of interest in a video sequence one may want to manipulate or edit the area e g remove occlusion from or replace with an advertisement on it such a task involves three main challenge including temporal consistency spatial pose and visual realism the proposed method effectively seek an optimal solution to simultaneously deal with temporal alignment pose rectification a well a precise recovery of the occlusion to make our method applicable to long video sequence we propose a batch alignment method for automatically aligning and rectifying a small number of initial frame and then show how to align the remaining frame incrementally to the aligned base image from the error residual of the robust alignment process we automatically construct a trimap of the region for each frame which is used a the input to alpha matting method to extract the occluding foreground experimental result on both simulated and real data demonstrate the accurate and robust performance of our method 
in this paper a notion of flow complexity that measure the amount of interaction among object is introduced and an approach to compute it directly from a video sequence is proposed the approach employ particle trajectory a the input representation of motion and map it into a braid based representation the mapping is based on the observation that d trajectory of particle take the form of a braid in space time due to the intermingling among particle over time a a result of this mapping the problem of estimating the flow complexity from particle trajectory becomes the problem of estimating braid complexity which in turn can be computed by measuring the topological entropy of a braid for this purpose recently developed mathematical tool from braid theory are employed which allow rapid computation of topological entropy of braid the approach is evaluated on a dataset consisting of open source video depicting variation in term of type of moving object scene layout camera view angle motion pattern and object density the result show that the proposed approach is able to quantify the complexity of the flow and at the same time provides useful insight about the source of the complexity 
when a translucent liquid is spilled over a rough surface it cause a significant change in the visual appearance of the surface this wetting phenomenon is easily detected by human and an early model wa devised by the physicist andres jonas angstrom nearly a century ago in this paper we investigate the problem of determining if a wet dry relationship between two image patch explains the difference in their visual appearance water tends to be the typical liquid involved and therefore it is the main objective at the same time we consider the general problem where the liquid ha some of the characteristic of water i e a similar refractive index but ha an unknown spectral absorption profile e g coffee tea wine etc we report on several experiment using our own image a publicly available dataset and image downloaded from the web 
a novel approach for event summarization and rare event detection is proposed unlike conventional method that deal with event summarization and rare event detection independently we solve them together by transforming the problem into a graph editing framework in our approach a video is represented a a graph in which each node of the graph indicates an event obtained by segmenting the video spatially and temporally while edge between node describe the event related to each other based on the degree of relation edge have different weight after learning the graph structure our method edits the graph by merging it subgraphs or pruning it edge the graph is edited toward minimizing a predefined energy model with the data driven markov chain monte carlo method the energy model consists of several parameter that represent causality frequency and significance of event we design a specific energy model utilizing these parameter to satisfy each objective of event summarization and rare event detection experimental result show that the proposed approach accurately summarizes a video in a fully unsupervised manner moreover the experiment also demonstrate that the approach is advantageous in detecting the rare transition of event 
we propose a fast pattern matching scheme termed matching by tone mapping mtm which allows matching under non linear tone mapping we show that when tone mapping is approximated by a piecewise constant function a fast computational scheme is possible requiring computational time similar to the fast implementation of normalized cross correlation ncc in fact the mtm measure can be viewed a a generalization of the ncc for non linear mapping and actually reduces to ncc when mapping are restricted to be linear the mtm is shown to be invariant to non linear tone mapping and is empirically shown to be highly discriminative and robust to noise 
in this paper we propose a method for the localization of multiple facial feature on challenging face image in the regression forest rf framework observation patch that are extracted at several image location cast vote for the localization of several facial feature in order to filter out vote that are not relevant we pas them through two type of sieve that are organised in a cascade and which enforce geometric constraint the first sieve filter out vote that are not consistent with a hypothesis for the location of the face center several sieve of the second type one associated with each individual facial point filter out distant vote we propose a method that adjusts on the fly the proximity threshold of each second type sieve by applying a classifier which based on middle level feature extracted from voting map for the facial feature in question make a sequence of decision on whether the threshold should be reduced or not we validate our proposed method on two challenging datasets with image collected from the internet in which we obtain state of the art result without resorting to explicit facial shape model we also show the benefit of our method for proximity threshold adjustment especially on difficult face image 
optical flow computation is a key component in many computer vision system designed for task such a action detection or activity recognition however despite several major advance over the last decade handling large displacement in optical flow remains an open problem inspired by the large displacement optical flow of brox and malik our approach termed deep flow blend a matching algorithm with a variational approach for optical flow we propose a descriptor matching algorithm tailored to the optical flow problem that allows to boost performance on fast motion the matching algorithm build upon a multi stage architecture with layer interleaving convolution and max pooling a construction akin to deep convolutional net using dense sampling it allows to efficiently retrieve quasi dense correspondence and enjoys a built in smoothing effect on descriptor match a valuable asset for integration into an energy minimization framework for optical flow estimation deep flow efficiently handle large displacement occurring in realistic video and show competitive performance on optical flow benchmark furthermore it set a new state of the art on the mpi sintel dataset 
in this paper we present a model of action based on the change in the state of the environment many action involve similar dynamic and hand object relationship but differ in their purpose and meaning the key to differentiating these action is the ability to identify how they change the state of object and material in the environment we propose a weakly supervised method for learning the object and material state that are necessary for recognizing daily action once these state detector are learned we can apply them to input video and pool their output to detect action we further demonstrate that our method can be used to segment discrete action from a continuous video of an activity our result outperform state of the art action recognition and activity segmentation result 
we propose a multimodal decomposable model for articulated human pose estimation in monocular image a typical approach to this problem is to use a linear structured model which struggle to capture the wide range of appearance present in realistic unconstrained image in this paper we instead propose a model of human pose that explicitly capture a variety of pose mode unlike other multimodal model our approach includes both global and local pose cue and us a convex objective and joint training for mode selection and pose estimation we also employ a cascaded mode selection step which control the trade off between speed and accuracy yielding a x speedup in inference and learning our model outperforms state of the art approach across the accuracy speed trade off curve for several pose datasets this includes our newly collected dataset of people in movie flic which contains an order of magnitude more labeled data for training and testing than existing datasets 
we present a hierarchical classification model that allows rare object to borrow statistical strength from related object that have many training example unlike many of the existing object detection and recognition system that treat different class a unrelated entity our model learns both a hierarchy for sharing visual appearance across object category and hierarchical parameter our experimental result on the challenging object localization and detection task demonstrate that the proposed model substantially improves the accuracy of the standard single object detector that ignore hierarchical structure altogether 
geometric detail is a universal phenomenon in real world object it is an important component in object modeling but not accounted for in current intrinsic image work in this work we explore using a non parametric method to separate geometric detail from intrinsic image component we further decompose an image a albedo coarse scale shading shading detail our decomposition offer quantitative improvement in albedo recovery and material classification our method also enables interesting image editing activity including bump removal geometric detail smoothing enhancement and material transfer 
in this paper we show that tracking multiple people whose path may intersect can be formulated a a convex global optimization problem our proposed framework is designed to exploit image appearance cue to prevent identity switch our method is effective even when such cue are only available at distant time interval this is unlike many current approach that depend on appearance being exploitable from frame to frame we validate our approach on three multi camera sport and pedestrian datasets that contain long and complex sequence our algorithm perseveres identity better than state of the art algorithm while keeping similar mota score 
we present a technique for separating foreground object from the background in a video our method is fast fully automatic and make minimal assumption about the video this enables handling essentially unconstrained setting including rapidly moving background arbitrary object motion and appearance and non rigid deformation and articulation in experiment on two datasets containing over video shot our method outperforms a state of the art background subtraction technique a well a method based on clustering point track moreover it performs comparably to recent video object segmentation method based on object proposal while being order of magnitude faster 
we present an approach for the automatic reconstruction of neuron from d stack of electron microscopy section the core of our system is a set of possible assignment each of which proposes with some cost a link between neuron region in consecutive section these can model the continuation branching and end of neuron the cost are trainable on positive assignment sample an optimal and consistent set of assignment is found for the whole volume at once by solving an integer linear program this set of assignment determines both the segmentation into neuron region and the correspondence between such region in neighboring slice for each picked assignment a confidence value help to prioritize decision to be reviewed by a human expert we evaluate the performance of our method on an annotated volume of neural tissue and compare to the current state of the art our method is superior in accuracy and can be trained using a small number of sample the observed inference time are linear with about millisecond per neuron and section 
for two consecutive frame in a video we identify which pixel in the first frame become occluded in the second such general purpose detection of occlusion region is difficult and important because one to one correspondence of imaged scene point is needed for many tracking video segmentation and reconstruction algorithm our hypothesis is that an effective trained occlusion detector can be generated on the basis of i a broad spectrum of visual feature and ii representative but synthetic training sequence by using a random forest based framework for feature selection and training we found that the proposed feature set wa sufficient to frequently assign a high probability of occlusion to just the pixel that were indeed becoming occluded our extensive experiment on many sequence support this finding and while accuracy is certainly still scene dependent the proposed classifier could be a useful preprocessing step to exploit temporal information in video 
in this paper we propose an approach to accurately localize detected object the goal is to predict which feature pertain to the object and define the object extent with segmentation or bounding box our initial detector is a slight modification of the dpm detector by felzenszwalb et al which often reduces confusion with background and other object but doe not cover the full object we then describe and evaluate several color model and edge cue for local prediction and we propose two approach for localization learned graph cut segmentation and structural bounding box prediction our experiment on the pascal voc dataset show that our approach lead to accurate pixel assignment and large improvement in bounding box overlap sometimes leading to large overall improvement in detection accuracy 
statistical shape analysis develops method for comparison deformation summarization and modeling of shape in given data set these task require a fundamental tool called parallel transport of tangent vector along arbitrary path this tool is essential for computation of geodesic path using either shooting or path straightening method transferring deformation across object and modeling of statistical variability in shape using the square root normal field srnf representation of parameterized surface we present a method for transporting deformation along path in the shape space this is difficult despite the underlying space being a vector space because the chosen elastic riemannian metric is non standard using a finite basis for representing srnfs of shape we derive expression for christoffel symbol that enable parallel transport we demonstrate this framework using example from shape analysis of parameterized spherical surface in the three context mentioned above 
compared to visual concept such a action scene and object complex event is a higher level abstraction of longer video sequence for example a marriage proposal event is described by multiple object e g ring face scene e g in a restaurant outdoor and action e g kneeling down the positive exemplar which exactly convey the precise semantic of an event are hard to obtain it would be beneficial to utilize the related exemplar for complex event detection however the semantic correlation between related exemplar and the target event vary substantially a relatedness assessment is subjective two related exemplar can be about completely different event e g in the trecvid med dataset both bicycle riding and equestrianism are labeled a related to attempting a bike trick event to tackle the subjectiveness of human assessment our algorithm automatically evaluates how positive the related exemplar are for the detection of an event and us them on an exemplar specific basis experiment demonstrate that our algorithm is able to utilize related exemplar adaptively and the algorithm gain good performance for complex event detection 
we analyse the potential of gibbs random field for shape prior modelling we show that the expressive power of second order grfs is already sufficient to express spatial relation between shape part and simple shape simultaneously this allows to model and recognise complex shape a spatial composition of simpler part 
this paper proposes a novel approach to optimally solve volumetric registration problem the proposed framework exploit parametric dictionary for sparse volumetric representation ell dissimilarity and dc difference of convex function decomposition the sad sum of absolute difference criterion is applied to the sparse representation of the reference volume and a dc decomposition of this criterion with respect to the transformation parameter is derived this permit to employ a cutting plane algorithm for determining the optimal relative transformation parameter of the query volume it further provides a guarantee for the global optimality of the obtained solution which to the best of our knowledge is not offered by any other existing approach a numerical validation demonstrates the effectiveness and the large potential of the proposed method 
this paper address the problem of reconstructing a deforming surface from point observation in a monocular video sequence recent state of the art approach divide the surface into smaller patch to simplify the problem among these one very promising approach reconstructs the patch individually using a quadratic deformation model in this paper we demonstrate limitation that affect it applicability to real world data and propose an approach that overcomes these problem in particular we show how to eliminate the need for manually picking a template that is used to model the deformation we evaluate our algorithm on both synthetic and real world data set and show that it systematically reduces the reconstruction error by a factor of up to ten 
in this paper we present a new idea to analyze facial expression by exploring some common and specific information among different expression inspired by the observation that only a few facial part are active in expression disclosure e g around mouth eye we try to discover the common and specific patch which are important to discriminate all the expression and only a particular expression respectively a two stage multi task sparse learning mtsl framework is proposed to efficiently locate those discriminative patch in the first stage mtsl expression recognition task each of which aim to find dominant patch for each expression are combined to located common patch second two related task facial expression recognition and face verification task are coupled to learn specific facial patch for individual expression extensive experiment validate the existence and significance of common and specific patch utilizing these learned patch we achieve superior performance on expression recognition compared to the state of the art 
repeated feature are common in urban scene many object such a clock tower with nearly identical side or dome with strong radial symmetry pose challenge for structure from motion when similar but distinct feature are mistakenly equated the resulting d reconstruction can have error ranging from phantom wall and superimposed structure to a complete failure to reconstruct we present a new approach to solving such problem by considering the local visibility structure of such repeated feature drawing upon network theory we present a new way of scoring feature using a measure of local clustering our model lead to a simple fast and highly scalable technique for disambiguating repeated feature based on an analysis of an underlying visibility graph without relying on explicit geometric reasoning we demonstrate our method on several very large datasets drawn from internet photo collection and compare it to a more traditional geometry based disambiguation technique 
in this paper we propose a generative tracking method based on a novel robust linear regression algorithm in contrast to existing method the proposed least soft thresold square l algorithm model the error term with the gaussian laplacian distribution which can be solved efficiently based on maximum joint likelihood of parameter we derive a l distance to measure the difference between an observation sample and the dictionary compared with the distance derived from ordinary least square method the proposed metric is more effective in dealing with outlier in addition we present an update scheme to capture the appearance change of the tracked target and ensure that the model is properly updated experimental result on several challenging image sequence demonstrate that the proposed tracker achieves more favorable performance than the state of the art method 
fully automatic face recognition across pose frap is one of the most desirable technique however also one of the most challenging task in face recognition field matching a pair of face image in different pose can be converted into matching their pixel corresponding to the same semantic facial point following this idea given two image g and p in different pose we propose a novel method named morphable displacement field mdf to match g with p s virtual view under g s pose by formulating mdf a a convex combination of a number of template displacement field generated from a d face database our model satisfies both global conformity and local consistency we further present an approximate but effective solution of the proposed mdf model named implicit morphable displacement field imdf which synthesizes virtual view implicitly via an mdf by minimizing matching residual this formulation not only avoids intractable optimization of the high dimensional displacement field but also facilitates a constrained quadratic optimization the proposed method can work well even when only facial landmark are labeled which make it especially suitable for fully automatic frap system extensive evaluation on feret pie and multi pie database show considerable improvement over state of the art frap algorithm in both semi automatic and fully automatic evaluation protocol 
we propose a novel algorithm called latent space sparse subspace clustering for simultaneous dimensionality reduction and clustering of data lying in a union of subspace specifically we describe a method that learns the projection of data and find the sparse coefficient in the low dimensional latent space cluster label are then assigned by applying spectral clustering to a similarity matrix built from these sparse coefficient an efficient optimization method is proposed and it non linear extension based on the kernel method are presented one of the main advantage of our method is that it is computationally efficient a the sparse coefficient are found in the low dimensional latent space various experiment show that the proposed method performs better than the competitive state of the art subspace clustering method 
stereopsis provides an additional depth cue and play an important role in the human vision system this paper explores stereopsis for saliency analysis and present two approach to stereo saliency detection from stereoscopic image the first approach computes stereo saliency based on the global disparity contrast in the input image the second approach leverage domain knowledge in stereoscopic photography a good stereoscopic image take care of it disparity distribution to avoid d fatigue particularly salient content tends to be positioned in the stereoscopic comfort zone to alleviate the vergence accommodation conflict accordingly our method computes stereo saliency of an image region based on the distance between it perceived location and the comfort zone moreover we consider object popping out from the screen salient a these object tend to catch a viewer s attention we build a stereo saliency analysis benchmark dataset that contains stereoscopic image with salient object mask our experiment on this dataset show that stereo saliency provides a useful complement to existing visual saliency analysis and our method can successfully detect salient content from image that are difficult for monocular saliency analysis method 
representing articulated object a a graphical model ha gained much popularity in recent year often the root node of the graph describes the global position and orientation of the object in this work a method is presented to robustly track d human pose by permitting greater uncertainty to be modeled over the root node than existing technique allow significantly this is achieved without increasing the uncertainty of remaining part of the model the benefit is that a greater volume of the posterior can be supported making the approach le vulnerable to tracking failure given a hypothesis of the root node state a novel method is presented to estimate the posterior over the remaining part of the body conditioned on this value all probability distribution are approximated using a single gaussian allowing inference to be carried out in closed form a set of deterministically selected sample point are used that allow the posterior to be updated for each part requiring just seven image likelihood evaluation making it extremely efficient multiple root node state are supported and propagated using standard sampling technique we believe this to be the first work devoted to efficient tracking of human pose whilst modeling large uncertainty in the root node and demonstrate the presented method to be more robust to tracking failure than existing approach 
the human body is structurally symmetric tracking by detection approach for human pose suffer from emph double counting where the same image evidence is used to explain two separate but symmetric part such a the left and right foot double counting if left unaddressed can critically affect subsequent process such a action recognition affordance estimation and pose reconstruction in this work we present an occlusion aware algorithm for tracking human pose in an image sequence that address the problem of double counting our key insight is that tracking human pose can be cast a a multi target tracking problem where the target are related by an underlying articulated structure the human body is modeled a a combination of singleton part such a the head and neck and symmetric pair of part such a the shoulder knee and foot symmetric body part are jointly tracked with mutual exclusion constraint to prevent double counting by reasoning about occlusion we evaluate our algorithm on an outdoor dataset with natural background clutter a standard indoor dataset emph human eva i and compare against a state of the art pose estimation algorithm 
the motion field of a scene can be used for object segmentation and to provide feature for classification task like action recognition scene flow is the full d motion field of the scene and is more difficult to estimate than it s d counterpart optical flow current approach use a smoothness cost for regularisation which tends to over smooth at object boundary this paper present a novel formulation for scene flow estimation a collection of moving point in d space modelled using a particle filter that support multiple hypothesis and doe not oversmooth the motion field in addition this paper is the first to address scene flow estimation while making use of modern depth sensor and monocular appearance image rather than traditional multi viewpoint rig the algorithm is applied to an existing scene flow dataset where it achieves comparable result to approach utilising multiple view while taking a fraction of the time 
we propose an approach to learn action category from static image that leverage prior observation of generic human motion to augment it training process using unlabeled video containing various human activity the system first learns how body pose tends to change locally in time then given a small number of labeled static image it us that model to extrapolate beyond the given exemplar and generate synthetic training example pose that could link the observed image and or immediately precede or follow them in time in this way we expand the training set without requiring additional manually labeled example we explore both example based and manifold based method to implement our idea applying our approach to recognize action in both image and video we show it enhances a state of the art technique when very few labeled training example are available 
computing distance between large set of sift descriptor is a basic step in numerous algorithm in computer vision when the number of descriptor is large a is often the case computing these distance can be extremely time consuming in this paper we propose the sift pack a compact way of storing sift descriptor which enables significantly faster calculation between set of sifts than the current solution sift pack can be used to represent sifts densely extracted from a single image or sparsely from multiple different image we show that the sift pack representation save both storage space and run time for both finding nearest neighbor and for computing all distance between all descriptor the usefulness of sift pack is also demonstrated a an alternative implementation for k mean dictionary of visual word 
pictorial structure p define a probabilistic model of d articulated object in image typical p model assume an object can be represented by a set of rigid part connected with pairwise constraint that define the prior probability of part configuration these model are widely used to represent non rigid articulated object such a human and animal despite the fact that such object have part that deform non rigidly here we define a new deformable structure d model that is a natural extension of previous p model and that capture the non rigid shape deformation of the part each part in a d model is represented by a low dimensional shape deformation space and pairwise potential between part capture how the shape varies with pose and the shape of neighboring part a key advantage of such a model is that it more accurately model object boundary this enables image likelihood model that are more discriminative than previous p likelihood this likelihood is learned using training imagery annotated using a d puppet we focus on a human d model learned from d projection of a realistic d human body model and use it to infer human pose in image using a form of non parametric belief propagation 
in this paper we propose an efficient algorithm for computing the euclidean distance transform of two dimensional binary image called pbedt perpendicular bisector euclidean distance transform pbedt is a two stage independent scan algorithm in the first stage pbedt computes the distance from each point to it closest feature point in the same column using one time column wise scan in the second stage pbedt computes the distance transform for each point by row with intermediate result of the previous stage by using the geometric property of the perpendicular bisector pbedt directly computes the segmentation by feature point for each row and each segment corresponding to one feature point furthermore by using integer arithmetic to avoid time consuming float operation pbedt still achieves exact result all these method reduce the computational complexity significantly consequently an efficient and exact linear time euclidean distance transform algorithm is implemented detailed comparison with state of the art linear time euclidean distance transform algorithm show that pbedt is the fastest on most case and also the most stable one with respect to image content 
over the last decade fiducial marker have provided widely adopted tool to add reliable model based feature into an otherwise general scene given their central role in many computer vision task countless different solution have been proposed in the literature some design are focused on the accuracy of the recovered camera pose with respect to the tag some other concentrate on reaching high detection speed or on recognizing a large number of distinct marker in the scene in such a crowded area both the researcher and the practitioner are licensed to wonder if there is any need to introduce yet another approach nevertheless with this paper we would like to present a general purpose fiducial marker system that can be deemed to add some valuable feature to the pack specifically by exploiting the projective property of a circular set of sizeable dot we propose a detection algorithm that is highly accurate further applying a dot pattern scheme derived from error correcting code allows for robustness with respect to very large occlusion in addition the design of the marker itself is flexible enough to accommodate different requirement in term of pose accuracy and number of pattern the overall performance of the marker system is evaluated in an extensive experimental section where a comparison with a well known baseline technique is presented 
efficient learning with non linear kernel is often based on extracting feature from the data that linearise the kernel while most construction aim at obtaining low dimensional and dense feature in this work we explore high dimensional and sparse one we give a method to compute sparse feature for arbitrary kernel re deriving a a special case a popular map for the intersection kernel and extending it to arbitrary additive kernel we show that bundle optimisation method can handle efficiently these sparse feature in learning a an application we show that product quantisation can be interpreted a a sparse feature encoding and use this to significantly accelerate learning with this technique we demonstrate these idea on image classification with fisher kernel and object detection with deformable part model on the challenging pascal voc data obtaining five to ten fold speed ups a well a reducing memory use by an order of magnitude 
previous metric learning approach learn a unified metric for all the class on single feature representation thus cannot be directly transplanted to application involving multiple feature hundred to thousand of hierarchical structured semantics and abundant social tagging in this paper we propose a novel multi task multi feature metric learning method which model the information sharing mechanism among different learning task we decompose the real world multi class problem such a semantic categorization or automatic tagging into a set of task where each task corresponds to several class with strong visual correlation we conduct metric learning to learn a set of hyper category specific metric for all the task by encouraging model sharing among task more generalization power is acquired another advantage is the capability of simultaneous learning with semantic information and social tagging based on the multi task learning framework and thus they both benefit from the information provided by each other experiment demonstrate the advantage on application including semantic categorization and automatic tagging compared with other popular metric learning approach 
the goal of high level event classification from video is to assign a single high level event label to each query video traditional approach represent each video a a set of low level feature and encode it into a fixed length feature vector e g bag of word which leave a big gap between low level visual feature and high level event our paper try to address this problem by exploiting activity concept transition in video event active a video is treated a a sequence of short clip all of which are observation corresponding to latent activity concept variable in a hidden markov model hmm we propose to apply fisher kernel technique so that the concept transition over time can be encoded into a compact and fixed length feature vector very efficiently our approach can utilize concept annotation from independent datasets and work well even with a very small number of training sample experiment on the challenging nist trecvid multimedia event detection med dataset show our approach performs favorably over the state of the art 
we tackle the detection of prominent object in image a a retrieval task given a global image descriptor we find the most similar image in an annotated dataset and transfer the object bounding box we refer to this approach a data driven detection ddd that is an alternative to sliding window previous work have used similar notion but with task independent similarity and representation i e they were not tailored to the end goal of localization this article proposes two contribution i a metric learning algorithm and ii a representation of image a object probability map that are both optimized for detection we show experimentally that these two contribution are crucial to ddd do not require costly additional operation and in some case yield comparable or better result than state of the art detector despite conceptual simplicity and increased speed a an application of prominent object detection we improve fine grained categorization by precropping image with the proposed approach 
unsupervised video segmentation is a challenging problem because it involves a large amount of data and image segment undergo noisy variation in color texture and motion with time however there are significant redundancy that can help disambiguate the effect of noise to exploit these redundancy and obtain the most spatio temporally consistent video segmentation we formulate the problem a a consistent labeling problem by exploiting higher order image structure a label stand for a specific moving segment each segment or region is treated a a random variable which is to be assigned a label region assigned the same label comprise a d space time segment or a region tube the label can also be automatically created or terminated at any frame in the video sequence to allow object entering or leaving the scene to formulate this problem we use the crf conditional random field model unlike conventional crf which ha only unary and binary potential we also use higher order potential to favor label consistency among disconnected spatial and temporal segment compared to region tracking based method the main advantage of the proposed algorithm are two fold the label consistency constraint are imposed on multiple region but in a soft manner and the labeling decision is postponed until the confidence in the labeling is high we compare our result with a recent state of the art video segmentation algorithm and show that our result are quantitatively and qualitatively better 
we propose a novel method for predicting whether an image taken from a given location will match an existing set of image this problem appears prominently in image based localization and augmented reality application where new image are matched to an existing set to determine location or add virtual information into a scene our process generates a spatial coverage map showing the confidence that image taken at specific location will match an existing image set a new way to measure distortion between image using affine model is introduced the distortion measure is combined with existing machine learning and structure from motion technique to create a matching confidence predictor the predictor is used to generate the spatial coverage map and also compute which image in the original set are redundant and can be removed result are presented showing the predictor is more accurate than previously published approach 
hyper spectral imaging is beneficial to many application but current method do not consider fluorescent effect which are present in everyday item ranging from paper to clothing to even our food furthermore everyday fluorescent item exhibit a mix of reflectance and fluorescence so proper separation of these component is necessary for analyzing them in this paper we demonstrate efficient separation and recovery of reflective and fluorescent emission spectrum through the use of high frequency illumination in the spectral domain with the obtained fluorescent emission spectrum from our high frequency illuminant we then present to our knowledge the first method for estimating the fluorescent absorption spectrum of a material given it emission spectrum conventional bispectral measurement of absorption and emission spectrum need to examine all combination of incident and observed light wavelength in contrast our method requires only two hyper spectral image the effectiveness of our proposed method are then evaluated through a combination of simulation and real experiment we also demonstrate an application of our method to synthetic relighting of real scene 
we present an algorithm for calibrated camera relative pose estimation from line given three line with two of the line parallel and orthogonal to the third we can compute the relative rotation between two image we can also compute the relative translation from two intersection point we also present a framework in which such line can be detected we evaluate the performance of the algorithm using synthetic and real data the intended use of the algorithm is with robust hypothesize and test framework such a ransac our approach is suitable for urban and indoor environment where most line are either parallel or orthogonal to each other 
we present a new point matching algorithm for robust nonrigid registration the method iteratively recovers the point correspondence and estimate the transformation between two point set in the first step of the iteration feature descriptor such a shape context are used to establish rough correspondence in the second step we estimate the transformation using a robust estimator called l e this is the main novelty of our approach and it enables u to deal with the noise and outlier which arise in the correspondence step the transformation is specified in a functional space more specifically a reproducing kernel hilbert space we apply our method to nonrigid sparse image feature correspondence on d image and d surface our result quantitatively show that our approach outperforms state of the art method particularly when there are a large number of outlier moreover our method of robustly estimating transformation from correspondence is general and ha many other application 
scene understanding from a monocular moving camera is a challenging problem with a number of application including robotics and automotive safety while recent system have shown that this is best accomplished with a d scene model handling of partial object occlusion is still unsatisfactory in this paper we propose an approach that tightly integrates monocular d scene tracking by detection with explicit object object occlusion reasoning full object and object part detector are combined in a mixture of expert based on their expected visibility which is obtained from the d scene model for the difficult case of multi people tracking we demonstrate that our approach yield more robust detection and tracking of partially visible pedestrian even when they are occluded over long period of time our approach is evaluated on two challenging sequence recorded from a moving camera in busy pedestrian zone and outperforms several state of the art approach 
camera shake is a common source of degradation in photograph restoring blurred picture is challenging because both the blur kernel and the sharp image are unknown which make this problem severely underconstrained in this work we estimate camera shake by analyzing edge in the image effectively constructing the radon transform of the kernel building upon this result we describe two algorithm for estimating spatially invariant blur kernel in the first method we directly invert the transform which is computationally efficient since it is not necessary to also estimate the latent sharp image this approach is well suited for scene with a diversity of edge such a man made environment in the second method we incorporate the radon transform within the map estimation framework to jointly estimate the kernel and the image while more expensive this algorithm performs well on a broader variety of scene even when fewer edge can be observed our experiment show that our algorithm achieve comparable result to the state of the art in general and produce superior output on man made scene and photo degraded by a small kernel 
we introduce a saliency model based on two key idea the first one is considering local and global image patch rarity a two complementary process the second one is based on our observation that for different image one of the rgb and lab color space outperforms the other in saliency detection we propose a framework that measure patch rarity in each color space and combine them in a final map for each color channel first the input image is partitioned into non overlapping patch and then each patch is represented by a vector of coefficient that linearly reconstruct it from a learned dictionary of patch from natural scene next two measure of saliency local and global are calculated and fused to indicate saliency of each patch local saliency is distinctiveness of a patch from it surrounding patch global saliency is the inverse of a patch s probability of happening over the entire image the final saliency map is built by normalizing and fusing local and global saliency map of all channel from both color system extensive evaluation over four benchmark eye tracking datasets show the significant advantage of our approach over state of the art saliency model 
we propose a novel approach to fine grained image classification in which instance from different class share common part but have wide variation in shape and appearance we use dog breed identification a a test case to show that extracting corresponding part improves classification performance this domain is especially challenging since the appearance of corresponding part can vary dramatically e g the face of bulldog and beagle are very different to find accurate correspondence we build exemplar based geometric and appearance model of dog breed and their face part part correspondence allows u to extract and compare descriptor in like image location our approach also feature a hierarchy of part e g face and eye and breed specific part localization we achieve recognition rate on a large real world dataset including dog breed and image and experimental result show that accurate part localization significantly increase classification performance compared to state of the art approach 
simple tree model for articulated object prevails in the last decade however it is also believed that these simple tree model are not capable of capturing large variation in many scenario such a human pose estimation this paper attempt to address three question are simple tree model sufficient more specifically how to use tree model effectively in human pose estimation and how shall we use combined part together with single part efficiently assuming we have a set of single part and combined part and the goal is to estimate a joint distribution of their location we surprisingly find that no latent variable are introduced in the leeds sport dataset lsp during learning latent tree for deformable model which aim at approximating the joint distribution of body part location using minimal tree structure this suggests one can straightforwardly use a mixed representation of single and combined part to approximate their joint distribution in a simple tree model a such one only need to build textit visual category of the combined part and then perform inference on the learned latent tree our method outperformed the state of the art on the lsp both in the scenario when the training image are from the same dataset and from the parse dataset experiment on animal image from the voc challenge further support our finding 
this paper present a new method for deblurring photo using a sharp reference example that contains some shared content with the blurry photo most previous deblurring method that exploit information from other photo require an accurately registered photo of the same static scene in contrast our method aim to exploit reference image where the shared content may have undergone substantial photometric and non rigid geometric transformation a these are the kind of reference image most likely to be found in personal photo album our approach build upon a recent method for example based deblurring using non rigid dense correspondence nrdc hacohen et al and extends it in two way first we suggest exploiting information from the reference image not only for blur kernel estimation but also a a powerful local prior for the non blind deconvolution step second we introduce a simple yet robust technique for spatially varying blur estimation rather than assuming spatially uniform blur unlike the above previous method which ha proven successful only with simple deblurring scenario we demonstrate that our method succeeds on a variety of real world example we provide quantitative and qualitative evaluation of our method and show that it outperforms the state of the art 
we introduce an extension of bag of word image representation to encode spatial layout using the fisher kernel framework we derive a representation that encodes the spatial mean and the variance of image region associated with visual word we extend this representation by using a gaussian mixture model to encode spatial layout and show that this model is related to a soft assign version of the spatial pyramid representation we also combine our representation of spatial layout with the use of fisher kernel to encode the appearance of local feature through an extensive experimental evaluation we show that our representation yield state of the art image categorization result while being more compact than spatial pyramid representation in particular using fisher kernel to encode both appearance and spatial layout result in an image representation that is computationally efficient compact and yield excellent performance while using linear classifier 
in this paper we present a novel technique that enables capturing of detailed d model from flash photograph integrating shading and silhouette cue our main contribution is an optimization framework which not only capture subtle surface detail but also handle change in topology to incorporate normal estimated from shading we employ a mesh based deformable model using deformation gradient this method is capable of manipulating precise geometry and in fact it outperforms previous method in term of both accuracy and efficiency to adapt the topology of the mesh we convert the mesh into an implicit surface representation and then back to a mesh representation this simple procedure remove self intersecting region of the mesh and solves the topology problem effectively in addition to the algorithm we introduce a hand held setup to achieve multi view photometric stereo the key idea is to acquire flash photograph from a wide range of position in order to obtain a sufficient lighting variation even with a standard flash unit attached to the camera experimental result showed that our method can capture detailed shape of various object and cope with topology change well 
face recognition is a challenging problem complicated by variation in pose expression lighting and the passage of time significant work ha been done to solve each of these problem separately we consider the problem of lighting and expression variation together proposing a method that account for both variability within a single model we present a novel deformation and lighting insensitive metric to compare image and we present a novel framework to optimize over this metric to calculate dense correspondence between image typical correspondence cost pattern are learned between face image pair and a naive bayes classifier is applied to improve recognition accuracy very promising result are presented on the ar face database and we note that our method can be extended to a broad set of application 
this paper present a robust algorithm for estimating a single latent sharp image given multiple blurry and or noisy observation the underlying multi image blind deconvolution problem is solved by linking all of the observation together via a bayesian inspired penalty function which couple the unknown latent image blur kernel and noise level together in a unique way this coupled penalty function enjoys a number of desirable property including a mechanism whereby the relative concavity or shape is adapted a a function of the intrinsic quality of each blurry observation in this way higher quality observation may automatically contribute more to the final estimate than heavily degraded one the resulting algorithm which requires no essential tuning parameter can recover a high quality image from a set of observation containing potentially both blurry and noisy example without knowing a priori the degradation type of each observation experimental result on both synthetic and real world test image clearly demonstrate the efficacy of the proposed method 
we propose an original particle filtering based approach combining optimization and decomposition technique for sequential non parametric density estimation defined in high dimensional state space our method relies on annealing to focus on the correct distribution and on probabilistic conditional independence defined by dynamic bayesian network to focus sample on their mode after proving it theoretical correctness and showing it complexity we highlight it ability to track single and multiple articulated object both on synthetic and real video sequence we show that our approach is particularly effective both in term of estimation error and computation time 
we present a method to detect the region of interest in moving camera view of dynamic scene with multiple moving object we start by extracting a global motion tendency that reflects the scene context by tracking movement of object in the scene we then use gaussian process regression to represent the extracted motion tendency a a stochastic vector field the generated stochastic field is robust to noise and can handle a video from an uncalibrated moving camera we use the stochastic field for predicting important future region of interest a the scene evolves dynamically we evaluate our approach on a variety of video of team sport and compare the detected region of interest to the camera motion generated by actual camera operator our experimental result demonstrate that our approach is computationally efficient and provides better prediction than previously proposed rbf based approach 
many tensor based algorithm have been proposed for the study of high dimensional data in a large variety of computer vision and machine learning application however most of the existing tensor analysis approach are based on frobenius norm which make them sensitive to outlier because they minimize the sum of squared error and enlarge the influence of both outlier and large feature noise in this paper we propose a robust tucker tensor decomposition model rtd to suppress the influence of outlier which us l norm loss function yet the optimization on l norm based tensor analysis is much harder than standard tensor decomposition in this paper we propose a simple and efficient algorithm to solve our rtd model moreover tensor factorization based image storage need much le space than pca based method we carry out extensive experiment to evaluate the proposed algorithm and verify the robustness against image occlusion both numerical and visual result show that our rtd model is consistently better against the existence of outlier than previous tensor and pca method 
we propose a novel method for weakly supervised semantic segmentation training image are labeled only by the class they contain not by their location in the image on test image instead the method predicts a class label for every pixel our main innovation is a multi image model mim a graphical model for recovering the pixel label of the training image the model connects superpixels from all training image in a data driven fashion based on their appearance similarity for generalizing to new test image we integrate them into mim using a learned multiple kernel metric instead of learning conventional classifier on the recovered pixel label we also introduce an objectness potential that help separating object e g car dog human from background class e g grass sky road in experiment on the msrc dataset and the labelme subset of our technique outperforms previous weakly supervised method and achieves accuracy comparable with fully supervised method 
we present a joint estimation technique of event localization and role assignment when the target video event is described by a scenario specifically to detect multi agent event from video our algorithm identifies agent involved in an event and assigns role to the participating agent instead of iterating through all possible agent role combination we formulate the joint optimization problem a two efficient sub problem quadratic programming for role assignment followed by linear programming for event localization additionally we reduce the computational complexity significantly by applying role specific event detector to each agent independently we test the performance of our algorithm in natural video which contain multiple target event and nonparticipating agent 
head pose estimation is a critical problem in many computer vision application these include human computer interaction video surveillance face and expression recognition in most prior work on head pose estimation the position of the face on which the pose is to be estimated are specified manually therefore the result are reported without studying the effect of misalignment we propose a method based on partial least square pls regression to estimate pose and solve the alignment problem simultaneously the contribution of this paper are two fold we show that the kernel version of pls kpls achieves better than state of the art result on the estimation problem and we develop a technique to reduce misalignment based on the learned pls factor 
this paper proposes a novel method that preserve the geometrical structure created by variation of multiple factor in analysis of multiple factor model i e multifactor analysis we use factor dependent submanifolds a constituent element of the factor dependent geometry in a multiple factor framework in this paper a submanifold is defined a some subset of a manifold in the data space and factor dependent submanifolds are defined a the submani fold created for each factor by varying only this factor in this paper we show that mpca is formulated using factor dependent submanifolds a is our proposed method we show however that mpca loses the original shape of these submanifolds because mpca s parameterization is based on averaging the shape of factor dependent subman ifolds for each factor on the other hand our proposed multifactor analysis preserve the shape of individual factor dependent submanifolds in low dimensional space because the parameter obtained by our method do not lose their structure our method unlike mpca sufficiently cover original factor dependent submanifolds a a result of sufficient coverage our method is appropriate for accurate classification of each sample 
many architectural scene contain symmetric or repeated structure which can generate erroneous image correspondence during structure from motion sfm computation prior work ha shown that the detection and removal of these incorrect match is crucial for accurate and robust recovery of scene structure in this paper we point out that these incorrect match in fact provide strong cue to the existence of symmetry and structural regularity in the unknown d structure we make two key contribution first we propose a method to recover various symmetry relation in the structure using geometric and appearance cue a set of structural constraint derived from the symmetry are imposed within a new constrained bundle adjustment formulation where symmetry prior are also incorporated second we show that the recovered symmetry enable u to choose a natural coordinate system for the d structure where gauge freedom in rotation is held fixed furthermore based on the symmetry d structure completion is also performed our approach significantly reduces drift through structural loop closure and improves the accuracy of reconstruction in urban scene 
we present a new generative image model integrating technique arising from two different domain manifold modeling and markov random field first we develop a probabilistic model with a mixture of hyperplanes to approximate the manifold of orientable image patch and demonstrate that it is more effective than the field of expert in expressing local texture pattern next we develop a construction that yield an mrf for coherent image generation given a configuration of local patch model and thereby establish a prior distribution over an mrf space taking advantage of the model structure we derive a variational inference algorithm and apply it to low level vision in contrast to previous method that rely on a single mrf the method infers an approximate posterior distribution of mrfs and recovers the underlying image by combining the prediction in a bayesian fashion experiment quantitatively demonstrate superior performance a compared to state of the art method on image denoising and inpainting 
image feature are widely used in computer vision application they need to be robust to scene change and image transformation designing and comparing feature descriptor requires the ability to evaluate their performance with respect to those transformation we want to know how robust the descriptor are to change in the lighting scene or viewing condition for this we need ground truth data of different scene viewed under different camera or lighting condition in a controlled way such data is very difficult to gather in a real world setting we propose using a photorealistic virtual world to gain complete and repeatable control of the environment in order to evaluate image feature we calibrate our virtual world evaluation by comparing against feature ranking made from photographic data of the same subject matter the statue of liberty we find very similar feature ranking between the two datasets we then use our virtual world to study the effect on descriptor performance of controlled change in viewpoint and illumination we also study the effect of augmenting the descriptor with depth information to improve performance 
symmetry especially repetitive structure in architecture are universally demonstrated across country and culture existing detection method mainly focus on the detection of planar pattern from a single image it is difficult to apply them to detect repetitive structure in architecture which abounds with non planar d repetitive element such a balcony and window and curved surface we study the repetitive structure detection problem from multiple image of such architecture our method jointly analyzes these image and a set of d point reconstructed from them by structure from motion algorithm d point help to rectify geometric deformation and hypothesize possible lattice structure while image provide denser color and texture information to evaluate and confirm these hypothesis in the experiment we compare our method with existing algorithm we also show how our result might be used to assist image based modeling 
in this paper we propose a diffusion based approach to improve an input similarity metric the diffusion process propagates similarity mass along the intrinsic manifold of data point our approach result in a global similarity metric which differs from the query specific one for ranking produced by label propagation unlike diffusion map our approach directly improves a given similarity metric without introducing any extra distance notion we call our approach self smoothing operator sso to demonstrate it wide applicability experiment are reported on image retrieval clustering classification and segmentation task in most case using sso result in significant performance gain over the original similarity metric with also very evident advantage over diffusion map 
given a community contributed set of photo of a crowded public event this paper address the problem of finding all image of each person in the scene this problem is very challenging due to large change in camera viewpoint severe occlusion low resolution and photo from ten or hundred of different photographer despite these challenge the problem is made tractable by exploiting a variety of visual and contextual cue appearance time stamp camera pose and co occurrence of people this paper demonstrates an approach that integrates these cue to enable high quality person matching in community photo collection downloaded from flickr com 
detecting pedestrian in cluttered scene is a challenging problem in computer vision the difficulty is added when several pedestrian overlap in image and occlude each other we observe however that the occlusion visibility status of overlapping pedestrian provide useful mutual relationship for visibility estimation the visibility estimation of one pedestrian facilitates the visibility estimation of another in this paper we propose a mutual visibility deep model that jointly estimate the visibility status of overlapping pedestrian the visibility relationship among pedestrian is learned from the deep model for recognizing co existing pedestrian experimental result show that the mutual visibility deep model effectively improves the pedestrian detection result compared with existing image based pedestrian detection approach our approach ha the lowest average miss rate on the caltech train dataset the caltech test dataset and the eth dataset including mutual visibility lead to improvement on multiple benchmark datasets 
simply choosing one model out of a large set of possibility for a given vision task is a surprisingly difficult problem especially if there is limited evaluation data with which to distinguish among model such a when choosing the best walk action classifier from a large pool of classifier tuned for different viewing angle lighting condition and background clutter in this paper we suggest that this problem of selecting a good model can be recast a a recommendation problem where the goal is to recommend a good model for a particular task based on how well a limited probe set of model appears to perform through this conceptual remapping we can bring to bear all the collaborative filtering technique developed for consumer recommender system e g netflix amazon com we test this hypothesis on action recognition and find that even when every model ha been directly rated on a training set recommendation find better selection for the corresponding test set than the best performer on the training set 
the objective of foreground segmentation is to extract the desired foreground object from input video over the year there have been significant amount of effort on this topic nevertheless there still lack a simple yet effective algorithm that can process live video of object with fuzzy boundary captured by freely moving camera this paper present an algorithm toward this goal the key idea is to train and maintain two competing one class support vector machine svms at each pixel location which model local color distribution for foreground and background respectively we advocate the usage of two competing local classifier a it provides higher discriminative power and allows better handling of ambiguity a a result our algorithm can deal with a variety of video with complex background and freely moving camera with minimum user interaction in addition by introducing novel acceleration technique and by exploiting the parallel structure of the algorithm realtime processing speed is achieved for vga sized video 
we propose a d sub query expansion approach for boosting sketch based multi view image retrieval the core idea of our method is to automatically convert two guided d sketch into an approximated d sketch model and then generate multi view sketch a expanded sub query to improve the retrieval performance to learn the weight among synthesized view sub query we present a new multi query feature to model the similarity between sub query and dataset image and formulate it into a convex optimization problem our approach show superior performance compared with the state of the art approach on a public multi view image dataset moreover we also conduct sensitivity test to analyze the parameter of our approach based on the gathered user sketch 
active learning and crowdsourcing are promising way to efficiently build up training set for object recognition but thus far technique are tested in artificially controlled setting typically the vision researcher ha already determined the dataset s scope the label actively obtained are in fact already known and or the crowd sourced collection process is iteratively fine tuned we present an approach for live learning of object detector in which the system autonomously refines it model by actively requesting crowd sourced annotation on image crawled from the web to address the technical issue such a large scale system entail we introduce a novel part based detector amenable to linear classifier and show how to identify it most uncertain instance in sub linear time with a hashing based solution we demonstrate the approach with experiment of unprecedented scale and autonomy and show it successfully improves the state of the art for the most challenging object in the pascal benchmark in addition we show our detector competes well with popular nonlinear classifier that are much more expensive to train 
the recent popularity of structured light depth sensor ha enabled many new application from gesture based user interface to d reconstruction the quality of the depth measurement of these system however is far from perfect some depth value can have significant error while others can be missing altogether the uncertainty in depth measurement among these sensor can significantly degrade the performance of any subsequent vision processing in this paper we propose a novel probabilistic model to capture various type of uncertainty in the depth measurement process among structured light system the key to our model is the use of depth layer to account for the difference between foreground object and background scene the missing depth value phenomenon and the correlation between color and depth channel the depth layer labeling is solved a a maximum a posteriori estimation problem and a markov random field attuned to the uncertainty in measurement is used to spatially smooth the labeling process using the depth layer label we propose a depth correction and completion algorithm that outperforms other technique in the literature 
the development of complex powerful classifier and their constant improvement have contributed much to the progress in many field of computer vision however the trend towards large scale datasets revived the interest in simpler classifier to reduce runtime simple nearest neighbor classifier have several beneficial property such a low complexity and inherent multi class handling however they have a runtime linear in the size of the database recent related work represents data sample by assigning them to a set of prototype that partition the input feature space and afterwards applies linear classifier on top of this representation to approximate decision boundary locally linear in this paper we go a step beyond these approach and purely focus on nearest prototype classification where we propose a novel algorithm for deriving optimal prototype in a discriminative manner from the training sample our method is implicitly multi class capable parameter free avoids noise over fitting and since during testing only comparison to the derived prototype are required highly efficient experiment demonstrate that we are able to outperform related locally linear method while even getting close to the result of more complex classifier 
with the ever expanding volume of visual content available the ability to organize and navigate such content by aesthetic preference is becoming increasingly important while still in it nascent stage research into computational model of aesthetic preference already show great potential however to advance research realistic diverse and challenging database are needed to this end we introduce a new large scale database for conducting aesthetic visual analysis ava it contains over image along with a rich variety of meta data including a large number of aesthetic score for each image semantic label for over category a well a label related to photographic style we show the advantage of ava with respect to existing database in term of scale diversity and heterogeneity of annotation we then describe several key insight into aesthetic preference afforded by ava finally we demonstrate through three application how the large scale of ava can be leveraged to improve performance on existing preference task 
kernel descriptor provide a unified way to generate rich visual feature set by turning pixel attribute into patch level feature and yield impressive result on many object recognition task however best result with kernel descriptor are achieved using efficient match kernel in conjunction with nonlinear svms which make it impractical for large scale problem in this paper we propose hierarchical kernel descriptor that apply kernel descriptor recursively to form image level feature and thus provide a conceptually simple and consistent way to generate image level feature from pixel attribute more importantly hierarchical kernel descriptor allow linear svms to yield state of the art accuracy while being scalable to large datasets they can also be naturally extended to extract feature over depth image we evaluate hierarchical kernel descriptor both on the cifar dataset and the new rgb d object dataset consisting of segmented rgb and depth image of everyday object 
invariant representation in object recognition system are generally obtained by pooling feature vector over spatially local neighborhood but pooling is not local in the feature vector space so that widely dissimilar feature may be pooled together if they are in nearby location recent approach rely on sophisticated encoding method and more specialized codebooks or dictionary e g learned on subset of descriptor which are close in feature space to circumvent this problem in this work we argue that a common trait found in much recent work in image recognition or retrieval is that it leverage locality in feature space on top of purely spatial locality we propose to apply this idea in it simplest form to an object recognition system based on the spatial pyramid framework to increase the performance of small dictionary with very little added engineering state of the art result on several object recognition benchmark show the promise of this approach 
existing eye gaze tracking system typically require an explicit personal calibration process in order to estimate certain person specific eye parameter for natural human computer interaction such a personal calibration is often cumbersome and unnatural in this paper we propose a new probabilistic eye gaze tracking system without explicit personal calibration unlike the traditional eye gaze tracking method which estimate the eye parameter deterministically our approach estimate the probability distribution of the eye parameter and the eye gaze by combining image saliency with the d eye model by using an incremental learning framework the subject doesn t need personal calibration before using the system his her eye parameter and gaze estimation can be improved gradually when he she is naturally viewing a sequence of image on the screen the experimental result show that the proposed system can achieve le than three degree accuracy for different people without calibration 
in this paper we tackle the problem of facial action unit au recognition by exploiting the complex semantic relationship among au which carry crucial top down information yet have not been thoroughly exploited towards this goal we build a hierarchical model that combine the bottom level image feature and the top level au relationship to jointly recognize au in a principled manner the proposed model ha two major advantage over existing method unlike method that can only capture local pair wise au dependency our model is developed upon the restricted boltzmann machine and therefore can exploit the global relationship among au although au relationship are influenced by many related factor such a facial expression these factor are generally ignored by the current method our model however can successfully capture them to more accurately characterize the au relationship efficient learning and inference algorithm of the proposed model are also developed experimental result on benchmark database demonstrate the effectiveness of the proposed approach in modelling complex au relationship a well a it superior au recognition performance over existing approach 
in this paper we propose a novel approach for detection segmentation and characterization of brain tumor our method exploit prior knowledge in the form of a sparse graph representing the expected spatial position of tumor class such information is coupled with image based classification technique along with spatial smoothness constraint towards producing a reliable detection map within a unified graphical model formulation towards optimal use of prior knowledge a two layer interconnected graph is considered with one layer corresponding to the low grade glioma type characterization and the second layer to voxel based decision of tumor presence efficient linear programming both in term of performance a well a in term of computational load is considered to recover the lowest potential of the objective function the outcome of the method refers to both tumor segmentation a well a their characterization promising result on substantial data set demonstrate the extreme potential of our method 
human activity recognition and speech recognition appear to be two loosely related research area however on a careful thought there are several analogy between activity and speech signal with regard to the way they are generated propagated and perceived in this paper we propose a novel action representation the action spectrogram which is inspired by a common spectrographic representation of speech different from sound spectrogram an action spectrogram is a space time frequency representation which characterizes the short time spectral property of body part movement while the essence of the speech signal is the variation of air pressure in time our method model activity a the likelihood time series of action associated local interest pattern this low level process is realized by learning boosted window classifier from spatially quantized spatio temporal interest feature we have tested our algorithm on a variety of human activity datasets and achieved superior result 
several attempt have been lately proposed to tackle the problem of recovering the original image of an underwater scene using a sequence distorted by water wave the main drawback of the state of the art is that it heavily depends on modelling the wave which in fact is ill posed since the actual behavior of the wave along with the imaging process are complicated and include several noise component therefore their result are not satisfactory in this paper we revisit the problem by proposing a data driven two stage approach each stage is targeted toward a certain type of noise the first stage leverage the temporal mean of the sequence to overcome the structured turbulence of the wave through an iterative robust registration algorithm the result of the first stage is a high quality mean and a better structured sequence however the sequence still contains unstructured sparse noise thus we employ a second stage at which we extract the sparse error from the sequence through rank minimization our method converges faster and drastically outperforms state of the art on all testing sequence even only after the first stage 
subwindow search aim to find the optimal subimage which maximizes the score function of an object to be detected after the development of the branch and bound b b method called efficient subwindow search es several algorithm y aess arc have been proposed to improve the performance of es for n n image y s time complexity is bounded by o n which is better than es but only applicable to linear score function other work show that monge property can hold in subwindow search and can be used to speed up the search to o n but only applies to certain type of score function in this paper we explore the connection between submodular function and the monge property and prove that sub modular score function can be used to achieve o n time complexity for object detection the time complexity can be further improved to be sub cubic by applying b b method on row interval only when the score function ha a multivariate submodular bound function condition for sub modularity of common non linear score function and multivariate submodularity of their bound function are also provided and experiment are provided to compare the proposed approach against es and arc for object detection with some nonlinear score function 
to quickly synthesize complex scene digital artist often collage together visual element from multiple source for example mountain from new zealand behind a scottish castle with wisp of saharan sand in front in this paper we propose to use a similar process in order to parse a scene we model a scene a a collage of warped layered object sampled from labeled reference image each object is related to the rest by a set of support constraint scene parsing is achieved through analysis by synthesis starting with a dataset of labeled exemplar scene we retrieve a dictionary of candidate object segment that match a query image we then combine element of this set into a scene collage that explains the query image beyond just assigning object label to pixel scene collaging produce a lot more information such a the number of each type of object in the scene how they support one another the ordinal depth of each object and to some degree occluded content we exploit this representation for several application image editing random scene synthesis and image to anaglyph 
recognition of gesture sequence is in general a very difficult problem but in certain domain the difficulty may be mitigated by exploiting the domain s grammar one such grammatically constrained gesture sequence domain is sign language in this paper we investigate the case of finger spelling recognition which can be very challenging due to the quick small motion of the finger most prior work on this task ha assumed a closed vocabulary of finger spelled word here we study the more natural open vocabulary case where the only domain knowledge is the possible finger spelled letter and statistic of their sequence we develop a semi markov conditional model approach where feature function are defined over segment of video and their corresponding letter label we use classifier of letter and linguistic hand shape feature along with expected motion profile to define segmental feature function this approach improves letter error rate levenshtein distance between hypothesized and correct letter sequence from using a hidden markov model baseline to using the proposed semi markov model 
sparse representation based classification src is a powerful tool in distinguishing signal category which lie on different subspace despite it wide application to visual recognition task current understanding of src is solely based on a reconstructive perspective which neither offer any guarantee on it classification performance nor provides any insight on how to design a discriminative dictionary for src in this paper we present a novel perspective towards src and interpret it a a margin classifier the decision boundary and margin of src are analyzed in local region where the support of sparse code is stable based on the derived margin we propose a hinge loss function a the gauge for the classification performance of src a stochastic gradient descent algorithm is implemented to maximize the margin of src and obtain more discriminative dictionary experiment validate the effectiveness of the proposed approach in predicting classification performance and improving dictionary quality over reconstructive one classification result competitive with other state of the art sparse coding method are reported on several data set 
image based location estimation method typically recognize every photo independently and their resulting reliance on strong visual feature match make them most suited for distinctive landmark scene we observe that when touring a city people tend to follow common travel pattern for example a stroll down wall street might be followed by a ferry ride then a visit to the statue of liberty we propose an approach that learns these trend directly from online image data and then leverage them within a hidden markov model to robustly estimate location for novel sequence of tourist photo we further devise a set to set matching based likelihood that treat each burst of photo from the same camera a a single observation thereby better accommodating image that may not contain particularly distinctive scene our experiment with two large datasets of major tourist city clearly demonstrate the approach s advantage over method that recognize each photo individually a well a a simpler hmm baseline that lack the proposed burst based observation model 
human age estimation ha recently become an active research topic in computer vision and pattern recognition because of many potential application in reality in this paper we propose to use the kernel partial least square kpls regression for age estimation the kpls or linear pls method ha several advantage over previous approach the kpls can reduce feature dimensionality and learn the aging function simultaneously in a single learning framework instead of performing each task separately using different technique the kpls can find a small number of latent variable e g to project thousand of feature into a very low dimensional subspace which may have great impact on real time application and the kpls regression ha an output vector that can contain multiple label so that several related problem e g age estimation gender classification and ethnicity estimation can be solved altogether this is the first time that the kernel pls method is introduced and applied to solve a regression problem in computer vision with high accuracy experimental result on a very large database show that the kpls is significantly better than the popular svm method and outperform the state of the art approach in human age estimation 
kinship verification from facial appearance is a difficult problem this paper explores the possibility of employing facial expression dynamic in this problem by using feature that describe facial dynamic and spatio temporal appearance over smile expression we show that it is possible to improve the state of the art in this problem and verify that it is indeed possible to recognize kinship by resemblance of facial expression the proposed method is tested on different kin relationship on the average verification accuracy is achieved on spontaneous smile 
blind image quality assessment biqa is an important yet difficult task in image processing related application existing algorithm for universal biqa learn a mapping from feature of an image to the corresponding subjective quality or divide the image into different distortion before mapping although these algorithm are promising they face the following problem they require a large number of sample pair of distorted image and it subjective quality to train a robust mapping they are sensitive to different datasets and they have to be retrained when new training sample are available in this paper we introduce a simple yet effective algorithm based upon the sparse representation of natural scene statistic n feature it consists of three key step extracting n feature in the wavelet domain representing feature via sparse coding and weighting differential mean opinion score by the sparse coding coefficient to obtain the final visual quality value thorough experiment on standard database show that the proposed algorithm outperforms representative biqa algorithm and some full reference metric 
this paper is concerned with energy based image segmentation problem we introduce a general class of regional functionals defined a an arbitrary non linear combination of regional unary term such high order functionals are very useful in vision and medical application and some special case appear in prior art for example our general class of functionals includes but is not restricted to soft constraint on segment volume it appearance histogram or shape our overall segmentation energy combine regional functionals with standard length based regularizers and or other submodular term in general regional functionals make the corresponding energy minimization np hard we propose a new greedy algorithm based on iterative line search a parametric max flow technique efficiently explores all solution along the direction line of the steepest descent of the energy we compute the best step size i e the globally optimal solution along the line this algorithm can make large move escaping weak local minimum a demonstrated on many real image 
temporal alignment of human motion ha been a topic of recent interest due to it application in animation telerehabilitation and activity recognition among others this paper present generalized time warping gtw an extension of dynamic time warping dtw for temporally aligning multi modal sequence from multiple subject performing similar activity gtw solves three major drawback of existing approach based on dtw gtw provides a feature weighting layer to adapt different modality e g video and motion capture data gtw extends dtw by allowing a more flexible time warping a combination of monotonic function unlike dtw that typically incurs in quadratic cost gtw ha linear complexity experimental result demonstrate that gtw can efficiently solve the multi modal temporal alignment problem and outperforms state of the art dtw method for temporal alignment of time series within the same modality 
recent work have shown that facial attribute are useful in a number of application such a face recognition and retrieval however estimating attribute in image with large variation remains a big challenge this challenge is addressed in this paper unlike existing method that assume the independence of attribute during their estimation our approach capture the interdependency of local region for each attribute a well a the high order correlation between different attribute which make it more robust to occlusion and misdetection of face region first we have modeled region interdependency with a discriminative decision tree where each node consists of a detector and a classifier trained on a local region the detector allows u to locate the region while the classifier determines the presence or absence of an attribute second correlation of attribute and attribute predictor are modeled by organizing all of the decision tree into a large sum product network spn which is learned by the em algorithm and yield the most probable explanation mpe of the facial attribute in term of the region s localization and classification experimental result on a large data set with image show the effectiveness of the proposed approach 
identifying suitable image feature is a central challenge in computer vision ranging from representation for low level to high level vision due to the difficulty of this task technique for learning feature directly from example data have recently gained attention despite significant benefit these learned feature often have many fewer of the desired invariance or equivariances than their hand crafted counterpart while translation in equivariance ha been addressed the issue of learning rotation invariant or equivariant representation is hardly explored in this paper we describe a general framework for incorporating invariance to linear image transformation into product model for feature learning a particular benefit is that our approach induces transformation aware feature learning i e it yield feature that have a notion with which specific image transformation they are used we focus our study on rotation in equivariance and show the advantage of our approach in learning rotation invariant image prior and in building rotation equivariant and invariant descriptor of learned feature which result in state of the art performance for rotation invariant object detection 
non rigid structure from motion nrsfm is a difficult underconstrained problem in computer vision the standard approach in nrsfm constrains d shape deformation using a linear combination of k basis shape the solution is then obtained a the low rank factorization of an input observation matrix an important but overlooked problem with this approach is that non linear deformation are often observed these deformation lead to a weakened low rank constraint due to the need to use additional basis shape to linearly model point that move along curve here we demonstrate how the kernel trick can be applied in standard nrsfm a a result we model complex deformable d shape a the output of a non linear mapping whose input are point within a low dimensional shape space this approach is flexible and can use different kernel to build different non linear model using the kernel trick our model complement the low rank constraint by capturing non linear relationship in the shape coefficient of the linear model the net effect can be seen a using non linear dimensionality reduction to further compress the shape space of possible solution 
supervoxel hierarchy provide a rich multiscale decomposition of a given video suitable for subsequent processing in video analysis the hierarchy are typically computed by an unsupervised process that is susceptible to under segmentation at coarse level and over segmentation at fine level which make it a challenge to adopt the hierarchy for later use in this paper we propose the first method to overcome this limitation and flatten the hierarchy into a single segmentation our method called the uniform entropy slice seek a selection of supervoxels that balance the relative level of information in the selected supervoxels based on some post hoc feature criterion such a object ness for example with this criterion in region nearby object our method prefers finer supervoxels to capture the local detail but in region away from any object we prefer coarser supervoxels we formulate the uniform entropy slice a a binary quadratic program and implement four different feature criterion both unsupervised and supervised to drive the flattening although we apply it only to supervoxel hierarchy in this paper our method is generally applicable to segmentation tree hierarchy our experiment demonstrate both strong qualitative performance and superior quantitative performance to state of the art baseline on benchmark internet video 
typical approach to articulated pose estimation combine spatial modelling of the human body with appearance modelling of body part this paper aim to push the state of the art in articulated pose estimation in two way first we explore various type of appearance representation aiming to substantially improve the body part hypothesis and second we draw on and combine several recently proposed powerful idea such a more flexible spatial model a well a image conditioned spatial model in a series of experiment we draw several important conclusion we show that the proposed appearance representation are complementary we demonstrate that even a basic tree structure spatial human body model achieves state of the art performance when augmented with the proper appearance representation and we show that the combination of the best performing appearance model with a flexible image conditioned spatial model achieves the best result significantly improving over the state of the art on the leeds sport pose and parse benchmark 
we propose a scheme that allows to partition an image into a previously unknown number of segment using only minimal supervision in term of a few must link and cannot link annotation we make no use of regional data term learning instead what constitutes a likely boundary between segment since boundary are only implicitly specified through cannot link constraint this is a hard and nonconvex latent variable problem we address this problem in a greedy fashion using a randomized decision tree on feature associated with interpixel edge we use a it structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optimum the proposed strategy is compared with prior art on natural image 
an affine invariant representation is constructed with a cascade of invariant which preserve information for classification a joint translation and rotation invariant representation of image patch is calculated with a scattering transform it is implemented with a deep convolution network which computes successive wavelet transforms and modulus non linearity invariant to scaling shearing and small deformation are calculated with linear operator in the scattering domain state of the art classification result are obtained over texture database with uncontrolled viewing condition 
in this paper we present an active sampling method to speed up conventional pixel wise background subtraction algorithm the proposed active sampling strategy is designed to focus on attentional region such a foreground region the attentional region is estimated by detection result of previous frame in a recursive probabilistic way for the estimation of the attentional region we propose a foreground probability map based on temporal spatial and frequency property of foreground by using this foreground probability map active attentional sampling scheme is developed to make a minimal sampling mask covering almost foreground the effectiveness of the proposed active sampling method is shown through various experiment the proposed masking method successfully speed up pixel wise background subtraction method approximately time without deteriorating detection performance also realtime detection with full hd video is successfully achieved through various conventional background subtraction algorithm 
object detection in image withstanding significant clutter and occlusion is still a challenging task whenever the object surface is characterized by poor informative content we propose to tackle this problem by a compact and distinctive representation of group of neighboring line segment aggregated over limited spatial support and invariant to rotation translation and scale change peculiarly our proposal allows for leveraging on the inherent strength of descriptor based approach i e robustness to occlusion and clutter and scalability with respect to the size of the model library also when dealing with scarcely textured object 
undoubtedly a key feature in the popularity of smartmobile device is the numerous application one can install frequently we learn about an application we desire by seeing it on a review site someone else s device or a magazine a user friendly way to obtain this particular application could be by taking a snapshot of it corresponding icon and being directed automatically to it download link such a solution exists today for qr code which can be thought of a icon with a binary pattern in this paper we extend this to app icon and propose a complete system for automatic icon scanning it first detects the icon in a snapshot and then recognizes it icon scanning is a highly challenging problem due to the large variety of icon k in app store and background wallpaper in addition our system should further deal with the challenge introduced by taking picture of a screen nevertheless the novel solution proposed in this paper provides high detection and recognition rate we test our complete icon scanning system on icon snapshot taken by independent user and search them within the entire set of icon in app store our success rate are high and improve significantly on other method 
in this paper we propose a novel norm graph model to perform unsupervised and semi supervised learning method instead of minimizing the norm of spectral embedding a traditional graph based learning method our new graph learning model minimizes the norm of spectral embedding with well motivation the sparsity produced by the norm minimization result in the solution with much clearer cluster structure which are suitable for both image clustering and classification task we introduce a new efficient iterative algorithm to solve the norm of spectral embedding minimization problem and prove the convergence of the algorithm more specifically our algorithm adaptively re weight the original weight of graph to discover clearer cluster structure experimental result on both toy data and real image data set show the effectiveness and advantage of our proposed method 
because manual image annotation is both expensive and labor intensive in practice we often do not have sufficient labeled image to train an effective classifier for the new image classification task although multiple labeled image data set are publicly available for a number of computer vision task a simple mixture of them cannot achieve good performance due to the heterogeneous property and structure between different data set in this paper we propose a novel nonnegative matrix tri factorization based transfer learning framework called a dyadic knowledge transfer dkt approach to transfer cross domain image knowledge for the new computer vision task such a classification an efficient iterative algorithm to solve the proposed optimization problem is introduced we perform the proposed approach on two benchmark image data set to simulate the real world cross domain image classification task promising experimental result demonstrate the effectiveness of the proposed approach 
this paper present a novel way to perform multi modal face recognition we use partial least square pls to linearly map image in different modality to a common linear subspace in which they are highly correlated pls ha been previously used effectively for feature selection in face recognition we show both theoretically and experimentally that pls can be used effectively across modality we also formulate a generic intermediate subspace comparison framework for multi modal recognition surprisingly we achieve high performance using only pixel intensity a feature we experimentally demonstrate the highest published recognition rate on the pose variation in the pie data set and also show that pls can be used to compare sketch to photo and to compare image taken at different resolution 
many image retargeting algorithm despite aesthetically carving image smaller pay limited attention to image browsing task where tiny thumbnail are presented when applying traditional retargeting method for generating thumbnail several important issue frequently arise including thumbnail scale object completeness and local structure smoothness to address these issue we propose a novel image retargeting algorithm scale and object aware retargeting soar which ha four component a scale dependent saliency map to integrate size information of thumbnail objectness alexe et al for preserving object completeness a cyclic seam carving algorithm to guide continuous retarget warping and a thin plate spline tps retarget warping algorithm that champion local structure smoothness the effectiveness of the proposed algorithm is evaluated both quantitatively and qualitatively the quantitative evaluation is conducted through an image browsing user study to measure the effectiveness of different thumbnail generating algorithm followed by the anova analysis the qualitative study is performed on the retargetme benchmark dataset in both study soar generates very promising performance in comparison with state of the art retargeting algorithm 
we propose a learning based conditional random field crf model for tracking multiple target by progressively associating detection response into long track tracking task is transformed into a data association problem and most previous approach developed heuristical parametric model or learning approach for evaluating independent affinity between track fragment tracklets we argue that the independent assumption is not valid in many case and adopt a crf model to consider both tracklet affinity and dependency among them which are represented by unary term cost and pairwise term cost respectively unlike previous method we learn the best global association instead of the best local affinity between tracklets and transform the task of finding the best association into an energy minimization problem a rankboost algorithm is proposed to select effective feature for estimation of term cost in the crf model so that better association have lower cost our approach is evaluated on challenging pedestrian data set and are compared with state of art method experiment show effectiveness of our algorithm a well a improvement in tracking performance 
early prediction of ongoing activity ha been more and more valuable in a large variety of time critical application to build an effective representation for prediction human activity can be characterized by a complex temporal composition of constituent simple action different from early recognition on short duration simple activity we propose a novel framework for long duration complex activity prediction by discovering the causal relationship between constituent action and the predictable characteristic of activity the major contribution of our work include we propose a novel activity decomposition method by monitoring motion velocity which encodes a temporal decomposition of long activity into a sequence of meaningful action unit probabilistic suffix tree pst is introduced to represent both large and small order markov dependency between action unit we present a predictive accumulative function paf to depict the predictability of each kind of activity the effectiveness of the proposed method is evaluated on two experimental scenario activity with middle level complexity and activity with high level complexity our method achieves promising result and can predict global activity class and local action unit 
in this paper we present a novel interactive image segmentation technique that automatically learns segmentation parameter tailored for each and every image unlike existing work our method doe not require any offline parameter tuning or training stage and is capable of determining image specific parameter according to some simple user interaction with the target image we formulate the segmentation problem a an inference of a conditional random field crf over a segmentation mask and the target image and parametrize this crf by different weight e g color texture and smoothing the weight parameter are learned via an energy margin maximization which is solved using a constraint approximation scheme and the cutting plane method experimental result show that our method by learning image specific parameter automatically outperforms other state of the art interactive image segmentation technique 
in this paper we introduce a new domain adaptation da algorithm where the source and target domain are represented by subspace described by eigenvectors in this context our method seek a domain adaptation solution by learning a mapping function which aligns the source subspace with the target one we show that the solution of the corresponding optimization problem can be obtained in a simple closed form leading to an extremely fast algorithm we use a theoretical result to tune the unique hyper parameter corresponding to the size of the subspace we run our method on various datasets and show that despite it intrinsic simplicity it outperforms state of the art da method 
in this paper we tackle the problem of understanding the temporal structure of complex event in highly varying video obtained from the internet towards this goal we utilize a conditional model trained in a max margin framework that is able to automatically discover discriminative and interesting segment of video while simultaneously achieving competitive accuracy on difficult detection and recognition task we introduce latent variable over the frame of a video and allow our algorithm to discover and assign sequence of state that are most discriminative for the event our model is based on the variable duration hidden markov model and model duration of state in addition to the transition between state the simplicity of our model allows u to perform fast exact inference using dynamic programming which is extremely important when we set our sight on being able to process a very large number of video quickly and efficiently we show promising result on the olympic sport dataset and the trecvid multimedia event detection task we also illustrate and visualize the semantic understanding capability of our model 
while bottom up and top down process have shown effectiveness during predicting attention and eye fixation map on image in this paper inspired by the perceptual organization mechanism before attention selection we propose to utilize figure ground map for the purpose so a to take both pixel wise and region wise interaction into consideration when predicting label probability for each pixel we develop a context aware model based on multiple segmentation to obtain final result the mit attention dataset is applied finally to evaluate both new feature and model quantitative experiment demonstrate that figure ground cue are valid in predicting attention selection and our proposed model produce improvement over baseline method 
despite the success of recent object class recognition system the long standing problem of partial occlusion remains a major challenge and a principled solution is yet to be found in this paper we leave the beaten path of method that treat occlusion a just another source of noise instead we include the occluder itself into the modelling by mining distinctive reoccurring occlusion pattern from annotated training data these pattern are then used a training data for dedicated detector of varying sophistication in particular we evaluate and compare model that range from standard object class detector to hierarchical part based representation of occluder occludee pair in an extensive evaluation we derive insight that can aid further development in tackling the occlusion challenge 
we present a hierarchical model that learns image decomposition via alternating layer of convolutional sparse coding and max pooling when trained on natural image the layer of our model capture image information in a variety of form low level edge mid level edge junction high level object part and complete object to build our model we rely on a novel inference scheme that ensures each layer reconstructs the input rather than just the output of the layer directly beneath a is common with existing hierarchical approach this make it possible to learn multiple layer of representation and we show model with layer trained on image from the caltech and datasets when combined with a standard classifier feature extracted from these model outperform sift a well a representation from other feature learning method 
we present a method that enhances the performance of depth from defocus dfd through the use of shading information dfd suffers from important limitation namely coarse shape reconstruction and poor accuracy on texture le surface that can be overcome with the help of shading we integrate both form of data within a bayesian framework that capitalizes on their relative strength shading data however is challenging to recover accurately from surface that contain texture to address this issue we propose an iterative technique that utilizes depth information to improve shading estimation which in turn is used to elevate depth estimation in the presence of texture with this approach we demonstrate improvement over existing dfd technique a well a effective shape reconstruction of texture le surface 
this paper offer the first variational approach to the problem of dense d reconstruction of non rigid surface from a monocular video sequence we formulate non rigid structure from motion nrsfm a a global variational energy minimization problem to estimate dense low rank smooth d shape for every frame along with the camera motion matrix given dense d correspondence unlike traditional factorization based approach to nrsfm which model the low rank non rigid shape using a fixed number of basis shape and corresponding coefficient we minimize the rank of the matrix of time varying shape directly via trace norm minimization in conjunction with this low rank constraint we use an edge preserving total variation regularization term to obtain spatially smooth shape for every frame thanks to proximal splitting technique the optimization problem can be decomposed into many point wise sub problem and simple linear system which can be easily solved on gpu hardware we show result on real sequence of different object face torso beating heart where despite challenge in tracking illumination change and occlusion our method reconstructs highly deforming smooth surface densely and accurately directly from video without the need for any prior model or shape template 
in this paper we address the problem of shadow detection and removal from single image of natural scene different from traditional method that explore pixel or edge information we employ a region based approach in addition to considering individual region separately we predict relative illumination condition between segmented region from their appearance and perform pairwise classification based on such information classification result are used to build a graph of segment and graph cut is used to solve the labeling of shadow and non shadow region detection result are later refined by image matting and the shadow free image is recovered by relighting each pixel based on our lighting model we evaluate our method on the shadow detection dataset in addition we created a new dataset with shadow free ground truth image which provides a quantitative basis for evaluating shadow removal 
we present an approach to add true fine scale spatio temporal shape detail to dynamic scene geometry captured from multi view video footage our approach exploit shading information to recover the millimeter scale surface structure but in contrast to related approach succeeds under general unconstrained lighting condition our method start off from a set of multi view video frame and an initial series of reconstructed coarse d mesh that lack any surface detail in a spatio temporal maximum a posteriori probability map inference framework our approach first estimate the incident illumination and the spatially varying albedo map on the mesh surface for every time instant thereafter albedo and illumination are used to estimate the true geometric detail visible in the image and add it to the coarse reconstruction the map framework us weak temporal prior on lighting albedo and geometry which improve reconstruction quality yet allow for temporal variation in the data 
we propose a method to generate highly detailed textured d model of large environment from rgb d sequence our system run in real time on a standard desktop pc with a state of the art graphic card to reduce the memory consumption we fuse the acquired depth map and color in a multi scale octree representation of a signed distance function to estimate the camera pose we construct a pose graph and use dense image alignment to determine the relative pose between pair of frame we add edge between node when we detect loop closure and optimize the pose graph to correct for long term drift our implementation is highly parallelized on graphic hardware to achieve real time performance more specifically we can reconstruct store and continuously update a colored d model of an entire corridor of nine room at high level of detail in real time on a single gpu with gb 
we present a novel and simple computational imaging solution to robustly and accurately recover d dynamic fluid surface traditional specular surface reconstruction scheme place special pattern checkerboard or color pattern beneath the fluid surface to establish point pixel correspondence however point pixel correspondence alone are insufficient to recover surface normal or height and they rely on additional constraint to resolve the ambiguity in this paper we exploit using bokode a computational optical device that emulates a pinhole projector for capturing ray ray correspondence which can then be used to directly recover the surface normal we further develop a robust feature matching algorithm based on the active appearance model to robustly establishing ray ray correspondence our solution result in an angularly sampled normal field and we derive a new angular domain surface integration scheme to recover the surface from the normal field specifically we reformulate the problem a an over constrained linear system under spherical coordinate and solve it using singular value decomposition experiment result on real and synthetic surface demonstrate that our approach is robust and accurate and is easier to implement than state of the art multi camera based approach 
in this paper we present an unsupervised method for mining activity in video from unlabeled video sequence of a scene our method can automatically recover what are the recurrent temporal activity pattern or motif and when they occur using non parametric bayesian method we are able to automatically find both the underlying number of motif and the number of motif occurrence in each document the model s robustness is first validated on synthetic data it is then applied on a large set of video data from state of the art paper we show that it can effectively recover temporal activity with high semantics for human and strong temporal information the model is also used for prediction where it is shown to be a efficient a other approach although illustrated on video sequence this model can be directly applied to various kind of time series where multiple activity occur simultaneously 
grouping cue can affect the performance of segmentation greatly in this paper we show that superpixels image segment can provide powerful grouping cue to guide segmentation where superpixels can be collected easily by over segmenting the image using any reasonable existing segmentation algorithm generated by different algorithm with varying parameter superpixels can capture diverse and multi scale visual pattern of a natural image successful integration of the cue from a large multitude of superpixels present a promising yet not fully explored direction in this paper we propose a novel segmentation framework based on bipartite graph partitioning which is able to aggregate multi layer superpixels in a principled and very effective manner computationally it is tailored to unbalanced bipartite graph structure and lead to a highly efficient linear time spectral algorithm our method achieves significantly better performance on the berkeley segmentation database compared to state of the art technique 
representation is a fundamental problem in object tracking conventional method track the target by describing it local or global appearance in this paper we present that besides the two paradigm the composition of local region histogram can also provide diverse and important object cue we use cell to extract local appearance and construct complex cell to integrate the information from cell with different spatial arrangement of cell complex cell can explore various contextual information at multiple scale which is important to improve the tracking performance we also develop a novel template matching algorithm for object tracking where the template is composed of temporal varying cell and ha two layer to capture the target and background appearance respectively an adaptive weight is associated with each complex cell to cope with occlusion a well a appearance variation a fusion weight is associated with each complex cell type to preserve the global distinctiveness our algorithm is evaluated on challenging sequence and the result not only confirm the contribution of each component in our tracking system but also outperform other competing tracker 
cascade are a popular framework to speed up object detection system here we focus on the first layer of a category independent object detection cascade in which we sample a large number of window from an objectness prior and then discriminatively learn to filter these candidate window by an order of magnitude we make a number of contribution to cascade design that substantially improve over the state of the art i our novel objectness prior give much higher recall than competing method ii we propose objectness feature that give high performance with very low computational cost and iii we make use of a structured output ranking approach to learn highly effective but inexpensive linear feature combination by directly optimizing cascade performance thorough evaluation on the pascal voc data set show consistent improvement over the current state of the art and over alternative discriminative learning strategy 
scene text recognition ha inspired great interest from the computer vision community in recent year in this paper we propose a novel scene text recognition method using part based tree structured character detection different from conventional multi scale sliding window character detection strategy which doe not make use of the character specific structure information we use part based tree structure to model each type of character so a to detect and recognize the character at the same time while for word recognition we build a conditional random field model on the potential character location to incorporate the detection score spatial constraint and linguistic knowledge into one framework the final word recognition result is obtained by minimizing the cost function defined on the random field experimental result on a range of challenging public datasets icdar icdar svt demonstrate that the proposed method outperforms state of the art method significantly both for character detection and word recognition 
junction are strong cue for understanding the geometry of a scene in this paper we consider the problem of detecting junction and using them for recovering the spatial layout of an indoor scene junction detection ha always been challenging due to missing and spurious line we work in a constrained manhattan world setting where the junction are formed by only line segment along the three principal orthogonal direction junction can be classified into several category based on the number and orientation of the incident line segment we provide a simple and efficient voting scheme to detect and classify these junction in real image indoor scene are typically modeled a cuboid and we formulate the problem of the cuboid layout estimation a an inference problem in a conditional random field our formulation allows the incorporation of junction feature and the training is done using structured prediction technique we outperform other single view geometry estimation method on standard datasets 
face detection is an important task in computer vision and often serf a the first step for a variety of application state of the art approach use efficient learning algorithm and train on large amount of manually labeled imagery acquiring appropriate training image however is very time consuming and doe not guarantee that the collected training data is representative in term of data variability moreover available data set are often acquired under controlled setting restricting for example scene illumination or d head pose to a narrow range this paper take a look into the automated generation of adaptive training sample from a d morph able face model using statistical insight the tailored training data guarantee full data variability and is enriched by arbitrary facial attribute such a age or body weight moreover it can automatically adapt to environmental constraint such a illumination or viewing angle of recorded video footage from surveillance camera we use the tailored imagery to train a new many core implementation of viola jones adaboost object detection framework the new implementation is not only faster but also enables the use of multiple feature channel such a color feature at training time in our experiment we trained seven view dependent face detector and evaluate these on the face detection data set and benchmark fddb our experiment show that the use of tailored training imagery outperforms state of the art approach on this challenging dataset 
learning good image prior is of utmost importance for the study of vision computer vision and image processing application learning prior and optimizing over whole image can lead to tremendous computational challenge in contrast when we work with small image patch it is possible to learn prior and perform patch restoration very efficiently this raise three question do prior that give high likelihood to the data also lead to good performance in restoration can we use such patch based prior to restore a full image can we learn better patch prior in this work we answer these question we compare the likelihood of several patch model and show that prior that give high likelihood to data perform better in patch restoration motivated by this result we propose a generic framework which allows for whole image restoration using any patch based prior for which a map or approximate map estimate can be calculated we show how to derive an appropriate cost function how to optimize it and how to use it to restore whole image finally we present a generic surprisingly simple gaussian mixture prior learned from a set of natural image when used with the proposed framework this gaussian mixture model outperforms all other generic prior method for image denoising deblurring and inpainting 
eliciting and representing expert remarkable perceptual capability of locating identifying and categorizing object in image specific to their domain of expertise will benefit image understanding in term of transferring human domain knowledge and perceptual expertise into image based computational procedure in this paper we present a hierarchical probabilistic framework to summarize the stereotypical and idiosyncratic eye movement pattern shared within board certified dermatologist while they are examining and diagnosing medical image each inferred eye movement pattern characterizes the similar temporal and spatial property of it corresponding segment of the expert eye movement sequence we further discover a subset of distinctive eye movement pattern which are commonly exhibited across multiple image based on the combination of the exhibition of these eye movement pattern we are able to categorize the image from the perspective of expert viewing strategy in each category image share similar lesion distribution and configuration the performance of our approach show that modeling physician diagnostic viewing behavior informs about medical image understanding to correct diagnosis 
we present a new spatio temporal method for markerless motion capture we reconstruct the pose and motion of a character from a multi view video sequence without requiring the camera to be synchronized and without aligning captured frame in time by formulating the model to image similarity measure a a temporally continuous functional we are also able to reconstruct motion in much higher temporal detail than wa possible with previous synchronized approach by purposefully running camera unsynchronized we can capture even very fast motion at speed that off the shelf but high quality camera provide 
this paper present an approach to view invariant action recognition where human pose and motion exhibit large variation across different camera viewpoint when each viewpoint of a given set of action class is specified a a learning task then multitask learning appears suitable for achieving view invariance in recognition we extend the standard multitask learning to allow identifying latent grouping of action view i e task and discriminative action part along with joint learning of all task this is because it seems reasonable to expect that certain distinct view are more correlated than some others and thus identifying correlated view could improve recognition also part based modeling is expected to improve robustness against self occlusion when actor are imaged from different view result on the benchmark datasets show that we outperform standard multitask learning by and the state of the art alternative by 
local binary pattern lbp and it variant are effective descriptor for face recognition the traditional lbp like feature are extracted based on the original pixel or patch value of image in this paper we propose to learn the discriminative image filter to improve the discriminant power of the lbp like feature the basic idea is after the image filtering with the learned filter the difference of pixel difference vector pdvs between the image from the same person is consistent and the difference between the image from different person is enlarged in this way the lbp like feature extracted from the filtered image are considered to be more discriminant than those extracted from the original image moreover a coupled discriminant image filter learning method is proposed to deal with the heterogenous face image matching problem by reducing the feature gap between the heterogeneous image experiment on feret frgc and a vi nir heterogeneous face database validate the effectiveness of our proposed image filter learning method combined with lbp like feature 
obtaining effective mid level representation ha become an increasingly important task in computer vision in this paper we propose a fully automatic algorithm which harvest visual concept from a large number of internet image more than a quarter of a million using text based query existing approach to visual concept learning from internet image either rely on strong supervision with detailed manual annotation or learn image level classifier only here we take the advantage of having massive well organized google and bing image data visual concept around are automatically exploited from image using word based query using the learned visual concept we show state of the art performance on a variety of benchmark datasets which demonstrate the effectiveness of the learned mid level representation being able to generalize well to general natural image our method show significant improvement over the competing system in image classification including those with strong supervision 
we present an algorithm for the per voxel semantic segmentation of a three dimensional volume at the core of our algorithm is a novel pyramid context feature a descriptive representation designed such that exact per voxel linear classification can be made extremely efficient this feature not only allows for efficient semantic segmentation but enables other aspect of our algorithm such a novel learned feature and a stacked architecture that can reason about self consistency we demonstrate our technique on d fluorescence microscopy data of drosophila embryo for which we are able to produce extremely accurate semantic segmentation in a matter of minute and for which other algorithm fail due to the size and high dimensionality of the data or due to the difficulty of the task 
in this paper we present an efficient general purpose objective no reference nr image quality assessment iqa framework based on unsupervised feature learning the goal is to build a computational model to automatically predict human perceived image quality without a reference image and without knowing the distortion present in the image previous approach for this problem typically rely on hand crafted feature which are carefully designed based on prior knowledge in contrast we use raw image patch extracted from a set of unlabeled image to learn a dictionary in an unsupervised manner we use soft assignment coding with max pooling to obtain effective image representation for quality estimation the proposed algorithm is very computationally appealing using raw image patch a local descriptor and using soft assignment for encoding furthermore unlike previous method our unsupervised feature learning strategy enables our method to adapt to different domain cornia codebook representation for no reference image assessment is tested on live database and shown to perform statistically better than the full reference quality measure structural similarity index ssim and is shown to be comparable to state of the art general purpose nr iqa algorithm 
recently sparse representation ha been applied to visual tracker by modeling the target appearance using a sparse approximation over a template set which lead to the so called l tracker a it need to solve an norm related minimization problem for many time while these l tracker showed impressive tracking accuracy they are very computationally demanding and the speed bottleneck is the solver to norm minimization this paper aim at developing an l tracker that not only run in real time but also enjoys better robustness than other l tracker in our proposed l tracker a new norm related minimization model is proposed to improve the tracking accuracy by adding an norm regularization on the coefficient associated with the trivial template moreover based on the accelerated proximal gradient approach a very fast numerical solver is developed to solve the resulting norm related minimization problem with guaranteed quadratic convergence the great running time efficiency and tracking accuracy of the proposed tracker is validated with a comprehensive evaluation involving eight challenging sequence and five alternative state of the art tracker 
in this paper we propose a novel framework of style transfer matrix stm learning to reduce the writing style variation in handwriting recognition after writer specific style transfer learning the data of different writer is projected onto a style free space where a writer independent classifier can yield high accuracy we combine stm learning with a specific nearest prototype classifier learning vector quantization lvq with discriminative feature extraction dfe where both the prototype and the subspace transformation matrix are learned via online discriminative learning to adapt the basic classifier trained with writer independent data to particular writer we first propose two supervised model one based on incremental learning and the other based on supervised stm learning to overcome the lack of labeled sample for particular writer we propose an unsupervised model to learn the stm using the self taught strategy also known a self training experiment on a large scale chinese online handwriting database demonstrate that stm learning can reduce recognition error significantly and the unsupervised adaptation model performs even better than the supervised model 
modeling image similarity for browsing and searching in voluminous image database is a challenging task of nearly all content based image retrieval system one promising way of defining image similarity consists in applying distance based similarity measure on compact image representation beyond feature histogram and feature signature more general feature representation are mixture model of which the gaussian mixture model is the most prominent one this feature representation can be compared by employing approximation of the kullback leibler divergence although several of those approximation have been successfully applied to model image similarity their applicability to mixture model based on high dimensional feature descriptor is questionable in this paper we thus introduce the signature quadratic form distance to measure the distance between two gaussian mixture model of high dimensional feature descriptor we show the analytical computation of the proposed gaussian quadratic form distance and evaluate it retrieval performance by making use of different benchmark image database 
we consider the task of learning the parameter of a segmentation model that assigns a specific semantic class to each pixel of a given image the main problem we face is the lack of fully supervised data we address this issue by developing a principled framework for learning the parameter of a specific class segmentation model using diverse data more precisely we propose a latent structural support vector machine formulation where the latent variable model any missing information in the human annotation of particular interest to u are three type of annotation i image segmented using generic foreground or background class ii image with bounding box specified for object and iii image labeled to indicate the presence of a class using large publicly available datasets we show that our approach is able to exploit the information present in different annotation to improve the accuracy of a state of the art region based model 
we propose a new approach to detecting irregular curvilinear structure in noisy image stack in contrast to earlier approach that rely on circular model of the cross section ours allows for the arbitrarily shaped one that are prevalent in biological imagery this is achieved by maximizing the image gradient flux along multiple direction and radius instead of only two with a unique radius a is usually done this yield a more complex optimization problem for which we propose a computationally efficient solution we demonstrate the effectiveness of our approach on a wide range of challenging gray scale and color datasets and show that it outperforms existing technique especially on very irregular structure 
object detector are typically trained on a large set of still image annotated by bounding box this paper introduces an approach for learning object detector from real world web video known only to contain object of a target class we propose a fully automatic pipeline that localizes object in a set of video of the class and learns a detector for it the approach extract candidate spatio temporal tube based on motion segmentation and then selects one tube per video jointly over all video to compare to the state of the art we test our detector on still image i e pascal voc we observe that frame extracted from web video can differ significantly in term of quality to still image taken by a good camera thus we formulate the learning from video a a domain adaptation task we show that training from a combination of weakly annotated video and fully annotated still image using domain adaptation improves the performance of a detector trained from still image alone 
empirically we find that despite the class specific feature owned by the object appearing in the image the object from different category usually share some common pattern which do not contribute to the discrimination of them concentrating on this observation and under the general dictionary learning dl framework we propose a novel method to explicitly learn a common pattern pool the commonality and class specific dictionary the particularity for classification we call our method dl copar which can learn the most compact and most discriminative class specific dictionary used for classification the proposed dl copar is extensively evaluated both on synthetic data and on benchmark image database in comparison with existing dl based classification method the experimental result demonstrate that dl copar achieves very promising performance in various application such a face recognition handwritten digit recognition scene classification and object recognition 
for scene classification patch level linear feature do not always work a well a handcrafted feature in this paper we present a new model to greatly improve the usefulness of linear feature in classification by introducing co variance pattern we analyze their property discus the fundamental importance and present a generative model to properly utilize them with this set of covariance information in our framework even the most naive linear feature that originally lack the vital ability in classification become powerful experiment show that the performance of our new covariance model based on linear feature is comparable with or even better than handcrafted feature in scene classification 
state of the art human activity recognition method build on discriminative learning which requires a representative training set for good performance this lead to scalability issue for the recognition of large set of highly diverse activity in this paper we leverage the fact that many human activity are compositional and that the essential component of the activity can be obtained from textual description or script to share and transfer knowledge between composite activity we model them by a common set of attribute corresponding to basic action and object participant this attribute representation allows to incorporate script data that delivers new variation of a composite activity or even to unseen composite activity in our experiment on composite cooking task we found that script data to successfully capture the high variability of composite activity we show improvement in a supervised case where training data for all composite cooking task is available but we are also able to recognize unseen composite by just using script data and without any manual video annotation 
we propose a physically based approach to separate reflection using multiple polarized image with a background scene captured behind glass the input consists of three polarized image each captured from the same view point but with a different polarizer angle separated by degree the output is the high quality separation of the reflection and background layer from each of the input image a main technical challenge for this problem is that the mixing coefficient for the reflection and background layer depends on the angle of incidence and the orientation of the plane of incidence which are spatially varying over the pixel of an image exploiting physical property of polarization for a double surfaced glass medium we propose an algorithm which automatically find the optimal separation of the reflection and background layer thorough experiment we demonstrate that our approach can generate superior result to those of previous method 
this paper present model and algorithm for estimating the shape of a mirrored surface from a single image of that surface rendered under an unknown natural illumination while the unconstrained nature of this problem seems to make shape recovery impossible the curvature of the surface cause characteristic image pattern to appear these image pattern can be used to estimate how the surface curve in different direction we show how these estimate can be used to produce constraint that can be used to estimate the shape of the surface this approach is demonstrated on simple surface rendered under both natural and synthetic illumination 
this paper proposes a novel approach for sparse coding that further improves upon the sparse representation based classification src framework the proposed framework affine constrained group sparse coding acgsc extends the current src framework to classification problem with multiple input sample geometrically the affineconstrained group sparse coding essentially search for the vector in the convex hull spanned by the input vector that can best be sparse coded using the given dictionary the resulting objective function is still convex and can be efficiently optimized using iterative block coordinate descent scheme that is guaranteed to converge furthermore we provide a form of sparse recovery result that guarantee at least theoretically that the classification performance of the constrained group sparse coding should be at least a good a the group sparse coding we have evaluated the proposed approach using three different recognition experiment that involve illumination variation of face and texture and face recognition under occlusion preliminary experiment have demonstrated the effectiveness of the proposed approach and in particular the result from the recognition occlusion experiment are surprisingly accurate and robust 
this paper present the first semi supervised transductive algorithm for real time articulated hand pose estimation noisy data and occlusion are the major challenge of articulated hand pose estimation in addition the discrepancy among realistic and synthetic pose data undermine the performance of existing approach that use synthetic data extensively in training we therefore propose the semi supervised transductive regression str forest which learns the relationship between a small sparsely labelled realistic dataset and a large synthetic dataset we also design a novel data driven pseudo kinematic technique to refine noisy or occluded joint our contribution include i capturing the benefit of both realistic and synthetic data via transductive learning ii showing accuracy can be improved by considering unlabelled data and iii introducing a pseudo kinematic technique to refine articulation efficiently experimental result show not only the promising performance of our method with respect to noise and occlusion but also it superiority over state of the art in accuracy robustness and speed 
we propose scalpel a flexible method for object segmentation that integrates rich region merging cue with midand high level information about object layout class and scale into the segmentation process unlike competing approach scalpel us a cascade of bottom up segmentation model that is capable of learning to ignore boundary early on yet use them a a stopping criterion once the object ha been mostly segmented furthermore we show how such cascade can be learned efficiently when paired with a novel method that generates better localized shape prior than our competitor our method lead to a concise accurate set of segmentation proposal these proposal are more accurate on the pascal voc dataset than state of the art method that use re ranking to filter much larger bag of proposal the code for our algorithm is available online 
the k nn graph ha played a central role in increasingly popular data driven technique for various learning and vision task yet finding an efficient and effective way to construct k nn graph remains a challenge especially for large scale high dimensional data in this paper we propose a new approach to construct approximate k nn graph with emphasis in efficiency and accuracy we hierarchically and randomly divide the data point into subset and build an exact neighborhood graph over each subset achieving a base approximate neighborhood graph we then repeat this process for several time to generate multiple neighborhood graph which are combined to yield a more accurate approximate neighborhood graph furthermore we propose a neighborhood propagation scheme to further enhance the accuracy we show both theoretical and empirical accuracy and efficiency of our approach to k nn graph construction and demonstrate significant speed up in dealing with large scale visual data 
previous video stabilization method often employ homographies to model transition between consecutive frame or require robust long feature track however the homography model is invalid for scene with significant depth variation and feature point tracking is fragile in video with textureless object severe occlusion or camera rotation to address these challenging case we propose to solve video stabilization with an additional depth sensor such a the kinect camera though the depth image is noisy incomplete and low resolution it facilitates both camera motion estimation and frame warping which make the video stabilization a much well posed problem the experiment demonstrate the effectiveness of our algorithm 
in this paper we present a novel algorithm for fast tracking of generic object in video the algorithm us two component a detector that make use of the generalised hough transform with pixel based descriptor and a probabilistic segmentation method based on global model for foreground and background these component are used for tracking in a combined way and they adapt each other in a co training manner through effective model adaptation and segmentation the algorithm is able to track object that undergo rigid and non rigid deformation and considerable shape and appearance variation the proposed tracking method ha been thoroughly evaluated on challenging standard video and outperforms state of the art tracking method designed for the same task finally the proposed model allow for an extremely efficient implementation and thus tracking is very fast 
many work in computer vision attempt to solve different task such a object detection scene recognition or attribute detection either separately or a a joint problem in recent year there ha been a growing interest in combining the result from these different task in order to provide a textual description of the scene however when describing a scene there are many item that can be mentioned if we include all the object relationship and attribute that exist in the image the description would be extremely long and not convey a true understanding of the image we present a novel approach to ranking the importance of the item to be described specifically we focus on the task of discriminating one image from a group of others we investigate the factor that contribute to the most efficient description that achieves this task we also provide a quantitative method to measure the description quality for this specific task using data from human subject and show that our method achieves better result than baseline method 
we propose an on line algorithm to extract a human by foreground background segmentation and estimate pose of the human from the video captured by moving camera we claim that a virtuous cycle can be created by appropriate interaction between the two module to solve individual problem this joint estimation problem is divided into two sub problem foreground background segmentation and pose tracking which alternate iteratively for optimization segmentation step generates foreground mask for human pose tracking and human pose tracking step provides fore ground response map for segmentation the final solution is obtained when the iterative procedure converges we evaluate our algorithm quantitatively and qualitatively in real video involving various challenge and present it outstanding performance compared to the state of the art technique for segmentation and pose estimation 
we propose a novel model based method for estimating and tracking the six degree of freedom dof pose of rigid object of arbitrary shape in real time by combining dense motion and stereo cue with sparse key point correspondence and by feeding back information from the model to the cue extraction level the method is both highly accurate and robust to noise and occlusion a tight integration of the graphical and computational capability of graphic processing unit gpus result in pose update at frame rate exceeding hz since a benchmark dataset that enables the evaluation of stereo vision based pose estimator in complex scenario is currently missing in the literature we have introduced a novel synthetic benchmark dataset with varying object background motion noise and occlusion using this dataset and a novel evaluation methodology we show that the proposed method greatly outperforms state of the art method finally we demonstrate excellent performance on challenging real world sequence involving object manipulation 
contour are a powerful cue for semantic image understanding object and part of object in the image are delineated from their surrounding by closed contour which make up their boundary in this paper we introduce a new bottom up visual operator to capture the concept of closed contour which we call the torque operator it computation is inspired by the mechanical definition of torque or moment of force and applied to image edge the torque operator take a input edge and computes over region of different size a measure of how well the edge are aligned to form a closed convex contour we explore fundamental property of this measure and demonstrate that it can be made a useful tool for visual attention segmentation and boundary edge detection by verifying it benefit on these application 
the recognition of a place depicted in an image typically adopts method from image retrieval in large scale database first a query image is described a a bag of feature and compared to every image in the database second the most similar image are passed to a geometric verification stage however this is an inefficient approach when considering that some database image may be almost identical and many image feature may not repeatedly occur we address this issue by clustering similar database image to represent distinct scene and tracking local feature that are consistently detected to form a set of real world landmark query image are then matched to landmark rather than feature and a probabilistic model of landmark property is learned from the cluster to appropriately verify or reject putative feature match we present novelty in both a bag of feature retrieval and geometric verification stage based on this concept result on a database of k image of popular tourist destination show improvement in both recognition performance and efficiency compared to traditional image retrieval method 
acquiring dynamic d fluid surface is a challenging problem in computer vision single or stereo camera based solution are sensitive to refraction distortion fast fluid motion and calibration error in this paper we present a multi view based solution for robustly capturing fast evolving fluid wavefront we first construct a portable camera array system a the main acquisition device we elaborately design the system to allow high resolution and high speed capture to recover fluid surface we place a known pattern beneath the surface and position the camera array on top to observe the pattern by tracking the distorted feature point over time and across camera we obtain spatial temporal correspondence map and we use them for specular carving to reconstruct the time varying surface in case one of the camera loses track due to distortion or blur we use the rest of the camera to construct the surface and then apply multi perspective warping to locate the lost track feature point so that we can continue using the camera in later frame our experiment on synthetic and real data demonstrate that our multi view framework is robust and reliable 
this paper present recent work on a new framework for non blind document bleed through removal the framework includes image preprocessing to remove local intensity variation pixel region classification based on a segmentation of the joint recto verso intensity histogram and connected component analysis on the subsequent image labelling finally restoration of the degraded region is performed using exemplar based image in painting the proposed method is evaluated visually and numerically on a freely available database of scanned manuscript image pair with ground truth and is shown to outperform recent non blind bleed through removal technique 
in this paper we propose a new method for detecting multiple specific d object in real time we start from the template based approach based on the line d linemod representation introduced recently by hinterstoisser et al yet extend it in two way first we propose to learn the template in a discriminative fashion we show that this can be done online during the collection of the example image in just a few millisecond and ha a big impact on the accuracy of the detector second we propose a scheme based on cascade that speed up detection since detection of an object is fast new object can be added with very low cost making our approach scale well in our experiment we easily handle d object at frame rate above fps using a single cpu core we outperform the state of the art both in term of speed a well a in term of accuracy a validated on different datasets this hold both when using monocular color image with line d and when using rgbd image with linemod moreover we propose a challenging new dataset made of object for future competing method on monocular color image 
existing scene flow approach mainly focus on two frame stereo pair configuration and reconstruct an image based representation of scene flow instead we propose a variational formulation of scene flow relative to a coarse proxy geometry which is better suited for many view furthermore a linear basis is used to represent temporal surface flow allowing for longer range temporal correspondence with fewer variable our formulation take known proxy motion into account e g if the proxy is a tracked human subject which enables d trajectory reconstruction when only a single view is available additionally through the appropriate proxy and basis our framework generalizes existing approach for scene flow optic flow and two frame stereo we illustrate result on real data for both static and moving proxy surface over several frame 
this paper present a new adaptive graph cut based move making algorithm for energy minimization traditional move making algorithm such a expansion and swap operate by searching for better solution in some predefined move space around the current solution in contrast our algorithm us the primal dual interpretation of the expansion move algorithm to adaptively compute the best move space to search over at each step it try to greedily find the move space that will lead to biggest decrease in the primal dual gap we test different variant of our algorithm on a variety of image labelling problem such a object segmentation and stereo experimental result show that our adaptive strategy significantly outperforms the conventional expansion move algorithm in some case cutting the runtime by 
we address the problem of wide baseline registration of rgb d data such a photo textured laser scan without any artificial target or prediction on the relative motion our approach allows to fully automatically register scan taken in gps denied environment such a urban canyon industrial facility or even indoors we build upon image feature which are plenty localized well and much more discriminative than geometry feature however they suffer from viewpoint distortion and request for normalization we utilize the principle of salient direction present in the geometry and propose to extract several direction from the distribution of surface normal or other cue such a observable symmetry compared to previous work we pose no requirement on the scanned scene like containing large textured plane and can handle arbitrary surface shape rendering the whole scene from these repeatable direction using an orthographic camera generates texture which are identical up to d similarity transformation this ambiguity is naturally handled by d feature and allows to find stable correspondence among scan for geometric pose estimation from tentative match we propose a fast and robust point sample consensus scheme integrating an early rejection phase we evaluate our approach on different challenging real world scene 
recognizing the category of a visual object remains a challenging computer vision problem in this paper we develop a novel deep learning method that facilitates example based visual object category recognition our deep learning architecture consists of multiple stacked layer and computes an intermediate representation that can be fed to a nearest neighbor classifier this intermediate representation is discriminative and structure preserving it is also capable of extracting essential characteristic shared by object in the same category while filtering out nonessential difference among them each layer in our model is a nonlinear mapping whose parameter are learned through two sequential step that are designed to achieve the aforementioned property the first step computes a discrete mapping called supervised laplacian eigenmap the second step computes a continuous mapping from the discrete version through nonlinear regression we have extensively tested our method and it achieves state of the art recognition rate on a number of benchmark datasets 
recognizing face in unconstrained video is a task of mounting importance while obviously related to face recognition in still image it ha it own unique characteristic and algorithmic requirement over the year several method have been suggested for this problem and a few benchmark data set have been assembled to facilitate it study however there is a sizable gap between the actual application need and the current state of the art in this paper we make the following contribution a we present a comprehensive database of labeled video of face in challenging uncontrolled condition i e in the wild the youtube face database along with benchmark pair matching test b we employ our benchmark to survey and compare the performance of a large variety of existing video face recognition technique finally c we describe a novel set to set similarity measure the matched background similarity mbgs this similarity is shown to considerably improve performance on the benchmark test 
we propose a structured hough voting method for detecting object with heavy occlusion in indoor environment first we extend the hough hypothesis space to include both object location and it visibility pattern and design a new score function that accumulates vote for object detection and occlusion prediction in addition we explore the correlation between object and their environment building a depth encoded object context model based on rgb d data particularly we design a layered context representation and allow image patch from both object and background voting for the object hypothesis we demonstrate that using a data driven d representation we can learn visual codebooks with better quality and more interpretable detection result in term of spatial relationship between object and viewer we test our algorithm on two challenging rgb d datasets with significant occlusion and intraclass variation and demonstrate the superior performance of our method 
we propose a novel algorithm for video event detection and localization a the optimal path discovery problem in spatio temporal video space by finding the optimal spatio temporal path our method not only detects the starting and ending point of the event but also accurately locates it in each video frame moreover our method is robust to the scale and intra class variation of the event a well a false and missed local detection therefore improves the overall detection and localization accuracy the proposed search algorithm obtains the global optimal solution with proven lowest computational complexity experiment on realistic video datasets demonstrate that our proposed method can be applied to different type of event detection task such a abnormal event detection and walking pedestrian detection 
we present a dense reconstruction approach that overcomes the drawback of traditional multiview stereo by incorporating semantic information in the form of learned category level shape prior and object detection given training data comprised of d scan and image of object from various viewpoint we learn a prior comprised of a mean shape and a set of weighted anchor point the former capture the commonality of shape across the category while the latter encodes similarity between instance in the form of appearance and spatial consistency we propose robust algorithm to match anchor point across instance that enable learning a mean shape for the category even with large shape variation across instance we model the shape of an object instance a a warped version of the category mean along with instance specific detail given multiple image of an unseen instance we collate information from d object detector to align the structure from motion point cloud with the mean shape which is subsequently warped and refined to approach the actual shape extensive experiment demonstrate that our model is general enough to learn semantic prior for different object category yet powerful enough to reconstruct individual shape with large variation qualitative and quantitative evaluation show that our framework can produce more accurate reconstruction than alternative state of the art multiview stereo system 
markov random field play a central role in solving a variety of low level vision problem including denoising in painting segmentation and motion estimation much previous work wa based on mrfs with hand crafted network yet the underlying graphical structure is rarely explored in this paper we show that if appropriately estimated the mrf s graphical structure which capture significant information about appearance and motion can provide crucial guidance to low level vision task motivated by this observation we propose a principled framework to solve low level vision task via an exponential family of mrfs with variable structure which we call switchable mrfs the approach explicitly seek a structure that optimally adapts to the image or video along the pursuit of task specific goal through theoretical analysis and experimental study we demonstrate that the proposed method address a number of drawback suffered by previous method including failure to capture heavy tail statistic computational difficulty and lack of generality 
video based face recognition vfr can be converted to the matching of two image set containing face image captured from each video for this purpose we propose to bridge the two set with a reference image set that is well defined and pre structured to a number of local model offline in other word given two image set a long a each of them is aligned to the reference set they are mutually aligned and well structured therefore the similarity between them can be computed by comparing only the corresponded local model rather than considering all the pair to align an image set with the reference set we further formulate the problem a a quadratic programming it integrates three constrains to guarantee robust alignment including appearance matching cost term exploiting principal angle geometric structure consistency using affine invariant reconstruction weight smoothness constraint preserving local neighborhood relationship extensive experimental evaluation are performed on three database honda mobo and youtube compared with competing method our approach can consistently achieve better result 
we propose an unsupervised video segmentation approach by simultaneously tracking multiple holistic figure ground segment segment track are initialized from a pool of segment proposal generated from a figure ground segmentation algorithm then online non local appearance model are trained incrementally for each track using a multi output regularized least square formulation by using the same set of training example for all segment track a computational trick allows u to track hundred of segment track efficiently a well a perform optimal online update in closed form besides a new composite statistical inference approach is proposed for refining the obtained segment track which break down the initial segment proposal and recombines for better one by utilizing high order statistic estimate from the appearance model and enforcing temporal consistency for evaluating the algorithm a dataset segtrack v is collected with about frame with pixel level annotation the proposed framework outperforms state of the art approach in the dataset showing it efficiency and robustness to challenge in different video sequence 
an object detector must detect and localize each instance of the object class of interest in the image many recent detector adopt a sliding window approach reducing the problem to one of deciding whether the detection window currently contains a valid object instance or background machine learning based discriminants such a svm and boosting are typically used for this often in the form of classifier cascade to allow more rapid rejection of easy negative we argue that one class method one that focus mainly on modelling the range of the positive class are a useful alternative to binary discriminants in such application particularly in the early stage of the cascade where one class approach may allow simpler classifier and faster rejection we implement this in the form of a short cascade of efficient nearest convex model one class classifier starting with linear distance to affine hyperplane and interior of hypersphere classifier and finishing with kernelized hypersphere classifier we show that our method have very competitive performance on the face in the wild and esogu face detection datasets and state of the art performance on the inria person dataset a predicted the one class formulation provide significant reduction in classifier complexity relative to the corresponding two class one 
efficient keypoint based object detection method are used in many real time computer vision application these approach often model an object a a collection of keypoints and associated descriptor and detection then involves first constructing a set of correspondence between object and image keypoints via descriptor matching and subsequently using these correspondence a input to a robust geometric estimation algorithm such a ransac to find the transformation of the object in the image in such approach the object model is generally constructed offline and doe not adapt to a given environment at runtime furthermore the feature matching and transformation estimation stage are treated entirely separately in this paper we introduce a new approach to address these problem by combining the overall pipeline of correspondence generation and transformation estimation into a single structured output learning framework following the recent trend of using efficient binary descriptor for feature matching we also introduce an approach to approximate the learned object model a a collection of binary basis function which can be evaluated very efficiently at runtime experiment on challenging video sequence show that our algorithm significantly improves over state of the art descriptor matching technique using a range of descriptor a well a recent online learning based approach 
in this paper a new visual saliency detection method is proposed based on the spatially weighted dissimilarity we measured the saliency by integrating three element a follows the dissimilarity between image patch which were evaluated in the reduced dimensional space the spatial distance between image patch and the central bias the dissimilarity were inversely weighted based on the corresponding spatial distance a weighting mechanism indicating a bias for human fixation to the center of the image wa employed the principal component analysis pca wa the dimension reducing method used in our system we extracted the principal component pc by sampling the patch from the current image our method wa compared with four saliency detection approach using three image datasets experimental result show that our method outperforms current state of the art method on predicting human fixation 
to achieve a good trade off between recognition accuracy and computational efficiency it is often needed to reduce high dimensional visual data to medium dimensional one for this task even applying a simple full matrix based linear projection cause significant computation and memory use when the number of visual data is large how to efficiently learn such a projection could even become a problem the recent feature merging approach offer an efficient way to reduce the dimensionality which only requires a single scan of feature to perform reduction however existing merging algorithm do not scale well with high dimensional data especially in the unsupervised case to address this problem we formulate unsupervised feature merging a a pca problem imposed with a special structure constraint by exploiting it connection with k mean we transform this constrained pca problem into a feature clustering problem moreover we employ the hashing technique to improve it scalability these produce a scalable feature merging algorithm for our dimensionality reduction task in addition we develop an extension of this method by leveraging the neighborhood structure in the data to further improve dimensionality reduction performance in further we explore the incorporation of bipolar merging a variant of merging function which allows the subtraction operation into our algorithm through three application in visual recognition we demonstrate that our method can not only achieve good dimensionality reduction performance with little computational cost but also help to create more powerful representation at both image level and local feature level 
the problem of action recognition and human activity ha been an active research area in computer vision and robotics while full body motion can be characterized by movement and change of posture no characterization that hold invariance ha yet been proposed for the description of manipulation action we propose that a fundamental concept in understanding such action are the consequence of action there is a small set of fundamental primitive action consequence that provides a systematic high level classification of manipulation action in this paper a technique is developed to recognize these action consequence at the heart of the technique lie a novel active tracking and segmentation method that monitor the change in appearance and topological structure of the manipulated object these are then used in a visual semantic graph vsg based procedure applied to the time sequence of the monitored object to recognize the action consequence we provide a new dataset called manipulation action consequence mac which can serve a test bed for other study on this topic several experiment on this dataset demonstrates that our method can robustly track object and detect their deformation and division during the manipulation quantitative test prove the effectiveness and efficiency of the method 
specular flow is the motion field induced on the image plane by the movement of point reflected by a curved mirror like surface this flow provides information about surface shape and when the camera and surface move a a fixed pair shape can be recovered by solving linear differential equation along integral curve of flow previous analysis ha shown that two distinct motion i e two flow field are generally sufficient to guarantee a unique solution without externally provided initial condition in this work we show that we can often succeed with only one flow the key idea is to exploit the fact that smooth surface induce integrability constraint on the surface normal field we show that this induces a new differential equation that facilitates the propagation of shape information between integral curve of flow and that combining this equation with known method often permit the recovery of unique shape from a single specular flow given only a single seed point 
we propose a method for understanding the d geometry of indoor environment e g bedroom kitchen while simultaneously identifying object in the scene e g bed couch door we focus on how modeling the geometry and location of specific object is helpful for indoor scene understanding for example bed are shorter than they are wide and are more likely to be in the center of the room than cabinet which are tall and narrow we use a generative statistical model that integrates a camera model an enclosing room box frame window door picture and object bed table couch cabinet each with their own prior on size relative dimension and location we fit the parameter of this complex multi dimensional statistical model using an mcmc sampling approach that combine discrete change e g adding a bed and continuous parameter change e g making the bed larger we find that introducing object category lead to state of the art performance on room layout estimation while also enabling recognition based only on geometry 
in this paper we show how to train a deformable part model dpm fast typically in le than minute or four time faster than the current fastest method while maintaining high average precision on the pascal voc datasets at the core of our approach is latent lda a novel generalization of linear discriminant analysis for learning latent variable model unlike latent svm latent lda us efficient closed form update and doe not require an expensive search for hard negative example our approach also act a a springboard for a detailed experimental study of dpm training we isolate and quantify the impact of key training factor for the first time e g how important are discriminative svm filter how important is joint parameter estimation how many negative image are needed for training our finding yield useful insight for researcher working with markov random field and part based model and have practical implication for speeding up task such a model selection 
in this paper we introduce a new shape driven approach for object segmentation given a training set of shape we first use deep boltzmann machine to learn the hierarchical architecture of shape prior this learned hierarchical architecture is then used to model shape variation of global and local structure in an energetic form finally it is applied to data driven variational method to perform object extraction of corrupted data based on shape probabilistic representation experiment demonstrate that our model can be applied to dataset of arbitrary prior shape and can cope with image noise and clutter a well a partial occlusion 
this paper present a novel locality sensitive histogram algorithm for visual tracking unlike the conventional image histogram that count the frequency of occurrence of each intensity value by adding one to the corresponding bin a locality sensitive histogram is computed at each pixel location and a floating point value is added to the corresponding bin for each occurrence of an intensity value the floating point value decline exponentially with respect to the distance to the pixel location where the histogram is computed thus every pixel is considered but those that are far away can be neglected due to the very small weight assigned an efficient algorithm is proposed that enables the locality sensitive histogram to be computed in time linear in the image size and the number of bin a robust tracking framework based on the locality sensitive histogram is proposed which consists of two main component a new feature for tracking that is robust to illumination change and a novel multi region tracking algorithm that run in real time even with hundred of region extensive experiment demonstrate that the proposed tracking framework outperforms the state of the art method in challenging scenario especially when the illumination change dramatically 
object segmentation need to be driven by top down knowledge to produce semantically meaningful result in this paper we propose a supervised segmentation approach that tightly integrates object level top down information with low level image cue the information from the two level is fused under a kernelized structural svm learning framework we defined a novel nonlinear kernel for comparing two image segmentation mask this kernel combine four different kernel the object similarity kernel the object shape kernel the per image color distribution kernel and the global color distribution kernel our experiment show that the structured svm algorithm find bad segmentation of the training example given the current scoring function and punishes these bad segmentation to lower score than the example good segmentation the result is a segmentation algorithm that not only know what good segmentation are but also learns potential segmentation mistake and try to avoid them our proposed approach can obtain comparable performance to other state of the art top down driven segmentation approach yet is flexible enough to be applied to widely different domain 
this paper proposes modeling the complex web image collection with an automatically generated graph structure called visual semantic complex network vscn the node on this complex network are cluster of image with both visual and semantic consistency called semantic concept these node are connected based on the visual and semantic correlation our vscn with concept is generated from a collection of million web image a great deal of valuable information on the structure of the web image collection can be revealed by exploring the vscn such a the small world behavior concept community in degree distribution hub and isolated concept it not only help u better understand the web image collection at a macroscopic level but also ha many important practical application this paper present two application example content based image retrieval and image browsing experimental result show that the vscn lead to significant improvement on both the precision of image retrieval over and user experience for image browsing 
method of interacting with stereo image pair are important for handling the increasing amount of stereoscopic d data now being produced in this paper we introduce a framework for interactively selecting object in two stereo image simultaneously using graph cut a key contribution of our method is the use of stereo correspondence probability distribution to govern the strength of the connection between the two image this allows information from arbitrary stereo matching algorithm to be utilized by our method we show how to enforce consistency in these distribution to improve the result for comparison we introduce a new dataset of stereo image and ground truth selection we evaluate different correspondence distribution and show that our method is effective in selecting object from stereo pair 
we present a robust and efficient technique for matching dense set of point undergoing non rigid spatial transformation our main intuition is that the subset of point that can be matched with high confidence should be used to guide the matching procedure for the rest we propose a novel algorithm that incorporates these high confidence match a a spatial prior to learn a discriminative subspace that simultaneously encodes both the feature similarity a well a their spatial arrangement conventional subspace learning usually requires spectral decomposition of the pair wise distance matrix across the point set which can become inefficient even for moderately sized problem to this end we propose the use of random projection for approximate subspace learning which can provide significant time improvement at the cost of minimal precision loss this efficiency gain allows u to iteratively find and remove high confidence match from the point set resulting in high recall to show the effectiveness of our approach we present a systematic set of experiment and result for the problem of dense non rigid image feature matching 
the problem of adaptively selecting pooling region for the classification of complex video event is considered complex event are defined a event composed of several characteristic behavior whose temporal configuration can change from sequence to sequence a dynamic pooling operator is defined so a to enable a unified solution to the problem of event specific video segmentation temporal structure modeling and event detection video is decomposed into segment and the segment most informative for detecting a given event are identified so a to dynamically determine the pooling operator most suited for each sequence this dynamic pooling is implemented by treating the location of characteristic segment a hidden information which is inferred on a sequence by sequence basis via a large margin classification rule with latent variable although the feasible set of segment selection is combinatorial it is shown that a globally optimal solution to the inference problem can be obtained efficiently through the solution of a series of linear program besides the coarse level location of segment a finer model of video structure is implemented by jointly pooling feature of segment tuples experimental evaluation demonstrates that the resulting event detector ha state of the art performance on challenging video datasets 
in this paper we address the task of tracking group of people in surveillance scenario this is a major challenge in computer vision since group are structured entity subjected to repeated split and merge event our solution is a joint individual group tracking framework inspired by a recent technique dubbed decentralized particle filtering the proposed strategy factorizes the joint individual group state space in two dependent subspace where individual and group share the knowledge of the joint individual group distribution in practice we establish a tight relation of mutual support between the modeling of individual and that of group promoting the idea that group are better tracked if individual are considered and viceversa extensive experiment on a published and novel dataset validate our intuition opening up to many future development 
representative data in term of a set of selected sample is of interest for various machine learning application e g dimensionality reduction and classification the best known technique probably still are k nearest neighbor knn and it variant recently richer representation have become popular example are method based on l regularized least square sparse representation sr or l regularized least square collaborative representation cr or on l constrained least square local linear embedding lle we propose iterative nearest neighbor inn this is a novel sparse representation that combine the power of sr and lle with the computational simplicity of knn we test our method in term of dimensionality reduction and classification using standard benchmark such a face ar traffic sign gtsrb and pascal voc inn performs better than nn and comparable with cr and sr while being order of magnitude faster than the latter 
distance metric learning play an important role in many vision problem previous work of quadratic mahalanobis metric learning usually need to solve a semidefinite programming sdp problem a standard interior point sdp solver ha a complexity of o d with d the dimension of input data and can only solve problem up to a few thousand variable since the number of variable is d d l this corresponds to a limit around d this high complexity hamper the application of metric learning to high dimensional problem in this work we propose a very efficient approach to this metric learning problem we formulate a lagrange dual approach which is much simpler to optimize and we can solve much larger mahalanobis metric learning problem roughly the proposed approach ha a time complexity of o t d with t for most problem in our experiment the proposed algorithm is scalable and easy to implement experiment on various datasets show it similar accuracy compared with state of the art we also demonstrate that this idea may also be able to be applied to other sdp problem such a maximum variance unfolding 
we present a novel approach to improving subspace clustering by exploiting the spatial constraint the new method encourages the sparse solution to be consistent with the spatial geometry of the tracked point by embedding weight into the sparse formulation by doing so we are able to correct sparse representation in a principled manner without introducing much additional computational cost we discus alternative way to treat the missing and corrupted data using the latest theory in robust lasso regression and suggest numerical algorithm so solve the proposed formulation the experiment on the benchmark john hopkins dataset demonstrate that exploiting spatial constraint significantly improves motion segmentation 
active range acquisition system such a light detection and ranging lidar and time of flight tof camera achieve high depth resolution but suffer from poor spatial resolution in this paper we introduce a new range acquisition architecture that doe not rely on scene raster scanning a in lidar or on a two dimensional array of sensor a used in tof camera instead we achieve spatial resolution through patterned sensing of the scene using a digital micromirror device dmd array our depth map reconstruction us parametric signal modeling to recover the set of distinct depth range present in the scene then using a convex program that exploit the sparsity of the laplacian of the depth map we recover the spatial content at the estimated depth range in our experiment we acquired pixel depth map of fronto parallel scene at range up to m using a pulsed laser a dmd array and a single photon counting detector we also demonstrated imaging in the presence of unknown partially transmissive occluders the prototype and result provide promising direction for non scanning low complexity range acquisition device for various computer vision application 
the proposed approach is based on standard graph transduction semi supervised learning ssl framework it key novelty is the integration of global connectivity constraint into this framework although connectivity lead to higher order constraint and their number is an exponential finding the most violated connectivity constraint can be done efficiently in polynomial time moreover each such constraint can be represented a a linear inequality based on this fact we design a cutting plane algorithm to solve the integrated problem it iterates between solving a convex quadratic problem of label propagation with linear inequality constraint and finding the most violated constraint we demonstrate the benefit of the proposed approach on a realistic and very challenging problem of co segmentation of multiple foreground object in photo collection in which the foreground object are not present in all photo the obtained result not only demonstrate performance boost induced by the connectivity constraint but also show a significant improvement over the state of the art method 
in this paper we propose a robust distracter resistant tracking approach by learning a discriminative metric that adaptively learns the importance of feature on the fly the proposed metric is elaborately designed for the tracking problem by forming a margin objective function which systematically includes distance margin maximization and reconstruction error constraint that act a a force to push distracters away from the positive space and into the negative space due to the variety of negative sample in the tracking problem we specifically introduce the similarity propagation technique that give distracters a second force from the negative space consequently the discriminative metric obtained help to preserve the most discriminative information to separate the target from distracters while ensuring the stability of the optimal metric we seamlessly combine it with the popular l minimization tracker our tracker is therefore not only resistant to distracters but also inherits the merit of occlusion robustness from the l tracker quantitative comparison with several state of the art algorithm have been conducted in many challenging video sequence the result show that our method resists distracters excellently and achieves superior performance 
natural image are known to carry several distinct property which are not shared with randomly generated image in this article we utilize the scale invariant property of natural image to construct a filter which extract feature invariant to illumination condition in contrast to most of the existing method which assume that such feature lie in high frequency part of spectrum by analyzing the power spectrum of natural image we show that some of these feature could lie in low frequency part a well from this fact we derive a wiener filter approach to best separate the illumination invariant feature from an image we also provide a linear time algorithm for our proposed wiener filter which only involves solving linear equation with narrowly banded matrix our experiment on variable lighting face recognition show that our proposed method doe achieve the best recognition rate and is generally faster compared to the state of the art method 
with the rise in popularity of digital camera the amount of visual data available on the web is growing exponentially some of these picture are extremely beautiful and aesthetically pleasing but the vast majority are uninteresting or of low quality this paper demonstrates a simple yet powerful method to automatically select high aesthetic quality image from large image collection our aesthetic quality estimation method explicitly predicts some of the possible image cue that a human might use to evaluate an image and then us them in a discriminative approach these cue or high level describable image attribute fall into three broad type compositional attribute related to image layout or configuration content attribute related to the object or scene type depicted and sky illumination attribute related to the natural lighting condition we demonstrate that an aesthetic classifier trained on these describable attribute can provide a significant improvement over baseline method for predicting human quality judgment we also demonstrate our method for predicting the interestingness of flickr photo and introduce a novel problem of estimating query specific interestingness 
layered model provide a compelling approach for estimating image motion and segmenting moving scene previous method however have failed to capture the structure of complex scene provide precise object boundary effectively estimate the number of layer in a scene or robustly determine the depth order of the layer furthermore previous method have focused on optical flow between pair of frame rather than longer sequence we show that image sequence with more frame are needed to resolve ambiguity in depth ordering at occlusion boundary temporal layer constancy make this feasible our generative model of image sequence is rich but difficult to optimize with traditional gradient descent method we propose a novel discrete approximation of the continuous objective in term of a sequence of depth ordered mrfs and extend graph cut optimization method with new move that make joint layer segmentation and motion estimation feasible our optimizer which mix discrete and continuous optimization automatically determines the number of layer and reason about their depth ordering we demonstrate the value of layered model our optimization strategy and the use of more than two frame on both the middlebury optical flow benchmark and the mit layer segmentation benchmark 
due to it simplicity the eight point algorithm ha been widely used in fundamental matrix estimation unfortunately the rank constraint of a fundamental matrix is enforced via a posterior rank correction step thus leading to non optimal solution to the original problem to address this drawback existing algorithm need to solve either a very high order polynomial or a sequence of convex relaxation problem both of which are computationally ineffective and numerically unstable in this work we present a new rank constrained eight point algorithm which directly incorporates the rank constraint in the minimization process to avoid singularity we propose to solve seven sub problem and retrieve their globally optimal solution by using tailored polynomial system solver our proposed method is noniterative computationally efficient and numerically stable experiment result have verified it superiority over existing algebraic error based algorithm in term of accuracy a well a it advantage when used to initialize geometric error based algorithm 
we present a novel multi class classifier that strike a balance between the nearest subspace classifier which assigns a test sample to the class that minimizes the distance between the test sample and it principal projection in the selected class and a collaborative representation based classifier which classifies a sample to the class that minimizes the distance between the collaborative component of the test sample by using all training sample from all class a the dictionary and it projection in the selected class in our formulation the sparse representation based classifier and nearest subspace classifier become special case under different regularization parameter we show that the classification performance can be improved by optimally tuning the regularization parameter which can be done at almost no extra computational cost we give extensive numerical example for digit identification and face recognition with performance comparison of different choice of collaborative representation in particular when only a partial observation of the test sample is available via compressive sensing measurement 
we propose a novel dictionary based learning method for ambiguously labeled multiclass classification where each training sample ha multiple label and only one of them is the correct label the dictionary learning problem is solved using an iterative alternating algorithm at each iteration of the algorithm two alternating step are performed a confidence update and a dictionary update the confidence of each sample is defined a the probability distribution on it ambiguous label the dictionary are updated using either soft em based or hard decision rule extensive evaluation on existing datasets demonstrate that the proposed method performs significantly better than state of the art ambiguously labeled learning approach 
in this paper we propose a graph based method for d vessel tree structure segmentation based on a new tubularity markov tree model tmt which work a both new energy function and graph construction method with the help of power watershed implementation a global optimal segmentation can be obtained with low computational cost different with other graph based vessel segmentation method the proposed method doe not depend on any skeleton and roi extraction method the classical issue of the graph based method such a shrinking bias and sensitivity to seed point location can be solved with the proposed method thanks to vessel data fidelity obtained with tmt the proposed method is compared with some classical graph based image segmentation method and two up to date d vessel segmentation method and is demonstrated to be more accurate than these method for d vessel tree segmentation although the segmentation is done without roi extraction the computational cost for the proposed method is low within second for image 
the goal of object category discovery is to automatically identify group of image region which belong to some new previously unseen category this task is typically performed in a purely unsupervised setting and a a result performance depends critically upon accurate assessment of similarity between unlabeled image region to improve the accuracy of category discovery we develop a novel multiple kernel learning algorithm based on structural svm which optimizes a similarity space for nearest neighbor prediction the optimized space is then used to cluster unlabeled data and identify new category experimental result on the msrc and pascal voc data set indicate that using an optimized similarity metric can improve clustering for category discovery furthermore we demonstrate that including both labeled and unlabeled training data when optimizing the similarity metric can improve the overall quality of the system 
we present a novel approach to non rigid object tracking based on a supervised level set model slsm in contrast with conventional level set model which emphasize the intensity consistency only and consider no prior the curve evolution of the proposed slsm is object oriented and supervised by the specific knowledge of the target we want to track therefore the slsm can ensure a more accurate convergence to the target in tracking application in particular we firstly construct the appearance model for the target in an on line boosting manner due to it strong discriminative power between object and background then the probability of the contour is modeled by considering both the region and edge cue in a bayesian manner leading the curve converge to the candidate region with maximum likelihood of being the target finally accurate target region qualifies the sample fed the boosting procedure a well a the target model prepared for the next time step positive decrease rate is used to adjust the learning pace over time enabling tracking to continue under partial and total occlusion experimental result on a number of challenging sequence validate the effectiveness of the technique 
face recognition with large pose and illumination variation is a challenging problem in computer vision this paper address this challenge by proposing a new learning based face representation the face identity preserving fip feature unlike conventional face descriptor the fip feature can significantly reduce intra identity variance while maintaining discriminative ness between identity moreover the fip feature extracted from an image under any pose and illumination can be used to reconstruct it face image in the canonical view this property make it possible to improve the performance of traditional descriptor such a lbp and gabor which can be extracted from our reconstructed image in the canonical view to eliminate variation in order to learn the fip feature we carefully design a deep network that combine the feature extraction layer and the reconstruction layer the former encodes a face image into the fip feature while the latter transforms them to an image in the canonical view extensive experiment on the large multipie face database demonstrate that it significantly outperforms the state of the art face recognition method 
the archetype hull model is playing an important role in large scale data analytics and mining but rarely applied to vision problem in this paper we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework upon a scalable graph characterized by a compact set of archetype exemplar whose convex hull encompasses most of the training image the proposed framework explicitly capture the relevance between any query and the stored archetype yielding a rank vector over the archetype hull the archetype hull ranking is then executed for every block of face image to generate a block wise similarity measure that is achieved by comparing two different rank vector with respect to the same archetype hull after integrating block wise similarity measurement with learned importance weight we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification we evaluate the face similarity measure in term of experiment performed on three benchmark face database multi pie pubfig and lfw demonstrating it performance superior to the state of the art 
when face image are taken in the wild the large variation in facial pose illumination and expression make face recognition challenging the most fundamental problem for face recognition is to measure the similarity between face the traditional measurement such a various mathematical norm hausdorff distance and approximate geodesic distance cannot accurately capture the structural information between face in such complex circumstance to address this issue we develop a novel face patch network based on which we define a new similarity measure called the random path rp measure the rp measure is derived from the collective similarity of path by performing random walk in the network it can globally characterize the contextual and curved structure of the face space to apply the rp measure we construct two kind of network the in face network and the out face network the in face network is drawn from any two face image and capture the local structural information the out face network is constructed from all the training face patch thereby modeling the global structure of face space the two face network are structurally complementary and can be combined together to improve the recognition performance experiment on the multi pie and lfw benchmark show that the rp measure outperforms most of the state of art algorithm for face recognition 
passively estimating the intrinsic material property of deformable object moving in a natural environment is essential for scene understanding we present a framework to automatically analyze video of fabric moving under various unknown wind force and recover two key material property of the fabric stiffness and area weight we extend feature previously developed to compactly represent static image texture to describe video texture such a fabric motion a discriminatively trained regression model is then used to predict the physical property of fabric from these feature the success of our model is demonstrated on a new publicly available database of fabric video with corresponding measured ground truth material property we show that our prediction are well correlated with ground truth measurement of stiffness and density for the fabric our contribution include a a database that can be used for training and testing algorithm for passively predicting fabric property from video b an algorithm for predicting the material property of fabric from a video and c a perceptual study of human ability to estimate the material property of fabric from video and image 
image denoising can be described a the problem of mapping from a noisy image to a noise free image the best currently available denoising method approximate this mapping with cleverly engineered algorithm in this work we attempt to learn this mapping directly with a plain multi layer perceptron mlp applied to image patch while this ha been done before we will show that by training on large image database we are able to compete with the current state of the art image denoising method furthermore our approach is easily adapted to le extensively studied type of noise by merely exchanging the training data for which we achieve excellent result a well 
in this paper we propose a novel framework for contour based object detection compared to previous work our contribution is three fold a novel shape matching scheme suitable for partial matching of edge fragment the shape descriptor ha the same geometric unit a shape context but our shape representation is not histogram based grouping of partial matching hypothesis to object detection hypothesis is expressed a maximum clique inference on a weighted graph a novel local affine transformation to utilize the holistic shape information for scoring and ranking the shape similarity hypothesis consequently each detection result not only identifies the location of the target object in the image but also provides a precise location of it contour since we transform a complete model contour to the image very competitive result on ethz dataset obtained in a pure shape based framework demonstrate that our method achieves not only accurate object detection but also precise contour localization on cluttered background 
d reconstruction from an unordered set of image may fail due to incorrect epipolar geometry eg between image pair arising from ambiguous feature correspondence previous method often analyze the consistency between different egs and regard the largest subset of self consistent egs a correct however a demonstrated in such a largest self consistent set often corresponds to incorrect result especially when there are duplicate structure in the scene we propose a novel optimization criterion based on the idea of missing correspondence the global minimum of our optimization objective function is associated with the correct solution we then design an efficient algorithm for minimization whose convergence to a local minimum is guaranteed experimental result show our method outperforms the state of the art 
we propose an unsupervised learning framework to infer motion pattern in video and in turn use them to improve tracking of moving object in sequence from static camera based on tracklets we use a manifold learning method tensor voting to infer the local geometric structure in x y space and embed tracklet point into x y space where represents motion direction in this space point automatically form intrinsic manifold structure each of which corresponds to a motion pattern to define each group a novel robustmanifold grouping algorithm is proposed tensor voting is performed to provide multiple geometric cue which formulate multiple similarity kernel between any pair of point and a spectral clustering technique is used in this multiple kernel setting the grouping algorithm achieves better performance than state of the art method in our application extracted motion pattern can then be used a a prior to improve the performance of any object tracker it is especially useful to reduce false alarm and id switch experiment are performed on challenging real world sequence and a quantitative analysis of the result show the framework effectively improves state of the art tracker 
there are a huge number of video with text tag on the web nowadays in this paper we propose a method of automatically extracting from web video video shot corresponding to specific action with just only providing action keywords such a walking and eating the proposed method consists of three step tag based video selection segmenting video into shot and extracting feature from the shot and visual feature based video shot selection with tag based score taken into account firstly we gather video id and tag list for web video corresponding to given keywords via web api and we calculate tag relevance score for each video using a tag co occurrence dictionary which is constructed in advance secondly we fetch the top video from the web in the descending order of the tag relevance score and segment each downloaded video into several shot from each shot we extract spatio temporal feature global motion feature and appearance feature and convert them into the bag of feature representation finally we apply the visualrank method to select the video shot which describe the action corresponding to the given keywords best after calculating a similarity matrix between video shot in the experiment we achieved the precision at shot over six kind of human action by just providing keywords without any supervision in addition we made large scale experiment on kind of action keywords 
cross modal matching ha recently drawn much attention due to the widespread existence of multimodal data it aim to match data from different modality and generally involves two basic problem the measure of relevance and coupled feature selection most previous work mainly focus on solving the first problem in this paper we propose a novel coupled linear regression framework to deal with both problem our method learns two projection matrix to map multimodal data into a common feature space in which cross modal data matching can be performed and in the learning procedure the ell norm penalty are imposed on the two projection matrix separately which lead to select relevant and discriminative feature from coupled feature space simultaneously a trace norm is further imposed on the projected data a a low rank constraint which enhances the relevance of different modal data with connection we also present an iterative algorithm based on half quadratic minimization to solve the proposed regularized linear regression problem the experimental result on two challenging cross modal datasets demonstrate that the proposed method outperforms the state of the art approach 
we propose a novel formulation to express the attachment of a polygonal surface to a skeleton using purely linear term this enables to simultaneously adapt the pose and shape of an articulated model in an efficient way our work is motivated by the difficulty to constrain a mesh when adapting it to multi view silhouette image however such an adaption is essential when capturing the detailed temporal evolution of skin and clothing of a human actor without marker while related work is only able to ensure surface consistency during mesh adaption our coupled optimization of the skeleton creates structural stability and minimizes the sensibility to occlusion and outlier in input image we demonstrate the benefit of our approach in an extensive evaluation the skeleton attachment considerably reduces implausible deformation especially when the number of input view is limited 
in this paper the face recognition problem is addressed in a part based sparse approach through the comparison of respective facial region between different image to this purpose a sparse coding procedure is applied to non overlapping patch derived from frontal face image in order to extract local facial information an adequate measure is introduced incorporating the resulted sparse representation along with the hamming distance in order to express pairwise similarity between face finally a simple nearest neighbor classifier is employed to determine the identity of each facial image in addition a new criterion is presented for the rejection of outlier the emerged face recognition scheme is evaluated using publicly available facial image database and the result are compared with those of other well established recognition method 
we propose an integer programming method for estimating the instantaneous count of pedestrian crossing a line of interest in a video sequence through a line sampling process the video is first converted into a temporal slice image next the number of people is estimated in a set of overlapping sliding window on the temporal slice image using a regression function that map from local feature to a count given that count in a sliding window is the sum of the instantaneous count in the corresponding time interval an integer programming method is proposed to recover the number of pedestrian crossing the line of interest in each frame integrating over a specific time interval yield the cumulative count of pedestrian crossing the line compared with current method for line counting our proposed approach achieves state of the art performance on several challenging crowd video datasets 
in this work we address the problem of human parsing namely partitioning the human body into semantic region by using the novel parse let representation previous work often consider solving the problem of human pose estimation a the prerequisite of human parsing we argue that these approach cannot obtain optimal pixel level parsing due to the inconsistent target between these task in this paper we propose to use parse let a the building block of our parsing model parse let are a group of parsable segment which can generally be obtained by low level over segmentation algorithm and bear strong semantic meaning we then build a deformable mixture parsing model dmpm for human parsing to simultaneously handle the deformation and multi modality of parse let the proposed model ha two unique characteristic the possible numerous modality of parse let ensemble are exhibited a the and or structure of sub tree to further solve the practical problem of parse let occlusion or absence we directly model the visibility property at some leaf node the dmpm thus directly solves the problem of human parsing by searching for the best graph configuration from a pool of parse let hypothesis without intermediate task comprehensive evaluation demonstrate the encouraging performance of the proposed approach 
principal component analysis pca is a widely used to learn a low dimensional representation in many application both vector data x and graph data w are available laplacian embedding is widely used for embedding graph data we propose a graph laplacian pca glpca to learn a low dimensional representation of x that incorporates graph structure encoded in w this model ha several advantage it is a data representation model it ha a compact closed form solution and can be efficiently computed it is capable to remove corruption extensive experiment on datasets show promising result on image reconstruction and significant improvement on clustering and classification 
we describe a mid level approach for action recognition from an input video we extract salient spatio temporal structure by forming cluster of trajectory that serve a candidate for the part of an action the assembly of these cluster into an action class is governed by a graphical model that incorporates appearance and motion constraint for the individual part and pairwise constraint for the spatio temporal dependency among them during training we estimate the model parameter discriminatively during classification we efficiently match the model to a video using discrete optimization we validate the model s classification ability in standard benchmark datasets and illustrate it potential to support a fine grained analysis that not only give a label to a video but also identifies and localizes it constituent part 
stereo visual odometry and dense scene reconstruction depend critically on accurate calibration of the extrinsic relative stereo camera pose we present an algorithm for continuous online stereo extrinsic re calibration operating only on sparse stereo correspondence on a per frame basis we obtain the degree of freedom extrinsic pose for each frame with a fixed baseline making it possible to model time dependent variation the initial extrinsic estimate are found by minimizing epipolar error and are refined via a kalman filter kf observation covariance are derived from the cr mer rao lower bound of the solution uncertainty the algorithm operates at frame rate with unoptimized matlab code with over correspondence per frame we validate it performance using a variety of real stereo datasets and simulation 
for the task of visual categorization the learning model is expected to be endowed with discriminative visual feature representation and flexibility in processing many category many existing approach are designed based on a flat category structure or rely on a set of pre computed visual feature hence may not be appreciated for dealing with large number of category in this paper we propose a novel dictionary learning method by taking advantage of hierarchical category correlation for each internode of the hierarchical category structure a discriminative dictionary and a set of classification model are learnt for visual categorization and the dictionary in different layer are learnt to exploit the discriminative visual property of different granularity moreover the dictionary in lower level also inherit the dictionary of ancestor node so that category in lower level are described with multi scale visual information using our dictionary learning approach experiment on image net object data subset and sun scene dataset demonstrate that our approach achieves promising performance on data with large number of class compared with some state of the art method and is more efficient in processing large number of category 
we present a unified model for face detection pose estimation and landmark estimation in real world cluttered image our model is based on a mixture of tree with a shared pool of part we model every facial landmark a a part and use global mixture to capture topological change due to viewpoint we show that tree structured model are surprisingly effective at capturing global elastic deformation while being easy to optimize unlike dense graph structure we present extensive result on standard face benchmark a well a a new in the wild annotated dataset that suggests our system advance the state of the art sometimes considerably for all three task though our model is modestly trained with hundred of face it compare favorably to commercial system trained with billion of example such a google picasa and face com 
metric learning method for person re identification estimate a scaling for distance in a vector space that is optimized for picking out observation of the same individual this paper present a novel approach to the pedestrian re identification problem that us metric learning to improve the state of the art performance on standard public datasets very high dimensional feature are extracted from the source color image a first processing stage performs unsupervised pca dimensionality reduction constrained to maintain the redundancy in color space representation a second stage further reduces the dimensionality using a local fisher discriminant analysis defined by a training set a regularization step is introduced to avoid singular matrix during this stage the experiment conducted on three publicly available datasets confirm that the proposed method outperforms the state of the art performance including all other known metric learning method further more the method is an effective way to process observation comprising multiple shot and is non iterative the computation time are relatively modest finally a novel statistic is derived to characterize the match characteristic the normalized entropy reduction can be used to define the proportion of uncertainty removed pur this measure is invariant to test set size and provides an intuitive indication of performance 
automatic facial action unit au detection from video is a long standing problem in facial expression analysis au detection is typically posed a a classification problem between frame or segment of positive example and negative one where existing work emphasizes the use of different feature or classifier in this paper we propose a method called cascade of task cot that combine the use of different task i e frame segment and transition for au event detection we train cot in a sequential manner embracing diversity which ensures robustness and generalization to unseen data in addition to conventional frame based metric that evaluate frame independently we propose a new event based metric to evaluate detection performance at event level we show how the cot method consistently outperforms state of the art approach in both frame based and event based metric across three public datasets that differ in complexity ck fera and ru facs 
this paper present a novel learning framework for training boosting cascade based object detector from large scale dataset the framework is derived from the well known viola jones vj framework but distinguished by three key difference first the proposed framework adopts multi dimensional surf feature instead of single dimensional haar feature to describe local patch in this way the number of used local patch can be reduced from hundred of thousand to several hundred second it adopts logistic regression a weak classifier for each local patch instead of decision tree in the vj framework third we adopt auc a a single criterion for the convergence test during cascade training rather than the two trade off criterion false positive rate and hit rate in the vj framework the benefit is that the false positive rate can be adaptive among different cascade stage and thus yield much faster convergence speed of surf cascade combining these point together the proposed approach ha three good property first the boosting cascade can be trained very efficiently experiment show that the proposed approach can train object detector from billion of negative sample within one hour even on personal computer second the built detector is comparable to the state of the art algorithm not only on the accuracy but also on the processing speed third the built detector is small in model size due to short cascade stage 
non rigid structure from motion is a fundamental problem in computer vision which is yet to be solved satisfactorily the main difficulty of the problem lie in choosing the right constraint for the solution in this paper we propose new constraint that are more effective for non rigid shape recovery unlike the other proposal which have mainly focused on restricting the deformation space using rank constraint our proposal constrains the motion parameter so that the d shape are most closely aligned to each other which make the rank constraint unnecessary based on these constraint we define a new class of probability distribution called the procrustean normal distribution and propose a new nrsfm algorithm em pnd the experimental result show that the proposed method outperforms the existing method and it work well even if there is no temporal dependence between the observed sample 
structured light range sensor such a the microsoft kinect have recently become popular a perception device for computer vision and robotic system these sensor use cmos imaging chip with electronic rolling shutter er when using such a sensor on a moving platform both the image and the depth map will exhibit geometric distortion we introduce an algorithm that can suppress such distortion by rectifying the d point cloud from the range sensor this is done by first estimating the time continuous d camera trajectory and then transforming the d point to where they would have been if the camera had been stationary to ensure that image and range data are synchronous the camera trajectory is computed from klt track on the structured light frame after suppressing the structured light pattern we evaluate our rectification by measuring angle between the visible side of a cube before and after rectification we also measure how much better the d point cloud can be aligned after rectification the obtained improvement is also related to the actual rotational velocity measured using a mem gyroscope 
offline tracking of visual object is particularly helpful in the presence of significant occlusion when a frame by frame causal tracker is likely to lose sight of the target in addition the trajectory found by offline tracking are typically smoother and more stable because of the global optimization this approach entail in contrast with previous work we show that this global optimization can be performed in o mnt time for t frame of video at m n resolution with the help of the generalized distance transform developed by felzenszwalb and huttenlocher recognizing the importance of this distance transform we extend the computation to a more general lower envelope algorithm in certain heterogeneous l distance metric space the generalized lower envelope algorithm is of complexity o mn m n and is useful for a more challenging offline tracking problem experiment show that trajectory found by offline tracking are superior to those computed by online tracking method and are computed at frame per second 
in this paper we propose a novel perception based shape decomposition method which aim to decompose a shape into semantically meaningful part in addition to three popular perception rule the minimum rule the short cut rule and the convexity rule in shape decomposition we propose a new rule named part similarity rule to encourage consistent partition of similar part the problem is formulated a a quadratic ally constrained quadratic program qcqp problem and is solved by a trust region method experiment result on mpeg dataset show that we can get a more consistent shape decomposition with human perception compared with other state of the art method both qualitatively and quantitatively finally we show the advantage of semantic part over non meaningful part in object detection on the ethz dataset 
we couple occlusion modeling and multi frame motion estimation to compute dense temporally extended point trajectory in video with significant occlusion our approach combine robust spatial regularization with spatially and temporally global occlusion labeling in a variational lagrangian framework with subspace constraint we track point even through ephemeral occlusion experiment demonstrate accuracy superior to the state of the art while tracking more point through more frame 
we present a real time approach for image based localization within large scene that have been reconstructed offline using structure from motion sfm from monocular video our method continuously computes a precise dof camera pose by efficiently tracking natural feature and matching them to d point in the sfm point cloud our main contribution lie in efficiently interleaving a fast keypoint tracker that us inexpensive binary feature descriptor with a new approach for direct d to d matching the d to d matching avoids the need for online extraction of scale invariant feature instead offline we construct an indexed database containing multiple daisy descriptor per d point extracted at multiple scale the key to the efficiency of our method lie in invoking daisy descriptor extraction and matching sparingly during localization and in distributing this computation over a window of successive frame this enables the algorithm to run in real time without fluctuation in the latency over long duration we evaluate the method in large indoor and outdoor scene our algorithm run at over hz on a laptop and at hz on a low power mobile computer suitable for onboard computation on a quadrotor micro aerial vehicle 
we present a real time approach for image based localization within large scene that have been reconstructed offline using structure from motion sfm from monocular video our method continuously computes a precise dof camera pose by efficiently tracking natural feature and matching them to d point in the sfm point cloud our main contribution lie in efficiently interleaving a fast keypoint tracker that us inexpensive binary feature descriptor with a new approach for direct d to d matching the d to d matching avoids the need for online extraction of scale invariant feature instead offline we construct an indexed database containing multiple daisy descriptor per d point extracted at multiple scale the key to the efficiency of our method lie in invoking daisy descriptor extraction and matching sparingly during localization and in distributing this computation over a window of successive frame this enables the algorithm to run in real time without fluctuation in the latency over long duration we evaluate the method in large indoor and outdoor scene our algorithm run at over hz on a laptop and at hz on a low power mobile computer suitable for onboard computation on a quadrotor micro aerial vehicle 
visual reranking ha been widely deployed to refine the quality of conventional content based image retrieval engine the current trend lie in employing a crowd of retrieved result stemming from multiple feature modality to boost the overall performance of visual reranking however a major challenge pertaining to current reranking method is how to take full advantage of the complementary property of distinct feature modality given a query image and one feature modality a regular visual reranking framework treat the top ranked image a pseudo positive instance which are inevitably noisy difficult to reveal this complementary property and thus lead to inferior ranking performance this paper proposes a novel image reranking approach by introducing a co regularized multi graph learning co rmgl framework in which the intra graph and inter graph constraint are simultaneously imposed to encode affinity in a single graph and consistency across different graph moreover weakly supervised learning driven by image attribute is performed to denoise the pseudo labeled instance thereby highlighting the unique strength of individual feature modality meanwhile such learning can yield a few anchor in graph that vitally enable the alignment and fusion of multiple graph a a result an edge weight matrix learned from the fused graph automatically give the ordering to the initially retrieved result we evaluate our approach on four benchmark image retrieval datasets demonstrating a significant performance gain over the state of the art 
human use rich natural language to describe and communicate visual perception in order to provide natural language description for visual content this paper combine two important ingredient first we generate a rich semantic representation of the visual content including e g object and activity label to predict the semantic representation we learn a crf to model the relationship between different component of the visual input and second we propose to formulate the generation of natural language a a machine translation problem using the semantic representation a source language and the generated sentence a target language for this we exploit the power of a parallel corpus of video and textual description and adapt statistical machine translation to translate between our two language we evaluate our video description on the taco dataset which contains video snippet aligned with sentence description using automatic evaluation and human judgment we show significant improvement over several baseline approach motivated by prior work our translation approach also show improvement over related work on an image description task 
the ability to normalize pose based on super category landmark can significantly improve model of individual category when training data are limited previous method have considered the use of volumetric or morphable model for face and for certain class of articulated object we consider method which impose fewer representational assumption on category of interest and exploit contemporary detection scheme which consider the ensemble of response of detector trained for specific posekeypoint configuration we develop representation for poselet based pose normalization using both explicit warping and implicit pooling a mechanism our method defines a pose normalized similarity or kernel function that is suitable for nearest neighbor or kernel based learning method 
label fusion strategy are used in multi atlas image segmentation approach to compute a consensus segmentation of an image given a set of candidate segmentation produced by registering the image to a set of atlas effective label fusion strategy such a local similarity weighted voting substantially reduce segmentation error compared to single atlas segmentation this paper extends the label fusion idea to the problem of finding correspondence across a set of image instead of computing a consensus segmentation weighted voting is used to estimate a consensus coordinate map between a target image and a reference space two variant of the problem are considered where correspondence between a set of atlas are known and are propagated to the target image where correspondence are estimated across a set of image without prior knowledge evaluation in synthetic data show that correspondence recovered by fusion method are more accurate than those based on registration to a population template in a d example in real mri data fusion method result in more consistent mapping between manual segmentation of the hippocampus 
this paper present a hierarchical method for finding correspondence in non rigid shape we propose a new representation for d mesh the decomposition tree this structure characterizes the recursive decomposition process of a mesh into region of interest and key point the internal node contain region of interest which may be recursively decomposed and the leaf node contain the key point to be matched we also propose a hierarchical matching algorithm that performs in a level wise manner the matching process is guided by the similarity between region in high level of the tree until reaching the key point stored in the leaf this allows u to reduce the search space of correspondence making also the matching process efficient we evaluate the effectiveness of our approach using the shrec robust correspondence benchmark in addition we show that our result outperform the state of the art 
with nearly one billion online video viewed everyday an emerging new frontier in computer vision research is recognition and search in video while much effort ha been devoted to the collection and annotation of large scalable static image datasets containing thousand of image category human action datasets lag far behind current action recognition database contain on the order of ten different action category collected under fairly controlled condition state of the art performance on these datasets is now near ceiling and thus there is a need for the design and creation of new benchmark to address this issue we collected the largest action video database to date with action category which in total contain around manually annotated clip extracted from a variety of source ranging from digitized movie to youtube we use this database to evaluate the performance of two representative computer vision system for action recognition and explore the robustness of these method under various condition such a camera motion viewpoint video quality and occlusion 
we address the problem of localisation of object a bounding box in image with weak label this weakly supervised object localisation problem ha been tackled in the past using discriminative model where each object class is localised independently from other class we propose a novel framework based on bayesian joint topic modelling our framework ha three distinctive advantage over previous work all object class and image background are modelled jointly together in a single generative model so that explaining away inference can resolve ambiguity and lead to better learning and localisation the bayesian formulation of the model enables easy integration of prior knowledge about object appearance to compensate for limited supervision our model can be learned with a mixture of weakly labelled and unlabelled data allowing the large volume of unlabelled image on the internet to be exploited for learning extensive experiment on the challenging voc dataset demonstrate that our approach outperforms the state of the art competitor 
we propose structured model for image labeling that take into account the dependency among the image label explicitly these model are more expressive than independent label predictor and lead to more accurate prediction while the improvement is modest for fully automatic image labeling the gain is significant in an interactive scenario where a user provides the value of some of the image label such an interactive scenario offer an interesting trade off between accuracy and manual labeling effort the structured model are used to decide which label should be set by the user and transfer the user input to more accurate prediction on other image label we also apply our model to attribute based image classification where attribute prediction of a test image are mapped to class probability by mean of a given attribute class mapping in this case the structured model are built at the attribute level we also consider an interactive system where the system asks a user to set some of the attribute value in order to maximally improve class prediction performance experimental result on three publicly available benchmark data set show that in all scenario our structured model lead to more accurate prediction and leverage user input much more effectively than state of the art independent model 
the recognition of text in everyday scene is made difficult by viewing condition unusual font and lack of linguistic context most method integrate a priori appearance information and some sort of hard or soft constraint on the allowable string weinman and learned miller showed that the similarity among character a a supplement to the appearance of the character with respect to a model could be used to improve scene text recognition in this work we make further improvement to scene text recognition by taking a novel approach to the incorporation of similarity in particular we train a similarity expert that learns to classify each pair of character a equivalent or not after removing logical inconsistency in an equivalence graph we formulate the search for the maximum likelihood interpretation of a sign a an integer program we incorporate the equivalence information a constraint in the integer program and build an optimization criterion out of appearance feature and character bigram finally we take the optimal solution from the integer program and compare all nearby solution using a probability model for string derived from search engine query we demonstrate word error reduction of more than relative to previous method on the same data set 
we propose hierarchical space time segment a a new representation for action recognition and localization this representation ha a two level hierarchy the first level comprises the root space time segment that may contain a human body the second level comprises multi grained space time segment that contain part of the root we present an unsupervised method to generate this representation from video which extract both static and non static relevant space time segment and also preserve their hierarchical and temporal relationship using simple linear svm on the resultant bag of hierarchical space time segment representation we attain better than or comparable to state of the art action recognition performance on two challenging benchmark datasets and at the same time produce good action localization result 
in this paper we propose a distributed message passing algorithm for inference in large scale graphical model our method can handle large problem efficiently by distributing and parallelizing the computation and memory requirement the convergence and optimality guarantee of recently developed message passing algorithm are preserved by introducing new type of consistency message sent between the distributed computer we demonstrate the effectiveness of our approach in the task of stereo reconstruction from high resolution imagery and show that inference is possible with more than label in image larger than mpixels 
in this paper we propose a bilevel sparse coding model for coupled feature space where we aim to learn dictionary for sparse modeling in both space while enforcing some desired relationship between the two signal space we first present our new general sparse coding model that relates signal from the two space by their sparse representation and the corresponding dictionary the learning algorithm is formulated a a generic bilevel optimization problem which is solved by a projected first order stochastic gradient descent algorithm this general sparse coding model can be applied to many specific application involving coupled feature space in computer vision and signal processing in this work we tailor our general model to learning dictionary for compressive sensing recovery and single image super resolution to demonstrate it effectiveness in both case the new sparse coding model remarkably outperforms previous approach in term of recovery accuracy 
we present a human centric paradigm for scene understanding our approach go beyond estimating d scene geometry and predicts the workspace of a human which is represented by a data driven vocabulary of human interaction our method build upon the recent work in indoor scene understanding and the availability of motion capture data to create a joint space of human pose and scene geometry by modeling the physical interaction between the two this joint space can then be used to predict potential human pose and joint location from a single image in a way this work revisits the principle of gibsonian affordances reinterpreting it for the modern data driven era 
in this paper we are interested in how semantic segmentation can help object detection towards this goal we propose a novel deformable part based model which exploit region based segmentation algorithm that compute candidate object region by bottom up clustering followed by ranking of those region our approach allows every detection hypothesis to select a segment including void and score each box in the image using both the traditional hog filter a well a a set of novel segmentation feature thus our model blend between the detector and segmentation model since our feature can be computed very efficiently given the segment we maintain the same complexity a the original dpm we demonstrate the effectiveness of our approach in pascal voc and show that when employing only a root filter our approach outperforms dalal triggs detector on all class achieving higher average ap when employing the part we outperform the original dpm in out of class achieving an improvement of ap furthermore we outperform the previous state of the art on voc test by 
we describe a very simple framework for deriving the most well known optimization problem in active appearance model aams and most importantly for providing efficient solution our formulation result in two optimization problem for fast and exact aam fitting and one new algorithm which ha the important advantage of being applicable to d we show that the dominant cost for both forward and inverse algorithm is a few time mn which is the cost of projecting an image onto the appearance subspace this make both algorithm not only computationally realizable but also very attractive speed wise for most current system because exact aam fitting is no longer computationally prohibitive we trained aams in the wild with the goal of investigating whether aams benefit from such a training process our result show that although we did not use sophisticated shape prior robust feature or robust norm for improving performance aams perform notably well and in some case comparably with current state of the art method we provide matlab source code for training fitting and reproducing the result presented in this paper at http ibug doc ic ac uk resource 
in this paper we propose a method to detect change in the geometry of a city using panoramic image captured by a car driving around the city we designed our approach to account for all the challenge involved in a large scale application of change detection such a inaccuracy in the input geometry error in the geo location data of the image a well a the limited amount of information due to sparse imagery we evaluated our approach on an area of square kilometer inside a city using image downloaded from google street view these image besides being publicly available are also a good example of panoramic image captured with a driving vehicle and hence demonstrating all the possible challenge resulting from such an acquisition we also quantitatively compared the performance of our approach with respect to a ground truth a well a to prior work this evaluation show that our approach outperforms the current state of the art 
this paper introduces new type of square piece jigsaw puzzle those for which the orientation of each jigsaw piece is unknown we propose a tree based reassembly that greedily merges component while respecting the geometric constraint of the puzzle problem the algorithm ha state of the art performance for puzzle assembly whether or not the orientation of the piece is known our algorithm make fewer assumption than past work and success is shown even when piece from multiple puzzle are mixed together for solving puzzle where jigsaw piece location is known but orientation is unknown we propose a pairwise mrf where each node represents a jigsaw piece s orientation other contribution of the paper include an improved measure mgc for quantifying the compatibility of potential jigsaw piece match based on expecting smoothness in gradient distribution across boundary 
we present a data driven method for estimating the d shape of face viewed in single unconstrained photo aka in the wild our method wa designed with an emphasis on robustness and efficiency with the explicit goal of deployment in real world application which reconstruct and display face in d our key observation is that for many practical application warping the shape of a reference face to match the appearance of a query is enough to produce realistic impression of the query s d shape doing so however requires matching visual feature between the possibly very different query and reference image while ensuring that a plausible face shape is produced to this end we describe an optimization process which seek to maximize the similarity of appearance and depth jointly to those of a reference model we describe our system for monocular face shape reconstruction and present both qualitative and quantitative experiment comparing our method against alternative system and demonstrating it capability finally a a testament to it suitability for real world application we offer an open on line implementation of our system providing unique mean of instant d viewing of face appearing in web photo 
a topical video object refers to an object that is frequently highlighted in a video it could be e g the product logo and the leading actor actress in a tv commercial we propose a topic model that incorporates a word co occurrence prior for efficient discovery of topical video object from a set of key frame previous work using topic model such a latent dirichelet allocation lda for video object discovery often take a bag of visual word representation which ignored important co occurrence information among the local feature we show that such data driven co occurrence information from bottom up can conveniently be incorporated in lda with a gaussian markov prior which combine top down probabilistic topic modeling with bottom up prior in a unified model our experiment on challenging video demonstrate that the proposed approach can discover different type of topical object despite variation in scale view point color and lighting change or even partial occlusion the efficacy of the co occurrence prior is clearly demonstrated when comparing with topic model without such prior 
in this work we introduce a hierarchical matching framework with so called side information for image classification based on bag of word representation each image is expressed a a bag of orderless pair each of which includes a local feature vector encoded over a visual dictionary and it corresponding side information from prior or context the side information is used for hierarchical clustering of the encoded local feature then a hierarchical matching kernel is derived a the weighted sum of the similarity over the encoded feature pooled within cluster at different level finally the new kernel is integrated with popular machine learning algorithm for classification purpose this framework is quite general and flexible other practical and powerful algorithm can be easily designed by using this framework a a template and utilizing particular side information for hierarchical clustering of the encoded local feature to tackle the latent spatial mismatch issue in spm we design in this work two exemplar algorithm based on two type of side information object confidence map and visual saliency map from object detection prior and within image context respectively the extensive experiment over the caltech ucsd bird oxford flower and pascal voc and pascal voc database show the state of the art performance from these two exemplar algorithm 
robust detection and tracking of multiple people in cluttered and crowded scene with severe occlusion is a significant challenging task for many computer vision application in this paper we present a novel hybrid synthetic aperture imaging model to solve this problem the main characteristic of this approach include to the best of our knowledge this algorithm is the first time to solve the occluded people imaging and tracking problem in a joint multiple camera synthetic aperture imaging domain a multiple model framework is designed to achieve seamless interaction among the detection imaging and tracking module in the object detection module a multiple constraint based approach is presented for people localizing and ghost object removal in a d foreground silhouette synthetic aperture imaging volume in the synthetic imaging module a novel occluder removal based synthetic imaging approach is proposed to continuously obtain object clear image even under severe occlusion in the object tracking module a camera array is used for robust people tracking in color synthetic aperture image a network camera based hybrid synthetic aperture imaging system ha been set up and experimental result with qualitative and quantitative analysis demonstrate that the method can reliably locate and see people in challenge scene 
we introduce the concept of relative volume constraint in order to account for insufficient information in the reconstruction of d object from a single image the key idea is to formulate a variational reconstruction approach with shape prior in form of relative depth profile or volume ratio relating object part such shape prior can easily be derived either from a user sketch or from the object s shading profile in the image they can handle textured or shadowed object region by propagating information we propose a convex relaxation of the constrained optimization problem which can be solved optimally in a few second on graphic hardware in contrast to existing single view reconstruction algorithm the proposed algorithm provides substantially more flexibility to recover shape detail such a self occlusion dent and hole which are not visible in the object silhouette 
while total variation is among the most popular regularizers for variational problem it extension to function with value in a manifold is an open problem in this paper we propose the first algorithm to solve such problem which applies to arbitrary riemannian manifold the key idea is to reformulate the variational problem a a multilabel optimization problem with an infinite number of label this lead to a hard optimization problem which can be approximately solved using convex relaxation technique the framework can be easily adapted to different manifold including sphere and three dimensional rotation and allows to obtain accurate solution even with a relatively coarse discretization with numerous example we demonstrate that the proposed framework can be applied to variational model that incorporate chromaticity value normal field or camera trajectory 
today visual recognition system are still rarely employed in robotics application perhaps one of the main reason for this is the lack of demanding benchmark that mimic such scenario in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmark for the task of stereo optical flow visual odometry slam and d object detection our recording platform is equipped with four high resolution video camera a velodyne laser scanner and a state of the art localization system our benchmark comprise stereo and optical flow image pair stereo visual odometry sequence of km length and more than k d object annotation captured in cluttered scenario up to car and pedestrian are visible per image result from state of the art algorithm reveal that method ranking high on established datasets such a middlebury perform below average when being moved outside the laboratory to the real world our goal is to reduce this bias by providing challenging benchmark with novel difficulty to the computer vision community our benchmark are available online at www cvlibs net datasets kitti 
many existing technique for analyzing face image assume that the face are at nearly frontal generalizing to non frontal face is often difficult due to a dearth of ground truth for non frontal face and also to the inherent challenge in handling pose variation in this work we investigate how to learn a universal multi view age estimator by harnessing unlabeled web video a publicly available labeled frontal face corpus and zero or more non frontal face with age label first a large diverse human involved video corpus is collected from online video sharing website then multi view face detection and tracking are performed to build a large set of frontal v profile face bundle each of which is from the same tracking sequence and thus exhibiting the same age these unlabeled face bundle constitute the so called video context and the parametric multi view age estimator is trained by enforcing the face to age relation for the partially labeled face imposing the consistency of the predicted age for the non frontal and frontal face within each face bundle and mutually constraining the multi view age model with the spatial correspondence prior derived from the face bundle our multi view age estimator performs well on a realistic evaluation dataset that contains face under varying pose and whose ground truth age wa manually annotated 
matching patch between two image also known a computing nearest neighbor field ha been proven a useful technique in various computer vision graphic algorithm but this is a computationally challenging nearest neighbor search task because both the query set and the candidate set are of image size in this paper we propose propagation assisted kd tree to quickly compute an approximate solution we develop a novel propagation search method for kd tree in this method the tree node checked by each query are propagated from the nearby query this method not only avoids the time consuming backtracking in traditional tree method but is more accurate experiment on public data show that our method is time faster than the patchmatch method at the same accuracy or reduces it error by at the same running time our method is also time faster and is more accurate than coherency sensitive hashing a latest state of the art method 
we propose a novel shape model for object detection called fan shape model fsm we model contour sample point a ray of final length emanating for a reference point a in folding fan it slat which we call ray are very flexible this flexibility allows fsm to tolerate large shape variance however the order and the adjacency relation of the slat stay invariant during fan deformation since the slat are connected with a thin fabric in analogy we enforce the order and adjacency relation of the ray to stay invariant during the deformation therefore fsm preserve discriminative power while allowing for a substantial shape deformation fsm allows also for precise scale estimation during object detection thus there is not need to scale the shape model or image in order to perform object detection another advantage of fsm is the fact that it can be applied directly to edge image since it doe not require any linking of edge pixel to edge fragment contour 
we extend patch based method to work on patch in d space we start with coherency sensitive hashing csh which is an algorithm for matching patch between two rgb image and extend it to work with rgbd image this is done by warping all d patch to a common virtual plane in which csh is performed to avoid noise due to warping of patch of various normal and depth we estimate a group of dominant plane and compute csh on each plane separately before merging the matching patch the result is dcsh an algorithm that match world d patch in order to guide the search for image plane match an independent contribution is an extension of csh which we term social csh it allows a major speedup of the k nearest neighbor knn version of csh it runtime growing linearly rather than quadratic ally in k social csh is used a a subcomponent of dcsh when many nns are required a in the case of image denoising we show the benefit of using depth information to image reconstruction and image denoising demonstrated on several rgbd image 
typical approach to classification treat class label a disjoint for each training example it is assumed that there is only one class label that correctly describes it and that all other label are equally bad we know however that good and bad label are too simplistic in many scenario hurting accuracy in the realm of example dependent cost sensitive learning each label is instead a vector representing a data point s affinity for each of the class at test time our goal is not to minimize the misclassification rate but to maximize that affinity we propose a novel example dependent cost sensitive impurity measure for decision tree our experiment show that this new impurity measure improves test performance while still retaining the fast test time of standard classification tree we compare our approach to classification tree and other cost sensitive method on three computer vision problem tracking descriptor matching and optical flow and show improvement in all three domain 
in this paper we propose a new non rigid robust registration method that register a point distribution model pdm of a surface to given d image the contribution of the paper are a new hierarchical statistical shape model ssm of the surface that ha better generalization ability is introduced the registration algorithm of the hierarchical ssm that can estimate the marginal posterior distribution of the surface location is proposed and the registration performance is improved by robustly registering each local shape of the surface with the sparsity regularization and by referring to the appearance between the neighboring model point in the likelihood computation the ssm of a liver wa constructed from a set of clinical ct image and the performance of the proposed method wa evaluated experimental result demonstrated that the proposed method outperformed some existing method that use non hierarchical ssms 
despite recent success of searching small object in image it remains a challenging problem to search and locate action in crowded video because of the large variation of human action and the intensive computational cost of searching the video space to address these challenge we propose a fast action search and localization method that support relevance feedback from the user by characterizing video a spatio temporal interest point and building a random forest to index and match these point our query matching is robust and efficient to enable efficient action localization we propose a coarse to fine sub volume search scheme which is several order faster than the existing video branch and bound search the challenging cross dataset search of several action validates the effectiveness and efficiency of our method 
representing the raw input of a data set by a set of relevant code is crucial to many computer vision application due to the intrinsic sparse property of real world data dictionary learning in which the linear decomposition of a data point us a set of learned dictionary base i e code ha demonstrated state of the art performance however traditional dictionary learning method suffer from three weakness sensitivity to noisy and outlier sample difficulty to determine the optimal dictionary size and incapability to incorporate supervision information in this paper we address these weakness by learning a semi supervised robust dictionary ssr d specifically we use the l norm a the loss function to improve the robustness against outlier and develop a new structured sparse regularization to incorporate the supervision information in dictionary learning without incurring additional parameter moreover the optimal dictionary size is automatically learned from the input data minimizing the derived objective function is challenging because it involves many non smooth l norm term we present an efficient algorithm to solve the problem with a rigorous proof of the convergence of the algorithm extensive experiment are presented to show the superior performance of the proposed method 
this paper present a framework for image parsing with multiple label set for example we may want to simultaneously label every image region according to it basic level object category car building road tree etc superordinate category animal vehicle manmade object natural object etc geometric orientation horizontal vertical etc and material metal glass wood etc some object region may also be given part name a car can have wheel door windshield etc we compute co occurrence statistic between different label type of the same region to capture relationship such a road are horizontal car are made of metal car have wheel but horse have leg and so on by incorporating these constraint into a markov random field inference framework and jointly solving for all the label set we are able to improve the classification accuracy for all the label set at once achieving a richer form of image understanding 
we propose an approach to multi writer word spotting where the goal is to find a query word in a dataset comprised of document image we propose an attribute based approach that lead to a low dimensional fixed length representation of the word image that is fast to compute and especially fast to compare this approach naturally lead to an unified representation of word image and string which seamlessly allows one to indistinctly perform query by example where the query is an image and query by string where the query is a string we also propose a calibration scheme to correct the attribute score based on canonical correlation analysis that greatly improves the result on a challenging dataset we test our approach on two public datasets showing state of the art result 
the perspective three point p p problem aim at determining the position and orientation of the camera in the world reference frame from three d d point correspondence this problem is known to provide up to four solution that can then be disambiguated using a fourth point all existing solution attempt to first solve for the position of the point in the camera reference frame and then compute the position and orientation of the camera in the world frame which alignes the two point set in contrast in this paper we propose a novel closed form solution to the p p problem which computes the aligning transformation directly in a single stage without the intermediate derivation of the point in the camera frame this is made possible by introducing intermediate camera and world reference frame and expressing their relative position and orientation using only two parameter the projection of a world point into the parametrized camera pose then lead to two condition and finally a quartic equation for finding up to four solution for the parameter pair a subsequent backsubstitution directly lead to the corresponding camera pose with respect to the world reference frame we show that the proposed algorithm offer accuracy and precision comparable to a popular standard state of the art approach but at much lower computational cost time faster furthermore it provides improved numerical stability and is le affected by degenerate configuration of the selected world point the superior computational efficiency is particularly suitable for any ransac outlier rejection step which is always recommended before applying pnp or non linear optimization of the final solution 
one fundamental problem in object retrieval with the bag of visual word bow model is it lack of spatial information although various approach are proposed to incorporate spatial constraint into the bow model most of them are either too strict or too loose so that they are only effective in limited case we propose a new spatially constrained similarity measure scsm to handle object rotation scaling view point change and appearance deformation the similarity measure can be efficiently calculated by a voting based method using inverted file object retrieval and localization are then simultaneously achieved without post processing furthermore we introduce a novel and robust re ranking method with the k nearest neighbor of the query for automatically refining the initial search result extensive performance evaluation on six public datasets show that scsm significantly outperforms other spatial model while k nn re ranking outperforms most state of the art approach using query expansion 
we present a theory that address the problem of determining shape from the small or differential motion of an object with unknown isotropic reflectance under arbitrary unknown distant illumination for both orthographic and perpsective projection our theory imposes fundamental limit on the hardness of surface reconstruction independent of the method involved under orthographic projection we prove that three differential motion suffice to yield an invariant that relates shape to image derivative regardless of brdf and illumination under perspective projection we show that four differential motion suffice to yield depth and a linear constraint on the surface gradient with unknown brdf and lighting further we delineate the topological class up to which reconstruction may be achieved using the invariant finally we derive a general stratification that relates hardness of shape recovery to scene complexity qualitatively our invariant are homogeneous partial differential equation for simple lighting and inhomogeneous for complex illumination quantitatively our framework show that the minimal number of motion required to resolve shape is greater for more complex scene prior work that assume brightness constancy lambertian brdf or a known directional light source follow a special case of our stratification we illustrate with synthetic and real data how potential reconstruction method may exploit our framework 
in this work we present a novel method for the challenging problem of depth image up sampling modern depth camera such a kinect or time of flight camera deliver dense high quality depth measurement but are limited in their lateral resolution to overcome this limitation we formulate a convex optimization problem using higher order regularization for depth image up sampling in this optimization an an isotropic diffusion tensor calculated from a high resolution intensity image is used to guide the up sampling we derive a numerical algorithm based on a primal dual formulation that is efficiently parallelized and run at multiple frame per second we show that this novel up sampling clearly outperforms state of the art approach in term of speed and accuracy on the widely used middlebury datasets furthermore we introduce novel datasets with highly accurate ground truth which for the first time enable to benchmark depth up sampling method using real sensor data 
datasets are an integral part of contemporary object recognition research they have been the chief reason for the considerable progress in the field not just a source of large amount of training data but also a mean of measuring and comparing performance of competing algorithm at the same time datasets have often been blamed for narrowing the focus of object recognition research reducing it to a single benchmark performance number indeed some datasets that started out a data capture effort aimed at representing the visual world have become closed world unto themselves e g the corel world the caltech world the pascal voc world with the focus on beating the latest benchmark number on the latest dataset have we perhaps lost sight of the original purpose the goal of this paper is to take stock of the current state of recognition datasets we present a comparison study using a set of popular datasets evaluated based on a number of criterion including relative data bias cross dataset generalization effect of closed world assumption and sample value the experimental result some rather surprising suggest direction that can improve dataset collection a well a algorithm evaluation protocol but more broadly the hope is to stimulate discussion in the community regarding this very important but largely neglected issue 
we address the problem of finding deformation between two image for the purpose of recognizing object the challenge is that discriminative feature are often transformation variant e g histogram of oriented gradient texture while transformation invariant feature e g intensity color are often not discriminative we introduce the concept of attribute flow which explicitly model how image attribute vary with it deformation we develop a non parametric method to approximate this using histogram matching which can be solved efficiently using linear programming our method produce dense correspondence between image and utilizes discriminative transformation variant feature for simultaneous detection and alignment experiment on ethz shape category dataset show that we can accurately recognize highly de formable object with few training example 
we address the problem of visual recognition from multiple observation of the same physical object which can be generated under different condition such a frame at different time instance or snapshot from different viewpoint we formulate the multi observation visual recognition task a a joint sparse representation model and take advantage of the correlation among the multiple observation for classification using a novel joint dynamic sparsity prior the proposed joint dynamic sparsity prior promotes shared joint sparsity pattern among the multiple sparse representation vector at class level while allowing distinct sparsity pattern at atom level within each class in order to facilitate a flexible representation the proposed method can handle both homogenous a well a heterogenous data within the same framework extensive experiment on various visual classification task including face recognition and generic object classification demonstrate that the proposed method outperforms existing state of the art method 
we present a novel framework for multiple object tracking in which the problem of object detection and data association are expressed by a single objective function the framework follows the lagrange dual decomposition strategy taking advantage of the often complementary nature of the two subproblems our coupling formulation avoids the problem of error propagation from which traditional detection tracking approach to multiple object tracking suffer we also eschew common heuristic such a nonmaximum suppression of hypothesis by modeling the joint image likelihood a opposed to applying independent likelihood assumption our coupling algorithm is guaranteed to converge and can handle partial or even complete occlusion furthermore our method doe not have any severe scalability issue but can process hundred of frame at the same time our experiment involve challenging notably distinct datasets and demonstrate that our method can achieve result comparable to those of state of art approach even without a heavily trained object detector 
this paper address the problem of efficiently solving large scale energy minimization problem encountered in computer vision we propose an energy aware method for merging random variable to reduce the size of the energy to be minimized the method examines the energy function to find group of variable which are likely to take the same label in the minimum energy state and thus can be represented by a single random variable we propose and evaluate a number of extremely efficient variable grouping strategy experimental result show that our method result in a dramatic reduction in the computational cost and memory requirement in some case by a factor of one hundred with almost no drop in the accuracy of the final result comparative evaluation with efficient super pixel generation method which are commonly used in variable grouping reveals that our method are far superior both in term of accuracy and running time 
urban model are key to navigation architecture and entertainment apart from visualizing facade a number of tedious task remain largely manual e g compression generating new facade design and structurally comparing facade for classification retrieval and clustering we propose a novel procedural modelling method to automatically learn a grammar from a set of facade generate new facade instance and compare facade to deal with the difficulty of grammatical inference we reformulate the problem instead of inferring a compromising one size fit all single grammar for all task we infer a model whose successive refinement are production rule tailored for each task we demonstrate our automatic rule inference on datasets of two different architectural style our method supercedes manual expert work and cut the time required to build a procedural model of a facade from several day to a few millisecond 
we present a novel approach to simultaneously reconstruct the d structure of a non rigid coronary tree and estimate point correspondence between an input x ray image and a reference d shape at the core of our approach lie an optimization scheme that iteratively fit a generative d model of increasing complexity and guide the matching process a a result and in contrast to existing approach that assume rigidity or quasi rigidity of the structure our method is able to retrieve large non linear deformation even when the input data is corrupted by the presence of noise and partial occlusion we extensively evaluate our approach under synthetic and real data and demonstrate a remarkable improvement compared to state of the art 
we present a noise resilient probabilistic model for active learning of a gaussian process classifier from crowd i e a set of noisy labelers it explicitly model both the overall label noise and the expertise level of each individual labeler in two level of flip model expectation propagation is adopted for efficient approximate bayesian inference of our probabilistic model for classification based on which a generalized em algorithm is derived to estimate both the global label noise and the expertise of each individual labeler the probabilistic nature of our model immediately allows the adoption of the prediction entropy and estimated expertise for active selection of data sample to be labeled and active selection of high quality labelers to label the data respectively we apply the proposed model for three visual recognition task i e object category recognition gender recognition and multi modal activity recognition on three datasets with real crowd sourced label from amazon mechanical turk the experiment clearly demonstrated the efficacy of the proposed model 
we propose a unified variational formulation for joint motion estimation and segmentation with explicit occlusion handling this is done by a multi label representation of the flow field where each label corresponds to a parametric representation of the motion we use a convex formulation of the multi label potts model with label cost and show that the asymmetric map uniqueness criterion can be integrated into our formulation by mean of convex constraint explicit occlusion handling eliminates error otherwise created by the regularization a occlusion can occur only at object boundary a large number of object may be required by using a fast primal dual algorithm we are able to handle several hundred motion segment result are shown on several classical motion segmentation and optical flow example 
imagenet is a large scale database of object class with million of image unfortunately only a small fraction of them is manually annotated with bounding box this prevents useful development such a learning reliable object detector for thousand of class in this paper we propose to automatically populate imagenet with many more bounding box by leveraging existing manual annotation the key idea is to localize object of a target class for which annotation are not available by transferring knowledge from related source class with available annotation we distinguish two kind of source class ancestor and sibling each source provides knowledge about the plausible location appearance and context of the target object which induces a probability distribution over window in image of the target class we learn to combine these distribution so a to maximize the location accuracy of the most probable window finally we employ the combined distribution in a procedure to jointly localize object in all image of the target class through experiment on million image from class we show that our technique i annotates a wide range of class with bounding box ii effectively exploit the hierarchical structure of imagenet since all source and type of knowledge we propose contribute to the result iii scale efficiently 
saliency estimation ha become a valuable tool in image processing yet existing approach exhibit considerable variation in methodology and it is often difficult to attribute improvement in result quality to specific algorithm property in this paper we reconsider some of the design choice of previous method and propose a conceptually clear and intuitive algorithm for contrast based saliency estimation our algorithm consists of four basic step first our method decomposes a given image into compact perceptually homogeneous element that abstract unnecessary detail based on this abstraction we compute two measure of contrast that rate the uniqueness and the spatial distribution of these element from the element contrast we then derive a saliency measure that produce a pixel accurate saliency map which uniformly cover the object of interest and consistently separate foreand background we show that the complete contrast and saliency estimation can be formulated in a unified way using high dimensional gaussian filter this contributes to the conceptual simplicity of our method and lends itself to a highly efficient implementation with linear complexity in a detailed experimental evaluation we analyze the contribution of each individual feature and show that our method outperforms all state of the art approach 
we introduce a method to repair an image which ha been stamped by an identigram or a watermark our method is based on the cross channel correlation which assures the co occurrence of image discontinuity and correlation of color distribution across different color channel of an image using blind source separation we find the transformation of color space which separate the structure of identigram and that of the original image into two different individual color channel to repair the image content in the corrupted channel we formulate the problem using bayes rule where the prior and the likelihood probability are defined based on the cross channel correlation assumption we compare our result with result from inpainting and texture synthesis based hole filling technique our result are pleasable for real world example and have the maximum psnr for synthetic example 
semantic road labeling is a key component of system that aim at assisted or even autonomous driving considering that such system continuously operate in the real world unforeseen condition not represented in any conceivable training procedure are likely to occur on a regular basis in order to equip system with the ability to cope with such situation we would like to enable adaptation to such new situation and condition at runtime existing adaptive method for image labeling either require labeled data from the new condition or even operate globally on a complete test set none of this is a desirable mode of operation for a system a described above where new image arrive sequentially and condition may vary we study the effect of changing test condition on scene labeling method based on a new diverse street scene dataset we propose a novel approach that can operate in such condition and is based on a sequential bayesian model update in order to robustly integrate the arriving image into the adapting procedure 
in recent year efficiency of large scale object detection ha arisen a an important topic due to the exponential growth in the size of benchmark object detection datasets most current object detection method focus on improving accuracy of large scale object detection with efficiency being an afterthought in this paper we present the efficient maximum appearance search emas model which is an order of magnitude faster than the existing state of the art large scale object detection approach while maintaining comparable accuracy our emas model consists of representing an image a an ensemble of densely sampled feature point with the proposed point wise fisher vector encoding method so that the learnt discriminative scoring function can be applied locally consequently the object detection problem is transformed into searching an image sub area for maximum local appearance probability thereby making emas an order of magnitude faster than the traditional detection method in addition the proposed model is also suitable for incorporating global context at a negligible extra computational cost emas can also incorporate fusion of multiple feature which greatly improves it performance in detecting multiple object category our experiment show that the proposed algorithm can perform detection of object class in le than one minute per image on the image net ilsvrc dataset and for object class in le than second per image for the sun dataset using a single cpu 
advance in d imaging have recently made d surface scanner capable of capturing textured surface at video rate affordable and common in computer vision this is a relatively new source of data the potential of which ha not yet been fully exploited a the problem of non rigid registration of surface is difficult while registration based on shape alone ha been an active research area for some time the problem of registering surface based on texture information ha not been addressed in a principled way we propose a novel efficient and reliable fully automatic method for performing groupwise non rigid registration of textured surface such a those obtained with d scanner we demonstrate the robustness of our approach on d scan of human face including the notoriously difficult case of inter subject registration we show how our method can be used to build high quality d model of appearance fully automatically 
semantic reconstruction of a scene is important for a variety of application such a d modelling object recognition and autonomous robotic navigation however most object labelling method work in the image domain and fail to capture the information present in d space in this work we propose a principled way to generate object labelling in d our method build a triangulated meshed representation of the scene from multiple depth estimate we then define a crf over this mesh which is able to capture the consistency of geometric property of the object present in the scene in this framework we are able to generate object hypothesis by combining information from multiple source geometric property from the d mesh and appearance property from image we demonstrate the robustness of our framework in both indoor and outdoor scene for indoor scene we created an augmented version of the nyu indoor scene dataset rgbd image with object labelled mesh for training and evaluation for outdoor scene we created ground truth object labellings for the kitty odometry dataset stereo image sequence we observe a significant speed up in the inference stage by performing labelling on the mesh and additionally achieve higher accuracy 
loopy belief propagation lbp is a powerful tool for approximate inference in markov random field mrfs however for problem with large state space the runtime cost are often prohibitively high in this paper we present a new lbp algorithm that represents all belief marginals and message in a wavelet representation which can encode the probabilistic information much more compactly unlike previous work our algorithm operates solely in the wavelet domain this yield an output sensitive algorithm where the running time depends mostly on the information content rather than the discretization resolution we apply the new technique to typical problem with large state space such a image matching and wide baseline optical flow where we observe a significantly improved scaling behavior with discretization resolution for large problem the new technique is significantly faster than even an optimized spatial domain implementation 
in this work we propose to use attribute and part for recognizing human action in still image we define action attribute a the verb that describe the property of human action while the part of action are object and poselets that are closely related to the action we jointly model the attribute and part by learning a set of sparse base that are shown to carry much semantic meaning then the attribute and part of an action image can be reconstructed from sparse coefficient with respect to the learned base this dual sparsity provides theoretical guarantee of our base learning and feature reconstruction approach on the pascal action dataset and a new stanford action dataset we show that our method extract meaningful high order interaction between attribute and part in human action while achieving state of the art classification performance 
in this paper we propose a general framework for approximating differential operator directly on point cloud and use it for geometric understanding on them the discrete approximation of differential operator on the underlying manifold represented by point cloud is based only on local approximation using nearest neighbor which is simple efficient and accurate this allows u to extract the complete local geometry solve partial differential equation and perform intrinsic calculation on surface since no mesh or parametrization is needed our method can work with point cloud in any dimension or co dimension or even with variable dimension the computation complexity scaled well with the number of point and the intrinsic dimension rather than the embedded dimension we use this method to define the laplace beltrami lb operator on point cloud which link local and global information together with this operator we propose a few key application essential to geometric understanding for point cloud including the computation of lb eigenvalue and eigenfunctions the extraction of skeleton from point cloud and the extraction of conformal structure from point cloud 
object recognition is challenging especially when the object from different category are visually similar to each other in this paper we present a novel joint dictionary learning jdl algorithm to exploit the visual correlation within a group of visually similar object category for dictionary learning where a commonly shared dictionary and multiple category specific dictionary are accordingly modeled to enhance the discrimination of the dictionary the dictionary learning problem is formulated a a joint optimization by adding a discriminative term on the principle of the fisher discrimination criterion a well a presenting the jdl model a classification scheme is developed to better take advantage of the multiple dictionary that have been trained the effectiveness of the proposed algorithm ha been evaluated on popular visual benchmark 
we propose a novel localized principal component analysis pca based curve evolution approach which evolves the segmenting curve semi locally within various target region division in an image and then combine these locally accurate segmentation curve to obtain a global segmentation the training data for our approach consists of training shape and associated auxiliary target mask the mask indicate the various region of the shape exhibiting highly correlated variation locally which may be rather independent of the variation in the distant part of the global shape thus in a sense we are clustering the variation exhibited in the training data set we then use a parametric model to implicitly represent each localized segmentation curve a a combination of the local shape prior obtained by representing the training shape and the mask a a collection of signed distance function we also propose a parametric model to combine the locally evolved segmentation curve into a single hybrid global segmentation finally we combine the evolution of these semilocal and global parameter to minimize an objective energy function the resulting algorithm thus provides a globally accurate solution which retains the local variation in shape we present some result to illustrate how our approach performs better than the traditional approach with fully global pca 
we present a method for estimating the relative pose of two calibrated or uncalibrated non overlapping surveillance camera from observing a moving object we show how to tackle the problem of missing point correspondence heavily required by sfm pipeline and how to go beyond this basic paradigm we relax the non linear nature of the problem by accepting two assumption which surveillance scenario offer ie the presence of a moving object and easily estimable gravity vector by those assumption we cast the problem a a quadratic eigenvalue problem offering an elegant way of treating nonlinear monomials and delivering a quasi closed form solution a a reliable starting point for a further bundle adjustment we are the first to bring the closed form solution to such a very practical problem arising in video surveillance result in different camera setup demonstrate the feasibility of the approach 
we address the problem of large scale annotation of web image our approach is based on the concept of visual synset which is an organization of image which are visually similar and semantically related each visual synset represents a single prototypical visual concept and ha an associated set of weighted annotation linear svm s are utilized to predict the visual synset membership for unseen image example and a weighted voting rule is used to construct a ranked list of predicted annotation from a set of visual synset we demonstrate that visual synset lead to better performance than standard method on a new annotation database containing more than million image and thousand annotation which is the largest ever reported 
we present an approach to jointly estimating camera motion and dense scene structure in term of depth map from monocular image sequence in driver assistance scenario for two consecutive frame of a sequence taken with a single fast moving camera the approach combine numerical estimation of egomotion on the euclidean manifold of motion parameter with variational regularization of dense depth map estimation embedding this online joint estimator into a recursive framework achieves a pronounced spatio temporal filtering effect and robustness we report the evaluation of thousand of image taken from a car moving at speed up to km h the result compare favorably with two alternative setting that require more input data stereo based scene reconstruction and camera motion estimation in batch mode using multiple frame the employed benchmark dataset is publicly available 
recently hashing based approximate nearest neighbor ann technique have been attracting lot of attention in computer vision the data dependent hashing method e g spectral hashing expects better performance than the data blind counterpart e g locality sensitive hashing lsh however most data dependent hashing method only employ a single hash table when higher recall is desired they have to retrieve exponentially growing number of hash bucket around the bucket containing the query which may drag down the precision rapidly in this paper we propose a so called complementary hashing approach which is able to balance the precision and recall in a more effective way the key idea is to employ multiple complementary hash table which are learned sequentially in a boosting manner so that given a query it true nearest neighbor missed from the active bucket of one hash table are more likely to be found in the active bucket of the next hash table compared with lsh that also can exploit multiple hash table our approach is more effective to find true nns thanks to the complementarity property of the hash table from our approach experimental result on large scale ann search show that the proposed method significantly improves the performance and outperforms the state of the art 
temporal irradiance variation are useful for finding dense stereo correspondence these variation can be created artificially using structured light they also occur naturally underwater we introduce a variational optimization formulation for finding a dense stereo correspondence field it is based on multi frame optical flow adapted to stereo the formulation us a sequence of stereo frame and yield dense and robust result the inherent aperture problem of optical flow is resolved using a temporal sequence of stereo frame pair the result are achieved even without considering epi polar geometry the method ha the ability to handle dynamic stereo underwater in harsh condition of flickering illumination the method is demonstrated experimentally both outdoors and indoors 
repeated structure such a building facade fence or road marking often represent a significant challenge for place recognition repeated structure are notoriously hard for establishing correspondence using multi view geometry even more importantly they violate the feature independence assumed in the bag of visual word representation which often lead to over counting evidence and significant degradation of retrieval performance in this work we show that repeated structure are not a nuisance but when appropriately represented they form an important distinguishing feature for many place we describe a representation of repeated structure suitable for scalable retrieval it is based on robust detection of repeated image structure and a simple modification of weight in the bag of visual word model place recognition result are shown on datasets of street level imagery from pittsburgh and san francisco demonstrating significant gain in recognition performance compared to the standard bag of visual word baseline and more recently proposed burstiness weighting 
in this paper we propose a novel conditional random field crf formulation for the semantic scene labeling problem which is able to enforce temporal consistency between consecutive video frame and take advantage of the d scene geometry to improve segmentation quality the main contribution of this work lie in the novel use of a d scene reconstruction a a mean to temporally couple the individual image segmentation allowing information flow from d geometry to the d image space a our result show the proposed framework outperforms state of the art method and open a new perspective towards a tighter interplay of d and d information in the scene understanding problem 
reconstructing transparent object is a challenging problem while producing reasonable result for quite complex object existing approach require custom calibration or somewhat expensive labor to achieve high precision on the other hand when an overall shape preserving salient and fine detail is sufficient we show in this paper a significant step toward solving the problem on a shoestring budget by using only a video camera a moving spotlight and a small chrome sphere specifically the problem we address is to estimate the normal map of the exterior surface of a given solid transparent object from which the surface depth can be integrated our technical contribution lie in relating this normal reconstruction problem to one of graph cut segmentation unlike conventional formulation however our graph is dual layered since we can see a transparent object s foreground a well a the background behind it quantitative and qualitative evaluation are performed to verify the efficacy of this practical solution 
detecting abnormality in video is a challenging problem since the class of all irregular object and behavior is infinite and thus no or by far not enough abnormal training sample are available consequently a standard setting is to find abnormality without actually knowing what they are because we have not been shown abnormal example during training however although the training data doe not define what an abnormality look like the main paradigm in this field is to directly search for individual abnormal local patch or image region independent of another to address this problem we parse video frame by establishing a set of hypothesis that jointly explain all the foreground while at same time trying to find normal training sample that explain the hypothesis consequently we can avoid a direct detection of abnormality they are discovered indirectly a those hypothesis which are needed for covering the foreground without finding an explanation by normal sample for themselves we present a probabilistic model that localizes abnormality using statistical inference on the challenging dataset of it outperforms the state of the art by to achieve a frame based abnormality classification performance of and the localization performance improves by to 
an articulated trajectory is defined a a trajectory that remains at a fixed distance with respect to a parent trajectory in this paper we present a method to reconstruct an articulated trajectory in three dimension given the two dimensional projection of the articulated trajectory the d parent trajectory and the camera pose at each time instant this is a core challenge in reconstructing the d motion of articulated structure such a the human body because endpoint of each limb form articulated trajectory we simultaneously apply activity independent spatial and temporal constraint in the form of fixed d distance to the parent trajectory and smooth d motion there exist two solution that satisfy each instantaneous d projection and articulation constraint a ray intersects a sphere at up to two location and we show that resolving this ambiguity by enforcing smoothness is equivalent to solving a binary quadratic programming problem a geometric analysis of the reconstruction of articulated trajectory is also presented and a measure of the reconstructibility of an articulated trajectory is proposed 
computational model of visual process with biological inspiration and even biological realism are currently of great interest in the computer vision community this paper provides a biologically plausible model of d shape which incorporates intermediate layer of visual representation that have not previously been fully explored we propose that endstopping and curvature cell are of great importance for shape selectivity and show how their combination can lead to shape selective neuron this shape representation model provides a highly accurate fit with neural data from and provides comparable result with real world image to current computer vision system the conclusion is that such intermediate representation may no longer require a learning approach a a bridge between early representation based on gabor or difference of gaussian filter that are not learned since they are well understood and later representation closer to object representation that still can benefit from a learning methodology 
robust principal component analysis rpca via rank minimization is a powerful tool for recovering underlying low rank structure of clean data corrupted with sparse noise outlier in many low level vision problem not only it is known that the underlying structure of clean data is low rank but the exact rank of clean data is also known yet when applying conventional rank minimization for those problem the objective function is formulated in a way that doe not fully utilize a priori target rank information about the problem this observation motivates u to investigate whether there is a better alternative solution when using rank minimization in this paper instead of minimizing the nuclear norm we propose to minimize the partial sum of singular value the proposed objective function implicitly encourages the target rank constraint in rank minimization our experimental analysis show that our approach performs better than conventional rank minimization when the number of sample is deficient while the solution obtained by the two approach are almost identical when the number of sample is more than sufficient we apply our approach to various low level vision problem e g high dynamic range imaging photometric stereo and image alignment and show that our result outperform those obtained by the conventional nuclear norm rank minimization method 
what make an object salient most previous work assert that distinctness is the dominating factor the difference between the various algorithm is in the way they compute distinctness some focus on the pattern others on the color and several add high level cue and prior we propose a simple yet powerful algorithm that integrates these three factor our key contribution is a novel and fast approach to compute pattern distinctness we rely on the inner statistic of the patch in the image for identifying unique pattern we provide an extensive evaluation and show that our approach outperforms all state of the art method on the five most commonly used datasets 
when glancing at a magazine or browsing the internet we are continuously being exposed to photograph despite of this overflow of visual information human are extremely good at remembering thousand of picture along with some of their visual detail but not all image are equal in memory some stitch to our mind and other are forgotten in this paper we focus on the problem of predicting how memorable an image will be we show that memorability is a stable property of an image that is shared across different viewer we introduce a database for which we have measured the probability that each picture will be remembered after a single view we analyze image feature and label that contribute to making an image memorable and we train a predictor based on global image descriptor we find that predicting image memorability is a task that can be addressed with current computer vision technique whereas making memorable image is a challenging task in visualization and photography this work is a first attempt to quantify this useful quality of image 
we first propose a new spatio temporal context distribution feature of interest point for human action recognition each action video is expressed a a set of relative xyt coordinate between pairwise interest point in a local region we learn a global gmm referred to a universal background model ubm using the relative coordinate feature from all the training video and then represent each video a the normalized parameter of a video specific gmm adapted from the global gmm in order to capture the spatio temporal relationship at different level multiple gmms are utilized to describe the context distribution of interest point over multi scale local region to describe the appearance information of an action video we also propose to use gmm to characterize the distribution of local appearance feature from the cuboid centered around the interest point accordingly an action video can be represented by two type of distribution feature multiple gmm distribution of spatio temporal context gmm distribution of local video appearance to effectively fuse these two type of heterogeneous and complementary distribution feature we additionally propose a new learning algorithm called multiple kernel learning with augmented feature afmkl to learn an adapted classifier based on multiple kernel and the pre learned classifier of other action class extensive experiment on kth multi view ixmas and complex ucf sport datasets demonstrate that our method generally achieves higher recognition accuracy than other state of the art method 
this paper demonstrates how the nonlocal principle benefit video matting via the knn laplacian which come with a straightforward implementation using motion aware k nearest neighbor in hindsight the fundamental problem to solve in video matting is to produce spatio temporally coherent cluster of moving foreground pixel when used a described the motion aware knn laplacian is effective in addressing this fundamental problem a demonstrated by sparse user markup typically on only one frame in a variety of challenging example featuring ambiguous foreground and background color changing topology with disocclusion significant illumination change fast motion and motion blur when working with existing laplacian based system we expect our laplacian can benefit them immediately with an improved clustering of moving foreground pixel 
in the area of d shape analysis research in mesh segmentation ha always been an important topic a it is a fundamental low level task which can be utilized in many application including computer aided design computer animation biomedical application and many other field we define the automatic robust mesh segmentation arm method in this paper which is invariant to isometric transformation is insensitive to noise and deformation performs closely to human perception is efficient in computation and is minimally dependent on prior knowledge in this work we develop a new framework namely the center shift which discovers meaningful segment of a d object by exploring the intrinsic geometric structure encoded in the biharmonic kernel our center shift framework ha three main step first we construct a feature space where every vertex on the mesh surface is associated with the corresponding biharmonic kernel density function value second we apply the center shift algorithm for initial segmentation third the initial segmentation result is refined through an efficient iterative process which lead to visually salient segmentation of the shape the performance of this segmentation method is demonstrated through extensive experiment on various set of d shape and different type of noise and deformation the experimental result of d shape segmentation have shown better performance of center shift compared to state of the art segmentation method 
recently sparse representation ha been introduced for robust object tracking by representing the object sparsely i e using only a few template via l norm minimization these so called l tracker exhibit promising tracking result in this work we address the object template building and updating problem in these l tracking approach which ha not been fully studied we propose to perform template updating in a new perspective a an online incremental dictionary learning problem which is efficiently solved through an online optimization procedure to guarantee the robustness and adaptability of the tracking algorithm we also propose to build a multi lifespan dictionary model by building target dictionary of different life span effective object observation can be obtained to deal with the well known drifting problem in tracking and thus improve the tracking accuracy we derive effective observation model both generatively and discriminatively based on the online multi lifespan dictionary learning model and deploy them to the bayesian sequential estimation framework to perform tracking the proposed approach ha been extensively evaluated on ten challenging video sequence experimental result demonstrate the effectiveness of the online learned template a well a the state of the art tracking performance of the proposed approach 
in this paper we propose a complete on device d reconstruction pipeline for mobile monocular hand held device which generates dense d model with absolute scale on site while simultaneously supplying the user with real time interactive feedback the method fill a gap in current cloud based mobile reconstruction service a it ensures at capture time that the acquired image set fulfills desired quality and completeness criterion in contrast to existing system the developed framework offer multiple innovative solution in particular we investigate the usability of the available on device inertial sensor to make the tracking and mapping process more resilient to rapid motion and to estimate the metric scale of the captured scene moreover we propose an efficient and accurate scheme for dense stereo matching which allows to reduce the processing time to interactive speed we demonstrate the performance of the reconstruction pipeline on multiple challenging indoor and outdoor scene of different size and depth variability 
this paper present a method of learning reconfigurable and or tree aot model discriminatively from weakly annotated data for object detection to explore the appearance and geometry space of latent structure effectively we first quantize the image lattice using an over complete set of shape primitive and then organize them into a directed a cyclic and or graph aog by exploiting their compositional relation we allow overlap between child node when combining them into a parent node which is equivalent to introducing an appearance or node implicitly for the overlapped portion the learning of an aot model consists of three component i unsupervised sub category learning i e branch of an object or node with the latent structure in aog being integrated out ii weakly supervised part configuration learning i e seeking the globally optimal parse tree in aog for each sub category to search the globally optimal parse tree in aog efficiently we propose a dynamic programming dp algorithm iii joint appearance and structural parameter training under latent structural svm framework in experiment our method is tested on pascal voc and detection benchmark of object class and outperforms comparable state of the art method 
segmenting d end firing transrectal ultrasound trus prostate image efficiently and accurately is of utmost importance for the planning and guiding d trus guided prostate biopsy poor image quality and imaging artifact of d trus image often introduce a challenging task in computation to directly extract the d prostate surface in this work we propose a novel global optimization approach to delineate d prostate boundary using it rotational resliced image around a specified axis which properly enforces the inherent rotational symmetry of prostate shape to jointly adjust a series of d slice wise segmentation in the global d sense we show that the introduced challenging combinatorial optimization problem can be solved globally and exactly by mean of convex relaxation in this regard we propose a novel coupled continuous max flow model which not only provides a powerful mathematical tool to analyze the proposed optimization problem but also amount to a new and efficient duality based algorithm extensive experiment demonstrate that the proposed method significantly outperforms the state of art method in term of efficiency accuracy reliability and le user interaction and reduces the execution time by a factor of 
the paper conjecture and demonstrates that repeatable key point based on salient symmetry at different scale can be detected by a novel analysis grounded on the wave equation rather than the heat equation underlying traditional gaussian scale space theory while the image structure found by most state of the art detector such a blob and corner occur typically on planar highly textured surface salient symmetry are widespread in diverse kind of image including those related to untextured object which are hardly dealt with by current feature based recognition pipeline we provide experimental result on standard datasets and also contribute with a new dataset focused on untextured object based on the positive experimental result we hope to foster further research on the promising topic of scale invariant analysis through the wave equation 
the problem of efficiently deciding which of a database of model is most similar to a given input query arises throughout modern computer vision motivated by application in recognition image retrieval and optimization there ha been significant recent interest in the variant of this problem in which the database model are linear subspace and the input is either a point or a subspace current approach to this problem have poor scaling in high dimension and may not guarantee sub linear query complexity we present a new approach to approximate nearest subspace search based on a simple new locality sensitive hash for subspace our approach allows point to subspace query for a database of subspace of arbitrary dimension d in a time that depends sub linearly on the number of subspace in the database the query complexity of our algorithm is linear in the ambient dimension d allowing it to be directly applied to high dimensional imagery data numerical experiment on model problem in image repatching and automatic face recognition confirm the advantage of our algorithm in term of both speed and accuracy 
the classical relieff and f statistic feature selection can not be directly applied into multi label problem due to the ambiguity produced from a data point attributed to multiple class simultaneously in this paper we present mrelieff and mf statistic algorithm for multi label feature selection discriminant feature are selected to boost the multi label classification accuracy the proposed mrelieff and mf statistic can be used in image categorization and annotation problem extensive experiment on image annotation task show the good performance of our approach to our knowledge this is the first work to generalize the relieff and f statistic feature selection algorithm for multi label image annotation task 
feature selection from sparse and high dimension feature using conventional greedy based boosting give classifier of poor generalization we propose a novel shrink boost method to address this problem it solves a sparse regularization problem with two iterative step first a boosting step us weighted training sample to learn a full high dimensional classifier on all feature this avoids over fitting to few feature and improves generalization next a shrinkage step shrink least discriminative classifier dimension to zero to remove the redundant feature in our object detection system we use shrink boost to select sparse feature from histogram of local binary pattern lbp of multiple quantization and image channel to learn classifier of additive lookup table lut our evaluation show that our classifier ha much better generalization than those from greedy based boosting and those from svm method even under limited number of train sample on public dataset of human detection and pedestrian detection we achieve better performance than state of the art on our more challenging dataset of bird detection we show promising result 
this paper extends the neighborhood component analysis method nca to learning a mixture of sparse distance metric for classification and dimensionality reduction we emphasize two important property in the recent learning literature locality and sparsity and pursue a set of local distance metric by maximizing a conditional likelihood of observed data and add l norm of eigenvalue of the distance metric to favor low rank matrix of fewer parameter experimental result on standard uci machine learning datasets face recognition datasets and image categorization datasets demonstrate the feasibility of our approach for both distance metric learning and dimensionality reduction 
we present a novel approach for video parsing and simultaneous online learning of dominant and anomalous behavior in surveillance video dominant behavior are those occurring frequently in video and hence usually do not attract much attention they can be characterized by different complexity in space and time ranging from a scene background to human activity in contrast an anomalous behavior is defined a having a low likelihood of occurrence we do not employ any model of the entity in the scene in order to detect these two kind of behavior in this paper video event are learnt at each pixel without supervision using densely constructed spatio temporal video volume furthermore the volume are organized into large contextual graph these composition are employed to construct a hierarchical codebook model for the dominant behavior by decomposing spatio temporal contextual information into unique spatial and temporal context the proposed framework learns the model of the dominant spatial and temporal event thus it is ultimately capable of simultaneously modeling high level behavior a well a low level spatial temporal and spatio temporal pixel level change 
we propose a novel model for the spatio temporal clustering of trajectory based on motion which applies to challenging street view video sequence of pedestrian captured by a mobile camera a key contribution of our work is the introduction of novel probabilistic region trajectory motivated by the non repeatability of segmentation of frame in a video sequence hierarchical image segment are obtained by using a state of the art hierarchical segmentation algorithm and connected from adjacent frame in a directed acyclic graph the region trajectory and measure of confidence are extracted from this graph using a dynamic programming based optimisation our second main contribution is a bayesian framework with a twofold goal to learn the optimal in a maximum likelihood sense random forest classifier of motion pattern based on video feature and construct a unique graph from region trajectory of different frame length and hierarchical level finally we demonstrate the use of isomap for effective spatio temporal clustering of the region trajectory of pedestrian we support our claim with experimental result on new and existing challenging video sequence 
dense motion of image point over many video frame can provide important information about the world however occlusion and drift make it impossible to compute long motion path by merely concatenating optical flow vector between consecutive frame instead we solve for entire path directly and flag the frame in which each is visible a in previous work we anchor each path to a unique pixel which guarantee an even spatial distribution of path unlike earlier method we allow path to be anchored in any frame by explicitly requiring that at least one visible path pass within a small neighborhood of every pixel we guarantee complete coverage of all visible point in all frame we achieve state of the art result on real sequence including both rigid and non rigid motion with significant occlusion 
a a central problem in computer vision and pattern recognition data representation ha attracted great attention in the past year non negative matrix factorization nmf which is a useful data representation method make great contribution on finding the latent structure of the data and lead to a part based representation by decomposing the data matrix into a few base and encoding with nonnegative constraint however non negative constraint is insufficient for getting more robust data representation in this paper we propose a novel method called a optimal non negative projection anp for image data representation and further analysis anp imposes a constraint on the encoding factor a a regularizer during matrix factorization in this way the learned data representation lead to a stable linear model no matter what kind of data label is selected for further processing thus it can preserve more intrinsic characteristic of the data regardless of any specific label we demonstrate the effectiveness of this novel algorithm through a set of evaluation on real world application 
we present a compositional model for video event detection a video is modeled using a collection of both global and segment level feature and kernel function are employed for similarity comparison the location of salient discriminative video segment are treated a a latent variable allowing the model to explicitly ignore portion of the video that are unimportant for classification a novel multiple kernel learning mkl latent support vector machine svm is defined that is used to combine and re weight multiple feature type in a principled fashion while simultaneously operating within the latent variable framework the compositional nature of the proposed model allows it to respond directly to the challenge of temporal clutter and intra class variation which are prevalent in unconstrained internet video experimental result on the trecvid multimedia event detection med dataset demonstrate the efficacy of the method 
a novel correspondence le approach is proposed to find a thin plate spline map between a pair of deformable d object represented by triangular surface mesh the proposed method work without landmark extraction and feature correspondence the aligning transformation is found simply by solving a system of nonlinear equation each equation is generated by integrating a nonlinear function over the object s domain we derive recursive formula for the efficient computation of these integral based on a series of comparative test on a large synthetic dataset our triangular mesh based algorithm outperforms state of the art method both in term of computing time and accuracy the applicability of the proposed approach ha been demonstrated on the registration of d lung ct volume 
the traditional shape from shading problem with a single light source and lambertian reflectance is challenging since the constraint implied by the illumination are not sufficient to specify local orientation photometric stereo algorithm a variant of shape from shading simplify the problem by controlling the illumination to obtain additional constraint in this paper we demonstrate that many natural lighting environment already have sufficient variability to constrain local shape we describe a novel optimization scheme that exploit this variability to estimate surface normal from a single image of a diffuse object in natural illumination we demonstrate the effectiveness of our method on both simulated and real image 
it is shown that the set of all i element collection of interdependent homography matrix describing homographies induced by i plane in the d scene between two view ha dimension i this improves on an earlier result which gave an upper bound for the dimension in question and solves a long standing open problem the significance of the present result lie in that it is critical to the identification of the full set of constraint to which collection of interdependent homography matrix are subject which in turn is critical to the design of constrained optimisation technique for estimating such collection from image data 
clothing recognition is an extremely challenging problem due to wide variation in clothing item appearance layering and style in this paper we tackle the clothing parsing problem using a retrieval based approach for a query image we find similar style from a large database of tagged fashion image and use these example to parse the query our approach combine parsing from pre trained global clothing model local clothing model learned on the fly from retrieved example and transferred parse mask paper doll item transfer from retrieved example experimental evaluation show that our approach significantly outperforms state of the art in parsing accuracy 
handling motion blur is one of important issue in visual slam for a fast moving camera motion blur is an unavoidable effect and it can degrade the result of localization and reconstruction severely in this paper we present a unified algorithm to handle motion blur for visual slam including the blur robust data association method and the fast deblurring method in our framework camera motion and d point structure are reconstructed by slam and the information from slam make the estimation of motion blur quite easy and effective reversely estimating motion blur enables robust data association and drift free localization of slam with blurred image the blurred image are recovered by fast deconvolution using slam data and more feature are extracted and registered to the map so that the slam procedure can be continued even with the blurred image in this way visual slam and deblurring are solved simultaneously and improve each other s result significantly 
scalability of object detector with respect to the number of class is a very important issue for application where many object class need to be detected while combining single class detector yield a linear complexity for testing multi class detector that localize all object at once come often at the cost of a reduced detection accuracy in this work we present a scalable multi class detection algorithm which scale sublinearly with the number of class without compromising accuracy to this end a shared discriminative codebook of feature appearance is jointly trained for all class and detection is also performed for all class jointly based on the learned sharing distribution of feature among class we build a taxonomy of object class the taxonomy is then exploited to further reduce the cost of multi class object detection our method ha linear training and sublinear detection complexity in the number of class we have evaluated our method on the challenging pascal voc and pascal voc datasets and show that scaling the system doe not lead to a loss in accuracy 
in this paper we show how to simplify a d morphable model our method only requires knowledge of the original highest resolution statistical model and lead to low resolution model in which the model statistic are a subset of the original high resolution model we employ an iterative edge collapse strategy where the deleted edge is chosen a a function of the model statistic we show that the expected value of the quadric error metric can be computed in closed form for a pca deformable model model parameter obtained using the model at any resolution lower can be used to reconstruct a high resolution surface providing a route to super resolution we provide experimental result for a statistical face model showing how the simplified model improve the efficiency of model fitting we are able to decrease the model resolution and fitting time by factor of approximately and respectively whilst inducing an error which is only slightly larger than the fitting error of the original model 
sparse coding which is the decomposition of a vector using only a few basis element is widely used in machine learning and image processing the basis set also called dictionary is learned to adapt to specific data this approach ha proven to be very effective in many image processing task traditionally the dictionary is an unstructured flat set of atom in this paper we study structured dictionary which are obtained from an epitome or a set of epitome the epitome is itself a small image and the atom are all the patch of a chosen size inside this image this considerably reduces the number of parameter to learn and provides sparse image decomposition with shift invariance property we propose a new formulation and an algorithm for learning the structured dictionary associated with epitome and illustrate their use in image de noising task 
we address the problem of determining where a photo wa taken by estimating a full dof plus intrincs camera pose with respect to a large geo registered d point cloud bringing together research on image localization landmark recognition and d pose estimation our method scale to datasets with hundred of thousand of image and ten of million of d point through the use of two new technique a co occurrence prior for ransac and bidirectional matching of image feature with d point we evaluate our method on several large data set and show state of the art result on landmark recognition a well a the ability to locate camera to within meter requiring only second per query 
gathering accurate training data for recognizing a set of attribute or tag on image or video is a challenge obtaining label via manual effort or from weakly supervised data typically result in noisy training label we develop the flipsvm a novel algorithm for handling these noisy structured label the flipsvm model label noise by flipping label on training example we show empirically that the flipsvm is effective on image and attribute and video tagging datasets 
the codebook based bag of word model is a widely applied model for image classification we analyze recent coding strategy in this model and find that saliency is the fundamental characteristic of coding the saliency in coding mean that if a visual code is much closer to a descriptor than other code it will obtain a very strong response the salient representation under maximum pooling operation lead to the state of the art performance on many database and competition however most current coding scheme do not recognize the role of salient representation so that they may lead to large deviation in representing local descriptor in this paper we propose salient coding which employ the ratio between descriptor nearest code and other code to describe descriptor this approach can guarantee salient representation without deviation we study salient coding on two set of image classification database scene and pascal voc the experimental result demonstrate that our approach outperforms all other coding method in image classification 
we study the challenging problem of localizing and classifying category specific object contour in real world image for this purpose we present a simple yet effective method for combining generic object detector with bottom up contour to identify object contour we also provide a principled way of combining information from different part detector and across category in order to study the problem and evaluate quantitatively our approach we present a dataset of semantic exterior boundary on more than object instance belonging to category using the image from the voc pascal challenge 
in this paper we introduce a novel method for depth acquisition based on refraction of light a scene is captured twice by a fixed perspective camera with the first image captured directly by the camera and the second by placing a transparent medium between the scene and the camera a depth map of the scene is then recovered from the displacement of scene point in the image unlike other existing depth from refraction method our method doe not require the knowledge of the pose and refractive index of the transparent medium but can recover them directly from the input image we hence call our method self calibrating depth from refraction experimental result on both synthetic and real world data are presented which demonstrate the effectiveness of the proposed method 
relating visual information to it linguistic semantic meaning remains an open and challenging area of research the semantic meaning of image depends on the presence of object their attribute and their relation to other object but precisely characterizing this dependence requires extracting complex visual information from an image which is in general a difficult and yet unsolved problem in this paper we propose studying semantic information in abstract image created from collection of clip art abstract image provide several advantage they allow for the direct study of how to infer high level semantic information since they remove the reliance on noisy low level object attribute and relation detector or the tedious hand labeling of image importantly abstract image also allow the ability to generate set of semantically similar scene finding analogous set of semantically similar real image would be nearly impossible we create set of semantically similar abstract scene with corresponding written description we thoroughly analyze this dataset to discover semantically important feature the relation of word to visual feature and method for measuring semantic similarity 
topic model such a plsa lda and their variant have been widely adopted for visual recognition however most of the adopted model if not all are unsupervised which neglected the valuable supervised label during model training in this paper we exploit recent advancement in supervised topic modeling more particularly the disclda model for object recognition we extend it to a part based visual representation to automatically identify and model different object part we call the proposed model a spatial disclda s disclda it model the appearance and location of the object part simultaneously which also take the supervised label into consideration it can be directly used a a classifier to recognize the object this is performed by an approximate inference algorithm based on gibbs sampling and bridge sampling method we examine the performance of our model by comparing it performance with another supervised topic model on two scene category datasets i e labelme and uiuc sport dataset we also compare our approach with other approach which model spatial structure of visual feature on the popular caltech dataset the experimental result illustrate that it provides competitive performance 
image based classification of tissue histology in term of different component e g normal signature category of aberrant signature provides a series of index for tumor composition subsequently aggregation of these index in each whole slide image wsi from a large cohort can provide predictive model of clinical outcome however the performance of the existing technique is hindered a a result of large technical and biological variation that are always present in a large cohort in this paper we propose two algorithm for classification of tissue histology based on robust representation of morphometric context which are built upon nuclear level morphometric feature at various location and scale within the spatial pyramid matching spm framework these method have been evaluated on two distinct datasets of different tumor type collected from the cancer genome atlas tcga and the experimental result indicate that our method are i extensible to different tumor type ii robust in the presence of wide technical and biological variation iii invariant to different nuclear segmentation strategy and iv scalable with varying training sample size in addition our experiment suggest that enforcing sparsity during the construction of morphometric context further improves the performance of the system 
this paper present a robust occupancy analysis system for thermal imaging reliable detection of people is very hard in crowded scene due to occlusion and segmentation problem we therefore propose a framework that optimises the occupancy analysis over long period by including information on the transition in occupancy when people enter or leave the monitored area in stable period with no activity close to the border people are detected and counted which contributes to a weighted histogram when activity close to the border is detected local tracking is applied in order to identify a crossing after a full sequence the number of people during all period are estimated using a probabilistic graph search optimisation the system is tested on a total of frame captured in sport arena the mean error for a minute period containing people is which is a half of the error percentage optained by detection only and better than the result of comparable work the framework is also tested on a public available dataset from an outdoor scene which prof the generality of the method 
computational color constancy is a very important topic in computer vision and ha attracted many researcher attention recently lot of research ha shown the effect of using high level visual content cue for improving illumination estimation however nearly all the existing method are essentially combinational strategy in which image s content analysis is only used to guide the combination or selection from a variety of individual illumination estimation method in this paper we propose a novel bilayer sparse coding model for illumination estimation that considers image similarity in term of both low level color distribution and high level image scene content simultaneously for the purpose the image s scene content information is integrated with it color distribution to obtain optimal illumination estimation model the experimental result on real world image set show that our algorithm is superior to some prevailing illumination estimation method even better than some combinational method 
we aim to unsupervisedly discover human s action motion pattern of manipulating various object in scenario such a assisted living we are motivated by two key observation first large variation exists in motion pattern associated with various type of object being manipulated thus manually defining motion primitive is infeasible second some motion pattern are shared among different object being manipulated while others are object specific we therefore propose a nonparametric bayesian method that adopts a hierarchical dirichlet process prior to learn representative manipulation motion pattern in an unsupervised manner taking easy to obtain object detection score map and dense motion trajectory a input the proposed probabilistic model can discover motion pattern group associated with different type of object being manipulated with a shared manipulation pattern dictionary the size of the learned dictionary is automatically inferred comprehensive experiment on two assisted living benchmark and a cooking motion dataset demonstrate superiority of our learned manipulation pattern dictionary in representing manipulation action for recognition 
we conduct image classification by learning a class to image distance function that match object the set of object in training image for an image class are treated a a collage when presented with a test image the best matching between this collage of training image object and those in the test image is found we validate the efficacy of the proposed model on the pascal and sun datasets showing that our model is effective for object classification and scene classification task state of the art image classification result are obtained and qualitative result demonstrate that object can be accurately matched 
a good model of object shape is essential in application such a segmentation object detection inpainting and graphic for example when performing segmentation local constraint on the shape can help where the object boundary is noisy or unclear and global constraint can resolve ambiguity where background clutter look similar to part of the object in general the stronger the model of shape the more performance is improved in this paper we use a type of deep boltzmann machine that we call a shape boltzmann machine shapebm for the task of modeling binary shape image we show that the shapebm characterizes a strong model of shape in that sample from the model look realistic and it can generalize to generate sample that differ from training example we find that the shapebm learns distribution that are qualitatively and quantitatively better than existing model for this task 
generic object detection is the challenging task of proposing window that localize all the object in an image regardless of their class such detector have recently been shown to benefit many application such a speeding up class specific object detection weakly supervised learning of object detector and object discovery in this paper we introduce a novel and very efficient method for generic object detection based on a randomized version of prim s algorithm using the connectivity graph of an image s super pixel with weight modelling the probability that neighbouring super pixel belong to the same object the algorithm generates random partial spanning tree with large expected sum of edge weight object localization are proposed a bounding box of those partial tree our method ha several benefit compared to the state of the art thanks to the efficiency of prim s algorithm it sample proposal very quickly proposal are obtained in about s with proposal bound to super pixel boundary yet diversified by randomization it yield very high detection rate and window that tightly fit object in extensive experiment on the challenging pascal voc and and sun benchmark datasets we show that our method improves over state of the art competitor for a wide range of evaluation scenario 
this paper present a comprehensive theory of photometric surface reconstruction from image derivative for unknown isotropic brdfs we show that two measurement of spatial and temporal image derivative under unknown light source on a circle suffice to determine the surface this result is the culmination of a series of fundamental observation first we discover a photometric invariant that relates image derivative to the surface geometry regardless of the form of isotropic brdf next we show that just two pair of differential image from unknown light direction suffice to recover surface information from the photometric invariant this is shown to be equivalent to determining isocontours of constant magnitude of the surface gradient a well a isocontours of constant depth further we prove that specification of the surface normal at a single point completely determines the surface depth from these isocontours in addition we propose practical algorithm that require additional initial or boundary information but recover depth from lower order derivative our theoretical result are illustrated with several example on synthetic and real data 
linear svms are efficient in both training and testing however the data in real application is rarely linearly separable non linear kernel svms are too computationally intensive for application with large scale data set recently locally linear classifier have gained popularity due to their efficiency whilst remaining competitive with kernel method the vanilla nearest neighbor algorithm is one of the simplest locally linear classifier but it lack robustness due to the noise often present in real world data in this paper we introduce a novel local classifier parametric nearest neighbor p nn and it extension ensemble of p nn ep nn we parameterize the nearest neighbor algorithm based on the minimum weighted squared euclidean distance between the data point and the prototype where a prototype is represented by a locally linear combination of some data point meanwhile our method attempt to jointly learn both the prototype and the classifier parameter discriminatively via max margin this make our classifier suitable to approximate the classification decision boundary locally based on nonlinear function during testing the computational complexity of both classifier is linear in the product of the dimension of data and the number of prototype our classification result on mnist usps letter and char k are comparable and in some case are better than many other method such a the state of the art locally linear classifier 
this paper present a realtime incremental multibody visual slam system that allows choosing between full d reconstruction or simply tracking of the moving object motion reconstruction of dynamic point or object from a monocular camera is considered very hard due to well known problem of observability we attempt to solve the problem with a bearing only tracking bot and by integrating multiple cue to avoid observability issue the bot is accomplished through a particle filter and by integrating multiple cue from the reconstruction pipeline with the help of these cue many real world scenario which are considered unobservable with a monocular camera is solved to reasonable accuracy this enables building of a unified dynamic d map of scene involving multiple moving object tracking and reconstruction is preceded by motion segmentation and detection which make use of efficient geometric constraint to avoid difficult degenerate motion where object move in the epipolar plane result reported on multiple challenging real world image sequence verify the efficacy of the proposed framework 
the representation of local image patch is crucial for the good performance and efficiency of many vision task patch descriptor have been designed to generalize towards diverse variation depending on the application a well a the desired compromise between accuracy and efficiency we present a novel formulation of patch description that serf such issue well sparse quantization lie at it heart this allows for efficient encoding leading to powerful novel binary descriptor yet also to the generalization of existing descriptor like sift or brief we demonstrate the capability of our formulation for both key point matching and image classification our binary descriptor achieve state of the art result for two key point matching benchmark namely those by brown and mikolajczyk for image classification we propose new descriptor that perform similar to sift on caltech and pascal voc 
conventional saliency analysis method measure the saliency of individual pixel the resulting saliency map inevitably loses information in the original image and finding salient object in it is difficult we propose to detect salient object by directly measuring the saliency of an image window in the original image and adopt the well established sliding window based object detection paradigm 
we propose a novel offline tracking algorithm based on model averaged posterior estimation through patch matching across frame contrary to existing online and offline tracking method our algorithm is not based on temporally ordered estimate of target state but attempt to select easy to track frame first out of the remaining one without exploiting temporal coherency of target the posterior of the selected frame is estimated by propagating density from the already tracked frame in a recursive manner the density propagation across frame is implemented by an efficient patch matching technique which is useful for our algorithm since it doe not require motion smoothness assumption also we present a hierarchical approach where a small set of key frame are tracked first and non key frame are handled by local key frame our tracking algorithm is conceptually well suited for the sequence with abrupt motion shot change and occlusion we compare our tracking algorithm with existing technique in real video with such challenge and illustrate it superior performance qualitatively and quantitatively 
we propose an algorithm for creating superpixels the major step in our algorithm is simply minimizing two pseudo boolean function the processing time of our algorithm on image of moderate size is only half a second experiment on a benchmark dataset show that our method produce superpixels of comparable quality with existing algorithm last but not least the speed of our algorithm is independent of the number of superpixels which is usually the bottle neck for the traditional algorithm of superpixel creation 
a wide range of property and assumption determine the most appropriate spatial matching model for an application e g recognition detection registration or large scale image retrieval most notably these include discriminative power geometric invariance rigidity constraint mapping constraint assumption made on the underlying feature or descriptor and of course computational complexity having image retrieval in mind we present a very simple model inspired by hough voting in the transformation space where vote arise from single feature correspondence a relaxed matching process allows for multiple matching surface or non rigid object under one to one mapping yet is linear in the number of correspondence we apply it to geometry re ranking in a search engine yielding superior performance with the same space requirement but a dramatic speed up compared to the state of the art 
the current state of the art solution for object detection describe each class by a set of model trained on discovered sub class so called component with each model itself composed of collection of interrelated part deformable model these detector build upon the now classic histogram of oriented gradient linear svm combo abstract in this paper we revisit some of the core assumption in hog svm and show that by properly designing the feature pooling feature selection preprocessing and training method it is possible to reach top quality at least for pedestrian detection using a single rigid component abstract we provide experiment for a large design space that give insight into the design of classifier a well a relevant information for practitioner our best detector is fully feed forward ha a single unified architecture us only histogram of oriented gradient and colour information in monocular static image and improves over other method on the inria eth and caltech usa datasets reducing the average miss rate over hog svm by more than 
background modeling and subtraction is an essential task in video surveillance application most traditional study use information observed in past frame to create and update a background model to adapt to background change the background model ha been enhanced by introducing various form of information including spatial consistency and temporal tendency in this paper we propose a new framework that leverage information from a future period our proposed approach realizes a low cost and highly accurate background model the proposed framework is called bidirectional background modeling and performs background subtraction based on bidirectional analysis i e analysis from past to present and analysis from future to present although a result will be output with some delay because information is taken from a future period our proposed approach improves the accuracy by about if only a millisecond of delay is acceptable furthermore the memory cost can be reduced by about relative to typical background modeling 
inference in continuous label markov random field is a challenging task we use particle belief propagation pbp for solving the inference problem in continuous label space sampling particle from the belief distribution is typically done by using metropolis hastings mh markov chain monte carlo mcmc method which involves sampling from a proposal distribution this proposal distribution ha to be carefully designed depending on the particular model and input data to achieve fast convergence we propose to avoid dependence on a proposal distribution by introducing a slice sampling based pbp algorithm the proposed approach show superior convergence performance on an image denoising toy example our finding are validated on a challenging relational d feature tracking application 
numerous existing object segmentation framework commonly utilize the object bounding box a a prior in this paper we address semantic segmentation assuming that object bounding box are provided by object detector but no training data with annotated segment are available based on a set of segment hypothesis we introduce a simple voting scheme to estimate shape guidance for each bounding box the derived shape guidance is used in the subsequent graph cut based figure ground segmentation the final segmentation result is obtained by merging the segmentation result in the bounding box we conduct an extensive analysis of the effect of object bounding box accuracy comprehensive experiment on both the challenging pascal voc object segmentation dataset and grabcut image segmentation dataset show that the proposed approach achieves competitive result compared to previous detection or bounding box prior based method a well a other state of the art semantic segmentation method 
single camera based multiple person tracking is often hindered by difficulty such a occlusion and change in appearance in this paper we address such problem by proposing a robust part based tracking by detection framework human detection using part model ha become quite popular yet it extension in tracking ha not been fully explored our approach learns part based person specific svm classifier which capture the articulation of the human body in dynamically changing appearance and background with the part based model our approach is able to handle partial occlusion in both the detection and the tracking stage in the detection stage we select the subset of part which maximizes the probability of detection which significantly improves the detection performance in crowded scene in the tracking stage we dynamically handle occlusion by distributing the score of the learned person classifier among it corresponding part which allows u to detect and predict partial occlusion and prevent the performance of the classifier from being degraded extensive experiment using the proposed method on several challenging sequence demonstrate state of the art performance in multiple people tracking 
tensor based dimensionality reduction ha recently attracted attention from computer vision and pattern recognition community for both feature extraction and data compression a an unsupervised method high order singular value decomposition hosvd search for low rank subspace such that the low rank approximation error is minimized in this paper we propose a new unsupervised high order tensor decomposition approach which employ the strength of discriminative analysis and k mean clustering to adaptively select subspace that improve the clustering classification and retrieval capability of hosvd we provide both theoretical analysis to guarantee that our new method generates more discriminative subspace and empirical study on several public computer vision data set to show the consistent improvement of our method over existing method 
a observed in several recent publication improved retrieval performance is achieved when pairwise similarity between the query and the database object are replaced with more global affinity that also consider the relation among the database object this is commonly achieved by propagating the similarity information in a weighted graph representing the database and query object instead of propagating the similarity information on the original graph we propose to utilize the tensor product graph tpg obtained by the tensor product of the original graph with itself by virtue of this construction not only local but also long range similarity among graph node are explicitly represented a higher order relation making it possible to better reveal the intrinsic structure of the data manifold in addition we improve the local neighborhood structure of the original graph in a preprocessing stage we illustrate the benefit of the proposed approach on shape and image ranking and retrieval task we are able to achieve the bull s eye retrieval score of on mpeg shape dataset which is much higher than the state of the art algorithm 
the current paper proposes a new parametric local color correction technique initially several color transfer function are computed from the output of the mean shift color segmentation algorithm secondly color influence map are calculated finally the contribution of every color transfer function is merged using the weight from the color influence map the proposed approach is compared with both global and local color correction approach result show that our method outperforms the technique ranked first in a recent performance evaluation on this topic moreover the proposed approach is computed in about one tenth of the time 
this paper proposes a very general max margin learning framework for distance based clustering to this end it formulates clustering a a high order energy minimization problem with latent variable and applies a dual decomposition approach for training this model the resulting framework allows learning a very broad class of distance function permit an automatic determination of the number of cluster during testing and is also very efficient a an additional contribution we show how our method can be generalized to handle the training of a very broad class of important model in computer vision arbitrary high order latent crfs experimental result verify it effectiveness 
this paper extends classical object pose and relative camera motion estimation algorithm for imaging sensor sampling the scene through light path many algorithm in multi view geometry assume that every pixel observes light traveling in a single line in space we wish to relax this assumption and address various theoretical and practical issue in modeling camera ray a piece wise linear path such path consisting of finitely many linear segment are typical of any simple camera configuration with reflective and refractive element our main contribution is to propose efficient algorithm that can work with the complete light path without knowing the correspondence between their individual segment and the scene point second we investigate light path containing infinitely many and small piece wise linear segment that can be modeled using simple parametric curve such a conic we show compelling simulation and real experiment involving catadioptric configuration and mirage to validate our study 
random forest have been successfully applied to various high level computer vision task such a human pose estimation and object segmentation these model are extremely efficient but work under the assumption that the output variable such a body part location or pixel label are independent in this paper we present a conditional regression forest model for human pose estimation that incorporates dependency relationship between output variable through a global latent variable while still maintaining a low computational cost we show that the incorporation of a global latent variable encoding torso orientation or human height etc can dramatically increase the accuracy of body joint location prediction our model also allows efficient and seamless incorporation of prior knowledge about the problem instance such a the height or orientation of the human subject which can be available from the problem context or via a temporal model we show that our method significantly outperforms state of the art method for pose estimation from depth image the conditional regression model proposed in the paper is general and can be applied to other problem where random forest are used 
relative comparative attribute are promising for thematic ranking of visual entity which also aid in recognition task however attribute rank learning often requires a substantial amount of relational supervision which is highly tedious and apparently impractical for real world application in this paper we introduce the semantic transform which under minimal supervision adaptively find a semantic feature space along with a class ordering that is related in the best possible way such a semantic space is found for every attribute category to relate the class under weak supervision the class ordering need to be refined according to a cost function in an iterative procedure this problem is ideally np hard and we thus propose a constrained search tree formulation for the same driven by the adaptive semantic feature space representation our model achieves the best result to date for all of the task of relative absolute and zero shot classification on two popular datasets 
rank correlation measure are known for their resilience to perturbation in numeric value and are widely used in many evaluation metric such ordinal measure have rarely been applied in treatment of numeric feature a a representational transformation we emphasize the benefit of ordinal representation of input feature both theoretically and empirically we present a family of algorithm for computing ordinal embeddings based on partial order statistic apart from having the stability benefit of ordinal measure these embeddings are highly nonlinear giving rise to sparse feature space highly favored by several machine learning method these embeddings are deterministic data independent and by virtue of being based on partial order statistic add another degree of resilience to noise these machine learning free method when applied to the task of fast similarity search outperform state of the art machine learning method with complex optimization setup for solving classification problem the embeddings provide a nonlinear transformation resulting in sparse binary code that are well suited for a large class of machine learning algorithm these method show significant improvement on voc using simple linear classifier which can be trained quickly our method can be extended to the case of polynomial kernel while permitting very efficient computation further since the popular min hash algorithm is a special case of our method we demonstrate an efficient scheme for computing min hash on conjunction of binary feature the actual method can be implemented in about line of code in most language line in mat lab and doe not require any data driven optimization 
current pedestrian tracking approach ignore important aspect of human behavior human are not moving independently but they closely interact with their environment which includes not only other person but also different scene object typical everyday scenario include people moving in group pushing child stroller or pulling luggage in this paper we propose a probabilistic approach for classifying such person object interaction associating object to person and predicting how the interaction will most likely continue our approach relies on stereo depth information in order to track all scene object in d while simultaneously building up their d shape model these model and their relative spatial arrangement are then fed into a probabilistic graphical model which jointly infers pairwise interaction and object class the inferred interaction can then be used to support tracking by recovering lost object track we evaluate our approach on a novel dataset containing more than frame of person object interaction in video sequence and demonstrate good performance in challenging real world scenario 
this paper address the challenge of recognizing behavior of group of individual in unconstraint surveillance environment a opposed to approach that rely on agglomerative or decisive hierarchical clustering technique we propose to recognize group interaction without making hard decision about the underlying group structure instead we use a probabilistic grouping strategy evaluated from the pairwise spatial temporal tracking information a path based grouping scheme determines a soft segmentation of group and produce a weighted connection graph where it edge express the probability of individual belonging to a group without further segmenting this graph we show how a large number of lowand high level behavior recognition task can be performed our work build on a mature multi camera multi target person tracking system that operates in real time we derive probabilistic model to analyze individual track motion a well a group interaction we show that the soft grouping can combine with motion analysis elegantly to robustly detect and predict group level activity experimental result demonstrate the efficacy of our approach 
many computer vision problem e g camera calibration image alignment structure from motion are solved through a nonlinear optimization method it is generally accepted that nd order descent method are the most robust fast and reliable approach for nonlinear optimization of a general smooth function however in the context of computer vision nd order descent method have two main drawback the function might not be analytically differentiable and numerical approximation are impractical the hessian might be large and not positive definite to address these issue this paper proposes a supervised descent method sdm for minimizing a non linear least square nls function during training the sdm learns a sequence of descent direction that minimizes the mean of nls function sampled at different point in testing sdm minimizes the nls objective using the learned descent direction without computing the jacobian nor the hessian we illustrate the benefit of our approach in synthetic and real example and show how sdm achieves state of the art performance in the problem of facial feature detection the code is available at www humansensing c cmu edu intraface 
most existing pose robust method are too computational complex to meet practical application and their performance under unconstrained environment are rarely evaluated in this paper we propose a novel method for pose robust face recognition towards practical application which is fast pose robust and can work well under unconstrained environment firstly a d deformable model is built and a fast d model fitting algorithm is proposed to estimate the pose of face image secondly a group of gabor filter are transformed according to the pose and shape of face image for feature extraction finally pca is applied on the pose adaptive gabor feature to remove the redundance and cosine metric is used to evaluate the similarity the proposed method ha three advantage the pose correction is applied in the filter space rather than image space which make our method le affected by the precision of the d model by combining the holistic pose transformation and local gabor filtering the final feature is robust to pose and other negative factor in face recognition the d structure and facial symmetry are successfully used to deal with self occlusion extensive experiment on feret and pie show the proposed method outperforms state of the art method significantly meanwhile the method work well on lfw 
a practical lipreading system can be considered either a subject dependent sd or subject independent si an sd system is user specific i e customized for some particular user while an si system ha to cope with a large number of user these two type of system pose variant challenge and have to be treated differently in this paper we propose a simple deterministic model to tackle the problem the model first seek a low dimensional manifold where visual feature extracted from the frame of a video can be projected onto a continuous deterministic curve embedded in a path graph moreover it can map arbitrary point on the curve back into the image space making it suitable for temporal interpolation based on the model we develop two separate strategy for sd and si lipreading the former is turned into a simple curve matching problem while for the latter we propose a video normalization scheme to improve the system developed by zhao et al we evaluated our system on the ouluvs database and achieved recognition rate more than higher than the one reported by zhao et al in both sd and si testing scenario 
in this paper we present a novel approach to model d human body with variation on both human shape and pose by exploring a tensor decomposition technique d human body modeling is important for d reconstruction and animation of realistic human body which can be widely used in tele presence and video game application it is challenging due to a wide range of shape variation over different people and pose the existing scape model is popular in computer vision for modeling d human body however it considers shape and pose deformation separately which is not accurate since pose deformation is person dependent our tensor based model address this issue by jointly modeling shape and pose deformation experimental result demonstrate that our tensor based model outperforms the scape model quite significantly we also apply our model to capture human body using microsoft kinect sensor with excellent result 
we address the problem of multiple view face detection mvfd in unconstrained environment in order to achieve generalized face detection we use part based image representation by tessellation of small image patch which are typified by d vector array face are detected by a method named vector array recognition by indexing and sequencing varis varis is designed to find the optimal similarity matching between the input image and stored exemplar while allowing wide geometrical variation that are limited only by topological constraint aggregated similarity is further enhanced by matching the input image with compound exemplar the novel compounding procedure also reduces the number of exemplar necessary for each class representation varis with compounding performs efficient parallel classification and ha polynomial computational complexity 
in the square jigsaw puzzle problem one is required to reconstruct the complete image from a set of non overlapping unordered square puzzle part here we propose a fully automatic solver for this problem where unlike some previous work it assumes no clue regarding part location and requires no prior knowledge about the original image or it simplified e g lower resolution version to do so we introduce a greedy solver which combine both informed piece placement and rearrangement of puzzle segment to find the final solution among our other contribution are new compatibility metric which better predict the chance of two given part to be neighbor and a novel estimation measure which evaluates the quality of puzzle solution without the need for ground truth information incorporating these contribution our approach facilitates solution that surpass state of the art solver on puzzle of size larger than ever attempted before 
we introduce a novel probabilistic framework for image registration this framework considers in contrast to previous one local neighborhood information we integrate the neighborhood information into the framework by adding layer of latent random variable characterizing the descriptive information of each image this extension ha multiple advantage it allows for a unified description of geometric and iconic registration with the consequential analysis of similarity it enables to arrange registration technique in a continuum limited by pure intensity and feature based registration with this wide spectrum of technique combined we can model hybrid registration approach the probabilistic coupling allows further to deduce optimal descriptor and to model the adaptation of description layer during the process a it is done for joint registration segmentation finally we deduce a new registration algorithm that allows for a dynamic adaptation of the description layer during the registration excellent result confirm the advantage of the new registration method the major contribution of this article lie however in the theoretical analysis 
in this paper we explore approach to accelerating segmentation and edge detection algorithm based on the emph gpb framework the paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offer performance that is competitive with the pb detector the paper also describes an approach for computing a reduced order normalized cut that capture the essential feature of the original problem but can be computed in le than half a second on a standard computing platform 
most existing structure from motion sfm approach for unordered image cannot handle multiple instance of the same structure in the scene when image pair containing different instance are matched based on visual similarity the pairwise geometric relation a well a the correspondence inferred from such pair are erroneous which can lead to catastrophic failure in the reconstruction in this paper we investigate the geometric ambiguity caused by the presence of repeated or duplicate structure and show that to disambiguate between multiple hypothesis requires more than pure geometric reasoning we couple an expectation maximization em based algorithm that estimate camera pose and identifies the false match pair with an efficient sampling method to discover plausible data association hypothesis the sampling method is informed by geometric and image based cue our algorithm usually recovers the correct data association even in the presence of large number of false pairwise match 
complex event essentially include human scene object and action that can be summarized by visual attribute so leveraging relevant attribute properly could be helpful for event detection many work have exploited attribute at image level for various application however attribute at image level are possibly insufficient for complex event detection in video due to their limited capability in characterizing the dynamic property of video data hence we propose to leverage attribute at video level named a video attribute in this work i e the semantic label of external video are used a attribute compared to complex event video these external video contain simple content such a object scene and action which are the basic element of complex event specifically building upon a correlation vector which correlate the attribute and the complex event we incorporate video attribute latently a extra informative cue into the event detector learnt from complex event video extensive experiment on a real world large scale dataset validate the efficacy of the proposed approach 
this paper address the problem of affine distortion caused by viewpoint change for the application of image retrieval we study how to expand the visual word from a query image for better retrieval recall without the sacrifice of retrieval precision and efficiency our main contribution is the building of visual dictionary that retain the mapping relationship between visual word extracted from different viewpoint of the same object additionally in each mapping rule we record the affine transformation in which the two visual word are related a a compact code of viewpoint relationship by analogizing the concept of verb stem and verb tense in text we use visual stem to denote visual word extracted from robust local patch and record the relationship between their affine variant a visual stem mapping rule including the geometric relationship coded a geometric tense in this way our method augments original visual vocabulary with sufficient and accurate expansion information in query phase only the object corresponding to the same visual stem and coherent geometric tense code will be regarded a similar one moreover the mapping rule can be learned offline with only one sample for each object experiment show that our method can support efficient object retrieval with high recall requiring little extra time and space cost over traditional visual vocabulary 
learning based method have been widely used in detecting landmark or anatomical structure in various medical imaging application the performance of discriminative learning technique ha been demonstrated superior to traditional low level filtering in robustness and scalability nevertheless some structure and pattern are more difficult to be defined by such method and complicated and ad hoc method still need to be used e g a non rigid and highly deformable wire structure in this paper we propose a novel scheme to train classifier to detect the marker and guide wire segment anchored by marker the classifier utilizes the marker a the end point and parameterizes the wire in between them the probability of the marker and the wire are integrated in a bayesian framework a a result both the marker and the wire detection are improved by such a unified approach promising result are demonstrated by quantitative evaluation on fluoroscopic sequence with frame our training scheme can further be generalized to localize longer guidewire with higher degree of parameterization 
we describe a structure from motion framework that handle generalized camera such a moving rolling shutter camera and work at an unprecedented scale billion of image covering million of linear kilometer of road by exploiting a good relative pose prior along vehicle path we exhibit a planet scale appearance augmented point cloud constructed with our framework and demonstrate it practical use in correcting the pose of a street level image collection 
detecting visually salient region in image is one of the fundamental problem in computer vision we propose a novel method to decompose an image into large scale perceptually homogeneous element for efficient salient region detection using a soft image abstraction representation by considering both appearance similarity and spatial distribution of image pixel the proposed representation abstract out unnecessary image detail allowing the assignment of comparable saliency value across similar region and producing perceptually accurate salient region detection we evaluate our salient region detection approach on the largest publicly available dataset with pixel accurate annotation the experimental result show that the proposed method outperforms alternate method reducing the mean absolute error by compared to the previous best result while being computationally more efficient 
the most defining characteristic of texture is it underlying geometry although the appearance of texture is a dynamic a it illumination and viewing condition it geometry remains constant in this work we study the fundamental characteristic property of texture geometry self similarity and scale variability and exploit them to perform surface normal estimation and geometric texture classification texture whether they are regular or stochastic exhibit some form of repetition in their underlying geometry we use this property to derive a photometric stereo method uniquely tailored to utilize the redundancy in geometric texture using basic observation about the scale variability of texture geometry we derive a compact rotation invariant scale space representation of geometric texture to evaluate this representation we introduce an extensive new texture database that contains multiple distance a well a in plane and out of plane rotation the high accuracy of the classification result indicate the descriptive yet compact nature of our texture representation and demonstrates the importance of geometric texture analysis pointing the way towards improvement in appearance modeling and synthesis 
in this paper we formulate object tracking in a particle filter framework a a multi task sparse learning problem which we denote a multi task tracking mtt since we model particle a linear combination of dictionary template that are updated dynamically learning the representation of each particle is considered a single task in mtt by employing popular sparsity inducing p q mixed norm p and q we regularize the representation problem to enforce joint sparsity and learn the particle representation together a compared to previous method that handle particle independently our result demonstrate that mining the interdependency between particle improves tracking performance and overall computational complexity interestingly we show that the popular l tracker is a special case of our mtt formulation denoted a the l tracker when p q the learning problem can be efficiently solved using an accelerated proximal gradient apg method that yield a sequence of closed form update a such mtt is computationally attractive we test our proposed approach on challenging sequence involving heavy occlusion drastic illumination change and large pose variation experimental result show that mtt method consistently outperform state of the art tracker 
we propose a principled probabilistic formulation of object saliency a a sampling problem this novel formulation allows u to learn from a large corpus of unlabelled image which patch of an image are of the greatest interest and most likely to correspond to an object we then sample the object saliency map to propose object location we show that using only a single object location proposal per image we are able to correctly select an object in over of the image in the pascal voc dataset substantially outperforming existing approach furthermore we show that our object proposal can be used a a simple unsupervised approach to the weakly supervised annotation problem our simple unsupervised approach to annotating object of interest in image achieves a higher annotation accuracy than most weakly supervised approach 
we present a computational imaging method for raw material classification using feature of bidirectional texture function btf texture is an intrinsic feature for many material such a wood fabric and granite at appropriate scale even uniform material will also exhibit texture feature that can be helpful for recognition such a paper metal and ceramic to cope with the high dimensionality of btfs in this paper we proposed to learn discriminative illumination pattern and texture filter with which we can directly measure optimal projection of btfs for classification we also studied the effect of texture rotation and scale variation for material classification we built an led based multispectral dome with which we have acquired a btf database of a variety of material and demonstrated the effectiveness of the proposed approach for material classification 
the problem of finding one dimensional structure in image and video can be formulated a a problem of searching for cycle in graph in an untangling cycle cost function wa proposed for identifying persistent cycle in a weighted graph corresponding to salient contour in an image we have analyzed their method and give two significant improvement first we generalize their cost function to a contour cut criterion and give a computational solution by solving a family of hermitian eigenvalue problem second we use the idea of a graph circulation which ensures that each node ha a balanced inand out flow and permit a natural random walk interpretation of our cost function we show that our method find far more accurate contour in image than furthermore we show that our method is robust to graph compression which allows u to accelerate the computation without loss of accuracy 
attribute based query offer an intuitive way of image retrieval in which user can describe the intended search target with understandable attribute in this paper we develop a general and powerful framework to solve this problem by leveraging a large pool of weak attribute comprised of automatic classifier score or other mid level representation that can be easily acquired with little or no human labor we extend the existing retrieval model of modeling dependency within query attribute to modeling dependency of query attribute on a large pool of weak attribute which is more expressive and scalable to efficiently learn such a large dependency model without overfitting we further propose a semi supervised graphical model to map each multiattribute query to a subset of weak attribute through extensive experiment over several attribute benchmark we demonstrate consistent and significant performance improvement over the state of the art technique in addition we compile the largest multi attribute image retrieval dateset to date including fully labeled query attribute and weak attribute of million image 
it ha been shown that a surface deforming isometric ally can be reconstructed from a single image and a template d shape method from the literature solve this problem efficiently however they all assume that the camera model is calibrated which drastically limit their applicability we propose i a general variational framework that applies to calibrated and uncalibrated general camera model and ii self calibrating d reconstruction algorithm for the weak perspective and full perspective camera model in the former case our algorithm return the normal field and camera s scale factor in the latter case our algorithm return the normal field depth and camera s focal length our algorithm are the first to achieve deformable d reconstruction including camera self calibration they apply to much more general setup than existing method experimental result on simulated and real data show that our algorithm give result with the same level of accuracy a existing method which use the true focal length on perspective image and correctly find the normal field on affine image for which the existing method fail 
in real world application of visual recognition many factor such a pose illumination or image quality can cause a significant mismatch between the source domain on which classifier are trained and the target domain to which those classifier are applied a such the classifier often perform poorly on the target domain domain adaptation technique aim to correct the mismatch existing approach have concentrated on learning feature representation that are invariant across domain and they often do not directly exploit low dimensional structure that are intrinsic to many vision datasets in this paper we propose a new kernel based method that take advantage of such structure our geodesic flow kernel model domain shift by integrating an infinite number of subspace that characterize change in geometric and statistical property from the source to the target domain our approach is computationally advantageous automatically inferring important algorithmic parameter without requiring extensive cross validation or labeled data from either domain we also introduce a metric that reliably measure the adaptability between a pair of source and target domain for a given target domain and several source domain the metric can be used to automatically select the optimal source domain to adapt and avoid le desirable one empirical study on standard datasets demonstrate the advantage of our approach over competing method 
discrete graphical model also known a discrete markov random field are a major conceptual tool to model the structure of optimization problem in computer vision while in the last decade research ha focused on fast approximative method algorithm that provide globally optimal solution have come more into the research focus in the last year however large scale computer vision problem seemed to be out of reach for such method in this paper we introduce a promising way to bridge this gap based on partial optimality and structural property of the underlying problem factorization combining these preprocessing step we are able to solve grid of size x in le than second on the hitherto unsolvable chinese character dataset of nowozin et al we obtain provably optimal result in of the instance and achieve competitive runtimes on other recent benchmark problem while in the present work only generalized potts model are considered an extension to general graphical model seems to be feasible 
this paper examines numerical algorithm for factorization of a low rank matrix with missing component we first propose a new method that incorporates a damping factor into the wiberg method to solve the problem the new method is characterized by the way it constrains the ambiguity of the matrix factorization which help improve both the global convergence ability and the local convergence speed we then present experimental comparison with the latest method used to solve the problem no comprehensive comparison of the method that have been proposed recently ha yet been reported in literature in our experiment we prioritize the assessment of the global convergence performance of each method that is how often and how fast the method can reach the global optimum starting from random initial value our conclusion is that top performance is achieved by a group of method based on newton family minimization with damping factor that reduce the problem by eliminating either of the two factored matrix our method which belongs to this group consistently show a global convergence rate for different type of affine structure from motion data with a very high population of missing component 
in this paper we present an approach for scene understanding by reasoning physical stability of object from point cloud we utilize a simple observation that by human design object in static scene should be stable with respect to gravity this assumption is applicable to all scene category and pose useful constraint for the plausible interpretation par in scene understanding our method consists of two major step geometric reasoning recovering solid d volumetric primitive from defective point cloud and physical reasoning grouping the unstable primitive to physically stable object by optimizing the stability and the scene prior we propose to use a novel disconnectivity graph dg to represent the energy landscape and use a swendsen wang cut mcmc method for optimization in experiment we demonstrate that the algorithm achieves substantially better performance for i object segmentation ii d volumetric recovery of the scene and iii better parsing result for scene understanding in comparison to state of the art method in both public dataset and our own new dataset 
we present novel approach for fully automated extraction of tree like tubular structure from d image stack a d open curve active contour snake model is proposed for simultaneous d centerline tracing and local radius estimation an image energy term stretching term and a novel region based radial energy term constitute the energy to be minimized this combination of energy term allows the d open curve snake model starting from an automatically detected seed point to stretch along and fit the tubular structure like neurites and blood vessel a graph based curve completion approach is proposed to merge possible fragment caused by discontinuity in the tree structure after tree structure extraction the centerline serve a the starting point for a fast marching segmentation for which the stopping time is automatically chosen we illustrate the performance of our method with various datasets 
in previous work of face recognition similarity between face is measured by comparing corresponding face region that is to say matching eye with eye and mouth with mouth etc in this paper we propose that face can be also recognized by matching non corresponding facial region in another word face can be recognized by matching eye with mouth for example specifically the problem we study in this paper can be formulated a how to measure the possibility whether two non corresponding face region belong to the same face we propose that the possibility can be measured via canonical correlation analysis experimental result show that it is feasible to recognize face via non corresponding region matching the proposed method provides an alternative and more flexible way to recognize face 
we propose to formulate multi target tracking a minimization of a continuous energy function other than a number of recent approach we focus on designing an energy function that represents the problem a faithfully a possible rather than one that is amenable to elegant optimization we then go on to construct a suitable optimization scheme to find strong local minimum of the proposed energy the scheme extends the conjugate gradient method with periodic trans dimensional jump these move allow the search to escape weak minimum and explore a much larger portion of the variable dimensional search space while still always reducing the energy to demonstrate the validity of this approach we present an extensive quantitative evaluation both on synthetic data and on six different real video sequence in both case we achieve a significant performance improvement over an extended kalman filter baseline a well a an ilp based state of the art tracker 
the multi label problem is of fundamental importance to computer vision yet finding global minimum of the associated energy is very hard and usually impossible in practice recently progress ha been made using continuous formulation of the multi label problem and solving a convex relaxation globally thereby getting a solution with optimality bound in this work we develop a novel framework for continuous convex relaxation where the label space is a continuous product space in this setting we can combine the memory efficient product relaxation of with the much tighter relaxation of which lead to solution closer to the global optimum furthermore the new setting allows u to formulate more general continuous regularizers which can be freely combined in the different label dimension we also improve upon the relaxation of the product in the data term of which remove the need for artificial smoothing and allows the use of exact solver 
human action recognition is an important yet challenging task the recently developed commodity depth sensor open up new possibility of dealing with this problem but also present some unique challenge the depth map captured by the depth camera are very noisy and the d position of the tracked joint may be completely wrong if serious occlusion occur which increase the intra class variation in the action in this paper an actionlet ensemble model is learnt to represent each action and to capture the intra class variance in addition novel feature that are suitable for depth data are proposed they are robust to noise invariant to translational and temporal misalignment and capable of characterizing both the human motion and the human object interaction the proposed approach is evaluated on two challenging action recognition datasets captured by commodity depth camera and another dataset captured by a mocap system the experimental evaluation show that the proposed approach achieves superior performance to the state of the art algorithm 
in real application sometimes visual recognition may need to rely on incomplete or ambiguous feature for a unique decision furthermore the detected feature may suffer a lot of uncertainty due to environment change in order to solve the problem with ambiguity and uncertainty in one computational framework we propose a probabilistic d object recognition approach using both positive and negative evidence in cluttered environment first of all initial feature are selected a parallel and perpendicular line pair to generate pose hypothesis a the multiple interpretation secondly given a d polyhedral object model and the estimated pose positive and negative evidence can be identified a additional information for probability computation of the multiple interpretation more specifically given the estimated pose followed by visibility test positive evidence is the feature that should be appeared around the pose and negative evidence is the feature that should not be appeared due to self occlusion where the probability is computed using bayesian principle in term of both likelihood and unlikelihood the experimental result support the potential of the proposed approach in the real environment 
a number of computer vision problem such a human age estimation crowd density estimation and body face pose view angle estimation can be formulated a a regression problem by learning a mapping function between a high dimensional vector formed feature input and a scalar valued output such a learning problem is made difficult due to sparse and imbalanced training data and large feature variation caused by both uncertain viewing condition and intrinsic ambiguity between observable visual feature and the scalar value to be estimated encouraged by the recent success in using attribute for solving classification problem with sparse training data this paper introduces a novel cumulative attribute concept for learning a regression model when only sparse and imbalanced data are available more precisely low level visual feature extracted from sparse and imbalanced image sample are mapped onto a cumulative attribute space where each dimension ha clearly defined semantic interpretation a label that capture how the scalar output value e g age people count change continuously and cumulatively extensive experiment show that our cumulative attribute framework gain notable advantage on accuracy for both age estimation and crowd counting when compared against conventional regression model especially when the labelled training data is sparse with imbalanced sampling 
camera face a fundamental tradeoff between the spatial and temporal resolution digital still camera can capture image with high spatial resolution but most high speed video camera suffer from low spatial resolution it is hard to overcome this tradeoff without incurring a significant increase in hardware cost in this paper we propose technique for sampling representing and reconstructing the space time volume in order to overcome this tradeoff our approach ha two important distinction compared to previous work we achieve sparse representation of video by learning an over complete dictionary on video patch and we adhere to practical constraint on sampling scheme which is imposed by architecture of present image sensor device consequently our sampling scheme can be implemented on image sensor by making a straightforward modification to the control unit to demonstrate the power of our approach we have implemented a prototype imaging system with per pixel coded exposure control using a liquid crystal on silicon lcos device using both simulation and experiment on a wide range of scene we show that our method can effectively reconstruct a video from a single image maintaining high spatial resolution 
personal photo album are heavily biased towards face of people but most state of the art algorithm for image denoising and noise estimation do not exploit facial information we propose a novel technique for jointly estimating noise level of all face image in a photo collection photo in a personal album are likely to contain several face of the same people while some of these photo would be clean and high quality others may be corrupted by noise our key idea is to estimate noise level by comparing multiple image of the same content that differ predominantly in their noise content specifically we compare geometrically and photo metrically aligned face image of the same person our estimation algorithm is based on a probabilistic formulation that seek to maximize the joint probability of estimated noise level across all image we propose an approximate solution that decomposes this joint maximization into a two stage optimization the first stage determines the relative noise between pair of image by pooling estimate from corresponding patch pair in a probabilistic fashion the second stage then jointly optimizes for all absolute noise parameter by conditioning them upon relative noise level which allows for a pair wise factorization of the probability distribution we evaluate our noise estimation method using quantitative experiment to measure accuracy on synthetic data additionally we employ the estimated noise level for automatic denoising using bm d and evaluate the quality of denoising on real world photo through a user study 
we propose a method for vector field learning with outlier called vector field consensus vfc it could distinguish inliers from outlier and learn a vector field fitting for the inliers simultaneously a prior is taken to force the smoothness of the field which is based on the tiknonov regularization in vector valued reproducing kernel hilbert space under a bayesian framework we associate each sample with a latent variable which indicates whether it is an inlier and then formulate the problem a maximum a posteriori problem and use expectation maximization algorithm to solve it the proposed method posse two characteristic robust to outlier and being able to tolerate outlier and even more computationally efficient a an application we apply vfc to solve the problem of mismatch removing the result demonstrate that our method outperforms many state of the art method and it is very robust 
our primary interest is in generalizing the problem of cosegmentation to a large group of image that is concurrent segmentation of common foreground region s from multiple image we further wish for our algorithm to offer scale invariance foreground may have arbitrary size in different image and the running time to increase no more than near linearly in the number of image in the set what make this setting particularly challenging is that even if we ignore the scale invariance desideratum the cosegmentation problem a formalized in many recent paper except is already hard to solve optimally in the two image case a straightforward extension of such model to multiple image lead to loose relaxation and unless we impose a distributional assumption on the appearance model existing mechanism for image pair wise measurement of foreground appearance variation lead to significantly large problem size even for moderate number of image this paper present a surprisingly easy to implement algorithm which performs well and satisfies all requirement listed above scale invariance low computational requirement and viability for the multiple image setting we present qualitative and technical analysis of the property of this framework 
regression based technique have shown promising result for people counting in crowded scene however most existing technique require expensive and laborious data annotation for model training in this study we propose to address this problem from three perspective instead of exhaustively annotating every single frame the most informative frame are selected for annotation automatically and actively rather than learning from only labelled data the abundant unlabelled data are exploited labelled data from other scene are employed to further alleviate the burden for data annotation all three idea are implemented in a unified active and semi supervised regression framework with ability to perform transfer learning by exploiting the underlying geometric structure of crowd pattern via manifold analysis extensive experiment validate the effectiveness of our approach 
this paper present a method for the detection and recognition of social interaction in a day long first person video of u social event like a trip to an amusement park the location and orientation of face are estimated and used to compute the line of sight for each face the context provided by all the face in a frame is used to convert the line of sight into location in space to which individual attend further individual are assigned role based on their pattern of attention the rote and location of individual are analyzed over time to detect and recognize the type of social interaction in addition to pattern of face location and attention the head movement of the first person can provide additional useful cue a to their attentional focus we demonstrate encouraging result on detection and recognition of social interaction in first person video captured from multiple day of experience in amusement park 
we address the problem of editing facial expression in video such a exaggerating attenuating or replacing the expression with a different one in some part of the video to achieve this we develop a tensor based d face geometry reconstruction method which fit a d model for each video frame with the constraint that all model have the same identity and requiring temporal continuity of pose and expression with the identity constraint the difference between the underlying d shape capture only change in expression and pose we show that various expression editing task in video can be achieved by combining face reordering with face warping where the warp is induced by projecting difference in d face shape into the image plane analogously we show how the identity can be manipulated while fixing expression and pose experimental result show that our method can effectively edit expression and identity in video in a temporally coherent way with high fidelity 
user feedback help an image search system refine it relevance prediction tailoring the search towards the user s preference existing method simply take feedback at face value clicking on an image mean the user want thing like it commenting that an image lack a specific attribute mean the user want thing that have it however we expect there is actually more information behind the user s literal feedback in particular a user s possibly subconscious search strategy lead him to comment on certain image rather than others based on how any of the visible candidate image compare to the desired content for example he may be more likely to give negative feedback on an irrelevant image that is relatively close to his target a opposed to bothering with one that is altogether different we introduce novel feature to capitalize on such implied feedback cue and learn a ranking function that us them to improve the system s relevance estimate we validate the approach with real user searching for shoe face or scene using two different mode of feedback binary relevance feedback and relative attribute based feedback the result show that retrieval improves significantly when the system account for the learned behavior we show that the nuance learned are domain invariant and useful for both generic user independent search a well a personalized user specific search 
we describe a method for human pose estimation in static image based on a novel representation of part model notably we do not use articulated limb part but rather capture orientation with a mixture of template for each part we describe a general flexible mixture model for capturing contextual co occurrence relation between part augmenting standard spring model that encode spatial relation we show that such relation can capture notion of local rigidity when co occurrence and spatial relation are tree structured our model can be efficiently optimized with dynamic programming we present experimental result on standard benchmark for pose estimation that indicate our approach is the state of the art system for pose estimation outperforming past work by while being order of magnitude faster 
the efficient and robust extraction of invariant pattern from an image is a long standing problem in computer vision invariant structure are often related to repetitive or near repetitive pattern the perception of repetitive pattern in an image is strongly linked to the visual interpretation and composition of texture repetitive pattern are product of both repetitive structure a well a repetitive reflection or color pattern in other word pattern that exhibit near stationary behavior provide a rich information about object their shape and their texture in an image in this paper we propose a new algorithm for repetitive pattern detection and grouping the algorithm follows the classical region growing image segmentation scheme it utilizes a mean shift like dynamic to group local image patch into cluster it exploit a continuous joint alignment to a match similar patch and b refine the subspace grouping the result of higher level grouping for image pattern can be used to infer the geometry of object surface and estimate the general layout of a crowded scene 
in video post production it is often necessary to track interest point in the video this is called off line tracking because the complete video is available to the algorithm and can be contrasted with on line tracking where an incoming stream is tracked in real time off line tracking should be accurate and if used interactively need to be fast preferably faster than real time we describe a to frame per second off line tracking algorithm which globally maximizes the probability of the track given the complete video the algorithm is more reliable than previous method because it explains the complete frame not only the patch of the final track making a much use of the data a possible it achieves efficiency by using a greedy search strategy with deferred cost evaluation focusing the computational effort on the most promising track candidate while finding the globally optimal track 
many computational photography application require the user to take multiple picture of the same scene with different camera setting while this allows to capture more information about the scene than what is possible with a single image the approach is limited by the requirement that the image be perfectly registered in a typical scenario the camera is hand held and is therefore prone to moving during the capture of an image burst while the scene is likely to contain moving object combining such image without careful registration introduces annoying artifact in the final image this paper present a method to register exposure stack in the presence of both camera motion and scene change our approach warp and modifies the content of the image in the stack to match that of a reference image even in the presence of large highly non rigid displacement we show that the image are correctly registered to the reference 
for problem over continuous random variable mrfs with large clique pose a challenge in probabilistic inference difficulty in performing optimization efficiently have limited the probabilistic model explored in computer vision and other field one inference technique that handle large clique well is expectation propagation ep offer run time independent of clique size which instead depend only on the rank or intrinsic dimensionality of potential this property would be highly advantageous in computer vision unfortunately for grid shaped model common in vision traditional gaussian ep requires quadratic space and cubic time in the number of pixel here we propose a variation of ep that exploit regularity in natural scene statistic to achieve run time that are linear in both number of pixel and clique size we test these method on shape from shading and we demonstrate strong performance not only for lambertian surface but also on arbitrary surface reflectance and lighting arrangement which requires highly non gaussian potential finally we use large non local clique to exploit cast shadow which is traditionally ignored in shape from shading 
the goal of face identification is to decide whether two face depict the same person or not this paper address the identification problem for face track that are automatically collected from uncontrolled tv video data face track identification is an important component in system that automatically label character in tv series or movie based on subtitle and or script it enables effective transfer of the sparse text based supervision to other face we show that without manually labeling any example metric learning can be effectively used to address this problem this is possible by using pair of face within a track a positive example while negative training example can be generated from pair of face track of different people that appear together in a video frame in this manner we can learn a cast specific metric adapted to the people appearing in a particular video without using any supervision identification performance can be further improved using semi supervised learning where we also include label for some of the face track we show that our cast specific metric not only improve identification but also recognition and clustering 
transfer learning is established a an effective technology in computer vision for leveraging rich labeled data in the source domain to build an accurate classifier for the target domain however most prior method have not simultaneously reduced the difference in both the marginal distribution and conditional distribution between domain in this paper we put forward a novel transfer learning approach referred to a joint distribution adaptation jda specifically jda aim to jointly adapt both the marginal distribution and conditional distribution in a principled dimensionality reduction procedure and construct new feature representation that is effective and robust for substantial distribution difference extensive experiment verify that jda can significantly outperform several state of the art method on four type of cross domain image classification problem 
the demise of segmentation then recognition strategy led to a paradigm shift toward feature based discriminative recognition with significant success however increased complexity in multi class datasets reveals that local low level feature may not be sufficiently discriminative requiring the construction and use of more complex structural feature which are necessarily category independent the paper proposes a bottom up procedure for generating fragment feature which are intended to be object part hypothesis suggesting that the demise of segmentation to generate a representation suitable for recognition wa due to prematurely committing to a grouping option in the face of ambiguity the proposed framework considers and track multiple alternate grouping option this approach is made tractable by i using a medial fragment representation which allows for the simultaneous use of multiple cue ii a set of transforms to effect grouping operation iii a containment graph representation which avoids duplicate consideration of possibility and the estimation of the likelihood of a grouping sequence to retain only plausible grouping the resulting hypothesis are evaluated intrinsically by measuring their ability to represent object with a few fragment they are also evaluated by comparison to algorithm which aim to generate full object segment with result that match or exceed the state of art thus demonstrating the suitability of the proposed mid level representation 
a label consistent k svd lc ksvd algorithm to learn a discriminative dictionary for sparse coding is presented in addition to using class label of training data we also associate label information with each dictionary item column of the dictionary matrix to enforce discriminability in sparse code during the dictionary learning process more specifically we introduce a new label consistent constraint called discriminative sparse code error and combine it with the reconstruction error and the classification error to form a unified objective function the optimal solution is efficiently obtained using the k svd algorithm our algorithm learns a single over complete dictionary and an optimal linear classifier jointly it yield dictionary so that feature point with the same class label have similar sparse code experimental result demonstrate that our algorithm outperforms many recently proposed sparse coding technique for face and object category recognition under the same learning condition 
in the security domain a key problem is identifying rare behaviour of interest training example for these behaviour may or may not exist and if they do exist there will be few example quite probably one we present a novel weakly supervised algorithm that can detect behaviour that either have never before been seen or for which there are few example global context is modelled allowing the detection of abnormal behaviour that in isolation appear normal pragmatic aspect are considered such that no parameter tuning is required and real time performance is achieved 
in this paper we present a unified statistical framework for modeling both saccadic eye movement and visual saliency by analyzing the statistical property of human eye fixation on natural image we found that human attention is sparsely distributed and usually deployed to location with abundant structural information this new observation inspired u to model saccadic behavior and visual saliency based on super gaussian component sgc analysis the model sequentially obtains sgc using projection pursuit and generates eye movement by selecting the location with maximum sgc response beside human saccadic behavior simulation we also demonstrated our superior effectiveness and robustness over state of the art by carrying out dense experiment on psychological pattern and human eye fixation benchmark these result also show promising potential of statistical approach for human behavior research 
in recent year metric learning method based on pairwise side information have attracted considerable interest and lot of effort have been devoted to utilize these method for visual analysis like content based image retrieval and face identification when applied to image analysis these method merely look on an n n image a a vector in rn n space and the pixel of the image are considered a independent they fail to consider the fact that an image represented in the plane is intrinsically a matrix and pixel spatially close to each other may probably be correlated even though we have n n pixel per image this spatial correlation suggests the real number of freedom is far le in this paper we introduce a regularized metric learning framework two dimensional smooth metric learning dsml which us a discretized laplacian penalty to restrict the coefficient to be two dimensional smooth many existing metric learning algorithm can fit into this framework and learn a spatially smooth metric which is better for image application than their original version recognition clustering and retrieval can be then performed based on the learned metric experimental result on benchmark image datasets demonstrate the effectiveness of our method 
we propose to leverage multiple source of information to compute an estimate of the number of individual present in an extremely dense crowd visible in a single image due to problem including perspective occlusion clutter and few pixel per person counting by human detection in such image is almost impossible instead our approach relies on multiple source such a low confidence head detection repetition of texture element using sift and frequency domain analysis to estimate count along with confidence associated with observing individual in an image region secondly we employ a global consistency constraint on count using markov random field this caters for disparity in count in local neighborhood and across scale we tested our approach on a new dataset of fifty crowd image containing k annotated human with the head count ranging from to this is in stark contrast to datasets used for existing method which contain not more than ten of individual we experimentally demonstrate the efficacy and reliability of the proposed approach by quantifying the counting performance 
we generalize the method of slow feature analysis for vector valued function of multivariables and apply it to the problem of blind source separation in particular image separation for the linear case exact mathematical analysis is given which show in particular that the source are perfectly separated by sfa if and only if they and their first order derivative are uncorrelated when the source are correlated we apply the following technique called decorrelation filtering use a linear filter to decorrelate the source and their derivative then apply the separating matrix obtained on the filtered source to the original source we show that if the filtered source are perfectly separated by this matrix then so are the original source we show how to numerically obtain such a decorrelation filter by solving a nonlinear optimization problem this technique can also be applied to other linear separation method whose output signal are decorrelated such a ica 
handshape is a key linguistic component of sign and thus handshape recognition is essential to algorithm for sign language recognition and retrieval in this work linguistic constraint on the relationship between start and end handshapes are leveraged to improve handshape recognition accuracy a bayesian network formulation is proposed for learning and exploiting these constraint while taking into consideration inter signer variation in the production of particular handshapes a variational bayes formulation is employed for supervised learning of the model parameter a non rigid image alignment algorithm which yield improved robustness to variability in handshape appearance is proposed for computing image observation likelihood in the model the resulting handshape inference algorithm is evaluated using a dataset of lexical sign in american sign language asl where each lexical sign is produced by three native asl signer 
weakly supervised discovery of common visual structure in highly variable cluttered image is a key problem in recognition we address this problem using deformable part based model dpm s with latent svm training these model have been introduced for fully supervised training of object detector but we demonstrate that they are also capable of more open ended learning of latent structure for such task a scene recognition and weakly supervised object localization for scene recognition dpm s can capture recurring visual element and salient object in combination with standard global image feature they obtain state of the art result on the mit category indoor scene dataset for weakly supervised object localization optimization over latent dpm parameter can discover the spatial extent of object in cluttered training image without ground truth bounding box the resulting method outperforms a recent state of the art weakly supervised object localization approach on the pascal dataset 
this paper investigates how to segment an image into semantic region by harnessing an unlabeled image corpus first the image segmentation task is recast a a small size patch grouping problem then we discover two novel patch pair prior namely the first order patch pair density prior and the second order patch pair co occurrence prior founded on two statistical observation from the natural image corpus the underlying rationality are a patch pair falling within the same object region generally ha higher density than a patch pair falling on different object and two patch pair with high co occurrence frequency are likely to bear similar semantic consistence confidence sccs i e the confidence of the consisted two patch belonging to the same semantic concept these two discriminative prior are further integrated into a unified objective function in order to augment the intrinsic patch pair similarity originally calculated using patch level visual feature into the semantic consistence confidence nonnegative constraint is also imposed over the output variable and an efficient iterative procedure is provided to seek the optimal solution the ultimate patch grouping is conducted by first building a similarity graph which take the atomic patch a vertex and the augmented patch pair sccs a edge weight and then employing the popular normalized cut approach to group patch into semantic cluster extensive image segmentation experiment on two public database clearly demonstrate the superiority of the proposed approach over various state of the art unsupervised image segmentation algorithm 
in this paper we consider the problem of aligning multiple non rigid surface mesh sequence into a single temporally consistent representation of the shape and motion a global alignment graph structure is introduced which us shape similarity to identify frame for inter sequence registration graph optimisation is performed to minimise the total non rigid deformation required to register the input sequence into a common structure the resulting global alignment ensures that all input sequence are resampled with a common mesh structure which preserve the shape and temporal correspondence result demonstrate temporally consistent representation of several public database of mesh sequence for multiple people performing a variety of motion with loose clothing and hair 
elongated object have various shape and can shift rotate change scale and be rigid or deform by flexing articulating and vibrating with example a varied a a glass bottle a robotic arm a surgical suture a finger pair a tram and a guitar string this generally make tracking of pose of elongated object very challenging we describe a unified configurable framework for tracking the pose of elongated object which move in the image plane and extend over the image region our method strives for simplicity versatility and efficiency the object is decomposed into a chained assembly of segment of multiple part that are arranged under a hierarchy of tailored spatio temporal constraint in this hierarchy segment can rescale independently while their elasticity is controlled with global orientation and local distance while the trend in tracking is to design complex structure free algorithm that update object appearance on line we show that our tracker with the novel but remarkably simple structured organization of part with constant appearance reach or improves state of the art performance most importantly our model can be easily configured to track exact pose of arbitrary elongated object in the image plane the tracker can run up to fps on a desktop pc yet the computation time scale linearly with the number of object part to our knowledge this is the first approach to generic tracking of elongated object 
improving coding and spatial pooling for bag of word based feature design have gained a lot of attention in recent work addressing object recognition and scene classification regarding the coding step in particular property such a sparsity locality and saliency have been investigated the main contribution of this work consists in taking into acount the local spatial context of an image into the usual coding strategy proposed in the state of the art for this purpose given an imgae dense local feature are extracted and structured in a lattice the latter is endowed with a neighborhood system and pairwise interaction we propose a new objective function to encode local feature which preserve locality constraint both in the feature space and the spatial domain of the image in addition an appropriate efficient optimization algorithm is provided inspired from the graph cut framework in conjunction with the maximum pooling operation and the spatial pyramid matching that reflects a global spatial layout the proposed method improves the performance of several state of the art coding scheme for scene classification on three publicly available benchmark uiuc sport scene and caltech 
a visual recognition scale up to ever larger number of category maintaining high accuracy is increasingly difficult in this work we study the problem of optimizing accuracy specificity trade offs in large scale recognition motivated by the observation that object category form a semantic hierarchy consisting of many level of abstraction a classifier can select the appropriate level trading off specificity for accuracy in case of uncertainty by optimizing this trade off we obtain classifier that try to be a specific a possible while guaranteeing an arbitrarily high accuracy we formulate the problem a maximizing information gain while ensuring a fixed arbitrarily small error rate with a semantic hierarchy we propose the dual accuracy reward trade off search dart algorithm and prove that under practical condition it converges to an optimal solution experiment demonstrate the effectiveness of our algorithm on datasets ranging from to over category 
distributional word clustering merges the word having similar probability distribution to attain reliable parameter estimation compact classification model and even better classification performance agglomerative information bottleneck aib is one of the typical word clustering algorithm and ha been applied to both traditional text classification and recent image recognition although enjoying theoretical elegance aib ha one main issue on it computational efficiency especially when clustering a large number of word different from existing solution to this issue we analyze the characteristic of it objective function the loss of mutual information and show that by merely using the ratio of word class joint probability of each word good candidate word pair for merging can be easily identified based on this finding we propose a fast approximate aib algorithm and show that it can significantly improve the computational efficiency of aib while well maintaining or even slightly increasing it classification performance experimental study on both text and image classification benchmark data set show that our algorithm can achieve more than time speedup on large real data set over the state of the art method 
the ability to generate good model hypothesis is instrumental to accurate and robust geometric model fitting we present a novel dynamic hypothesis generation algorithm for robust fitting of multiple structure underpinning our method is a fast guided sampling scheme enabled by analysing correlation of preference induced by data and hypothesis residual our method progressively accumulates evidence in the search space and us the information to dynamically identify outlier filter unpromising hypothesis and bias the sampling for active discovery of multiple structure in the data all achieved without sacrificing the speed associated with sampling based method our algorithm yield a disproportionately higher number of good hypothesis among the sampling outcome i e most hypothesis correspond to the genuine structure in the data this directly support a novel hierarchical model fitting algorithm that elicits the underlying stratified manner in which the structure are organized allowing more meaningful result than traditional flat multi structure fitting 
in this paper we propose a visual saliency detection algorithm from the perspective of reconstruction error the image boundary are first extracted via super pixel a likely cue for background template from which dense and sparse appearance model are constructed for each image region we first compute dense and sparse reconstruction error second the reconstruction error are propagated based on the context obtained from k mean clustering third pixel level saliency is computed by an integration of multi scale reconstruction error and refined by an object biased gaussian model we apply the bayes formula to integrate saliency measure based on dense and sparse reconstruction error experimental result show that the proposed algorithm performs favorably against seventeen state of the art method in term of precision and recall in addition the proposed algorithm is demonstrated to be more effective in highlighting salient object uniformly and robust to background noise 
this paper present a novel discriminative multi class classifier based on sequential pattern tree it is efficient to learn compared to other sequential pattern method and scalable for use with large classifier bank for these reason it is well suited to sign language recognition using deterministic robust feature based on hand trajectory sign level classifier are built from sub unit result are presented both on a large lexicon single signer data set and a multi signer kinect data set in both case it is shown to out perform the non discriminative markov model approach and be equivalent to previous more costly sequential pattern sp technique 
the automatic discovery of distinctive part for an object or scene class is challenging since it requires simultaneously to learn the part appearance and also to identify the part occurrence in image in this paper we propose a simple efficient and effective method to do so we address this problem by learning part incrementally starting from a single part occurrence with an exemplar svm in this manner additional part instance are discovered and aligned reliably before being considered a training example we also propose entropy rank curve a a mean of evaluating the distinctiveness of part shareable between category and use them to select useful part out of a set of candidate we apply the new representation to the task of scene categorisation on the mit scene benchmark we show that our method can learn part which are significantly more informative and for a fraction of the cost compared to previous part learning method such a singh et al we also show that a well constructed bag of word or fisher vector model can substantially outperform the previous state of the art classification performance on this data 
we present an approach to multi target tracking that ha expressive potential beyond the capability of chain shaped hidden markov model yet ha significantly reduced complexity our framework which we call tracking by selection is similar to tracking by detection in that it separate the task of detection and tracking but it shift temporal reasoning from the tracking stage to the detection stage the core feature of tracking by selection is that it reason about path hypothesis that traverse the entire video instead of a chain of single frame object hypothesis a traditional chain shaped tracking by detection model is only able to promote consistency between one frame and the next in tracking by selection path hypothesis exist across time and encouraging long term temporal consistency is a simple a rewarding path hypothesis with consistent image feature one additional advantage of tracking by selection is that it result in a dramatically simplified model that can be solved exactly we adapt an existing tracking by detection model to the tracking by selection framework and show improved performance on a challenging dataset 
recent study on visual tracking have shown significant improvement in accuracy by handling the appearance variation of the target object whereas most study present scheme to extract the time invariant characteristic of the target and adaptively update the appearance model the present paper concentrate on modeling the probabilistic dependency between sequential target appearance fig a to actualize this interest a new bayesian tracking framework is formulated under the autoregressive hidden markov model ar hmm where the probabilistic dependency between sequential target appearance is implied during the learning phase at each time step the proposed tracker separate formerly seen target sample into several cluster based on their visual similarity and learns cluster specific classifier a multiple appearance model each of which represents a certain type of the target appearance then the dependency between these appearance model is learned during the searching phase the target state is estimated by inferring the most probable appearance model under the consideration of it dependency on formerly utilized appearance model the proposed method is tested on challenging video sequence containing target with abrupt appearance variation and demonstrates that it outperforms current state of the art method in accuracy 
in this paper we propose an efficient method to detect the underlying structure in data the same a ransac we randomly sample ms minimal size sample and generate hypothesis instead of analyzing each hypothesis separately the consensus information in all hypothesis is naturally fused into a hypergraph called random consensus graph with real structure corresponding to it dense subgraphs the sampling process is essentially a progressive refinement procedure of the random consensus graph due to the huge number of hyperedges it is generally inefficient to detect dense subgraphs on random consensus graph to overcome this issue we construct a pairwise graph which approximately retains the dense subgraphs of the random consensus graph the underlying structure are then revealed by detecting the dense subgraphs of the pair wise graph since our method fuse information from all hypothesis it can robustly detect structure even under a small number of ms the graph framework enables our method to simultaneously discover multiple structure besides our method is very efficient and scale well for large scale problem extensive experiment illustrate the superiority of our proposed method over previous approach achieving several order of magnitude speedup along with satisfactory accuracy and robustness 
the perplexing effect of noise and high feature dimensionality greatly complicate functional magnetic resonance imaging fmri classification in this paper we present a novel formulation for constructing generalized group sparse classifier gssc to alleviate these problem in particular we propose an extension of group lasso that permit association between feature within predefined group to be modeled integrating this new penalty into classifier learning enables incorporation of additional prior information beyond group structure in the context of fmri ggsc provides a flexible mean for modeling how the brain is functionally organized into specialized module i e group of voxels with spatially proximal voxels often displaying similar level of brain activity i e feature association applying gssc to real fmri data improved predictive performance over standard classifier while providing more neurologically interpretable classifier weight pattern our result thus demonstrate the importance of incorporating prior knowledge into classification problem 
in this paper we propose an adaptation and transcription of the mean curvature level set equation on a general discrete domain weighted graph with arbitrary topology we introduce the perimeter on graph using difference operator and define the curvature a the first variation of these perimeter our proposed approach of mean curvature unifies both local and non local notion of mean curvature on euclidean domain furthermore it allows the extension to the processing of manifold and data which can be represented by graph 
the problem of learning a proper distance or similarity metric arises in many application such a content based image retrieval in this work we propose a boosting algorithm metricboost to learn the distance metric that preserve the proximity relationship among object triplet object i is more similar to object j than to object k metric boost construct a positive semi definite psd matrix that parameterizes the distance metric by combining rank one psd matrix different option of weak model and combination coefficient are derived unlike existing proximity preserving metric learning which is generally not scalable metricboost employ a bipartite strategy to dramatically reduce computation cost by decomposing proximity relationship over triplet into pair wise constraint met ricboost outperforms the state of the art on two real world medical problem identifying and quantifying diffuse lung disease colorectal polyp matching between different view a well a on other benchmark datasets 
egocentric camera can be used to benefit such task a analyzing fine motor skill recognizing gesture and learning about hand object manipulation to enable such technology we believe that the hand must detected on the pixel level to gain important information about the shape of the hand and finger we show that the problem of pixel wise hand detection can be effectively solved by posing the problem a a model recommendation task a such the goal of a recommendation system is to recommend the n best hand detector based on the probe set a small amount of labeled data from the test distribution this requirement of a probe set is a serious limitation in many application such a ego centric hand detection where the test distribution may be continually changing to address this limitation we propose the use of virtual probe which can be automatically extracted from the test distribution the key idea is that many feature such a the color distribution or relative performance between two detector can be used a a proxy to the probe set in our experiment we show that the recommendation paradigm is well equipped to handle complex change in the appearance of the hand in first person vision in particular we show how our system is able to generalize to new scenario by testing our model across multiple user 
the main question we address in this paper is how to use purely textual description of category with no training image to learn visual classifier for these category we propose an approach for zero shot learning of object category where the description of unseen category come in the form of typical text such a an encyclopedia entry without the need to explicitly defined attribute we propose and investigate two baseline formulation based on regression and domain adaptation then we propose a new constrained optimization formulation that combine a regression function and a knowledge transfer function with additional constraint to predict the classifier parameter for new class we applied the proposed approach on two fine grained categorization datasets and the result indicate successful classifier prediction 
aiming at reaching an interactive and simplified usage of high resolution d acquisition system this paper present a fast and automated technique for pre alignment of dense range image starting from a multi scale feature point extraction and description a processing chain composed by feature matching and correspondence searching ranking grouping and skimming is performed to select the most reliable correspondence over which the correct alignment is estimated pre alignment is obtained in few second per million point image on a off the shelf pc architecture the experimental setup aimed to demonstrate the system behavior with respect to a set of concurrent requirement and the obtained performance are significant in the perspective of a fast robust and unconstrained d object reconstruction 
recently a new image deformation technique called content preserving warping cpw ha been successfully employed to produce the state of the art video stabilization result in many challenging case the key insight of cpw is that the true image deformation due to viewpoint change can be well approximated by a carefully constructed warp using a set of sparsely constructed d point only however since cpw solely relies on the tracked feature point to guide the warping it work poorly in large texture le region such a ground and building interior to overcome this limitation in this paper we present a hybrid approach for novel view synthesis observing that the texture le region often correspond to large planar surface in the scene particularly given a jittery video we first segment each frame into piecewise planar region a well a region labeled a non planar using markov random field then a new warp is computed by estimating a single homography for region belong to the same plane while inheriting result from cpw in the non planar region we demonstrate how the segmentation information can be efficiently obtained and seamlessly integrated into the stabilization framework experimental result on a variety of real video sequence verify the effectiveness of our method 
first order markov random field mrfs have become a predominant tool in computer vision over the past decade such a success wa mostly due to the development of efficient optimization algorithm both in term of speed a well a in term of optimality property message passing algorithm are among the most popular method due to their good performance for a wide range of pairwise potential function ppfs their main bottleneck is computational complexity in this paper we revisit message computation a a distance transformation using a more formal setting than to generalize it to arbitrary ppfs the method is based on yielding accurate result for a specific class of ppfs and in most other case a close approximation the proposed algorithm is parallel and thus enables u to fully take advantage of the computational power of parallel processing architecture the proposed scheme coupled with an efficient belief propagation algorithm and implemented on a massively parallel coprocessor provides result a accurate a state of the art inference method though is in general one order of magnitude faster in term of speed 
spatial super resolution sr aim to recover fine image detail smaller than a pixel size temporal sr aim to recover rapid dynamic event that occur faster than the video frame rate and are therefore invisible or seen incorrectly in the video sequence previous method for space time sr combined information from multiple video recording of the same dynamic scene in this paper we show how this can be done from a single video recording our approach is based on the observation that small space time patch st patch e g of a single natural video recur many time inside the same video sequence at multiple spatio temporal scale we statistically explore the degree of these st patch recurrence inside natural video and show that this is a very strong statistical phenomenon space time sr is obtained by combining information from multiple st patch at sub frame accuracy we show how finding similar st patch can be done both efficiently with a randomized based search in space time and at sub frame accuracy despite severe motion aliasing our approach is particularly useful for temporal sr resolving both severe motion aliasing and severe motion blur in complex natural video 
great progress ha been made in face sketch synthesis in recent year state of the art method commonly apply a markov random field mrf model to select local sketch patch from a set of training data such method however have two major drawback firstly the mrf model used cannot synthesize new sketch patch secondly the optimization problem in solving the mrf is np hard in this paper we propose a novel markov weight field mwf model that is capable of synthesizing new sketch patch we formulate our model into a convex quadratic programming qp problem to which the optimal solution is guaranteed based on the markov property of our model we further propose a cascade decomposition method cdm for solving such a large scale qp problem efficiently experimental result on the cuhk face sketch database and celebrity photo show that our model outperforms the common mrf model used in other state of the art method 
we present a novel method to integrate multiple d scan captured from different viewpoint saliency information is used to guide the integration process the multi scale saliency of a point is specifically designed to reflect it sensitivity to registration error then scan are partitioned into salient and non salient region through an markov random field mrf framework where neighbourhood consistency is incorporated to increase the robustness against potential scanning error we then develop different scheme to discriminatively integrate point in the two region for the point in salient region which are more sensitive to registration error we employ the iterative closest point algorithm to compensate the local registration error and find the correspondence for the integration for the point in non salient region which are le sensitive to registration error we integrate them via an efficient and effective point shifting scheme a comparative study show that the proposed method delivers improved surface integration 
human gait modeling e g for person identification largely relies on image based representation that muddle gait with body shape silhouette for instance inherently entangle body shape and gait for gait analysis and recognition decoupling these two factor is desirable most important once decoupled they can be combined for the task at hand but not if left entangled in the first place in this paper we introduce two point gait a gait representation that encodes the limb motion regardless of the body shape two point gait is directly computed on the image sequence based on the two point statistic of optical flow field we demonstrate it use for exploring the space of human gait and gait recognition under large clothing variation the result show that we can achieve state of the art person recognition accuracy on a challenging dataset 
in this paper we propose an object tracking method in case of inaccurate initialization to track object accurately in such situation the proposed method us motion saliency and descriptor saliency of local feature and performs tracking based on generalized hough transform ght the proposed motion saliency of a local feature emphasizes feature having distinctive motion compared to the motion which are not from the target object the descriptor saliency emphasizes feature which are likely to be of the object in term of it feature descriptor through these saliency the proposed method try to learn and find the target object rather than looking for what wa given at initialization giving robust result even with inaccurate initialization also our tracking result is obtained by combining the result of each local feature of the target and the surroundings with ght voting thus is robust against severe occlusion a well the proposed method is compared against nine other method with nine image sequence and hundred random initialization the experimental result show that our method outperforms all other compared method 
automatic computation of surface correspondence via harmonic map is an active research field in computer vision computer graphic and computational geometry it may help document and understand physical and biological phenomenon and also ha broad application in biometrics medical imaging and motion capture although numerous study have been devoted to harmonic map research limited progress ha been made to compute a diffeomorphic harmonic map on general topology surface with landmark constraint this work conquer this problem by changing the riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraint the computational algorithm are based on the ricci flow method and the method is general and robust we apply our algorithm to study constrained human brain surface registration problem experimental result demonstrate that by changing the riemannian metric the registration are always diffeomorphic and achieve relative high performance when evaluated with some popular cortical surface registration evaluation standard 
similarity search namely finding approximate nearest neighborhood is the core of many large scale machine learning or vision application recently many research result demonstrate that hashing with compact code can achieve promising performance for large scale similarity search however most of the previous hashing method with compact code only model and optimize the search accuracy search time which is an important factor for hashing in practice is usually not addressed explicitly in this paper we develop a new scalable hashing algorithm with joint optimization of search accuracy and search time simultaneously our method generates compact hash code for data of general format with any similarity function we evaluate our method using diverse data set up to million sample e g web image our comprehensive result show the proposed method significantly outperforms several state of the art hashing approach 
we address shape grammar parsing for facade segmentation using reinforcement learning rl shape parsing entail simultaneously optimizing the geometry and the topology e g number of floor of the facade so a to optimize the fit of the predicted shape with the response of pixel level terminal detector we formulate this problem in term of a hierarchical markov decision process by employing a recursive binary split grammar this allows u to use rl to efficiently find the optimal parse of a given facade in term of our shape grammar building on the rl paradigm we exploit state aggregation to speedup computation and introduce image driven exploration in rl to accelerate convergence we achieve state of the art result on facade parsing with a significant speed up compared to existing method and substantial robustness to initial condition we demonstrate that the method can also be applied to interactive segmentation and to a broad variety of architectural style 
we propose a fast regression model for practical single image super resolution based on in place example by leveraging two fundamental super resolution approacheslearning from an external database and learning from self example our in place self similarity refines the recently proposed local self similarity by proving that a patch in the upper scale image have good match around it origin location in the lower scale image based on the in place example a first order approximation of the nonlinear mapping function from low to high resolution image patch is learned extensive experiment on benchmark and real world image demonstrate that our algorithm can produce natural looking result with sharp edge and preserved fine detail while the current state of the art algorithm are prone to visual artifact furthermore our model can easily extend to deal with noise by combining the regression result on multiple in place example for robust estimation the algorithm run fast and is particularly useful for practical application where the input image typically contain diverse texture and they are potentially contaminated by noise or compression artifact 
geometry and geography can play an important role in recognition task in computer vision to aid in studying connection between geometry and recognition we introduce nyc dcars a rich dataset for vehicle detection in urban scene built from internet photo drawn from the wild focused on densely trafficked area of new york city our dataset is augmented with detailed geometric and geographic information including full camera pose derived from structure from motion d vehicle annotation and geographic information from open resource including road segmentation and direction of travel nyc dcars can be used to study new question about using geometric information in detection task and to explore application of internet photo in understanding city to demonstrate the utility of our data we evaluate the use of the geographic information in our dataset to enhance a part based detection method and suggest other avenue for future exploration 
we study the problem of interactive segmentation and contour completion for multiple object the form of constraint our model incorporates are those coming from user scribble interior or exterior constraint a well a information regarding the topology of the d space after partitioning number of closed contour desired we discus how concept from discrete calculus and a simple identity using the euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem we also present specialized branch and bound method for the case of single contour completion under such constraint on an extensive dataset of image our experiment suggest that a small amount of side knowledge can give strong improvement over fully unsupervised contour completion method we show that by interpreting user indication topologically user effort is substantially reduced 
we propose a benchmark of several objective function for large scale image classification we compare the one v rest multiclass ranking and weighted average ranking svms using stochastic gradient descent optimization we can scale the learning to million of image and thousand of class our experimental evaluation show that ranking based algorithm do not outperform a one v rest strategy and that the gap between the different algorithm reduces in case of high dimensional data we also show that for one v rest learning through cross validation the optimal degree of imbalance between the positive and the negative sample can have a significant impact furthermore early stopping can be used a an effective regularization strategy when training with stochastic gradient algorithm following these good practice we were able to improve the state of the art on a large subset of k class and m of image of lmagenet from accuracy to 
an extension of the latent dirichlet allocation lda denoted class specific simplex lda cs lda is proposed for image classification an analysis of the supervised lda model currently used for this task show that the impact of class information on the topic discovered by these model is very weak in general this implies that the discovered topic are driven by general image regularity rather than the semantic regularity of interest for classification to address this we introduce a model that induces supervision in topic discovery while retaining the original flexibility of lda to account for unanticipated structure of interest the proposed cs lda is an lda model with class supervision at the level of image feature in cs lda topic are discovered per class i e a single set of topic shared across class is replaced by multiple class specific topic set this model can be used for generative classification using the bayes decision rule or even extended to discriminative classification with support vector machine svms a cs lda model can endow an image with a vector of class and topic specific count statistic that are similar to the bag of word bow histogram svm based discriminants can be learned for class in the space of these histogram the effectiveness of cs lda model in both generative and discriminative classification framework is demonstrated through an extensive experimental evaluation involving multiple benchmark datasets where it is shown to outperform all existing lda based image classification approach 
we investigate on local reference frame lrf deployed with d descriptor to achieve invariance to object pose we address the task of matching together partial view of surface and propose an experimental study on a large corpus of real data which allows for clearly ranking existing lrf proposal based on their repeatability then drawing inspiration from analysis of the experimental finding we formulate a new proposal which in particular peculiarly includes a procedure aimed at estimating a repeatable lrf also at border feature which is very important when matching partial view of surface experiment show that the new proposal neatly outperforms existing method in term of repeatability is computationally very efficient and provide relevant benefit in practical application 
traditional locality sensitive hashing lsh technique aim to tackle the curse of explosive data scale by guaranteeing that similar sample are projected onto proximal hash bucket despite the success of lsh on numerous vision task like image retrieval and object matching however it potential in large scale optimization is only realized recently in this paper we further advance this nascent area we first identify two common operation known a the computational bottleneck of numerous optimization algorithm in a large scale setting i e min max inner product we propose a hashing scheme for accelerating min max inner product which exploit property of order statistic of statistically correlated random vector compared with other scheme our algorithm exhibit improved recall at a lower computational cost the effectiveness and efficiency of the proposed method are corroborated by theoretic analysis and several important application especially we use the proposed hashing scheme to perform approximate regularized least square with dictionary with million of element a scale which is beyond the capability of currently known exact solver nonetheless it is highlighted that the focus of this paper is not on a new hashing scheme for approximate nearest neighbor problem it exploit a new application for the hashing technique and proposes a general framework for accelerating a large variety of optimization procedure in computer vision 
subordinate level categorization typically rest on establishing salient distinction between part level characteristic of object in contrast to basic level categorization where the presence or absence of part is determinative we develop an approach for subordinate categorization in vision focusing on an avian domain due to the fine grained structure of the category taxonomy for this domain we explore a pose normalized appearance model based on a volumetric poselet scheme the variation in shape and appearance property of these part across a taxonomy provides the cue needed for subordinate categorization training pose detector requires a relatively large amount of training data per category when done from scratch using a subordinate level approach we exploit a pose classifier trained at the basic level and extract part appearance and shape information to build subordinate level model our model associate the underlying image pattern parameter used for detection with corresponding volumetric part location scale and orientation parameter these parameter implicitly define a mapping from the image pixel into a pose normalized appearance space removing view and pose dependency facilitating fine grained categorization from relatively few training example 
traditional camera model are often the result of a compromise between the ability to account for non linearity in the image formation model and the need for a feasible number of degree of freedom in the estimation process these consideration led to the definition of several ad hoc model that best adapt to different imaging device ranging from pinhole camera with no radial distortion to the more complex catadioptric or polydioptric optic in this paper we propose the use of an unconstrained model even in standard central camera setting dominated by the pinhole model and introduce a novel calibration approach that can deal effectively with the huge number of free parameter associated with it resulting in a higher precision calibration than what is possible with the standard pinhole model with correction for radial distortion this effectively extends the use of general model to setting that traditionally have been ruled by parametric approach out of practical consideration the benefit of such an unconstrained model to quasi pinhole central camera is supported by an extensive experimental validation 
adjusting photograph to obtain compelling rendition requires skill and time even contrast and brightness adjustment are challenging because they require taking into account the image content photographer are also known for having different retouching preference a the result of this complexity rule based one size fit all automatic technique often fail this problem can greatly benefit from supervised machine learning but the lack of training data ha impeded work in this area our first contribution is the creation of a high quality reference dataset we collected photo manually annotated them and hired trained photographer to retouch each picture the result is a collection of set of example input output pair that enable supervised learning we first use this dataset to predict a user s adjustment from a large training set we then show that our dataset and feature enable the accurate adjustment personalization using a carefully chosen set of training photo finally we introduce difference learning this method model and predicts difference between user it free the user from using predetermined photo for training we show that difference learning enables accurate prediction using only a handful of example 
articulated object represent an important class of object in our everyday environment automatic detection of the type of articulated or otherwise restricted motion and extraction of the corresponding motion parameter are therefore of high value eg in order to augment an otherwise static d reconstruction with dynamic semantics such a rotation ax and allowable translation direction for certain rigid part or object hence in this paper a novel theory to analyse relative transformation between two motion restricted part will be presented the analysis is based on linear subspace spanned by relative transformation moreover a signature for relative transformation will be introduced which uniquely specifies the type of restricted motion encoded in these relative transformation this theoretic framework enables the derivation of novel algebraic constraint such a low rank constraint for subsequent rotation around two fixed ax for example lastly given the type of restricted motion a predicted by the signature the paper show how to extract all the motion parameter with matrix manipulation from linear algebra our theory is verified on several real data set such a a rotating blackboard or a wheel rolling on the floor amongst others 
the problem of describing image through natural language ha gained importance in the computer vision community solution to image description have either focused on a top down approach of generating language through combination of object detection and language model or bottom up propagation of keyword tag from training image to test image through probabilistic or nearest neighbor technique in contrast describing video with natural language is a le studied problem in this paper we combine idea from the bottom up and top down approach to image description and propose a method for video description that capture the most relevant content of a video in a natural language description we propose a hybrid system consisting of a low level multimodal latent topic model for initial keyword annotation a middle level of concept detector and a high level module to produce final lingual description we compare the result of our system to human description in both short and long form on two datasets and demonstrate that final system output ha greater agreement with the human description than any single level 
lip reading from visual channel remains a challenging topic considering the various speaking characteristic in this paper we address an efficient lip reading approach by investigating the unsupervised random forest manifold alignment rfma the density random forest is employed to estimate affinity of patch trajectory in speaking facial video we propose novel criterion for node splitting to avoid the rank deficiency in learning density forest by virtue of the hierarchical structure of random forest the trajectory affinity are measured efficiently which are used to find embeddings of the speaking video clip by a graph based algorithm lip reading is formulated a matching between manifold of query and reference video clip we employ the manifold alignment technique for matching where the l norm based manifold to manifold distance is proposed to find the matching pair we apply this random forest manifold alignment technique to various video data set captured by consumer camera the experiment demonstrate that lip reading can be performed effectively and outperform state of the art 
with the advent of larger image classification dataseis such a imagenet designing scalable and efficient multi class classification algorithm is now an important challenge we introduce a new scalable learning algorithm for large scale multi class image classification based on the multinomial logistic loss and the trace norm regularization penalty reframing the challenging non smooth optimization problem into a surrogate infinite dimensional optimization problem with a regular regularization penalty we propose a simple and provably efficient accelerated coordinate descent algorithm furthermore we show how to perform efficient matrix computation in the compressed domain for quantized dense visual feature scaling up to s example s dimensional feature and s of category promising experimental result on the fungus ungulate and vehicle subset of imagenet are presented where we show that our approach performs significantly better than state of the art approach for fisher vector with gaussians 
we introduce an online learning approach for multitarget tracking detection response are gradually associated into tracklets in multiple level to produce final track unlike most previous approach which only focus on producing discriminative motion and appearance model for all target we further consider discriminative feature for distinguishing difficult pair of target the tracking problem is formulated using an online learned crf model and is transformed into an energy minimization problem the energy function include a set of unary function that are based on motion and appearance model for discriminating all target a well a a set of pairwise function that are based on model for differentiating corresponding pair of tracklets the online crf approach is more powerful at distinguishing spatially close target with similar appearance a well a in dealing with camera motion an efficient algorithm is introduced for finding an association with low energy cost we evaluate our approach on three public data set and show significant improvement compared with several state of art method 
visual recognition system for video using statistical learning model often show degraded performance when being deployed to a real world environment primarily due to the fact that training data can hardly cover sufficient variation in reality to alleviate this issue we propose to utilize the object correspondence in successive frame a weak supervision to adapt visual recognition model which is particularly suitable for human profile recognition specifically we substantialize this new strategy on an advanced convolutional neural network cnn based system to estimate human gender age and race we enforce the system to output consistent and stable result on face image from the same trajectory in video by using incremental stochastic training our baseline system already achieves competitive performance on gender and age estimation a compared to the state of the art algorithm on the fg net database further on two new video datasets containing about person the proposed supervision of correspondence improves the estimation accuracy by a large margin over the baseline 
we present a shading based shape refinement algorithm which us a noisy incomplete depth map from kinect to help resolve ambiguity in shape from shading in our framework the partial depth information is used to overcome ba relief ambiguity in normal estimation a well a to assist in recovering relative albedo which are needed to reliably estimate the lighting environment and to separate shading from albedo this refinement of surface normal using a noisy depth map lead to high quality d surface the effectiveness of our algorithm is demonstrated through several challenging real world example 
symmetry is a powerful shape regularity that s been exploited by perceptual grouping researcher in both human and computer vision to recover part structure from an image without a priori knowledge of scene content drawing on the concept of a medial axis defined a the locus of center of maximal inscribed disc that sweep out a symmetric part we model part recovery a the search for a sequence of deformable maximal inscribed disc hypothesis generated from a multiscale super pixel segmentation a framework proposed by lev however we learn affinity between adjacent super pixel in a space that s invariant to bending and tapering along the symmetry axis enabling u to capture a wider class of symmetric part moreover we introduce a global cost that perceptually integrates the hypothesis space by combining a pair wise and a higher level smoothing term which we minimize globally using dynamic programming the new framework is demonstrated on two datasets and is shown to significantly outperform the baseline lev 
the problem of human activity recognition is a central problem in many real world application in this paper we propose a fast and effective segmental alignment based method that is able to classify activity and interaction in complex environment we empirically show that such model is able to recover the alignment that lead to improved similarity measure within sequence class and hence raise the classification performance we also apply a bounding technique on the histogram distance to reduce the computation of the otherwise exhaustive search 
image object retrieval locating image occurrence of specific object in large scale image collection is essential for manipulating the sheer amount of photo current solution mostly based on bag of word model suffer from low recall rate and do not resist noise caused by the change in lighting viewpoint and even occlusion we propose to augment each image with auxiliary visual word avws semantically relevant to the search target the avws are automatically discovered by feature propagation and selection in textual and visual image graph in an unsupervised manner we investigate variant optimization method for effectiveness and scalability in large scale image collection experimenting in the large scale consumer photo we found that the the proposed method significantly improves the traditional bag of word relatively meanwhile the selection process can also notably reduce the number of feature to and can further facilitate indexing in large scale image object retrieval 
in this paper the problem of pairwise model to scene point set registration is considered three contribution are made firstly the relation between correspondence based and some information theoretic point cloud registration algorithm are formalized starting from the observation that the outlier handling of existing method relies on heuristically determined model a second contribution is made exploiting aforementioned relation to derive a new robust point set registration algorithm representing model and scene point cloud by mixture of gaus sian the method minimizes their kullback leibler divergence both w r t the registration transformation parameter and w r t the scene s mixture coefficient this result in an expectation maximization iterative closest point em icp approach with a parameter free outlier model that is optimal in information theoretical sense while the current cuda implementation is limited to the rigid registration case the underlying theory applies to both rigid and non rigid point set registration a a by product of the registration algorithm s theory a third contribution is made by suggesting a new point cloud kernel density estimation approach which relies on maximizing the resulting distribution s entropy w r t the kernel weight the rigid registration algorithm is applied to align different patch of the publicly available stanford dragon and stanford happy budha range data the result show good performance regarding accuracy robustness and convergence range 
d building reconstruction aim at creating building model composed of complex roof and vertical wall in this paper we define d building topology a a set of roof feature wall feature and point feature together with the association between them based on this definition we extend d dual contouring into a d modeling method with topology control comparing with the previous method we put le restriction on the adaptive simplification process we show result under intense geometry simplification our result preserve significant topology structure while the number of triangle is comparable to that of manually created model or primitive based model 
edge detection is a critical component of many vision system including object detector and image segmentation algorithm patch of edge exhibit well known form of local structure such a straight line or t junction in this paper we take advantage of the structure present in local image patch to learn both an accurate and computationally efficient edge detector we formulate the problem of predicting local edge mask in a structured learning framework applied to random decision forest our novel approach to learning decision tree robustly map the structured label to a discrete space on which standard information gain measure may be evaluated the result is an approach that obtains real time performance that is order of magnitude faster than many competing state of the art approach while also achieving state of the art edge detection result on the bsds segmentation dataset and nyu depth dataset finally we show the potential of our approach a a general purpose edge detector by showing our learned edge model generalize well across datasets 
joint segmentation of image set ha great importance for object recognition image classification and image retrieval in this paper we aim to jointly segment a set of image starting from a small number of labeled image or none at all to allow the image to share segmentation information with each other we build a network that contains segmented a well a unsegmented image and extract functional map between connected image pair based on image appearance feature these functional map act a general property transporter between the image and in particular are used to transfer segmentation we define and operate in a reduced functional space optimized so that the functional map approximately satisfy cycle consistency under composition in the network a joint optimization framework is proposed to simultaneously generate all segmentation function over the image so that they both align with local segmentation cue in each particular image and agree with each other under network transportation this formulation allows u to extract segmentation even with no training data but can also exploit such data when available the collective effect of the joint processing using functional map lead to accurate information sharing among image and yield superior segmentation result a shown on the icoseg msrc and pascal data set 
surface irradiance signal are turned into outgoing radiance through the surface reflectance function which can be significantly perturbed by the illumination condition due to their low frequency nature irradiance signal can be represented using low order basis function where spherical harmonic sh have been extensively used to provide such basis when capturing image irradiance from a single viewpoint the visible part of the object s surface construct the upper hemisphere of the surface normal where the sh are no longer orthonormal this reduced domain pave the way for even lower dimensional approximation since full spherical representation is not needed while harmonic basis are known to be optimal under distant light light coming from near by object and indoor environment are common near light scenario it is essential to relax distant light assumption considering light source s distributed uniformly over the upper hemisphere we propose the use of hemispherical harmonic hsh to model image irradiance of convex lambertian object perceived from single viewpoint under unknown near illumination we prove analytically and experimentally validated that the lambertian kernel ha a more compact harmonic expansion in the hemispherical domain when compared to it spherical counterpart we illustrate that hsh provide an efficient and accurate low dimensional representation of image irradiance of lambertian object under near lighting condition in contrast to sh 
using multiple family of image feature is a very efficient strategy to improve performance in object detection or recognition however such a strategy induces multiple challenge for machine learning method both from a computational and a statistical perspective 
large margin learning approach such a support vector machine svm have been successfully applied to numerous classification task especially for automatic facial expression recognition the risk of such approach however is their sensitivity to large margin loss due to the influence from noisy training example and outlier which is a common problem in the area of affective computing i e manual coding at the frame level is tedious so coarse label are normally assigned in this paper we leverage the relaxation of the parallel hyperplanes constraint and propose the use of modified correlation filter mcf the mcf is similar in spirit to svms and correlation filter but with the key difference of optimizing only a single hyperplane we demonstrate the superiority of mcf over current technique on a battery of experiment 
we describe a novel method that simultaneously cluster and associate short sequence of detected face termed a face track let in video the rationale of our method is that face track let clustering and linking are related problem that can benefit from the solution of each other our method is based on a hidden markov random field model that represents the joint dependency of cluster label and track let linking association we provide an efficient algorithm based on constrained clustering and optimal matching for the simultaneous inference of cluster label and track let association we demonstrate significant improvement on the state of the art result in face tracking and clustering performance on several video datasets 
matching people across non overlapping camera view known a person re identification is challenging due to the lack of spatial and temporal constraint and large visual appearance change caused by variation in view angle lighting background clutter and occlusion to address these challenge most previous approach aim to extract visual feature that are both distinctive and stable under appearance change however most visual feature and their combination under realistic condition are neither stable nor distinctive thus should not be used indiscriminately in this paper we propose to formulate person re identification a a distance learning problem which aim to learn the optimal distance that can maximises matching accuracy regardless the choice of representation to that end we introduce a novel probabilistic relative distance comparison prdc model which differs from most existing distance learning method in that rather than minimising intra class variation whilst maximising intra class variation it aim to maximise the probability of a pair of true match having a smaller distance than that of a wrong match pair this make our model more tolerant to appearance change and le susceptible to model over fitting extensive experiment are carried out to demonstrate that by formulating the person re identification problem a a distance learning problem notable improvement on matching accuracy can be obtained against conventional person re identification technique which is particularly significant when the training sample size is small and our prdc outperforms not only existing distance learning method but also alternative learning method based on boosting and learning to rank 
in this work we present an efficient multi scale low rank representation for image segmentation our method begin with partitioning the input image into a set of super pixel followed by seeking the optimal super pixel pair affinity matrix both of which are performed at multiple scale of the input image since low level super pixel feature are usually corrupted by image noise we propose to infer the low rank refined affinity matrix the inference is guided by two observation on natural image first looking into a single image local small size image pattern tend to recur frequently within the same semantic region but may not appear in semantically different region we call this internal image statistic a replication prior and quantitatively justify it on real image database second the affinity matrix at different scale should be consistently solved which lead to the cross scale consistency constraint we formulate these two purpose with one unified formulation and develop an efficient optimization procedure our experiment demonstrate the presented method can substantially improve segmentation accuracy 
pmsvm power mean svm a classifier that train significantly faster than state of the art linear and non linear svm solver in large scale visual classification task is presented pmsvm also achieves higher accuracy a scalable learning method for large vision problem e g with million of example or dimension is a key component in many current vision system recent progress have enabled linear classifier to efficiently process such large scale problem linear classifier however usually have inferior accuracy in vision task non linear classifier on the other hand may take week or even year to train we propose a power mean kernel and present an efficient learning algorithm through gradient approximation the power mean kernel family include a special case many popular additive kernel empirically pmsvm is up to time faster than liblinear and two time faster than state of the art additive kernel classifier in term of accuracy it outperforms state of the art additive kernel implementation and ha major advantage over linear svm 
we present the major advantage of a new object oriented d slam paradigm which take full advantage in the loop of prior knowledge that many scene consist of repeated domain specific object and structure a a hand held depth camera browse a cluttered scene real time d object recognition and tracking provides dof camera object constraint which feed into an explicit graph of object continually refined by efficient pose graph optimisation this offer the descriptive and predictive power of slam system which perform dense surface reconstruction but with a huge representation compression the object graph enables prediction for accurate icp based camera to model tracking at each live frame and efficient active search for new object in currently undescribed image region we demonstrate real time incremental slam in large cluttered environment including loop closure relocalisation and the detection of moved object and of course the generation of an object level scene description with the potential to enable interaction 
in this paper we propose a novel dense depth recovery method for a trinocular video sequence specifically we contribute a novel trinocular stereo matching model which can effectively utilize the advantage of trinocular stereo image and incorporate the visibility term with segmentation prior for robust depth estimate in order to make the recovered depth map more accurate and temporally consistent we propose to first classify the pixel to static and dynamic one and then perform spatio temporal depth optimization for them in different way especially we propose two motion model for handling dynamic pixel the traditional bundle optimization model and our spatio temporal optimization model are softly combined in a probabilistic way so that the depth of both static and dynamic pixel can be effectively refined our automatic depth recovery approach is evaluated using a variety of challenging trinocular video sequence 
object localization is a challenging problem due to variation in object s structure and illumination although existing part based model have achieved impressive progress in the past several year their improvement is still limited by low level feature representation therefore this paper mainly study the description of object structure from both feature level and topology level following the bottom up paradigm we propose a boosted local structured hog lbp based object detector firstly at feature level we propose local structured descriptor to capture the object s local structure and develop the descriptor from shape and texture information respectively secondly at topology level we present a boosted feature selection and fusion scheme for part based object detector all experiment are conducted on the challenging pascal voc datasets experimental result show that our method achieves the state of the art performance 
we present a novel technique for figure ground segmentation where the goal is to separate all foreground object in a test image from the background we decompose the test image and all image in a supervised training set into overlapping window likely to cover foreground object the key idea is to transfer segmentation mask from training window that are visually similar to window in the test image these transferred mask are then used to derive the unary potential of a binary pairwise energy function defined over the pixel of the test image which is minimized with standard graph cut this result in a fully automatic segmentation scheme a opposed to interactive technique based on similar energy function using window a support region for transfer efficiently exploit the training data a the test image doe not need to be globally similar to a training image for the method to work this enables to compose novel scene using local part of training image our approach obtains very competitive result on three datasets pascal voc segmentation challenge weizmann horse graz 
this paper present a novel tree based cost aggregation method for dense stereo matching instead of employing the minimum spanning tree mst and it variant a new tree structure segment tree is proposed for non local matching cost aggregation conceptually the segment tree is constructed in a three step process first the pixel are grouped into a set of segment with the reference color or intensity image second a tree graph is created for each segment and in the final step these independent segment graph are linked to form the segment tree structure in practice this tree can be efficiently built in time nearly linear to the number of the image pixel compared to mst where the graph connectivity is determined with local edge weight our method introduces some non local decision rule the pixel in one perceptually consistent segment are more likely to share similar disparity and therefore their connectivity within the segment should be first enforced in the tree construction process the matching cost are then aggregated over the tree within two pass performance evaluation on middlebury data set show that the proposed method is comparable to previous state of the art aggregation method in disparity accuracy and processing speed furthermore the tree structure can be refined with the estimated disparity which lead to consistent scene segmentation and significantly better aggregation result 
a novel statistical textural distinctiveness approach for robustly detecting salient region in natural image is proposed rotational invariant neighborhood based textural representation are extracted and used to learn a set of representative texture atom for defining a sparse texture model for the image based on the learnt sparse texture model a weighted graphical model is constructed to characterize the statistical textural distinctiveness between all representative texture atom pair finally the saliency of each pixel in the image is computed based on the probability of occurrence of the representative texture atom their respective statistical textural distinctiveness based on the constructed graphical model and general visual attentive constraint experimental result using a public natural image dataset and a variety of performance evaluation metric show that the proposed approach provides interesting and promising result when compared to existing saliency detection method 
many standard computer vision datasets exhibit bias due to a variety of source including illumination condition imaging system and preference of dataset collector bias like these can have downstream effect in the use of vision datasets in the construction of generalizable technique especially for the goal of the creation of a classification system capable of generalizing to unseen and novel datasets in this work we propose unbiased metric learning uml a metric learning approach to achieve this goal uml operates in the following two step by varying hyper parameter it learns a set of le biased candidate distance metric on training example from multiple biased datasets the key idea is to learn a neighborhood for each example which consists of not only example of the same category from the same dataset but those from other datasets the learning framework is based on structural svm we do model validation on a set of weakly labeled web image retrieved by issuing class label a keywords to search engine the metric with best validation performance is selected although the web image sometimes have noisy label they often tend to be le biased which make them suitable for the validation set in our task cross dataset image classification experiment are carried out result show significant performance improvement on four well known computer vision datasets 
attribute based representation ha shown great promise for visual recognition due to it intuitive interpretation and cross category generalization property however human effort are usually involved in the attribute designing process making the representation costly to obtain in this paper we propose a novel formulation to automatically design discriminative category level attribute which can be efficiently encoded by a compact category attribute matrix the formulation allows u to achieve intuitive and critical design criterion category separability learn ability in a principled way the designed attribute can be used for task of cross category knowledge transfer achieving superior performance over well known attribute dataset animal with attribute awa and a large scale ilsvrc dataset m image this approach also lead to state of the art performance on the zero shot learning task on awa 
challenge but also an opportunity to eliminate spurious similarity luckily a major source of confusion in visual similarity of face is the d head orientation for which image analysis tool provide an accurate estimation the method we propose belongs to a family of classifier based similarity score we present an effective way to discount pose induced similarity within such a framework which is based on a newly introduced classifier called svm minus the presented method is shown to outperform existing technique on the most challenging and realistic publicly available video face recognition benchmark both by itself and in concert with other method 
under unknown directional lighting the uncalibrated lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized ba relief gbr ambiguity we resolve this ambiguity from the half vector symmetry which is observed in many isotropic material under this symmetry a d brdf slice with low rank structure can be obtained from an image if the surface normal and light direction are correctly recovered in general this structure is destroyed by the gbr ambiguity a a result we can resolve the ambiguity by restoring this structure we develop a simple algorithm of auto calibration from separable homogeneous specular reflection of real image compared with previous method this method take a holistic approach to exploiting reflectance symmetry and produce superior result 
haar like feature are ubiquitous in computer vision e g for viola and jones face detection or local descriptor such a speeded up robust feature they are classically computed in one pas over integral image by reading the value at the feature corner here we present a new general parsing formalism for convolving them more efficiently our method is fully automatic and applicable to an arbitrary set of haar like feature the parser reduces the number of memory access which are the main computational bottleneck during convolution on modern computer architecture it first split the feature into simpler kernel then it aligns and reuses them where applicable forming an ensemble of recursive convolution tree which can be computed faster this is illustrated with experiment which show a significant speed up over the classic approach 
in this paper we present a framework for the recognition of collective human activity a collective activity is defined or reinforced by the existence of coherent behavior of individual in time and space we call such coherent behavior crowd context example of collective activity are queuing in a line or talking following we propose to recognize collective activity using the crowd context and introduce a new scheme for learning it automatically our scheme is constructed upon a random forest structure which randomly sample variable volume spatio temporal region to pick the most discriminating attribute for classification unlike previous approach our algorithm automatically find the optimal configuration of spatio temporal bin over which to sample the evidence by randomization this enables a methodology for modeling crowd context we employ a d markov random field to regularize the classification and localize collective activity in the scene we demonstrate the flexibility and scalability of the proposed framework in a number of experiment and show that our method outperforms state of the art action classification technique 
learning from stream of evolving and unbounded data is an important problem for example in visual surveillance or internet scale data for such large and evolving real world data exhaustive supervision is impractical particularly so when the full space of class is not known in advance therefore joint class discovery exploration and boundary learning exploitation becomes critical active learning ha shown promise in jointly optimising exploration exploitation with minimal human supervision however existing active learning method either rely on heuristic multi criterion weighting or are limited to batch processing in this paper we present a new unified framework for joint exploration exploitation active learning in stream without any heuristic weighting extensive evaluation on classification of various image and surveillance video datasets demonstrates the superiority of our framework over existing method 
product quantization is an effective vector quantization approach to compactly encode high dimensional vector for fast approximate nearest neighbor ann search the essence of product quantization is to decompose the original high dimensional space into the cartesian product of a finite number of low dimensional subspace that are then quantized separately optimal space decomposition is important for the performance of ann search but still remains unaddressed in this paper we optimize product quantization by minimizing quantization distortion w r t the space decomposition and the quantization codebooks we present two novel method for optimization a non parametric method that alternatively solves two smaller sub problem and a parametric method that is guaranteed to achieve the optimal solution if the input data follows some gaussian distribution we show by experiment that our optimized approach substantially improves the accuracy of product quantization for ann search 
in recent year polynomial solver based on algebraic geometry technique and specifically the action matrix method have become popular for solving minimal problem in computer vision in this paper we develop a new method for reducing the computational time and improving numerical stability of algorithm using this method to achieve this we propose and prove a set of algebraic condition which allow u to reduce the size of the elimination template polynomial coefficient matrix which lead to faster lu or qr decomposition our technique is generic and ha potential to improve performance of many solver that use the action matrix method we demonstrate the approach on specific example including an image stitching algorithm where computation time is halved and single precision arithmetic can be used 
evaluating visual tracking algorithm or tracker for short is of great importance in computer vision however it is hard to fairly compare tracker due to many parameter need to be tuned in the experimental configuration on the other hand when introducing a new tracker a recent trend is to validate it by comparing it with several existing one such an evaluation may have subjective bias towards the new tracker which typically performs the best this is mainly due to the difficulty to optimally tune all it competitor and sometimes the selected testing sequence by contrast little subjective bias exists towards the second best one in the contest this observation inspires u with a novel perspective towards inhibiting subjective bias in evaluating tracker by analyzing the result between the second best in particular we first collect all tracking paper published in major computer vision venue in recent year from these paper after filtering out potential bias in various aspect we create a dataset containing many record of comparison result between various visual tracker using these record we derive performance ranking of the involved tracker by four different method the first two method model the dataset a a graph and then derive the ranking over the graph one by a rank aggregation algorithm and the other by a pagerank like solution the other two method take the record a generated from sport contest and adopt widely used elo s and glicko s rating system to derive the ranking the experimental result are presented and may serve a a reference for related research 
we propose a novel framework for automatic saliency estimation in natural image we consider saliency to be an anomaly with respect to a given context that can be global or local in the case of global context we estimate saliency in the whole image relative to a large dictionary of image unlike in some prior method this dictionary is not annotated i e saliency is assumed unknown in the case of local context we partition the image into patch and estimate saliency in each patch relative to a large dictionary of un annotated patch from the rest of the image we propose a unified framework that applies to both case in three step first given an input image or patch we extract k nearest neighbor from the dictionary then we geometrically warp each neighbor to match the input finally we derive the saliency map from the mean absolute error between the input and all it warped neighbor this algorithm is not only easy to implement but also outperforms state of the art method 
local spatio temporal interest point stips and the resulting feature from rgb video have been proven successful at activity recognition that can handle cluttered background and partial occlusion in this paper we propose it counterpart in depth video and show it efficacy on activity recognition we present a filtering method to extract stips from depth video called dstip that effectively suppress the noisy measurement further we build a novel depth cuboid similarity feature dcsf to describe the local d depth cuboid around the dstips with an adaptable supporting size we test this feature on activity recognition application using the public msraction d msrdailyactivity d datasets and our own dataset experimental evaluation show that the proposed approach outperforms state of the art activity recognition algorithm on depth video and the framework is more widely applicable than existing approach we also give detailed comparison with other feature and analysis of choice of parameter a a guidance for application 
in this paper we present a novel approach of human activity prediction human activity prediction is a probabilistic process of inferring ongoing activity from video only containing onset i e the beginning part of the activity the goal is to enable early recognition of unfinished activity a opposed to the after the fact classification of completed activity activity prediction methodology are particularly necessary for surveillance system which are required to prevent crime and dangerous activity from occurring we probabilistically formulate the activity prediction problem and introduce new methodology designed for the prediction we represent an activity a an integral histogram of spatio temporal feature efficiently modeling how feature distribution change over time the new recognition methodology named dynamic bag of word is developed which considers sequential nature of human activity while maintaining advantage of the bag of word to handle noisy observation our experiment confirm that our approach reliably recognizes ongoing activity from streaming video with a high accuracy 
shadow encode a powerful geometric cue if one pixel cast a shadow onto another then the two pixel are colinear with the lighting direction given many image over many lighting direction this constraint can be leveraged to recover the depth of a scene from a single viewpoint for outdoor scene with solar illumination we term this the episolar constraint which provides a convex optimization to solve for the sparse depth of a scene from shadow correspondence a method to reduce the search space when finding shadow correspondence and a method to geometrically calibrate a camera using shadow constraint our method construct a dense network of nonlocal constraint which complement recent work on outdoor photometric stereo and cloud based cue for d we demonstrate result across a variety of time lapse sequence from web cam in the wild 
it is well known that multi surface segmentation can be cast a a multi labeling problem different segment may belong to the same semantic object which may impose various inter segment constraint in medical application there are a lot of scenario where upper bound on the hausdorff distance between subsequent surface are known we show that incorporating these prior into multi surface segmentation is potentially np hard to cope with this problem we develop a submodular supermodular procedure that converges to a locally optimal solution well approximating the problem while we cannot guarantee global optimality only feasible solution are considered during the optimization process empirically we get useful solution for many challenging medical application including mri and ultrasound image 
we present data driven technique to augment bag of word bow model which allow for more robust modeling and recognition of complex long term activity especially when the structure and topology of the activity are not known a priori our approach specifically address the limitation of standard bow approach which fail to represent the underlying temporal and causal information that is inherent in activity stream in addition we also propose the use of randomly sampled regular expression to discover and encode pattern in activity we demonstrate the effectiveness of our approach in experimental evaluation where we successfully recognize activity and detect anomaly in four complex datasets 
the presence of bias in existing object recognition datasets is now well known in the computer vision community while it remains in question whether creating an unbiased dataset is possible given limited resource in this work we propose a discriminative framework that directly exploit dataset bias during training in particular our model learns two set of weight bias vector associated with each individual dataset and visual world weight that are common to all datasets which are learned by undoing the associated bias from each dataset the visual world weight are expected to be our best possible approximation to the object model trained on an unbiased dataset and thus tend to have good generalization ability we demonstrate the effectiveness of our model by applying the learned weight to a novel unseen dataset and report superior result for both classification and detection task compared to a classical svm that doe not account for the presence of bias overall we find that it is beneficial to explicitly account for bias when combining multiple datasets 
we present a part based approach to the problem of human attribute recognition from a single image of a human body to recognize the attribute of human from the body part it is important to reliably detect the part this is a challenging task due to the geometric variation such a articulation and view point change a well a the appearance variation of the part arisen from versatile clothing type the prior work have primarily focused on handling geometric variation by relying on pre trained part detector or pose estimator which require manual part annotation but the appearance variation ha been relatively neglected in these work this paper explores the importance of the appearance variation which is directly related to the main task attribute recognition to this end we propose to learn a rich appearance part dictionary of human with significantly le supervision by decomposing image lattice into overlapping window at multiscale and iteratively refining local appearance template we also present quantitative result in which our proposed method outperforms the existing approach 
in this work we propose to leverage a large number of loosely labeled web video e g from youtube and web image e g from google bing image search for visual event recognition in consumer video without requiring any labeled consumer video we formulate this task a a new multi domain adaptation problem with heterogeneous source in which the sample from different source domain can be represented by different type of feature with different dimension e g the sift feature from web image and space time st feature from web video while the target domain sample have all type of feature to effectively cope with the heterogeneous source where some source domain are more relevant to the target domain we propose a new method called multi domain adaptation with heterogeneous source mda h to learn an optimal target classifier in which we simultaneously seek the optimal weight for different source domain with different type of feature a well a infer the label of unlabeled target domain data based on multiple type of feature we solve our optimization problem by using the cutting plane algorithm based on group based multiple kernel learning comprehensive experiment on two datasets demonstrate the effectiveness of mda h for event recognition in consumer video 
effective and efficient generation of keypoints from an image is a well studied problem in the literature and form the basis of numerous computer vision application established leader in the field are the sift and surf algorithm which exhibit great performance under a variety of image transformation with surf in particular considered a the most computationally efficient amongst the high performance method to date in this paper we propose brisk 
in moving camera video motion segmentation is commonly performed using the image plane motion of pixel or optical flow however object that are at different depth from the camera can exhibit different optical flow even if they share the same real world motion this can cause a depth dependent segmentation of the scene our goal is to develop a segmentation algorithm that cluster pixel that have similar real world motion irrespective of their depth in the scene our solution us optical flow orientation instead of the complete vector and exploit the well known property that under camera translation optical flow orientation are independent of object depth we introduce a probabilistic model that automatically estimate the number of observed independent motion and result in a labeling that is consistent with real world motion in the scene the result of our system is that static object are correctly identified a one segment even if they are at different depth color feature and information from previous frame in the video sequence are used to correct occasional error due to the orientation based segmentation we present result on more than thirty video from different benchmark the system is particularly robust on complex background scene containing object at significantly different depth 
we propose to align the orientation of local feature descriptor with the gravitational force measured with inertial sensor in contrast to standard approach that gain a reproducible feature orientation from the intensity of neighboring pixel to remain invariant against rotation this approach result in clearly distinguishable descriptor for congruent feature in different orientation gravity aligned feature descriptor gafd are suitable for any application relying on corresponding point in multiple image of static scene and are particularly beneficial in the presence of differently oriented repetitive feature a they are widespread in urban scene and on man made object in this paper we show with different example that the process of feature description and matching get both faster and result in better match when aligning the descriptor with the gravity compared to traditional technique 
we propose a hierarchical segmentation algorithm that start with a very fine over segmentation and gradually merges region using a cascade of boundary classifier this approach allows the weight of region and boundary feature to adapt to the segmentation scale at which they are applied the stage of the cascade are trained sequentially with asymetric loss to maximize boundary recall on six segmentation data set our algorithm achieves best performance under most region quality measure and doe it with fewer segment than the prior work our algorithm is also highly competitive in a dense over segmentation super pixel regime under boundary based measure 
multi atlas segmentation ha been widely applied in medical image analysis with deformable registration this technique realizes label transfer from pre labeled atlas to unknown image when deformable registration produce error label fusion that combine result produced by multiple atlas is an effective way for reducing segmentation error among the existing label fusion strategy similarity weighted voting strategy with spatially varying weight distribution have been particularly successful we show that weighted voting based label fusion produce a spatial bias that under segment structure with convex shape the bias can be approximated a applying spatial convolution to the ground truth spatial label probability map where the convolution kernel combine the distribution of residual registration error and the function producing similarity based voting weight to reduce this bias we apply a standard spatial deconvolution to the spatial probability map obtained from weighted voting in a brain image segmentation experiment we demonstrate the spatial bias and show that our technique substantially reduces this spatial bias 
we address the problem of matching image with disparate appearance arising from factor like dramatic illumination day v night age historic v new and rendering style difference the lack of local intensity or gradient pattern in these image make the application of pixel level descriptor like sift infeasible we propose a novel formulation for detecting and matching persistent feature between such image by analyzing the eigen spectrum of the joint image graph constructed from all the pixel in the two image we show experimental result of our approach on a public dataset of challenging image pair and demonstrate significant performance improvement over state of the art 
although graph matching is a fundamental problem in pattern recognition and ha drawn broad interest from many field the problem of learning graph matching ha not received much attention in this paper we redefine the learning of graph matching a a model learning problem in addition to conventional training of matching parameter our approach modifies the graph structure and attribute to generate a graphical model in this way the model learning is oriented toward both matching and recognition performance and can proceed in an unsupervised fashion experiment demonstrate that our approach outperforms conventional method for learning graph matching 
we present a method for reconstructing a trajectory of an object moving in front of non overlapping fully or partially calibrated camera the non overlapping setup turn that problem ill posed a no point correspondence can be established which are necessary for the well known point triangulation the proposed solution instead build on the assumption of trajectory smoothness and depth ordering prior information we propose a novel formulation with a consistent minimization criterion and a way to utilize the depth ordering prior reflected by the size change of a bounding box associated to an image point being tracked reconstructing trajectory minimizing the trajectory smoothness it re projection error and employing the depth prior is casted a the second order cone program yielding a global optimum the new formulation together with the proposed depth prior significantly improves the trajectory reconstruction in sense of accuracy and topology and speed up the solver synthetic and real experiment validate the feasibility of the proposed approach 
in this paper we demonstrated an application of video tracking to radiation detection where a vision based tracking system enables a traditional czt cadmium zinc telluride based radiation imaging device to detect radioactive target that are in motion an integrated real time system consisting of multiple fixed camera and radiation detector wa implemented and tested the multi camera tracking system combine multiple feature cue such a silhouette appearance and geometry from different viewing angle to ensure consistent target identity under challenging tracking condition experimental result show that both the video tracking and the integrated system perform accurately and persistently under various scenario involving multiple vehicle driving speed and driving pattern the result also validate and reiterate the importance of video tracking a an enabling technology in the field of radiation imaging 
collecting and annotating video of realistic human action is tedious yet critical for training action recognition system we propose a method to actively request the most useful video annotation among a large set of unlabeled video predicting the utility of annotating unlabeled video is not trivial since any given clip may contain multiple action of interest and it need not be trimmed to temporal region of interest to deal with this problem we propose a detection based active learner to train action category model we develop a voting based framework to localize likely interval of interest in an unlabeled clip and use them to estimate the total reduction in uncertainty that annotating that clip would yield on three datasets we show our approach can learn accurate action detector more efficiently than alternative active learning strategy that fail to accommodate the untrimmed nature of real video data 
when tracking multiple target in crowded scenario modeling mutual exclusion between distinct target becomes important at two level in data association each target observation should support at most one trajectory and each trajectory should be assigned at most one observation per frame in trajectory estimation two trajectory should remain spatially separated at all time to avoid collision yet existing tracker often sidestep these important constraint we address this using a mixed discrete continuous conditional random field crf that explicitly model both type of constraint exclusion between conflicting observation with super modular pairwise term and exclusion between trajectory by generalizing global label cost to suppress the co occurrence of incompatible label trajectory we develop an expansion move based map estimation scheme that handle both non sub modular constraint and pairwise global label cost furthermore we perform a statistical analysis of ground truth trajectory to derive appropriate crf potential for modeling data fidelity target dynamic and inter target occlusion 
the bag of system bos representation is a descriptor of motion in a video where dynamic texture dt codewords represent the typical motion pattern in spatio temporal patch extracted from the video the efficacy of the bos descriptor depends on the richness of the codebook which directly depends on the number of codewords in the codebook however for even modest sized codebooks mapping video onto the codebook result in a heavy computational load in this paper we propose the bos tree which construct a bottom up hierarchy of codewords that enables efficient mapping of video to the bos codebook by leveraging the tree structure to efficiently index the codewords the bos tree allows for fast look ups in the codebook and enables the practical use of larger richer codebooks we demonstrate the effectiveness of bos tree on classification of three video datasets a well a on annotation of a music dataset 
we address two key issue of co segmentation over multiple image the first is whether a pure unsupervised algorithm can satisfactorily solve this problem without the user s guidance segmenting the foreground implied by the common object is quite a challenging task especially when substantial variation in the object s appearance shape and scale are allowed the second issue concern the efficiency if the technique can lead to practical us with these in mind we establish an mrf optimization model that ha an energy function with nice property and can be shown to effectively resolve the two difficulty specifically instead of relying on the user input our approach introduces a co saliency prior a the hint about possible foreground location and us it to construct the mrf data term to complete the optimization framework we include a novel global term that is more appropriate to co segmentation and result in a submodular energy function the proposed model can thus be optimally solved by graph cut we demonstrate these advantage by testing our method on several benchmark datasets 
we present a novel method that can separate m bounced light and remove the interreflection in a photometric stereo setup under the assumption of a uniformly colored lambertian surface the intensity of a point in the scene is the sum of bounced light through m bounced light ray ruled by the law of diffuse reflection whenever a light ray is bounced by the surface it intensity will be attenuated by the factor of albedo this implies that the measured intensity value can be written a a polynomial function of and the intensity contribution of the m bounced light ray are expressed by the term of m therefore when we change the surface albedo the intensity of the m bounced light is changed to the order of m this non linearity give u the possibility to separate the m bounced light in practice we illuminate the scene with different light color to effectively simulate different surface albedo since albedo is spectrum dependent once the m bounced light ray are separated we can perform the photometric stereo algorithm on the bounced light direct lighting image to produce the d shape without the impact of interreflection experiment have shown that we get significantly improved scene reconstruction with a minimum of two color image 
this paper address the independent assumption issue in fusion process in the last decade dependency modeling technique were developed under a specific distribution of classifier this paper proposes a new framework to model the dependency between feature without any assumption on feature classifier distribution in this paper we prove that feature dependency can be modeled by a linear combination of the posterior probability under some mild assumption based on the linear combination property two method namely linear classifier dependency modeling lcdm and linear feature dependency modeling lfdm are derived and developed for dependency modeling in classifier level and feature level respectively the optimal model for lcdm and lfdm are learned by maximizing the margin between the genuine and imposter posterior probability both synthetic data and real datasets are used for experiment experimental result show that lfdm outperforms all existing combination method 
video segmentation research is currently limited by the lack of a benchmark dataset that cover the large variety of sub problem appearing in video segmentation and that is large enough to avoid over fitting consequently there is little analysis of video segmentation which generalizes across subtasks and it is not yet clear which and how video segmentation should leverage the information from the still frame a previously studied in image segmentation alongside video specific information such a temporal volume motion and occlusion in this work we provide such an analysis based on annotation of a large video dataset where each video is manually segmented by multiple person moreover we introduce a new volume based metric that includes the important aspect of temporal consistency that can deal with segmentation hierarchy and that reflects the tradeoff between over segmentation and segmentation accuracy 
sparse subspace clustering ssc is one of the recent approach to subspace segmentation in ssc a graph is constructed whose node are the data point and whose edge are inferred from the l sparse representation of each point by the others it ha been proved that if the point lie on a mixture of independent subspace the graphical structure of each subspace is disconnected from the others however the problem of connectivity within each subspace is still unanswered this is important since the subspace segmentation in ssc is based on finding the connected component of the graph our analysis is built upon the connection between the sparse representation through l norm minimization and the geometry of convex poly tope proposed by the compressed sensing community after introduction of some assumption to make the problem well defined it is proved that the connectivity within each subspace hold for and dimensional subspace the claim of connectivity for general d dimensional case even for generic configuration is proved false by giving a counterexample in dimension greater than 
in this paper we study human age estimation in face image under significant expression change we will address two issue is age estimation affected by facial expression change and how significant is the influence how to develop a robust method to perform age estimation undergoing various facial expression change this systematic study will not only discover the relation between age estimation and expression change but also contribute a robust solution to solve the problem of cross expression age estimation this study is an important step towards developing a practical and robust age estimation system that allows user to present their face naturally with various expression rather than constrained to the neutral expression only two database originally captured in the psychology community are introduced to computer vision to quantitatively demonstrate the influence of expression change on age estimation and evaluate the proposed framework and corresponding method for cross expression age estimation 
recently there is a considerable amount of effort devoted to the problem of unconstrained face verification where the task is to predict whether pair of image are from the same person or not this problem is challenging and difficult due to the large variation in face image in this paper we develop a novel regularization framework to learn similarity metric for unconstrained face verification we formulate it objective function by incorporating the robustness to the large intra personal variation and the discriminative power of novel similarity metric in addition our formulation is a convex optimization problem which guarantee the existence of it global solution experiment show that our proposed method achieves the state of the art result on the challenging labeled face in the wild lfw database 
this paper present an approach to address the problem of image fa ade labelling in the architectural literature domain knowledge is usually expressed geometrically in the final design so fa ade labelling should on the one hand conform to visual evidence and on the other hand to the architectural principle how individual asset e g door window interact with each other to form a fa ade a a whole to this end we first propose a recursive splitting method to segment fa ade into a bunch of tile for semantic recognition the segmentation improves the processing speed guide visual recognition on suitable scale and render the extraction of architectural principle easy given a set of segmented training fa ade with their label map we then identify a set of meta feature to capture both the visual evidence and the architectural principle the feature are used to train our fa ade labelling model in the test stage the feature are extracted from segmented fa ade and the inferred label map the following three step are iterated until the optimal labelling is reached proposing modification to the current labelling extracting new feature for the proposed labelling feeding the new feature to the labelling model to decide whether to accept the modification in experiment we evaluated our method on the ecp fa ade dataset and achieved higher precision than the state of the art at both the pixel level and the structural level 
recognizing the event and object in the video sequence are two challenging task due to the complex temporal structure and the large appearance variation in this paper we propose a d human object interaction model where the two task jointly boost each other our human object interaction is defined in d space i the co occurrence and geometric constraint of human pose and object in d space ii the sub event transition and object coherence in d temporal dimension we represent the structure of event sub event and object in a hierarchical graph for an input rgb depth video we design a dynamic programming beam search algorithm to i segment the video ii recognize the event and iii detect the object simultaneously for evaluation we built a large scale multiview d event dataset which contains video sequence and rgbd frame captured by the kinect camera the experiment result on this dataset show the effectiveness of our method 
active appearance model aams employ a paradigm of inverting a synthesis model of how an object can vary in term of shape and appearance a a result the ability of aams to register an unseen object image is intrinsically linked to two factor first how well the synthesis model can reconstruct the object image second the degree of freedom in the model fewer degree of freedom yield a higher likelihood of good fitting performance in this paper we look at how these seemingly contrasting factor can complement one another for the problem of aam fitting of an ensemble of image stemming from a constrained set e g an ensemble of face image of the same person 
in this paper we propose a method to select a discriminative set of image processing operation for linear discriminant analysis lda a an application of the use of generating matrix representing image processing operator acting on image first we show that generating matrix can be used for formulating lda with increasing training sample then analyze them a image processing operator acting on d continuous function for compressing many large generating matrix by using pca and hermite decomposition then we propose linear discriminative image processing operator analysis an iterative method for estimating lda feature space along with a discriminative set of generating matrix in experiment we demonstrate that discriminative generating matrix outperform a non discriminative set on the orl and feret datasets 
this paper address recognition of human activity with stochastic structure characterized by variable spacetime arrangement of primitive action and conducted by a variable number of actor we demonstrate that modeling aggregate count of visual word is surprisingly expressive enough for such a challenging recognition task an activity is represented by a sum product network spn spn is a mixture of bag of word bow with exponentially many mixture component where subcomponents are reused by larger one spn consists of terminal node representing bow and product and sum node organized in a number of layer the product are aimed at encoding particular configuration of primitive action and the sum serve to capture their alternative configuration the connectivity of spn and parameter of bow distribution are learned under weak supervision using the em algorithm spn inference amount to parsing the spn graph which yield the most probable explanation mpe of the video in term of activity detection and localization spn inference ha linear complexity in the number of node under fairly general condition enabling fast and scalable recognition a new volleyball dataset is compiled and annotated for evaluation our classification accuracy and localization precision and recall are superior to those of the state of the art on the benchmark and our volleyball datasets 
we present a sensor fusion scheme that combine active stereo with photometric stereo aiming at capturing full frame depth for dynamic scene at a minimum of three lighting condition we formulate an iterative optimization scheme that adaptively adjusts the contribution from photometric stereo so that discontinuity can be preserved detects shadow area by checking the visibility of the estimated point with respect to the light source instead of using image based heuristic and behaves well for ill conditioned pixel that are under shadow which are inevitable in almost any scene furthermore we decompose our non linear cost function into subproblems that can be optimized efficiently using linear technique experiment show significantly improved result over the previous state of the art in sensor fusion 
we consider video object cut a an ensemble of frame level background foreground object classifier which fuse information across frame and refine their segmentation result in a collaborative and iterative manner our approach address the challenging issue of modeling of background with dynamic texture and segmentation of foreground object from cluttered scene we construct patch level bag of word background model to effectively capture the background motion and texture dynamic we propose a foreground salience graph fsg to characterize the similarity of an image patch to the bag of word background model in the temporal domain and to neighboring image patch in the spatial domain we incorporate this similarity information into a graph cut energy minimization framework for foreground object segmentation the background foreground classification result at neighboring frame are fused together to construct a foreground probability map to update the graph weight the resulting object shape at neighboring frame are also used a constraint to guide the energy minimization process during graph cut our extensive experimental result and performance comparison over a diverse set of challenging video with dynamic scene including the new change detection challenge dataset demonstrate that the proposed ensemble video object cut method outperforms various state of the art algorithm 
d mesh segmentation is a fundamental low level task with application in area a diverse a computer vision computer aided design bio informatics and d medical imaging a perceptually consistent mesh segmentation pcms a defined in this paper is one that satisfies in variance to isometric transformation of the underlying surface robust to the perturbation of the surface robustness to numerical noise on the surface and close conformation to human perception we exploit the intelligence of the heat a a global structure aware message on a meshed surface and develop a robust pcms scheme called heat mapping based on the heat kernel there are three main step in heat mapping first the number of the segment is estimated based on the analysis of the behavior of the laplacian spectrum second the heat center which is defined a the most representative vertex on each segment is discovered by a proposed heat center hunting algorithm third a heat center driven segmentation scheme reveals the pcms with a high consistency towards human perception extensive experimental result on various type of model verify the performance of heat mapping with respect to the consistent segmentation of articulated body the topological change and various level of numerical noise 
with the increasing popularity of practical vision system and smart phone text detection in natural scene becomes a critical yet challenging task most existing method have focused on detecting horizontal or near horizontal text in this paper we propose a system which detects text of arbitrary orientation in natural image our algorithm is equipped with a two level classification scheme and two set of feature specially designed for capturing both the intrinsic characteristic of text to better evaluate our algorithm and compare it with other competing algorithm we generate a new dataset which includes various text in diverse real world scenario we also propose a protocol for performance evaluation experiment on benchmark datasets and the proposed dataset demonstrate that our algorithm compare favorably with the state of the art algorithm when handling horizontal text and achieves significantly enhanced performance on text of arbitrary orientation in complex natural scene 
we present an approach to recognizing single actor human action in complex background we adopt a joint tracking and recognition approach which track the actor pose by sampling from d action model most existing such approach require large training data or mocap to handle multiple viewpoint and often rely on clean actor silhouette the action model in our approach are obtained by annotating keyposes in d lifting them to d stick figure and then computing the transformation matrix between the d keypose figure pose sampled from coarse action model may not fit the observation well to overcome this difficulty we propose an approach for efficiently localizing a pose by generating a pose specific part model pspm which capture appropriate kinematic and occlusion constraint in a tree structure in addition our approach also doe not require pose silhouette we show improvement to previous result on two publicly available datasets a well a on a novel augmented dataset with dynamic background 
this paper present a novel multi body multi view stereo method to simultaneously recover dense depth map and perform segmentation with the input of a monocular image sequence unlike traditional multi view stereo approach that generally handle a single static scene or an object we show that depth estimation and segmentation can be jointly modeled and be globally solved in an energy minimization framework for ubiquitous scene containing multiple independently moving rigid object our major contribution includes a new multi body stereo model which integrates the color geometry and layer constraint for spatio temporal depth recovery and automatic object segmentation a two pas optimization scheme is proposed to progressively update the estimate our method is applied to a variety of challenging example 
fusion of multiple feature can boost the performance of large scale visual classification and detection task like trecvid multimedia event detection med competition in this paper we propose a novel feature fusion approach namely feature weighting via optimal thresholding fwot to effectively fuse various feature fwot learns the weight thresholding and smoothing parameter in a joint framework to combine the decision value obtained from all the individual feature and the early fusion to the best of our knowledge this is the first work to consider the weight and threshold factor of fusion problem simultaneously compared to state of the art fusion algorithm our approach achieves promising improvement on hmdb action recognition dataset and ccv video classification dataset in addition experiment on two trecvid med collection show that our approach outperforms the state of the art fusion method for complex event detection 
the d shape of the human body is useful for application in fitness game and apparel accurate body scanner however are expensive limiting the availability of d body model we present a method for human shape reconstruction from noisy monocular image and range data using a single inexpensive commodity sensor the approach combine low resolution image silhouette with coarse range data to estimate a parametric model of the body accurate d shape estimate are obtained by combining multiple monocular view of a person moving in front of the sensor to cope with varying body pose we use a scape body model which factor d body shape and pose variation this enables the estimation of a single consistent shape while allowing pose to vary additionally we describe a novel method to minimize the distance between the projected d body contour and the image silhouette that us analytic derivative of the objective function we propose a simple method to estimate standard body measurement from the recovered scape model and show that the accuracy of our method is competitive with commercial body scanning system costing order of magnitude more 
in many visual classification task the spatial distribution of discriminative information is i non uniform e g person reading can be distinguished from taking a photo based on the area around the arm i e ignoring the leg and ii ha intra class variation e g different reader may hold the book differently motivated by these observation we propose to learn the discriminative spatial saliency of image while simultaneously learning a max margin classifier for a given visual classification task using the saliency map to weight the corresponding visual feature improves the discriminative power of the image representation we treat the saliency map a latent variable and allow them to adapt to the image content to maximize the classification score while regularizing the change in the saliency map our experimental result on three challenging datasets for i human action classification ii fine grained classification and iii scene classification demonstrate the effectiveness and wide applicability of the method 
in this paper we study the problem of social relational inference using visual concept which serve a indicator of actor social interaction while social network analysis from video ha started to gain attention in the recent year the existing work either us proximity or co occurrence statistic or exploit a holistic model of the scene content where the relation are assumed to stay constant throughout the video this work permit changing relation and argues that there exists a relationship between the visual concept and the social relation among actor which is a fundamentally new concept in computer vision specifically we leverage the existing large scale concept detector to generate concept score vector to represent the video content and we further map them to grouping cue that are used to detect the social structure in our framework a probabilistic graphical model with temporal smoothing provides a mean to analyze social relation among actor and detect community experiment on youtube video and theatrical movie validate the proposed framework 
this paper proposes a dictionary learning framework that combine the proposed block group bgsc or reconstructed block group r bgsc sparse coding scheme with the novel intra block coherence suppression dictionary learning algorithm an important and distinguishing feature of the proposed framework is that all dictionary block are trained simultaneously with respect to each data group while the intra block coherence being explicitly minimized a an important objective we provide both empirical evidence and heuristic support for this feature that can be considered a a direct consequence of incorporating both the group structure for the input data and the block structure for the dictionary in the learning process the optimization problem for both the dictionary learning and sparse coding can be solved efficiently using block gradient descent and the detail of the optimization algorithm are presented we evaluate the proposed method using well known datasets and favorable comparison with state of the art dictionary learning method demonstrate the viability and validity of the proposed framework 
the paper present a new online incremental zero shot learning method for application in robotics and mobile communication where attribute labeling is obtained via online interaction with user and where the potential for inconsistency exists unique to most previous offline batch learning method the proposed method is based on the indirect attribute prediction iap model instead of the direct attribute prediction dap using self organizing and incremental neural network soinn a the learning mechanism our method can learn new attribute and update existing attribute in an online incremental manner while retaining a high accuracy a that of the state of the art offline method compared to the offline method the computation time ha also been reduced by more than two experiment evaluated two aspect of the proposed method first our method clearly outperforms the previous iap based offline method in term of both time and accuracy and yield approximately the same accuracy a the dap based offline method second the proposed method can deal with situation where object attribute are gradually labeled via interaction with many user and where some of them may be incorrect this scenario is very important for application in mobile communication and robotics where some object and attribute may be initially unknown and must be learnt online 
we address the problem of contour detection bottom up grouping and semantic segmentation using rgb d data we focus on the challenging setting of cluttered indoor scene and evaluate our approach on the recently introduced nyu depth v nyud dataset we propose algorithm for object boundary detection and hierarchical segmentation that generalize the gpb ucm approach of by making effective use of depth information we show that our system can label each contour with it type depth normal or albedo we also propose a generic method for long range amodal completion of surface and show it effectiveness in grouping we then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixel into the dominant object category in nyud we use both generic and class specific feature to encode the appearance and geometry of object we also show how our approach can be used for scene classification and how this contextual information in turn improves object recognition in all of these task we report significant improvement over the state of the art 
we present a simple accurate and flexible method to calibrate intrinsic parameter of a camera together with possibly significant lens distortion this new method can work under a wide range of practical scenario using multiple image of a known pattern multiple image of an unknown pattern single or multiple image s of multiple pattern etc moreover this new method doe not rely on extracting any low level feature such a corner or edge it can tolerate considerably large lens distortion noise error illumination and viewpoint change and still obtain accurate estimation of the camera parameter the new method leverage on the recent breakthrough in powerful high dimensional convex optimization tool especially those for matrix rank minimization and sparse signal recovery we will show how the camera calibration problem can be formulated a an important extension to principal component pursuit and solved by similar technique we characterize to exactly what extent the parameter can be recovered in case of ambiguity we verify the efficacy and accuracy of the proposed algorithm with extensive experiment on real image 
most stereo correspondence algorithm match support window at integer valued disparity and assume a constant disparity value within the support window the recently proposed patch match stereo algorithm by bleyer et al overcomes this limitation of previous algorithm by directly estimating plane this work present a method that integrates the patch match stereo algorithm into a variational smoothing formulation using quadratic relaxation the resulting algorithm allows the explicit regularization of the disparity and normal gradient using the estimated plane parameter evaluation of our method in the middlebury benchmark show that our method outperforms the traditional integer valued disparity strategy a well a the original algorithm and it variant in sub pixel accurate disparity estimation 
in machine learning and computer vision input signal are often filtered to increase data discriminability for example preprocessing face image with gabor band pas filter is known to improve performance in expression recognition task sometimes however one may wish to purposely decrease discriminability of one classification task a distractor task while simultaneously preserving information relevant to another task the target task for example due to privacy concern it may be important to mask the identity of person contained in face image before submitting them to a crowdsourcing site e g mechanical turk when labeling them for certain facial attribute suppressing discriminability in distractor task may also be needed to improve inter dataset generalization training datasets may sometimes contain spurious correlation between a target attribute e g facial expression and a distractor attribute e g gender we might improve generalization to new datasets by suppressing the signal related to the distractor task in the training dataset this can be seen a a special form of supervised regularization in this paper we present an approach to automatically learning preprocessing filter that suppress discriminability in distractor task while preserving it in target task we present promising result in simulated image classification problem and in a realistic expression recognition problem 
it ha recently been shown that only a small number of sample from a low rank matrix are necessary to reconstruct the entire matrix we bring this to bear on computer vision problem that utilize low dimensional subspace demonstrating that subsampling can improve computation speed while still allowing for accurate subspace learning we present grasta grassmannian robust adaptive subspace tracking algorithm an online algorithm for robust subspace estimation from randomly subsampled data we consider the specific application of background and foreground separation in video and we ass grasta on separation accuracy and computation time in one benchmark video example grasta achieves a separation rate of frame per second even when run in matlab on a personal laptop 
visual reranking ha become a widely accepted method to improve traditional text based image search result the main principle is to exploit the visual aggregation property of relevant image among top result so a to boost ranking score of relevant image by explicitly or implicitly detecting the confident relevant image and propagating ranking score among visually similar image however such a visual aggregation property doe not always hold and thus these scheme may fail in this paper we instead propose to filter out the most probable irrelevant image using deep context which is the extra information that is not limited in the current search result the deep context for each image consist of set of image that are returned by search using the query formed by the textual context of this image we compare the popularity of this image in the current search result and the deep context to check the irrelevance score then the irrelevance score are propagated to the image whose useful textual context is missed we formulate the two scheme together to reach a markov random field which is effectively solved by graph cut the key is that our scheme doe not rely on the assumption that relevant image are visually aggregated among top result and is based on the observation that an outlier under the current query is likely to be more popular under some other query after that we perform graph reranking over filtered result to reorder them experimental result on the inria dataset show that our proposed method achieves significant improvement over previous approach 
we propose an adaptive sub gradient descent method to efficiently learn the parameter of crf model for image parsing to balance the learning efficiency and performance of the learned crf model the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling a solution of sub gradient descent updating form is derived for the convex optimization problem with an adaptively determined updating step size besides to deal with partially labeled training data we propose a new objective constraint modeling both the labeled and unlabeled part in the partially labeled training data for the parameter learning of crf model the superior learning efficiency of the proposed method is verified by the experiment result on two public datasets we also demonstrate the powerfulness of our method for handling partially labeled training data 
motion can occur over both short and long time scale we introduce motion denoising which treat short term change a noise long term change a signal and re render a video to reveal the underlying long term event we demonstrate motion denoising for time lapse video one of the characteristic of traditional time lapse imagery is stylized jerkiness where short term change in the scene appear a small and annoying jitter in the video often obfuscating the underlying temporal event of interest we apply motion denoising for resynthesizing time lapse video showing the long term evolution of a scene with jerky short term change removed we show that existing filtering approach are often incapable of achieving this task and present a novel computational approach to denoise motion without explicit motion analysis we demonstrate promising experimental result on a set of challenging time lapse sequence 
in this paper rather than modeling activity in video individually we propose a hierarchical framework that jointly model and recognizes related activity using motion and various context feature this is motivated from the observation that the activity related in space and time rarely occur independently and can serve a the context for each other given a video action segment are automatically detected using motion segmentation based on a nonlinear dynamical model we aim to merge these segment into activity of interest and generate optimum label for the activity towards this goal we utilize a structural model in a max margin framework that jointly model the underlying activity which are related in space and time the model explicitly learns the duration motion and context pattern for each activity class a well a the spatio temporal relationship for group of them the learned model is then used to optimally label the activity in the testing video using a greedy search method we show promising result on the virat ground dataset demonstrating the benefit of joint modeling and recognizing activity in a wide area scene 
this paper introduces a novel solution to hand eye calibration problem it is the first method that us camera measurement directly and at the same time requires neither prior knowledge of the external camera calibration nor a known calibration device our algorithm us branch and bound approach to minimize an objective function based on the epipolar constraint further it employ linear programming to decide the bounding step of the algorithm the presented technique is able to recover both the unknown rotation and translation simultaneously and the solution is guaranteed to be globally optimal with respect to the l norm 
this paper introduces a hybrid two stage approach to semantic image segmentation in the first stage a probabilistic model generates a set of diverse plausible segmentation in the second stage a discriminatively trained re ranking model selects the best segmentation from this set the re ranking stage can use much more complex feature than what could be tractably used in the probabilistic model allowing a better exploration of the solution space than possible by simply producing the most probable solution from the probabilistic model while our proposed approach already achieves state of the art result on the challenging voc dataset our machine and human analysis suggest that even larger gain are possible with such an approach 
in this paper a new mixture model of dynamic pedestrian agent mda is proposed to learn the collective behavior pattern of pedestrian in crowded scene collective behavior characterize the intrinsic dynamic of the crowd from the agent based modeling each pedestrian in the crowd is driven by a dynamic pedestrian agent which is a linear dynamic system with it initial and termination state reflecting a pedestrian s belief of the starting point and the destination then the whole crowd is modeled a a mixture of dynamic pedestrian agent once the model is unsupervisedly learned from real data mda can simulate the crowd behavior furthermore mda can well infer the past behavior and predict the future behavior of pedestrian given their trajectory only partially observed and classify different pedestrian behavior in the scene the effectiveness of mda and it application are demonstrated by qualitative and quantitative experiment on the video surveillance dataset collected from the new york grand central station 
this paper considers the problem of sustained multicamera tracking in the presence of occlusion and change in the target motion model the key insight of the proposed method is the fact that under mild condition the d trajectory of the target in the image plane of each of the camera are constrained to evolve in the same subspace this observation allows for identifying at each time instant a single piecewise linear model that explains all the available d measurement in turn this model can be used in the context of a modified particle filter to predict future target location in the case where the target is occluded to some of the camera the missing measurement can be estimated using the fact that they must lie both in the subspace spanned by previous measurement and satisfy epipolar constraint hence by exploiting both dynamical and geometrical constraint the proposed method can robustly handle substantial occlusion without the need for performing d reconstruction calibrated camera or constraint on sensor separation the performance of the proposed tracker is illustrated with several challenging example involving target that substantially change appearance and motion model while occluded to some of the camera 
in this paper we introduce structured local predictor slp a new formulation that considers the image labelling problem from a structured learning point of view slp are locally operating model which provide a per pixel labelling by exploiting contextual relation learned from complex interaction between label and a customizable intermediate representation of the image data our first key contribution is to handle flexible configuration of pairwise interaction between image pixel while allowing them to be made arbitrarily dependent on the image data moreover we pose the parameter learning process a a convex structured learning problem which can be efficiently solved in a globally optimal way due to the introduction of a continuous structured output space finally we provide an interface to our model by mean of a quantization space allowing to define task specific intermediate representation for the input data in our experiment we demonstrate the broad applicability of our model for task like inpainting and semantic labelling 
scale invariant feature transform sift ha been well studied in recent year most related research effort focused on designing and learning effective descriptor to characterize a local interest point however how to identify stable local interest point is still a very challenging problem in this paper we propose a set of differential feature and based on them we adopt a data driven approach to learn a ranking function to sort local interest point according to their stability across image containing the same visual object compared with the handcrafted rule based method used by the standard sift algorithm our algorithm substantially improves the stability of detected local interest point on a very challenging benchmark dataset in which image were generated under very different imaging condition experimental result on the oxford and pascal database further demonstrate the superior performance of the proposed algorithm on both object image retrieval and category recognition 
in this paper a novel approach is developed to achieve automatic image collection summarization the effectiveness of the summary is reflected by it ability to reconstruct the original set or each individual image in the set we have leveraged the dictionary learning for sparse representation model to construct the summary and to represent the image specifically we reformulate the summarization problem into a dictionary learning problem by selecting base which can be sparsely combined to represent the original image and achieve a minimum global reconstruction error such a mse mean square error the resulting sparse least square problem is np hard thus a simulated annealing algorithm is adopted to learn such dictionary or image summary by minimizing the proposed optimization function a quantitative measurement is defined for assessing the quality of the image summary by investigating both it reconstruction ability and it representativeness of the original image set in large size we have also compared the performance of our image summarization approach with that of six other baseline summarization tool on multiple image set imagenet nu wide scene and event image set our experimental result have shown that the proposed dictionary learning approach can obtain more accurate result a compared with other six baseline summarization algorithm elsevier ltd 
we introduce the novel continuous regularizer total curvature tc for image math it is defined a the menger melnikov curvature of the radon measure du which can be understood a a measure theoretic formulation of curvature mathematically related to mean curvature the functional is not convex therefore we define a convex relaxation which yield a close approximation similar to the total variation the relaxation can be written a the support functional of a convex set which mean that there are stable and efficient minimization algorithm available when it is used a a regularizer in image processing problem our current implementation can handle general inverse problem inpainting and segmentation we demonstrate in experiment and comparison how the regularizer performs in practice 
people detection is an important task for a wide range of application in computer vision state of the art method learn appearance based model requiring tedious collection and annotation of large data corpus also obtaining data set representing all relevant variation with sufficient accuracy for the intended application domain at hand is often a non trivial task therefore this paper investigates how d shape model from computer graphic can be leveraged to ease training data generation in particular we employ a rendering based reshaping method in order to generate thousand of synthetic training sample from only a few person and view we evaluate our data generation method for two different people detection model our experiment on a challenging multi view dataset indicate that the data from a few a eleven person suffices to achieve good performance when we additionally combine our synthetic training sample with real data we even outperform existing state of the art method 
we show how to build large dictionary of meaningful image fragment these fragment could represent object object in a local context or part of scene our fragment operate a region based exemplar and we show how they can be used for image classification to localize object and to compose new image while each of these activity ha been demonstrated before each ha required manually extracted fragment because our method for fragment extraction is automatic it can operate at a large scale our method us recent advance in generic object detection technique together with discriminative test to obtain good clean fragment set with extensive diversity our fragment are organized by the tag of the source image to build a semantically organized fragment table a good set of fragment exemplar describes only the object rather than object context context could help identify an object but it could also contribute noise because other object might appear in the same context we show a slight improvement in classification performance by two standard exemplar matching method using our fragment dictionary over such method using image exemplar this suggests that knowing the support of an exemplar is valuable furthermore we demonstrate our automatically built fragment dictionary is capable of good localization finally our fragment dictionary support a keyword based fragment search system which allows artist to get the fragment they need to make image collage 
we present a preconditioning scheme for improving the efficiency of optimization of arbitrary difference measure in deformable registration problem this is of particular interest for high dimensional registration problem with statistical difference measure such a mi and the demon method since in these case the range of applicable optimization method is limited the proposed scheme is simple and computationally efficient it performs an approximate normalization of the point wise vector of the difference gradient to unit length the major contribution of this work is a theoretical analysis which demonstrates the improvement of the condition by our approach which is furthermore shown to be an approximation to the optimal case for the analyzed model our scheme improves the convergence speed while adding only negligible computational cost thus resulting in shorter effective runtimes the theoretical finding are confirmed by experiment on d brain data 
layered model allow scene segmentation and motion estimation to be formulated together and to inform one another traditional layered motion method however employ fairly weak model of scene structure relying on locally connected ising potts model which have limited ability to capture long range correlation in natural scene to address this we formulate a fully connected layered model that enables global reasoning about the complicated segmentation of real object optimization with fully connected graphical model is challenging and our inference algorithm leverage recent work on efficient mean field update for fully connected conditional random field these method can be implemented efficiently using high dimensional gaussian filtering we combine these idea with a layered flow model and find that the long range connection greatly improve segmentation into figure ground layer when compared with locally connected mrf model experiment on several benchmark datasets show that the method can recover fine structure and large occlusion region with good flow accuracy and much lower computational cost than previous locally connected layered model 
in this paper we propose a discriminative low rank dictionary learning algorithm for sparse representation sparse representation seek the sparsest coefficient to represent the test signal a linear combination of the base in an over complete dictionary motivated by low rank matrix recovery and completion assume that the data from the same pattern are linearly correlated if we stack these data point a column vector of a dictionary then the dictionary should be approximately low rank an objective function with sparse coefficient class discrimination and rank minimization is proposed and optimized during dictionary learning we have applied the algorithm for face recognition numerous experiment with improved performance over previous dictionary learning method validate the effectiveness of the proposed algorithm 
d face recognition in the presence of large pose variation present a significant challenge when comparing a frontal image of a face to a near profile image one must cope with large occlusion non linear correspondence and significant change in appearance due to viewpoint stereo matching ha been used to handle these problem but performance of this approach degrades with large pose change we show that some of this difficulty is due to the effect that foreshortening of slanted surface ha on window based matching method which are needed to provide robustness to lighting change we address this problem by designing a new dynamic programming stereo algorithm that account for surface slant we show that on the cmu pie dataset this method result in significant improvement in recognition performance 
we present a video summarization approach for egocentric or wearable camera data given hour of video the proposed method produce a compact storyboard summary of the camera wearer s day in contrast to traditional keyframe selection technique the resulting summary focus on the most important object and people with which the camera wearer interacts to accomplish this we develop region cue indicative of high level saliency in egocentric video such a the nearness to hand gaze and frequency of occurrence and learn a regressor to predict the relative importance of any new region based on these cue using these prediction and a simple form of temporal event detection our method selects frame for the storyboard that reflect the key object driven happening critically the approach is neither camera wearer specific nor object specific that mean the learned importance metric need not be trained for a given user or context and it can predict the importance of object and people that have never been seen previously our result with hour of egocentric data show the method s promise relative to existing technique for saliency and summarization 
in this work we address the problem of multi class classification problem in semi supervised setting a regularized multi task learning approach is presented to train multiple binary class semi supervised support vector machine s vms using the one v rest strategy within a joint framework a novel type of regularization namely positiveness exclusive regularization per is introduced to induce the following prior if an unlabeled sample receives significant positive response from one of the classifier it is le likely for this sample to receive positive response from the other classifier that is we expect an exclusive relationship among different s vms for evaluating the same unlabeled sample we propose to use an norm regularizer a an implementation of per the objective of our approach is to minimize an empirical risk regularized by a per term and a manifold regularization term an efficient nesterov type smoothing approximation based method is developed for optimization evaluation with comparison are conducted on several benchmark for visual classification to demonstrate the advantage of the proposed method 
recurrence of small clean image patch across different scale of a natural image ha been successfully used for solving ill posed problem in clean image e g super resolution from a single image in this paper we show how this multi scale property can be extended to solve ill posed problem under noisy condition such a image denoising while clean patch are obscured by severe noise in the original scale of a noisy image noise level drop dramatically at coarser image scale this allows for the unknown hidden clean patch to naturally emerge in some coarser scale of the noisy image we further show that patch recurrence across scale is strengthened when using directional pyramid that blur and sub sample only in one direction our statistical experiment show that for almost any noisy image patch more than there exists a good clean version of itself at the same relative image coordinate in some coarser scale of the image this is a strong phenomenon of noise contaminated natural image which can serve a a strong prior for separating the signal from the noise finally incorporating this multi scale prior into a simple denoising algorithm yield state of the art denoising result 
recovering d geometry from a single view of an object is an important and challenging problem in computer vision previous method mainly focus on one specific class of object without large topological change such a car face or human body in this paper we propose a novel single view reconstruction algorithm for symmetric piece wise planar object that are not restricted to some object class symmetry is ubiquitous in manmade and natural object and provides rich information for d reconstruction given a single view of a symmetric piecewise planar object we first find out all the symmetric line pair the geometric property of symmetric object are used to narrow down the searching space then based on the symmetric line a depth map is recovered through a markov random field experimental result show that our algorithm can efficiently recover the d shape of different object with significant topological variation 
most existing bottom up method measure the foreground saliency of a pixel or region based on it contrast within a local context or the entire image whereas a few method focus on segmenting out background region and thereby salient object instead of considering the contrast between the salient object and their surrounding region we consider both foreground and background cue in a different way we rank the similarity of the image element pixel or region with foreground cue or background cue via graph based manifold ranking the saliency of the image element is defined based on their relevance to the given seed or query we represent the image a a close loop graph with super pixel a node these node are ranked based on the similarity to background and foreground query based on affinity matrix saliency detection is carried out in a two stage scheme to extract background region and foreground salient object efficiently experimental result on two large benchmark database demonstrate the proposed method performs well when against the state of the art method in term of accuracy and speed we also create a more difficult benchmark database containing image to test the proposed saliency model and make this database publicly available with this paper for further study in the saliency field 
in this paper we address the problem of robust and efficient averaging of relative d rotation apart from having an interesting geometric structure robust rotation averaging address the need for a good initialization for large scale optimization used in structure from motion pipeline such pipeline often use unstructured image datasets harvested from the internet thereby requiring an initialization method that is robust to outlier our approach work on the lie group structure of d rotation and solves the problem of large scale robust rotation averaging in two way firstly we use modern l optimizers to carry out robust averaging of relative rotation that is efficient scalable and robust to outlier in addition we also develop a two step method that us the l solution a an initialisation for an iteratively reweighted least square irls approach these method achieve excellent result on large scale real world datasets and significantly outperform existing method i e the state of the art discrete continuous optimization method of a well a the weiszfeld method of we demonstrate the efficacy of our method on two large scale real world datasets and also provide the result of the two aforementioned method for comparison 
variation in viewpoint pose significant challenge to action recognition one popular way of encoding view invariant action representation is based on the exploitation of epipolar geometry between different view of the same action majority of representative work considers detection of landmark point and their tracking by assuming that motion trajectory for all landmark point on human body are available throughout the course of an action unfortunately due to occlusion and noise detection and tracking of these landmark is not always robust to facilitate it some of the work assumes that such trajectory are manually marked which is a clear drawback and lack automation introduced by computer vision in this paper we address this problem by proposing view invariant action matching score based on epipolar geometry between actor silhouette without tracking and explicit point correspondence in addition we explore multi body epipolar constraint which facilitates to work on original action volume without any pre processing we show that multi body fundamental matrix capture the geometry of dynamic action scene and help devising an action matching score across different view without any prior segmentation of actor extensive experimentation on challenging view invariant action datasets show that our approach not only remove long standing assumption but also achieves significant improvement in recognition accuracy and retrieval 
we present a data driven method for building dense d reconstruction using a combination of recognition and multi view cue our approach is based on the idea that there are image patch that are so distinctive that we can accurately estimate their latent d shape solely using recognition we call these patch shape anchor and we use them a the basis of a multi view reconstruction system that transfer dense complex geometry between scene we anchor our d interpretation from these patch using them to predict geometry for part of the scene that are relatively ambiguous the resulting algorithm produce dense reconstruction from stereo point cloud that are sparse and noisy and we demonstrate it on a challenging dataset of real world indoor scene 
diffuse object generally tell u little about the surrounding lighting since the radiance they reflect blur together incident lighting from many direction in this paper we discus how occlusion geometry can help invert diffuse reflectance to recover lighting or surface albedo self occlusion in the scene can be regarded a a form of coding creating high frequency that improve the conditioning of diffuse light transport our analysis build on a basic observation that diffuse reflector with sufficiently detailed geometry can fully resolve the incident lighting using a bayesian framework we propose a novel reconstruction method based on high resolution photography taking advantage of visibility change near occlusion boundary we also explore the limit of single pixel observation a the diffuse reflector and potentially the lighting vary over time diffuse reflectance imaging is particularly relevant for astronomy application where diffuse reflector arise naturally but the incident lighting and camera position cannot be controlled to test our approach we first study the feasibility of using the moon a a diffuse reflector to observe the earth a seen from space next we present a reconstruction of mar using historical photometry measurement not previously used for this purpose a our result suggest diffuse reflectance imaging expands our notion of what can qualify a a camera 
we propose a method to learn a diverse collection of discriminative part from object bounding box annotation part detector can be trained and applied individually which simplifies learning and extension to new feature or category we apply the part to object category detection pooling part detection within bottom up proposed region and using a boosted classifier with proposed sigmoid weak learner for scoring on pascal voc we evaluate the part detector ability to discriminate and localize annotated key point our detection system is competitive with the best existing system outperforming other hog based detector on the more deformable category 
this paper address recognition of human activity with stochastic structure characterized by variable space time arrangement of primitive action and conducted by a variable number of actor our approach classifies the activity of interest a well a identifies the relevant foreground in the video each activity representation is considered a a mixture distribution of bow captured by a sum product network spn in our approach spn represents a linear mixture of many bag of word bow where each bow represents an important foreground part of the activity this mixture distribution is efficiently computed by organizing the bow in a hierarchy where child bow are nested within parent bow spn allows u to model this mixture since it consists of terminal node representing bow product node and sum node organized in a number of layer the product are aimed at encoding particular configuration of primitive action and the sum serve to capture their alternative configuration spn inference amount to parsing the spn graph which yield the most probable explanation mpe of the video foreground spn inference ha linear complexity in the number of node under fairly general condition enabling fast and scalable recognition the connectivity of spn and the parameter of bow distribution are learned under weak supervision using a variational em algorithm for our evaluation we have compiled and annotated a new volleyball dataset our classification accuracy and localization result are superior to those of the state of the art on current benchmark a well a our volleyball datasets 
compressive sensing ha become one of the standard method of face recognition within the literature we show however that the sparsity assumption which underpins much of this work is not supported by the data this lack of sparsity in the data mean that compressive sensing approach cannot be guaranteed to recover the exact signal and therefore that sparse approximation may not deliver the robustness or performance desired in this vein we show that a simple approach to the face recognition problem is not only significantly more accurate than the state of the art approach it is also more robust and much faster these result are demonstrated on the publicly available yaleb and ar face datasets but have implication for the application of compressive sensing more broadly 
interpreting an image a a function on a compact subset of the euclidean plane we get it scale space by diffusion spreading the image over the entire plane this generates a parameter family of function alternatively defined a convolution with a progressively wider gaussian kernel we prove that the corresponding parameter family of persistence diagram have norm that go rapidly to zero a time go to infinity this result rationalizes experimental observation about scale space we hope this will lead to targeted improvement of related computer vision method 
in the past decade the bag of feature model ha established itself a the state of the art method in various visual classification task despite it simplicity and high performance it normally work a a black box and the classification rule is not transparent to user however to better understand the classification process it is favorable to look into the black box to see how an image is recognized to fill this gap we developed a tool called restricted support region set rsrs detection which can be utilized to visualize the image region that are critical to the classification decision more specifically we define the restricted support region set for a given image a such a set of size restricted and non overlapped region that if any one of them is removed the image will be wrongly classified focusing on the state of the art bag of feature classification system we developed an efficient rsrs detection algorithm and discussed it application we showed that it can be used to identify the limitation of a classifier predict it failure mode discover the classification rule and reveal the database bias moreover a experimentally demonstrated this tool also enables common user to efficiently tune the classifier by removing the inappropriate support region which can lead to a better generalization performance 
recently there ha been an increasing interest in the investigation of statistical pattern recognition model for the fully automatic segmentation of the left ventricle lv of the heart from ultrasound data the main vulnerability of these model resides in the need of large manually annotated training set for the parameter estimation procedure the issue is that these training set need to be annotated by clinician which make this training set acquisition process quite expensive therefore reducing the dependence on large training set is important for a more extensive exploration of statistical model in the lv segmentation problem in this paper we present a novel incremental on line semi supervised learning model that reduces the need of large training set for estimating the parameter of statistical model compared to other semi supervised technique our method yield an on line incremental re training and segmentation instead of the off line incremental re training and segmentation more commonly found in the literature another innovation of our approach is that we use a statistical model based on deep learning architecture which are easily adapted to this on line incremental learning framework we show that our fully automatic lv segmentation method achieves state of the art accuracy with training set containing le than twenty annotated image 
in this paper we automatically ass the aesthetic property of image in the past this problem ha been addressed by hand crafting feature which would correlate with best photographic practice e g doe this image respect the rule of third or with photographic technique e g is this image a macro we depart from this line of research and propose to use generic image descriptor to ass aesthetic quality we experimentally show that the descriptor we use which aggregate statistic computed from low level local feature implicitly encode the aesthetic property explicitly used by state of the art method and outperform them by a significant margin 
recent work on unsupervised feature learning ha shown that learning on polynomial expansion of input patch such a on pair wise product of pixel intensity can improve the performance of feature learner and extend their applicability to spatio temporal problem such a human action recognition or learning of image transformation learning of such higher order feature however ha been much more difficult than standard dictionary learning because of the high dimensionality and because standard learning criterion are not applicable here we show how one can cast the problem of learning higher order feature a the problem of learning a parametric family of manifold this allows u to apply a variant of a de noising autoencoder network to learn higher order feature using simple gradient based optimization our experiment show that the approach can outperform existing higher order model while training and inference are exact fast and simple 
shape decomposition is a fundamental problem for part based shape representation we propose a novel shape decomposition method called minimum near convex decomposition mncd which decomposes d and d arbitrary shape into minimum number of near convex part with the degree of near convexity a user specified parameter our decomposition is robust to large local distortion and shape deformation the shape decomposition is formulated a a combinatorial optimization problem by minimizing the number of non intersection cut two major perception rule are also imposed into our scheme to improve the visual naturalness of the decomposition the global optimal solution of this challenging discrete optimization problem is obtained by a dynamic subgradient based branch and bound search both theoretical analysis and experiment result show that our approach outperforms the state of the art result without introducing redundant part finally we also show the superiority of our method in the application of hand gesture recognition 
in this paper we present a method of detecting translation symmetry from a fronto parallel image the proposed method automatically detects unknown multiple repetitive pattern of arbitrary shape which are characterized by translation symmetry on a plane the central idea of our approach is to take advantage of the interesting property of translation symmetry in both image space and the space of transformation group we first detect feature point in input image a sampling point then for each sampling point we search for the most probable corresponding lattice structure in the image and transform space using scale space similarity map finally using a mrf formulation we optimally partition the graph of all sampling point associated with the estimated lattice into subgraphs of sampling point and lattice belonging to the same symmetry pattern our method is robust because of the joint analysis in image and transform space and the mrf optimization we demonstrate the robustness and effectiveness of our method on a large variety of image 
we propose a new approach for estimation of the position of facial key point with three level carefully designed convolutional network at each level the output of multiple network are fused for robust and accurate estimation thanks to the deep structure of convolutional network global high level feature are extracted over the whole face region at the initialization stage which help to locate high accuracy key point there are two fold of advantage for this first the texture context information over the entire face is utilized to locate each key point second since the network are trained to predict all the key point simultaneously the geometric constraint among key point are implicitly encoded the method therefore can avoid local minimum caused by ambiguity and data corruption in difficult image sample due to occlusion large pose variation and extreme lighting the network at the following two level are trained to locally refine initial prediction and their input are limited to small region around the initial prediction several network structure critical for accurate and robust facial point detection are investigated extensive experiment show that our approach outperforms state of the art method in both detection accuracy and reliability 
we present a novel formulation of fully corrective boosting for multi class classification problem with the awareness of sharing feature our multi class boosting is solved in a single optimization problem in order to share feature across different class we introduce the mixed norm regularization which promotes group sparsity into boosting we then derive the lagrange dual problem which enable u to design fully corrective multi class algorithm using the primal dual optimization technique we show that sharing feature across class can improve classification performance and efficiency we empirically show that in many case the proposed multi class boosting generalizes better than a range of competing multi class boosting algorithm due to the capability of feature sharing experimental result on machine learning data visual scene and object recognition demonstrate the efficiency and effectiveness of proposed algorithm and validate our theoretical finding 
low rank representation lrr is an effective method for exploring the multiple subspace structure of data usually the observed data matrix itself is chosen a the dictionary which is a key aspect of lrr however such a strategy may depress the performance especially when the observation are insufficient and or grossly corrupted in this paper we therefore propose to construct the dictionary by using both observed and unobserved hidden data we show that the effect of the hidden data can be approximately recovered by solving a nuclear norm minimization problem which is convex and can be solved efficiently the formulation of the proposed method called latent low rank representation latlrr seamlessly integrates subspace segmentation and feature extraction into a unified framework and thus provides u with a solution for both subspace segmentation and feature extraction a a subspace segmentation algorithm latlrr is an enhanced version of lrr and outperforms the state of the art algorithm being an unsupervised feature extraction algorithm latlrr is able to robustly extract salient feature from corrupted data and thus can work much better than the benchmark that utilizes the original data vector a feature for classification compared to dimension reduction based method latlrr is more robust to noise 
cascaded classifier have been widely used in pedestrian detection and achieved great success these classifier are trained sequentially without joint optimization in this paper we propose a new deep model that can jointly train multi stage classifier through several stage of back propagation it keep the score map output by a classifier within a local region and us it a contextual information to support the decision at the next stage through a specific design of the training strategy this deep architecture is able to simulate the cascaded classifier by mining hard sample to train the network stage by stage each classifier handle sample at a different difficulty level unsupervised pre training and specifically designed stage wise supervised training are used to regularize the optimization problem both theoretical analysis and experimental result show that the training strategy help to avoid over fitting experimental result on three datasets caltech eth and tud brussels show that our approach outperforms the state of the art approach 
small sample size is one of the most challenging problem in face recognition due to the difficulty of sample collection in many real world application by representing the query sample a a linear combination of training sample from all class the so called collaborative representation based classification crc show very effective face recognition performance with low computational cost however the recognition rate of crc will drop dramatically when the available training sample per subject are very limited one intuitive solution to this problem is operating crc on patch and combining the recognition output of all patch nonetheless the setting of patch size is a non trivial task considering the fact that patch on different scale can have complementary information for classification we propose a multi scale patch based crc method while the ensemble of multi scale output is achieved by regularized margin distribution optimization our extensive experiment validated that the proposed method outperforms many state of the art patch based face recognition algorithm 
this paper investigates an approach for generating two grating image so that the moire pattern of their superposition resembles the target image our method is grounded on the fundamental moire theorem by focusing on the visually most dominant moire component we obtain the phase modulation constraint on the phase shift between the two grating image for improving visual appearance of the grating image and hiding capability the embedded image a smoothness term is added to spread information between the two grating image and an appearance phase function is used to add irregular structure into grating image the grating image can be printed on transparency and the hidden image decoding can be performed optically by overlaying them together the proposed method enables the creation of moire art and allows visual decoding without computer 
in visual recognition task the design of low level image feature representation is fundamental the advent of local patch feature from pixel attribute such a sift and lbp ha precipitated dramatic progress recently a kernel view of these feature called kernel descriptor kdes generalizes the feature design in an unsupervised fashion and yield impressive result in this paper we present a supervised framework to embed the image level label information into the design of patch level kernel descriptor which we call supervised kernel descriptor skdes specifically we adopt the broadly applied bag of word bow image classification pipeline and a large margin criterion to learn the low level patch representation which make the patch feature much more compact and achieve better discriminative ability than kdes with this method we achieve competitive result over several public datasets comparing with state of the art method 
conventional non blind image deblurring algorithm involve natural image prior and maximum a posteriori map estimation a a consequence of map estimation separate pre processing step such a noise estimation and training of the regularization parameter are necessary to avoid user interaction moreover map estimate involving standard natural image prior have been found lacking in term of restoration performance to address these issue we introduce an integrated bayesian framework that unifies non blind deblurring and noise estimation thus freeing the user of tediously pre determining a noise level a sampling based technique allows to integrate out the unknown noise level and to perform deblurring using the bayesian minimum mean squared error estimate mmse which requires no regularization parameter and yield higher performance than map estimate when combined with a learned high order image prior a quantitative evaluation demonstrates state of the art result for both non blind deblurring and noise estimation 
we study in this paper the problem of learning classifier from ambiguously labeled image for instance in the collection of new image each image contains some sample of interest emph e g human face and it associated caption ha label with the true one included while the sample label association is unknown the task is to learn classifier from these ambiguously labeled image and generalize to new image an essential consideration here is how to make use of the information embedded in the relation between sample and label both within each image and across the image set to this end we propose a novel framework to address this problem our framework is motivated by the observation that sample from the same class repetitively appear in the collection of ambiguously labeled training image while they are just ambiguously labeled in each image if we can identify sample of the same class from each image and associate them across the image set the matrix formed by the sample from the same class would be ideally low rank by leveraging such a low rank assumption we can simultaneously optimize a partial permutation matrix ppm for each image which is formulated in order to exploit all information between sample and label in a principled way the obtained ppms can be readily used to assign label to sample in training image and then a standard svm classifier can be trained and used for unseen data experiment on benchmark datasets show the effectiveness of our proposed method 
in this work we address the problem of estimating d human pose from still image recent method that rely on discriminatively trained deformable part organized in a tree model have shown to be very successful in solving this task within such a pictorial structure framework we address the problem of obtaining good part template by proposing novel non linear joint regressors in particular we employ two layered random forest a joint regressors the first layer act a a discriminative independent body part classifier the second layer take the estimated class distribution of the first one into account and is thereby able to predict joint location by modeling the interdependence and co occurrence of the part this result in a pose estimation framework that take dependency between body part already for joint localization into account and is thus able to circumvent typical ambiguity of tree structure such a for leg and arm in the experiment we demonstrate that our body part dependent joint regressors achieve a higher joint localization accuracy than tree based state of the art method 
compressive sampling c aim at acquiring a signal at a sampling rate that is significantly below the nyquist rate it main idea is that a signal can be decoded from incomplete linear measurement by seeking it sparsity in some domain despite the remarkable progress in the theory of c little headway ha been made in the compressive imaging ci camera in this paper a three dimensional compressive sampling dc approach is proposed to reduce the required sampling rate of the ci camera to a practical level in dc a generic three dimensional sparsity measure dsm is presented which decodes a video from incomplete sample by exploiting it d piecewise smoothness and temporal low rank property in addition an efficient decoding algorithm is developed for this dsm with guaranteed convergence the experimental result show that our dc requires a much lower sampling rate than the existing c method without compromising recovery accuracy 
we present a study of radiometric calibration and the in camera imaging process through an extensive analysis of more than image from over camera the goal is to investigate if image value can be transformed to physically meaningful value and if so when and how this can be done from our analysis we show that the conventional radiometric model fit well for image pixel with low color saturation but begin to degrade a color saturation level increase this is due to the color mapping process which includes gamut mapping in the in camera processing that cannot be modeled with conventional method to this end we introduce a new imaging model for radiometric calibration and present an effective calibration scheme that allows u to compensate for the nonlinear color correction to convert non linear srgb image to ccd raw response 
a popular approach to pixel labeling problem such a multiclass image segmentation is to construct a pairwise conditional markov random field crf over image pixel where the pairwise term encodes a preference for smoothness within local connected or connected pixel neighborhood recently researcher have considered higherorder model that encode soft non local constraint e g label consistency connectedness or co occurrence statistic these new model and the associated energy minimization algorithm have significantly pushed the state of the art for pixel labeling problem in this paper we consider a new non local constraint that penalizes inconsistent pixel label between disjoint image region having similar appearance we encode this constraint a a truncated higher order matching potential function between pair of image region in a conditional markov random field model and show how to perform efficient approximate map inference in the model we experimentally demonstrate quantitative and qualitative improvement over a strong baseline pairwise conditional markov random field model on two challenging multiclass pixel labeling datasets 
this paper address the problem of learning over complete dictionary for the coupled feature space where the learned dictionary also reflect the relationship between the two space a bayesian method using a beta process prior is applied to learn the over complete dictionary compared to previous couple feature space dictionary learning algorithm our algorithm not only provides dictionary that customized to each feature space but also add more consistent and accurate mapping between the two feature space this is due to the unique property of the beta process model that the sparse representation can be decomposed to value and dictionary atom indicator the proposed algorithm is able to learn sparse representation that correspond to the same dictionary atom with the same sparsity but different value in coupled feature space thus bringing consistent and accurate mapping between coupled feature space another advantage of the proposed method is that the number of dictionary atom and their relative importance may be inferred non parametrically we compare the proposed approach to several state of the art dictionary learning method by applying this method to single image super resolution the experimental result show that dictionary learned by our method produce the best super resolution result compared to other state of the art method 
we propose a novel parametrization of the data association problem for multi target tracking in our formulation the number of target is implicitly inferred together with the data association effectively solving data association and model selection a a single inference problem the novel formulation allows u to interpret data association and tracking a a single switching linear dynamical system slds we compute an approximate posterior solution to this problem using a dynamic programming message passing technique this inference based approach allows u to incorporate richer probabilistic model into the tracking system in particular we incorporate inference over inliers outlier and track termination time into the system we evaluate our approach on publicly available datasets and demonstrate result competitive with and in some case exceeding the state of the art 
previous work on action recognition ha focused on adapting hand designed local feature such a sift or hog from static image to the video domain in this paper we propose using unsupervised feature learning a a way to learn feature directly from video data more specifically we present an extension of the independent subspace analysis algorithm to learn invariant spatio temporal feature from unlabeled video data we discovered that despite it simplicity this method performs surprisingly well when combined with deep learning technique such a stacking and convolution to learn hierarchical representation by replacing hand designed feature with our learned feature we achieve classification result superior to all previous published result on the hollywood ucf kth and youtube action recognition datasets on the challenging hollywood and youtube action datasets we obtain and respectively which are approximately better than the current best published result further benefit of this method such a the ease of training and the efficiency of training and prediction will also be discussed you can download our code and learned spatio temporal feature here http ai stanford edu wzou 
in geometric computer vision the structure from motion sfm problem can be formulated a a optimization problem with a rank constraint it is well known that the trace norm of a matrix can act a a convex proxy for a low rank constraint hence in recent work the trace norm relaxation ha been applied to the sfm problem however sfm problem often exhibit a certain structure for example a smooth camera path unfortunately the trace norm relaxation can not make use of this additional structure this observation motivates the main contribution of this paper we present the so called generalized trace norm which allows to encode prior knowledge about a specific problem into a convex regularization term which enforces a low rank solution while at the same time taking the problem structure into account while deriving the generalized trace norm and stating it different formulation we draw interesting connection to other field most importantly to the field of compressive sensing even though the generalized trace norm is a very general concept with a wide area of potential application we are ultimately interested in applying it to sfm problem therefore we also present an efficient algorithm to optimize the resulting generalized trace norm regularized optimization problem result show that the generalized trace norm indeed achieves it goal in providing a problem dependent regularization 
in this paper we propose novel algorithm for inpainting and refinement of diffeomorphisms we first represent a diffeomorphism by it beltrami coefficient then it is possible to refine and inpaint the diffeomorphism by processing this beltrami coefficient with the inpainted refined beltrami coefficient we construct a new diffeomorphism using the exact beltrami holomorphic flow algorithm proposed in this paper we apply our algorithm on several practical application which include the inpainting of a highly distorted diffeomorphism the inpainting of image sequence of deforming shape the super resolution of diffeomorphisms and the global parameterization of cortical surface by combining local parameterizations experiment show that our algorithm can solve these problem with natural and smooth result we demonstrate how our proposed method can be widely applied in area from texture mapping to video processing and from computer graphic to medical imaging 
in this work we present intrinsic shape context isc descriptor for d shape we generalize to surface the polar sampling of the image domain used in shape context for this purpose we chart the surface by shooting geodesic outwards from the point being analyzed angle is treated a tantamount to geodesic shooting direction and radius a geodesic distance to deal with orientation ambiguity we exploit property of the fourier transform our charting method is intrinsic i e invariant to isometric shape transformation the resulting descriptor is a meta descriptor that can be applied to any photometric or geometric property field defined on the shape in particular we can leverage recent development in intrinsic shape analysis and construct isc based on state of the art dense shape descriptor such a heat kernel signature our experiment demonstrate a notable improvement in shape matching on standard benchmark 
we present a discriminative latent topic model for scene recognition the capacity of our model is originated from the modeling of two type of visual context i e the category specific global spatial layout of different scene element and the reinforcement of the visual coherence in uniform local region in contrast most previous method for scene recognition either only modeled one of these two visual context or just totally ignored both of them we cast these two coupled visual context in a discriminative latent dirichlet allocation framework namely context aware topic model then scene recognition is achieved by bayesian inference given a target image our experiment on several scene recognition benchmark clearly demonstrated the advantage of the proposed model 
traditional stereo matching assumes perspective viewing camera under a translational motion the second camera is translated away from the first one to create parallax in this paper we investigate a different rotational stereo model on a special multi perspective camera the xslit camera we show that rotational xslit r xslit stereo can be effectively created by fixing the sensor and slit location but switching the two slit direction we first derive the epipolar geometry of r xslit in the d light field ray space our derivation lead to a simple but effective scheme for locating corresponding epipolar curve to conduct stereo matching we further derive a new disparity term in our model and develop a patch based graph cut solution to validate our theory we assemble an xslit lens by using a pair of cylindrical lens coupled with slit shaped aperture the xslit lens can be mounted on commodity camera where the slit direction are adjustable to form desirable r xslit pair we show through experiment that r xslit provides a potentially advantageous imaging system for conducting fixed location dynamic baseline stereo 
this paper address the problem of restoring image subjected to unknown and spatially varying blur caused by defocus or linear say horizontal motion the estimation of the global non uniform image blur is cast a a multi label energy minimization problem the energy is the sum of unary term corresponding to learned local blur estimator and binary one corresponding to blur smoothness it global minimum is found using ishikawa s method by exploiting the natural order of discretized blur value for linear motion and defocus once the blur ha been estimated the image is restored using a robust non uniform deblurring algorithm based on sparse regularization with global image statistic the proposed algorithm output both a segmentation of the image into uniform blur layer and an estimate of the corresponding sharp image we present qualitative result on real image and use synthetic data to quantitatively compare our approach to the publicly available implementation of chakrabarti et al 
for an ill posed problem like boundary detection human labeled datasets play a critical role compared with the active research on finding a better boundary detector to refresh the performance record there is surprisingly little discussion on the boundary detection benchmark itself the goal of this paper is to identify the potential pitfall of today s most popular boundary benchmark bsds in the paper we first introduce a psychophysical experiment to show that many of the weak boundary label are unreliable and may contaminate the benchmark then we analyze the computation of f measure and point out that the current benchmarking protocol encourages an algorithm to bias towards those problematic weak boundary label with this evidence we focus on a new problem of detecting strong boundary a one alternative finally we ass the performance of major algorithm on different way of utilizing the dataset suggesting new direction for improvement 
this paper deal with generalized procrustes analysis this is the problem of registering a set of shape data by estimating a reference shape and a set of rigid transformation given point correspondence the transformed shape data must align with the reference shape a best possible this is a difficult problem the classical approach computes alternatively the reference shape usually a the average of the transformed shape and each transformation in turn we propose a global approach to generalized procrustes analysis for twoand three dimensional shape it us modern convex optimization based on the theory of sum of square function we show how to convert the whole procrustes problem including missing data into a semidefinite program our approach is statistically grounded it find the maximum likelihood estimate we provide result on synthetic and real datasets compared to classical alternation our algorithm obtains lower error the discrepancy is very high when similarity are estimated or when the shape data have significant deformation 
we propose a representation for scene containing relocatable object that can cause partial occlusion of people in a camera s field of view in many practical application relocatable object tend to appear often therefore model for them can be learned off line and stored in a database we formulate an occluder centric representation called a graphical model layer where a person s motion in the ground plane is defined a a first order markov process on activity zone while image evidence is aggregated in d observation region that are depth ordered with respect to the occlusion mask of the relocatable object we represent real world scene a a composition of depth ordered interacting graphical model layer and account for image evidence in a way that handle mutual overlap of the observation region and their occlusion by the relocatable object these layer interact proximate ground plane zone of different model instance are linked to allow a person to move between the layer and image evidence is shared between the observation region of these model we demonstrate our formulation in tracking pedestrian in the vicinity of parked vehicle our result compare favorably with a sprite learning algorithm with a pedestrian tracker based on deformable contour and with pedestrian detector 
in this work we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold a finding an atlas or a set of overlapping chart that accurately describe local structure we formulate the problem of learning the manifold a an optimisation that simultaneously refines the continuous parameter defining the chart and the discrete assignment of point to chart in contrast to existing method this direct formulation of a manifold doe not require unwrapping the manifold into a lower dimensional space and allows u to learn closed manifold of interest to vision such a those corresponding to gait cycle or camera pose we report state of the art result for manifold based nearest neighbour classification on vision datasets and show how the same technique can be applied to the d reconstruction of human motion from a single image 
we consider the problem of finding a few representative for a dataset i e a subset of data point that efficiently describes the entire dataset we assume that each data point can be expressed a a linear combination of the representative and formulate the problem of finding the representative a a sparse multiple measurement vector problem in our formulation both the dictionary and the measurement are given by the data matrix and the unknown sparse code select the representative via convex optimization in general we do not assume that the data are low rank or distributed around cluster center when the data do come from a collection of low rank model we show that our method automatically selects a few representative from each low rank model we also analyze the geometry of the representative and discus their relationship to the vertex of the convex hull of the data we show that our framework can be extended to detect and reject outlier in datasets and to efficiently deal with new observation and large datasets the proposed framework and theoretical foundation are illustrated with example in video summarization and image classification using representative 
current object recognition algorithm use local feature such a scale invariant feature transform sift and speeded up robust feature surf for visually learning to recognize object these approach though cannot apply to transparent object made of glass or plastic a such object take on the visual feature of background object and the appearance of such object dramatically varies with change in scene background indeed in transmitting light transparent object have the unique characteristic of distorting the background by refraction in this paper we use a single shot light field image a an input and model the distortion of the light field caused by the refractive property of a transparent object we propose a new feature called the light field distortion lfd feature for identifying a transparent object the proposal incorporates this lfd feature into the bag of feature approach for recognizing transparent object we evaluated it performance in laboratory and real setting 
we significantly extrapolate the field of view of a photograph by learning from a roughly aligned wide angle guide image of the same scene category our method can extrapolate typical photo into complete panorama the extrapolation problem is formulated in the shift map image synthesis framework we analyze the self similarity of the guide image to generate a set of allowable local transformation and apply them to the input image our guided shift map method reserve to the scene layout of the guide image when extrapolating a photograph while conventional shift map method only support translation this is not expressive enough to characterize the self similarity of complex scene therefore we additionally allow image transformation of rotation scaling and reflection to handle this increase in complexity we introduce a hierarchical graph optimization method to choose the optimal transformation at each output pixel we demonstrate our approach on a variety of indoor outdoor natural and man made scene 
we present a method for estimating human scan path which are sequence of gaze shift that follow visual attention over an image in this work scan path are modeled based on three principal factor that influence human attention namely low level feature saliency spatial position and semantic content low level feature saliency is formulated a transition probability between different image region based on feature difference the effect of spatial position on gaze shift is modeled a a levy flight with the shift following a d cauchy distribution to account for semantic content we propose to use a hidden markov model hmm with a bag of visual word descriptor of image region an hmm is well suited for this purpose in that the hidden state obtained by unsupervised learning can represent latent semantic concept the prior distribution of the hidden state describes visual attraction to the semantic concept and the transition probability represent human gaze shift pattern the proposed method is applied to task driven viewing process experiment and analysis performed on human eye gaze data verify the effectiveness of this method 
high quality urban reconstruction requires more than multi view reconstruction and local optimization the structure of facade depends on the general layout which ha to be optimized globally shape grammar are an established method to express hierarchical spatial relationship and are therefore suited a representing constraint for semantic facade interpretation usually inference us numerical approximation or hard coded grammar scheme existing method inspired by classical grammar parsing are not applicable on real world image due to their prohibitively high complexity this work provides feasible generic facade reconstruction by combining low level classifier with mid level object detector to infer an irregular lattice the irregular lattice preserve the logical structure of the facade while reducing the search space to a manageable size we introduce a novel method for handling symmetry and repetition within the generic grammar we show competitive result on two datasets namely the paris and the graz the former includes only hausmannian while the latter includes classicism biedermeier historicism art nouveau and post modern architectural style 
the random fourier embedding methodology can be used to approximate the performance of non linear kernel classifier in linear time on the number of training example however there still exists a non trivial performance gap between the approximation and the nonlinear model especially for the exponential kernel one of the most powerful model for histogram based on analogy with chebyshev polynomial we propose an asymptotically convergent analytic series of the measure the new series remove the need to use periodic approximation to the function a typical in previous method and improves the classification accuracy when used in the random fourier approximation of the exponential kernel besides out of core principal component analysis pca method are introduced to reduce the dimensionality of the approximation and achieve better performance at the expense of only an additional constant factor to the time complexity moreover when pca is performed jointly on the training and unlabeled testing data further performance improvement can be obtained the proposed approach are tested on the pascal voc segmentation and the imagenet ilsvr c datasets and shown to give statistically significant improvement over alternative approximation method 
over the past decade single image super resolution sr research ha focused on developing sophisticated image prior leading to significant advance estimating and incorporating the blur model that relates the high re and low re image ha received much le attention however in particular the reconstruction constraint namely that the blurred and down sampled high re output should approximately equal the low re input image ha been either ignored or applied with default fixed blur model in this work we examine the relative importance of the image prior and the reconstruction constraint first we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves sr result almost a good a those of state of the art algorithm with sophisticated image prior second we study both empirically and theoretically the sensitivity of sr algorithm to the blur model assumed in the reconstruction constraint we find that an accurate blur model is more important than a sophisticated image prior finally using real camera data we demonstrate that the default blur model of various sr algorithm may differ from the camera blur typically leading to over smoothed result our finding highlight the importance of accurately estimating camera blur in reconstructing raw lower image acquired by an actual camera 
we address the problem of person identification in tv series we propose a unified learning framework for multi class classification which incorporates labeled and unlabeled data and constraint between pair of feature in the training we apply the framework to train multinomial logistic regression classifier for multi class face recognition the method is completely automatic a the labeled data is obtained by tagging speaking face using subtitle and fan transcript of the video we demonstrate our approach on six episode each of two diverse tv series and achieve state of the art performance 
we propose a new approach for template based extensible surface reconstruction from a single view we extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction our approach relies on the minimization of a proposed stretching energy formalized with respect to the poisson ratio parameter of the surface we derive a patch based formulation of this stretching energy by assuming local linear elasticity this formulation unifies geometrical and mechanical constraint in a single energy term we prevent local scale ambiguity by imposing a set of fixed boundary d point we experimentally prove the sufficiency of this set of boundary point and demonstrate the effectiveness of our approach on different developable and non developable surface with a wide range of extensibility 
recognizing functional scene element in video scene based on the behavior of moving object that interact with them is an emerging problem of interest existing approach have a limited ability to characterize element such a cross walk intersection and building that have low activity are multi modal or have indirect evidence our approach recognizes the low activity and multi model element crosswalk intersection by introducing a hierarchy of descriptive cluster to form a pyramid of codebooks that is sparse in the number of cluster and dense in content the incorporation of local behavioral context such a person enter building and vehicle parking nearby enables the detection of element that do not have direct motion based evidence e g building these two contribution significantly improve scene element recognition when compared against three state of the art approach result are shown on typical ground level surveillance video and for the first time on the more complex wide area motion imagery 
in this work we consider the problem of tracking object from a moving airborne platform in wide area surveillance through long occlusion and or when their motion is unpredictable the main idea is to take advantage of the known d scene structure to estimate a dynamic occlusion map and to use the occlusion map to determine traffic entry and exit into these zone which we call source and sink then the track linking problem is formulated a an alignment of sequence of track entering a sink and leaving a source the sequence alignment problem is solved optimally and efficiently using dynamic programming we have evaluated our algorithm on a vehicle tracking task in wide area motion imagery and have shown that track fragmentation is significantly decreased and outperforms the hungarian algorithm 
we address the problem of weakly supervised semantic segmentation the training image are labeled only by the class they contain not by their location in the image on test image instead the method must predict a class label for every pixel our goal is to enable segmentation algorithm to use multiple visual cue in this weakly supervised setting analogous to what is achieved by fully supervised method however it is difficult to ass the relative usefulness of different visual cue from weakly supervised training data we define a parametric family of structured model were each model weight visual cue in a different way we propose a maximum expected agreement model selection principle that evaluates the quality of a model from the family without looking at superpixel label searching for the best model is a hard optimization problem which ha no analytic gradient and multiple local optimum we cast it a a bayesian optimization problem and propose an algorithm based on gaussian process to efficiently solve it our second contribution is an extremely randomized hashing forest that represents diverse superpixel feature a a sparse binary vector it enables using appearance model of visual class that are fast at training and testing and yet accurate experiment on the sift flow dataset show a significant improvement over previous weakly supervised method and even over some fully supervised method 
in complex scene with multiple atomic event happening sequentially or in parallel detecting each individual event separately may not always obtain robust and reliable result it is essential to detect them in a holistic way which incorporates the causality and temporal dependency among them to compensate the limitation of current computer vision technique in this paper we propose an interval temporal constrained dynamic bayesian network to extend allen s interval algebra network ian from a deterministic static model to a probabilistic dynamic system which can not only capture the complex interval temporal relationship but also model the evolution dynamic and handle the uncertainty from the noisy visual observation in the model the topology of the ian on each time slice and the interlinks between the time slice are discovered by an advanced structure learning method the duration of the event and the unsynchronized time lag between two correlated event interval are captured by a duration model so that we can better determine the temporal boundary of the event empirical result on two real world datasets show the power of the proposed interval temporal constrained model 
when modeling structured output such a image segmentation prediction can be improved by accurately modeling structure present in the label a key challenge is developing tractable model that are able to capture complex high level structure like shape in this work we study the learning of a general class of pattern like high order potential which we call compositional high order pattern potential chopps we show that chopps include the linear deviation pattern potential of rother et al and also restricted boltzmann machine rbms we also establish the near equivalence of these two model experimentally we show that performance is affected significantly by the degree of variability present in the datasets and we define a quantitative variability measure to aid in studying this we then improve chopps performance in high variability datasets with two primary contribution a developing a loss sensitive joint learning procedure so that internal pattern parameter can be learned in conjunction with other model potential to minimize expected loss and b learning an image dependent mapping that encourages or inhibits pattern depending on image feature we also explore varying how multiple pattern are composed and learning convolutional pattern quantitative result on challenging highly variable datasets show that the joint learning and image dependent high order potential can improve performance 
a a recently proposed technique sparse representation based classification src ha been widely used for face recognition fr src first code a testing sample a a sparse linear combination of all the training sample and then classifies the testing sample by evaluating which class lead to the minimum representation error while the importance of sparsity is much emphasized in src and many related work the use of collaborative representation cr in src is ignored by most literature however is it really the l norm sparsity that improves the fr accuracy this paper devotes to analyze the working mechanism of src and indicates that it is the cr but not the l norm sparsity that make src powerful for face classification consequently we propose a very simple yet much more efficient face classification scheme namely cr based classification with regularized least square crc rls the extensive experiment clearly show that crc rls ha very competitive classification result while it ha significantly le complexity than src 
imaging system consisting of a camera looking at multiple spherical mirror reflection or multiple refractive sphere refraction have been used for wide angle imaging application we describe such setup a multi axial imaging system since a single sphere result in an axial system assuming an internally calibrated camera calibration of such multi axial system involves estimating the sphere radius and location in the camera coordinate system however previous calibration approach require manual intervention or constrained setup we present a fully automatic approach using a single photo of a d calibration grid the pose of the calibration grid is assumed to be unknown and is also recovered our approach can handle unconstrained setup where the mirror refractive ball can be arranged in any fashion not necessarily on a grid the axial nature of ray allows u to compute the axis of each sphere separately we then show that by choosing ray from two or more sphere the unknown pose of the calibration grid can be obtained linearly and independently of sphere radius and location knowing the pose we derive analytical solution for obtaining the sphere radius and location this lead to an interesting result that dof pose estimation of a multi axial camera can be done without the knowledge of full calibration simulation and real experiment demonstrate the applicability of our algorithm 
this paper proposes a content aware image resizing method which simultaneously preserve both salient image feature and important line structure property parallelism collinearity and orientation when there are prominent line structure in the image image resizing method without explicitly taking these property into account could produce line structure distortion in their result since the human visual system is very sensitive to line structure such distortion often become noticeable and disturbing our method couple mesh deformation for image resizing with similarity transforms for line feature mesh deformation are used to control content preservation while similarity transforms are analyzed in the hough space to maintain line structure property our method strike a good balance between preserving content and maintaining line structure property experiment show the proposed method often outperforms method without taking line structure into account especially for scene with prominent line structure 
we propose an approach to identify and segment object from scene that a person or robot encounter in activity of daily living adl image collected in those cluttered scene contain multiple object each image provides only a partial possibly very different view of each object an object instance discovery program must be able to link piece of visual information from multiple image and extract the consistent pattern 
in this paper we propose a new approach for matching image observed in different camera view with complex cross view transforms and apply it to person re identification it jointly partition the image space of two camera view into different configuration according to the similarity of cross view transforms the visual feature of an image pair from different view are first locally aligned by being projected to a common feature space and then matched with softly assigned metric which are locally optimized the feature optimal for recognizing identity are different from those for clustering cross view transforms they are jointly learned by utilizing sparsity inducing norm and information theoretical regularization this approach can be generalized to the setting where test image are from new camera view not the same a those in the training set extensive experiment are conducted on public datasets and our own dataset comparison with the state of the art metric learning and person re identification method show the superior performance of our approach 
this paper present an integrated solution for the problem of detecting tracking and identifying vehicle in a tunnel surveillance application taking into account practical constraint including realtime operation poor imaging condition and a decentralized architecture vehicle are followed through the tunnel by a network of non overlapping camera they are detected and tracked in each camera and then identified i e matched to any of the vehicle detected in the previous camera s to limit the computational load we propose to reuse the same set of haar feature for each of these step for the detection we use an adaboost cascade here we introduce a composite confidence score integrating information from all stage of the cascade a subset of the feature used for detection is then selected optimizing for the identification problem this result in a compact binary vehicle fingerprint requiring very limited bandwidth finally we show that the same set of feature can also be used for tracking this haar feature based tracking by identification yield surprisingly good result on standard datasets without the need to update the model online 
we present a robust radiometric calibration method that capitalizes on the transform invariant low rank structure of sensor irradiances recorded from a static scene with different exposure time we formulate the radiometric calibration problem a a rank minimization problem unlike previous approach our method naturally avoids over fitting problem therefore it is robust against biased distribution of the input data which is common in practice when the exposure time are completely unknown the proposed method can robustly estimate the response function up to an exponential ambiguity the method is evaluated using both simulation and real world datasets and show a superior performance than previous approach 
we deal with the problem of recognizing social role played by people in an event social role are governed by human interaction and form a fundamental component of human event description we focus on a weakly supervised setting where we are provided different video belonging to an event class without training role label since social role are described by the interaction between people in an event we propose a conditional random field to model the inter role interaction along with person specific social descriptor we develop tractable variational inference to simultaneously infer model weight a well a role assignment to all people in the video we also present a novel youtube social role dataset with ground truth role annotation and introduce annotation on a subset of video from the trecvid med event kit for evaluation purpose the performance of the model is compared against different baseline method on these datasets 
we propose a unified branch and contract method to estimate the fundamental matrix with guaranteed global optimality by minimizing either the sampson error or the point to epipolar line distance and explicitly handling the rank constraint and scale ambiguity based on a novel denominator linearization strategy the fundamental matrix estimation problem can be transformed into an equivalent problem that involves squared univariate bilinear and trilin ear term we build tight convex and concave relaxation for these nonconvex term and solve the problem deterministically under the branch and bound framework for acceleration a bound contraction mechanism is introduced to reduce the size of the branching region at the root node given high quality correspondence and proper data normalization our experiment show that the state of the art locally optimal method generally converge to the globally optimal solution however they indeed have the risk of being trapped into local minimum in case of noise a another important experimental result we also demonstrate from the viewpoint of global optimization that the point to epipolar line distance is slightly inferior to the sampson error in case of drastically varying object scale across two view 
boosting combine a set of moderately accurate weak classifier to form a highly accurate predictor compared with binary boosting classification multi class boosting received le attention we propose a novel multi class boosting formulation here unlike most previous multi class boosting algorithm which decompose a multi boost problem into multiple independent binary boosting problem we formulate a direct optimization method for training multi class boosting moreover by explicitly deriving the la grange dual of the formulated primal optimization problem we design totally corrective boosting using the column generation technique in convex optimization at each iteration all weak classifier weight are updated our experiment on various data set demonstrate that our direct multi class boosting achieves competitive test accuracy compared with state of the art multi class boosting in the literature 
predicting human occupation in photo ha great application potential in intelligent service and system however using traditional classification method cannot reliably distinguish different occupation due to the complex relation between occupation and the low level image feature in this paper we investigate the human occupation prediction problem by modeling the appearance of human clothing a well a surrounding context the human clothing regarding it complex detail and variant appearance is described via part based modeling on the automatically aligned patch of human body part the image patch are represented with semantic level pattern such a clothes and haircut style using method based on sparse coding towards informative and noise tolerant capacity this description of human clothing is proved to be more effective than traditional method different kind of surrounding context are also investigated a a complementarity of human clothing feature in the case that the background information is available experiment are conducted on a well labeled image database that contains more than image from representative occupation category the preliminary study show the human occupation is reasonably predictable using the proposed clothing feature and possible context 
combining information from the higher level and the lower level ha long been recognized a an essential component in holistic image understanding however an efficient inference method for multi level model remains an open problem moreover modeling the complex relation within real world image often give rise to energy term that couple many variable in arbitrary way they make the inference problem even harder in this paper we construct an energy function over the pose of the human body and pixel wise foreground background segmentation the energy function incorporates term both on the higher level which model the human pose and the lower level which model the pixel it also contains an intractable term that couple all body part we show how to optimize this energy in a principled way by relaxed dual decomposition which proceeds by maximizing a concave lower bound on the energy function empirically we show that our approach improves the state of the art performance of human pose estimation on the ramanan benchmark dataset 
we propose a new convex regularizer named the local color nuclear norm lcnn for color image recovery the lcnn is designed to promote a property inherent in natural color image in which their local color distribution often exhibit strong linearity and is thus expected to reduce color artifact effectively in addition the very nature of lcnn allows u to incorporate it into various type of color image recovery formulation with the associated convex optimization problem solvable using proximal splitting technique application of lcnn are demonstrated with illustrative numerical example 
separating the direct and global component of radiance can aid shape recovery algorithm and can provide useful information about material in a scene practical method for finding the direct and global component use multiple image captured under varying illumination pattern and require the scene light source and camera to remain stationary during the image acquisition process in this paper we develop a motion compensation method that relaxes this condition and allows direct global separation to be performed on video sequence of dynamic scene captured by moving projector camera system key to our method is being able to register frame in a video sequence to each other in the presence of time varying high frequency active illumination pattern we compare our motion compensated method to alternative such a single shot separation and frame interleaving a well a ground truth we present result on challenging video sequence that include various type of motion and deformation in scene that contain complex material like fabric skin leaf and wax 
a combination of photographic filter placed over the lens and the color filter array on image sensor induces difference in red green and blue channel sensitivity spectrally selective single shot hdr s hdr imaging treat this a an exposure bracketing optimally exposed region of low dynamic range red green blue color component are merged in a principled manner to yield a single hdr color image though not expected to yield result superior to the traditional time multiplexing counterpart the single shot hdr solution we propose is a robust alternative that can be realized with conventional camera hardware 
despite recent success pose estimator are still somewhat fragile and they frequently rely on a precise knowledge of the location of the object unfortunately articulated object are also very difficult to detect knowledge about the articulated nature of these object however can substantially contribute to the task of finding them in an image it is somewhat surprising that these two task are usually treated entirely separately in this paper we propose an articulated part based model apm for jointly detecting object and estimating their pose apm recursively represents an object a a collection of part at multiple level of detail from coarse to fine where part at every level are connected to a coarser level through a parent child relationship fig b horizontal part are further grouped into part type e g left facing head long stretching arm etc so a to model appearance variation fig b vertical by having the ability to share appearance model of part type and by decomposing complex pose into parent child pairwise relationship apm strike a good balance between model complexity and model richness extensive quantitative and qualitative experiment result on public datasets show that apm outperforms state of the art method we also show result on pascal cat and dog two highly challenging articulated object category 
we present a novel approach to representing and recognizing composite video event a composite event is specified by a scenario which is based on primitive event and their temporal logical relation to constrain the arrangement of the primitive event in the composite event we propose a new scenario description method to represent composite event fluently and efficiently a composite event is recognized by a constrained optimization algorithm whose constraint are defined by the scenario the dynamic configuration of the scenario constraint is represented with constraint flow which is generated from scenario automatically by our scenario parsing algorithm the constraint flow reduces the search space dramatically alleviates the effect of preprocessing error and guarantee the globally optimal solution for recognition we validate our method to describe scenario and construct constraint flow for real video and illustrate the effectiveness of our composite event recognition algorithm for natural video event 
this paper address scene understanding in the context of a moving camera integrating semantic reasoning idea from monocular vision with d information available through structure from motion we combine geometric and photometric cue in a bayesian framework building on recent success leveraging the indoor manhattan assumption in monocular vision we focus on indoor environment and show how to extract key boundary while ignoring clutter and decoration to achieve this we present a graphical model that relates photometric cue learned from labeled data stereo photo consistency across multiple view and depth cue derived from structure from motion point cloud we show how to solve map inference using dynamic programming allowing exact global inference in m in addition to feature computation of under one second without using specialized hardware experiment show our system out performing the state of the art 
we present a system for the annotation and augmentation of mountain photograph the key issue resides in the registration of a given photograph with a d georeferenced terrain model typical outdoor image contain little structural information particularly mountain scene whose aspect change drastically across season and varying weather condition existing approach usually fail on such difficult scenario to avoid the burden of manual registration we propose a novel automatic technique given only a viewpoint and fov estimate the technique is able to automatically derive the pose of the camera relative to the geometric terrain model we make use of silhouette edge which are among most reliable feature that can be detected in the targeted situation using an edge detection algorithm our technique then search for the best match with silhouette edge rendered using the synthetic model we develop a robust matching metric allowing u to cope with the inevitable noise affecting detected edge e g due to cloud snow rock forest or any phenomenon not encoded in the digital model once registered against the model photograph can easily be augmented with annotation e g topographic data peak name path which would otherwise imply a tedious fusion process we further illustrate various other application such a d model assisted image enhancement or inversely texturing of digital model 
we establish a link between fourier optic and a recent construction from the machine learning community termed the kernel mean map using the fraunhofer approximation it identifies the kernel with the squared fourier transform of the aperture this allows u to use result about the invertibility of the kernel mean map to provide a statement about the invertibility of fraunhofer diffraction showing that imaging process with arbitrarily small aperture can in principle be invertible i e do not lose information provided the object to be imaged satisfy a generic condition a real world experiment show that we can super resolve beyond the rayleigh limit 
d reconstruction deal with the problem of finding the shape of an object from a set of image thin object that have virtually no volume pose a special challenge for reconstruction with respect to shape representation and fusion of depth information in this paper we present a dense point based reconstruction method that can deal with this special class of object we seek to jointly optimize a set of depth map by treating each pixel a a point in space point are pulled towards a common surface by pair wise force in an iterative scheme the method also handle the problem of opposed surface by mean of penalty force efficient optimization is achieved by grouping point to super pixel and a spatial hashing approach for fast neighborhood query we show that the approach is on a par with state of the art method for standard multi view stereo setting and give superior result for thin object 
the task of recognizing event in photo collection is central for automatically organizing image it is also very challenging because of the ambiguity of photo across different event class and because many photo do not convey enough relevant information unfortunately the field still lack standard evaluation data set to allow comparison of different approach in this paper we introduce and release a novel data set of personal photo collection containing more than image in collection annotated with diverse social event class casting collection a sequential data we build upon recent and state of the art work in event recognition in video to propose a latent sub event approach for event recognition in photo collection however photo in collection are sparsely sampled over time and come in burst from which transpires the importance of specific moment for the photographer thus we adapt a discriminative hidden markov model to allow the transition between state to be a function of the time gap between consecutive image which we coin a stopwatch hidden markov model shmm in our experiment we show that our proposed model outperforms approach based only on feature pooling or a classical hidden markov model with an average accuracy of we also highlight the difficulty of the data set and the need for future advance in event recognition in photo collection 
this paper is concerned with model fitting in the presence of noise and outlier previously it ha been shown that the number of outlier can be minimized with polynomial complexity in the number of measurement this paper improves on these result in two way first it is shown that for a large class of problem the statistically more desirable truncated l norm can be optimized with the same complexity then with the same methodology it is shown how to transform multi model fitting into a purely combinatorial problem with worst case complexity that is polynomial in the number of measurement though exponential in the number of model we apply our framework to a series of hard registration and stitching problem demonstrating that the approach is not only of theoretical interest it give a practical method for simultaneously dealing with measurement noise and large amount of outlier for fitting problem with low dimensional model 
this paper present a complete system for expressive visual text to speech vtts which is capable of producing expressive output in the form of a talking head given an input text and a set of continuous expression weight the face is modeled using an active appearance model aam and several extension are proposed which make it more applicable to the task of vtts the model allows for normalization with respect to both pose and blink state which significantly reduces artifact in the resulting synthesized sequence we demonstrate quantitative improvement in term of reconstruction error over a million frame a well a in large scale user study comparing the output of different system 
we present a model for early vision task such a denoising super resolution deblurring and demosaicing the model provides a resolution independent representation of discrete image which admits a truly rotationally invariant prior the model generalizes several existing approach variational method finite element method and discrete random field the primary contribution is a novel energy functional which ha not previously been written down which combine the discrete measurement from pixel with a continuous domain world viewed through continous domain point spread function the value of the functional is that simple prior such a total variation and generalization on the continous domain world become realistic prior on the sampled image we show that despite it apparent complexity optimization of this model depends on just a few computational primitive which although tedious to derive can now be reused in many domain we define a set of optimization algorithm which greatly overcome the apparent complexity of this model and make possible it practical application new experimental result include infinite resolution upsampling and a method for obtaining subpixel superpixels 
this paper proposes a simple yet effective method to learn the hierarchical object shape model consisting of local contour fragment which represents a category of shape in the form of an and or tree this model extends the traditional hierarchical tree structure by introducing the switch variable i e the or node that explicitly specify production rule to capture shape variation we thus define the model with three layer the leaf node for detecting local contour fragment the or node specifying selection of leaf node and the root node encoding the holistic distortion in the training stage for optimization of the and or tree learning we extend the concave convex procedure cccp by embedding the structural clustering during the iterative learning step the inference of shape detection is consistent with the model optimization which integrates the local testing via the leaf node and or node with the global verification via the root node the advantage of our approach are validated on the challenging shape database i e ethz and inria horse and summarized a follows the proposed method is able to accurately localize shape contour against unreliable edge detection and edge tracing the and or tree model enables u to well capture the intraclass variance 
many object detection system are constrained by the time required to convolve a target image with a bank of filter that code for different aspect of an object s appearance such a the presence of component part we exploit locality sensitive hashing to replace the dot product kernel operator in the convolution with a fixed number of hash table probe that effectively sample all of the filter response in time independent of the size of the filter bank to show the effectiveness of the technique we apply it to evaluate deformable part model requiring over a million part filter on multiple scale of a target image in le than second using a single multi core processor with gb of ram this represents a speed up of approximately time four order of magnitude when compared with performing the convolution explicitly on the same hardware while mean average precision over the full set of object class is around due in large part to the challenge in gathering training data and collecting ground truth for so many class we achieve a map of at least on a third of the class and or better on about of the class 
we present visibility based preconditioning vbp a new technique for efficiently solving the linear least square problem that arise in bundle adjustment using the camera point visibility structure of the scene we describe the construction of two preconditioners these preconditioners when combined with an inexact step levenberg marquardt algorithm offer state of the art performance on the bal data set with reduction in execution time over currently available method while delivering comparable or better solution quality 
complex real world signal such a image contain discriminative structure that differ in many aspect including scale invariance and data channel while progress in deep learning show the importance of learning feature through multiple layer it is equally important to learn feature through multiple path we propose multipath hierarchical matching pursuit m hmp a novel feature learning architecture that combine a collection of hierarchical sparse feature for image classification to capture multiple aspect of discriminative structure our building block are mi ksvd a codebook learning algorithm that balance the reconstruction error and the mutual incoherence of the codebook and batch orthogonal matching pursuit omp we apply them recursively at varying layer and scale the result is a highly discriminative image representation that lead to large improvement to the state of the art on many standard benchmark e g caltech caltech mitscenes oxford iiit pet and caltech ucsd bird 
we present a new technique for extracting local feature from image of architectural scene based on detecting and representing local symmetry these new feature are motivated by the fact that local symmetry at different scale are a fundamental characteristic of many urban image and are potentially more invariant to large appearance change than lower level feature such a sift hence we apply these feature to the problem of matching challenging pair of photo of urban scene our feature are based on simple measure of local bilateral and rotational symmetry computed using local image operation these measure are used both for feature detection and for computing descriptor we demonstrate our method on a challenging new dataset containing image pair exhibiting a range of dramatic variation in lighting age and rendering style and show that our feature can improve matching performance for this difficult task 
in this paper we introduce a novel image descriptor enabling accurate object categorization even with linear model akin to the popular attribute descriptor our feature vector comprises the output of a set of classifier evaluated on the image however unlike traditional attribute which represent hand selected object class and predefined visual property our feature are learned automatically and correspond to abstract category which we name meta class each meta class is a super category obtained by grouping a set of object class such that collectively they are easy to distinguish from other set of category by using learnability of the meta class a criterion for feature generation we obtain a set of attribute that encode general visual property shared by multiple object class and that are effective in describing and recognizing even novel category i e class not present in the training set we demonstrate that simple linear svms trained on our meta class descriptor significantly outperform the best known classifier on the caltech benchmark we also present result on the imagenet challenge database where our system produce result approaching those of the best system but at a much lower computational cost 
localizing facial landmark is a fundamental step in facial image analysis however the problem is still challenging due to the large variability in pose and appearance and the existence of occlusion in real world face image in this paper we present exemplar based graph matching egm a robust framework for facial landmark localization compared to conventional algorithm egm ha three advantage an affine invariant shape constraint is learned online from similar exemplar to better adapt to the test face the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint the graph matching problem can be optimized efficiently by linear programming to our best knowledge this is the first attempt to apply a graph matching technique for facial landmark localization experiment on several challenging datasets demonstrate the advantage of egm over state of the art method 
combining multiple low level visual feature is a proven and effective strategy for a range of computer vision task however limited attention ha been paid to combining such feature with information from other modality such a audio and videotext for large scale analysis of web video in our work we rigorously analyze and combine a large set of low level feature that capture appearance color motion audio and audio visual co occurrence pattern in video we also evaluate the utility of high level i e semantic visual information obtained from detecting scene object and action concept further we exploit multimodal information by analyzing available spoken and videotext content using state of the art automatic speech recognition asr and videotext recognition system we combine these diverse feature using a two step strategy employing multiple kernel learning mkl and late score level fusion method based on the trecvid med evaluation for detecting event in a large benchmark set of video our system showed the best performance among the international team 
we present a new coprime blurred pair cbp theory that may benefit a number of computer vision application a cbp is constructed by blurring the same latent image with two unknown kernel where the two kernel are co prime when mapped to bivariate polynomial under the z transform we first show that the blurred content in a cbp are difficult to restore using conventional blind deconvolution method based on sparsity prior we therefore introduce a new coprime prior for recovering the latent image in a cbp our solution map the cbp to bivariate polynomial and sample them on the unit circle in both dimension we show that coprimality can be derived in term of the rank of the b zout matrix formed by the sampled polynomial and we present an efficient algorithm to factor the b zout matrix for recovering the latent image finally we discus application of the cbp theory in privacy preserving surveillance and motion deblurring a well a physical implementation of cbps using flutter shutter camera 
we present a novel theory for characterizing defocus blur in multi perspective camera such a catadioptric mirror our approach study how multi perspective ray geometry transforms under the thin lens we first use the general linear camera glcs to approximate the incident multi perspective ray to the lens and then apply a thin lens operator tlo to map an incident glc to the exit glc to study defocus blur caused by the glc ray we further introduce a new ray spread function rsf model analogous the point spread function psf while psf model defocus blur caused by a d scene point rsf model blur spread by ray we derive closed form rsfs for incident glc ray and we show that for catadioptric camera with a circular aperture the rsf can be effectively approximated a a single or mixture of elliptic shaped kernel we apply our method for predicting defocus blur on commonly used catadioptric camera and for reducing de focus blur in catadioptric projection experiment on synthetic and real data demonstrate the accuracy and general applicability of our approach 
the aim of this work is to localize a query photograph by finding other image depicting the same place in a large geotagged image database this is a challenging task due to change in viewpoint imaging condition and the large size of the image database the contribution of this work is two fold first we cast the place recognition problem a a classification task and use the available geotags to train a classifier for each location in the database in a similar manner to per exemplar svms in object recognition second a only few positive training example are available for each location we propose a new approach to calibrate all the per location svm classifier using only the negative example the calibration we propose relies on a significance measure essentially equivalent to the p value classically used in statistical hypothesis testing experiment are performed on a database of geotagged street view image of pittsburgh and demonstrate improved place recognition accuracy of the proposed approach over the previous work 
we present a new approach to learning attribute based description of object unlike earlier work we do not assume that the description are hand labeled instead our approach jointly learns both the attribute classifier and the description from data by incorporating class information into the attribute classifier learning we get an attribute level representation that generalizes well to both unseen example of known class and unseen class we consider two different setting one with unlabeled image available for learning and another without the former corresponds to a novel transductive setting where the unlabeled image can come from new class result from animal with attribute and a yahoo a pascal benchmark datasets show that the learned representation give similar or even better accuracy than the hand labeled description 
this paper is concerned with recognizing realistic human action in video based on spatio temporal interest point stips existing stip based action recognition approach operate on intensity representation of the image data because of this these approach are sensitive to disturbing photometric phenomenon such a highlight and shadow moreover valuable information is neglected by discarding chromaticity from the photometric representation these issue are addressed by color stips color stips are multi channel reformulations of existing intensity based stip detector and descriptor for which we consider a number of chromatic representation derived from the opponent color space this enhanced modeling of appearance improves the quality of subsequent stip detection and description color stips are shown to substantially outperform their intensity based counterpart on the challenging ucf sport ucf and ucf action recognition benchmark moreover the result show that color stips are currently the single best low level feature choice for stip based approach to human action recognition 
we present a novel paradigm to deal with depth reconstruction from d light field in a variational framework taking into account the special structure of light field data we reformulate the problem of stereo matching to a constrained labeling problem on epipolar plane image which can be thought of a vertical and horizontal d cut through the field this alternative formulation allows to estimate accurate depth value even for specular surface while simultaneously taking into account global visibility constraint in order to obtain consistent depth map for all view the resulting optimization problem are solved with state of the art convex relaxation technique we test our algorithm on a number of synthetic and real world example captured with a light field gantry and a plenoptic camera and compare to ground truth where available all data set a well a source code are provided online for additional evaluation 
we present a generic framework for object segmentation using depth map based on random forest and graph cut theory and apply it to the segmentation of human limb in depth map first from a set of random depth feature random forest is used to infer a set of label probability for each data sample this vector of probability is used a unary term in swap graph cut algorithm moreover depth of spatio temporal neighboring data point are used a boundary potential result on a new multi label human depth data set show high performance in term of segmentation overlapping of the novel methodology compared to classical approach 
camera are ubiquitous everywhere and hold the promise of significantly changing the way we live and interact with our environment human activity recognition is central to understanding dynamic scene for application ranging from security surveillance to assisted living for the elderly to video gaming without controller most current approach to solve this problem are based in the use of local temporal spatial feature that limit their ability to recognize long and complex action in this paper we propose a new approach to exploit the temporal information encoded in the data the main idea is to model activity a the output of unknown dynamic system evolving from unknown initial condition under this framework we show that activity video can be compared by computing the principal angle between subspace representing activity type which are found by a simple svd of the experimental data the proposed approach outperforms state of the art method classifying activity in the kth dataset a well a in much more complex scenario involving interacting actor 
cross domain image synthesis and recognition are typically considered a two distinct task in the area of computer vision and pattern recognition therefore it is not clear whether approach addressing one task can be easily generalized or extended for solving the other in this paper we propose a unified model for coupled dictionary and feature space learning the proposed learning model not only observes a common feature space for associating cross domain image data for recognition purpose the derived feature space is able to jointly update the dictionary in each image domain for improved representation this is why our method can be applied to both cross domain image synthesis and recognition problem experiment on a variety of synthesis and recognition task such a single image super resolution cross view action recognition and sketch to photo face recognition would verify the effectiveness of our proposed learning model 
recent year have seen an increasing interest in sparse representation for image classification and object recognition probably motivated by evidence from the analysis of the primate visual cortex it is still unclear however whether or not sparsity help classification in this paper we evaluate it impact on the recognition rate using a shallow modular architecture adopting both standard filter bank and filter bank learned in an unsupervised way in our experiment on the cifar and on the caltech datasets enforcing sparsity constraint actually doe not improve recognition performance this ha an important practical impact in image descriptor design a enforcing these constraint can have a heavy computational cost 
global illumination effect such a inter reflection diffusion and sub surface scattering severely degrade the performance of structured light based d scanning in this paper we analyze the error caused by global illumination in structured light based shape recovery based on this analysis we design structured light pattern that are resilient to individual global illumination effect using simple logical operation and tool from combinatorial mathematics scene exhibiting multiple phenomenon are handled by combining result from a small ensemble of such pattern this combination also allows u to detect any residual error that are corrected by acquiring a few additional image our technique do not require explicit separation of the direct and global component of scene radiance and hence work even in scenario where the separation fails or the direct component is too low our method can be readily incorporated into existing scanning system without significant overhead in term of capture time or hardware we show result on a variety of scene with complex shape and material property and challenging global illumination effect 
non rigid structure from motion nr sfm is a difficult underconstrained problem in computer vision this paper proposes a new algorithm that revise the standard matrix factorization approach in nr sfm we consider two alternative representation for the linear space spanned by a small number k of d basis shape a compared to the standard approach using general rank k matrix factor we show that improved result are obtained by explicitly modeling k complementary space of rank our new method is positively compared to the state of the art in nr sfm providing improved result on high frequency deformation of both articulated and simpler deformable shape we also present an approach for nr sfm with occlusion 
face recognition approach have traditionally focused on direct comparison between aligned image e g using pixel value or local image feature such comparison become prohibitively difficult when comparing face across extreme difference in pose illumination and expression the goal of this work is to develop a face similarity measure that is largely invariant to these difference we propose a novel data driven method based on the insight that comparing image of face is most meaningful when they are in comparable imaging condition to this end we describe an image of a face by an ordered list of identity from a library the order of the list is determined by the similarity of the library image to the probe image the list act a a signature for each face image similarity between face image is determined via the similarity of the signature here the cmu multi pie database which includes image of individual in more than pose lighting and illumination combination serf a the library we show improved performance over state of the art face similarity measure based on local feature such a fplbp especially across large pose variation on facepix and multi pie on lfw we show improved performance in comparison with measure like sift on fiducials lbp fplbp and gabor c 
we study the problem of segmenting multiple cell nucleus from gfp or hoechst stained microscope image with a shape prior this problem is encountered ubiquitously in cell biology and developmental biology our work is motivated by the observation that segmentation with loose boundary or shrinking bias not only jeopardize feature extraction for downstream task e g cell tracking but also prevent robust statistical analysis e g modeling of fluorescence distribution we therefore propose a novel extension to the graph cut framework that incorporates a blob like shape prior the corresponding energy term are parameterized via structured learning extensive evaluation and comparison on d d datasets show substantial quantitative improvement over other state of the art method for example our method achieves an rand index increase and a hausdorff distance decrease over the second best method on a public hand labeled d benchmark 
taking a sharp photo at several megapixel resolution traditionally relies on high grade lens in this paper we present an approach to alleviate image degradation caused by imperfect optic we rely on a calibration step to encode the optical aberration in a space variant point spread function and obtain a corrected image by non stationary deconvolution by including the bayer array in our image formation model we can perform demosaicing a part of the deconvolution 
we consider the problem of minimum distortion intrinsic correspondence between deformable shape many useful formulation of which give rise to the np hard quadratic assignment problem qap previous attempt to use the spectral relaxation have had limited success due to the lack of sparsity of the obtained fuzzy solution in this paper we adopt the recently introduced alternative l relaxation of the qap based on the principle of game theory we relate it to the gromov and lipschitz metric between metric space and demonstrate on state of the art benchmark that the proposed approach is capable of finding very accurate sparse correspondence between deformable shape 
inspired by the close relation between nearest neighbor search and clustering in high dimensional space a well a the success of one helping to solve the other we introduce a new paradigm where both problem are solved simultaneously our solution is recursive not in the size of input data but in the number of dimension one result is a clustering algorithm that is tuned to small codebooks but doe not need all data in memory at the same time and is practically constant in the data size a a by product a tree structure performs either exact or approximate quantization on trained centroid the latter being not very precise but extremely fast a lesser contribution is a new indexing scheme for image retrieval that exploit multiple small codebooks to provide an arbitrarily fine partition of the descriptor space large scale experiment on public datasets exhibit state of the art performance and remarkable generalization 
this paper proposes a new projection model for mapping a hemisphere to a plane such a model can be useful for viewing wide angle image our model consists of two step in the first step the hemisphere is projected onto a swung surface constructed by a circular profile and a rounded rectangular trajectory the second step map the projected image on the swung surface onto the image plane through the perspective projection we also propose a method for automatically determining proper parameter for the projection model based on image content the proposed model ha several advantage it is simple efficient and easy to control most importantly it make a better compromise between distortion minimization and line preserving than popular projection model such a stereographic and pannini projection experiment and analysis demonstrate the effectiveness of our model 
convex relaxation technique have become a popular approach to image segmentation a they allow to compute solution independent of initialization to a variety of image segmentation problem in this paper we will show that shape prior in term of moment constraint can be imposed within the convex optimization framework since they give rise to convex constraint in particular the lower order moment correspond to the overall volume the centroid and the variance or covariance of the shape and can be easily imposed in interactive segmentation method respective constraint can be imposed a hard constraint or soft constraint quantitative segmentation study on a variety of image demonstrate that the user can easily impose such constraint with a few mouse click giving rise to substantial improvement of the resulting segmentation and reducing the average segmentation error from to gpu based computation time of around second allow for interactive segmentation 
symmetric positive definite spd matrix are ubiquitous in computer vision machine learning and medical image analysis finding the center average of a population of such matrix is a common theme in many algorithm such a clustering segmentation principal geodesic analysis etc the center of a population of such matrix can be defined using a variety of distance divergence measure a the minimizer of the sum of squared distance divergence from the unknown center to the member of the population it is well known that the computation of the karcher mean for the space of spd matrix which is a negatively curved riemannian manifold is computationally expensive recently the logdet divergence based center wa shown to be a computationally attractive alternative however the logdet based mean of more than two matrix can not be computed in closed form which make it computationally le attractive for large population in this paper we present a novel recursive estimator for center based on the stein distance which is the square root of the logdet divergence that is significantly faster than the batch mode computation of this center the key theoretical contribution is a closed form solution for the weighted stein center of two spd matrix which is used in the recursive computation of the stein center for a population of spd matrix additionally we show experimental evidence of the convergence of our recursive stein center estimator to the batch mode stein center we present application of our recursive estimator to k mean clustering and image indexing depicting significant time gain over corresponding algorithm that use the batch mode computation for the latter application we develop novel hashing function using the stein distance and apply it to publicly available data set and experimental result have shown favorable comparison to other competing method 
many computer vision approach take for granted positive answer to question such a are semantic category visually separable and is visual similarity correlated to semantic similarity in this paper we study experimentally whether these assumption hold and show parallel to question investigated in cognitive science about the human visual system the insight gained from our analysis enable building a novel distance function between image assessing whether they are from the same basic level category this function go beyond direct visual distance a it also exploit semantic similarity measured through imagenet we demonstrate experimentally that it outperforms purely visual distance 
in this work we present a unified view on markov random field and recently proposed continuous tight convex relaxation for multi label assignment in the image plane these relaxation are far le biased towards the grid geometry than markov random field it turn out that the continuous method are non linear extension of the local polytope mrf relaxation in view of this result a better understanding of these tight convex relaxation in the discrete setting is obtained further a wider range of optimization method is now applicable to find a minimizer of the tight formulation we propose two method to improve the efficiency of minimization one us a weaker but more efficient continuously inspired approach a initialization and gradually refines the energy where it is necessary the other one reformulates the dual energy enabling smooth approximation to be used for efficient optimization we demonstrate the utility of our proposed minimization scheme in numerical experiment 
recently developed structure from motion sfm reconstruction approach enable the creation of large scale d model of urban scene these compact scene representation can then be used for accurate image based localization creating the need for localization approach that are able to efficiently handle such large amount of data an important bottleneck is the computation of d to d correspondence required for pose estimation current stateofthe art approach use indirect matching technique to accelerate this search in this paper we demonstrate that direct d to d matching method have a considerable potential for improving registration performance we derive a direct matching framework based on visual vocabulary quantization and a prioritized correspondence search through extensive experiment we show that our framework efficiently handle large datasets and outperforms current state of the art method 
image noise can present a serious problem in motion deblurring while most state of the art motion deblurring algorithm can deal with small level of noise in many case such a low light imaging the noise is large enough in the blurred image that it cannot be handled effectively by these algorithm in this paper we propose a technique for jointly denoising and deblurring such image that elevates the performance of existing motion deblurring algorithm our method take advantage of estimated motion blur kernel to improve denoising by constraining the denoised image to be consistent with the estimated camera motion i e no high frequency noise feature that do not match the motion blur this improved denoising then lead to higher quality blur kernel estimation and deblurring performance the two operation are iterated in this manner to obtain result superior to suppressing noise effect through regularization in deblurring or by applying denoising a a preprocess this is demonstrated in experiment both quantitatively and qualitatively using various image example 
sparse coding learns a set of basis function such that each input signal can be well approximated by a linear combination of just a few of the base it ha attracted increasing interest due to it state of the art performance in bow based image representation however when labeled and unlabeled image are sampled from different distribution they may be quantized into different visual word of the codebook and encoded with different representation which may severely degrade classification performance in this paper we propose a transfer sparse coding tsc approach to construct robust sparse representation for classifying cross distribution image accurately specifically we aim to minimize the distribution divergence between the labeled and unlabeled image and incorporate this criterion into the objective function of sparse coding to make the new representation robust to the distribution difference experiment show that tsc can significantly outperform state of the art method on three type of computer vision datasets 
we present a novel discriminative regression based approach for the constrained local model clms framework referred to a the discriminative response map fitting drmf method which show impressive performance in the generic face fitting scenario the motivation behind this approach is that unlike the holistic texture based feature used in the discriminative aam approach the response map can be represented by a small set of parameter and these parameter can be very efficiently used for reconstructing unseen response map furthermore we show that by adopting very simple off the shelf regression technique it is possible to learn robust function from response map to the shape parameter update the experiment conducted on multi pie xm vt and lfpw database show that the proposed drmf method outperforms state of the art algorithm for the task of generic face fitting moreover the drmf method is computationally very efficient and is real time capable the current matlab implementation take second per image to facilitate future comparison we release the matlab code and the pre trained model for research purpose 
we propose a method for accurate d shape reconstruction using uncalibrated multiview photometric stereo a coarse mesh reconstructed using multiview stereo is first parameterized using a planar mesh parameterization technique subsequently multiview photometric stereo is performed in the d parameter domain of the mesh where all geometric and photometric cue from multiple image can be treated uniformly unlike traditional method there is no need for merging view dependent surface normal map our key contribution is a new photometric stereo based mesh refinement technique that can efficiently reconstruct mesh with extremely fine geometric detail by directly estimating a displacement texture map in the d parameter domain we demonstrate that intricate surface geometry can be reconstructed using several challenging datasets containing surface with specular reflection multiple albedo and complex topology 
in this paper a random field topic rft model is proposed for semantic region analysis from motion of object in crowded scene different from existing approach of learning semantic region either from optical flow or from complete trajectory our model assumes that fragment of trajectory called tracklets are observed in crowded scene it advance the existing latent dirichlet allocation topic model by integrating the markov random field mrf a prior to enforce the spatial and temporal coherence between tracklets during the learning process two kind of mrf pairwise mrf and the forest of randomly spanning tree are defined another contribution of this model is to include source and sink a high level semantic prior which effectively improves the learning of semantic region and the clustering of tracklets experiment on a large scale data set which includes tracklets collected from the crowded new york grand central station show that our model outperforms state of the art method both on qualitative result of learning semantic region and on quantitative result of clustering tracklets 
this paper is about detecting and segmenting interrelated event which occur in challenging video with motion blur occlusion dynamic background and missing observation we argue that holistic reasoning about time interval of event and their temporal constraint is critical in such domain to overcome the noise inherent to low level video representation for this purpose our first contribution is the formulation of probabilistic event logic pel for representing temporal constraint among event a pel knowledge base consists of confidence weighted formula from a temporal event logic and specifies a joint distribution over the occurrence time interval of all event our second contribution is a map inference algorithm for pel that address the scalability issue of reasoning about an enormous number of time interval and their constraint in a typical video specifically our algorithm leverage the spanning interval data structure for compactly representing and manipulating entire set of time interval without enumerating them our experiment on interpreting basketball video show that pel inference is able to jointly detect event and identify their time interval based on noisy input from primitive event detector 
where doe the sparsity in image signal come from local and nonlocal image model have supplied complementary view toward the regularity in natural image the former attempt to construct or learn a dictionary of basis function that promotes the sparsity while the latter connects the sparsity with the self similarity of the image source by clustering in this paper we present a variational framework for unifying the above two view and propose a new denoising algorithm built upon clustering based sparse representation csr inspired by the success of l optimization we have formulated a double header l optimization problem where the regularization involves both dictionary learning and structural structuring a surrogate function based iterative shrinkage solution ha been developed to solve the double header l optimization problem and a probabilistic interpretation of csr model is also included our experimental result have shown convincing improvement over state of the art denoising technique bm d on the class of regular texture image the psnr performance of csr denoising is at least comparable and often superior to other competing scheme including bm d on a collection of generic natural image 
in this paper we focus on the problem of detecting object in d from rgb d image we propose a novel framework that explores the compatibility between segmentation hypothesis of the object in the image and the corresponding d map our framework allows to discover the optimal location of the object using a generalization of the structural latent svm formulation in d a well a the definition of a new loss function defined over the d space in training we evaluate our method using two existing rgb d datasets extensive quantitative and qualitative experimental result show that our proposed approach outperforms state of the art a method well a a number of baseline approach for both d and d object recognition task 
a camera raw file contains minimally processed data from the image sensor the content of the raw file include more information and potentially higher quality than the commonly used jpeg file but the raw file is typically several time larger than the jpeg file taking fewer image slower quick shooting and lack the standard file format not ready to use prolonging the image workflow these drawback limit it application in this paper we suggest a new hybrid image capture mode a high re jpeg file and a low re raw file a alternative of the original raw file most raw user can be benefited from such a combination to address this problem we provide an effective approach to reconstruct a high quality image by combining the advantage of two kind of file we formulate this reconstruction process a a global optimization problem by enforcing two constraint reconstruction constraint and detail consistency constraint the final recovered image is smaller than the full re raw file enables faster quick shooting and ha both richer information e g color space dynamic range lossless bit data and higher resolution in practice the functionality of capturing such a hybrid image pair in one shot ha been supported in some existing digital camera 
blind image deconvolution is an ill posed problem that requires regularization to solve however many common form of image prior used in this setting have a major drawback in that the minimum of the resulting cost function doe not correspond to the true sharp solution accordingly a range of additional method are needed to yield good result bayesian method adaptive cost function alpha matte extraction and edge localization in this paper we introduce a new type of image regularization which give lowest cost for the true sharp image this allows a very simple cost formulation to be used for the blind deconvolution model obviating the need for additional method due to it simplicity the algorithm is fast and very robust we demonstrate our method on real image with both spatially invariant and spatially varying blur 
active learning provides useful tool to reduce annotation cost without compromising classifier performance however it traditionally view the supervisor simply a a labeling machine recently a new interactive learning paradigm wa introduced that allows the supervisor to additionally convey useful domain knowledge using attribute the learner first conveys it belief about an actively chosen image e g i think this is a forest what do you think if the learner is wrong the supervisor provides an explanation e g no this is too open to be a forest with access to a pre trained set of relative attribute predictor the learner fetch all unlabeled image more open than the query image and us them a negative example of forest to update it classifier this rich human machine communication lead to better classification performance in this work we propose three improvement over this set up first we incorporate a weighting scheme that instead of making a hard decision reason about the likelihood of an image being a negative example second we do away with pre trained attribute and instead learn the attribute model on the fly alleviating overhead and restriction of a pre determined attribute vocabulary finally we propose an active learning framework that account for not just the label but also the attribute based feedback while selecting the next query image we demonstrate significant improvement in classification accuracy on face and shoe we also collect and make available the largest relative attribute dataset containing attribute of face from category 
we present a quadratic unconstrained binary optimization qubo framework for reasoning about multiple object detection with spatial overlap the method maximizes an objective function composed of unary detection confidence score and pairwise overlap constraint to determine which overlapping detection should be suppressed and which should be kept the framework is flexible enough to handle the problem of detecting object a a shape covering of a foreground mask and to handle the problem of filtering confidence weighted detection produced by a traditional sliding window object detector in our experiment we show that our method outperforms two existing state of the art pedestrian detector 
we present a technique for motion and size estimation of non line of sight nlos moving object in cluttered environment using a time of flight camera and multipath analysis we exploit relative time of arrival after reflection from a grid of point on a diffuse surface and create a virtual phased array by subtracting space time impulse response for successive frame we separate response of nlos moving object from those resulting from the cluttered environment after reconstructing the line of sight scene geometry we analyze the space of wavefront using the phased array and solve a constrained least square problem to recover the nlos target location importantly we can recover target s motion vector even in presence of uncalibrated time and pose bias common in time of flight system in addition we compute the upper bound on the size of the target by backprojecting the extremas of the time profile ability to track target inside room despite opaque occluders and multipath response ha numerous application in search and rescue medicine and defense we show centimeter accurate result by making appropriate modification to a time of flight system 
in graph based semi supervised learning approach the classification rate is highly dependent on the size of the availabel labeled data a well a the accuracy of the similarity measure here we propose a semi supervised multi class multi label classification scheme dynamic label propagation dlp which performs transductive learning through propagation in a dynamic process existing semi supervised classification method often have difficulty in dealing with multi class multi label problem due to the lack in consideration of label correlation our algorithm instead emphasizes dynamic metric fusion with label information significant improvement over the state of the art method is observed on benchmark datasets for both multi class and multi label task 
in this paper we tackle the problem of combining feature extracted from video for complex event recognition feature combination is an especially relevant task in video data a there are many feature we can extract ranging from image feature computed from individual frame to video feature that take temporal information into account to combine feature effectively we propose a method that is able to be selective of different subset of feature a some feature or feature combination may be uninformative for certain class we introduce a hierarchical method for combining feature based on the and or graph structure where node in the graph represent combination of different set of feature our method automatically learns the structure of the and or graph using score based structure learning and we introduce an inference procedure that is able to efficiently compute structure score we present promising result and analysis on the difficult and large scale trecvid multimedia event detection dataset 
we present a method for sampling from the posterior distribution of implicitly defined segmentation conditioned on the observed image segmentation is often formulated a an energy minimization or statistical inference problem in which either the optimal or most probable configuration is the goal exponentiating the negative energy functional provides a bayesian interpretation in which the solution are equivalent sampling method enable evaluation of distribution property that characterize the solution space via the computation of marginal event probability we develop a metropolis hastings sampling algorithm over level set which improves upon previous method by allowing for topological change while simultaneously decreasing computational time by order of magnitude an m ary extension to the method is provided 
this work make use of a novel recently proposed epipolar constraint for computing the relative pose between two calibrated image by enforcing the co planarity of epipolar plane normal vector it constrains the three degree of freedom of the relative rotation between two camera view directly independently of the translation the present paper show how the approach can be extended to n point and translated into an efficient eigenvalue minimization over the three rotational degree of freedom each iteration in the non linear optimization ha constant execution time independently of the number of feature two global optimization approach are proposed the first one consists of an efficient levenberg marquardt scheme with randomized initial value which already lead to stable and accurate result the second scheme consists of a globally optimal branch and bound algorithm based on a bound on the eigenvalue variation derived from symmetric eigenvalue perturbation theory analysis of the cost function reveals insight into the nature of a specific relative pose problem and outline the complexity under different condition the algorithm show state of the art performance w r t essential matrix based solution and a frame to frame application to a video sequence immediately lead to an alternative real time visual odometry solution 
hair play an important role in human appearance however hair segmentation is still a challenging problem partially due to the lack of an effective model to handle it arbitrary shape variation in this paper we present a part based model robust to hair shape and environment variation the key idea of our method is to identify local part by promoting the effectiveness of the part based model to this end we propose a measurable statistic called subspace clustering dependency sc dependency to estimate the co occurrence probability between local shape sc dependency guarantee output reasonability and allows u to evaluate the effectiveness of part wise constraint in an information theoretic way then we formulate the part identification problem a an mrf that aim to optimize the effectiveness of the potential function experiment are performed on a set of consumer image and show our algorithm s capability and robustness to handle hair shape variation and extreme environment condition 
this paper introduces pairwise constrained component analysis pcca a new algorithm for learning distance metric from sparse pairwise similarity dissimilarity constraint in high dimensional input space problem for which most existing distance metric learning approach are not adapted pcca learns a projection into a low dimensional space where the distance between pair of data point respect the desired constraint exhibiting good generalization property in presence of high dimensional data the paper also show how to efficiently kernelize the approach pcca is experimentally validated on two challenging vision task face verification and person re identification for which we obtain state of the art result 
we present a novel vanishing point detection algorithm for uncalibrated monocular image of man made environment we advance the state of the art by a new model of measurement error in the line segment extraction and minimizing it impact on the vanishing point estimation our contribution is twofold beyond existing hand crafted model we formally derive a novel consistency measure which capture the stochastic nature of the correlation between line segment and vanishing point due to the measurement error and use this new consistency measure to improve the line segment clustering we propose a novel minimum error vanishing point estimation approach by optimally weighing the contribution of each line segment pair in the cluster towards the vanishing point estimation unlike existing work our algorithm provides an optimal solution that minimizes the uncertainty of the vanishing point in term of the trace of it covariance in a closed form we test our algorithm and compare it with the state of the art on two public datasets york urban dataset and eurasian city dataset the experiment show that our approach outperforms the state of the art 
we introduce here an improved design of the uniform marker field and an algorithm for their fast and reliable detection our concept of the marker field is designed so that it can be detected and recognized for camera pose estimation in various lighting condition under a severe perspective while heavily occluded and under a strong motion blur our marker field detection harness the fact that the edge within the marker field meet at two vanishing point and that the projected planar grid of square can be defined by a detectable mathematical formalism the module of the grid are grey scale and the location within the marker field are defined by the edge between the module the assumption that the marker field is planar allows for a very cheap and reliable camera pose estimation in the captured scene the detection rate and accuracy are slightly better compared to state of the art marker based solution at the same time and more importantly our detector of the marker field is several time faster and the reliable real time detection can be thus achieved on mobile and low power device we show three targeted application where the planarity is assured and where the presented marker field design and detection algorithm provide a reliable and extremely fast solution 
detecting people remains a popular and challenging problem in computer vision in this paper we analyze part based model for person detection to determine which component of their pipeline could benefit the most if improved we accomplish this task by studying numerous detector formed from combination of component performed by human subject and machine the part based model we study can be roughly broken into four component feature detection part detection spatial part scoring and contextual reasoning including non maximal suppression our experiment conclude that part detection is the weakest link for challenging person detection datasets non maximal suppression and context can also significantly boost performance however the use of human or machine spatial model doe not significantly or consistently affect detection accuracy 
an object model base that cover a large number of object category is of great value for many computer vision task a artifact are usually designed to have various texture their structure is the primary distinguishing feature between different category thus how to encode this structural information and how to start the model learning with a minimum of human labeling become two key challenge for the construction of the model base we design a graphical model that us object edge to represent object structure and this paper aim to incrementally learn this category model from one labeled object and a number of casually captured scene however the incremental model learning may be biased due to the limited human labeling therefore we propose a new strategy that us the depth information in rgbd image to guide the model learning for object detection in ordinary rgb image in experiment the proposed method achieves superior performance a good a the supervised method that require the labeling of all target object 
we propose a method for recognizing attribute such a the gender hair style and type of clothes of people under large variation in viewpoint pose articulation and occlusion typical of personal photo album image robust attribute classifier under such condition must be invariant to pose but inferring the pose in itself is a challenging problem we use a part based approach based on poselets our part implicitly decompose the aspect the pose and viewpoint we train attribute classifier for each such aspect and we combine them together in a discriminative model we propose a new dataset of people with annotated attribute our method performs very well on this dataset significantly outperforming a baseline built on the spatial pyramid match kernel method on gender recognition we outperform a commercial face recognition system 
we present a novel algorithm for automatically applying constrainable l optimal camera path to generate stabilized video by removing undesired motion our goal is to compute camera path that are composed of constant linear and parabolic segment mimicking the camera motion employed by professional cinematographer to this end our algorithm is based on a linear programming framework to minimize the first second and third derivative of the resulting camera path our method allows for video stabilization beyond the conventional filtering of camera path that only suppresses high frequency jitter we incorporate additional constraint on the path of the camera directly in our algorithm allowing for stabilized and retargeted video our approach accomplishes this without the need of user interaction or costly d reconstruction of the scene and work a a post process for video from any camera or from an online source 
we propose an efficient approach that unifies activity categorization with space time localization the main idea is to pose activity detection a a maximum weight connected subgraph problem over a learned space time graph constructed on the test sequence we show this permit an efficient branch and cut solution for the best scoring and possibly non cubically shaped portion of the video for a given activity classifier the upshot is a fast method that can evaluate a broader space of candidate than wa previously practical which we find often lead to more accurate detection we demonstrate the proposed algorithm on three datasets and show it speed and accuracy advantage over multiple existing search strategy 
we present a statistical model of aerial image of recreational trail and a method to infer trail route in such image we learn a set of textons describing the image and use them to divide the image into super pixel represented by their text on we then learn for each text on the frequency of generating on trail and off trail pixel and the direction of trail through on trail pixel from these we derive an image likelihood function we combine that with a prior model of trail length and smoothness yielding a posterior distribution for trail given an image we search for good value of this posterior using a novel stochastic variation of dijkstra s algorithm our experiment on trail image and ground truth collected in the western continental usa show substantial improvement over those of the previous best trail finding method 
we address the effect of noise in low light image in this paper color image are usually captured by a sensor with a color filter array cfa this requires a demosaicing process to generate a full color image the captured image typically have low signal to noise ratio and the demosaicing step further corrupts the image which we show to be the leading cause of visually objectionable random noise pattern splotch to avoid this problem we propose a combined framework of denoising and demosaicing where we use information about the image inferred in the denoising step to perform demosaicing our experiment show that such a framework result in sharper low light image that are devoid of splotch and other noise artifact 
we present a novel method for recovering the d structure and scene flow from calibrated multi view sequence we propose a d point cloud parametrization of the d structure and scene flow that allows u to directly estimate the desired unknown a unified global energy functional is proposed to incorporate the information from the available sequence and simultaneously recover both depth and scene flow the functional enforces multi view geometric consistency and imposes brightness constancy and piecewise smoothness assumption directly on the d unknown it inherently handle the challenge of discontinuity occlusion and large displacement the main contribution of this work is the fusion of a d representation and an advanced variational framework that directly us the available multi view information this formulation allows u to advantageously bind the d unknown in time and space different from optical flow and disparity the proposed method result in a nonlinear mapping between the image coordinate thus giving rise to additional challenge in the optimization process our experiment on real and synthetic data demonstrate that the proposed method successfully recovers the d structure and scene flow despite the complicated nonconvex optimization problem 
we develop a generative probabilistic model for temporally consistent super pixel in video sequence in contrast to supermodel method object part in different frame are tracked by the same temporal super pixel we explicitly model flow between frame with a bilateral gaussian process and use this information to propagate super pixel in an online fashion we consider four novel metric to quantify performance of a temporal super pixel representation and demonstrate superior performance when compared to supermodel method 
in this paper we introduce a new method to detect salient object in image the approach is based on the standard structure of cognitive visual attention model but realizes the computation of saliency in each feature dimension in an information theoretic way the method allows a consistent computation of all feature channel and a well founded fusion of these channel to a saliency map our framework enables the computation of arbitrarily scaled feature and local center surround pair in an efficient manner we show that our approach outperforms eight state of the art saliency detector in term of precision and recall 
we propose a generic method for obtaining nonparametric image warp from noisy point correspondence our formulation integrates a huber function into a motion coherence framework this make our fitting function especially robust to piecewise correspondence noise where an image section is consistently mismatched by utilizing over parameterized curve we can generate realistic nonparametric image warp from very noisy correspondence we also demonstrate how our algorithm can be used to help stitch image taken from a panning camera by warping the image onto a virtual push broom camera imaging plane 
tag of image region are often arranged in a hierarchical taxonomy based on their semantic meaning in this paper using the given tag taxonomy we propose to jointly learn multi layer hierarchical dictionary and corresponding linear classifier for region tagging specifically we generate a node specific dictionary for each tag node in the taxonomy and then concatenate the node specific dictionary from each level to construct a level specific dictionary the hierarchical semantic structure among tag is preserved in the relationship among node dictionary simultaneously the sparse code obtained using the level specific dictionary are summed up a the final feature representation to design a linear classifier our approach not only make use of sparse code obtained from higher level to help learn the classifier for lower level but also encourages the tag node from lower level that have the same parent tag node to implicitly share sparse code obtained from higher level experimental result using three benchmark datasets show that the proposed approach yield the best performance over recently proposed method 
we present a method to track the precise shape of a dynamic object in video joint dynamic shape and appearance model in which a template of the object is propagated to match the object shape and radiance in the next frame are advantageous over method employing global image statistic in case of complex object radiance and cluttered background in case of complex d object motion and relative viewpoint change self occlusion and disocclusions of the object are prominent and current method employing joint shape and appearance model are unable to accurately adapt to new shape and appearance information leading to inaccurate shape detection in this work we model self occlusion and dis occlusion in a joint shape and appearance tracking framework experiment on video exhibiting occlusion dis occlusion complex radiance and background show that occlusion dis occlusion modeling lead to superior shape accuracy compared to recent method employing joint shape appearance model or employing global statistic 
pairwise discrete energy defined over graph are ubiquitous in computer vision many algorithm have been proposed to minimize such energy often concentrating on sparse graph topology or specialized class of pairwise potential however when the graph is fully connected and the pairwise potential are arbitrary the complexity of even approximate minimization algorithm such a trw s grows quadratically both in the number of node and in the number of state a node can take moreover recent application are using more and more computationally expensive pairwise potential these factor make it very hard to employ fully connected model in this paper we propose a novel generic algorithm to approximately minimize any discrete pairwise energy function our method exploit tractable sub energy to filter the domain of the function the parameter of the filter are learnt from instance of the same class of energy with good candidate solution compared to existing method it efficiently handle fully connected graph with many state per node and arbitrary pairwise potential which might be expensive to compute we demonstrate experimentally on two application that our algorithm is much more efficient than other generic minimization algorithm such a trw s while returning essentially identical solution 
this paper describes a method of finding thin elongated structure in image and volume we use shortest path to minimize very general functionals of higher order curve property such a curvature and torsion our globally optimal method us line graph and it runtime is polynomial in the size of the discretization often in the order of second on a single computer to our knowledge we are the first to perform experiment in three dimension with curvature and torsion regularization the largest graph we process have almost one hundred billion arc experiment on medical image and in multi view reconstruction show the significance and practical usefulness of regularization based on curvature while torsion is still only tractable for small scale problem 
we propose an image classification framework by leveraging the non negative sparse coding low rank and sparse matrix decomposition technique lr sc spm first we propose a new non negative sparse coding along with max pooling and spatial pyramid matching method sc spm to extract local feature information in order to represent image where non negative sparse coding is used to encode local feature max pooling along with spatial pyramid matching spm is then utilized to get the feature vector to represent image second motivated by the observation that image of the same class often contain correlated or common item and specific or noisy item we propose to leverage the low rank and sparse matrix recovery technique to decompose the feature vector of image per class into a low rank matrix and a sparse error matrix to incorporate the common and specific attribute into the image representation we still adopt the idea of sparse coding to recode the sc spm representation of each image in particular we collect the column of the both matrix a the base and use the coding parameter a the updated image representation by learning them through the locality constrained linear coding llc finally linear svm classifier is leveraged for the final classification experimental result show that the proposed method achieves or outperforms the state of the art result on several benchmark 
estimating missing value in visual data is a challenging problem in computer vision which can be considered a a low rank matrix approximation problem most of the recent study use the nuclear norm a a convex relaxation of the rank operator however by minimizing the nuclear norm all the singular value are simultaneously minimized and thus the rank can not be well approximated in practice in this paper we propose a novel matrix completion algorithm based on the truncated nuclear norm regularization tnnr by only minimizing the smallest n r singular value where n is the number of singular value and r is the rank of the matrix in this way the rank of the matrix can be better approximated than the nuclear norm we further develop an efficient iterative procedure to solve the optimization problem by using the alternating direction method of multiplier and the accelerated proximal gradient line search method experimental result in a wide range of application demonstrate the effectiveness of our proposed approach 
we propose a framework that performs action recognition and identity maintenance of multiple target simultaneously instead of first establishing track using an appearance model and then performing action recognition we construct a network flow based model that link detected bounding box across video frame while inferring activity thus integrating identity maintenance and action recognition inference in our model reduces to a constrained minimum cost flow problem which we solve exactly and efficiently by leveraging both appearance similarity and action transition likelihood our model improves on state of the art result on action recognition for two datasets 
this paper present a multiscale curvature based shape representation technique for general genus zero closed surface the method is invariant under rotation translation scaling or general isometric deformation it is robust to noise and preserve intrinsic symmetry the method is a direct generalization of the curvature scale space cs shape descriptor for planar curve in our method the riemannian metric of the surface is deformed under ricci flow such that the gaussian curvature evolves according to a heat diffusion process eventually the surface becomes a sphere with constant positive curvature everywhere the evolution of zero curvature curve on the surface is utilized a the shape descriptor our experimental result on a d geometric database with about shape demonstrate the efficiency and efficacy of the method 
a early stage of video processing we introduce an iterative trajectory merging algorithm that produce a region based and hierarchical representation of the video sequence called the trajectory binary partition tree bpt from this representation many analysis and graph cut technique can be used to extract partition or object that are useful in the context of specific application in order to define trajectory and to create a precise merging algorithm color and motion cue have to be used both type of information are very useful to characterize object but present strong difference of behavior in the spatial and the temporal dimension on the one hand scene and object are rich in their spatial color distribution but these distribution are rather stable over time object motion on the other hand present simple structure and low spatial variability but may change from frame to frame the proposed algorithm take into account this key difference and relies on different model and associated metric to deal with color and motion information we show that the proposed algorithm outperforms existing hierarchical video segmentation algorithm and provides more stable and precise region 
radiometric image analysis method heavily rely on reflectance model due to the complexity of real material method based on simple model such a the lambertian model often suffer from inaccuracy on the other hand more advanced model such a the cook torrance model severely complicate the analysis problem we tackle this dilemma by focusing on the low frequency component of the reflectance we propose a compact biquadratic reflectance model to represent the reflectance of a broad class of material precisely in the low frequency domain we validate our model by fitting to both existing parametric model and non parametric measured data and show that our model outperforms existing parametric diffuse model we show application of reflectometry using general diffuse surface and photometric stereo for general isotropic material experimental result show the effectiveness of our biquadratic model and it usefulness in radiometric image analysis 
image annotation is usually formulated a a multi label semi supervised learning problem traditional graph based method only utilize the data image graph induced from image similarity while ignore the label semantic term graph induced from label correlation of a multi label image data set in this paper we propose a novel bi relational graph bg model that comprises both the data graph and the label graph a subgraphs and connect them by an additional bipartite graph induced from label assignment by considering each class and it labeled image a a semantic group we perform random walk on the bg to produce group to vertex relevance including class to image and class to class relevance the former can be used to predict label for unannotated image while the latter are new class relationship called a causal relationship cr which are asymmetric cr is learned from input data and ha better semantic meaning to enhance the label prediction for unannotated image we apply the proposed approach to automatic image annotation and semantic image retrieval task on four benchmark multi label image data set the superior performance of our approach compared to state of the art multi label classification method demonstrate their effectiveness 
we discus a model for image segmentation that is able to overcome the short boundary bias observed in standard pairwise random field based approach to wit we show that a random field with multi layered hidden unit can encode boundary preserving higher order potential such a the one used in the cooperative cut model of while still allowing for fast and exact map inference exact inference allows our model to outperform previous image segmentation method and to see the true effect of coupling graph edge finally our model can be easily extended to handle segmentation instance with multiple label for which it yield promising result 
currently bag of visual word bovw and part based method are the most popular approach for visual recognition in both case a mid level representation is built on top of low level image descriptor and top level classifier use this mid level representation to achieve visual recognition while in current part based approach midand top level representation are usually jointly trained this is not the usual case for bovw scheme a main reason for this is the complex data association problem related to the usual large dictionary size needed by bovw approach a a further observation typical solution based on bovw and part based representation are usually limited to extension of binary classification scheme a strategy that ignores relevant correlation among class in this work we propose a novel hierarchical approach to visual recognition based on a bovw scheme that jointly learns suitable midand top level representation furthermore using a max margin learning framework the proposed approach directly handle the multiclass case at both level of abstraction we test our proposed method using several popular benchmark datasets a our main result we demonstrate that by coupling learning of midand top level representation the proposed approach foster sharing of discriminative visual word among target class being able to achieve state of the art recognition performance using far le visual word than previous approach 
we present a scanning method that recovers dense sub pixel camera projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry sub pixel accuracy is achieved by considering several zero crossing defined by the difference between pair of unstructured pattern we use gray level band pas white noise pattern that increase robustness to indirect lighting and scene discontinuity simulated and experimental result show that our method recovers scene geometry with high sub pixel precision and that it can handle many challenge of active reconstruction system we compare our result to state of the art method such a micro phase shifting and modulated phase shifting 
catheter tracking ha become more and more important in recent interventional application it provides real time navigation for the physician and can be used to control a motion compensated fluoro overlay reference image for other mean of guidance e g involving a d anatomical model tracking the coronary sinus c catheter is effective to compensate respiratory and cardiac motion for d overlay navigation to assist positioning the ablation catheter in atrial fibrillation afib treatment during intervention the c catheter performs rapid motion and non rigid deformation due to the beating heart and respiration in this paper we model the c catheter a a set of electrode novelly designed hypothesis generated by a number of learning based detector are fused robust hypothesis matching through a bayesian framework is then used to select the best hypothesis for each frame a a result our tracking method achieves very high robustness against challenging scenario such a low snr occlusion foreshortening non rigid deformation a well a the catheter moving in and out of roi quantitative evaluation ha been conducted on a database of frame from sequence our approach obtains mm median error and mm mean error of evaluated data have error le than mm the speed of our tracking algorithm reach frame per second on most data set our approach is not limited to the catheter inside the c but can be extended to track other type of catheter such a ablation catheter or circumferential mapping catheter 
the bag of word bow model treat image a an unordered set of local region and represents them by visual word histogram implicitly region are assumed to be identically and independently distributed iid which is a poor assumption from a modeling perspective we introduce non iid model by treating the parameter of bow model a latent variable which are integrated out rendering all local region dependent using the fisher kernel we encode an image by the gradient of the data log likelihood w r t hyper parameter that control prior on the model parameter our representation naturally involves discounting transformation similar to taking square root providing an explanation of why such transformation have proven successful using variational inference we extend the basic model to include gaussian mixture over local descriptor and latent topic model to capture the co occurrence structure of visual word both improving performance our model yield state of the art categorization performance using linear classifier without using non linear transformation such a taking square root of feature or using approximate explicit embeddings of non linear kernel 
in this paper we propose a long term motion model for visual object tracking in crowded street scene persistent occlusion are a frequent challenge for tracking algorithm and a robust long term motion model could help in these situation motivated by progress in robot motion planning we propose to construct a set of plausible plan for each person which are composed of multiple long term motion prediction hypothesis that do not include redundancy unnecessary loop or collision with other object constructing plausible plan is the key step in utilizing motion planning in object tracking which ha not been fully investigate in robot motion planning we propose a novel method of efficiently constructing disjoint plan in different homotopy class based on winding number and winding angle of planned path around all obstacle a the goal can be specified by winding number and winding angle we can avoid redundant plan in the same homotopy class and multiple whirl or loop around a single obstacle we test our algorithm on a challenging real world dataset and compare our algorithm with linear trajectory avoidance and a simplified linear planning model we find that our algorithm outperforms both algorithm in most sequence 
this paper present a novel approach to recovering temporally coherent estimate of d structure of a dynamic scene from a sequence of binocular stereo image the approach is based on matching spatiotemporal orientation distribution between left and right temporal image stream which encapsulates both local spatial and temporal structure for disparity estimation by capturing spatial and temporal structure in this unified fashion both source of information combine to yield disparity estimate that are naturally temporal coherent while helping to resolve match that might be ambiguous when either source is considered alone further by allowing subset of the orientation measurement to support different disparity estimate an approach to recovering multilayer disparity from spacetime stereo is realized the approach ha been implemented with real time performance on commodity gpus empirical evaluation show that the approach yield qualitatively and quantitatively superior disparity estimate in comparison to various alternative approach including the ability to provide accurate multilayer estimate in the presence of semi transparent and specular surface 
convexity concavity is a bottom up cue to assign figure ground relation in the perceptual organization it suggests that region on the convex side of a curved boundary tend to be figural to explore the validity of this cue in the task of salient object detection we segment the image in a test dataset into superpixels and then locate the concave arc and their bounding box along boundary of superpixels ecological statistic indicate that such bounding box contains salient object with a large probability to utilize this spatial context information i e concavity context we follow the multi scale analysis of human visual perception and design a hierarchical model the model yield an affinity graph over candidate superpixels in which weight between vertex are determined by the summation of concavity context on different scale in the hierarchy finally a graph cut algorithm is performed to separate the salient and background object evaluation on msra salient object detection sod dataset show that concavity context is effective and our approach provides improvement over state of the art feature based algorithm 
in this paper we introduce a probabilistic approach on multiple person localization using multiple calibrated camera view people present in the scene are approximated by a population of cylinder object in the d world coordinate system which is a realization of a marked point process the observation model is based on the projection of the pixel of the obtained motion mask in the different camera image to the ground plane and to other parallel plane with different height the proposed pixel level feature is based on physical property of the d image formation process and can accurately localize the leg position on the ground plane and estimate the height of the people even if the area of interest is only a part of the scene meanwhile silhouette from irrelevant outside motion may significantly overlap with the monitored region in some of the camera view we introduce an energy function which contains a data term calculated from the extracted feature and a geometrical constraint term modeling the distance between two people the final configuration result location and height are obtained by an iterative stochastic energy optimization process called the multiple birth and death dynamic the proposed approached is compared to a recent state of the art technique in a publicly available dataset and it advantage are quantitatively demonstrated 
we present an approach to discover and segment foreground object s in video given an unannotated video sequence the method first identifies object like region in any frame according to both static and dynamic cue we then compute a series of binary partition among those candidate key segment to discover hypothesis group with persistent appearance and motion finally using each ranked hypothesis in turn we estimate a pixel level object labeling across all frame where a the foreground likelihood depends on both the hypothesis s appearance a well a a novel localization prior based on partial shape matching and b the background likelihood depends on cue pulled from the key segment possibly diverse surroundings observed across the sequence compared to existing method our approach automatically focus on the persistent foreground region of interest while resisting oversegmentation we apply our method to challenging benchmark video and show competitive or better result than the state of the art 
in this paper we propose a low rank sparse coding lrsc method that exploit local structure information among feature in an image for the purpose of image level classification lrsc represents densely sampled sift descriptor in a spatial neighborhood collectively a low rank sparse linear combination of code word a such it cast the feature coding problem a a low rank matrix learning problem which is different from previous method that encode feature independently this lrsc ha a number of attractive property it encourages sparsity in feature code locality in codebook construction and low rankness for spatial consistency lrsc encodes local feature jointly by considering their low rank structure information and is computationally attractive we evaluate the lrsc by comparing it performance on a set of challenging benchmark with that of popular coding and other state of the art method our experiment show that by representing local feature jointly lrsc not only outperforms the state of the art in classification accuracy but also improves the time complexity of method that use a similar sparse linear representation model for feature coding 
we present an approach to jointly solve the segmentation and recognition problem using a multiple segmentation framework we formulate the problem a segment selection from a pool of segment assigning each selected segment a class label previous multiple segmentation approach used local appearance matching to select segment in a greedy manner in contrast our approach formulates a cost function based on contextual information in conjunction with appearance matching this relaxed cost function formulation is minimized using an efficient quadratic programming solver and an approximate solution is obtained by discretizing the relaxed solution our approach improves labeling performance compared to other segmentation based recognition approach 
this work address the challenging problem of unconstrained d human pose estimation hpe from a novel perspective existing approach struggle to operate in realistic application mainly due to their scene dependent prior such a background segmentation and multi camera network which restrict their use in unconstrained environment we therfore present a framework which applies action detection and d pose estimation technique to infer d pose in an unconstrained video action detection offer spatiotemporal prior to d human pose estimation by both recognising and localising action in space time instead of holistic feature e g silhouette we leverage the flexibility of deformable part model to detect d body part a a feature to estimate d pose a new unconstrained pose dataset ha been collected to justify the feasibility of our method which demonstrated promising result significantly outperforming the relevant state of the art 
hyperspectral image provide higher spectral resolution than typical rgb image by including per pixel irradiance measurement in a number of narrow band of wavelength in the visible spectrum the additional spectral resolution may be useful for many visual task including segmentation recognition and relighting vision system that seek to capture and exploit hyperspectral data should benefit from statistical model of natural hyperspectral image but at present relatively little is known about their structure using a new collection of fifty hyperspectral image of indoor and outdoor scene we derive an optimized spatio spectral basis for representing hyperspectral image patch and explore statistical model for the coefficient in this basis 
we present alternating regression forest arfs a novel regression algorithm that learns a random forest by optimizing a global loss function over all tree this interrelates the information of single tree during the training phase and result in more accurate prediction arfs can minimize any differentiable regression loss without sacrificing the appealing property of random forest like low computational complexity during both training and testing inspired by recent development for classification we derive a new algorithm capable of dealing with different regression loss function discus it property and investigate the relation to other method like boosted tree we evaluate arfs on standard machine learning benchmark where we observe better generalization power compared to both standard random forest and boosted tree moreover we apply the proposed regressor to two computer vision application object detection and head pose estimation from depth image arfs outperform the random forest baseline in both task illustrating the importance of optimizing a common loss function for all tree 
recent work ha shown that visual attribute are a powerful approach for application such a recognition image description and retrieval however fusing multiple attribute score a required during multi attribute query or similarity search present a significant challenge score from different attribute classifier cannot be combined in a simple way the same score for different attribute can mean different thing in this work we show how to construct normalized multi attribute space from raw classifier output using technique based on the statistical extreme value theory our method calibrates each raw score to a probability that the given attribute is present in the image we describe how these probability can be fused in a simple way to perform more accurate multiattribute search a well a enable attribute based similarity search a significant advantage of our approach is that the normalization is done after the fact requiring neither modification to the attribute classification system nor ground truth attribute annotation we demonstrate result on a large data set of nearly million face image and show significant improvement over prior work we also show that perceptual similarity of search result increase by using contextual attribute 
we present a new descriptor for activity recognition from video acquired by a depth sensor previous descriptor mostly compute shape and motion feature independently thus they often fail to capture the complex joint shape motion cue at pixel level in contrast we describe the depth sequence using a histogram capturing the distribution of the surface normal orientation in the d space of time depth and spatial coordinate to build the histogram we create d projector which quantize the d space and represent the possible direction for the d normal we initialize the projector using the vertex of a regular polychoron consequently we refine the projector using a discriminative density measure such that additional projector are induced in the direction where the d normal are more dense and discriminative through extensive experiment we demonstrate that our descriptor better capture the joint shape motion cue in the depth sequence and thus outperforms the state of the art on all relevant benchmark 
this paper proposes novel algorithm that use network flow and set cover technique to perform occlusion reasoning for a large number of small moving object in single or multiple view we designed a track linking framework for reasoning about short term and long term occlusion we introduce a two stage network flow process to automatically construct a track graph that describes the track merging and splitting event caused by occlusion to explain short term occlusion when local information is sufficient to distinguish object the process link trajectory segment through a series of optimal bipartite graph match to resolve long term occlusion when global information is needed to characterize object the linking process computes a logarithmic approximation solution to the set cover problem if multiple view are available our method build a track graph independently for each view and then simultaneously link track segment from each graph solving a joint set cover problem for which a logarithmic approximation also exists through experiment on different datasets we show that our proposed linear and integer optimization technique make the track graph a particularly useful tool for tracking large group of individual in image 
combining foreground image from multiple view by projecting them onto a common ground plane ha been recently applied within many multi object tracking approach these planar projection introduce severe artifact and constrain most approach to object moving on a common d ground plane to overcome these limitation we introduce the concept of an occupancy volume exploiting the full geometry and the object center of mass and develop an efficient algorithm for d object tracking individual object are tracked using the local mass density score within a particle filter based approach constrained by a voronoi partitioning between nearby tracker our method benefit from the geometric knowledge given by the occupancy volume to robustly extract feature and train classifier on demand when volumetric information becomes unreliable we evaluate our approach on several challenging real world scenario including the public apidis dataset experimental evaluation demonstrate significant improvement compared to state of the art method while achieving real time performance 
nearly every structured prediction problem in computer vision requires approximate inference due to large and complex dependency among output label while graphical model provide a clean separation between modeling and inference learning these model with approximate inference is not well understood furthermore even if a good model is learned prediction are often inaccurate due to approximation in this work instead of performing inference over a graphical model we instead consider the inference procedure a a composition of predictor specifically we focus on message passing algorithm such a belief propagation and show how they can be viewed a procedure that sequentially predict label distribution at each node over a graph given labeled graph we can then train the sequence of predictor to output the correct labeling s the result no longer corresponds to a graphical model but simply defines an inference procedure with strong theoretical property that can be used to classify new graph we demonstrate the scalability and efficacy of our approach on d point cloud classification and d surface estimation from single image 
in this paper we propose a novel nonparametric image parsing method for the image parsing problem in certain environment a novel and efficient nearest neighbor matching scheme the ann bilateral matching scheme is proposed based on the proposed matching scheme we first retrieve some partially similar image for each given test image from the training image database the test image can be well explained by these retrieved image with similar region existing in the retrieved image for each region in the test image then we match the test image to the retrieved training image with the ann bilateral matching scheme and parse the test image by integrating multiple cue in a markov random field experiment on three datasets show our method achieved promising parsing accuracy and outperformed two state of the art nonparametric image parsing method 
we explore recently proposed bayesian nonparametric model of image partition based on spatially dependent pitman yor process these model are attractive because they adapt to image of varying complexity successfully modeling uncertainty in the structure and scale of human segmentation of natural scene by developing substantially improved inference and learning algorithm we achieve performance comparable to state of the art method for learning we show how the gaussian process gp covariance function underlying these model can be calibrated to accurately match the statistic of example human segmentation for inference we develop a stochastic search based algorithm which is substantially le susceptible to local optimum than conventional variational method our approach utilizes the expectation propagation algorithm to approximately marginalize latent gps and a low rank covariance representation to improve computational efficiency experiment with two benchmark datasets show that our learning and inference innovation substantially improve segmentation accuracy by hypothesizing multiple partition for each image we also take step towards capturing the variability of human scene interpretation 
we employ hierarchical data association to track player in team sport player movement are often complex and highly correlated with both nearby and distant player a single model would require many degree of freedom to represent the full motion diversity and could be difficult to use in practice instead we introduce a set of game context feature extracted from noisy detection to describe the current state of the match such a how the player are spatially distributed our assumption is that player react to the current situation in only a finite number of way a a result we are able to select an appropriate simplified affinity model for each player and time instant using a random decision forest based on current track and game context feature our context conditioned motion model implicitly incorporate complex inter object correlation while remaining tractable we demonstrate significant performance improvement over existing multi target tracking algorithm on basketball and field hockey sequence several minute in duration and containing and player respectively 
statistic of natural image provides useful prior for solving under constrained problem in computer vision such statistic is usually obtained from large collection of natural image we claim that the substantial internal data redundancy within a single natural image e g recurrence of small image patch give rise to powerful internal statistic obtained directly from the image itself while internal patch recurrence ha been used in various application we provide a parametric quantification of this property we show that the likelihood of an image patch to recur at another image location can be expressed parametricly a a function of the spatial distance from the patch and it gradient content this internal parametric prior is used to improve existing algorithm that rely on patch recurrence moreover we show that internal image specific statistic is often more powerful than general external statistic giving rise to more powerful image specific prior in particular i patch tend to recur much more frequently densely inside the same image than in any random external collection of natural image ii to find an equally good external representative patch for all the patch of an image requires an external database of hundred of natural image iii internal statistic often ha stronger predictive power than external statistic indicating that it may potentially give rise to more powerful image specific prior 
we present a model and an algorithm to detect salient region in video taken from a moving camera in particular we are interested in capturing small object that move independently in the scene such a vehicle and people a seen from aerial or ground vehicle many of the scenario of interest challenge existing scheme based on background subtraction background motion too complex multi body motion estimation insufficient parallax and occlusion detection uniformly textured background region we adopt a robust statistical inference approach to simultaneously estimate a maximally reduced regressor and select region that violate the null hypothesis co visibility under an epipolar domain deformation a salient we show that our algorithm can perform even in the absence of camera calibration information while the resulting motion estimate would be incorrect the partition of the domain into salient v non salient is unaffected we demonstrate our algorithm on video footage from helicopter airplane and ground vehicle 
recently sparse representation ha been applied to visual tracking to find the target with the minimum reconstruction error from the target template subspace though effective these l tracker require high computational cost due to numerous calculation for minimization in addition the inherent occlusion insensitivity of the minimization ha not been fully utilized in this paper we propose an efficient l tracker with minimum error bound and occlusion detection which we call bounded particle resampling bpr l tracker first the minimum error bound is quickly calculated from a linear least square equation and serf a a guide for particle resampling in a particle filter framework without loss of precision during resampling most insignificant sample are removed before solving the computationally expensive minimization function the bpr technique enables u to speed up the l tracker without sacrificing accuracy second we perform occlusion detection by investigating the trivial coefficient in the minimization these coefficient by design contain rich information about image corruption including occlusion detected occlusion enhance the template update to effectively reduce the drifting problem the proposed method show good performance a compared with several state of the art tracker on challenging benchmark sequence 
in this paper we cast the problem of graph matching a one of non rigid manifold alignment the low dimensional manifold are from the commute time embedding and are matched though coherent point drift although there have been a number of attempt to realise graph matching in this way in this paper we propose a novel information theoretic measure of alignment the so called symmetrized normalized entropy square variation we successfully test this dissimilarity measure between manifold on a a challenging database the measure is estimated by mean of the bypass leonenko entropy functional in addition we prove that the proposed measure induces a positive definite kernel between the probability density function associated with the manifold and hence between graph after deformation in our experiment we find that the optimal embedding is associated to the commute time distance and we also find that our approach which is purely topological outperforms several state of the art graph based algorithm for point matching 
in this paper we propose a novel weakly supervised dual clustering wsdc approach for image semantic segmentation with image level label i e collaboratively performing image segmentation and tag alignment with those region the proposed approach is motivated from the observation that super pixel belonging to an object class usually exist across multiple image and hence can be gathered via the idea of clustering in wsdc spectral clustering is adopted to cluster the super pixel obtained from a set of over segmented image at the same time a linear transformation between feature and label a a kind of discriminative clustering is learned to select the discriminative feature among different class the both clustering output should be consistent a much a possible besides weakly supervised constraint from image level label are imposed to restrict the labeling of super pixel finally the non convex and non smooth objective function are efficiently optimized using an iterative cccp procedure extensive experiment conducted on msrc and label me datasets demonstrate the encouraging performance of our method in comparison with some state of the art 
deformable part model have achieved impressive performance for object detection even on difficult image datasets this paper explores the generalization of deformable part model from d image to d spatiotemporal volume to better study their effectiveness for action detection in video action are treated a spatiotemporal pattern and a deformable part model is generated for each action from a collection of example for each action model the most discriminative d sub volume are automatically selected a part and the spatiotemporal relation between their location are learned by focusing on the most distinctive part of each action our model adapt to intra class variation and show robustness to clutter extensive experiment on several video datasets demonstrate the strength of spatiotemporal dpms for classifying and localizing action 
general purpose blind image quality assessment biqa ha been recently attracting significant attention in the field of image processing vision and machine learning state of the art biqa method usually learn to evaluate the image quality by regression from human subjective score of the training sample however these method need a large number of human scored image for training and lack an explicit explanation of how the image quality is affected by image local feature an interesting question is then can we learn for effective biqa without using human scored image this paper make a good effort to answer this question we partition the distorted image into overlapped patch and use a percentile pooling strategy to estimate the local quality of each patch then a quality aware clustering qac method is proposed to learn a set of centroid on each quality level these centroid are then used a a codebook to infer the quality of each patch in a given image and subsequently a perceptual quality score of the whole image can be obtained the proposed qac based biqa method is simple yet effective it not only ha comparable accuracy to those method using human scored image in learning but also ha merit such a high linearity to human perception of image quality real time implementation and availability of image local quality map 
this paper proposes a novel approach to recognize object category in point cloud by quantizing d surf local descriptor computed on partial d shape extracted from the point cloud a vocabulary of d visual word is generated using this codebook we build a bag of word representation in d which is used in conjunction with a svm classification machinery we also introduce the d spatial pyramid matching kernel which work by partitioning a working volume into fine sub volume and computing a hierarchical weighted sum of histogram intersection at each level of the pyramid structure with the aim of increasing both the classification accuracy and the computational efficiency of the kernel we propose selective hierarchical volume decomposition strategy based on representative and discriminative sub volume selection process which drastically reduce the pyramid to consider result on the challenging large scale rgb d object dataset show that our kernel significantly outperform the state of the art result by using a single d shape feature type extracted from individual depth image 
in this paper we study the geometry problem of estimating camera pose with unknown focal length using combination of geometric primitive we consider point line and also rich feature such a quiver i e point with one or more direction we formulate the problem a polynomial system where the constraint for different primitive are handled in a unified way we develop efficient polynomial solver for each of the derived case with different combination of primitive the availability of these solver enables robust pose estimation with unknown focal length for wider class of feature such rich feature allow for fewer feature correspondence and generate larger inlier set with higher probability we demonstrate in synthetic experiment that our solver are fast and numerically stable for real image we show that our solver can be used in ransac loop to provide good initial solution 
conditional random field crfs provide powerful tool for building model to label image segment they are particularly well suited to modeling local interaction among adjacent region e g super pixel however crfs are limited in dealing with complex global long range interaction between region complementary to this restricted boltzmann machine rbms can be used to model global shape produced by segmentation model in this work we present a new model that us the combined power of these two network type to build a state of the art labeler although the crf is a good baseline labeler we show how an rbm can be added to the architecture to provide a global shape bias that complement the local modeling provided by the crf we demonstrate it labeling performance for the part of complex face image from the labeled face in the wild data set this hybrid model produce result that are both quantitatively and qualitatively better than the crf alone in addition to high quality labeling result we demonstrate that the hidden unit in the rbm portion of our model can be interpreted a face attribute that have been learned without any attribute level supervision 
approximate nearest neighbor search anns is a basic and important technique used in many task such a object recognition it involves two process selecting nearest neighbor candidate and performing a brute force search of these candidate only the former though ha scope for improvement in most existing method it approximates the space by quantization it then calculates all the distance between the query and all the quantized value e g cluster or bit sequence and selects a fixed number of candidate close to the query the performance of the method is evaluated based on accuracy a a function of the number of candidate this evaluation seems rational but pose a serious problem it ignores the computational cost of the process of selection in this paper we propose a new anns method that take into account cost in the selection process whereas existing method employ computationally expensive technique such a comparative sort and heap the proposed method doe not this realizes a significantly more efficient search we have succeeded in reducing computation time by one third compared with the state of theart on an experiment using million sift feature 
although facial feature detection from d image is a well studied field there is a lack of real time method that estimate feature point even on low quality image here we propose conditional regression forest for this task while regression forest learn the relation between facial image patch and the location of feature point from the entire set of face conditional regression forest learn the relation conditional to global face property in our experiment we use the head pose a a global property and demonstrate that conditional regression forest outperform regression forest for facial feature detection we have evaluated the method on the challenging labeled face in the wild database where close to human accuracy is achieved while processing image in real time 
in recent year more and more visual descriptor have been proposed to describe object and scene appearing in image different feature describe different aspect of the visual characteristic how to combine these heterogeneous feature ha become an increasing critical problem in this paper we propose a novel approach to unsupervised integrate such heterogeneous feature by performing multi modal spectral clustering on unlabeled image and unsegmented image considering each type of feature a one modal our new multi modal spectral clustering mmsc algorithm is to learn a commonly shared graph laplacian matrix by unifying different modal image feature a non negative relaxation is also added in our method to improve the robustness and efficiency of image clustering we applied our mmsc method to integrate five type of popularly used image feature including sift hog gist lbp centrist and evaluated the performance by two benchmark data set caltech and msrc v compared with existing unsupervised scene and object categorization method our approach always achieves superior performance measured by three standard clustering evaluation metrices 
we present a novel approach for automatically discovering spatio temporal pattern in complex dynamic scene similarly to recent non object centric method we use low level visual cue to detect atomic activity and then construct clip histogram differently from previous work we formulate the task of discovering high level activity pattern a a prototype learning problem where the correlation among atomic activity is explicitly taken into account when grouping clip histogram interestingly at the core of our approach there is a convex optimization problem which allows u to efficiently extract pattern at multiple level of detail the effectiveness of our method is demonstrated on publicly available datasets 
what primitive should we use to infer the rich d world behind an image we argue that these primitive should be both visually discriminative and geometrically informative and we present a technique for discovering such primitive we demonstrate the utility of our primitive by using them to infer d surface normal given a single image our technique substantially outperforms the state of the art and show improved cross dataset performance 
in this paper we address the problem of segmentation based tracking of multiple articulated person we propose two improvement to current level set tracking formulation the first is a localized appearance model that us additional level set in order to enforce a hierarchical subdivision of the object shape into multiple connected region with distinct appearance model the second is a novel mechanism to include detailed object shape information in the form of a per pixel figure ground probability map obtained from an object detection process both contribution are seamlessly integrated into the level set framework together they considerably improve the accuracy of the tracked segmentation we experimentally evaluate our proposed approach on two challenging sequence and demonstrate it good performance in practice 
we propose a new method to quickly and accurately predict d position of body joint from a single depth image using no temporal information we take an object recognition approach designing an intermediate body part representation that map the difficult pose estimation problem into a simpler per pixel classification problem our large and highly varied training dataset allows the classifier to estimate body part invariant to pose body shape clothing etc finally we generate confidence scored d proposal of several body joint by reprojecting the classification result and finding local mode the system run at frame per second on consumer hardware our evaluation show high accuracy on both synthetic and real test set and investigates the effect of several training parameter we achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole skeleton nearest neighbor matching 
we propose a novel nonparametric approach for semantic segmentation using high order semantic relation conventional context model mainly focus on learning pairwise relationship between object pairwise relation however are not enough to represent high level contextual knowledge within image in this paper we propose semantic relation transfer a method to transfer high order semantic relation of object from annotated image to unlabeled image analogous to label transfer technique where label information are transferred we first define semantic tensor representing high order relation of object semantic relation transfer problem is then formulated a semi supervised learning using a quadratic objective function of the semantic tensor by exploiting low rank property of the semantic tensor and employing kronecker sum similarity an efficient approximation algorithm is developed based on the predicted high order semantic relation we reason semantic segmentation and evaluate the performance on several challenging datasets 
in this paper we tackle the problem of performing inference in graphical model whose energy is a polynomial function of continuous variable our energy minimization method follows a dual decomposition approach where the global problem is split into sub problem defined over the graph clique the optimal solution to these sub problem is obtained by making use of a polynomial system solver our algorithm inherits the convergence guarantee of dual decomposition to speed up optimization we also introduce a variant of this algorithm based on the augmented lagrangian method our experiment illustrate the diversity of computer vision problem that can be expressed with polynomial energy and demonstrate the benefit of our approach over existing continuous inference method 
we propose a detection and segmentation algorithm for the purpose of fine grained recognition the algorithm first detects low level region that could potentially belong to the object and then performs a full object segmentation through propagation apart from segmenting the object we can also zoom in on the object i e center it normalize it for scale and thus discount the effect of the background we then show that combining this with a state of the art classification algorithm lead to significant improvement in performance especially for datasets which are considered particularly hard for recognition e g bird specie the proposed algorithm is much more efficient than other known method in similar scenario our method is also simpler and we apply it here to different class of object e g bird flower cat and dog we tested the algorithm on a number of benchmark datasets for fine grained categorization it outperforms all the known state of the art method on these datasets sometimes by a much a it improves the performance of our baseline algorithm by consistently on all datasets we also observed more than a improvement in the recognition performance on a challenging large scale flower dataset containing specie of flower and image 
we introduce a probabilistic framework for simultaneous tracking and reconstruction of d rigid object using an rgb d camera the tracking problem is handled using a bag of pixel representation and a back projection scheme surface and background appearance model are learned online leading to robust tracking in the presence of heavy occlusion and outlier in both our tracking and reconstruction module the d object is implicitly embedded using a d level set function the framework is initialized with a simple shape primitive model e g a sphere or a cube and the real d object shape is tracked and reconstructed online unlike existing depth based d reconstruction work which either rely on calibrated fixed camera set up or use the observed world map to track the depth camera our framework can simultaneously track and reconstruct small moving object we use both qualitative and quantitative result to demonstrate the superior performance of both tracking and reconstruction of our method 
image classification method have been significantly developed in the last decade most method stem from bag of feature bof approach and it is recently extended to a vector aggregation model such a using fisher kernel in this paper we propose a novel feature extraction method for image classification following the bof approach a plenty of local descriptor are first extracted in an image and the proposed method is built upon the probability density function p d f formed by those descriptor since the p d f essentially represents the image we extract the feature from the p d f by mean of the gradient on the p d f the gradient especially their orientation effectively characterize the shape of the p d f from the geometrical viewpoint we construct the feature by the histogram of the oriented p d f gradient via orientation coding followed by aggregation of the orientation code the proposed image feature imposing no specific assumption on the target are so general a to be applicable to any kind of task regarding image classification in the experiment on object recognition and scene classification using various datasets the proposed method exhibit superior performance compared to the other existing method 
the higher order clustering problem arises when data is drawn from multiple subspace or when observation fit a higher order parametric model most solution to this problem either decompose higher order similarity measure for use in spectral clustering or explicitly use low rank matrix representation in this paper we present our approach of sparse grassmann clustering sgc that combine attribute of both category while we decompose the higher order similarity tensor we cluster data by directly finding a low dimensional representation without explicitly building a similarity matrix by exploiting recent advance in online estimation on the grassmann manifold grouse we develop an efficient and accurate algorithm that work with individual column of similarity or partial observation thereof since it avoids the storage and decomposition of large similarity matrix our method is efficient scalable and ha low memory requirement even for large scale data we demonstrate the performance of our sgc method on a variety of segmentation problem including planar segmentation of kinect depth map and motion segmentation of the hopkins dataset for which we achieve performance comparable to the state of the art 
conventional appearance based face recognition method usually assume there are multiple sample per person mspp available during the training phase for discriminative feature extraction in many practical face recognition application such a law enhancement e passport and id card identification this assumption however may not hold a there is only a single sample per person sspp enrolled or recorded in these system many popular face recognition method fail to work well in this scenario because there are not enough sample for discriminant learning to address this problem we propose in this paper a novel discriminative multi manifold analysis dmma method by learning discriminative feature from image patch first we partition each enrolled image into several non overlapping patch to form an image set for each sample per person then we formulate the sspp face recognition a a manifold manifold matching problem and learn multiple dmma feature space to maximize the manifold margin of different person lastly we propose a reconstruction based manifold manifold distance to identify the unlabeled subject experimental result on three widely used face database are presented to demonstrate the efficacy of the proposed approach 
rapidly growing application on smartphones have provided an excellent platform for mobile visual search most of previous visual search system adopt the framework of bag of word in which word indicate quantized code of visual feature in this work we propose a novel visual search system based on bag of hash bit bohb in which each local feature is encoded to a very small number of hash bit instead of quantized to visual word and the whole image is represented a bag of hash bit the proposed bohb method offer unique benefit in solving the challenge associated with mobile visual search e g low transmission cost cheap memory and computation on the mobile side etc moreover our bohb method leverage the distinct property of hashing bit such a multi table indexing multiple bucket probing bit reuse and hamming distance based ranking to achieve efficient search over gigantic visual database the proposed method significantly outperforms state of the art mobile visual search method like chog and other conventional desktop visual search approach like bag of word via vocabulary tree or product quantization the proposed bohb approach is easy to implement on mobile device and general in the sense that it can be applied to different type of local feature hashing algorithm and image database we also incorporate a boundary feature in the reranking step to describe the object shape complementing the local feature that are usually used to characterize the local detail the boundary feature can further filter out noisy result and improve the search performance especially at the coarse category level extensive experiment over large scale data set up to k product image demonstrate the effectiveness of our approach 
human nameable visual attribute offer many advantage when used a mid level feature for object recognition but existing technique to gather relevant attribute can be inefficient costing substantial effort or expertise and or insufficient descriptive property need not be discriminative we introduce an approach to define a vocabulary of attribute that is both human understandable and discriminative the system take object scene labeled image a input and return a output a set of attribute elicited from human annotator that distinguish the category of interest to ensure a compact vocabulary and efficient use of annotator effort we show how to actively augment the vocabulary such that new attribute resolve inter class confusion and propose a novel nameability manifold that prioritizes candidate attribute by their likelihood of being associated with a nameable property we demonstrate the approach with multiple datasets and show it clear advantage over baseline that lack a nameability model or rely on a list of expert provided attribute 
this paper proposes a non parametric approach to scene parsing inspired by the work of tighe and lazebnik in their approach a simple knn scheme with multiple descriptor type is used to classify super pixel we add two novel mechanism i a principled and efficient method for learning per descriptor weight that minimizes classification error and ii a context driven adaptation of the training set used for each query which condition on common class which are relatively easy to classify to improve performance on rare one the first technique help to remove extraneous descriptor that result from the imperfect distance metric representation of each super pixel the second contribution re balance the class frequency away from the highly skewed distribution found in real world scene both method give a significant performance boost over and the overall system achieves state of the art performance on the sift flow dataset 
most recently the bag of feature bof representation ha been well advocated for image search and classification with two decent phase named sparse coding and max pooling to compensate quantization loss a well a inject spatial layout but still much information ha been discarded by quantizing local descriptor with two dimensional layout into a one dimensional bof histogram in this paper we revisit this popular sparse coding max pooling paradigm by looking around the local descriptor context towards an optimal bof first we introduce a weakly supervised sparse coding wsc to exploit the classemes based attribute labeling to refine the descriptor coding procedure it is achieved by learning an attribute to word co occurrence prior to impose a label inconsistency distortion over the based coding regularizer such that the descriptor code can maximally preserve the image semantic similarity second we propose an adaptive feature pooling scheme over superpixels rather than over fixed spatial pyramid named geometric consistency pooling gcp a an effect local descriptor enjoying good geometric consistency are pooled together to ensure a more precise spatial layout embedding in bof both of our phase are unsupervised which differ from the existing work in supervised dictionary learning sparse coding and feature pooling therefore our approach enables potential application like scalable visual search we evaluate in both image classification and search benchmark and report good improvement over the state of the art 
in this paper we address a practical problem of cross scenario clothing retrieval given a daily human photo captured in general environment e g on street finding similar clothing in online shop where the photo are captured more professionally and with clean background there are large discrepancy between daily photo scenario and online shopping scenario we first propose to alleviate the human pose discrepancy by locating human part detected by a well trained human detector then founded on part feature we propose a two step calculation to obtain more reliable one to many similarity between the query daily photo and online shopping photo the within scenario one to many similarity between a query daily photo and the auxiliary set are derived by direct sparse reconstruction and by a cross scenario many to many similarity transfer matrix inferred offline from an extra auxiliary set and the online shopping set the reliable cross scenario one to many similarity between the query daily photo and all online shopping photo are obtained we collect a large online shopping dataset and a daily photo dataset both of which are thoroughly labeled with clothing attribute via mechanic turk the extensive experimental evaluation on the collected datasets well demonstrate the effectiveness of the proposed framework for cross scenario clothing retrieval 
intrinsic image decomposition is an important problem that target the recovery of shading and reflectance component from a single image while this is an ill posed problem on it own we propose a novel approach for intrinsic image decomposition using a reflectance sparsity prior that we have developed our method is based on a simple observation neighboring pixel usually have the same reflectance if their chromaticity are the same or very similar we formalize this sparsity constraint on local reflectance and derive a sparse representation of reflectance component using data driven edge avoiding wavelet we show that the reflectance component of natural image is sparse in this representation we also propose and formulate a novel global reflectance sparsity constraint using this sparsity prior and global constraint we formulate a l regularized least square minimization problem for intrinsic image decomposition that can be solved efficiently our algorithm can successfully extract intrinsic image from a single image without using other reflection or color model or any user interaction the result on challenging scene demonstrate the power of the proposed technique 
automated facial expression recognition ha received increased attention over the past two decade existing work in the field usually do not encode either the temporal evolution or the intensity of the observed facial display they also fail to jointly model multidimensional multi class continuous facial behaviour data binary classifier one for each target basic emotion class are used instead in this paper intrinsic topology of multidimensional continuous facial affect data is first modeled by an ordinal manifold this topology is then incorporated into the hidden conditional ordinal random field h corf framework for dynamic ordinal regression by constraining h corf parameter to lie on the ordinal manifold the resulting model attains simultaneous dynamic recognition and intensity estimation of facial expression of multiple emotion to the best of our knowledge the proposed method is the first one to achieve this on both deliberate a well a spontaneous facial affect data 
we propose an exact general and efficient coarse to fine energy minimization strategy for semantic video segmentation our strategy is based on a hierarchical abstraction of the supervoxel graph that allows u to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energy defined over coarser graph the strategy is exact i e it produce the same solution a minimizing over the finest graph it is general i e it can be used to minimize any energy function e g unary pair wise and higher order term with any existing energy minimization algorithm e g graph cut and belief propagation it also give significant speedup in inference for several datasets with varying degree of spatio temporal continuity we also discus the strength and weakness of our strategy relative to existing hierarchical approach and the kind of image and video data that provide the best speedup 
we show that bilateral symmetry plane estimation for three dimensional d shape may be carried out accurately and efficiently in the spherical harmonic domain our method are valuable for application where spherical harmonic expansion is already employed such a d shape registration morphometry and retrieval we show that the presence of bilateral symmetry in the d shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficient and provide algorithm for estimating the orientation of the symmetry plane the benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptor without the need to solve a correspondence problem our method work on point cloud a well a large scale mesh model of d shape 
this paper present a nonparametric approach to semantic parsing using small patch and simple gradient color and location feature we learn the relevance of individual feature channel at test time using a locally adaptive distance metric to further improve the accuracy of the nonparametric approach we examine the importance of the retrieval set used to compute the nearest neighbour using a novel semantic descriptor to retrieve better candidate the approach is validated by experiment on several datasets used for semantic parsing demonstrating the superiority of the method compared to the state of art approach 
in this paper we explore the regularized feature selection method for person specific face verification in unconstrained environment we reformulate the generalization of the single task sparsity enforced feature selection method to multi task case a a simultaneous sparse approximation problem we also investigate two feature selection strategy in the multi task generalization based on the positive and negative feature correlation assumption across different person simultaneous orthogonal matching pursuit somp is adopted and modified to solve the corresponding optimization problem we further proposed a named simultaneous subspace pursuit ssp method which generalize the subspace pursuit method to solve the corresponding optimization problem the performance of different feature selection strategy and different solver for face verification are compared on the challenging lfw face database our experimental result show that the selected subset based on positive correlation assumption are more effective than those based on the negative correlation assumption the omp based solver outperform sp based solver in term of feature selection and the regularized method with omp based solver can outperform state of the art feature selection method 
how should a video be represented we propose a new representation for video based on mid level discriminative spatio temporal patch these spatio temporal patch might correspond to a primitive human action a semantic object or perhaps a random but informative spatio temporal patch in the video what defines these spatio temporal patch is their discriminative and representative property we automatically mine these patch from hundred of training video and experimentally demonstrate that these patch establish correspondence across video and align the video for label transfer technique furthermore these patch can be used a a discriminative vocabulary for action classification where they demonstrate state of the art performance on ucf and olympics datasets 
in this paper we investigate the problem of recognizing occupation of multiple people with arbitrary pose in a photo previous work utilizing single person s nearly frontal clothing information and fore background context preliminarily prof that occupation recognition is computationally feasible in computer vision however in practice multiple people with arbitrary pose are common in a photo and recognizing their occupation is even more challenging we argue that with appropriately built visual attribute co occurrence and spatial configuration model that is learned through structure svm we can recognize multiple people s occupation in a photo simultaneously to evaluate our method s performance we conduct extensive experiment on a new well labeled occupation database with representative occupation and over k image result on this database validate our method s effectiveness and show that occupation recognition is solvable in a more general case 
video data provides a rich source of information that is available to u today in large quantity e g from on line resource task like segmentation benefit greatly from the analysis of spatio temporal motion pattern in video and recent advance in video segmentation ha shown great progress in exploiting these addition cue however observing a single video is often not enough to predict meaningful segmentation and inference across video becomes necessary in order to predict segmentation that are consistent with object class therefore the task of video co segmentation is being proposed that aim at inferring segmentation from multiple video but current approach are limited to only considering binary foreground background segmentation and multiple video of the same object this is a clear mismatch to the challenge that we are facing with video from online resource or consumer video we propose to study multi class video co segmentation where the number of object class is unknown a well a the number of instance in each frame and video we achieve this by formulating a non parametric bayesian model across video sequence that is based on a new video segmentation prior a well a a global appearance model that link segment of the same class we present the first multi class video co segmentation evaluation we show that our method is applicable to real video data from online resource and outperforms state of the art video segmentation and image co segmentation baseline 
this paper advance descriptor based face recognition by suggesting a novel usage of descriptor to form an over complete representation and by proposing a new metric learning pipeline within the same not same framework first the over complete local binary pattern oclbp face representation scheme is introduced a a multi scale modified version of the local binary pattern lbp scheme second we propose an efficient matrix vector multiplication based recognition system the system is based on linear discriminant analysis lda coupled with within class covariance normalization wccn this is further extended to the unsupervised case by proposing an unsupervised variant of wccn lastly we introduce diffusion map dm for non linear dimensionality reduction a an alternative to the whitened principal component analysis wpca method which is often used in face recognition we evaluate the proposed framework on the lfw face recognition dataset under the restricted unrestricted and unsupervised protocol in all three case we achieve very competitive result 
this paper address the problem of scene categorization while arguing that better and more accurate result can be obtained by endowing the computational process with perceptual relation between scene category we first describe a psychophysical paradigm that probe human scene categorization extract perceptual relation between scene category and suggests that these perceptual relation do not always conform the semantic structure between category we then incorporate the obtained perceptual finding into a computational classification scheme which take inter class relationship into account to obtain better scene categorization regardless of the particular descriptor with which scene are represented we present such improved classification result using several popular descriptor we discus why the contribution of inter class perceptual relation is particularly pronounced for under sampled training set and we argue that this mechanism may explain the ability of the human visual system to perform well under similar condition finally we introduce an online experimental system for obtaining perceptual relation for large collection of scene category 
we propose a novel patch based image representation that is useful because it inherently detects region with repetitive structure at multiple scale and yield a parameterless hierarchical segmentation we describe an image by breaking it into coherent region where each region is well described easily reconstructed by repeatedly instantiating a patch using a set of simple transformation in other word a good segment is one that ha sufficient repetition of some pattern and a patch is useful if it contains a pattern that is repeated in the image 
we consider the problem of estimating the extrinsic parameter pose of a camera with respect to a reference d object without a direct view since the camera doe not view the object directly previous approach have utilized reflection in a planar mirror to solve this problem however a planar mirror based approach requires a minimum of three reflection and ha degenerate configuration where estimation fails in this paper we show that the pose can be obtained using a single reflection in a spherical mirror of known radius this make our approach simpler and easier in practice in addition unlike planar mirror the spherical mirror based approach doe not have any degenerate configuration leading to a robust algorithm while a planar mirror reflection result in a virtual perspective camera a spherical mirror reflection result in a non perspective axial camera the axial nature of ray allows u to compute the axis direction of sphere center and few pose parameter in a linear fashion we then derive an analytical solution to obtain the distance to the sphere center and remaining pose parameter and show that it corresponds to solving a th degree equation we present comparison with a recent method that use planar mirror and show that our approach recovers more accurate pose in the presence of noise extensive simulation and result on real data validate our algorithm 
in this paper we present a novel threshold free robust estimation framework capable of efficiently fitting model to contaminated data while ransac and it many variant have emerged a popular tool for robust estimation their performance is largely dependent on the availability of a reasonable prior estimate of the inlier threshold in this work we aim to remove this threshold dependency we build on the observation that model generated from uncontaminated minimal subset are consistent in term of the behavior of their residual while contaminated model exhibit uncorrelated behavior by leveraging this observation we then develop a very simple yet effective algorithm that doe not require apriori knowledge of either the scale of the noise or the fraction of uncontaminated point the resulting estimator recon residual consensus is capable of elegantly adapting to the contamination level of the data and show excellent performance even at low inlier ratio and high noise level we demonstrate the efficiency of our framework on a variety of challenging estimation problem 
interest point ip detection is an important component of many computer vision method while there are a number of method for detecting ip in rgb image modality such a depth image and range scan have seen relatively little work in this paper we approach the ip detection problem from a machine learning viewpoint and formulate it a a regression problem we learn a regression forest rf model that given an image patch tell u if there is an ip in the center of the patch our rf based method for ip detection allows an easy trade off between speed and repeatability by adapting the depth and number of tree used for approximating the interest point response map the data used for training the rf model is obtained by running state of the art ip detection method on the depth image we show further how the ip response map used for training the rf can be specifically designed to increase repeatability by employing d model of scene generated by reconstruction system such a kinectfusion our experiment demonstrate that the use of such data lead to considerably improved ip detection 
image deconvolution is the ill posed problem of recovering a sharp image given a blurry one generated by a convolution in this work we deal with space invariant non blind deconvolution currently the most successful method involve a regularized inversion of the blur in fourier domain a a first step this step amplifies and color the noise and corrupts the image information in a second and arguably more difficult step one then need to remove the colored noise typically using a cleverly engineered algorithm however the method based on this two step approach do not properly address the fact that the image information ha been corrupted in this work we also rely on a two step procedure but learn the second step on a large dataset of natural image using a neural network we will show that this approach outperforms the current state of the art on a large dataset of artificially blurred image we demonstrate the practical applicability of our method in a real world example with photographic out of focus blur 
this paper present a novel method for estimating the geospatial trajectory of a moving camera with unknown intrinsic parameter in a city scale urban environment the proposed method is based on a three step process that includes finding the best visual match of individual image to a dataset of geo referenced street view image bayesian tracking to estimate the frame localization and it temporal evolution and a trajectory reconstruction algorithm to eliminate inconsistent estimation a a result of matching feature in query image with the feature in the reference geo taged image in the first step we obtain a distribution of geolocated vote of matching feature which is interpreted a the likelihood of the location latitude and longitude given the current observation in the second step bayesian tracking framework is used to estimate the temporal evolution of frame geolocalization based on the previous state probability and current likelihood finally once a trajectory is estimated we perform a minimum spanning tree mst based trajectory reconstruction algorithm to eliminate trajectory loop or noisy estimation the proposed method wa tested on sixty minute of video which included footage downloaded from youtube and footage captured by random user in orlando and pittsburgh 
in this work we propose a method for estimating disparity map from very few measurement based on the theory of compressive sensing our algorithm accurately reconstructs disparity map only using about of the entire map we propose a conjugate subgradient method for the arising optimization problem that is applicable to large scale system and recovers the disparity map efficiently experiment are provided that show the effectiveness of the proposed approach and robust behavior under noisy condition 
in this paper we propose a simple and effective way to integrate structural information in random forest for semantic image labelling by structural information we refer to the inherently available topological distribution of object class in a given image different object class label will not be randomly distributed over an image but usually form coherently labelled region in this work we provide a way to incorporate this topological information in the popular random forest framework for performing low level unary classification our paper ha several contribution first we show how random forest can be augmented with structured label information in the second part we introduce a novel data splitting function that exploit the joint distribution observed in the structured label space for learning typical label transition between object class finally we provide two possibility for integrating the structured output prediction into concise semantic labellings in our experiment on the challenging msrc and camvid database we compare our method to standard random forest and conditional random field classification result 
we present a hierarchical model for human activity recognition in entire multi person scene our model describes human behaviour at multiple level of detail ranging from low level action through to high level event we also include a model of social role the expected behaviour of certain people or group of people in a scene the hierarchical model includes these varied representation and various form of interaction between people present in a scene the model is trained in a discriminative max margin framework experimental result demonstrate that this model can improve performance at all considered level of detail on two challenging datasets 
graph matching ha been widely used in various application in computer vision due to it powerful performance however it pose three challenge to image sparse feature matching the combinatorial nature limit the size of the possible match it is sensitive to outlier because the objective function prefers more match it work poorly when handling many to many object correspondence due to it assumption of one single cluster for each graph in this paper we address these problem with a unified framework density maximization we propose a graph density local estimator dle to measure the quality of match density maximization aim to maximize the dle value both locally and globally the local maximization of dle find the cluster of node a well a eliminates the outlier the global maximization of dle efficiently refines the match by exploring a much larger matching space our density maximization is orthogonal to specific graph matching algorithm experimental evaluation demonstrates that it significantly boost the true match and enables graph matching to handle both outlier and many to many object correspondence 
photo sequencing is the problem of recovering the temporal order of a set of still image of a dynamic event taken asynchronously by a set of uncalibrated camera solving this problem is a first crucial step for analyzing or visualizing the dynamic content of the scene captured by a large number of freely moving spectator we propose a geometric based solution followed by rank aggregation to the photo sequencing problem our algorithm trade spatial certainty for temporal certainty whereas the previous solution proposed by relies on two image taken from the same static camera to eliminate uncertainty in space we drop the static camera assumption and replace it with temporal information available from image taken from the same moving camera our method thus overcomes the limitation of the static camera assumption and scale much better with the duration of the event and the spread of camera in space we present successful result on challenging real data set and large scale synthetic data image 
deformable part based model achieve state of the art performance for object detection but rely on heuristic initialization during training due to the optimization of non convex cost function this paper investigates limitation of such an initialization and extends earlier method using additional supervision we explore strong supervision in term of annotated object part and use it to i improve model initialization ii optimize model structure and iii handle partial occlusion our method is able to deal with sub optimal and incomplete annotation of object part and is shown to benefit from semi supervised learning setup where part level annotation is provided for a fraction of positive example only experimental result are reported for the detection of six animal class in pascal voc and datasets we demonstrate significant improvement in detection performance compared to the lsvm and the poselet object detector 
this paper describes a novel strategy to enhance underwater video and image built on the fusion principle our strategy derives the input and the weight measure only from the degraded version of the image in order to overcome the limitation of the underwater medium we define two input that represent color corrected and contrast enhanced version of the original underwater image frame but also four weight map that aim to increase the visibility of the distant object degraded due to the medium scattering and absorption our strategy is a single image approach that doe not require specialized hardware or knowledge about the underwater condition or scene structure our fusion framework also support temporal coherence between adjacent frame by performing an effective edge preserving noise reduction strategy the enhanced image and video are characterized by reduced noise level better exposed ness of the dark region improved global contrast while the finest detail and edge are enhanced significantly in addition the utility of our enhancing technique is proved for several challenging application 
in the context of shape segmentation and retrieval object wide distribution of measure are needed to accurately evaluate and compare local region of shape lien et al proposed two point wise concavity measure in the context of approximate convex decomposition of polygon measuring the distance from a point to the polygon s convex hull an accurate shortest path concavity spc measure and a straight line concavity slc approximation of the same while both are practicable on d shape the exponential cost of spc in d make it inhibitively expensive for a generalization to mesh in this paper we propose an efficient and straight forward approximation of the shortest path concavity measure to d mesh our approximation is based on discretizing the space between mesh and convex hull thereby reducing the continuous shortest path search to an efficiently solvable graph problem our approach work out of the box on complex mesh topology and requires no complicated handling of genus besides presenting a rigorous evaluation of our method on a variety of input mesh we also define an spc based shape descriptor and show it superior retrieval and runtime performance compared with the recently presented result on the convexity distribution by lian et al 
many classifier are trained with massive training set only to be applied at test time on data from a different distribution how can we rapidly and simply adapt a classifier to a new test distribution even when we do not have access to the original training data we present an on line approach for rapidly adapting a black box classifier to a new test data set without retraining the classifier or examining the original optimization criterion assuming the original classifier output a continuous number for which a threshold give the class we reclassify point near the original boundary using a gaussian process regression scheme we show how this general procedure can be used in the context of a classifier cascade demonstrating performance that far exceeds state of the art result in face detection on a standard data set we also draw connection to work in semi supervised learning domain adaptation and information regularization 
we investigate the problem of identifying the position of a viewer inside a room of planar mirror with unknown geometry in conjunction with the room s shape parameter we consider the observation to consist of angularly resolved depth measurement of a single scene point that is being observed via many multi bounce interaction with the specular room geometry application of this problem statement include area such a calibration acoustic echo cancelation and time of flight imaging we theoretically analyze the problem and derive sufficient condition for a combination of convex room geometry observer and scene point to be reconstruct able the resulting constructive algorithm is exponential in nature and therefore not directly applicable to practical scenario to counter the situation we propose theoretically devised geometric constraint that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that us these constraint to obtain an effective solution we demonstrate the effectiveness of our algorithm on extensive simulation a well a in a challenging real world calibration scenario 
substantial ambiguity arise in hand tracking due to issue such a small hand size deformable hand shape and similar hand appearance these issue have greatly limited the capability of current multi target tracking technique in hand tracking a an example state of the art approach for people tracking handle indentity switching by exploiting the appearance cue using advanced object detector for hand tracking such approach will fail due to similar or even identical hand appearance the main contribution of our work is a global optimization framework based on binary quadratic programming bqp that seamlessly integrates appearance motion and complex interaction between hand our approach effectively handle key challenge such a occlusion detection failure identity switching and robustly track both hand in two challenging real life scenario retail surveillance and sign language in addition we demonstrate that an automatic method based on hand trajectory analysis outperforms state of the art on checkout related activity recognition in grocery store 
competitive sliding window detector require vast training set since a pool of natural image provides a nearly endless supply of negative sample in the form of patch at different scale and location training with all the available data is considered impractical a staple of current approach is hard negative mining a method of selecting relevant sample which is nevertheless expensive given that sample at slightly different location have overlapping support there seems to be an enormous amount of duplicated work it is natural then to ask whether these redundancy can be eliminated in this paper we show that the gram matrix describing such data is block circulant we derive a transformation based on the fourier transform that block diagonalizes the gram matrix at once eliminating redundancy and partitioning the learning problem this decomposition is valid for any dense feature and several learning algorithm and take full advantage of modern parallel architecture surprisingly it allows training with all the potential sample in set of thousand of image by considering the full set we generate in a single shot the optimal solution which is usually obtained only after several round of hard negative mining we report speed gain on caltech pedestrian and inria pedestrian of over an order of magnitude allowing training on a desktop computer in a couple of minute 
people tracking in crowded real world scene is challenging due to frequent and long term occlusion recent tracking method obtain the image evidence from object people detector but typically use off the shelf detector and treat them a black box component in this paper we argue that for best performance one should explicitly train people detector on failure case of the overall tracker instead to that end we first propose a novel joint people detector that combine a state of the art single person detector with a detector for pair of people which explicitly exploit common pattern of person person occlusion across multiple viewpoint that are a frequent failure case for tracking in crowded scene to explicitly address remaining failure mode of the tracker we explore two method first we analyze typical failure of tracker and train a detector explicitly on these case and second we train the detector with the people tracker in the loop focusing on the most common tracker failure we show that our joint multi person detector significantly improves both detection accuracy a well a tracker performance improving the state of the art on standard benchmark 
we present a unified framework for detecting and classifying people interaction in unconstrained user generated image unlike previous approach that directly map people face location in d image space into feature for classification we first estimate camera viewpoint and people position in d space and then extract spatial configuration feature from explicit d people position this approach ha several advantage first it can accurately estimate relative distance and orientation between people in d second it encodes spatial arrangement of people into a richer set of shape descriptor than afforded in d our d shape descriptor are invariant to camera pose variation often seen in web image and video the proposed approach also estimate camera pose and us it to capture the intent of the photo to achieve accurate d people layout estimation we develop an algorithm that robustly fuse semantic constraint about human interposition into a linear camera model this enables our model to handle large variation in people size height e g age and pose an accurate d layout also allows u to construct feature informed by proxemics that improves our semantic classification to characterize the human interaction space we introduce visual proxemes a set of prototypical pattern that represent commonly occurring social interaction in event we train a discriminative classifier that classifies d arrangement of people into visual proxemes and quantitatively evaluate the performance on a large challenging dataset 
we present an active geodesic contour model in which we constrain the evolving active contour to be a geodesic with respect to a weighted edge based energy through it entire evolution rather than just at it final state a in the traditional geodesic active contour model since the contour is always a geodesic throughout the evolution we automatically get local optimality with respect to an edge fitting criterion this enables u to construct a purely region based energy minimization model without having to devise arbitrary weight in the combination of our energy function to balance edge based term with the region based term we show that this novel approach of combining edge information a the geodesic constraint in optimizing a purely region based energy yield a new class of active contour which exhibit both local and global behavior that are naturally responsive to intuitive type of user interaction we also show the relationship of this new class of globally constrained active contour with traditional minimal path method which seek global minimizers of purely edge based energy without incorporating region based criterion finally we present some numerical example to illustrate the benefit of this approach over traditional active contour model 
we present the first variational framework for multi label segmentation on the ray space of d light field for traditional segmentation of single image feature need to be extracted from the d projection of a three dimensional scene the associated loss of geometry information can cause severe problem for example if different object have a very similar visual appearance in this work we show that using a light field instead of an image not only enables to train classifier which can overcome many of these problem but also provides an optimal data structure for label optimization by implicitly providing scene geometry information it is thus possible to consistently optimize label assignment over all view simultaneously a a further contribution we make all light field available online with complete depth and segmentation ground truth data where available and thus establish the first benchmark data set for light field analysis to facilitate competitive further development of algorithm 
in this paper we propose a novel one shot optimization approach to simultaneously determine both the optimal d landmark model and the corresponding d projection without explicit estimation of the camera viewpoint which is also able to deal with misdetections a well a partial occlusion to this end a d shape manifold is built upon fourth order interaction of landmark from a training set where pose invariant statistic are obtained in this space the d d consistency is also encoded in such high order interaction which eliminate the necessity of viewpoint estimation furthermore the modeling of visibility improves further the performance of the method by handling missing correspondence and occlusion the inference is addressed through a map formulation which is naturally transformed into a higher order mrf optimization problem and is solved using a dual decomposition based method promising result on standard face benchmark demonstrate the potential of our approach 
we present a novel method to auto calibrate gaze estimator based on gaze pattern obtained from other viewer our method is based on the observation that the gaze pattern of human are indicative of where a new viewer will look at when a new viewer is looking at a stimulus we first estimate a topology of gaze point initial gaze point next these point are transformed so that they match the gaze pattern of other human to find the correct gaze point in a flexible uncalibrated setup with a web camera and no chin rest the proposed method wa tested on ten subject and ten image the method estimate the gaze point after looking at a stimulus for a few second with an average accuracy of although the reported performance is lower than what could be achieved with dedicated hardware or calibrated setup the proposed method still provides a sufficient accuracy to trace the viewer attention this is promising considering the fact that auto calibration is done in a flexible setup without the use of a chin rest and based only on a few second of gaze initialization data to the best of our knowledge this is the first work to use human gaze pattern in order to auto calibrate gaze estimator 
the task of d articulated human pose estimation in natural image is extremely challenging due to the high level of variation in human appearance these variation arise from different clothing anatomy imaging condition and the large number of pose it is possible for a human body to take recent work ha shown state of the art result by partitioning the pose space and using strong nonlinear classifier such that the pose dependence and multi modal nature of body part appearance can be captured we propose to extend these method to handle much larger quantity of training data an order of magnitude larger than current datasets and show how to utilize amazon mechanical turk and a latent annotation update scheme to achieve high quality annotation at low cost we demonstrate a significant increase in pose estimation accuracy while simultaneously reducing computational expense by a factor of and contribute a dataset of highly articulated pose 
we describe an online approach to learn non linear motion pattern and robust appearance model for multi target tracking in a tracklet association framework unlike most previous approach that use linear motion method only we online build a non linear motion map to better explain direction change and produce more robust motion affinity between tracklets moreover based on the incremental learned entry exit map a multiple instance learning method is devised to produce strong appearance model for tracking positive sample pair are collected from different track let so that training sample have high diversity finally using online learned moving group a tracklet completion process is introduced to deal with tracklets not reaching entry exit point we evaluate our approach on three public data set and show significant improvement compared with state of art method 
while the notion of joint sparsity in understanding common and innovative component of a multi receiver signal ensemble ha been well studied we investigate the utility of such joint sparse model in representing information contained in a single video signal by decomposing the content of a video sequence into that observed by multiple spatially and or temporally distributed receiver we first recover a collection of common and innovative component pertaining to individual video we then present modeling strategy based on subspace driven manifold metric to characterize pattern among these component across other video in the system to perform subsequent video analysis we demonstrate the efficacy of our approach for activity classification and clustering by reporting competitive result on standard datasets such a hmdb ucf olympic sport and kth 
we propose a novel linear method for scale invariant figure ground separation in image and video figure ground separation is treated a a superpixel labeling problem we optimize superpixel foreground and background labeling so that the object foreground estimation match model color histogram it area and perimeter are consistent with object shape prior and the foreground superpixels form a connected region this optimization problem is challenging due to high order soft and hard global constraint among large number of superpixels we devise a scale invariant linear method that give an integer solution with a guaranteed error bound via a branch and cut procedure the proposed method doe not rely on motion continuity and work on static image and video with abrupt motion our experimental result on both synthetic ground truth data and real image show that the proposed method is efficient and robust over object appearance change large deformation and strong background clutter 
document registration is a problem where the image of a template document whose layout is known is registered with a test document image given the registration parameter layout of the template image is superimposed on the test document registration algorithm have been popular in application such a form processing where the superimposed layout is used to extract relevant field prior art ha been designed to work with scanned document under affine transformation we find that the proliferation of camera captured image make it necessary to address camera noise such a non uniform lighting clutter and highly variable scale resolution the absence of a scan bed also lead to challenging non rigid deformation being seen in paper image prior approach in point pattern based registration like random sample consensus ransac and thin plate spline robust point matching tps rpm form the basis of our work we propose enhancement to these method to enable registration of cell phone and camera captured document under non rigid transformation we embed three novel aspect into the framework i histogram based uniformly transformed correspondence estimation ii clustering of point located near the region of interest roi to select only close by region for matching iii validation of the registration in ransac and tps rpm algorithm for non rigid registration we consider scale invariant feature transform sift and speeded up robust feature surf a our feature result are reported a comparing prior art with our method on a dataset that will be made publicly available 
camera spectral sensitivity play an important role for various color based computer vision task although several method have been proposed to estimate it their applicability is severely restricted by the requirement for a known illumination spectrum in this work we present a single image estimation method using fluorescence with no requirement for a known illumination spectrum under different illumination the spectral distribution of fluorescence emitted from the same material remain unchanged up to a certain scale thus a camera s response to the fluorescence would have the same chromaticity making use of this chromaticity invariance the camera spectral sensitivity can be estimated under an arbitrary illumination whose spectrum is unknown through extensive experiment we proved that our method is accurate under different illumination moreover we show how to recover the spectrum of daylight from the estimated result finally we use the estimated camera spectral sensitivity and daylight spectrum to solve color correction problem 
we introduce a spatially dense variational approach to estimate the calibration of multiple camera in the context of d reconstruction we propose a relaxation scheme which allows to transform the original photometric error into a geometric one thereby decoupling the problem of dense matching and camera calibration in both quantitative and qualitative experiment we demonstrate that the proposed decoupling scheme allows for robust and accurate estimation of camera parameter in particular the presented dense camera calibration formulation lead to substantial improvement both in the reconstructed d geometry and in the super resolution texture estimation 
in computer vision application feature often lie on riemannian manifold with known geometry popular learning algorithm such a discriminant analysis partial least square support vector machine etc are not directly applicable to such feature due to the non euclidean nature of the underlying space hence classification is often performed in an extrinsic manner by mapping the manifold to euclidean space using kernel however for kernel based approach poor choice of kernel often result in reduced performance in this paper we address the issue of kernel selection for the classification of feature that lie on riemannian manifold using the kernel learning approach we propose two criterion for jointly learning the kernel and the classifier using a single optimization problem specifically for the svm classifier we formulate the problem of learning a good kernel classifier combination a a convex optimization problem and solve it efficiently following the multiple kernel learning approach experimental result on image set based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing method for classification of manifold feature 
this paper address the problem of automatic reconstruction of a d relief from a line drawing on top of a given base object reconstruction is challenging due to four reason the sparsity of the stroke their ambiguity their large number and their inter relation our approach is able to reconstruct a model from a complex drawing that consists of many inter related stroke rather than viewing the inter dependency a a problem we show how they can be exploited to automatically generate a good initial interpretation of the line drawing then given a base and an interpretation we propose an algorithm for reconstructing a consistent surface the strength of our approach is demonstrated in the reconstruction of archaeological artifact from drawing these drawing are highly challenging since artist created very complex and detailed description of artifact regardless of any consideration concerning their future use for shape reconstruction 
we present a hierarchical method for human pose estimation from a single still image in our approach a dependency graph representing relationship between reference point such a body joint is constructed and the position of these reference point are sequentially estimated by a successive application of multidimensional output regression along the dependency path starting from the root node each regressor take image feature computed from an image patch centered on the current node s position estimated by the previous regressor and is specialized for estimating it child node position the use of the dependency graph allows u to decompose a complex pose estimation problem into a set of local pose estimation problem that are le complex we design a dependency graph for two commonly used human pose estimation datasets the buffy stickmen dataset and the ethz pascal stickmen dataset and demonstrate that our method achieves comparable accuracy to state of the art result on both datasets with significantly lower computation time than existing method furthermore we propose an importance weighted boosted regression tree method for transductive learning setting and demonstrate the resulting improved performance for pose estimation task 
raindrop adhered to a windscreen or window glass can significantly degrade the visibility of a scene detecting and removing raindrop will therefore benefit many computer vision application particularly outdoor surveillance system and intelligent vehicle system in this paper a method that automatically detects and remove adherent raindrop is introduced the core idea is to exploit the local spatio temporal derivative of raindrop first it detects raindrop based on the motion and the intensity temporal derivative of the input video second relying on an analysis that some area of a raindrop completely occludes the scene yet the remaining area occludes only partially the method remove the two type of area separately for partially occluding area it restores them by retrieving a much a possible information of the scene namely by solving a blending function on the detected partially occluding area using the temporal intensity change for completely occluding area it recovers them by using a video completion technique experimental result using various real video show the effectiveness of the proposed method 
multi instance learning mil is an emerging topic in machine learning which ha broad application in computer vision for example by considering video classification a a mil problem where we only need labeled video clip such a tagged online video but not labeled video frame one can lower down the labeling cost which is typically very expensive we propose a novel class specific distance metric enhanced class to bag distance m c b method to learn a robust and discriminative distance for multi instance data which employ the not squared norm distance to address the most difficult challenge in mil i e the outlier instance that abound in multi instance data by nature a a result the formulated objective end up to be a simultaneous norm minimization and maximization minmax problem which is very hard to solve in general due to the non smoothness of the norm we thus present an efficient iterative algorithm to solve the general norm minmax problem with rigorously proved convergence to the best of our knowledge we are the first to solve a general norm minmax problem in literature we have conducted extensive experiment to evaluate various aspect of the proposed method in which promising result validate our new method in cost effective video classification 
in this paper we propose a novel algorithm for automatic landmark building discovery in large unstructured image collection in contrast to other approach which aim at a hard clustering we regard the task a a mode estimation problem our algorithm search for local attractor in the image distribution that have a maximal mutual homography overlap with the image in their neighborhood those attractor correspond to central iconic view of single object or building which we efficiently extract using a medoid shift search with a novel distance measure we propose efficient algorithm for performing this search most importantly our approach performs only an efficient local exploration of the matching graph that make it applicable for large scale analysis of photo collection we show experimental result validating our approach on a dataset of k image of the inner city of paris 
fast and reliable algorithm for estimating the head pose are essential for many application and higher level face analysis task we address the problem of head pose estimation from depth data which can be captured using the ever more affordable d sensing technology available today to achieve robustness we formulate pose estimation a a regression problem while detecting specific face part like the nose is sensitive to occlusion learning the regression on rather generic surface patch requires enormous amount of training data in order to achieve accurate estimate we propose to use random regression forest for the task at hand given their capability to handle large training datasets moreover we synthesize a great amount of annotated training data using a statistical model of the human face in our experiment we show that our approach can handle real data presenting large pose change partial occlusion and facial expression even though it is trained only on synthetic neutral face data we have thoroughly evaluated our system on a publicly available database on which we achieve state of the art performance without having to resort to the graphic card 
over segment i e superpixels have been commonly used a supporting region for feature vector and primitive to reduce computational complexity in various image analysis task in this paper we describe a structuresensitive over segmentation technique by exploiting lloyd s algorithm with a geodesic distance it generates smaller superpixels to achieve lower under segmentation in structure dense region with high intensity or color variation and produce larger segment to increase computational efficiency in structure sparse region with homogeneous appearance we adopt geometric flow to compute the geodesic distance amongst pixel and in the segmentation procedure the density of over segment is automatically adjusted according to an energy functional that embeds color homogeneity structure density and compactness constraint comparative experiment with the berkeley database show that the proposed algorithm outperforms prior art while offering a comparable computational efficiency with fast method such a turbopixels 
the goal of saliency detection is to locate important pixel or region in an image which attract human visual attention the most this is a fundamental task whose output may serve a the basis for further computer vision task like segmentation resizing tracking and so forth in this paper we propose a novel salient region detection algorithm by integrating three important visual cue namely uniqueness focus ness and objectness ufo in particular uniqueness capture the appearance derived visual contrast focus ness reflects the fact that salient region are often photographed in focus and objectness help keep completeness of detected salient region while uniqueness ha been used for saliency detection for long it is new to integrate focus ness and objectness for this purpose in fact focus ness and objectness both provide important saliency information complementary of uniqueness in our experiment using public benchmark datasets we show that even with a simple pixel level combination of the three component the proposed approach yield significant improvement compared with previously reported method 
the growth of detection datasets and the multiple direction of object detection research provide both an unprecedented need and a great opportunity for a thorough evaluation of the current state of the field of categorical object detection in this paper we strive to answer two key question first where are we currently a a field what have we done right what still need to be improved second where should we be going in designing the next generation of object detector inspired by the recent work of hoiem et al on the standard pascal voc detection dataset we perform a large scale study on the image net large scale visual recognition challenge ilsvrc data first we quantitatively demonstrate that this dataset provides many of the same detection challenge a the pascal voc due to it scale of object category ilsvrc also provides an excellent test bed for understanding the performance of detector a a function of several key property of the object class we conduct a series of analysis looking at how different detection method perform on a number of image level and object class level property such a texture color deformation and clutter we learn important lesson of the current object detection method and propose a number of insight for designing the next generation object detector 
adaptive tracking by detection method are widely used in computer vision for tracking arbitrary object current approach treat the tracking problem a a classification task and use online learning technique to update the object model however for these update to happen one need to convert the estimated object position into a set of labelled training example and it is not clear how best to perform this intermediate step furthermore the objective for the classifier label prediction is not explicitly coupled to the objective for the tracker accurate estimation of object position in this paper we present a framework for adaptive visual object tracking based on structured output prediction by explicitly allowing the output space to express the need of the tracker we are able to avoid the need for an intermediate classification step our method us a kernelized structured output support vector machine svm which is learned online to provide adaptive tracking to allow for real time application we introduce a budgeting mechanism which prevents the unbounded growth in the number of support vector which would otherwise occur during tracking experimentally we show that our algorithm is able to outperform state of the art tracker on various benchmark video additionally we show that we can easily incorporate additional feature and kernel into our framework which result in increased performance 
in this paper we present an approach to predict the extent and height of supporting surface such a table chair and cabinet top from a single rgbd image we define support surface to be horizontal planar surface that can physically support object and human given a rgbd image our goal is to localize the height and full extent of such surface in d space to achieve this we created a labeling tool and annotated image with rich complete d scene model in nyu dataset we extract ground truth from the annotated dataset and developed a pipeline for predicting floor space wall the height and full extent of support surface finally we match the predicted extent with annotated scene in training scene and transfer the the support surface configuration from training scene we evaluate the proposed approach in our dataset and demonstrate it effectiveness in understanding scene in d space 
joint reasoning about object and d scene layout ha shown great promise in scene interpretation one visual cue that ha been overlooked is texture arising from a spatial repetition of object in the scene e g window of a building such texture provides scene specific constraint among object and thus facilitates scene interpretation we present an approach to detecting distinct texture of object in a scene reconstructing the d shape of detected texture surface and combining object detection and shape from texture toward a globally consistent scene interpretation inference is formulated within the reinforcement learning framework a a sequential interpretation of image region starting from confident region to guide the interpretation of other region our algorithm find an optimal policy that map state of detected object and reconstructed surface to action which ought to be taken in those state including detecting new object and identifying new texture so a to minimize a long term loss test against ground truth obtained from stereo image demonstrate that we can coarsely reconstruct a d model of the scene from a single image without learning the layout of common scene surface a done in prior work we also show that reasoning about texture of object improves object detection 
with the increasing availability of high dimensional data and demand in sophisticated data analysis algorithm manifold learning becomes a critical technique to perform dimensionality reduction unraveling the intrinsic data structure the real world data however often come with noise and outlier seldom all the data live in a single linear subspace inspired by the recent advance in sparse subspace learning and diffusion based approach we propose a new manifold denoising algorithm in which data neighborhood are adaptively inferred via sparse subspace reconstruction we then derive a new formulation to perform denoising to the original data experiment carried out on both toy and real application demonstrate the effectiveness of our method it is insensitive to parameter tuning and we show significant improvement over the competing algorithm 
retrieving image to match with a hand drawn sketch query is a highly desired feature especially with the popularity of device with touch screen although query by sketch ha been extensively studied since s it is still very challenging to build a real time sketch based image search engine on a large scale database due to the lack of effective and efficient matching indexing solution the explosive growth of web image and the phenomenal success of search technique have encouraged u to revisit this problem and target at solving the problem of web scale sketch based image retrieval in this work a novel index structure and the corresponding raw contour based matching algorithm are proposed to calculate the similarity between a sketch query and natural image and make sketch based image retrieval scalable to million of image the proposed solution simultaneously considers storage cost retrieval accuracy and efficiency based on which we have developed a real time sketch based image search engine by indexing more than million image extensive experiment on various retrieval task basic shape search specific image search and similar image search show better accuracy and efficiency than state of the art method 
we propose neil never ending image learner a computer program that run hour per day and day per week to automatically extract visual knowledge from internet data neil us a semi supervised learning algorithm that jointly discovers common sense relationship e g corolla is a kind of look similar to car wheel is a part of car and label instance of the given visual category it is an attempt to develop the world s largest visual structured knowledge base with minimum human labeling effort a of th october neil ha been continuously running for month on core cluster more than k cpu hour and ha an ontology of object category scene category and attribute during this period neil ha discovered more than relationship and ha labeled more than k visual instance 
we present a general model for tracking smooth trajectory of multiple target in complex data set where track potentially cross each other many time a the number of overlapping trajectory grows exploiting smoothness becomes increasingly important to disambiguate the association of successive point however in many important problem an effective parametric model for the trajectory doe not exist hence we propose modeling trajectory a independent realization of gaussian process with kernel function which allow for arbitrary smooth motion our generative statistical model account for the data a coming from an unknown number of such process together with expectation for noise point and the probability that point are missing for inference we compare two method a modified version of the markov chain monte carlo data association mcmcda method and a gibbs sampling method which is much simpler and faster and give better result by being able to search the solution space more efficiently in both case we compare our result against the smoothing provided by linear dynamical system lds we test our approach on video of bird and fish and on image sequence of pollen tube growing in a petri dish each with up to tube with multiple crossing we achieve accuracy on image sequence with up to ten trajectory sequence and accuracy when there are more than ten sequence this performance surpasses that of using an lds motion model and far exceeds a simple heuristic tracker 
we present an object detection system based on the fisher vector fv image representation computed over sift and color descriptor for computational and storage efficiency we use a recent segmentation based method to generate class independent object detection hypothesis in combination with data compression technique our main contribution is a method to produce tentative object segmentation mask to suppress background clutter in the feature re weighting the local image feature based on these mask is shown to improve object detection significantly we also exploit contextual feature in the form of a full image fv descriptor and an inter category rescoring mechanism our experiment on the voc and datasets show that our detector improves over the current state of the art detection result 
in recent year the availability of inexpensive depth camera such a the microsoft kinect ha boosted the research in monocular full body skeletal pose tracking unfortunately existing tracker often fail to capture pose where a single camera provides insufficient data such a non frontal pose and all other pose with body part occlusion in this paper we present a novel sensor fusion approach for real time full body tracking that succeeds in such difficult situation it take inspiration from previous tracking solution and combine a generative tracker and a discriminative tracker retrieving closest pose in a database in contrast to previous work both tracker employ data from a low number of inexpensive body worn inertial sensor these sensor provide reliable and complementary information when the monocular depth information alone is not sufficient we also contribute by new algorithmic solution to best fuse depth and inertial data in both tracker one is a new visibility model to determine global body pose occlusion and usable depth correspondence and to decide what data modality to use for discriminative tracking we also contribute with a new inertial based pose retrieval and an adapted late fusion step to calculate the final body pose 
we propose an unsupervised image segmentation method based on texton similarity and mode seeking the input image is first convolved with a filter bank followed by soft clustering on it filter response to generate textons the input image is then superpixelized where each belonging pixel is regarded a a voter and a soft voting histogram is constructed for each superpixel by averaging it voter posterior texton probability we further propose a modified mode seeking method called convex shift to group superpixels and generate segment the distribution of superpixel histogram is modeled nonparametrically in the histogram space using kullback leibler divergence k l divergence and kernel density estimation we show that each kernel shift step can be formulated a a convex optimization problem with linear constraint experiment on image segmentation show that convex shift performs mode seeking effectively on an enforced histogram structure grouping visually similar superpixels with the incorporation of texton and soft voting our method generates reasonably good segmentation result on natural image with relatively complex content showing significant superiority over traditional mode seeking based segmentation method while outperforming or being comparable to state of the art method 
our objective is transfer training of a discriminatively trained object category detector in order to reduce the number of training image required to this end we propose three transfer learning formulation where a template learnt previously for other category is used to regularize the training of a new category all the formulation result in convex optimization problem experiment on pascal voc demonstrate significant performance gain by transfer learning from one class to another e g motorbike to bicycle including one shot learning specialization from class to a subordinate class e g from quadruped to horse and transfer using multiple component in the case of multiple training sample it is shown that a detection performance approaching that of the state of the art can be achieved with substantially fewer training sample 
shape is a natural highly prominent characteristic of object that human vision utilizes everyday but despite it expressiveness shape pose significant challenge for category level object detection in cluttered scene object form is an emergent property that cannot be perceived locally but becomes only available once the whole object ha been detected and segregated from the background thus we address the detection of object and the assembling of their shape simultaneously a dictionary of meaningful contour is obtained by clustering based on contour co activation in all training image we seek a joint consistent placement of all contour in an image since placing them independently from another is not reliable due to the emergence of shape therefore the characteristic object shape is learned by discovering spatially consistent configuration of all dictionary contour using maximum margin multiple instance learning during recognition object are detected and their shape is explained simultaneously by optimizing a single cost function we demonstrate the benefit of our approach on standard shape benchmark 
we reexamine the role of multiscale cue in image segmentation using an architecture that construct a globally coherent scale space output representation this characteristic is in contrast to many existing work on bottom up segmentation which prematurely compress information into a single scale the architecture is a standard extension of normalized cut from an image plane to an image pyramid with cross scale constraint enforcing consistency in the solution while allowing emergence of coarse to fine detail we observe that multiscale processing in addition to improving segmentation quality offer a route by which to speed computation we make a significant algorithmic advance in the form of a custom multigrid eigensolver for constrained angular embedding problem possessing coarse to fine structure multiscale normalized cut is a special case our solver build atop recent result on randomized matrix approximation using a novel interpolation operation to mold it computational strategy according to cross scale constraint in the problem definition applying our solver to multiscale segmentation problem demonstrates speedup by more than an order of magnitude this speedup is at the algorithmic level and carry over to any implementation target 
we address the problem of recovering shape albedo and illumination from a single grayscale image of an object using shading a our primary cue because this problem is fundamentally underconstrained we construct statistical model of albedo and shape and define an optimization problem that search for the most likely explanation of a single image we present two prior on albedo which encourage local smoothness and global sparsity and three prior on shape which encourage flatness outward facing orientation at the occluding contour and local smoothness we present an optimization technique for using these prior to recover shape albedo and a spherical harmonic model of illumination our model which we call saifs shape albedo and illumination from shading produce reasonable result on arbitrary grayscale image taken in the real world and outperforms all previous grayscale intrinsic image style algorithm on the mit intrinsic image dataset 
unsupervised categorization of object is a fundamental problem in computer vision while appearance based method have become popular recently other important cue like functionality are largely neglected motivated by psycho logical study giving evidence that human demonstration ha a facilitative effect on categorization in infancy we pro pose an approach for object categorization from depth video stream to this end we have developed a method for cap turing human motion in real time the captured data is then used to temporally segment the depth stream into action the set of segmented action are then categorized in an un supervised manner through a novel descriptor for motion capture data that is robust to subject variation further more we automatically localize the object that is manipulated within a video segment and categorize it using the corresponding action for evaluation we have recorded a dataset that comprises depth data with registered video sequence for subject action class and object manipulation 
we propose a new model for recognizing human attribute e g wearing a suit sitting short hair and action e g running riding a horse in still image the proposed model relies on a collection of part template which are learnt discriminatively to explain specific scale space location in the image in human centric coordinate it avoids the limitation of highly structured model which consist of a few i e a mixture of average template to learn our model we propose an algorithm which automatically mine out part and learns corresponding discriminative template with their respective location from a large number of candidate part we validate the method on recent challenging datasets i willow action ii human attribute hat and iii stanford action we obtain convincing qualitative and state of the art quantitative result on the three datasets 
this paper address the problem of facial landmark localization and tracking from a single camera we present a two stage cascaded deformable shape model to effectively and efficiently localize facial landmark with large head pose variation for face detection we propose a group sparse learning method to automatically select the most salient facial landmark by introducing d face shape model we use procrustes analysis to achieve pose free facial landmark initialization for deformation the first step us mean shift local search with constrained local model to rapidly approach the global optimum the second step us component wise active contour to discriminatively refine the subtle shape variation our framework can simultaneously handle face detection pose free landmark localization and tracking in real time extensive experiment are conducted on both laboratory environmental face database and face in the wild database all result demonstrate that our approach ha certain advantage over state of the art method in handling pose variation 
most research effort on image classification so far have been focused on medium scale datasets which are often defined a datasets that can fit into the memory of a desktop typically g g there are two main reason for the limited effort on large scale image classification first until the emergence of imagenet dataset there wa almost no publicly available large scale benchmark data for image classification this is mostly because class label are expensive to obtain second large scale classification is hard because it pose more challenge than it medium scale counterpart a key challenge is how to achieve efficiency in both feature extraction and classifier training without compromising performance this paper is to show how we address this challenge using imagenet dataset a an example for feature extraction we develop a hadoop scheme that performs feature extraction in parallel using hundred of mapper this allows u to extract fairly sophisticated feature with dimension being hundred of thousand on million image within one day for svm training we develop a parallel averaging stochastic gradient descent asgd algorithm for training one against all class svm classifier the asgd algorithm is capable of dealing with terabyte of training data and converges very fast typically epoch are sufficient a a result we achieve state of the art performance on the imagenet class classification i e in classification accuracy and in top hit rate 
this work aim at introducing a new unified structure from motion sfm paradigm in which image of circular point pair can be combined with image of natural point an imaged circular point pair encodes the d euclidean structure of a world plane and can easily be derived from the image of a planar shape especially those including circle a classical sfm method generally run two step first a projective factorization of all matched image point into projective camera and point and second a camera self calibration that update the obtained world from projective to euclidean this work show how to introduce image of circular point in these two sfm step while it key contribution is to provide the theoretical foundation for combining classical linear self calibration constraint with additional one derived from such image we show that the two proposed sfm step clearly contribute to better result than the classical approach we validate our contribution on synthetic and real image 
temporal alignment of human behaviour from visual data is a very challenging problem due to a numerous reason including possible large temporal scale difference inter intra subject variability and more importantly due to the presence of gross error and outlier gross error are often in abundance due to incorrect localization and tracking presence of partial occlusion etc furthermore such error rarely follow a gaussian distribution which is the de facto assumption in machine learning method in this paper building on recent advance on rank minimization and compressive sensing a novel robust to gross error temporal alignment method is proposed while previous approach combine the dynamic time warping dtw with low dimensional projection that maximally correlate two sequence we aim to learn two underlying projection matrix one for each sequence which not only maximally correlate the sequence but at the same time efficiently remove the possible corruption in any datum in the sequence the projection are obtained by minimizing the weighted sum of nuclear and ell norm by solving a sequence of convex optimization problem while the temporal alignment is found by applying the dtw in an alternating fashion the superiority of the proposed method against the state of the art time alignment method namely the canonical time warping and the generalized time warping is indicated by the experimental result on both synthetic and real datasets 
data fusion which effectively fuse multiple prediction list from different kind of feature to obtain an accurate model is a crucial component in various computer vision application robust late fusion rlf is a recent proposed method that fuse multiple output score list from different model via pursuing a shared low rank latent matrix despite showing promising performance the repeated full singular value decomposition operation in rlf s optimization algorithm limit it scalability in real world vision datasets which usually have large number of test example to address this issue we provide a scalable solution for large scale low rank latent matrix pursuit by a divide and conquer method the proposed method divide the original low rank latent matrix learning problem into two size reduced sub problem which may be solved via any base algorithm and combine the result from the sub problem to obtain the final solution our theoretical analysis show that with fixed probability the proposed divide and conquer method ha recovery guarantee comparable to those of it base algorithm moreover we develop an efficient base algorithm for the corresponding sub problem by factorizing a large matrix into the product of two size reduced matrix we also provide high probability recovery guarantee of the base algorithm the proposed method is evaluated on various fusion problem in object categorization and video event detection under comparable accuracy the proposed method performs more than time faster than the state of the art baseline on the ccv dataset with about test example for video event detection 
due to their high fault tolerance ease of installation and scalability to large network distributed algorithm have recently gained immense popularity in the sensor network community especially in computer vision multi target tracking in a camera network is one of the fundamental problem in this domain distributed estimation algorithm work by exchanging information between sensor that are communication neighbor since most camera are directional sensor it is often the case that neighboring sensor may not be sensing the same target such sensor that do not have information about a target are termed a naive with respect to that target in this paper we propose consensus based distributed multi target tracking algorithm in a camera network that are designed to address this issue of naivety the estimation error in tracking and data association a well a the effect of naivety are jointly addressed leading to the development of an information weighted consensus algorithm which we term a the multi target information consensus mtic algorithm the incorporation of the probabilistic data association mechanism make the mtic algorithm very robust to false measurement clutter experimental analysis is provided to support the theoretical result 
this paper considers a family of metric to compare image based on their local descriptor it encompasses the vlad descriptor and matching technique such a hamming embedding making the bridge between these approach lead u to propose a match kernel that take the best of existing technique by combining an aggregation procedure with a selective match kernel finally the representation underpinning this kernel is approximated providing a large scale image search both precise and scalable a shown by our experiment on several benchmark 
the performance of a generic pedestrian detector may drop significantly when it is applied to a specific scene due to mismatch between the source dataset used to train the detector and sample in the target scene in this paper we investigate how to automatically train a scene specific pedestrian detector starting with a generic detector in video surveillance without further manually labeling any sample under a novel transfer learning framework it tackle the problem from three aspect with a graphical representation and through exploring the indegrees from target sample to source sample the source sample are properly re weighted the indegrees detect the boundary between the distribution of the source dataset and the target dataset the re weighted source dataset better match the target scene it take the context information from motion scene structure and scene geometry a the confidence score of sample from the target scene to guide transfer learning the confidence score propagate among sample on a graph according to the underlying visual structure of sample all these consideration are formulated under a single objective function called confidence encoded svm at the test stage only the appearance based detector is used without the context cue the effectiveness of the proposed framework is demonstrated through experiment on two video surveillance datasets compared with a generic pedestrian detector it significantly improves the detection rate by and at one false positive per image on the two datasets respectively 
in this paper we propose a temporal super resolution approach for quasi periodic image sequence such a human gait the proposed method effectively combine example based and reconstruction based temporal super resolution approach a periodic image sequence is expressed a a manifold parameterized by a phase and a standard manifold is learned from multiple high frame rate sequence in the training stage in the test stage an initial phase for each frame of an input low frame rate image sequence is estimated based on the standard manifold at first and the manifold reconstruction and the phase estimation are then iterated to generate better high frame rate image in the energy minimization framework that ensures the fitness to both the input image and the standard manifold the proposed method is applied to low frame rate gait recognition and experiment with real data of subject demonstrate a significant improvement by the proposed method particularly for quite low frame rate video e g fps 
we address the problem of segmenting and recognizing object in real world image focusing on challenging articulated category such a human and other animal for this purpose we propose a novel design for region based object detector that integrates efficiently top down information from scanning window part model and global appearance cue our detector produce class specific score for bottom up region and then aggregate the vote of multiple overlapping candidate through pixel classification we evaluate our approach on the pascal segmentation challenge and report competitive performance with respect to current leading technique on voc our method obtains the best result in category and the highest performance on articulated object 
the original mean shift algorithm on euclidean space m wa extended in to operate on general riemannian manifold this extension is extrinsic ext m since the mode seeking is performed on the tangent space where the underlying curvature is not fully considered tangent space are only valid in a small neighborhood in wa proposed an intrinsic mean shift designed to operate on two particular riemannian manifold intgs m i e grassmann and stiefel manifold using manifold dedicated density kernel it is then natural to ask whether mean shift could be intrinsically extended to work on a large class of manifold we propose a novel paradigm to intrinsically reformulate the mean shift on general riemannian manifold this is accomplished by embedding the riemannian manifold into a reproducing kernel hilbert space rkhs by using a general and mathematically well founded riemannian kernel function i e heat kernel the key issue is that when the data is implicitly mapped to the hilbert space the curvature of the manifold is taken into account i e exploit the underlying information of the data the inherent optimization is then performed on the embedded space theoretic analysis and experimental result demonstrate the promise and effectiveness of this novel paradigm 
with an explosion of popularity of online photo sharing we can trivially collect a huge number of photo stream for any interesting topic such a scuba diving a an outdoor recreational activity class obviously the retrieved photo stream are neither aligned nor calibrated since they are taken in different temporal spatial and personal perspective however at the same time they are likely to share common storyline that consist of sequence of event and activity frequently recurred within the topic in this paper a a first technical step to detect such collective storyline we propose an approach to jointly aligning and segmenting uncalibrated multiple photo stream the alignment task discovers the matched image between different photo stream and the image segmentation task par each image into multiple meaningful region to facilitate the image understanding we close a loop between the two task so that solving one task help enhance the performance of the other in a mutually rewarding way to this end we design a scalable message passing based optimization framework to jointly achieve both task for the whole input image set at once with evaluation on the new flickr dataset of outdoor activity that consist of million of image of thousand of photo stream our empirical result show that the proposed algorithm are more successful than other candidate method for both task 
we show that solving the lp relaxation of the map inference problem in graphical model also known a the min sum problem energy minimization or weighted constraint satisfaction is not easier than solving any lp more precisely any polytope is linear time represent able by a local marginal polytope and any lp can be reduced in linear time to a linear optimization allowing infinite weight over a local marginal polytope 
in order to avail the benefit of higher user convenience hygiene and improved accuracy contact le d fingerprint recognition technique have recently been introduced one of the key limitation of these emerging d fingerprint technology to replace the conventional d fingerprint system is their bulk and high cost which mainly result from the use of multiple imaging camera or structured lighting employed in these system this paper detail the development of a contact le d fingerprint identification system that us only single camera we develop a new representation of d finger surface feature using finger surface code and illustrate it effectiveness in matching d fingerprint conventional minutia representation is extended in d space to accurately match the recovered d minutia multiple d fingerprint image with varying illumination profile acquired to build d fingerprint can themselves be used recover d feature for further improving d fingerprint identification and ha been illustrated in this paper the experimental result are shown on a database of client fingerprint and confirm the advantage of the single camera based d fingerprint identification 
repeated structure such a building facade fence or road marking often represent a significant challenge for place recognition repeated structure are notoriously hard for establishing correspondence using multi view geometry even more importantly they violate the feature independence assumed in the bag of visual word representation which often lead to over counting evidence and significant degradation of retrieval performance in this work we show that repeated structure are not a nuisance but when appropriately represented they form an important distinguishing feature for many place we describe a representation of repeated structure suitable for scalable retrieval it is based on robust detection of repeated image structure and a simple modification of weight in the bag of visual word model place recognition result are shown on datasets of street level imagery from pittsburgh and san francisco demonstrating significant gain in recognition performance compared to the standard bag of visual word baseline and more recently proposed burstiness weighting 
we investigate projective estimation under model inadequacy i e when the underpinning assumption of the projective model are not fully satisfied by the data we focus on the task of image stitching which is customarily solved by estimating a projective warp a model that is justified when the scene is planar or when the view differ purely by rotation such condition are easily violated in practice and this yield stitching result with ghosting artefact that necessitate the usage of deghosting algorithm to this end we propose a projective a possible warp i e warp that aim to be globally projective yet allow local non projective deviation to account for violation to the assumed imaging condition based on a novel estimation technique called moving direct linear transformation moving dlt our method seamlessly bridge image region that are inconsistent with the projective model the result is highly accurate image stitching with significantly reduced ghosting effect thus lowering the dependency on post hoc deghosting 
point trajectory have emerged a a powerful mean to obtain high quality and fully unsupervised segmentation of object in video shot they can exploit the long term motion difference between object but they tend to be sparse due to computational reason and the difficulty in estimating motion in homogeneous area in this paper we introduce a variational method to obtain dense segmentation from such sparse trajectory cluster information is propagated with a hierarchical nonlinear diffusion process that run in the continuous domain but take superpixels into account we show that this process raise the density from to and even increase the average precision of label 
in this paper we formulate object tracking in a particle filter framework a a multi task sparse learning problem which we denote a multi task tracking mtt since we model particle a linear combination of dictionary template that are updated dynamically learning the representation of each particle is considered a single task in mtt by employing popular sparsity inducing p q mixed norm p and q we regularize the representation problem to enforce joint sparsity and learn the particle representation together a compared to previous method that handle particle independently our result demonstrate that mining the interdependency between particle improves tracking performance and overall computational complexity interestingly we show that the popular l tracker is a special case of our mtt formulation denoted a the l tracker when p q the learning problem can be efficiently solved using an accelerated proximal gradient apg method that yield a sequence of closed form update a such mtt is computationally attractive we test our proposed approach on challenging sequence involving heavy occlusion drastic illumination change and large pose variation experimental result show that mtt method consistently outperform state of the art tracker 
explosive growth of surveillance video data present formidable challenge to it browsing retrieval and storage video synopsis an innovation proposed by peleg and his colleague is aimed for fast browsing by shortening the video into a synopsis while keeping activity in video captured by a camera however the current technique are offline method requiring that all the video data be ready for the processing and are expensive in time and space in this paper we propose an online and efficient solution and it supporting algorithm to overcome the problem the method adopts an online content aware approach in a step wise manner hence applicable to endless video with le computational cost moreover we propose a novel tracking method called sticky tracking to achieve high quality visualization the system can achieve a faster than real time speed with a multi core cpu implementation the advantage are demonstrated by extensive experiment with a wide variety of video the proposed solution and algorithm could be integrated with surveillance camera and impact the way that surveillance video are recorded 
we introduce an online learning approach for multitarget tracking detection response are gradually associated into tracklets in multiple level to produce final track unlike most previous approach which only focus on producing discriminative motion and appearance model for all target we further consider discriminative feature for distinguishing difficult pair of target the tracking problem is formulated using an online learned crf model and is transformed into an energy minimization problem the energy function include a set of unary function that are based on motion and appearance model for discriminating all target a well a a set of pairwise function that are based on model for differentiating corresponding pair of tracklets the online crf approach is more powerful at distinguishing spatially close target with similar appearance a well a in dealing with camera motion an efficient algorithm is introduced for finding an association with low energy cost we evaluate our approach on three public data set and show significant improvement compared with several state of art method 
recent work on background subtraction ha shown development on two major front in one there ha been increasing sophistication of probabilistic model from mixture of gaussians at each pixel to kernel density estimate at each pixel and more recently to joint domainrange density estimate that incorporate spatial information another line of work ha shown the benefit of increasingly complex feature representation including the use of texture information local binary pattern and recently scale invariant local ternary pattern in this work we use joint domain range based estimate for background and foreground score and show that dynamically choosing kernel variance in our kernel estimate at each individual pixel can significantly improve result we give a heuristic method for selectively applying the adaptive kernel calculation which is nearly a accurate a the full procedure but run much faster we combine these modeling improvement with recently developed complex feature and show significant improvement on a standard backgrounding benchmark 
many human action recognition task involve data that can be factorized into multiple view such a body posture and hand shape these view often interact with each other over time providing important cue to understanding the action we present multi view latent variable discriminative model that jointly learn both view shared and view specific sub structure to capture the interaction between view knowledge about the underlying structure of the data is formulated a a multi chain structured latent conditional model explicitly learning the interaction between multiple view using disjoint set of hidden variable in a discriminative manner the chain are tied using a predetermined topology that repeat over time we present three topology linked coupled and linked coupled that differ in the type of interaction between view that they model we evaluate our approach on both segmented and unsegmented human action recognition task using the armgesture the natops and the armgesture continuous data experimental result show that our approach outperforms previous state of the art action recognition model 
we propose a method of clustering image that combine algorithmic and human input an algorithm provides u with pairwise image similarity we then actively obtain selected more accurate pairwise similarity from human a novel method is developed to choose the most useful pair to show a person obtaining constraint that improve clustering in a clustering assignment element in each data pair are either in the same cluster or in different cluster we simulate inverting these pairwise relation and see how that affect the overall clustering we choose a pair that maximizes the expected change in the clustering the proposed algorithm ha high time complexity so we also propose a version of this algorithm that is much faster and exactly replicates our original algorithm we further improve run time by adding heuristic and show that these do not significantly impact the effectiveness of our method we have run experiment in two different domain namely leaf image and face image and show that clustering performance can be improved significantly 
in real world application of visual recognition many factor such a pose illumination or image quality can cause a significant mismatch between the source domain on which classifier are trained and the target domain to which those classifier are applied a such the classifier often perform poorly on the target domain domain adaptation technique aim to correct the mismatch existing approach have concentrated on learning feature representation that are invariant across domain and they often do not directly exploit low dimensional structure that are intrinsic to many vision datasets in this paper we propose a new kernel based method that take advantage of such structure our geodesic flow kernel model domain shift by integrating an infinite number of subspace that characterize change in geometric and statistical property from the source to the target domain our approach is computationally advantageous automatically inferring important algorithmic parameter without requiring extensive cross validation or labeled data from either domain we also introduce a metric that reliably measure the adaptability between a pair of source and target domain for a given target domain and several source domain the metric can be used to automatically select the optimal source domain to adapt and avoid le desirable one empirical study on standard datasets demonstrate the advantage of our approach over competing method 
latent variable model provide valuable compact representation for learning and inference in many computer vision task however most existing model cannot directly encode prior knowledge about the specific problem at hand in this paper we introduce a constrained latent variable model whose generated output inherently account for such knowledge to this end we propose an approach that explicitly imposes equality and inequality constraint on the model s output during learning thus avoiding the computational burden of having to account for these constraint at inference our learning mechanism can exploit non linear kernel while only involving sequential closed form update of the model parameter we demonstrate the effectiveness of our constrained latent variable model on the problem of non rigid d reconstruction from monocular image and show that it yield qualitative and quantitative improvement over several baseline 
we introduce a framework for defining a distance on the non euclidean space of linear dynamical system ldss the proposed distance is induced by the action of the group of orthogonal matrix on the space of statespace realization of ldss this distance can be efficiently computed for large scale problem hence it is suitable for application in the analysis of dynamic visual scene and other high dimensional time series based on this distance we devise a simple lds averaging algorithm which can be used for classification and clustering of time series data we test the validity a well a the performance of our group action based distance on synthetic a well a real data and provide comparison with state of the art method 
previous metric learning approach learn a unified metric for all the class on single feature representation thus cannot be directly transplanted to application involving multiple feature hundred to thousand of hierarchical structured semantics and abundant social tagging in this paper we propose a novel multi task multi feature metric learning method which model the information sharing mechanism among different learning task we decompose the real world multi class problem such a semantic categorization or automatic tagging into a set of task where each task corresponds to several class with strong visual correlation we conduct metric learning to learn a set of hyper category specific metric for all the task by encouraging model sharing among task more generalization power is acquired another advantage is the capability of simultaneous learning with semantic information and social tagging based on the multi task learning framework and thus they both benefit from the information provided by each other experiment demonstrate the advantage on application including semantic categorization and automatic tagging compared with other popular metric learning approach 
efficient learning with non linear kernel is often based on extracting feature from the data that linearise the kernel while most construction aim at obtaining low dimensional and dense feature in this work we explore high dimensional and sparse one we give a method to compute sparse feature for arbitrary kernel re deriving a a special case a popular map for the intersection kernel and extending it to arbitrary additive kernel we show that bundle optimisation method can handle efficiently these sparse feature in learning a an application we show that product quantisation can be interpreted a a sparse feature encoding and use this to significantly accelerate learning with this technique we demonstrate these idea on image classification with fisher kernel and object detection with deformable part model on the challenging pascal voc data obtaining five to ten fold speed ups a well a reducing memory use by an order of magnitude 
we describe a novel max margin parameter learning approach for structured prediction problem under certain non decomposable performance measure structured prediction is a common approach in many vision problem non decomposable performance measure are also commonplace however efficient general method for learning parameter against non decomposable performance measure do not exist in this paper we develop such a method based on dual decomposition that is applicable to a large class of non decomposable performance measure we exploit dual decomposition to factorize the original hard problem into two smaller problem and show how to optimize each factor efficiently we show experimentally that the proposed approach significantly outperforms alternative which either sacrifice the model structure or approximate the performance measure and is an order of magnitude faster than a previous approach with comparable result 
the classical relieff and f statistic feature selection can not be directly applied into multi label problem due to the ambiguity produced from a data point attributed to multiple class simultaneously in this paper we present mrelieff and mf statistic algorithm for multi label feature selection discriminant feature are selected to boost the multi label classification accuracy the proposed mrelieff and mf statistic can be used in image categorization and annotation problem extensive experiment on image annotation task show the good performance of our approach to our knowledge this is the first work to generalize the relieff and f statistic feature selection algorithm for multi label image annotation task 
linear svms are efficient in both training and testing however the data in real application is rarely linearly separable non linear kernel svms are too computationally intensive for application with large scale data set recently locally linear classifier have gained popularity due to their efficiency whilst remaining competitive with kernel method the vanilla nearest neighbor algorithm is one of the simplest locally linear classifier but it lack robustness due to the noise often present in real world data in this paper we introduce a novel local classifier parametric nearest neighbor p nn and it extension ensemble of p nn ep nn we parameterize the nearest neighbor algorithm based on the minimum weighted squared euclidean distance between the data point and the prototype where a prototype is represented by a locally linear combination of some data point meanwhile our method attempt to jointly learn both the prototype and the classifier parameter discriminatively via max margin this make our classifier suitable to approximate the classification decision boundary locally based on nonlinear function during testing the computational complexity of both classifier is linear in the product of the dimension of data and the number of prototype our classification result on mnist usps letter and char k are comparable and in some case are better than many other method such a the state of the art locally linear classifier 
in this paper we raise important issue on scalability and the required degree of supervision of existing mahalanobis metric learning method often rather tedious optimization procedure are applied that become computationally intractable on a large scale further if one considers the constantly growing amount of data it is often infeasible to specify fully supervised label for all data point instead it is easier to specify label in form of equivalence constraint we introduce a simple though effective strategy to learn a distance metric from equivalence constraint based on a statistical inference perspective in contrast to existing method we do not rely on complex optimization problem requiring computationally expensive iteration hence our method is order of magnitude faster than comparable method result on a variety of challenging benchmark with rather diverse nature demonstrate the power of our method these include face in unconstrained environment matching before unseen object instance and person re identification across spatially disjoint camera in the latter two benchmark we clearly outperform the state of the art 
graph cut is a popular algorithm for finding the map assignment of many large scale graphical model that are common in computer vision while graph cut is powerful it doe not provide information about the marginal probability associated with the solution it find to ass uncertainty we are forced to fall back on le efficient and inexact inference algorithm such a loopy belief propagation or use le principled surrogate representation of uncertainty such a the min marginal approach of kohli torr in this work we give new justification for using min marginals to compute the uncertainty in conditional random field framing the min marginal output a exact marginals under a specially chosen generative probabilistic model we leverage this view to learn properly calibrated marginal probability a the result of straightforward maximization of the training likelihood showing that the necessary subgradients can be computed efficiently using dynamic graph cut operation we also show how this approach can be extended to compute multi label marginal distribution where again dynamic graph cut enable efficient marginal inference and maximum likelihood learning we demonstrate empirically that after proper training uncertainty based on min marginals provide better calibrated probability than baseline and that these distribution can be exploited in a decision theoretic way for improved segmentation in low level vision 
with the ever expanding volume of visual content available the ability to organize and navigate such content by aesthetic preference is becoming increasingly important while still in it nascent stage research into computational model of aesthetic preference already show great potential however to advance research realistic diverse and challenging database are needed to this end we introduce a new large scale database for conducting aesthetic visual analysis ava it contains over image along with a rich variety of meta data including a large number of aesthetic score for each image semantic label for over category a well a label related to photographic style we show the advantage of ava with respect to existing database in term of scale diversity and heterogeneity of annotation we then describe several key insight into aesthetic preference afforded by ava finally we demonstrate through three application how the large scale of ava can be leveraged to improve performance on existing preference task 
the problem of simultaneous feature extraction and selection for classifier design is considered a new framework is proposed based on boosting algorithm that can either select existing feature or assemble a combination of these feature this framework is simple and mathematically sound derived from the statistical view of boosting and taylor series approximation in functional space unlike classical boosting which is limited to linear feature combination the new algorithm support more sophisticated combination of weak learner such a sum of product or product of sum this is shown to enable the design of fairly complex predictor structure with few weak learner in a fully automated manner leading to faster and more accurate classifier based on more informative feature extensive experiment on synthetic data uci datasets object detection and scene recognition show that these predictor consistently lead to more accurate classifier than classical boosting algorithm 
we present a sensor fusion scheme that combine active stereo with photometric stereo aiming at capturing full frame depth for dynamic scene at a minimum of three lighting condition we formulate an iterative optimization scheme that adaptively adjusts the contribution from photometric stereo so that discontinuity can be preserved detects shadow area by checking the visibility of the estimated point with respect to the light source instead of using image based heuristic and behaves well for ill conditioned pixel that are under shadow which are inevitable in almost any scene furthermore we decompose our non linear cost function into subproblems that can be optimized efficiently using linear technique experiment show significantly improved result over the previous state of the art in sensor fusion 
image denoising can be described a the problem of mapping from a noisy image to a noise free image the best currently available denoising method approximate this mapping with cleverly engineered algorithm in this work we attempt to learn this mapping directly with a plain multi layer perceptron mlp applied to image patch while this ha been done before we will show that by training on large image database we are able to compete with the current state of the art image denoising method furthermore our approach is easily adapted to le extensively studied type of noise by merely exchanging the training data for which we achieve excellent result a well 
in this paper we propose a method to select a discriminative set of image processing operation for linear discriminant analysis lda a an application of the use of generating matrix representing image processing operator acting on image first we show that generating matrix can be used for formulating lda with increasing training sample then analyze them a image processing operator acting on d continuous function for compressing many large generating matrix by using pca and hermite decomposition then we propose linear discriminative image processing operator analysis an iterative method for estimating lda feature space along with a discriminative set of generating matrix in experiment we demonstrate that discriminative generating matrix outperform a non discriminative set on the orl and feret datasets 
in this paper we propose a bilevel sparse coding model for coupled feature space where we aim to learn dictionary for sparse modeling in both space while enforcing some desired relationship between the two signal space we first present our new general sparse coding model that relates signal from the two space by their sparse representation and the corresponding dictionary the learning algorithm is formulated a a generic bilevel optimization problem which is solved by a projected first order stochastic gradient descent algorithm this general sparse coding model can be applied to many specific application involving coupled feature space in computer vision and signal processing in this work we tailor our general model to learning dictionary for compressive sensing recovery and single image super resolution to demonstrate it effectiveness in both case the new sparse coding model remarkably outperforms previous approach in term of recovery accuracy 
in this paper we study human age estimation in face image under significant expression change we will address two issue is age estimation affected by facial expression change and how significant is the influence how to develop a robust method to perform age estimation undergoing various facial expression change this systematic study will not only discover the relation between age estimation and expression change but also contribute a robust solution to solve the problem of cross expression age estimation this study is an important step towards developing a practical and robust age estimation system that allows user to present their face naturally with various expression rather than constrained to the neutral expression only two database originally captured in the psychology community are introduced to computer vision to quantitatively demonstrate the influence of expression change on age estimation and evaluate the proposed framework and corresponding method for cross expression age estimation 
we propose a novel discriminative learning approach to image set classification by modeling the image set with it natural second order statistic i e covariance matrix since nonsingular covariance matrix a k a symmetric positive definite spd matrix lie on a riemannian manifold classical learning algorithm cannot be directly utilized to classify point on the manifold by exploring an efficient metric for the spd matrix i e log euclidean distance led we derive a kernel function that explicitly map the covariance matrix from the riemannian manifold to a euclidean space with this explicit mapping any learning method devoted to vector space can be exploited in either it linear or kernel formulation linear discriminant analysis lda and partial least square pls are considered in this paper for their feasibility for our specific problem we further investigate the conventional linear subspace based set modeling technique and cast it in a unified framework with our covariance matrix based modeling the proposed method is evaluated on two task face recognition and object categorization extensive experimental result show not only the superiority of our method over state of the art one in both accuracy and efficiency but also it stability to two real challenge noisy set data and varying set size 
we introduce regression tree field rtfs a fully conditional random field model for image labeling problem rtfs gain their expressive power from the use of non parametric regression tree that specify a tractable gaussian random field thereby ensuring globally consistent prediction our approach improves on the recently introduced decision tree field dtf model in three key way i rtfs have tractable test time inference making efficient optimal prediction feasible and order of magnitude faster than for dtfs ii rtfs can be applied to both discrete and continuous vector valued labeling task and hi the entire model including the structure of the regression tree and energy function parameter can be efficiently and jointly learned from training data we demonstrate the expressive power and flexibility of the rtf model on a wide variety of task including inpainting colorization denoising and joint detection and registration we achieve excellent predictive performance which is on par with or even surpassing dtfs on all task where a comparison is possible 
automated facial expression recognition ha received increased attention over the past two decade existing work in the field usually do not encode either the temporal evolution or the intensity of the observed facial display they also fail to jointly model multidimensional multi class continuous facial behaviour data binary classifier one for each target basic emotion class are used instead in this paper intrinsic topology of multidimensional continuous facial affect data is first modeled by an ordinal manifold this topology is then incorporated into the hidden conditional ordinal random field h corf framework for dynamic ordinal regression by constraining h corf parameter to lie on the ordinal manifold the resulting model attains simultaneous dynamic recognition and intensity estimation of facial expression of multiple emotion to the best of our knowledge the proposed method is the first one to achieve this on both deliberate a well a spontaneous facial affect data 
in this paper we present a new method for facial age estimation based on ordinal discriminative feature learning considering the temporally ordinal and continuous characteristic of aging process the proposed method not only aim at preserving the local manifold structure of facial image but also it want to keep the ordinal information among aging face moreover we try to remove redundant information from both the locality information and ordinal information a much a possible by minimizing nonlinear correlation and rank correlation finally we formulate these two issue into a unified optimization problem of feature selection and present an efficient solution the experiment are conducted on the public available image of group dataset and the fg net dataset and the experimental result demonstrate the power of the proposed method against the state of the art method 
this paper address the problem of scene categorization while arguing that better and more accurate result can be obtained by endowing the computational process with perceptual relation between scene category we first describe a psychophysical paradigm that probe human scene categorization extract perceptual relation between scene category and suggests that these perceptual relation do not always conform the semantic structure between category we then incorporate the obtained perceptual finding into a computational classification scheme which take inter class relationship into account to obtain better scene categorization regardless of the particular descriptor with which scene are represented we present such improved classification result using several popular descriptor we discus why the contribution of inter class perceptual relation is particularly pronounced for under sampled training set and we argue that this mechanism may explain the ability of the human visual system to perform well under similar condition finally we introduce an online experimental system for obtaining perceptual relation for large collection of scene category 
a popular approach to pixel labeling problem such a multiclass image segmentation is to construct a pairwise conditional markov random field crf over image pixel where the pairwise term encodes a preference for smoothness within local connected or connected pixel neighborhood recently researcher have considered higher order model that encode soft non local constraint e g label consistency connectedness or co occurrence statistic these new model and the associated energy minimization algorithm have significantly pushed the state of the art for pixel labeling problem in this paper we consider a new non local constraint that penalizes inconsistent pixel label between disjoint image region having similar appearance we encode this constraint a a truncated higher order matching potential function between pair of image region in a conditional markov random field model and show how to perform efficient approximate map inference in the model we experimentally demonstrate quantitative and qualitative improvement over a strong baseline pairwise conditional markov random field model on two challenging multiclass pixel labeling datasets 
there is mounting evidence about the benefit of tailoring a biometric authentication system to each user by postprocessing the system output at the score level also known a client specific score normalisation example of these procedure are z norm and f norm these procedure can calibrate the uneven hypothesis space such that the dispropotionate false acceptance and false rejection error are reduced after the calibration the interest in studying these scheme is that they are applicable to any biometric authentication system regardless of the underlying biometric modality and furthermore potentially be extended to object recognition framed a a verification problem we propose to further improve these procedure by adding additional client specific term that cannot be incorporated easily in their respective existing form experiment carried out on face and speech system show that both variant systematically outperform their respective score normalisation scheme z norm or f norm 
many work in computer vision attempt to solve different task such a object detection scene recognition or attribute detection either separately or a a joint problem in recent year there ha been a growing interest in combining the result from these different task in order to provide a textual description of the scene however when describing a scene there are many item that can be mentioned if we include all the object relationship and attribute that exist in the image the description would be extremely long and not convey a true understanding of the image we present a novel approach to ranking the importance of the item to be described specifically we focus on the task of discriminating one image from a group of others we investigate the factor that contribute to the most efficient description that achieves this task we also provide a quantitative method to measure the description quality for this specific task using data from human subject and show that our method achieves better result than baseline method 
in this paper we propose a novel conditional random field crf formulation for the semantic scene labeling problem which is able to enforce temporal consistency between consecutive video frame and take advantage of the d scene geometry to improve segmentation quality the main contribution of this work lie in the novel use of a d scene reconstruction a a mean to temporally couple the individual image segmentation allowing information flow from d geometry to the d image space a our result show the proposed framework outperforms state of the art method and open a new perspective towards a tighter interplay of d and d information in the scene understanding problem 
although facial feature detection from d image is a well studied field there is a lack of real time method that estimate feature point even on low quality image here we propose conditional regression forest for this task while regression forest learn the relation between facial image patch and the location of feature point from the entire set of face conditional regression forest learn the relation conditional to global face property in our experiment we use the head pose a a global property and demonstrate that conditional regression forest outperform regression forest for facial feature detection we have evaluated the method on the challenging labeled face in the wild database where close to human accuracy is achieved while processing image in real time 
previously flobject analysis wa introduced a a method for using motion or stereo disparity information to train better model of static image during training but not during testing optic flow is used a a cue for factorizing appearance based image feature into those belonging to different flow defined object or flobjects here we describe how the image epitome can be extended to model flobjects and introduce a suitable learning algorithm using the citycars and city f edestrians datasets we study the task of object classification and localization our method performs significantly better than the original lda based flobject analysis technique sift based method with and without spatial pyramid matching and gist descriptor 
for scene classification patch level linear feature do not always work a well a handcrafted feature in this paper we present a new model to greatly improve the usefulness of linear feature in classification by introducing co variance pattern we analyze their property discus the fundamental importance and present a generative model to properly utilize them with this set of covariance information in our framework even the most naive linear feature that originally lack the vital ability in classification become powerful experiment show that the performance of our new covariance model based on linear feature is comparable with or even better than handcrafted feature in scene classification 
we present a new pedestrian detector that improves both in speed and quality over state of the art by efficiently handling different scale and transferring computation from test time to training time detection speed is improved when processing monocular image our system provides high quality detection at fps we also propose a new method for exploiting geometric context extracted from stereo image on a single cpu gpu desktop machine we reach fps when processing street scene from rectified input to detection output 
we present a novel dataset and novel algorithm for the problem of detecting activity of daily living adl in firstperson camera view we have collected a dataset of million frame of dozen of people performing unscripted everyday activity the dataset is annotated with activity object track hand position and interaction event adls differ from typical action in that they can involve long scale temporal structure making tea can take a few minute and complex object interaction a fridge look different when it door is open we develop novel representation including temporal pyramid which generalize the well known spatial pyramid to approximate temporal correspondence when scoring a model and composite object model that exploit the fact that object look different when being interacted with we perform an extensive empirical evaluation and demonstrate that our novel representation produce a two fold improvement over traditional approach our analysis suggests that real world adl recognition is all about the object and in particular all about the object being interacted with 
we propose a novel mode of feedback for image search where a user describes which property of exemplar image should be adjusted in order to more closely match his her mental model of the image s sought for example perusing image result for a query black shoe the user might state show me shoe image like these but sportier offline our approach first learns a set of ranking function each of which predicts the relative strength of a nameable attribute in an image sportiness furriness etc at query time the system present an initial set of reference image and the user selects among them to provide relative attribute feedback using the resulting constraint in the multi dimensional attribute space our method update it relevance function and re rank the pool of image this procedure iterates using the accumulated constraint until the top ranked image are acceptably close to the user s envisioned target in this way our approach allows a user to efficiently whittle away irrelevant portion of the visual feature space using semantic language to precisely communicate her preference to the system we demonstrate the technique for refining image search for people product and scene and show it outperforms traditional binary relevance feedback in term of search speed and accuracy 
visual reranking ha become a widely accepted method to improve traditional text based image search result the main principle is to exploit the visual aggregation property of relevant image among top result so a to boost ranking score of relevant image by explicitly or implicitly detecting the confident relevant image and propagating ranking score among visually similar image however such a visual aggregation property doe not always hold and thus these scheme may fail in this paper we instead propose to filter out the most probable irrelevant image using deep context which is the extra information that is not limited in the current search result the deep context for each image consist of set of image that are returned by search using the query formed by the textual context of this image we compare the popularity of this image in the current search result and the deep context to check the irrelevance score then the irrelevance score are propagated to the image whose useful textual context is missed we formulate the two scheme together to reach a markov random field which is effectively solved by graph cut the key is that our scheme doe not rely on the assumption that relevant image are visually aggregated among top result and is based on the observation that an outlier under the current query is likely to be more popular under some other query after that we perform graph reranking over filtered result to reorder them experimental result on the inria dataset show that our proposed method achieves significant improvement over previous approach 
rapidly growing application on smartphones have provided an excellent platform for mobile visual search most of previous visual search system adopt the framework of bag of word in which word indicate quantized code of visual feature in this work we propose a novel visual search system based on bag of hash bit bohb in which each local feature is encoded to a very small number of hash bit instead of quantized to visual word and the whole image is represented a bag of hash bit the proposed bohb method offer unique benefit in solving the challenge associated with mobile visual search e g low transmission cost cheap memory and computation on the mobile side etc moreover our bohb method leverage the distinct property of hashing bit such a multi table indexing multiple bucket probing bit reuse and hamming distance based ranking to achieve efficient search over gigantic visual database the proposed method significantly outperforms state of the art mobile visual search method like chog and other conventional desktop visual search approach like bag of word via vocabulary tree or product quantization the proposed bohb approach is easy to implement on mobile device and general in the sense that it can be applied to different type of local feature hashing algorithm and image database we also incorporate a boundary feature in the reranking step to describe the object shape complementing the local feature that are usually used to characterize the local detail the boundary feature can further filter out noisy result and improve the search performance especially at the coarse category level extensive experiment over large scale data set up to k product image demonstrate the effectiveness of our approach 
in this article we focus on the problem of large scale instance level image retrieval for efficiency reason it is common to represent an image by a fixed length descriptor which is subsequently encoded into a small number of bit we note that most encoding technique include an unsupervised dimensionality reduction step our goal in this work is to learn a better subspace in a supervised manner we especially raise the following question can category level label be used to learn such a subspace to answer this question we experiment with four learning technique the first one is based on a metric learning framework the second one on attribute representation the third one on canonical correlation analysis cca and the fourth one on joint subspace and classifier learning jscl while the first three approach have been applied in the past to the image retrieval problem we believe we are the first to show the usefulness of jscl in this context in our experiment we use imagenet a a source of category level label and report retrieval result on two standard dataseis inria holiday and the university of kentucky benchmark our experimental study show that metric learning and attribute do not lead to any significant improvement in retrieval accuracy a opposed to cca and jscl a an example we report on holiday an increase in accuracy from to with dimensional representation overall jscl is shown to yield the best result 
we present a discriminative latent topic model for scene recognition the capacity of our model is originated from the modeling of two type of visual context i e the category specific global spatial layout of different scene element and the reinforcement of the visual coherence in uniform local region in contrast most previous method for scene recognition either only modeled one of these two visual context or just totally ignored both of them we cast these two coupled visual context in a discriminative latent dirichlet allocation framework namely context aware topic model then scene recognition is achieved by bayesian inference given a target image our experiment on several scene recognition benchmark clearly demonstrated the advantage of the proposed model 
aligning image pair with significant appearance change is a long standing computer vision challenge much of this problem stem from the local patch descriptor instability to appearance variation in this paper we suggest this instability is due le to descriptor corruption and more the difficulty in utilizing local information to canonically define the orientation scale and rotation at which a patch s descriptor should be computed we address this issue by jointly estimating correspondence and relative patch orientation within a hierarchical algorithm that utilizes a smoothly varying parameterization of geometric transformation by collectively estimating the correspondence and orientation of all the feature we can align and orient feature that cannot be stably matched with only local information at the price of smoothing over motion discontinuity due to independent motion or parallax this approach can align image pair that display significant inter image appearance variation 
we cast the problem of recognizing related category a a unified learning and structured prediction problem with shared body plan when provided with detailed annotation of object and their part these body plan model object in term of shared part and layout simultaneously capturing a variety of category in varied pose we can use these body plan to jointly train many detector in a shared framework with structured learning leading to significant gain for each supervised task using our model we can provide detailed prediction of object and their part for both familiar and unfamiliar category 
there ha been growing interest in mapping image data onto compact binary code for fast near neighbor search in vision application although binary code are motivated by their use a direct index address into a hash table code longer than bit are not being used in this way a it wa thought to be ineffective we introduce a rigorous way to build multiple hash table on binary code substring that enables exact k nearest neighbor search in hamming space the algorithm is straightforward to implement storage efficient and it ha sub linear run time behavior for uniformly distributed code empirical result show dramatic speed ups over a linear scan baseline and for datasets with up to one billion item or bit code and search radius up to bit 
metric learning is n fundamental problem in computer vision different feature and algorithm may tackle a problem from different angle and thus often provide complementary information in this paper we propose a fusion algorithm which output enhanced metric by combining multiple given metric similarity measure unlike traditional co training style algorithm where multi view feature or multiple data subset are used for classification or regression we focus on fusing multiple given metric through diffusion process in an unsupervised way our algorithm ha it particular advantage when the input similarity matrix are the output from diverse algorithm we provide both theoretical and empirical explanation to our method significant improvement over the state of the art result have been observed on various benchmark datasets for example we have achieved accuracy no longer the bull s eye measure on the mpeg shape dataset our method ha a wide range of application in machine learning and computer vision 
we present a novel paradigm to deal with depth reconstruction from d light field in a variational framework taking into account the special structure of light field data we reformulate the problem of stereo matching to a constrained labeling problem on epipolar plane image which can be thought of a vertical and horizontal d cut through the field this alternative formulation allows to estimate accurate depth value even for specular surface while simultaneously taking into account global visibility constraint in order to obtain consistent depth map for all view the resulting optimization problem are solved with state of the art convex relaxation technique we test our algorithm on a number of synthetic and real world example captured with a light field gantry and a plenoptic camera and compare to ground truth where available all data set a well a source code are provided online for additional evaluation 
an object detector must detect and localize each instance of the object class of interest in the image many recent detector adopt a sliding window approach reducing the problem to one of deciding whether the detection window currently contains a valid object instance or background machine learning based discriminants such a svm and boosting are typically used for this often in the form of classifier cascade to allow more rapid rejection of easy negative we argue that one class method one that focus mainly on modelling the range of the positive class are a useful alternative to binary discriminants in such application particularly in the early stage of the cascade where one class approach may allow simpler classifier and faster rejection we implement this in the form of a short cascade of efficient nearest convex model one class classifier starting with linear distance to affine hyperplane and interior of hypersphere classifier and finishing with kernelized hypersphere classifier we show that our method have very competitive performance on the face in the wild and esogu face detection datasets and state of the art performance on the inria person dataset a predicted the one class formulation provide significant reduction in classifier complexity relative to the corresponding two class one 
in this paper we propose a novel video foreground detection method that exploit the statistic of d spacetime patch d space time patch are characterized by mean of the subspace they span a the complexity of real time system prohibits performing this modeling directly on the raw pixel data we propose a novel framework in which spatiotemporal data is sequentially reduced in two stage the first stage reduces the data using a cascade of linear projection of d space time patch onto a small set of d walsh hadamard wh basis function known for it energy compaction of natural image and video this stage is efficiently implemented using the gray code filtering scheme requiring only operation per projection in the second stage the data is further reduced by applying pca directly to the wh coefficient exploiting the local statistic in an adaptive manner unlike common technique this spatiotemporal adaptive projection exploit window appearance a well a it dynamic characteristic test show that the proposed method outperforms recent foreground detection method and is suitable for real time implementation on streaming video 
many of contextual correlation co exist within the segmented region among image like the visual context and semantic context the appropriate integration and utilization of such context are very important to boost the performance of region tagging inspired by the recent advance of sparse reconstruction method this paper proposes an approach called graph guided sparse reconstruction for region tagging g srrt the g srrt consists of two step sparse reconstruction for testing region and tag propagation from training region to testing region in g srrt graph is conducted to flexibly model the contextual correlation among region to integrate the graph structure learned from training region into the sparse reconstruction we define a graph guided fusion g f penalty over the graph to encourage the sparsity of difference between two reconstruction coefficient which corresponds to the linked region in the graph guided by this g f penalty the highly correlated region tend to be jointly selected for the reconstruction which result in a better performance of region tagging experiment on three open benchmark image datasets demonstrate the effectiveness of the proposed algorithm 
part based model have demonstrated their merit in object detection however there is a key issue to be solved on how to integrate the inaccurate score of part detector when there are occlusion or large deformation to handle the imperfectness of part detector this paper present a probabilistic pedestrian detection framework in this framework a deformable part based model is used to obtain the score of part detector and the visibility of part are modeled a hidden variable unlike previous occlusion handling approach that assume independence among visibility probability of part or manually define rule for the visibility relationship a discriminative deep model is used in this paper for learning the visibility relationship among overlapping part at multiple layer experimental result on three public datasets caltech eth and daimler and a new cuhk occlusion dataset specially designed for the evaluation of occlusion handling approach show the effectiveness of the proposed approach 
both appearance and shape play important role in object localization and object detection in this paper we propose a new superedge grouping method for object localization by incorporating both boundary shape and appearance information of object compared with the previous edge grouping method the proposed method doe not subdivide detected edge into short edgels before grouping such long unsubdivided superedges not only facilitate the incorporation of object shape information into localization but also increase the robustness against image noise and reduce computation we identify and address several important problem in achieving the proposed superedge grouping including gap filling for connecting superedges accurate encoding of region based information into individual edge and the incorporation of object shape information into object localization in this paper we use the bag of visual word technique to quantify the region based appearance feature of the object of interest we find that the proposed method by integrating both boundary and region information can produce better localization performance than previous subwindow search and edge grouping method on most of the object category from the voc database experiment also show that the proposed method is roughly time faster than the previous edge grouping method 
in this paper we introduce a novel image descriptor enabling accurate object categorization even with linear model akin to the popular attribute descriptor our feature vector comprises the output of a set of classifier evaluated on the image however unlike traditional attribute which represent hand selected object class and predefined visual property our feature are learned automatically and correspond to abstract category which we name meta class each meta class is a super category obtained by grouping a set of object class such that collectively they are easy to distinguish from other set of category by using learnability of the meta class a criterion for feature generation we obtain a set of attribute that encode general visual property shared by multiple object class and that are effective in describing and recognizing even novel category i e class not present in the training set we demonstrate that simple linear svms trained on our meta class descriptor significantly outperform the best known classifier on the caltech benchmark we also present result on the imagenet challenge database where our system produce result approaching those of the best system but at a much lower computational cost 
in recent year the rise of digital image and video data available ha led to an increasing demand for image annotation in this paper we propose an interactive object annotation method that incrementally train an object detector while the user provides annotation in the design of the system we have focused on minimizing human annotation time rather than pure algorithm learning performance to this end we optimize the detector based on a realistic annotation cost model based on a user study since our system give live feedback to the user by detecting object on the fly and predicts the potential annotation cost of unseen image data can be efficiently annotated by a single user without excessive waiting time in contrast to popular tracking based method for video annotation our method is suitable for both still image and video we have evaluated our interactive annotation approach on three datasets ranging from surveillance television to cell microscopy 
feature selection from sparse and high dimension feature using conventional greedy based boosting give classifier of poor generalization we propose a novel shrink boost method to address this problem it solves a sparse regularization problem with two iterative step first a boosting step us weighted training sample to learn a full high dimensional classifier on all feature this avoids over fitting to few feature and improves generalization next a shrinkage step shrink least discriminative classifier dimension to zero to remove the redundant feature in our object detection system we use shrink boost to select sparse feature from histogram of local binary pattern lbp of multiple quantization and image channel to learn classifier of additive lookup table lut our evaluation show that our classifier ha much better generalization than those from greedy based boosting and those from svm method even under limited number of train sample on public dataset of human detection and pedestrian detection we achieve better performance than state of the art on our more challenging dataset of bird detection we show promising result 
the performance of a generic pedestrian detector may drop significantly when it is applied to a specific scene due to mismatch between the source dataset used to train the detector and sample in the target scene in this paper we investigate how to automatically train a scene specific pedestrian detector starting with a generic detector in video surveillance without further manually labeling any sample under a novel transfer learning framework it tackle the problem from three aspect with a graphical representation and through exploring the indegrees from target sample to source sample the source sample are properly re weighted the indegrees detect the boundary between the distribution of the source dataset and the target dataset the re weighted source dataset better match the target scene it take the context information from motion scene structure and scene geometry a the confidence score of sample from the target scene to guide transfer learning the confidence score propagate among sample on a graph according to the underlying visual structure of sample all these consideration are formulated under a single objective function called confidence encoded svm at the test stage only the appearance based detector is used without the context cue the effectiveness of the proposed framework is demonstrated through experiment on two video surveillance datasets compared with a generic pedestrian detector it significantly improves the detection rate by and at one false positive per image on the two datasets respectively 
active range acquisition system such a light detection and ranging lidar and time of flight tof camera achieve high depth resolution but suffer from poor spatial resolution in this paper we introduce a new range acquisition architecture that doe not rely on scene raster scanning a in lidar or on a two dimensional array of sensor a used in tof camera instead we achieve spatial resolution through patterned sensing of the scene using a digital micromirror device dmd array our depth map reconstruction us parametric signal modeling to recover the set of distinct depth range present in the scene then using a convex program that exploit the sparsity of the laplacian of the depth map we recover the spatial content at the estimated depth range in our experiment we acquired pixel depth map of fronto parallel scene at range up to m using a pulsed laser a dmd array and a single photon counting detector we also demonstrated imaging in the presence of unknown partially transmissive occluders the prototype and result provide promising direction for non scanning low complexity range acquisition device for various computer vision application 
a novel method is proposed for matching articulated object in cluttered video the method need only a single exemplar image of the target object instead of using a small set of large part to represent an articulated object the proposed model us hundred of small unit to represent walk along path of pixel between key point on an articulated object matching directly on dense pixel is key to achieving reliable matching when motion blur occurs the proposed method fit the model to local image property conforms to structure constraint and remembers the step taken along a pixel path the model formulation handle variation in object scaling rotation and articulation recovery of the optimal pixel walk is posed a a special shortest path problem which can be solved efficiently via dynamic programming further speedup is achieved via factorization of the path cost an efficient method is proposed to find multiple walk and simultaneously match multiple key point experiment show that the proposed method is efficient and reliable and can be used to match articulated object in fast motion video with strong clutter and blurry imagery 
fitting an articulated model to image data is often approached a an optimization over both model pose and model to image correspondence for complex model such a human previous work ha required a good initialization or an alternating minimization between correspondence and pose in this paper we investigate one shot pose estimation can we directly infer correspondence using a regression function trained to be invariant to body size and shape and then optimize the model pose just once we evaluate on several challenging single frame data set containing a wide variety of body pose shape torso rotation and image cropping our experiment demonstrate that one shot pose estimation achieves state of the art result and run in real time 
in this work we investigate how illuminant estimation can be performed exploiting the color statistic extracted from the face automatically detected in the image the proposed method is based on two observation first skin color tend to form a cluster in the color space making it a cue to estimate the illuminant in the scene second many photographic image are portrait or contain people the proposed method ha been tested on a public dataset of image in raw format using both a manual and a real face detector experimental result demonstrate the effectiveness of our approach the proposed method can be directly used in many digital still camera processing pipeline with an embedded face detector working on gray level image 
this paper describes a novel strategy to enhance underwater video and image built on the fusion principle our strategy derives the input and the weight measure only from the degraded version of the image in order to overcome the limitation of the underwater medium we define two input that represent color corrected and contrast enhanced version of the original underwater image frame but also four weight map that aim to increase the visibility of the distant object degraded due to the medium scattering and absorption our strategy is a single image approach that doe not require specialized hardware or knowledge about the underwater condition or scene structure our fusion framework also support temporal coherence between adjacent frame by performing an effective edge preserving noise reduction strategy the enhanced image and video are characterized by reduced noise level better exposed ness of the dark region improved global contrast while the finest detail and edge are enhanced significantly in addition the utility of our enhancing technique is proved for several challenging application 
we address the problem of semantic segmentation classifying each pixel in an image according to the semantic class it belongs to e g dog road car most existing method train from fully supervised image where each pixel is annotated by a class label to reduce the annotation effort recently a few weakly supervised approach emerged these require only image label indicating which class are present although their performance reach a satisfactory level there is still a substantial gap between the accuracy of fully and weakly supervised method we address this gap with a novel active learning method specifically suited for this setting we model the problem a a pairwise crf and cast active learning a finding it most informative node these node induce the largest expected change in the overall crf state after revealing their true label our criterion is equivalent to maximizing an upper bound on accuracy gain experiment on two data set show that our method achieves percent of the accuracy of the corresponding fully supervised model while querying le than of the super pixel label 
object detector are typically trained on a large set of still image annotated by bounding box this paper introduces an approach for learning object detector from real world web video known only to contain object of a target class we propose a fully automatic pipeline that localizes object in a set of video of the class and learns a detector for it the approach extract candidate spatio temporal tube based on motion segmentation and then selects one tube per video jointly over all video to compare to the state of the art we test our detector on still image i e pascal voc we observe that frame extracted from web video can differ significantly in term of quality to still image taken by a good camera thus we formulate the learning from video a a domain adaptation task we show that training from a combination of weakly annotated video and fully annotated still image using domain adaptation improves the performance of a detector trained from still image alone 
we present a new technique for extracting local feature from image of architectural scene based on detecting and representing local symmetry these new feature are motivated by the fact that local symmetry at different scale are a fundamental characteristic of many urban image and are potentially more invariant to large appearance change than lower level feature such a sift hence we apply these feature to the problem of matching challenging pair of photo of urban scene our feature are based on simple measure of local bilateral and rotational symmetry computed using local image operation these measure are used both for feature detection and for computing descriptor we demonstrate our method on a challenging new dataset containing image pair exhibiting a range of dramatic variation in lighting age and rendering style and show that our feature can improve matching performance for this difficult task 
contour is an important cue for object recognition in this paper built upon the concept of torque in image space we propose a new contour related feature to detect and describe local contour information in image there are two component for our proposed feature one is a contour patch detector for detecting image patch with interesting information of object contour which we call the maximal minimal torque patch mtp detector the other is a contour patch descriptor for characterizing a contour patch by sampling the torque value which we call the multi scale torque mst descriptor experiment for object recognition on the caltech dataset showed that the proposed contour feature outperforms other contour related feature and is on a par with many other type of feature when combing our descriptor with the complementary sift descriptor impressive recognition result are observed 
we address the problem of segmenting and recognizing object in real world image focusing on challenging articulated category such a human and other animal for this purpose we propose a novel design for region based object detector that integrates efficiently top down information from scanning window part model and global appearance cue our detector produce class specific score for bottom up region and then aggregate the vote of multiple overlapping candidate through pixel classification we evaluate our approach on the pascal segmentation challenge and report competitive performance with respect to current leading technique on voc our method obtains the best result in category and the highest performance on articulated object 
we present a photometric stereo technique that operates on time lapse sequence captured by static outdoor webcam over the course of several month outdoor webcam produce a large set of uncontrolled image subject to varying lighting and weather condition we first automatically select a suitable subset of the captured frame for further processing reducing the dataset size by several order of magnitude a camera calibration step is applied to recover the camera response function the absolute camera orientation and to compute the light direction for each image finally we describe a new photometric stereo technique for non lambertian scene and unknown light source intensity to recover normal map and spatially varying material of the scene 
flat refractive geometry corresponds to a perspective camera looking through single multiple parallel flat refractive medium we show that the underlying geometry of ray corresponds to an axial camera this realization while missing from previous work lead u to develop a general theory of calibrating such system using d d correspondence the pose of d point is assumed to be unknown and is also recovered calibration can be done even using a single image of a plane we show that the unknown orientation of the refracting layer corresponds to the underlying axis and can be obtained independently of the number of layer their distance from the camera and their refractive index interestingly the axis estimation can be mapped to the classical essential matrix computation and point algorithm can be used after computing the axis the thickness of layer can be obtained linearly when refractive index are known and we derive analytical solution when they are unknown we also derive the analytical forward projection afp equation to compute the projection of a d point via multiple flat refraction which allows non linear refinement by minimizing the reprojection error for two refraction afp is either th or th degree equation depending on the refractive index we analyze ambiguity due to small field of view stability under noise and show how a two layer system can be well approximated a a single layer system real experiment using a water tank validate our theory 
we propose a novel shape model for object detection called fan shape model fsm we model contour sample point a ray of final length emanating for a reference point a in folding fan it slat which we call ray are very flexible this flexibility allows fsm to tolerate large shape variance however the order and the adjacency relation of the slat stay invariant during fan deformation since the slat are connected with a thin fabric in analogy we enforce the order and adjacency relation of the ray to stay invariant during the deformation therefore fsm preserve discriminative power while allowing for a substantial shape deformation fsm allows also for precise scale estimation during object detection thus there is not need to scale the shape model or image in order to perform object detection another advantage of fsm is the fact that it can be applied directly to edge image since it doe not require any linking of edge pixel to edge fragment contour 
in this paper we address the problem of recovering both the topology and the geometry of a deformable shape using temporal mesh sequence the interest arises in multi camera application when unknown natural dynamic scene are captured while several approach allow recovery of shape model from static scene few consider dynamic scene with evolving topology and without prior knowledge in this nonetheless generic situation a single time observation is not necessarily sufficient to infer the correct topology of the observed shape and evidence must be accumulated over time in order to learn the topology and to enable temporally consistent modelling this appears to be a new problem for which no formal solution exists we propose a principled approach based on the assumption that the observed object have a fixed topology under this assumption we can progressively learn the topology meanwhile capturing the deformation of the dynamic scene the approach ha been successfully experimented on several standard d datasets 
current object class recognition system typically target d bounding box localization encouraged by benchmark data set such a pascal voc while this seems suitable for the detection of individual object higher level application such a d scene understanding or d object tracking would benefit from more fine grained object hypothesis incorporating d geometric information such a viewpoint or the location of individual part in this paper we help narrowing the representational gap between the ideal input of a scene understanding system and object class detector output by designing a detector particularly tailored towards d geometric reasoning in particular we extend the successful discriminatively trained deformable part model to include both estimate of viewpoint and d part that are consistent across viewpoint we experimentally verify that adding d geometric information come at minimal performance loss w r t d bounding box localization but outperforms prior work in d viewpoint estimation and ultra wide baseline matching 
most image understanding algorithm begin with the extraction of information thought to be relevant to the particular task this is commonly known a feature extraction and ha up to this date been a largely manual process where a reasonable method is chosen through validation on the experimented dataset in this work we propose a data driven local histogram based feature extraction method that reduces the manual intervention during the feature computation process and improves on the performance of widely used gradient histogram based feature e g hog we demonstrate favorable object detection result against hog on the inria pedestrian pascal data 
this paper present a robust photometric stereo method that effectively compensates for various non lambertian corruption such a specularities shadow and image noise we construct a constrained sparse regression problem that enforces both lambertian rank structure and sparse additive corruption a solution method is derived using a hierarchical bayesian approximation to accurately estimate the surface normal while simultaneously separating the non lambertian corruption extensive evaluation are performed that show state of the art performance using both synthetic and real world image 
this paper proposes a novel approach to recognize object category in point cloud by quantizing d surf local descriptor computed on partial d shape extracted from the point cloud a vocabulary of d visual word is generated using this codebook we build a bag of word representation in d which is used in conjunction with a svm classification machinery we also introduce the d spatial pyramid matching kernel which work by partitioning a working volume into fine sub volume and computing a hierarchical weighted sum of histogram intersection at each level of the pyramid structure with the aim of increasing both the classification accuracy and the computational efficiency of the kernel we propose selective hierarchical volume decomposition strategy based on representative and discriminative sub volume selection process which drastically reduce the pyramid to consider result on the challenging large scale rgb d object dataset show that our kernel significantly outperform the state of the art result by using a single d shape feature type extracted from individual depth image 
we propose a novel framework for reconstructing homogenous transparent refractive height field from a single viewpoint the height field is imaged against a known planar background or sequence of background unlike existing approach that do a point by point reconstruction which is known to have intractable ambiguity our method estimate and optimizes for the entire height field at the same time the formulation support shape recovery from measured distortion deflection or directly from the image themselves including from a single image we report result for a variety of refractive height field showing significant improvement over prior art 
today visual recognition system are still rarely employed in robotics application perhaps one of the main reason for this is the lack of demanding benchmark that mimic such scenario in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmark for the task of stereo optical flow visual odometry slam and d object detection our recording platform is equipped with four high resolution video camera a velodyne laser scanner and a state of the art localization system our benchmark comprise stereo and optical flow image pair stereo visual odometry sequence of km length and more than k d object annotation captured in cluttered scenario up to car and pedestrian are visible per image result from state of the art algorithm reveal that method ranking high on established datasets such a middlebury perform below average when being moved outside the laboratory to the real world our goal is to reduce this bias by providing challenging benchmark with novel difficulty to the computer vision community our benchmark are available online at www cvlibs net datasets kitti 
object recognition is challenging especially when the object from different category are visually similar to each other in this paper we present a novel joint dictionary learning jdl algorithm to exploit the visual correlation within a group of visually similar object category for dictionary learning where a commonly shared dictionary and multiple category specific dictionary are accordingly modeled to enhance the discrimination of the dictionary the dictionary learning problem is formulated a a joint optimization by adding a discriminative term on the principle of the fisher discrimination criterion a well a presenting the jdl model a classification scheme is developed to better take advantage of the multiple dictionary that have been trained the effectiveness of the proposed algorithm ha been evaluated on popular visual benchmark 
attribute are visual concept that can be detected by machine understood by human and shared across category they are particularly useful for fine grained domain where category are closely related to one other e g bird specie recognition in such scenario relevant attribute are often local e g white belly but the question of how to choose these local attribute remains largely unexplored in this paper we propose an interactive approach that discovers local attribute that are both discriminative and semantically meaningful from image datasets annotated only with fine grained category label and object bounding box our approach us a latent conditional random field model to discover candidate attribute that are detectable and discriminative and then employ a recommender system that selects attribute likely to be semantically meaningful human interaction is used to provide semantic name for the discovered attribute we demonstrate our method on two challenging datasets caltech ucsd bird and leeds butterfly and find that our discovered attribute outperform those generated by traditional approach 
pictorial structure p define a probabilistic model of d articulated object in image typical p model assume an object can be represented by a set of rigid part connected with pairwise constraint that define the prior probability of part configuration these model are widely used to represent non rigid articulated object such a human and animal despite the fact that such object have part that deform non rigidly here we define a new deformable structure d model that is a natural extension of previous p model and that capture the non rigid shape deformation of the part each part in a d model is represented by a low dimensional shape deformation space and pairwise potential between part capture how the shape varies with pose and the shape of neighboring part a key advantage of such a model is that it more accurately model object boundary this enables image likelihood model that are more discriminative than previous p likelihood this likelihood is learned using training imagery annotated using a d puppet we focus on a human d model learned from d projection of a realistic d human body model and use it to infer human pose in image using a form of non parametric belief propagation 
with the advent of larger image classification datasets such a imagenet designing scalable and efficient multi class classification algorithm is now an important challenge we introduce a new scalable learning algorithm for large scale multi class image classification based on the multinomial logistic loss and the trace norm regularization penalty reframing the challenging non smooth optimization problem into a surrogate infinite dimensional optimization problem with a regular regularization penalty we propose a simple and provably efficient accelerated coordinate descent algorithm furthermore we show how to perform efficient matrix computation in the compressed domain for quantized dense visual feature scaling up to s example s dimensional feature and s of category promising experimental result on the fungus ungulate and vehicle subset of imagenet are presented where we show that our approach performs significantly better than state of the art approach for fisher vector with gaussians 
while the detection of the interesting region in image ha been extensively studied relatively few paper have addressed surface this paper proposes an algorithm for detecting the region of interest of surface it look for region that are distinct both locally and globally and account for the distance to the focus of attention many application can utilize these region in this paper we explore one such application viewpoint selection the most informative view are those that collectively provide the most descriptive presentation of the surface we show that our result compete favorably with the state of the art result 
most recently the bag of feature bof representation ha been well advocated for image search and classification with two decent phase named sparse coding and max pooling to compensate quantization loss a well a inject spatial layout but still much information ha been discarded by quantizing local descriptor with two dimensional layout into a one dimensional bof histogram in this paper we revisit this popular sparse coding max pooling paradigm by looking around the local descriptor context towards an optimal bof first we introduce a weakly supervised sparse coding wsc to exploit the classemes based attribute labeling to refine the descriptor coding procedure it is achieved by learning an attribute to word co occurrence prior to impose a label inconsistency distortion over the based coding regularizer such that the descriptor code can maximally preserve the image semantic similarity second we propose an adaptive feature pooling scheme over superpixels rather than over fixed spatial pyramid named geometric consistency pooling gcp a an effect local descriptor enjoying good geometric consistency are pooled together to ensure a more precise spatial layout embedding in bof both of our phase are unsupervised which differ from the existing work in supervised dictionary learning sparse coding and feature pooling therefore our approach enables potential application like scalable visual search we evaluate in both image classification and search benchmark and report good improvement over the state of the art 
we investigate the fine grained object categorization problem of determining the breed of animal from an image to this end we introduce a new annotated dataset of pet covering different breed of cat and dog the visual problem is very challenging a these animal particularly cat are very deformable and there can be quite subtle difference between the breed we make a number of contribution first we introduce a model to classify a pet breed automatically from an image the model combine shape captured by a deformable part model detecting the pet face and appearance captured by a bag of word model that describes the pet fur fitting the model involves automatically segmenting the animal in the image second we compare two classification approach a hierarchical one in which a pet is first assigned to the cat or dog family and then to a breed and a flat one in which the breed is obtained directly we also investigate a number of animal and image orientated spatial layout these model are very good they beat all previously published result on the challenging asirra test cat v dog discrimination when applied to the task of discriminating the different breed of pet the model obtain an average accuracy of about a very encouraging result considering the difficulty of the problem 
we propose a benchmark of several objective function for large scale image classification we compare the one v rest multiclass ranking and weighted average ranking svms using stochastic gradient descent optimization we can scale the learning to million of image and thousand of class our experimental evaluation show that ranking based algorithm do not outperform a one v rest strategy and that the gap between the different algorithm reduces in case of high dimensional data we also show that for one v rest learning through cross validation the optimal degree of imbalance between the positive and the negative sample can have a significant impact furthermore early stopping can be used a an effective regularization strategy when training with stochastic gradient algorithm following these good practice we were able to improve the state of the art on a large subset of k class and m of image of lmagenet from accuracy to 
proxemics is the study of how people interact we present a computational formulation of visual proxemics by attempting to label each pair of people in an image with a subset of physically based touch code a baseline approach would be to first perform pose estimation and then detect the touch code based on the estimated joint location we found that this sequential approach doe not perform well because pose estimation step is too unreliable for image of interacting people due to difficulty with occlusion and limb ambiguity instead we propose a direct approach where we build an articulated model tuned for each touch code each such model contains two people connected in an appropriate manner for the touch code in question we fit this model to the image and then base classification on the fitting error experiment show that this approach significantly outperforms the sequential baseline a well a other related approches 
stereopsis provides an additional depth cue and play an important role in the human vision system this paper explores stereopsis for saliency analysis and present two approach to stereo saliency detection from stereoscopic image the first approach computes stereo saliency based on the global disparity contrast in the input image the second approach leverage domain knowledge in stereoscopic photography a good stereoscopic image take care of it disparity distribution to avoid d fatigue particularly salient content tends to be positioned in the stereoscopic comfort zone to alleviate the vergence accommodation conflict accordingly our method computes stereo saliency of an image region based on the distance between it perceived location and the comfort zone moreover we consider object popping out from the screen salient a these object tend to catch a viewer s attention we build a stereo saliency analysis benchmark dataset that contains stereoscopic image with salient object mask our experiment on this dataset show that stereo saliency provides a useful complement to existing visual saliency analysis and our method can successfully detect salient content from image that are difficult for monocular saliency analysis method 
modeling representation of image patch that are quasi invariant to spatial deformation is an important problem in computer vision in this paper we propose a novel concept the texture trace that allows sparse patch representation which are quasi invariant to smooth deformation and robust against occlusion we first propose a continuous domain model the profile trace which is a function only of the topological property of an image and is by construction invariant to any homeomorphic transformation of the domain we analyze it theoretical property and then derive a discrete domain approximation the discrete texture trace dtt dtts are designed to be computationally practical and shown by a set of controlled experiment to be quasi invariant to smooth spatial deformation a well a common image perturbation we then show how dtts can be naturally adapted to the incremental tracking problem yielding highly precise result on par with the state of the art on challenging real data without using heavy machine learning tool indeed we show that with even just using one image at the start of a sequence i e no incremental updating our method already outperforms four of six state of the art method of the recent literature on challenging sequence 
consumer digital camera use tone mapping to produce compact narrow gamut image that are nonetheless visually pleasing in doing so they discard or distort substantial radiometric signal that could otherwise be used for computer vision existing method attempt to undo these effect through deterministic map that de render the reported narrow gamut color back to their original wide gamut sensor measurement deterministic approach are unreliable however because the reverse narrow to wide mapping is one to many and ha inherent uncertainty our solution is to use probabilistic map providing uncertainty estimate useful to many application we use a non parametric bayesian regression technique local gaussian process regression to learn for each pixel s narrow gamut color a probability distribution over the scene color that could have created it using a variety of consumer camera we show that these distribution once learned from training data are effective in simple probabilistic adaptation of two popular application multi exposure imaging and photometric stereo our result on these application are better than those of corresponding deterministic approach especially for saturated and out of gamut color 
we introduce a method to repair an image which ha been stamped by an identigram or a watermark our method is based on the cross channel correlation which assures the co occurrence of image discontinuity and correlation of color distribution across different color channel of an image using blind source separation we find the transformation of color space which separate the structure of identigram and that of the original image into two different individual color channel to repair the image content in the corrupted channel we formulate the problem using bayes rule where the prior and the likelihood probability are defined based on the cross channel correlation assumption we compare our result with result from inpainting and texture synthesis based hole filling technique our result are pleasable for real world example and have the maximum psnr for synthetic example 
low level appearance a well a spatio temporal feature appropriately quantized and aggregated into bag of word bow descriptor have been shown to be effective in many detection and recognition task however their effcacy for complex event recognition in unconstrained video have not been systematically evaluated in this paper we use the nist trecvid multimedia event detection med open source dataset containing annotated data for high level event a the standardized test bed for evaluating the low level feature this dataset contains a large number of user generated video clip we consider different low level feature both static and dynamic using bow descriptor within an svm approach for event detection we present performance result on the med event for each of the feature a well a their combination using a number of early and late fusion strategy and discus their strength and limitation 
we introduce a novel d extension to the hierarchical visual cortex model used for prior work in d object recognition prior work on the use of the visual cortex standard model for the explicit task of object class recognition ha solely concentrated on d imagery in this paper we discus the explicit d extension of each layer in this visual cortex model hierarchy for use in object recognition in d volumetric imagery we apply this extended methodology to the automatic detection of a class of threat item in computed tomography ct security baggage imagery the ct imagery suffers from poor resolution and a large number of artefact generated through the presence of metallic object in our examination of recognition performance we make a comparison to a codebook approach derived from a d sift descriptor and demonstrate that the visual cortex method out performs in this imagery recognition rate in excess of with minimal false positive rate are demonstrated in the detection of a range of threat item 
we propose a novel algorithmic solution for estimating a three dimensional model of an object observed in a single image based on a minimal user input the algorithm interactively determines the object silhouette and subsequently computes a silhouette consistent d model which is precisely the globally minimal surface with user specified volume in contrast to a recently published approach to single view reconstruction the proposed algorithm doe not constrain the resolution in the depth direction it assures the global optimum and is faster by about an order of magnitude experiment demonstrate that plausible high resolution d model can be generated in fraction of a second and compare favorably with other method 
finding minimal cut on graph with a grid like structure ha become a core task for solving many computer vision and graphic related problem however computation speed and memory consumption oftentimes limit the effective use in application requiring high resolution grid or interactive response in particular memory bandwidth represents one of the major bottleneck even in today s most efficient implementation we propose a compact data structure with cache efficient memory layout for the representation of graph instance that are based on regular n d grid with topologically identical neighborhood system for this common class of graph our data structure allows for to time higher grid resolution and a to fold speedup compared to existing approach our design is agnostic to the underlying algorithm and hence orthogonal to other optimization such a parallel and hierarchical processing we evaluate the performance gain on a variety of typical problem including d d segmentation colorization and stereo all experiment show an unconditional improvement in term of speed and memory consumption with graceful performance degradation for graph with increasing topological irregularity 
widespread current camera are part of multisensory system with an integrated computer smartphones computer vision thus start evolving to cross modal sensing where vision and other sensor cooperate this exists in human and animal reflecting nature where visual event are often accompanied with sound can vision assist in denoising another modality a a case study we demonstrate this principle by using video to denoise audio unimodal audio only denoising is very difficult when the noise source is non stationary complex e g another speaker or music in the background strong and not individually accessible in any modality unseen cross modal association can help a clear video can direct the audio estimator we show this using an example based approach a training movie having clear audio provides cross modal example in testing cross modal input segment having noisy audio rely on the example for denoising the video channel drive the search for relevant training example we demonstrate this in speech and music experiment 
in this paper we address multi view reconstruction of urban environment using d shape grammar our formulation express the solution to the problem a a shape grammar parse tree where both the tree and the corresponding derivation parameter are unknown besides the grammar constraint the solution is guided by an image support that is twofold first we seek for a derivation that induces optimal semantic partition in the different view second using structure from motion noisy depth map can be determined towards minimizing their distance from to the one predicted by any potential solution we show how the underlying data structure can be efficiently optimized using evolutionary algorithm with automatic parameter selection to the best of our knowledge it is the first time that the multi view d procedural modeling problem is tackled promising result demonstrate the potential of the method towards producing a compact representation of urban environment 
we present local naive bayes nearest neighbor an improvement to the nbnn image classification algorithm that increase classification accuracy and improves it ability to scale to large number of object class the key observation is that only the class represented in the local neighborhood of a descriptor contribute significantly and reliably to their posterior probability estimate instead of maintaining a separate search structure for each class s training descriptor we merge all of the reference data together into one search structure allowing quick identification of a descriptor s local neighborhood we show an increase in classification accuracy when we ignore adjustment to the more distant class and show that the run time grows with the log of the number of class rather than linearly in the number of class a did the original local nbnn give a time speed up over the original nbnn on the caltech dataset we also provide the first head to head comparison of nbnn against spatial pyramid method using a common set of input feature we show that local nbnn outperforms all previous nbnn based method and the original spatial pyramid model however we find that local nbnn while competitive with doe not beat state of the art spatial pyramid method that use local soft assignment and max pooling 
we present a novel method for translational symmetry detection optimization and symmetry object segmentation in fa ade image unlike most previous method our detection algorithm accumulates pixel level correspondence in translation space thus it doe not rely on feature point detection and handle pattern with low repetition count to improve the robustness with multiple interfering symmetry we introduce an image space global optimization which resolve multiple per pixel symmetry lattice we then propose a learning based method that generates refined segmentation of foreground symmetry object of arbitrary shape with the aid of the per pixel symmetry information our proposed method is accurate robust and efficient a demonstrated by an extensive evaluation using a large fa ade image database 
a good model of object shape is essential in application such a segmentation object detection inpainting and graphic for example when performing segmentation local constraint on the shape can help where the object boundary is noisy or unclear and global constraint can resolve ambiguity where background clutter look similar to part of the object in general the stronger the model of shape the more performance is improved in this paper we use a type of deep boltzmann machine that we call a shape boltzmann machine shapebm for the task of modeling binary shape image we show that the shapebm characterizes a strong model of shape in that sample from the model look realistic and it can generalize to generate sample that differ from training example we find that the shapebm learns distribution that are qualitatively and quantitatively better than existing model for this task 
although tracing linear structure in d image and d image stack ha received much attention over the year full automation remains elusive in this paper we formulate the delineation problem a one of solving a quadratic mixed integer program q mip in a graph of potential path which can be done optimally up to a very small tolerance we further propose a novel approach to weighting these path which result in a q mip solution that accurately match the ground truth we demonstrate that our approach outperforms a state of the art technique based on the k minimum spanning tree formulation on a d dataset of aerial image and a d dataset of confocal microscopy stack 
in this paper we study the problem of landmark recognition and propose to leverage d visual phrase to improve the performance a d visual phrase is a triangular facet on the surface of a reconstructed d landmark model in contrast to existing d visual phrase which are mainly based on co occurrence statistic in d image plane such d visual phrase explicitly characterize the spatial structure of a d object landmark and are highly robust to projective transformation due to viewpoint change we present an effective solution to discover describe and detect d visual phrase the experiment on landmark have achieved promising result which demonstrate that our approach provides a good balance between precision and recall of landmark recognition while reducing the dependence on post verification to reject false positive 
mode seeking ha been widely used a a powerful data analysis technique for clustering and filtering in a metric feature space we introduce a versatile and efficient mode seeking method for graph representation where general embedding of relational data is possible beyond metric space exploiting the global structure of the graph by random walk our method intrinsically combine mode seeking with ranking on the graph and performs robust analysis by seeking high ranked authoritative data and suppressing low ranked noise and outlier this enables mode seeking to be applied to a large class of challenging real world problem involving graph representation which frequently arises in computer vision we demonstrate our method on various synthetic experiment and real application dealing with noisy and complex data such a scene summarization and object based image matching 
despite a considerable amount of previous work on bottom up saliency modeling for predicting human fixation over static and dynamic stimulus few study have thus far attempted to model top down and task driven influence of visual attention here taking advantage of the sequential nature of real world task we propose a unified bayesian approach for modeling task driven visual attention several source of information including global context of a scene previous attended location and previous motor action are integrated over time to predict the next attended location recording eye movement while subject engage in contemporary d and d video game a modest counterpart of everyday task we show that our approach is able to predict human attention and gaze better than the state of the art with a large margin about increase in prediction accuracy the advantage of our approach is that it is automatic and applicable to arbitrary visual task 
the conditional random field crf is a popular tool for object based image segmentation crfs used in practice typically have edge only between adjacent image pixel to represent object relationship statistic beyond adjacent pixel prior work either represents only weak spatial information using the segmented region or encodes only global object co occurrence in this paper we propose a unified model that augments the pixel wise crfs to capture object spatial relationship to this end we use a fully connected crf which ha an edge for each pair of pixel the edge potential are defined to capture the spatial information and preserve the object boundary at the same time traditional inference method such a belief propagation and graph cut are impractical in such a case where billion of edge are defined under only one assumption that the spatial relationship among different object only depend on their relative position spatially stationary we develop an efficient inference algorithm that converges in a few second on a standard resolution image where belief propagation take more than one hour for a single iteration 
we present a model and an algorithm to detect salient region in video taken from a moving camera in particular we are interested in capturing small object that move independently in the scene such a vehicle and people a seen from aerial or ground vehicle many of the scenario of interest challenge existing scheme based on background subtraction background motion too complex multi body motion estimation insufficient parallax and occlusion detection uniformly textured background region we adopt a robust statistical inference approach to simultaneously estimate a maximally reduced regressor and select region that violate the null hypothesis co visibility under an epipolar domain deformation a salient we show that our algorithm can perform even in the absence of camera calibration information while the resulting motion estimate would be incorrect the partition of the domain into salient v non salient is unaffected we demonstrate our algorithm on video footage from helicopter airplane and ground vehicle 
motion segmentation based on point trajectory can integrate information of a whole video shot to detect and separate moving object commonly similarity are defined between pair of trajectory however pairwise similarity restrict the motion model to translation non translational motion such a rotation or scaling is penalized in such an approach we propose to define similarity on higher order tuples rather than pair which lead to hypergraphs to apply spectral clustering the hypergraph is transferred to an ordinary graph an operation that can be interpreted a a projection we propose a specific nonlinear projection via a regularized maximum operator and show that it yield significant improvement both compared to pairwise similarity and alternative hypergraph projection 
this paper present a cross based framework of performing local multipoint filtering efficiently we formulate the filtering process a a local multipoint regression problem consisting of two main step multipoint estimation calculating the estimate for a set of point within a shape adaptive local support and aggregation fusing a number of multipoint estimate available for each point compared with the guided filter that applies the linear regression to all pixel covered by a fixed sized square window non adaptively the proposed filtering framework is a more generalized form two specific filtering method are instantiated from this framework based on piecewise constant and piecewise linear modeling respectively leveraging a cross based local support representation and integration technique the proposed filtering method achieve theoretically strong result in an efficient manner with the two main step complexity independent of the filtering kernel size we demonstrate the strength of the proposed filter in various application including stereo matching depth map enhancement edge preserving smoothing color image denoising detail enhancement and flash no flash denoising 
in the area of d shape analysis research in mesh segmentation ha always been an important topic a it is a fundamental low level task which can be utilized in many application including computer aided design computer animation biomedical application and many other field we define the automatic robust mesh segmentation arm method in this paper which is invariant to isometric transformation is insensitive to noise and deformation performs closely to human perception is efficient in computation and is minimally dependent on prior knowledge in this work we develop a new framework namely the center shift which discovers meaningful segment of a d object by exploring the intrinsic geometric structure encoded in the biharmonic kernel our center shift framework ha three main step first we construct a feature space where every vertex on the mesh surface is associated with the corresponding biharmonic kernel density function value second we apply the center shift algorithm for initial segmentation third the initial segmentation result is refined through an efficient iterative process which lead to visually salient segmentation of the shape the performance of this segmentation method is demonstrated through extensive experiment on various set of d shape and different type of noise and deformation the experimental result of d shape segmentation have shown better performance of center shift compared to state of the art segmentation method 
color information is leveraged by color sampling based matting method to find the best known sample for foreground and background color of unknown pixel such method do not perform well if there is an overlap in the color distribution of foreground and background region because color cannot distinguish between these region and hence the selected sample cannot reliably estimate the matte similarly alpha propagation based matting method may fail when the affinity among neighboring pixel is reduced by strong edge in this paper we overcome these two problem by considering texture a a feature that can complement color to improve matting the contribution of texture and color is automatically estimated by analyzing the content of the image an objective function containing color and texture component is optimized to choose the best foreground and background pair among a set of candidate pair experiment are carried out on a benchmark data set and an independent evaluation of the result show that the proposed method is ranked first among all other image matting method 
we present a generic framework for object segmentation using depth map based on random forest and graph cut theory and apply it to the segmentation of human limb in depth map first from a set of random depth feature random forest is used to infer a set of label probability for each data sample this vector of probability is used a unary term in swap graph cut algorithm moreover depth of spatio temporal neighboring data point are used a boundary potential result on a new multi label human depth data set show high performance in term of segmentation overlapping of the novel methodology compared to classical approach 
we propose an adaptive figure ground classification algorithm to automatically extract a foreground region using a user provided bounding box the image is first over segmented with an adaptive mean shift algorithm from which background and foreground prior are estimated the remaining patch are iteratively assigned based on their distance to the prior with the foreground prior being updated online a large set of candidate segmentation are obtained by changing the initial foreground prior the best candidate is determined by a score function that evaluates the segmentation quality rather than using a single distance function or score function we generate multiple hypothesis segmentation from different combination of distance measure and score function the final segmentation is then automatically obtained with a voting or weighted combination scheme from the multiple hypothesis experiment indicate that our method performs at or above the current state of the art on several datasets with particular success on challenging scene that contain irregular or multiple connected foreground in addition this improvement in accuracy is achieved with low computational cost 
many cue have been proposed for contour detection or image segmentation these include low level image gradient to high level information such a the identity of the object in the scene or d depth understanding while state of the art approach have been incorporating more cue the relative importance of the cue is unclear in this paper we examine the relative importance of low midand high level cue to gain a better understanding of their role in detecting object contour in an image to accomplish this task we conduct numerous human study and compare their performance to several popular segmentation and contour detection machine approach our finding suggest that the current state of the art contour detection algorithm perform a well a human using low level cue we also find evidence that the recognition of object but not occlusion information lead to improved human performance moreover when object are recognized by human their contour detection performance increase over current machine algorithm finally mid level cue appear to offer a larger performance boost than high level cue such a recognition 
we present a novel multi class classifier that strike a balance between the nearest subspace classifier which assigns a test sample to the class that minimizes the distance between the test sample and it principal projection in the selected class and a collaborative representation based classifier which classifies a sample to the class that minimizes the distance between the collaborative component of the test sample by using all training sample from all class a the dictionary and it projection in the selected class in our formulation the sparse representation based classifier and nearest subspace classifier become special case under different regularization parameter we show that the classification performance can be improved by optimally tuning the regularization parameter which can be done at almost no extra computational cost we give extensive numerical example for digit identification and face recognition with performance comparison of different choice of collaborative representation in particular when only a partial observation of the test sample is available via compressive sensing measurement 
we propose a system for the automatic segmentation of novelty from the background in scenario where multiple image of the same environment are available e g obtained by wearable visual camera our method find the pixel in a query image corresponding to the underlying background environment by comparing it to reference image of the same scene this is achieved despite the fact that all the image may have different viewpoint significantly different illumination condition and contain different object car people bicycle etc occluding the background we estimate the probability of each pixel in the query image belonging to the background by computing it appearance inconsistency to the multiple reference image we then produce multiple segmentation of the query image using an iterated graph cut algorithm initializing from these estimated probability and consecutively combine these segmentation to come up with a final segmentation of the background detection of the background in turn highlight the novel pixel we demonstrate the effectiveness of our approach on a challenging outdoors data set 
the efficient and robust extraction of invariant pattern from an image is a long standing problem in computer vision invariant structure are often related to repetitive or near repetitive pattern the perception of repetitive pattern in an image is strongly linked to the visual interpretation and composition of texture repetitive pattern are product of both repetitive structure a well a repetitive reflection or color pattern in other word pattern that exhibit near stationary behavior provide a rich information about object their shape and their texture in an image in this paper we propose a new algorithm for repetitive pattern detection and grouping the algorithm follows the classical region growing image segmentation scheme it utilizes a mean shift like dynamic to group local image patch into cluster it exploit a continuous joint alignment to a match similar patch and b refine the subspace grouping the result of higher level grouping for image pattern can be used to infer the geometry of object surface and estimate the general layout of a crowded scene 
we present an approach to synthesize the subtle d relief and texture of oil painting brush stroke from a single photograph this task is unique from traditional synthesize algorithm due to it mixed modality between the input and output i e our goal is to synthesize surface normal given an intensity image input to accomplish this task we propose a framework that first applies intrinsic image decomposition to produce a pair of initial normal map these map are combined into a conditional random field crf optimization framework that incorporates additional information derived from a training set consisting of normal captured using photometric stereo on oil painting with similar brush style additional constraint are incorporated into the crf framework to further ensures smoothness and preserve brush stroke edge our result show that this approach can produce compelling relief that are often indistinguishable from result captured using photometric stereo 
salient object detection is not a pure low level bottom up process higher level knowledge is important even for task independent image saliency we propose a unified model to incorporate traditional low level feature with higher level guidance to detect salient object in our model an image is represented a a low rank matrix plus sparse noise in a certain feature space where the non salient region or background can be explained by the low rank matrix and the salient region are indicated by the sparse noise to ensure the validity of this model a linear transform for the feature space is introduced and need to be learned given an image it low level saliency is then extracted by identifying those sparse noise when recovering the low rank matrix furthermore higher level knowledge is fused to compose a prior map and is treated a a prior term in the objective function to improve the performance extensive experiment show that our model can comfortably achieves comparable performance to the existing method even without the help from high level knowledge the integration of top down prior further improves the performance and achieves the state of the art moreover the proposed model can be considered a a prototype framework not only for general salient object detection but also for potential task dependent saliency application 
the fast radial symmetry fr transform ha been very popular for detecting interest point based on local radial symmetry although fr delivers good performance at a relatively low computational cost and is very well suited for a variety of real time computer vision application it is not invariant to perspective distortion moreover even perfectly radially symmetric visual pattern in the real world are perceived by u after a perspective projection in this paper we propose a systematic extension to the fr transform to make it invariant to bounded case of perspective projection we call this transform the generalized fr or gfrs transform we show that gfrs inherits the basic characteristic of fr and retains it computational efficiency we demonstrate the wide applicability of gfrs by applying it to a variety of natural image to detect radially symmetric pattern that have undergone significant perspective distortion subsequently we build a nucleus detector based on the gfrs transform and apply it to the important problem of digital histopathology we demonstrate superior performance over state of the art nucleus detection algorithm validated using roc curve 
watershed cut are among the fastest segmentation algorithm and therefore well suited for interactive segmentation of very large d data set to minimize the number of user interaction seed required until the result is correct we want the computer to actively query the human for input at the most critical location in analogy to active learning these location are found by mean of suitable uncertainty measure we propose various such measure for watershed cut along with a theoretical analysis of some of their property extensive evaluation on two type of d electron microscopic volume of neural tissue show that measure which estimate the non local consequence of new user input achieve performance close to an oracle endowed with complete knowledge of the ground truth 
we present a new approach to matching graph embedded in or unlike earlier method our approach doe not rely on the similarity of local appearance feature doe not require an initial alignment can handle partial match and can cope with non linear deformation and topological difference to handle arbitrary non linear deformation we represent them a gaussian process in the absence of appearance information we iteratively establish correspondence between graph node update the structure accordingly and use the current mapping estimate to find the most likely correspondence that will be used in the next iteration this make the computation tractable we demonstrate the effectiveness of our approach first on synthetic case and then on angiography data retinal fundus image and microscopy image stack acquired at very different resolution 
a plenoptic camera capture the d radiance about a scene recent practical solution mount a microlens array on top of a commodity slr to directly acquire these ray however they suffer from low resolution a hundred of thousand of view need to be captured in a single shot in this paper we develop a simple but effective technique for improving the image resolution of the plenoptic camera by maneuvering the demosaicing process we first show that the traditional solution by demosaicing each individual microlens image and then blending them for view synthesis is suboptimal in particular this demosaicing process often suffers from aliasing artifact and it damage high frequency information recorded by each microlens image hence degrades the image quality we instead propose to de mosaic the synthesized view at the rendering stage specifically we first transform the radiance to the desired focal plane and then apply frequency domain plenoptic resampling a full resolution color filtered image is then created by performing a d integral projection from the reparam eterized radiance finally we conduct demosacing to obtain the color result we show that our solution can achieve visible resolution enhancement on dynamic refocusing and depth assisted deep focus rendering 
we present an approach for the automatic reconstruction of neuron from d stack of electron microscopy section the core of our system is a set of possible assignment each of which proposes with some cost a link between neuron region in consecutive section these can model the continuation branching and end of neuron the cost are trainable on positive assignment sample an optimal and consistent set of assignment is found for the whole volume at once by solving an integer linear program this set of assignment determines both the segmentation into neuron region and the correspondence between such region in neighboring slice for each picked assignment a confidence value help to prioritize decision to be reviewed by a human expert we evaluate the performance of our method on an annotated volume of neural tissue and compare to the current state of the art our method is superior in accuracy and can be trained using a small number of sample the observed inference time are linear with about millisecond per neuron and section 
this paper present an algorithm that automatically corrects the distortion caused by multipath interference mpi in depth measurement obtained with time of flight camera tof camera a radiometric model that explains under some mild simplification the working principle of a tof camera including a model for mpi is proposed using this model we demonstrate that all the information needed for compensating the influence of mpi on the scene captured by the camera is self contained in the measurement depth and amplitude of infrared signal we propose an iterative optimization method that based on the measurement contaminated with mpi give depth correction for each pixel result are shown in artificially generated time of flight scene using the radiometric model in addition the system ha been validated in real scene using a commercial tof camera providing good result 
in this paper we propose a novel approach for detection segmentation and characterization of brain tumor our method exploit prior knowledge in the form of a sparse graph representing the expected spatial position of tumor class such information is coupled with image based classification technique along with spatial smoothness constraint towards producing a reliable detection map within a unified graphical model formulation towards optimal use of prior knowledge a two layer interconnected graph is considered with one layer corresponding to the low grade glioma type characterization and the second layer to voxel based decision of tumor presence efficient linear programming both in term of performance a well a in term of computational load is considered to recover the lowest potential of the objective function the outcome of the method refers to both tumor segmentation a well a their characterization promising result on substantial data set demonstrate the extreme potential of our method 
tracking the mitral valve leaflet in an ultrasound sequence is a challenging task because of the poor image quality and fast and irregular leaflet motion previous algorithm usually applied standard segmentation method based on edge object intensity and anatomical information to segment the mitral leaflet in static frame however they are limited in practical application due to the requirement of manual input for initialization or large annotated datasets for training in this paper we present a completely automatic and unsupervised algorithm for mitral leaflet detection and tracking we demonstrate that the image sequence of a cardiac cycle can be well approximated with a low rank matrix except for the mitral leaflet region with fast motion and tissue deformation based on this difference we propose to track the mitral leaflet by detecting contiguous outlier in the low rank representation with this formulation the leaflet is tracked using the motion cue but the complicated motion computation is avoided to the best of our knowledge the proposed algorithm is the first unsupervised method for mitral leaflet tracking the algorithm wa tested on both d and d echocardiography which achieved accurate segmentation with an average distance of mm compared to the manual tracing 
the k nn graph ha played a central role in increasingly popular data driven technique for various learning and vision task yet finding an efficient and effective way to construct k nn graph remains a challenge especially for large scale high dimensional data in this paper we propose a new approach to construct approximate k nn graph with emphasis in efficiency and accuracy we hierarchically and randomly divide the data point into subset and build an exact neighborhood graph over each subset achieving a base approximate neighborhood graph we then repeat this process for several time to generate multiple neighborhood graph which are combined to yield a more accurate approximate neighborhood graph furthermore we propose a neighborhood propagation scheme to further enhance the accuracy we show both theoretical and empirical accuracy and efficiency of our approach to k nn graph construction and demonstrate significant speed up in dealing with large scale visual data 
while bottom up and top down process have shown effectiveness during predicting attention and eye fixation map on image in this paper inspired by the perceptual organization mechanism before attention selection we propose to utilize figure ground map for the purpose so a to take both pixel wise and region wise interaction into consideration when predicting label probability for each pixel we develop a context aware model based on multiple segmentation to obtain final result the mit attention dataset is applied finally to evaluate both new feature and model quantitative experiment demonstrate that figure ground cue are valid in predicting attention selection and our proposed model produce improvement over baseline method 
while activity recognition is a current focus of research the challenging problem of fine grained activity recognition is largely overlooked we thus propose a novel database of cooking activity continuously recorded in a realistic setting activity are distinguished by fine grained body motion that have low inter class variability and high intra class variability due to diverse subject and ingredient we benchmark two approach on our dataset one based on articulated pose track and the second using holistic video feature while the holistic approach outperforms the pose based approach our evaluation suggests that fine grained activity are more difficult to detect and the body model can help in those case providing high resolution video a well a an intermediate pose representation we hope to foster research in fine grained activity recognition 
reconstructionand example based super resolution sr method are promising for restoring a high resolution hr image from low resolution lr image s under large magnification reconstruction based method usually fail to hallucinate visual detail while example based method sometimes introduce unexpected detail given a generic lr image to reconstruct a photo realistic sr image and to suppress artifact in the reconstructed sr image we introduce a multi scale dictionary to a novel sr method that simultaneously integrates local and non local prior the local prior suppresses artifact by using steering kernel regression to predict the target pixel from a small local area the non local prior enriches visual detail by taking a weighted average of a large neighborhood a an estimate of the target pixel essentially these two prior are complementary to each other experimental result demonstrate that the proposed method can produce high quality sr recovery both quantitatively and perceptually 
undoubtedly a key feature in the popularity of smartmobile device is the numerous application one can install frequently we learn about an application we desire by seeing it on a review site someone else s device or a magazine a user friendly way to obtain this particular application could be by taking a snapshot of it corresponding icon and being directed automatically to it download link such a solution exists today for qr code which can be thought of a icon with a binary pattern in this paper we extend this to app icon and propose a complete system for automatic icon scanning it first detects the icon in a snapshot and then recognizes it icon scanning is a highly challenging problem due to the large variety of icon k in app store and background wallpaper in addition our system should further deal with the challenge introduced by taking picture of a screen nevertheless the novel solution proposed in this paper provides high detection and recognition rate we test our complete icon scanning system on icon snapshot taken by independent user and search them within the entire set of icon in app store our success rate are high and improve significantly on other method 
human action recognition is an important yet challenging task the recently developed commodity depth sensor open up new possibility of dealing with this problem but also present some unique challenge the depth map captured by the depth camera are very noisy and the d position of the tracked joint may be completely wrong if serious occlusion occur which increase the intra class variation in the action in this paper an actionlet ensemble model is learnt to represent each action and to capture the intra class variance in addition novel feature that are suitable for depth data are proposed they are robust to noise invariant to translational and temporal misalignment and capable of characterizing both the human motion and the human object interaction the proposed approach is evaluated on two challenging action recognition datasets captured by commodity depth camera and another dataset captured by a mocap system the experimental evaluation show that the proposed approach achieves superior performance to the state of the art algorithm 
combining multiple low level visual feature is a proven and effective strategy for a range of computer vision task however limited attention ha been paid to combining such feature with information from other modality such a audio and videotext for large scale analysis of web video in our work we rigorously analyze and combine a large set of low level feature that capture appearance color motion audio and audio visual co occurrence pattern in video we also evaluate the utility of high level i e semantic visual information obtained from detecting scene object and action concept further we exploit multimodal information by analyzing available spoken and videotext content using state of the art automatic speech recognition asr and videotext recognition system we combine these diverse feature using a two step strategy employing multiple kernel learning mkl and late score level fusion method based on the trecvid med evaluation for detecting event in a large benchmark set of video our system showed the best performance among the international team 
activity recognition in video is dominated by lowand mid level feature and while demonstrably capable by nature these feature carry little semantic meaning inspired by the recent object bank approach to image representation we present action bank a new high level representation of video action bank is comprised of many individual action detector sampled broadly in semantic space a well a viewpoint space our representation is constructed to be semantically rich and even when paired with simple linear svm classifier is capable of highly discriminative performance we have tested action bank on four major activity recognition benchmark in all case our performance is better than the state of the art namely on kth better by on ucf sport better by on ucf baseline is and on hmdb baseline is furthermore when we analyze the classifier we find strong transfer of semantics from the constituent action detector to the bank classifier 
in this paper we tackle the problem of understanding the temporal structure of complex event in highly varying video obtained from the internet towards this goal we utilize a conditional model trained in a max margin framework that is able to automatically discover discriminative and interesting segment of video while simultaneously achieving competitive accuracy on difficult detection and recognition task we introduce latent variable over the frame of a video and allow our algorithm to discover and assign sequence of state that are most discriminative for the event our model is based on the variable duration hidden markov model and model duration of state in addition to the transition between state the simplicity of our model allows u to perform fast exact inference using dynamic programming which is extremely important when we set our sight on being able to process a very large number of video quickly and efficiently we show promising result on the olympic sport dataset and the trecvid multimedia event detection task we also illustrate and visualize the semantic understanding capability of our model 
trajectory basis non rigid structure from motion nrsfm currently face two problem the limit of reconstructability and the need to tune the basis size for different sequence this paper provides a novel theoretical bound on d reconstruction error arguing that the existing definition of reconstructability is fundamentally flawed in that it fails to consider system condition this insight motivates a novel strategy whereby the trajectory s response to a set of high pas filter is minimised the new approach eliminates the need to tune the basis size and is more efficient for long sequence additionally the truncated dct basis is shown to have a dual interpretation a a high pas filter the success of trajectory filter reconstruction is demonstrated quantitatively on synthetic projection of real motion capture sequence and qualitatively on real image sequence 
human activity recognition is central to many practical application ranging from visual surveillance to gaming interfacing most approach addressing this problem are based on localized spatio temporal feature that can vary significantly when the viewpoint change a a result their performance rapidly deteriorate a the difference between the viewpoint of the training and testing data increase in this paper we introduce a new type of feature the hankelet that capture dynamic property of short tracklets while hankelets do not carry any spatial information they bring invariant property to change in viewpoint that allow for robust cross view activity recognition i e when action are recognized using a classifier trained on data from a different viewpoint our experiment on the ixmas dataset show that using hanklets improves the state of the art performance by over 
in this paper we propose a novel dense depth recovery method for a trinocular video sequence specifically we contribute a novel trinocular stereo matching model which can effectively utilize the advantage of trinocular stereo image and incorporate the visibility term with segmentation prior for robust depth estimate in order to make the recovered depth map more accurate and temporally consistent we propose to first classify the pixel to static and dynamic one and then perform spatio temporal depth optimization for them in different way especially we propose two motion model for handling dynamic pixel the traditional bundle optimization model and our spatio temporal optimization model are softly combined in a probabilistic way so that the depth of both static and dynamic pixel can be effectively refined our automatic depth recovery approach is evaluated using a variety of challenging trinocular video sequence 
this paper introduces a bundle adjustment ba method that obtains accurate structure and motion from rolling shutter r video sequence rsba when a classical ba algorithm process a rolling shutter video the resultant camera trajectory is brittle and complete failure are not uncommon we exploit the temporal continuity of the camera motion to define residual of image point trajectory with respect to the camera trajectory we compare the camera trajectory from rsba to those from classical ba and from classical ba on rectified video the comparison are done on real video sequence from an iphone with ground truth obtained from a global shutter camera rigidly mounted to the iphone compared to classical ba the rolling shutter model requires just six extra parameter it also degrades the sparsity of the system jacobian slightly but a we demonstrate the increase in computation time is moderate decisive advantage are that rsba succeeds in case where competing method diverge and consistently produce more accurate result 
d reconstruction from an unordered set of image may fail due to incorrect epipolar geometry eg between image pair arising from ambiguous feature correspondence previous method often analyze the consistency between different egs and regard the largest subset of self consistent egs a correct however a demonstrated in such a largest self consistent set often corresponds to incorrect result especially when there are duplicate structure in the scene we propose a novel optimization criterion based on the idea of missing correspondence the global minimum of our optimization objective function is associated with the correct solution we then design an efficient algorithm for minimization whose convergence to a local minimum is guaranteed experimental result show our method outperforms the state of the art 
many architectural scene contain symmetric or repeated structure which can generate erroneous image correspondence during structure from motion sfm computation prior work ha shown that the detection and removal of these incorrect match is crucial for accurate and robust recovery of scene structure in this paper we point out that these incorrect match in fact provide strong cue to the existence of symmetry and structural regularity in the unknown d structure we make two key contribution first we propose a method to recover various symmetry relation in the structure using geometric and appearance cue a set of structural constraint derived from the symmetry are imposed within a new constrained bundle adjustment formulation where symmetry prior are also incorporated second we show that the recovered symmetry enable u to choose a natural coordinate system for the d structure where gauge freedom in rotation is held fixed furthermore based on the symmetry d structure completion is also performed our approach significantly reduces drift through structural loop closure and improves the accuracy of reconstruction in urban scene 
we present a novel method to integrate multiple d scan captured from different viewpoint saliency information is used to guide the integration process the multi scale saliency of a point is specifically designed to reflect it sensitivity to registration error then scan are partitioned into salient and non salient region through an markov random field mrf framework where neighbourhood consistency is incorporated to increase the robustness against potential scanning error we then develop different scheme to discriminatively integrate point in the two region for the point in salient region which are more sensitive to registration error we employ the iterative closest point algorithm to compensate the local registration error and find the correspondence for the integration for the point in non salient region which are le sensitive to registration error we integrate them via an efficient and effective point shifting scheme a comparative study show that the proposed method delivers improved surface integration 
we propose an energy based framework for approximating surface from a cloud of point measurement corrupted by noise and outlier our energy assigns a tangent plane to each noisy data point by minimizing the squared distance to the point and the irregularity of the surface implicitly defined by the tangent plane in order to avoid the well known shrinking bias associated with first order surface regularization we choose a robust smoothing term that approximates curvature of the underlying surface in contrast to a number of recent publication estimating curvature using discrete e g binary labellings with triple clique we use higher dimensional label that allows modeling curvature with only pair wise interaction hence many standard optimization algorithm e g message passing graph cut etc can minimize the proposed curvature based regularization functional the accuracy of our approach for representing curvature is demonstrated by theoretical and empirical result on synthetic and real data set from multiview reconstruction and stereo 
in this paper we present a unified statistical framework for modeling both saccadic eye movement and visual saliency by analyzing the statistical property of human eye fixation on natural image we found that human attention is sparsely distributed and usually deployed to location with abundant structural information this new observation inspired u to model saccadic behavior and visual saliency based on super gaussian component sgc analysis the model sequentially obtains sgc using projection pursuit and generates eye movement by selecting the location with maximum sgc response beside human saccadic behavior simulation we also demonstrated our superior effectiveness and robustness over state of the art by carrying out dense experiment on psychological pattern and human eye fixation benchmark these result also show promising potential of statistical approach for human behavior research 
we consider the problem of finding a few representative for a dataset i e a subset of data point that efficiently describes the entire dataset we assume that each data point can be expressed a a linear combination of the representative and formulate the problem of finding the representative a a sparse multiple measurement vector problem in our formulation both the dictionary and the measurement are given by the data matrix and the unknown sparse code select the representative via convex optimization in general we do not assume that the data are low rank or distributed around cluster center when the data do come from a collection of low rank model we show that our method automatically selects a few representative from each low rank model we also analyze the geometry of the representative and discus their relationship to the vertex of the convex hull of the data we show that our framework can be extended to detect and reject outlier in datasets and to efficiently deal with new observation and large datasets the proposed framework and theoretical foundation are illustrated with example in video summarization and image classification using representative 
high quality urban reconstruction requires more than multi view reconstruction and local optimization the structure of facade depends on the general layout which ha to be optimized globally shape grammar are an established method to express hierarchical spatial relationship and are therefore suited a representing constraint for semantic facade interpretation usually inference us numerical approximation or hard coded grammar scheme existing method inspired by classical grammar parsing are not applicable on real world image due to their prohibitively high complexity this work provides feasible generic facade reconstruction by combining low level classifier with mid level object detector to infer an irregular lattice the irregular lattice preserve the logical structure of the facade while reducing the search space to a manageable size we introduce a novel method for handling symmetry and repetition within the generic grammar we show competitive result on two datasets namely the paris and the graz the former includes only hausmannian while the latter includes classicism biedermeier historicism art nouveau and post modern architectural style 
a a central problem in computer vision and pattern recognition data representation ha attracted great attention in the past year non negative matrix factorization nmf which is a useful data representation method make great contribution on finding the latent structure of the data and lead to a part based representation by decomposing the data matrix into a few base and encoding with nonnegative constraint however non negative constraint is insufficient for getting more robust data representation in this paper we propose a novel method called a optimal non negative projection anp for image data representation and further analysis anp imposes a constraint on the encoding factor a a regularizer during matrix factorization in this way the learned data representation lead to a stable linear model no matter what kind of data label is selected for further processing thus it can preserve more intrinsic characteristic of the data regardless of any specific label we demonstrate the effectiveness of this novel algorithm through a set of evaluation on real world application 
in this work we present a unified view on markov random field and recently proposed continuous tight convex relaxation for multi label assignment in the image plane these relaxation are far le biased towards the grid geometry than markov random field it turn out that the continuous method are non linear extension of the local polytope mrf relaxation in view of this result a better understanding of these tight convex relaxation in the discrete setting is obtained further a wider range of optimization method is now applicable to find a minimizer of the tight formulation we propose two method to improve the efficiency of minimization one us a weaker but more efficient continuously inspired approach a initialization and gradually refines the energy where it is necessary the other one reformulates the dual energy enabling smooth approximation to be used for efficient optimization we demonstrate the utility of our proposed minimization scheme in numerical experiment 
human pose estimation in a static image is a challenging problem in computer vision in that body part configuration are often subject to severe deformation and occlusion moreover efficient pose estimation is often a desirable requirement in many application the trade off between accuracy and efficiency ha been explored in a large number of approach on the one hand model with simple representation like tree or star model can be efficiently applied in pose estimation problem however these model are often prone to body part misclassification error on the other hand model with rich representation i e loopy graphical model are theoretically more robust but their inference complexity may increase dramatically in this work we propose an efficient and exact inference algorithm based on branch and bound to solve the human pose estimation problem on loopy graphical model we show that our method is empirically much faster about time than the state of the art exact inference algorithm by extending a state of the art tree model to a loopy graphical model we show that the estimation accuracy improves for most of the body part especially lower arm on popular datasets such a buffy and stickmen datasets finally our method can be used to exactly solve most of the inference problem on stretchable model which contains a few hundred of variable in just a few minute 
this paper introduces a novel solution to hand eye calibration problem it is the first method that us camera measurement directly and at the same time requires neither prior knowledge of the external camera calibration nor a known calibration device our algorithm us branch and bound approach to minimize an objective function based on the epipolar constraint further it employ linear programming to decide the bounding step of the algorithm the presented technique is able to recover both the unknown rotation and translation simultaneously and the solution is guaranteed to be globally optimal with respect to the l norm 
this paper extends the classical warping based optical flow method to achieve accurate flow in the presence of spatially varying motion blur our idea is to parameterize the appearance of each frame a a function of both the pixel motion and the motion induced blur we search for the flow that best match two consecutive frame which amount to finding the derivative of a blurred frame with respect to both the motion and the blur where the blur itself is a function of the motion we propose an efficient technique to calculate the derivative using prefiltering our technique avoids performing spatially varying filtering which can be computationally expensive during the optimization iteration in the end our derivative calculation technique can be easily incorporated with classical flow code to handle video with non uniform motion blur with little performance penalty our method is evaluated on both synthetic and real video and outperforms conventional flow method in the presence of motion blur 
computing optical flow between any pair of internet face photo is challenging for most current state of the art flow estimation method due to difference in illumination pose and geometry we show that flow estimation can be dramatically improved by leveraging a large photo collection of the same or similar object in particular consider the case of photo of a celebrity from google image search any two such photo may have different facial expression lighting and face orientation the key idea is that instead of computing flow directly between the input pair i j we compute version of the image i j in which facial expression and pose are normalized while lighting is preserved this is achieved by iteratively projecting each photo onto an appearance subspace formed from the full photo collection the desired flow is obtained through concatenation of flow i i o j j our approach can be used with any two frame optical flow algorithm and significantly boost the performance of the algorithm by providing invariance to lighting and shape change 
the mean field mf method are an energy optimization method for markov random field mrfs these method which have their root in solid state physic estimate the marginal density of each site of an mrf graph by iterative computation similarly to loopy belief propagation lbp it appears that being shadowed by lbp the mf method have not been seriously considered in the computer vision community this study investigates whether these method are useful for practical problem particularly mpm maximum posterior marginal inference in computer vision to be specific we apply the naive mf equation and the tap thouless anderson palmer equation to interactive segmentation and stereo matching in this paper firstly we show implementation of these method for computer vision problem next we discus advantage of the mf method to lbp finally we present experimental result that the mf method are well comparable to lbp in term of accuracy and global convergence furthermore the rd order tap equation often outperforms lbp in term of accuracy 
our goal is to segment a video sequence into moving object and the world scene in recent work spectral embedding of point trajectory based on d motion cue accumulated from their lifespan ha shown to outperform factorization and per frame segmentation method for video segmentation the scale and kinematic nature of the moving object and the background scene determine how close or far apart trajectory are placed in the spectral embedding such density variation may confuse clustering algorithm causing over fragmentation of object interior therefore instead of clustering in the spectral embedding we propose detecting discontinuity of embedding density between spatially neighboring trajectory detected discontinuity are strong indicator of object boundary and thus valuable for video segmentation we propose a novel embedding discretization process that recovers from over fragmentation by merging cluster according to discontinuity evidence along inter cluster boundary for segmenting articulated object we combine motion grouping cue with a center surround saliency operation resulting in context aware spatially coherent saliency map figure ground segmentation obtained from saliency thresholding provides object connectedness constraint that alter motion based trajectory affinity by keeping articulated part together and separating disconnected in time object finally we introduce gabriel graph a effective per frame superpixel map for converting trajectory clustering to dense image segmentation gabriel edge bridge large contour gap via geometric reasoning without over segmenting coherent image region we present experimental result of our method that outperform the state of the art in challenging motion segmentation datasets 
in this paper we study the problem of online aligning a newly arrived image to previously well aligned image inspired by recent advance in batch image alignment using low rank decomposition we treat the newly arrived image after alignment a being linearly and sparsely reconstructed by the well aligned one the task is accomplished by a sequence of convex optimization that minimizes the l norm after that online basis updating is pursued in two different way a two stage incremental alignment for joint registration of a large image dataset which is known a prior and a greedy online alignment of dynamically increasing image sequence such a in the tracking scenario in we first sequentially collect basis image that are easily aligned by checking their reconstruction residual followed by the second stage where all image are re aligned one by one using the collected basis set in during the tracking process we dynamically enrich the image basis set by the new target if it significantly distinguishes itself from existing basis image while inheriting the benefit of sparsity our method enjoys the great time efficiency and therefore be capable of dealing with large image set and real time task such a visual tracking the efficacy of the proposed online robust alignment algorithm is verified with extensive experiment on image set alignment and visual tracking in reference with state of the art method 
efficient keypoint based object detection method are used in many real time computer vision application these approach often model an object a a collection of keypoints and associated descriptor and detection then involves first constructing a set of correspondence between object and image keypoints via descriptor matching and subsequently using these correspondence a input to a robust geometric estimation algorithm such a ransac to find the transformation of the object in the image in such approach the object model is generally constructed offline and doe not adapt to a given environment at runtime furthermore the feature matching and transformation estimation stage are treated entirely separately in this paper we introduce a new approach to address these problem by combining the overall pipeline of correspondence generation and transformation estimation into a single structured output learning framework following the recent trend of using efficient binary descriptor for feature matching we also introduce an approach to approximate the learned object model a a collection of binary basis function which can be evaluated very efficiently at runtime experiment on challenging video sequence show that our algorithm significantly improves over state of the art descriptor matching technique using a range of descriptor a well a recent online learning based approach 
in this paper we address the task of tracking group of people in surveillance scenario this is a major challenge in computer vision since group are structured entity subjected to repeated split and merge event our solution is a joint individual group tracking framework inspired by a recent technique dubbed decentralized particle filtering the proposed strategy factorizes the joint individual group state space in two dependent subspace where individual and group share the knowledge of the joint individual group distribution in practice we establish a tight relation of mutual support between the modeling of individual and that of group promoting the idea that group are better tracked if individual are considered and viceversa extensive experiment on a published and novel dataset validate our intuition opening up to many future development 
recently sparse representation ha been applied to visual tracker by modeling the target appearance using a sparse approximation over a template set which lead to the so called l tracker a it need to solve an norm related minimization problem for many time while these l tracker showed impressive tracking accuracy they are very computationally demanding and the speed bottleneck is the solver to norm minimization this paper aim at developing an l tracker that not only run in real time but also enjoys better robustness than other l tracker in our proposed l tracker a new norm related minimization model is proposed to improve the tracking accuracy by adding an norm regularization on the coefficient associated with the trivial template moreover based on the accelerated proximal gradient approach a very fast numerical solver is developed to solve the resulting norm related minimization problem with guaranteed quadratic convergence the great running time efficiency and tracking accuracy of the proposed tracker is validated with a comprehensive evaluation involving eight challenging sequence and five alternative state of the art tracker 
we introduce a novel probabilistic framework for image registration this framework considers in contrast to previous one local neighborhood information we integrate the neighborhood information into the framework by adding layer of latent random variable characterizing the descriptive information of each image this extension ha multiple advantage it allows for a unified description of geometric and iconic registration with the consequential analysis of similarity it enables to arrange registration technique in a continuum limited by pure intensity and feature based registration with this wide spectrum of technique combined we can model hybrid registration approach the probabilistic coupling allows further to deduce optimal descriptor and to model the adaptation of description layer during the process a it is done for joint registration segmentation finally we deduce a new registration algorithm that allows for a dynamic adaptation of the description layer during the registration excellent result confirm the advantage of the new registration method the major contribution of this article lie however in the theoretical analysis 
recent attempt of integrating metric learning in visual tracking have produced encouraging result instead of using fixed and pre specified metric in visual appearance matching these method are able to learn and adjust the metric adaptively by finding the best projection of the feature space such learned metric is by design the best to discriminate the target of interest and it distracters from the background however an important issue remained unaddressed is how we can determine the optimal dimensionality of the projection to achieve best discrimination using inappropriate dimension for the projection is likely to result in larger classification error or higher computational cost and over fitting this paper present a novel solution to this structural order determination problem by introducing sparsity regularization for metric learning or srml this regularization lead to the lowest possible dimensionality of the projection and thus determining the best order this can actually be viewed a the minimum description length regularization in metric learning the experiment validate this new approach on standard benchmark datasets and demonstrate it effectiveness in visual tracking application 
we describe an online approach to learn non linear motion pattern and robust appearance model for multi target tracking in a tracklet association framework unlike most previous approach that use linear motion method only we online build a non linear motion map to better explain direction change and produce more robust motion affinity between tracklets moreover based on the incremental learned entry exit map a multiple instance learning method is devised to produce strong appearance model for tracking positive sample pair are collected from different track let so that training sample have high diversity finally using online learned moving group a tracklet completion process is introduced to deal with tracklets not reaching entry exit point we evaluate our approach on three public data set and show significant improvement compared with state of art method 
in large scale query by example retrieval embedding image signature in a binary space offer two benefit data compression and search efficiency while most embedding algorithm binarize both query and database signature it ha been noted that this is not strictly a requirement indeed asymmetric scheme which binarize the database signature but not the query still enjoy the same two benefit but may provide superior accuracy in this work we propose two general asymmetric distance which are applicable to a wide variety of embedding technique including locality sensitive hashing lsh locality sensitive binary code lsbc spectral hashing sh and semi supervised hashing ssh we experiment on four public benchmark containing up to m image and show that the proposed asymmetric distance consistently lead to large improvement over the symmetric hamming distance for all binary embedding technique we also propose a novel simple binary embedding technique pca embedding pcae which is shown to yield competitive result with respect to more complex algorithm such a sh and ssh 
pedestrian detection is a problem of considerable practical interest adding to the list of successful application of deep learning method to vision we report state of the art and competitive result on all major pedestrian datasets with a convolutional network model the model us a few new twist such a multi stage feature connection that skip layer to integrate global shape information with local distinctive motif information and an unsupervised method based on convolutional sparse coding to pre train the filter at each stage 
we introduce a novel approach to automatically recover d human pose from a single image most previous work follows a pipelined approach initially a set of d feature such a edge joint or silhouette are detected in the image and then these observation are used to infer the d pose solving these two problem separately may lead to erroneous d pose when the feature detector ha performed poorly in this paper we address this issue by jointly solving both the d detection and the d inference problem for this purpose we propose a bayesian framework that integrates a generative model based on latent variable and discriminative d part detector based on hog and perform inference using evolutionary algorithm real experimentation demonstrates competitive result and the ability of our methodology to provide accurate d and d pose estimation even when the d detector are inaccurate 
this paper present a robust occupancy analysis system for thermal imaging reliable detection of people is very hard in crowded scene due to occlusion and segmentation problem we therefore propose a framework that optimises the occupancy analysis over long period by including information on the transition in occupancy when people enter or leave the monitored area in stable period with no activity close to the border people are detected and counted which contributes to a weighted histogram when activity close to the border is detected local tracking is applied in order to identify a crossing after a full sequence the number of people during all period are estimated using a probabilistic graph search optimisation the system is tested on a total of frame captured in sport arena the mean error for a minute period containing people is which is a half of the error percentage optained by detection only and better than the result of comparable work the framework is also tested on a public available dataset from an outdoor scene which prof the generality of the method 
the human body is structurally symmetric tracking by detection approach for human pose suffer from double counting where the same image evidence is used to explain two separate but symmetric part such a the left and right foot double counting if left unaddressed can critically affect subsequent process such a action recognition affordance estimation and pose reconstruction in this work we present an occlusion aware algorithm for tracking human pose in an image sequence that address the problem of double counting our key insight is that tracking human pose can be cast a a multi target tracking problem where the target are related by an underlying articulated structure the human body is modeled a a combination of singleton part such a the head and neck and symmetric pair of part such a the shoulder knee and foot symmetric body part are jointly tracked with mutual exclusion constraint to prevent double counting by reasoning about occlusion we evaluate our algorithm on an outdoor dataset with natural background clutter a standard indoor dataset humaneva i and compare against a state of the art pose estimation algorithm 
we present a quadratic unconstrained binary optimization qubo framework for reasoning about multiple object detection with spatial overlap the method maximizes an objective function composed of unary detection confidence score and pairwise overlap constraint to determine which overlapping detection should be suppressed and which should be kept the framework is flexible enough to handle the problem of detecting object a a shape covering of a foreground mask and to handle the problem of filtering confidence weighted detection produced by a traditional sliding window object detector in our experiment we show that our method outperforms two existing state of the art pedestrian detector 
we investigate the problem of identifying the position of a viewer inside a room of planar mirror with unknown geometry in conjunction with the room s shape parameter we consider the observation to consist of angularly resolved depth measurement of a single scene point that is being observed via many multi bounce interaction with the specular room geometry application of this problem statement include area such a calibration acoustic echo cancelation and time of flight imaging we theoretically analyze the problem and derive sufficient condition for a combination of convex room geometry observer and scene point to be reconstruct able the resulting constructive algorithm is exponential in nature and therefore not directly applicable to practical scenario to counter the situation we propose theoretically devised geometric constraint that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that us these constraint to obtain an effective solution we demonstrate the effectiveness of our algorithm on extensive simulation a well a in a challenging real world calibration scenario 
in several hand object s interaction scenario the change in the object state is a direct consequence of the hand s motion this ha a straightforward representation in newtonian dynamic we present the first approach that exploit this observation to perform model based d tracking of a table top scene comprising passive object and an active hand our forward modelling of d hand object s interaction regard both the appearance and the physical state of the scene and is parameterized over the hand motion dofs between two successive instant in time we demonstrate that our approach manages to track the d pose of all object and the d pose and articulation of the hand by only searching for the parameter of the hand motion in the proposed framework covert scene state is inferred by connecting it to the overt state through the incorporation of physic thus our tracking approach treat a variety of challenging observability issue in a principled manner without the need to resort to heuristic 
this paper is concerned with the inference of marginal density based on mrf model the optimization algorithm for continuous variable are only applicable to a limited number of problem whereas those for discrete variable are versatile thus it is quite common to convert the continuous variable into discrete one for the problem that ideally should be solved in the continuous domain such a stereo matching and optical flow estimation in this paper we show a novel formulation for this continuous discrete conversion the key idea is to estimate the marginal density in the continuous domain by approximating them with mixture of rectangular density based on this formulation we derive a mean field mf algorithm and a belief propagation bp algorithm these algorithm can correctly handle the case where the variable space is discretized in a non uniform manner by intentionally using such a non uniform discretization a higher balance between computational efficiency and accuracy of marginal density estimate could be achieved we present a method for actually doing this which dynamically discretizes the variable space in a coarse to fine manner in the course of the computation experimental result show the effectiveness of our approach 
urban model are key to navigation architecture and entertainment apart from visualizing facade a number of tedious task remain largely manual e g compression generating new facade design and structurally comparing facade for classification retrieval and clustering we propose a novel procedural modelling method to automatically learn a grammar from a set of facade generate new facade instance and compare facade to deal with the difficulty of grammatical inference we reformulate the problem instead of inferring a compromising one size fit all single grammar for all task we infer a model whose successive refinement are production rule tailored for each task we demonstrate our automatic rule inference on datasets of two different architectural style our method supercedes manual expert work and cut the time required to build a procedural model of a facade from several day to a few millisecond 
in this paper we propose a method to detect change in the geometry of a city using panoramic image captured by a car driving around the city we designed our approach to account for all the challenge involved in a large scale application of change detection such a inaccuracy in the input geometry error in the geo location data of the image a well a the limited amount of information due to sparse imagery we evaluated our approach on an area of square kilometer inside a city using image downloaded from google street view these image besides being publicly available are also a good example of panoramic image captured with a driving vehicle and hence demonstrating all the possible challenge resulting from such an acquisition we also quantitatively compared the performance of our approach with respect to a ground truth a well a to prior work this evaluation show that our approach outperforms the current state of the art 
we show that bilateral symmetry plane estimation for three dimensional d shape may be carried out accurately and efficiently in the spherical harmonic domain our method are valuable for application where spherical harmonic expansion is already employed such a d shape registration morphometry and retrieval we show that the presence of bilateral symmetry in the d shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficient and provide algorithm for estimating the orientation of the symmetry plane the benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptor without the need to solve a correspondence problem our method work on point cloud a well a large scale mesh model of d shape 
this paper introduces a novel approach for reassembling pot sherd found at archaeological excavation site for the purpose of reconstructing clay pot that had been made on a wheel these pot and the sherd into which they have broken are axially symmetric the reassembly process can be viewed a d puzzle solving or generalized cylinder learning from broken fragment the estimation exploit both local and semi global geometric structure thus making it a fundamental problem of geometry estimation from noisy fragment in computer vision and pattern recognition the data used are densely digitized d laser scan of each fragment s outer surface the proposed reassembly system is automatic and function when the pile of available fragment is from one or multiple pot and even when piece are missing from any pot the geometric structure used are curve on the pot along which the surface had broken and the silhouette of a pot with respect to an axis called axis profile curve apc for reassembling multiple pot with or without missing piece our algorithm estimate the apc from each fragment then reassembles into configuration the one having distinctive apc further growth of configuration is based on adding remaining fragment such that their apc and break curve are consistent with those of a configuration the method is novel more robust and handle the largest number of fragment to date 
this paper extends to surface the multi scale approach of edge detection on image the common practice for detecting curve on surface requires the user to first select the scale of the feature apply an appropriate smoothing and detect the edge on the smoothed surface this approach suffers from two drawback first it relies on a hidden assumption that all the feature on the surface are of the same scale second manual user intervention is required in this paper we propose a general framework for automatically detecting the optimal scale for each point on the surface we smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface our multi scale algorithm solves the two disadvantage of the single scale approach mentioned above we demonstrate how to realize our approach on two commonly used special case ridge valley and relief edge in each case the optimal scale is found in accordance with the mathematical definition of the curve 
colorization refers to the process of adding color to black and white image or video this paper extends the term to handle surface in three dimension this is important for application in which the color of an object need to be restored and no relevant image exists for texturing it we focus on surface with pattern and propose a novel algorithm for adding color to these surface the user need only to scribble a few color stroke on one instance of each pattern and the system proceeds to automatically colorize the whole surface for this scheme to work we address not only the problem of colorization but also the problem of pattern detection on surface 
an anaglyph is a single image created by selecting complementary color from a stereo color pair the user can perceive depth by viewing it through color filtered glass we propose a technique to reconstruct the original color stereo pair given such an anaglyph we modified sift flow and use it to initially match the different color channel across the two view our technique then iteratively refines the match selects the good match which defines the anchor color and propagates the anchor color we use a diffusion based technique for the color propagation and added a step to suppress unwanted color result on a variety of input demonstrate the robustness of our technique we also extended our method to anaglyph video by using optic flow between time frame 
we present a statistical model of aerial image of recreational trail and a method to infer trail route in such image we learn a set of text ons describing the image and use them to divide the image into super pixel represented by their text on we then learn for each text on the frequency of generating on trail and off trail pixel and the direction of trail through on trail pixel from these we derive an image likelihood function we combine that with a prior model of trail length and smoothness yielding a posterior distribution for trail given an image we search for good value of this posterior using a novel stochastic variation of dijkstra s algorithm our experiment on trail image and ground truth collected in the western continental usa show substantial improvement over those of the previous best trail finding method 
with the aim to improve accuracy of stereo confidence measure we apply the random decision forest framework to a large set of diverse stereo confidence measure learning and testing set were drawn from the recently introduced kitti dataset which currently pose higher challenge to stereo solver than other benchmark with ground truth for stereo evaluation we experiment with semi global matching stereo sgm and a census data term which is the best performing real time capable stereo method known to date on kitti image sgm still produce a significant amount of error we obtain consistently improved area under curve value of sparsification measure in comparison to best performing single stereo confidence measure where number of stereo error are large more specifically our method performs best in all but one out of frame of the kitti dataset 
we address the problem of contour detection bottom up grouping and semantic segmentation using rgb d data we focus on the challenging setting of cluttered indoor scene and evaluate our approach on the recently introduced nyu depth v nyud dataset we propose algorithm for object boundary detection and hierarchical segmentation that generalize the gpb ucm approach of by making effective use of depth information we show that our system can label each contour with it type depth normal or albedo we also propose a generic method for long range amodal completion of surface and show it effectiveness in grouping we then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixel into the dominant object category in nyud we use both generic and class specific feature to encode the appearance and geometry of object we also show how our approach can be used for scene classification and how this contextual information in turn improves object recognition in all of these task we report significant improvement over the state of the art 
in this paper we present a new image matting algorithm that achieves state of the art performance on a benchmark dataset of image this is achieved by solving two major problem encountered by current sampling based algorithm the first is that the range in which the foreground and background are sampled is often limited to such an extent that the true foreground and background color are not present here we describe a method by which a more comprehensive and representative set of sample is collected so a not to miss out on the true sample this is accomplished by expanding the sampling range for pixel farther from the foreground or background boundary and ensuring that sample from each color distribution are included the second problem is the overlap in color distribution of foreground and background region this cause sampling based method to fail to pick the correct sample for foreground and background our design of an objective function force those foreground and background sample to be picked that are generated from well separated distribution comparison on the dataset at and evaluation by www alphamatting com show that the proposed method rank first in term of error measure used in the website 
we present the first variational framework for multi label segmentation on the ray space of d light field for traditional segmentation of single image feature need to be extracted from the d projection of a three dimensional scene the associated loss of geometry information can cause severe problem for example if different object have a very similar visual appearance in this work we show that using a light field instead of an image not only enables to train classifier which can overcome many of these problem but also provides an optimal data structure for label optimization by implicitly providing scene geometry information it is thus possible to consistently optimize label assignment over all view simultaneously a a further contribution we make all light field available online with complete depth and segmentation ground truth data where available and thus establish the first benchmark data set for light field analysis to facilitate competitive further development of algorithm 
we study the problem of part discovery when partial correspondence between instance of a category are available for visual category that exhibit high diversity in structure such a building our approach can be used to discover part that are hard to name but can be easily expressed a a correspondence between pair of image part naturally emerge from point wise landmark match across many instance within a category we propose a learning framework for automatic discovery of part in such weakly supervised setting and show the utility of the rich part library learned in this way for three task object detection category specific saliency estimation and fine grained image parsing 
image deconvolution is the ill posed problem of recovering a sharp image given a blurry one generated by a convolution in this work we deal with space invariant non blind deconvolution currently the most successful method involve a regularized inversion of the blur in fourier domain a a first step this step amplifies and color the noise and corrupts the image information in a second and arguably more difficult step one then need to remove the colored noise typically using a cleverly engineered algorithm however the method based on this two step approach do not properly address the fact that the image information ha been corrupted in this work we also rely on a two step procedure but learn the second step on a large dataset of natural image using a neural network we will show that this approach outperforms the current state of the art on a large dataset of artificially blurred image we demonstrate the practical applicability of our method in a real world example with photographic out of focus blur 
in this work we present a new part based object detection algorithm with hundred of part performing real time detection part based model are currently state of the art for object detection due to their ability to represent large appearance variation however due to their high computational demand such method are limited to several part only and are too slow for practical real time implementation our algorithm is an accelerated version of the feature synthesis f method which us multiple object part for detection and is among state of the art method on human detection benchmark but also suffers from a high computational cost the proposed accelerated feature synthesis afs us several strategy for reducing the number of location searched for each part the first strategy us a novel algorithm for approximate nearest neighbor search which we developed termed kd fern to compare each image location to only a subset of the model part candidate part location for a specific part are further reduced using spatial inhibition and using an object level coarse to fine strategy in our empirical evaluation on pedestrian detection benchmark afs maintains almost fully the accuracy performance of the original f while running more than x faster than existing part based method which use only several part afs is to our best knowledge the first part based object detection method achieving real time running performance nearly frame per second on x image on a regular cpu 
what make an object salient most previous work assert that distinctness is the dominating factor the difference between the various algorithm is in the way they compute distinctness some focus on the pattern others on the color and several add high level cue and prior we propose a simple yet powerful algorithm that integrates these three factor our key contribution is a novel and fast approach to compute pattern distinctness we rely on the inner statistic of the patch in the image for identifying unique pattern we provide an extensive evaluation and show that our approach outperforms all state of the art method on the five most commonly used datasets 
recurrence of small clean image patch across different scale of a natural image ha been successfully used for solving ill posed problem in clean image e g super resolution from a single image in this paper we show how this multi scale property can be extended to solve ill posed problem under noisy condition such a image denoising while clean patch are obscured by severe noise in the original scale of a noisy image noise level drop dramatically at coarser image scale this allows for the unknown hidden clean patch to naturally emerge in some coarser scale of the noisy image we further show that patch recurrence across scale is strengthened when using directional pyramid that blur and sub sample only in one direction our statistical experiment show that for almost any noisy image patch more than there exists a good clean version of itself at the same relative image coordinate in some coarser scale of the image this is a strong phenomenon of noise contaminated natural image which can serve a a strong prior for separating the signal from the noise finally incorporating this multi scale prior into a simple denoising algorithm yield state of the art denoising result 
an affine invariant representation is constructed with a cascade of invariant which preserve information for classification a joint translation and rotation invariant representation of image patch is calculated with a scattering transform it is implemented with a deep convolution network which computes successive wavelet transforms and modulus non linearity invariant to scaling shearing and small deformation are calculated with linear operator in the scattering domain state of the art classification result are obtained over texture database with uncontrolled viewing condition 
we present a solution for generating high quality stereo panorama at mega pixel resolution while previous approach introduced the basic principle we show that those technique do not generalise well to today s high image resolution and lead to disturbing visual artefact a our first contribution we describe the necessary correction step and a compact representation for the input image in order to achieve a highly accurate approximation to the required ray space our second contribution is a flow based up sampling of the available input ray which effectively resolve known aliasing issue like stitching artefact the required ray are generated on the fly to perfectly match the desired output resolution even for small number of input image in addition the up sampling is real time and enables direct interactive control over the desired stereoscopic depth effect in combination our contribution allow the generation of stereoscopic panorama at high output resolution that are virtually free of artefact such a seam stereo discontinuity vertical parallax and other mono stereoscopic shape distortion our process is robust and other type of multiperspective panorama such a linear panorama can also benefit from our contribution we show various comparison and high resolution result 
during recent year remarkable progress ha been made in visual saliency modeling our interest is in video saliency since video are fundamentally different from still image they are viewed differently by human observer for example the time each video frame is observed is a fraction of a second while a still image can be viewed leisurely therefore video saliency estimation method should differ substantially from image saliency method in this paper we propose a novel method for video saliency estimation which is inspired by the way people watch video we explicitly model the continuity of the video by predicting the saliency map of a given frame conditioned on the map from the previous frame furthermore accuracy and computation speed are improved by restricting the salient location to a carefully selected candidate set we validate our method using two gaze tracked video datasets and show we outperform the state of the art 
in this paper we revisit diffusion process on affinity graph for capturing the intrinsic manifold structure defined by pair wise affinity matrix such diffusion process have already proved the ability to significantly improve subsequent application like retrieval we give a thorough overview of the state of the art in this field and discus obvious similarity and difference based on our observation we are then able to derive a generic framework for diffusion process in the scope of retrieval application where the related work represents specific instance of our generic formulation we evaluate our framework on several retrieval task and are able to derive algorithm that e g achieve a bull eye score on the popular mpeg shape retrieval data set 
we argue for the importance of explicit semantic modelling in human centred texture analysis task such a retrieval annotation synthesis and zero shot learning to this end low level attribute are selected and used to define a semantic space for texture texture class varying in illumination and rotation are positioned within this semantic space using a pair wise relative comparison procedure low level visual feature used by existing texture descriptor are then assessed in term of their correspondence to the semantic space texture with strong presence of attribute connoting randomness and complexity are shown to be poorly modelled by existing descriptor in a retrieval experiment semantic descriptor are shown to outperform visual descriptor semantic modelling of texture is thus shown to provide considerable value in both feature selection and in analysis task 
rolling shutter r camera are used across a wide range of consumer electronic device from smart phone to high end camera it is well known that if a r camera is used with a moving camera or scene significant image distortion are introduced the quality or even success of structure from motion on rolling shutter image requires the usual intrinsic parameter such a focal length and distortion coefficient a well a accurate modelling of the shutter timing the current state of the art technique for calibrating the shutter timing requires specialised hardware we present a new method that only requires video of a known calibration pattern experimental result on over real datasets show that our method is more accurate than the current state of the art 
we present the major advantage of a new object oriented d slam paradigm which take full advantage in the loop of prior knowledge that many scene consist of repeated domain specific object and structure a a hand held depth camera browse a cluttered scene real time d object recognition and tracking provides dof camera object constraint which feed into an explicit graph of object continually refined by efficient pose graph optimisation this offer the descriptive and predictive power of slam system which perform dense surface reconstruction but with a huge representation compression the object graph enables prediction for accurate icp based camera to model tracking at each live frame and efficient active search for new object in currently undescribed image region we demonstrate real time incremental slam in large cluttered environment including loop closure relocalisation and the detection of moved object and of course the generation of an object level scene description with the potential to enable interaction 
this article present a new global approach for detecting vanishing point and group of mutually orthogonal vanishing direction using line detected in image of man made environment these two multi model fitting problem are respectively cast a uncapacited facility location ufl and hierarchical facility location hfl instance that are efficiently solved using a message passing inference algorithm we also propose new function for measuring the consistency between an edge and a putative vanishing point and for computing the vanishing point defined by a subset of edge extensive experiment in both synthetic and real image show that our algorithm outperform the state of the art method while keeping computation tractable in addition we show for the first time result in simultaneously detecting multiple manhattan world configuration that can either share one vanishing direction atlanta world or be completely independent 
even year ago szeliski et al published an influential study on energy minimization method for markov random field mrf this study provided valuable insight in choosing the best optimization technique for certain class of problem while these insight remain generally useful today the phenominal success of random field model mean that the kind of inference problem we solve have changed significantly specifically the model today often include higher order interaction flexible connectivity structure large label space of different cardinality or learned energy table to reflect these change we provide a modernized and enlarged study we present an empirical comparison of state of art technique on a corpus of energy minimization instance from diverse computer vision application to ensure reproducibility we evaluate all method in the opengm framework and report extensive result regarding runtime and solution quality key insight from our study agree with the result of szeliski et al for the type of model they studied however on new and challenging type of model our finding disagree and suggest that polyhedral method and integer programming solver are competitive in term of runtime and solution quality over a large range of model type 
we propose cloud motion a a natural scene cue that enables geometric calibration of static outdoor camera this work introduces several new method that use observation of an outdoor scene over day and week to estimate radial distortion focal length and geo orientation cloud based cue provide strong constraint and are an important alternative to method that require specific form of static scene geometry or clear sky condition our method make simple assumption about cloud motion and build upon previous work on motion based and line based calibration we show result on real scene that highlight the effectiveness of our proposed method 
in this paper we propose a novel semantic bundle adjustment framework whereby known rigid stationary object are detected while tracking the camera and mapping the environment the system build on established tracking and mapping technique to exploit incremental d reconstruction in order to validate hypothesis on the presence and pose of sought object then detected object are explicitly taken into account for a global semantic optimization of both camera and object pose thus unlike all system proposed so far our approach allows for solving jointly the detection and slam problem so a to achieve object detection together with improved slam accuracy 
propagating similarity information along the data manifold requires careful selection of local neighborhood selecting a good neighborhood in an unsupervised setting given an affinity graph ha been a difficult task the most common way to select a local neighborhood ha been to use the k nearest neighborhood k nn selection criterion however it ha the tendency to include noisy edge in this paper we propose a way to select a robust neighborhood using the consensus of multiple round of k nns we explain how using consensus information can give better control over neighborhood selection we also explain in detail the problem with another recently proposed neighborhood selection criterion i e dominant neighbor and show that our method is immune to those problem finally we show the result from experiment in which we compare our method to other neighborhood selection approach the result corroborate our claim that consensus of k nns doe indeed help in selecting more robust and stable locality 
articulated object represent an important class of object in our everyday environment automatic detection of the type of articulated or otherwise restricted motion and extraction of the corresponding motion parameter are therefore of high value eg in order to augment an otherwise static d reconstruction with dynamic semantics such a rotation ax and allowable translation direction for certain rigid part or object hence in this paper a novel theory to analyse relative transformation between two motion restricted part will be presented the analysis is based on linear subspace spanned by relative transformation moreover a signature for relative transformation will be introduced which uniquely specifies the type of restricted motion encoded in these relative transformation this theoretic framework enables the derivation of novel algebraic constraint such a low rank constraint for subsequent rotation around two fixed ax for example lastly given the type of restricted motion a predicted by the signature the paper show how to extract all the motion parameter with matrix manipulation from linear algebra our theory is verified on several real data set such a a rotating blackboard or a wheel rolling on the floor amongst others 
for problem over continuous random variable mrfs with large clique pose a challenge in probabilistic inference difficulty in performing optimization efficiently have limited the probabilistic model explored in computer vision and other field one inference technique that handle large clique well is expectation propagation ep offer run time independent of clique size which instead depend only on the rank or intrinsic dimensionality of potential this property would be highly advantageous in computer vision unfortunately for grid shaped model common in vision traditional gaussian ep requires quadratic space and cubic time in the number of pixel here we propose a variation of ep that exploit regularity in natural scene statistic to achieve run time that are linear in both number of pixel and clique size we test these method on shape from shading and we demonstrate strong performance not only for lambertian surface but also on arbitrary surface reflectance and lighting arrangement which requires highly non gaussian potential finally we use large non local clique to exploit cast shadow which is traditionally ignored in shape from shading 
natural image statistic indicate that we should use non convex norm for most regularization task in image processing and computer vision still they are rarely used in practice due to the challenge to optimize them recently iteratively reweighed minimization ha been proposed a a way to tackle a class of non convex function by solving a sequence of convex problem here we extend the problem class to linearly constrained optimization of a lipschitz continuous function which is the sum of a convex function and a function being concave and increasing on the non negative orthant possibly non convex and non concave on the whole space this allows to apply the algorithm to many computer vision task we show the effect of non convex regularizers on image denoising deconvolution optical flow and depth map fusion non convexity is particularly interesting in combination with total generalized variation and learned image prior efficient optimization is made possible by some important property that are shown to hold 
pairwise discrete energy defined over graph are ubiquitous in computer vision many algorithm have been proposed to minimize such energy often concentrating on sparse graph topology or specialized class of pairwise potential however when the graph is fully connected and the pairwise potential are arbitrary the complexity of even approximate minimization algorithm such a trw s grows quadratically both in the number of node and in the number of state a node can take moreover recent application are using more and more computationally expensive pairwise potential these factor make it very hard to employ fully connected model in this paper we propose a novel generic algorithm to approximately minimize any discrete pairwise energy function our method exploit tractable sub energy to filter the domain of the function the parameter of the filter are learnt from instance of the same class of energy with good candidate solution compared to existing method it efficiently handle fully connected graph with many state per node and arbitrary pairwise potential which might be expensive to compute we demonstrate experimentally on two application that our algorithm is much more efficient than other generic minimization algorithm such a trw s while returning essentially identical solution 
in this paper we tackle the problem of performing inference in graphical model whose energy is a polynomial function of continuous variable our energy minimization method follows a dual decomposition approach where the global problem is split into sub problem defined over the graph clique the optimal solution to these sub problem is obtained by making use of a polynomial system solver our algorithm inherits the convergence guarantee of dual decomposition to speed up optimization we also introduce a variant of this algorithm based on the augmented lagrangian method our experiment illustrate the diversity of computer vision problem that can be expressed with polynomial energy and demonstrate the benefit of our approach over existing continuous inference method 
in computer vision application feature often lie on riemannian manifold with known geometry popular learning algorithm such a discriminant analysis partial least square support vector machine etc are not directly applicable to such feature due to the non euclidean nature of the underlying space hence classification is often performed in an extrinsic manner by mapping the manifold to euclidean space using kernel however for kernel based approach poor choice of kernel often result in reduced performance in this paper we address the issue of kernel selection for the classification of feature that lie on riemannian manifold using the kernel learning approach we propose two criterion for jointly learning the kernel and the classifier using a single optimization problem specifically for the svm classifier we formulate the problem of learning a good kernel classifier combination a a convex optimization problem and solve it efficiently following the multiple kernel learning approach experimental result on image set based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing method for classification of manifold feature 
statistical shape model such a active shape model asms suffer from their inability to represent a large range of variation of a complex shape and to account for the large error in detection of model point we propose a novel method dubbed pdm enlor that overcomes these limitation by locating each shape model point individually using an ensemble of local regression model and appearance cue from selected model point our method first detects a set of reference point which were selected based on their saliency during training for each model point an ensemble of regressors is built from the location of the detected reference point each regressor infers a candidate location for that model point using local geometric constraint encoded by a point distribution model pdm the final location of that point is determined a a weighted linear combination whose coefficient are learnt from the training data of candidate proposed from it ensemble s component regressors we use different subset of reference point a explanatory variable for the component regressors to provide varying degree of locality for the model in each ensemble this help our ensemble model to capture a larger range of shape variation a compared to a single pdm we demonstrate the advantage of our method on the challenging problem of segmenting gene expression image of mouse brain 
conventional subspace construction approach suffer from the need of large enough image ensemble rendering numerical method intractable in this paper we propose an analytic formulation for low dimensional subspace construction in which shading cue lie while preserving the natural structure of an image sample using the frequency space representation of the image irradiance equation the process of finding such subspace is cast a establishing a relation between it principal component and that of a deterministic set of basis function termed a irradiance harmonic representing image a matrix further lessen the number of parameter to be estimated to define a bilinear projection which map the image sample to a lower dimensional bilinear subspace result show significant impact on dimensionality reduction with minimal loss of information a well a robustness against noise 
the solution for the top down segmentation of non rigid visual object using machine learning technique is generally regarded a too complex to be solved in it full generality given the large dimensionality of the search space of the explicit representation of the segmentation contour in order to reduce this complexity the problem is usually divided into two stage rigid detection and non rigid segmentation the rationale is based on the fact that the rigid detection can be run in a lower dimensionality space i e le complex and faster than the original contour space and it result is then used to constrain the non rigid segmentation in this paper we propose the use of sparse manifold to reduce the dimensionality of the rigid detection search space of current state of the art top down segmentation methodology the main goal targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detector these goal are attainable given that both the search and training complexity are function of the dimensionality of the rigid search space we test our approach in the segmentation of the left ventricle from ultrasound image and lip from frontal face image compared to the performance of state of the art non rigid segmentation system our experiment show that the use of sparse manifold for the rigid detection lead to the two goal mentioned above 
human pose detector although successful in localising face and torso of people often fail with lower arm with fast movement body motion estimation is often inaccurate we build a segmentation detection algorithm that mediates the information between body part recognition and multi frame motion grouping to improve both pose detection and tracking motion of body part though not accurate is often sufficient to segment them from their background such segmentation are crucial for extracting hard to detect body part out of their interior body clutter by matching these segment to exemplar we obtain pose labeled body segment the pose labeled segment and corresponding articulated joint are used to improve the motion flow field by proposing kinematically constrained affine displacement on body part the pose based articulated motion model is shown to handle large limb rotation and displacement our algorithm can detect people under rare pose frequently missed by pose detector showing the benefit of jointly reasoning about pose segmentation and motion in video 
a early stage of video processing we introduce an iterative trajectory merging algorithm that produce a region based and hierarchical representation of the video sequence called the trajectory binary partition tree bpt from this representation many analysis and graph cut technique can be used to extract partition or object that are useful in the context of specific application in order to define trajectory and to create a precise merging algorithm color and motion cue have to be used both type of information are very useful to characterize object but present strong difference of behavior in the spatial and the temporal dimension on the one hand scene and object are rich in their spatial color distribution but these distribution are rather stable over time object motion on the other hand present simple structure and low spatial variability but may change from frame to frame the proposed algorithm take into account this key difference and relies on different model and associated metric to deal with color and motion information we show that the proposed algorithm outperforms existing hierarchical video segmentation algorithm and provides more stable and precise region 
we propose scalpel a flexible method for object segmentation that integrates rich region merging cue with midand high level information about object layout class and scale into the segmentation process unlike competing approach scalpel us a cascade of bottom up segmentation model that is capable of learning to ignore boundary early on yet use them a a stopping criterion once the object ha been mostly segmented furthermore we show how such cascade can be learned efficiently when paired with a novel method that generates better localized shape prior than our competitor our method lead to a concise accurate set of segmentation proposal these proposal are more accurate on the pascal voc dataset than state of the art method that use re ranking to filter much larger bag of proposal the code for our algorithm is available online 
unsupervised over segmentation of an image into region of perceptually similar pixel known a super pixel is a widely used preprocessing step in segmentation algorithm super pixel method reduce the number of region that must be considered later by more computationally expensive algorithm with a minimal loss of information nevertheless a some information is inevitably lost it is vital that super pixel not cross object boundary a such error will propagate through later step existing method make use of projected color or depth information but do not consider three dimensional geometric relationship between observed data point which can be used to prevent super pixel from crossing region of empty space we propose a novel over segmentation algorithm which us voxel relationship to produce over segmentation which are fully consistent with the spatial geometry of the scene in three dimensional rather than projective space enforcing the constraint that segmented region must have spatial connectivity prevents label flow across semantic object boundary which might otherwise be violated additionally a the algorithm work directly in d space observation from several calibrated rgb d camera can be segmented jointly experiment on a large data set of human annotated rgb d image demonstrate a significant reduction in occurrence of cluster crossing object boundary while maintaining speed comparable to state of the art d method 
we present a novel method for clustering data drawn from a union of arbitrary dimensional subspace called discriminative subspace clustering disc disc solves the subspace clustering problem by using a quadratic classifier trained from unlabeled data clustering by classification we generate label by exploiting the locality of point from the same subspace and a basic affinity criterion a number of classifier are then diversely trained from different partition of the data and their result are combined together in an ensemble in order to obtain the final clustering result we have tested our method with challenging datasets and compared against state of the art method from literature our result show that disc is a very strong performer in both accuracy and robustness and also of low computational complexity 
this paper tackle the supervised evaluation of image segmentation algorithm first it survey and structure the measure used to compare the segmentation result with a ground truth database and proposes a new measure the precision recall for object and part to compare the goodness of these measure it defines three quantitative meta measure involving six state of the art segmentation method the meta measure consist in assuming some plausible hypothesis about the result and assessing how well each measure reflects these hypothesis a a conclusion this paper proposes the precision recall curve for boundary and for object and part a the tool of choice for the supervised evaluation of image segmentation we make the datasets and code of all the measure publicly available 
we address the problem of long term object tracking where the object may become occluded or leave the view in this setting we show that an accurate appearance model is considerably more effective than a strong motion model we develop simple but effective algorithm that alternate between tracking and learning a good appearance model given a track we show that it is crucial to learn from the right frame and use the formalism of self paced curriculum learning to automatically select such frame we leverage technique from object detection for learning accurate appearance based template demonstrating the importance of using a large negative training set typically not used for tracking we describe both an offline algorithm that process frame in batch and a linear time on line i e causal algorithm that approach real time performance our model significantly outperform prior art reducing the average error on benchmark video by a factor of 
we present a method for computing ambient occlusion ao for a stack of image of a scene from a fixed viewpoint ambient occlusion a concept common in computer graphic characterizes the local visibility at a point it approximates how much light can reach that point from different direction without getting blocked by other geometry while ao ha received surprisingly little attention in vision we show that it can be approximated using simple per pixel statistic over image stack based on a simplified image formation model we use our derived ao measure to compute reflectance and illumination for object without relying on additional smoothness prior and demonstrate state of the art performance on the mit intrinsic image benchmark we also demonstrate our method on several synthetic and real scene including d printed object with known ground truth geometry 
we propose to leverage multiple source of information to compute an estimate of the number of individual present in an extremely dense crowd visible in a single image due to problem including perspective occlusion clutter and few pixel per person counting by human detection in such image is almost impossible instead our approach relies on multiple source such a low confidence head detection repetition of texture element using sift and frequency domain analysis to estimate count along with confidence associated with observing individual in an image region secondly we employ a global consistency constraint on count using markov random field this caters for disparity in count in local neighborhood and across scale we tested our approach on a new dataset of fifty crowd image containing k annotated human with the head count ranging from to this is in stark contrast to datasets used for existing method which contain not more than ten of individual we experimentally demonstrate the efficacy and reliability of the proposed approach by quantifying the counting performance 
in this paper we present a model of action based on the change in the state of the environment many action involve similar dynamic and hand object relationship but differ in their purpose and meaning the key to differentiating these action is the ability to identify how they change the state of object and material in the environment we propose a weakly supervised method for learning the object and material state that are necessary for recognizing daily action once these state detector are learned we can apply them to input video and pool their output to detect action we further demonstrate that our method can be used to segment discrete action from a continuous video of an activity our result outperform state of the art action recognition and activity segmentation result 
we deal with the problem of recognizing social role played by people in an event social role are governed by human interaction and form a fundamental component of human event description we focus on a weakly supervised setting where we are provided different video belonging to an event class without training role label since social role are described by the interaction between people in an event we propose a conditional random field to model the inter role interaction along with person specific social descriptor we develop tractable variational inference to simultaneously infer model weight a well a role assignment to all people in the video we also present a novel youtube social role dataset with ground truth role annotation and introduce annotation on a subset of video from the trecvid med event kit for evaluation purpose the performance of the model is compared against different baseline method on these datasets 
we present swig a swift and efficient guided sampling method for robust model estimation from image feature correspondence our method leverage the accuracy of our new confidence measure mr rayleigh which assigns a correctness confidence to a putative correspondence in an online fashion mr rayleigh is inspired by meta recognition mr an algorithm that aim to predict when a classifier s outcome is correct we demonstrate that by using a rayleigh distribution the prediction accuracy of mr can be improved considerably our experiment show that mr rayleigh tends to predict better than the often used lowe s ratio brown s ratio and the standard mr under a range of imaging condition furthermore our homography estimation experiment demonstrates that swig performs similarly or better than other guided sampling method while requiring fewer iteration leading to fast and accurate model estimate 
current object recognition algorithm use local feature such a scale invariant feature transform sift and speeded up robust feature surf for visually learning to recognize object these approach though cannot apply to transparent object made of glass or plastic a such object take on the visual feature of background object and the appearance of such object dramatically varies with change in scene background indeed in transmitting light transparent object have the unique characteristic of distorting the background by refraction in this paper we use a single shot light field image a an input and model the distortion of the light field caused by the refractive property of a transparent object we propose a new feature called the light field distortion lfd feature for identifying a transparent object the proposal incorporates this lfd feature into the bag of feature approach for recognizing transparent object we evaluated it performance in laboratory and real setting 
bag of word model for feature extraction have demonstrated top notch performance in image classification these representation are usually accompanied by a coding method recently method that code a descriptor giving regard to it nearby base have proved efficacious these method take into account the nonlinear structure of descriptor since local similarity are a good approximation of global similarity however they confine their usage of the global similarity to nearby base in this paper we propose a coding scheme that brings into focus the manifold structure of descriptor and devise a method to compute the global similarity of descriptor to the base given a local similarity measure between base a global measure is computed exploiting the local similarity of a descriptor and it nearby base a global measure of association of a descriptor to all the base is computed unlike the locality based and sparse coding method the proposed coding varies smoothly with respect to the underlying manifold experiment on benchmark image classification datasets substantiate the superiority of the proposed method over it locality and sparsity based rival 
we describe novel but simple motion feature for the problem of detecting object in video sequence previous approach either compute optical flow or temporal difference on video frame pair with various assumption about stabilization we describe a combined approach that us coarse scale flow and fine scale temporal difference feature our approach performs weak motion stabilization by factoring out camera motion and coarse object motion while preserving nonrigid motion that serve a useful cue for recognition we show result for pedestrian detection and human pose estimation in video sequence achieving state of the art result in both in particular given a fixed detection rate our method achieves a five fold reduction in false positive over prior art on the caltech pedestrian benchmark finally we perform extensive diagnostic experiment to reveal what aspect of our system are crucial for good performance proper stabilization long time scale feature and proper normalization are all critical 
in this work we exploit segmentation to construct appearance descriptor that can robustly deal with occlusion and background change for this we downplay measurement coming from area that are unlikely to belong to the same region a the descriptor s center a suggested by soft segmentation mask our treatment is applicable to any image point i e dense and it computational overhead is in the order of a few second we integrate this idea with dense sift and also with dense scale and rotation invariant descriptor sid delivering descriptor that are densely computable invariant to scaling and rotation and robust to background change we apply our approach to standard benchmark on large displacement motion estimation using sift flow and wide baseline stereo systematically demonstrating that the introduction of segmentation yield clear improvement 
we present a robust and efficient technique for matching dense set of point undergoing non rigid spatial transformation our main intuition is that the subset of point that can be matched with high confidence should be used to guide the matching procedure for the rest we propose a novel algorithm that incorporates these high confidence match a a spatial prior to learn a discriminative subspace that simultaneously encodes both the feature similarity a well a their spatial arrangement conventional subspace learning usually requires spectral decomposition of the pair wise distance matrix across the point set which can become inefficient even for moderately sized problem to this end we propose the use of random projection for approximate subspace learning which can provide significant time improvement at the cost of minimal precision loss this efficiency gain allows u to iteratively find and remove high confidence match from the point set resulting in high recall to show the effectiveness of our approach we present a systematic set of experiment and result for the problem of dense non rigid image feature matching 
this paper address the problem of semantic segmentation of d point cloud we extend the inference machine framework of ross et al by adding spatial factor that model mid range and long range dependency inherent in the data the new model is able to account for semantic spatial context during training our method automatically isolates and retains factor modelling spatial dependency between variable that are relevant for achieving higher prediction accuracy we evaluate the proposed method by using it to predict category semantic segmentation on set of stitched kinect scan experimental result show that the spatial dependency learned by our method significantly improve the accuracy of segmentation they also show that our method outperforms the existing segmentation technique of koppula et al 
relating visual information to it linguistic semantic meaning remains an open and challenging area of research the semantic meaning of image depends on the presence of object their attribute and their relation to other object but precisely characterizing this dependence requires extracting complex visual information from an image which is in general a difficult and yet unsolved problem in this paper we propose studying semantic information in abstract image created from collection of clip art abstract image provide several advantage they allow for the direct study of how to infer high level semantic information since they remove the reliance on noisy low level object attribute and relation detector or the tedious hand labeling of image importantly abstract image also allow the ability to generate set of semantically similar scene finding analogous set of semantically similar real image would be nearly impossible we create set of semantically similar abstract scene with corresponding written description we thoroughly analyze this dataset to discover semantically important feature the relation of word to visual feature and method for measuring semantic similarity 
visual attribute are powerful feature for many different application in computer vision such a object detection and scene recognition visual attribute present another application that ha not been examined a rigorously verbal communication from a computer to a human since many attribute are nameable the computer is able to communicate these concept through language however this is not a trivial task given a set of attribute selecting a subset to be communicated is task dependent moreover because attribute classifier are noisy it is important to find way to deal with this uncertainty we address the issue of communication by examining the task of composing an automatic description of a person in a group photo that distinguishes him from the others we introduce an efficient principled method for choosing which attribute are included in a short description to maximize the likelihood that a third party will correctly guess to which person the description refers we compare our algorithm to computer baseline and human describers and show the strength of our method in creating effective description 
in this paper we propose an affordable solution to self localization which utilizes visual odometry and road map a the only input to this end we present a probabilistic model a well a an efficient approximate inference algorithm which is able to utilize distributed computation to meet the real time requirement of autonomous system because of the probabilistic nature of the model we are able to cope with uncertainty due to noisy visual odometry and inherent ambiguity in the map e g in a manhattan world by exploiting freely available community developed map and visual odometry measurement we are able to localize a vehicle up to m after only a few second of driving on map which contain more than km of drivable road 
recent trend in semantic image segmentation have pushed for holistic scene understanding model that jointly reason about various task such a object detection scene recognition shape analysis contextual reasoning in this work we are interested in understanding the role of these different task in aiding semantic segmentation towards this goal we plug in human subject for each of the various component in a state of the art conditional random field model crf on the msrc dataset comparison among various hybrid human machine crfs give u indication of how much head room there is to improve segmentation by focusing research effort on each of the task one of the interesting finding from our slew of study wa that human classification of isolated super pixel while being worse than current machine classifier provides a significant boost in performance when plugged into the crf fascinated by this finding we conducted in depth analysis of the human generated potential this inspired a new machine potential which significantly improves state of the art performance on the mrsc dataset 
this paper present a nonparametric approach to semantic parsing using small patch and simple gradient color and location feature we learn the relevance of individual feature channel at test time using a locally adaptive distance metric to further improve the accuracy of the nonparametric approach we examine the importance of the retrieval set used to compute the nearest neighbour using a novel semantic descriptor to retrieve better candidate the approach is validated by experiment on several datasets used for semantic parsing demonstrating the superiority of the method compared to the state of art approach 
cascade style approach to implementing ensemble classifier can deliver significant speed ups at test time while highly effective they remain challenging to tune and their overall performance depends on the availability of large validation set to estimate rejection threshold these characteristic are often prohibitive and thus limit their applicability we introduce an alternative approach to speeding up classifier evaluation which overcomes these limitation it involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough a a result the evaluation terminates early based on the sequence of response observed furthermore it doe so independently of the type of ensemble classifier used or the way it wa trained we show through extensive experimentation that our method provides to fold speed ups over existing state of the art method at almost no loss in accuracy on a number of object classification task 
metric learning method for person re identification estimate a scaling for distance in a vector space that is optimized for picking out observation of the same individual this paper present a novel approach to the pedestrian re identification problem that us metric learning to improve the state of the art performance on standard public datasets very high dimensional feature are extracted from the source color image a first processing stage performs unsupervised pca dimensionality reduction constrained to maintain the redundancy in color space representation a second stage further reduces the dimensionality using a local fisher discriminant analysis defined by a training set a regularization step is introduced to avoid singular matrix during this stage the experiment conducted on three publicly available datasets confirm that the proposed method outperforms the state of the art performance including all other known metric learning method further more the method is an effective way to process observation comprising multiple shot and is non iterative the computation time are relatively modest finally a novel statistic is derived to characterize the match characteristic the normalized entropy reduction can be used to define the proportion of uncertainty removed pur this measure is invariant to test set size and provides an intuitive indication of performance 
we propose a principled probabilistic formulation of object saliency a a sampling problem this novel formulation allows u to learn from a large corpus of unlabelled image which patch of an image are of the greatest interest and most likely to correspond to an object we then sample the object saliency map to propose object location we show that using only a single object location proposal per image we are able to correctly select an object in over of the image in the pascal voc dataset substantially outperforming existing approach furthermore we show that our object proposal can be used a a simple unsupervised approach to the weakly supervised annotation problem our simple unsupervised approach to annotating object of interest in image achieves a higher annotation accuracy than most weakly supervised approach 
since the seminal work of thrun the learning to learn paradigm ha been defined a the ability of an agent to improve it performance at each task with experience with the number of task within the object categorization domain the visual learning community ha actively declined this paradigm in the transfer learning setting almost all proposed method focus on category detection problem addressing how to learn a new target class from few sample by leveraging over the known source but if one think of learning over multiple task there is a need for multiclass transfer learning algorithm able to exploit previous source knowledge when learning a new class while at the same time optimizing their overall performance this is an open challenge for existing transfer learning algorithm the contribution of this paper is a discriminative method that address this issue based on a least square support vector machine formulation our approach is designed to balance between transferring to the new class and preserving what ha already been learned on the source model extensive experiment on subset of publicly available datasets prove the effectiveness of our approach 
in this work we propose an exemplar based face image segmentation algorithm we take inspiration from previous work on image parsing for general scene our approach assumes a database of exemplar face image each of which is associated with a hand labeled segmentation map given a test image our algorithm first selects a subset of exemplar image from the database our algorithm then computes a nonrigid warp for each exemplar image to align it with the test image finally we propagate label from the exemplar image to the test image in a pixel wise manner using trained weight to modulate and combine label map from different exemplar we evaluate our method on two challenging datasets and compare with two face parsing algorithm and a general scene parsing algorithm we also compare our segmentation result with contour based face alignment result that is we first run the alignment algorithm to extract contour point and then derive segment from the contour our algorithm compare favorably with all previous work on all datasets evaluated 
estimating the amount and center of distortion from line in the scene ha been addressed in the literature by the so called plumb line approach in this paper we propose a new geometric method to estimate not only the distortion parameter but the entire camera calibration up to an angular scale factor using a minimum of line we propose a new framework for the unsupervised simultaneous detection of natural image of line and camera parameter estimation enabling a robust calibration from a single image comparative experiment with existing automatic approach for the distortion estimation and with ground truth data are presented 
we describe photo ocr a system for text extraction from image our particular focus is reliable text extraction from smartphone imagery with the goal of text recognition a a user input modality similar to speech recognition commercially available ocr performs poorly on this task recent progress in machine learning ha substantially improved isolated character classification we build on this progress by demonstrating a complete ocr system using these technique we also incorporate modern data center scale distributed language modelling our approach is capable of recognizing text in a variety of challenging imaging condition where traditional ocr system fail notably in the presence of substantial blur low resolution low contrast high image noise and other distortion it also operates with low latency mean processing time is m per image we evaluate our system on public benchmark datasets for text extraction and outperform all previously reported result more than halving the error rate on multiple benchmark the system is currently in use in many application at google and is available a a user input modality in google translate for android 
we present a method that can dramatically accelerate object detection with part based model the method is based on the observation that the cost of detection is likely to be dominated by the cost of matching each part to the image and not by the cost of computing the optimal configuration of the part a commonly assumed therefore accelerating detection requires minimizing the number of part to image comparison to this end we propose a multiple resolution hierarchical part based model and a corresponding coarse to fine inference procedure that recursively eliminates from the search space unpromising part placement the method yield a ten fold speedup over the standard dynamic programming approach and is complementary to the cascade of part approach of compared to the latter our method doe not have parameter to be determined empirically which simplifies it use during the training of the model most importantly the two technique can be combined to obtain a very significant speedup of two order of magnitude in some case we evaluate our method extensively on the pascal voc and inria datasets demonstrating a very high increase in the detection speed with little degradation of the accuracy 
sparse subspace clustering ssc is one of the recent approach to subspace segmentation in ssc a graph is constructed whose node are the data point and whose edge are inferred from the l sparse representation of each point by the others it ha been proved that if the point lie on a mixture of independent subspace the graphical structure of each subspace is disconnected from the others however the problem of connectivity within each subspace is still unanswered this is important since the subspace segmentation in ssc is based on finding the connected component of the graph our analysis is built upon the connection between the sparse representation through l norm minimization and the geometry of convex poly tope proposed by the compressed sensing community after introduction of some assumption to make the problem well defined it is proved that the connectivity within each subspace hold for and dimensional subspace the claim of connectivity for general d dimensional case even for generic configuration is proved false by giving a counterexample in dimension greater than 
this work attempt to considerably reduce the amount of user effort in the natural image matting problem the key observation is that the nonlocal principle introduced to denoise image can be successfully applied to the alpha matte to obtain sparsity in matte representation and therefore dramatically reduce the number of pixel a user need to manually label we show how to avoid making the user provide redundant and unnecessary input develop a method for clustering the image pixel for the user to label and a method to perform high quality matte extraction we show that this algorithm is therefore faster easier and higher quality than state of the art method 
computational model of visual process with biological inspiration and even biological realism are currently of great interest in the computer vision community this paper provides a biologically plausible model of d shape which incorporates intermediate layer of visual representation that have not previously been fully explored we propose that endstopping and curvature cell are of great importance for shape selectivity and show how their combination can lead to shape selective neuron this shape representation model provides a highly accurate fit with neural data from and provides comparable result with real world image to current computer vision system the conclusion is that such intermediate representation may no longer require a learning approach a a bridge between early representation based on gabor or difference of gaussian filter that are not learned since they are well understood and later representation closer to object representation that still can benefit from a learning methodology 
how many people should you ask if you are not sure about your way we provide an answer to this question for random forest classification the presented method is based on the statistical formulation of confidence interval and conjugate prior for binomial a well a multinomial distribution we derive appealing decision rule to speed up the classification process by leveraging the fact that many sample can be clearly mapped to class result on test data are provided and we highlight the applicability of our method to a wide range of problem the approach introduces only one non heuristic parameter that allows to trade off accuracy and speed without any re training of the classifier the proposed method automatically adapts to the difficulty of the test data and make classification significantly faster without deteriorating the accuracy 
spatial pyramid representation spr is a widely used method for embedding both global and local spatial information into a feature and it show good performance in term of generic image recognition in spr the image is divided into a sequence of increasingly finer grid on each pyramid level feature are extracted from all of the grid cell and are concatenated to form one huge feature vector a a result expensive computational cost are required for both learning and testing moreover because the strategy for partitioning the image at each pyramid level is designed by hand there is weak theoretical evidence of the appropriate partitioning strategy for good categorization in this paper we propose discriminative spr which is a new representation that form the image feature a a weighted sum of semi local feature over all pyramid level the weight are automatically selected to maximize a discriminative power the resulting feature is compact and preserve high discriminative power even in low dimension furthermore the discriminative spr can suggest the distinctive cell and the pyramid level simultaneously by observing the optimal weight generated from the fine grid cell 
is the real problem in finding the relative orientation of two viewpoint the correspondence problem we argue that this is only one difficulty even with known correspondence popular method like the eight point algorithm and minimal solver may break down due to planar scene or small relative motion in this paper we derive a simple brute force algorithm which is both robust to outlier and ha no such algorithmic degeneracy several cost function are explored including maximizing the consensus set and robust norm like truncated least square our method is based on parameter search in a four dimensional space using a new epipolar parametrization in principle we do an exhaustive search of parameter space but the computation are very simple and easily parallelizable resulting in an efficient method further speed ups can be obtained by restricting the domain of possible motion to for example planar motion or small rotation experimental result are given for a variety of scenario including scene with a large portion of outlier further we apply our algorithm to d motion segmentation where we outperform state of the art on the well known hopkins benchmark database 
in this paper we introduce a probabilistic approach on multiple person localization using multiple calibrated camera view people present in the scene are approximated by a population of cylinder object in the d world coordinate system which is a realization of a marked point process the observation model is based on the projection of the pixel of the obtained motion mask in the different camera image to the ground plane and to other parallel plane with different height the proposed pixel level feature is based on physical property of the d image formation process and can accurately localize the leg position on the ground plane and estimate the height of the people even if the area of interest is only a part of the scene meanwhile silhouette from irrelevant outside motion may significantly overlap with the monitored region in some of the camera view we introduce an energy function which contains a data term calculated from the extracted feature and a geometrical constraint term modeling the distance between two people the final configuration result location and height are obtained by an iterative stochastic energy optimization process called the multiple birth and death dynamic the proposed approached is compared to a recent state of the art technique in a publicly available dataset and it advantage are quantitatively demonstrated 
we propose a novel nonlinear probabilistic and variational method for adding shape information to level set based segmentation and tracking unlike previous work we represent shape with elliptic fourier descriptor and learn their lower dimensional latent space using gaussian process latent variable model segmentation is done by a nonlinear minimisation of an image driven energy function in the learned latent space we combine it with a d pose recovery stage yielding a single one shot optimisation of both shape and pose we demonstrate the performance of our method both qualitatively and quantitatively with multiple image video sequence and latent space capturing both shape kinematics and object class variance 
this paper deal with generalized procrustes analysis this is the problem of registering a set of shape data by estimating a reference shape and a set of rigid transformation given point correspondence the transformed shape data must align with the reference shape a best possible this is a difficult problem the classical approach computes alternatively the reference shape usually a the average of the transformed shape and each transformation in turn we propose a global approach to generalized procrustes analysis for twoand three dimensional shape it us modern convex optimization based on the theory of sum of square function we show how to convert the whole procrustes problem including missing data into a semidefinite program our approach is statistically grounded it find the maximum likelihood estimate we provide result on synthetic and real datasets compared to classical alternation our algorithm obtains lower error the discrepancy is very high when similarity are estimated or when the shape data have significant deformation 
the recognition of text in everyday scene is made difficult by viewing condition unusual font and lack of linguistic context most method integrate a priori appearance information and some sort of hard or soft constraint on the allowable string weinman and learned miller showed that the similarity among character a a supplement to the appearance of the character with respect to a model could be used to improve scene text recognition in this work we make further improvement to scene text recognition by taking a novel approach to the incorporation of similarity in particular we train a similarity expert that learns to classify each pair of character a equivalent or not after removing logical inconsistency in an equivalence graph we formulate the search for the maximum likelihood interpretation of a sign a an integer program we incorporate the equivalence information a constraint in the integer program and build an optimization criterion out of appearance feature and character bigram finally we take the optimal solution from the integer program and compare all nearby solution using a probability model for string derived from search engine query we demonstrate word error reduction of more than relative to previous method on the same data set 
color is known to be highly discriminative for many object recognition task but is difficult to infer from uncontrolled image in which the illuminant is not known traditional method for color constancy can improve surface reflectance estimate from such uncalibrated image but their output depends significantly on the background scene in many recognition and retrieval application we have access to image set that contain multiple view of the same object in different environment we show in this paper that correspondence between these image provide important constraint that can improve color constancy we introduce the multi view color constancy problem and present a method to recover estimate of underlying surface reflectance based on joint estimation of these surface property and the illuminant present in multiple image the method can exploit image correspondence obtained by various alignment technique and we show example based on matching local region feature our result show that multi view constraint can significantly improve estimate of both scene illuminant and object color surface reflectance when compared to a baseline single view method 
in real world application what you saw during training is often not what you get during deployment the distribution and even the type and dimensionality of feature can change from one dataset to the next in this paper we address the problem of visual domain adaptation for transferring object model from one dataset or visual domain to another we introduce arc t a flexible model for supervised learning of non linear transformation between domain our method is based on a novel theoretical result demonstrating that such transformation can be learned in kernel space unlike existing work our model is not restricted to symmetric transformation nor to feature of the same type and dimensionality making it applicable to a significantly wider set of adaptation scenario than previous method furthermore the method can be applied to category that were not available during training we demonstrate the ability of our method to adapt object recognition model under a variety of situation such a differing imaging condition feature type and codebooks 
this paper extends classical object pose and relative camera motion estimation algorithm for imaging sensor sampling the scene through light path many algorithm in multi view geometry assume that every pixel observes light traveling in a single line in space we wish to relax this assumption and address various theoretical and practical issue in modeling camera ray a piece wise linear path such path consisting of finitely many linear segment are typical of any simple camera configuration with reflective and refractive element our main contribution is to propose efficient algorithm that can work with the complete light path without knowing the correspondence between their individual segment and the scene point second we investigate light path containing infinitely many and small piece wise linear segment that can be modeled using simple parametric curve such a conic we show compelling simulation and real experiment involving catadioptric configuration and mirage to validate our study 
we propose in this work a patch based segmentation method relying on a label propagation framework based on image intensity similarity between the input image and a learning dataset an original strategy which doe not require any non rigid registration is presented following recent development in non local image denoising the similarity between image is represented by a weighted graph computed from intensity based distance between patch experiment on simulated and in vivo mr image show that the proposed method is very successful in providing automated human brain labeling 
the most popular way to use probabilistic model in vision is first to extract some descriptor of small image patch or object part using well engineered feature and then to use statistical learning tool to model the dependency among these feature and eventual label learning probabilistic model directly on the raw pixel value ha proved to be much more difficult and is typically only used for regularizing discriminative method in this work we use one of the best pixel level generative model of natural image a gated mrf a the lowest level of a deep belief network dbn that ha several hidden layer we show that the resulting dbn is very good at coping with occlusion when predicting expression category from face image and it can produce feature that perform comparably to sift descriptor for discriminating different type of scene the generative ability of the model also make it easy to see what information is captured and what is lost at each level of representation 
analysis of gene expression pattern in brain image obtained from high throughput in situ hybridization requires accurate and consistent annotation of anatomical region subregions such annotation are obtained by mapping an anatomical atlas onto the gene expression image through intensityand or landmark based registration method or deformable model based segmentation method due to the complex appearance of the gene expression image these approach require a pre processing step to determine landmark correspondence in order to incorporate landmark based geometric constraint in this paper we propose a novel method for landmark constrained intensity based registration without determining landmark correspondence a priori the proposed method performs dense image registration and identifies the landmark correspondence simultaneously using a single higher order markov random field model in addition a machine learning technique is used to improve the discriminating property of local descriptor for landmark matching by projecting them in a hamming space of lower dimension we qualitatively show that our method achieves promising result and also compare well quantitatively with the expert s annotation outperforming previous method 
we develop a dictionary learning method which is i online ii enables overlapping group structure with iii non convex sparsity inducing regularization and iv handle the partially observable case structured sparsity and the related group norm have recently gained widespread attention in group sparsity regularized problem in the case when the dictionary is assumed to be known and fixed however when the dictionary also need to be learned the problem is much more difficult only a few method have been proposed to solve this problem and they can handle two of these four desirable property at most to the best of our knowledge our proposed method is the first one that posse all of these property we investigate several interesting special case of our framework such a the online structured sparse non negative matrix factorization and demonstrate the efficiency of our algorithm with several numerical experiment 
in this paper we introduce visual phrase complex visual composite like a person riding a horse visual phrase often display significantly reduced visual complexity compared to their component object because the appearance of those object can change profoundly when they participate in relation we introduce a dataset suitable for phrasal recognition that us familiar pascal object category and demonstrate significant experimental gain resulting from exploiting visual phrase we show that a visual phrase detector significantly outperforms a baseline which detects component object and reason about relation even though visual phrase training set tend to be smaller than those for object we argue that any multi class detection system must decode detector output to produce final result this is usually done with non maximum suppression we describe a novel decoding procedure that can account accurately for local context without solving difficult inference problem we show this decoding procedure outperforms the state of the art finally we show that decoding a combination of phrasal and object detector produce real improvement in detector result 
handshape is a key linguistic component of sign and thus handshape recognition is essential to algorithm for sign language recognition and retrieval in this work linguistic constraint on the relationship between start and end handshapes are leveraged to improve handshape recognition accuracy a bayesian network formulation is proposed for learning and exploiting these constraint while taking into consideration inter signer variation in the production of particular handshapes a variational bayes formulation is employed for supervised learning of the model parameter a non rigid image alignment algorithm which yield improved robustness to variability in handshape appearance is proposed for computing image observation likelihood in the model the resulting handshape inference algorithm is evaluated using a dataset of lexical sign in american sign language asl where each lexical sign is produced by three native asl signer 
we present a hierarchical classification model that allows rare object to borrow statistical strength from related object that have many training example unlike many of the existing object detection and recognition system that treat different class a unrelated entity our model learns both a hierarchy for sharing visual appearance across object category and hierarchical parameter our experimental result on the challenging object localization and detection task demonstrate that the proposed model substantially improves the accuracy of the standard single object detector that ignore hierarchical structure altogether 
following the success of hashing method for multidimensional indexing more and more work are interested in embedding visual feature space in compact hash code such approach are not an alternative to using index structure but a complementary way to reduce both the memory usage and the distance computation cost several data dependent hash function have notably been proposed to closely fit data distribution and provide better selectivity than usual random projection such a lsh however improvement occur only for relatively small hash code size up to or bit a discussed in the paper this is mainly due to the lack of independence between the produced hash function we introduce a new hash function family that attempt to solve this issue in any kernel space rather than boosting the collision probability of close point our method focus on data scattering by training purely random split of the data regardless the closeness of the training sample it is indeed possible to generate consistently more independent hash function on the other side the use of large margin classifier allows to maintain good generalization performance experiment show that our new random maximum margin hashing scheme rmmh outperforms four state of the art hashing method notably in kernel space 
this paper present an integrated solution for the problem of detecting tracking and identifying vehicle in a tunnel surveillance application taking into account practical constraint including realtime operation poor imaging condition and a decentralized architecture vehicle are followed through the tunnel by a network of non overlapping camera they are detected and tracked in each camera and then identified i e matched to any of the vehicle detected in the previous camera s to limit the computational load we propose to reuse the same set of haar feature for each of these step for the detection we use an adaboost cascade here we introduce a composite confidence score integrating information from all stage of the cascade a subset of the feature used for detection is then selected optimizing for the identification problem this result in a compact binary vehicle fingerprint requiring very limited bandwidth finally we show that the same set of feature can also be used for tracking this haar feature based tracking by identification yield surprisingly good result on standard datasets without the need to update the model online 
nearly every structured prediction problem in computer vision requires approximate inference due to large and complex dependency among output label while graphical model provide a clean separation between modeling and inference learning these model with approximate inference is not well understood furthermore even if a good model is learned prediction are often inaccurate due to approximation in this work instead of performing inference over a graphical model we instead consider the inference procedure a a composition of predictor specifically we focus on message passing algorithm such a belief propagation and show how they can be viewed a procedure that sequentially predict label distribution at each node over a graph given labeled graph we can then train the sequence of predictor to output the correct labeling s the result no longer corresponds to a graphical model but simply defines an inference procedure with strong theoretical property that can be used to classify new graph we demonstrate the scalability and efficacy of our approach on d point cloud classification and d surface estimation from single image 
when glancing at a magazine or browsing the internet we are continuously being exposed to photograph despite of this overflow of visual information human are extremely good at remembering thousand of picture along with some of their visual detail but not all image are equal in memory some stitch to our mind and other are forgotten in this paper we focus on the problem of predicting how memorable an image will be we show that memorability is a stable property of an image that is shared across different viewer we introduce a database for which we have measured the probability that each picture will be remembered after a single view we analyze image feature and label that contribute to making an image memorable and we train a predictor based on global image descriptor we find that predicting image memorability is a task that can be addressed with current computer vision technique whereas making memorable image is a challenging task in visualization and photography this work is a first attempt to quantify this useful quality of image 
we characterize a class of video consisting of very small but potentially complicated motion we find that in these scene linear appearance variation have a direct relationship to scene motion we show how to interpret appearance variation captured through a pca decomposition of the image set a a scene specific non parametric motion basis we propose fast robust tool for dense flow estimate that are effective in scene with small motion and potentially large image noise we show example result in a variety of application including motion segmentation and long term point tracking 
in recent object scene recognition research image or large image region are often represented a disorganized bag of image feature this representation allows direct application of model of word count in text however the image feature count are likely to be constrained in different way than word count in text a a camera pan upwards from a building entrance over it first few floor and then above the penthouse to the backdrop formed by the mountain and then further up into the sky some feature count in the image drop while others rise only to drop again giving way to feature found more often at higher elevation fig the space of all possible feature count combination is constrained by the property of the larger scene a well a the size and the location of the window into it accordingly our model is based on a grid of feature count considerably larger than any of the modeled image and considerably smaller than the real estate needed to tile the image next to each other tightly each modeled image is assumed to have a representative window in the grid in which the sum of feature count mimic the distribution in the image we provide learning procedure that jointly map all image in the training set to the counting grid and estimate the appropriate local count in it experimentally we demonstrate that the resulting representation capture the space of feature count combination more accurately than the traditional model such a latent dirichlet allocation even when modeling image of different scene from the same category 
we propose a top down approach for understanding indoor scene such a bedroom and living room these environment typically have the manhattan world property that many surface are parallel to three principle one further the d geometry of the room and object within it can largely be approximated by non overlapping simple structure such a single block e g the room boundary thin block e g picture frame and object that are well modeled by single block e g simple bed we separately model the d geometry the imaging process camera parameter and edge likelihood to provide a generative statistical model for image data we fit this model using data driven mcmc sampling we combine reversible jump metropolis hastings sample for discrete change in the model such a the number of block and stochastic dynamic to estimate continuous parameter value in a particular parameter space that includes block position block size and camera parameter we tested our approach on two datasets using room box pixel orientation despite using only bounding box geometry and in particular not training on appearance our method achieves result approaching those of others we also introduce a new evaluation method for this domain based on ground truth camera parameter which we found to be more sensitive to the task of understanding scene geometry 
we analyse the potential of gibbs random field for shape prior modelling we show that the expressive power of second order grfs is already sufficient to express spatial relation between shape part and simple shape simultaneously this allows to model and recognise complex shape a spatial composition of simpler part 
in this paper the problem of pairwise model to scene point set registration is considered three contribution are made firstly the relation between correspondence based and some information theoretic point cloud registration algorithm are formalized starting from the observation that the outlier handling of existing method relies on heuristically determined model a second contribution is made exploiting aforementioned relation to derive a new robust point set registration algorithm representing model and scene point cloud by mixture of gaus sian the method minimizes their kullback leibler divergence both w r t the registration transformation parameter and w r t the scene s mixture coefficient this result in an expectation maximization iterative closest point em icp approach with a parameter free outlier model that is optimal in information theoretical sense while the current cuda implementation is limited to the rigid registration case the underlying theory applies to both rigid and non rigid point set registration a a by product of the registration algorithm s theory a third contribution is made by suggesting a new point cloud kernel density estimation approach which relies on maximizing the resulting distribution s entropy w r t the kernel weight the rigid registration algorithm is applied to align different patch of the publicly available stanford dragon and stanford happy budha range data the result show good performance regarding accuracy robustness and convergence range 
the problem of finding one dimensional structure in image and video can be formulated a a problem of searching for cycle in graph in an untangling cycle cost function wa proposed for identifying persistent cycle in a weighted graph corresponding to salient contour in an image we have analyzed their method and give two significant improvement first we generalize their cost function to a contour cut criterion and give a computational solution by solving a family of hermitian eigenvalue problem second we use the idea of a graph circulation which ensures that each node ha a balanced inand out flow and permit a natural random walk interpretation of our cost function we show that our method find far more accurate contour in image than furthermore we show that our method is robust to graph compression which allows u to accelerate the computation without loss of accuracy 
we address shape grammar parsing for facade segmentation using reinforcement learning rl shape parsing entail simultaneously optimizing the geometry and the topology e g number of floor of the facade so a to optimize the fit of the predicted shape with the response of pixel level terminal detector we formulate this problem in term of a hierarchical markov decision process by employing a recursive binary split grammar this allows u to use rl to efficiently find the optimal parse of a given facade in term of our shape grammar building on the rl paradigm we exploit state aggregation to speedup computation and introduce image driven exploration in rl to accelerate convergence we achieve state of the art result on facade parsing with a significant speed up compared to existing method and substantial robustness to initial condition we demonstrate that the method can also be applied to interactive segmentation and to a broad variety of architectural style 
many classifier are trained with massive training set only to be applied at test time on data from a different distribution how can we rapidly and simply adapt a classifier to a new test distribution even when we do not have access to the original training data we present an on line approach for rapidly adapting a black box classifier to a new test data set without retraining the classifier or examining the original optimization criterion assuming the original classifier output a continuous number for which a threshold give the class we reclassify point near the original boundary using a gaussian process regression scheme we show how this general procedure can be used in the context of a classifier cascade demonstrating performance that far exceeds state of the art result in face detection on a standard data set we also draw connection to work in semi supervised learning domain adaptation and information regularization 
the task of d articulated human pose estimation in natural image is extremely challenging due to the high level of variation in human appearance these variation arise from different clothing anatomy imaging condition and the large number of pose it is possible for a human body to take recent work ha shown state of the art result by partitioning the pose space and using strong nonlinear classifier such that the pose dependence and multi modal nature of body part appearance can be captured we propose to extend these method to handle much larger quantity of training data an order of magnitude larger than current datasets and show how to utilize amazon mechanical turk and a latent annotation update scheme to achieve high quality annotation at low cost we demonstrate a significant increase in pose estimation accuracy while simultaneously reducing computational expense by a factor of and contribute a dataset of highly articulated pose 
joint reasoning about object and d scene layout ha shown great promise in scene interpretation one visual cue that ha been overlooked is texture arising from a spatial repetition of object in the scene e g window of a building such texture provides scene specific constraint among object and thus facilitates scene interpretation we present an approach to detecting distinct texture of object in a scene reconstructing the d shape of detected texture surface and combining object detection and shape from texture toward a globally consistent scene interpretation inference is formulated within the reinforcement learning framework a a sequential interpretation of image region starting from confident region to guide the interpretation of other region our algorithm find an optimal policy that map state of detected object and reconstructed surface to action which ought to be taken in those state including detecting new object and identifying new texture so a to minimize a long term loss test against ground truth obtained from stereo image demonstrate that we can coarsely reconstruct a d model of the scene from a single image without learning the layout of common scene surface a done in prior work we also show that reasoning about texture of object improves object detection 
in recent year knowledge transfer algorithm have become one of most the active research area in learning visual concept most of the existing learning algorithm focus on leveraging the knowledge transfer process which is specific to a given category however in many case such a process may not be very effective when a particular target category ha very few sample in such case it is interesting to examine whether it is feasible to use cross category knowledge for improving the learning process by exploring the knowledge in correlated category such a task can be quite challenging due to variation in semantic similarity and difference between category which could either help or hinder the cross category learning process in order to address this challenge we develop a cross category label propagation algorithm which can directly propagate the inter category knowledge at instance level between the source and the target category furthermore this algorithm can automatically detect condition under which the transfer process can be detrimental to the learning process this provides u a way to know when the transfer of cross category knowledge is both useful and desirable we present experimental result on real image and video data set in order to demonstrate the effectiveness of our approach 
we propose a novel approach for ranking and retrieval of image based on multi attribute query existing image retrieval method train separate classifier for each word and heuristically combine their output for retrieving multiword query moreover these approach also ignore the interdependency among the query term in contrast we propose a principled approach for multi attribute retrieval which explicitly model the correlation that are present between the attribute given a multi attribute query we also utilize other attribute in the vocabulary which are not present in the query for ranking retrieval furthermore we integrate ranking and retrieval within the same formulation by posing them a structured prediction problem extensive experimental evaluation on the labeled face in the wild lfw facetracer and pascal voc datasets show that our approach significantly outperforms several state of the art ranking and retrieval method 
in the square jigsaw puzzle problem one is required to reconstruct the complete image from a set of non overlapping unordered square puzzle part here we propose a fully automatic solver for this problem where unlike some previous work it assumes no clue regarding part location and requires no prior knowledge about the original image or it simplified e g lower resolution version to do so we introduce a greedy solver which combine both informed piece placement and rearrangement of puzzle segment to find the final solution among our other contribution are new compatibility metric which better predict the chance of two given part to be neighbor and a novel estimation measure which evaluates the quality of puzzle solution without the need for ground truth information incorporating these contribution our approach facilitates solution that surpass state of the art solver on puzzle of size larger than ever attempted before 
in blind deconvolution one aim to estimate from an input blurred image y a sharp image x and an unknown blur kernel k recent research show that a key to success is to consider the overall shape of the posterior distribution p x ky and not only it mode this lead to a distinction between mapx k strategy which estimate the mode pair x k and often lead to undesired result and mapk strategy which select the best k while marginalizing over all possible x image the mapk principle is significantly more robust than the mapx k one yet it involves a challenging marginalization over latent image a a result mapk technique are considered complicated and have not been widely exploited this paper derives a simple approximated mapk algorithm which involves only a modest modification of common mapx k algorithm we show that mapk can in fact be optimized easily with no additional computational complexity 
global illumination effect such a inter reflection diffusion and sub surface scattering severely degrade the performance of structured light based d scanning in this paper we analyze the error caused by global illumination in structured light based shape recovery based on this analysis we design structured light pattern that are resilient to individual global illumination effect using simple logical operation and tool from combinatorial mathematics scene exhibiting multiple phenomenon are handled by combining result from a small ensemble of such pattern this combination also allows u to detect any residual error that are corrected by acquiring a few additional image our technique do not require explicit separation of the direct and global component of scene radiance and hence work even in scenario where the separation fails or the direct component is too low our method can be readily incorporated into existing scanning system without significant overhead in term of capture time or hardware we show result on a variety of scene with complex shape and material property and challenging global illumination effect 
without specialized sensor technology or custom multi chip camera high dynamic range imaging typically involves time sequential capture of multiple photograph the obvious downside to this approach is that it cannot easily be applied to image with moving object especially if the motion are complex in this paper we take a novel view of hdr capture which is based on a computational photography approach we propose to first optically encode both the low dynamic range portion of the scene and highlight information into a low dynamic range image that can be captured with a conventional image sensor this step is achieved using a cross screen or star filter second we decode in software both the low dynamic range image and the highlight information lastly these two portion can be combined to form an image of a higher dynamic range than the regular sensor dynamic range 
we propose a new method to quickly and accurately predict d position of body joint from a single depth image using no temporal information we take an object recognition approach designing an intermediate body part representation that map the difficult pose estimation problem into a simpler per pixel classification problem our large and highly varied training dataset allows the classifier to estimate body part invariant to pose body shape clothing etc finally we generate confidence scored d proposal of several body joint by reprojecting the classification result and finding local mode the system run at frame per second on consumer hardware our evaluation show high accuracy on both synthetic and real test set and investigates the effect of several training parameter we achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole skeleton nearest neighbor matching 
many object class are primarily defined by their function however this fact ha been left largely unexploited by visual object categorization or detection system we propose a method to learn an affordance detector it identifies location in the d space which support the particular function our novel approach imago an actor performing an action typical for the target object class instead of relying purely on the visual object appearance so function is handled a a cue complementary to appearance rather than being a consideration after appearance based detection experimental result are given for the functional category sitting such affordance is tested on a d representation of the scene a can be realistically obtained through sfm or depth camera in contrast to appearance based object detector affordance detection requires only very few training example and generalizes very well to other sittable object like bench or sofa when trained on a few chair 
achieving computer vision on micro scale device is a challenge on these platform the power and mass constraint are severe enough for even the most common computation matrix manipulation convolution etc to be difficult this paper proposes and analyzes a class of miniature vision sensor that can help overcome these constraint these sensor reduce power requirement through template based optical convolution and they enable a wide field of view within a small form through a novel optical design we describe the trade offs between the field of view volume and mass of these sensor and we provide analytic tool to navigate the design space we also demonstrate milli scale prototype for computer vision task such a locating edge tracking target and detecting face 
this paper proposes a novel approach to optimally solve volumetric registration problem the proposed framework exploit parametric dictionary for sparse volumetric representation dissimilarity and dc difference of convex function decomposition the sad sum of absolute difference criterion is applied to the sparse representation of the reference volume and a dc decomposition of this criterion with respect to the transformation parameter is derived this permit to employ a cutting plane algorithm for determining the optimal relative transformation parameter of the query volume it further provides a guarantee for the global optimality of the obtained solution which to the best of our knowledge is not offered by any other existing approach a numerical validation demonstrates the effectiveness and the large potential of the proposed method 
we propose to align the orientation of local feature descriptor with the gravitational force measured with inertial sensor in contrast to standard approach that gain a reproducible feature orientation from the intensity of neighboring pixel to remain invariant against rotation this approach result in clearly distinguishable descriptor for congruent feature in different orientation gravity aligned feature descriptor gafd are suitable for any application relying on corresponding point in multiple image of static scene and are particularly beneficial in the presence of differently oriented repetitive feature a they are widespread in urban scene and on man made object in this paper we show with different example that the process of feature description and matching get both faster and result in better match when aligning the descriptor with the gravity compared to traditional technique 
this paper present a novel way to perform multi modal face recognition we use partial least square pls to linearly map image in different modality to a common linear subspace in which they are highly correlated pls ha been previously used effectively for feature selection in face recognition we show both theoretically and experimentally that pls can be used effectively across modality we also formulate a generic intermediate subspace comparison framework for multi modal recognition surprisingly we achieve high performance using only pixel intensity a feature we experimentally demonstrate the highest published recognition rate on the pose variation in the pie data set and also show that pls can be used to compare sketch to photo and to compare image taken at different resolution 
datasets are an integral part of contemporary object recognition research they have been the chief reason for the considerable progress in the field not just a source of large amount of training data but also a mean of measuring and comparing performance of competing algorithm at the same time datasets have often been blamed for narrowing the focus of object recognition research reducing it to a single benchmark performance number indeed some datasets that started out a data capture effort aimed at representing the visual world have become closed world unto themselves e g the corel world the caltech world the pascal voc world with the focus on beating the latest benchmark number on the latest dataset have we perhaps lost sight of the original purpose the goal of this paper is to take stock of the current state of recognition datasets we present a comparison study using a set of popular datasets evaluated based on a number of criterion including relative data bias cross dataset generalization effect of closed world assumption and sample value the experimental result some rather surprising suggest direction that can improve dataset collection a well a algorithm evaluation protocol but more broadly the hope is to stimulate discussion in the community regarding this very important but largely neglected issue 
we propose a detection free system for segmenting multiple interacting and deforming people in a video people detector often fail under close agent interaction limiting the performance of detection based tracking method motion information often fails to separate similarly moving agent or to group distinctly moving articulated body part we formulate video segmentation a graph partitioning in the trajectory domain we classify trajectory a foreground or background based on trajectory saliency and use foreground trajectory a graph node we incorporate object connectedness constraint into our trajectory weight matrix based on topology of foreground we set repulsive weight between trajectory that belong to different connected component in any frame of their time intersection attractive weight are set between similarly moving trajectory information from foreground topology complement motion information and our spatiotemporal segment can be interpreted a connected moving entity rather than just trajectory group of similar motion all our cue are computed on trajectory and naturally encode large temporal context which is crucial for resolving local in time ambiguity we present result of our approach on challenging datasets outperforming by far the state of the art 
we consider the problem of fitting one or more subspace to a collection of data point drawn from the subspace and corrupted by noise outlier we pose this problem a a rank minimization problem where the goal is to decompose the corrupted data matrix a the sum of a clean self expressive low rank dictionary plus a matrix of noise outlier our key contribution is to show that for noisy data this non convex problem can be solved very efficiently and in closed form from the svd of the noisy data matrix remarkably this is true for both one or more subspace an important difference with respect to existing method is that our framework result in a polynomial thresholding of the singular value with minimal shrinkage indeed a particular case of our framework in the case of a single subspace lead to classical pca which requires no shrinkage in the case of multiple subspace our framework provides an affinity matrix that can be used to cluster the data according to the sub space in the case of data corrupted by outlier a closed form solution appears elusive we thus use an augmented lagrangian optimization framework which requires a combination of our proposed polynomial thresholding operator with the more traditional shrinkage thresholding operator 
spatial super resolution sr aim to recover fine image detail smaller than a pixel size temporal sr aim to recover rapid dynamic event that occur faster than the video frame rate and are therefore invisible or seen incorrectly in the video sequence previous method for space time sr combined information from multiple video recording of the same dynamic scene in this paper we show how this can be done from a single video recording our approach is based on the observation that small space time patch st patch e g of a single natural video recur many time inside the same video sequence at multiple spatio temporal scale we statistically explore the degree of these st patch recurrence inside natural video and show that this is a very strong statistical phenomenon space time sr is obtained by combining information from multiple st patch at sub frame accuracy we show how finding similar st patch can be done both efficiently with a randomized based search in space time and at sub frame accuracy despite severe motion aliasing our approach is particularly useful for temporal sr resolving both severe motion aliasing and severe motion blur in complex natural video 
the deformable part based model dpm proposed by felzenszwalb et al ha demonstrated state of the art result in object localization the model offer a high degree of learnt invariance by utilizing viewpoint dependent mixture component and movable part in each mixture component one might hope to increase the accuracy of the dpm by increasing the number of mixture component and part to give a more faithful model but limited training data prevents this from being effective we propose an extension to the dpm which allows for sharing of object part model among multiple mixture component a well a object class this result in more compact model and allows training example to be shared by multiple component ameliorating the effect of a limited size training set we i reformulate the dpm to incorporate part sharing and ii propose a novel energy function allowing for coupled training of mixture component and object class we report state of the art result on the pascal voc dataset 
motion can occur over both short and long time scale we introduce motion denoising which treat short term change a noise long term change a signal and re render a video to reveal the underlying long term event we demonstrate motion denoising for time lapse video one of the characteristic of traditional time lapse imagery is stylized jerkiness where short term change in the scene appear a small and annoying jitter in the video often obfuscating the underlying temporal event of interest we apply motion denoising for resynthesizing time lapse video showing the long term evolution of a scene with jerky short term change removed we show that existing filtering approach are often incapable of achieving this task and present a novel computational approach to denoise motion without explicit motion analysis we demonstrate promising experimental result on a set of challenging time lapse sequence 
this paper present model and algorithm for estimating the shape of a mirrored surface from a single image of that surface rendered under an unknown natural illumination while the unconstrained nature of this problem seems to make shape recovery impossible the curvature of the surface cause characteristic image pattern to appear these image pattern can be used to estimate how the surface curve in different direction we show how these estimate can be used to produce constraint that can be used to estimate the shape of the surface this approach is demonstrated on simple surface rendered under both natural and synthetic illumination 
in this work we propose a contour and region detector for video data that exploit motion cue and distinguishes occlusion boundary from internal boundary based on optical flow this detector outperforms the state of the art on the benchmark of stein and hebert improving average precision from to moreover the optical flow on and near occlusion boundary allows u to assign a depth ordering to the adjacent region to evaluate performance on this edge based figure ground labeling task we introduce a new video dataset that we believe will support further research in the field by allowing quantitative comparison of computational model for occlusion boundary detection depth ordering and segmentation in video sequence 
in this paper we reformulate the d reconstruction of deformable surface from monocular video sequence a a labeling problem we solve simultaneously for the assignment of feature point to multiple local deformation model and the fitting of model to point to minimize a geometric cost subject to a spatial constraint that neighboring point should also belong to the same model piecewise reconstruction method rely on feature shared between model to enforce global consistency on the d surface to account for this overlap between region we consider a super set of the classic labeling problem in which a set of label instead of a single one is assigned to each variable we propose a mathematical formulation of this new model and show how it can be efficiently optimized with a variant of expansion we demonstrate how this framework can be applied to non rigid structure from motion and lead to simpler explanation of the same data compared to existing method run on the same data our approach ha up to half the reconstruction error and is more robust to over fitting and outlier 
we propose structured model for image labeling that take into account the dependency among the image label explicitly these model are more expressive than independent label predictor and lead to more accurate prediction while the improvement is modest for fully automatic image labeling the gain is significant in an interactive scenario where a user provides the value of some of the image label such an interactive scenario offer an interesting trade off between accuracy and manual labeling effort the structured model are used to decide which label should be set by the user and transfer the user input to more accurate prediction on other image label we also apply our model to attribute based image classification where attribute prediction of a test image are mapped to class probability by mean of a given attribute class mapping in this case the structured model are built at the attribute level we also consider an interactive system where the system asks a user to set some of the attribute value in order to maximally improve class prediction performance experimental result on three publicly available benchmark data set show that in all scenario our structured model lead to more accurate prediction and leverage user input much more effectively than state of the art independent model 
we propose a novel method for predicting whether an image taken from a given location will match an existing set of image this problem appears prominently in image based localization and augmented reality application where new image are matched to an existing set to determine location or add virtual information into a scene our process generates a spatial coverage map showing the confidence that image taken at specific location will match an existing image set a new way to measure distortion between image using affine model is introduced the distortion measure is combined with existing machine learning and structure from motion technique to create a matching confidence predictor the predictor is used to generate the spatial coverage map and also compute which image in the original set are redundant and can be removed result are presented showing the predictor is more accurate than previously published approach 
local classifier have obtained great success in classification task due to it powerful discriminating ability on local region however most of them still have restricted generalization in twofold each local classifier is sensitive to noise in local region which lead to overfitting phenomenon in local classifier the local classifier also ignore the local correlation determined by the sample distribution in each local region to overcome the above two problem we present a novel locality sensitive support vector machine lssvm in this paper for image retrieval problem this classifier applies locality sensitive hashing lsh to divide the whole feature space into a number of local region on each of them a local model can be better constructed due to smaller within class variation on it to avoid these local model from overfitting into locality sensitive structure it imposes a global regularizer across local region so that local classifier are smoothly glued together to form a regularized overall classifier local correlation is modeled to capture the sample distribution that determines the locality structure of each local region which can increase the discriminating ability of the algorithm to evaluate the performance we apply the proposed algorithm into image retrieval task and competitive result are obtained on the real world web image data set 
we present a framework for the automatic recognition of complex multi agent event in setting where structure is imposed by rule that agent must follow while performing activity given semantic spatio temporal description of what generally happens i e rule event description physical constraint and based on video analysis we determine the event that occurred knowledge about spatio temporal structure is encoded using first order logic using an approach based on allen s interval logic and robustness to low level observation uncertainty is provided by markov logic network mln our main contribution is that we integrate interval based temporal reasoning with probabilistic logical inference relying on an efficient bottom up grounding scheme to avoid combinatorial explosion applied to one on one basketball our framework detects and track player their hand and foot and the ball generates event observation from the resulting trajectory and performs probabilistic logical inference to determine the most consistent sequence of event we demonstrate our approach on hr frame of outdoor video 
the realization that we see line known to be parallel in space a line that appear to converge in a corresponding vanishing point ha led to technique employed by artist since at least the renaissance to render a credible impression of perspective more recently it ha also led to technique for recovering information embedded in image pertaining to the geometry of their underlying scene in this paper we explore the extraction of vanishing point in the aim of facilitating the reconstruction of manhattan world scene in departure from most vanishing point extraction method ours extract a constellation of vanishing point corresponding respectively to the scene s two or three dominant pairwise orthogonal orientation by integrating information across multiple view rather than from a single image alone what make a multiple view approach attractive is that in addition to increasing robustness to segment that do not correspond to any of the three dominant orientation robustness is also increased with respect to inaccuracy in the extracted segment themselves 
statistic of natural image provides useful prior for solving under constrained problem in computer vision such statistic is usually obtained from large collection of natural image we claim that the substantial internal data redundancy within a single natural image e g recurrence of small image patch give rise to powerful internal statistic obtained directly from the image itself while internal patch recurrence ha been used in various application we provide a parametric quantification of this property we show that the likelihood of an image patch to recur at another image location can be expressed parametricly a a function of the spatial distance from the patch and it gradient content this internal parametric prior is used to improve existing algorithm that rely on patch recurrence moreover we show that internal image specific statistic is often more powerful than general external statistic giving rise to more powerful image specific prior in particular i patch tend to recur much more frequently densely inside the same image than in any random external collection of natural image ii to find an equally good external representative patch for all the patch of an image requires an external database of hundred of natural image iii internal statistic often ha stronger predictive power than external statistic indicating that it may potentially give rise to more powerful image specific prior 
portable high quality sport camera e g head or helmet mounted built for recording dynamic first person video footage are becoming a common item among many sport enthusiast we address the novel task of discovering first person action category which we call ego action which can be useful for such task a video indexing and retrieval in order to learn ego action category we investigate the use of motion based histogram and unsupervised learning algorithm to quickly cluster video content our approach assumes a completely unsupervised scenario where labeled training video are not available video are not pre segmented and the number of ego action category are unknown in our proposed framework we show that a stacked dirichlet process mixture model can be used to automatically learn a motion histogram codebook and the set of ego action category we quantitatively evaluate our approach on both in house and public youtube video and demonstrate robust ego action categorization across several sport genre comparative analysis show that our approach outperforms other state of the art topic model with respect to both classification accuracy and computational speed preliminary result indicate that on average the categorical content of a minute video sequence can be indexed in under second 
this paper proposes a new template matching method that is robust to outlier and fast enough for real time operation the template and image are densely transformed in binary code form by projecting and quantizing histogram of oriented gradient the binary code are matched by a generic method of robust similarity applicable to additive match measure such a lpand hamming distance the robust similarity map is computed efficiently via a proposed inverted location index structure that store pixel location indexed by their value the method is experimentally justified in large image patch datasets challenging application such a intra category object detection object tracking and multimodal image matching are demonstrated 
our primary interest is in generalizing the problem of cosegmentation to a large group of image that is concurrent segmentation of common foreground region s from multiple image we further wish for our algorithm to offer scale invariance foreground may have arbitrary size in different image and the running time to increase no more than near linearly in the number of image in the set what make this setting particularly challenging is that even if we ignore the scale invariance desideratum the cosegmentation problem a formalized in many recent paper except is already hard to solve optimally in the two image case a straightforward extension of such model to multiple image lead to loose relaxation and unless we impose a distributional assumption on the appearance model existing mechanism for image pair wise measurement of foreground appearance variation lead to significantly large problem size even for moderate number of image this paper present a surprisingly easy to implement algorithm which performs well and satisfies all requirement listed above scale invariance low computational requirement and viability for the multiple image setting we present qualitative and technical analysis of the property of this framework 
this paper present three new method for regularizing the least square solution of the reconstruction of a surface from it gradient field firstly the spectral regularization based on discrete generalized fourier series e g gram polynomial haar function etc secondly the tikhonov regularization applied directly to the d domain problem and thirdly the regularization via constraint such a arbitrary dirichlet boundary condition it is shown that the solution to the aforementioned problem all satisfy sylvester equation which lead to substantial computational gain specifically the solution of the sylvester equation is direct non iterative and for an m n surface is of the same complexity a computing an svd of the same size i e an o n algorithm in contrast state of the art algorithm are based on large scale linear solver and use iterative technique based on an o n linear sub step to emphasize this improvement it is demonstrated that the new algorithm are upwards of ten thousand time faster than the state of the art technique incorporating regularization in fact the new algorithm allow for the realtime regularized reconstruction of surface on the order of megapixels which is unprecedented for this computer vision problem 
one of the challenge in radiotherapy of moving tumor is to determine the location of the tumor accurately existing solution to the problem are either invasive or inaccurate we introduce a non invasive solution to the problem by tracking the tumor in d using bi plane ultrasound image sequence we present crosstrack a novel tracking algorithm in this framework we pose the problem a recursive inference of d location and tumor boundary segmentation in the two ultrasound view using the tumor d model a a prior for the segmentation task a robust graph based approach is deployed a follows first robust segmentation prior are obtained through the tumor d model second a unified graph combining information across time and multiple view is constructed with a robust weighting function for the tracking task an effective mechanism for recovery from respiration induced occlusion is introduced our experiment show the robustness of crosstrack in handling challenging tumor shape and disappearance scenario with sub voxel accuracy and almost precision and recall significantly outperforming baseline solution 
active learning and crowdsourcing are promising way to efficiently build up training set for object recognition but thus far technique are tested in artificially controlled setting typically the vision researcher ha already determined the dataset s scope the label actively obtained are in fact already known and or the crowd sourced collection process is iteratively fine tuned we present an approach for live learning of object detector in which the system autonomously refines it model by actively requesting crowd sourced annotation on image crawled from the web to address the technical issue such a large scale system entail we introduce a novel part based detector amenable to linear classifier and show how to identify it most uncertain instance in sub linear time with a hashing based solution we demonstrate the approach with experiment of unprecedented scale and autonomy and show it successfully improves the state of the art for the most challenging object in the pascal benchmark in addition we show our detector competes well with popular nonlinear classifier that are much more expensive to train 
face recognition is a challenging problem complicated by variation in pose expression lighting and the passage of time significant work ha been done to solve each of these problem separately we consider the problem of lighting and expression variation together proposing a method that account for both variability within a single model we present a novel deformation and lighting insensitive metric to compare image and we present a novel framework to optimize over this metric to calculate dense correspondence between image typical correspondence cost pattern are learned between face image pair and a nai ve bayes classifier is applied to improve recognition accuracy very promising result are presented on the ar face database and we note that our method can be extended to a broad set of application 
we present a novel probabilistic framework for rigid tracking and segmentation of shape observed from multiple camera most existing method have focused on solving each of these problem individually segmenting the shape assuming surface registration is solved or conversely performing surface registration assuming shape segmentation or kinematic structure is known we assume no prior kinematic or registration knowledge except for an over estimate k of the number of rigidity in the scene instead proposing to simultaneously discover adapt and track it rigid structure on the fly we simultaneously segment and infer pose of rigid subcomponents of a single chosen reference mesh acquired in the sequence we show that this problem can be rigorously cast a a likelihood maximization over rigid component parameter we solve this problem using an expectation maximization algorithm with latent observation assignment to reference vertex and rigid part our experiment on synthetic and real data show the validity of the method robustness to noise and it promising applicability to complex sequence 
scalability of object detector with respect to the number of class is a very important issue for application where many object class need to be detected while combining single class detector yield a linear complexity for testing multi class detector that localize all object at once come often at the cost of a reduced detection accuracy in this work we present a scalable multi class detection algorithm which scale sublinearly with the number of class without compromising accuracy to this end a shared discriminative codebook of feature appearance is jointly trained for all class and detection is also performed for all class jointly based on the learned sharing distribution of feature among class we build a taxonomy of object class the taxonomy is then exploited to further reduce the cost of multi class object detection our method ha linear training and sublinear detection complexity in the number of class we have evaluated our method on the challenging pascal voc and pascal voc datasets and show that scaling the system doe not lead to a loss in accuracy 
hyperspectral imaging is a promising tool for application in geosensing cultural heritage and beyond however compared to current rgb camera existing hyperspectral camera are severely limited in spatial resolution in this paper we introduce a simple new technique for reconstructing a very high resolution hyperspectral image from two readily obtained measurement a lower resolution hyper spectral image and a high resolution rgb image our approach is divided into two stage we first apply an unmixing algorithm to the hyperspectral input to estimate a basis representing reflectance spectrum we then use this representation in conjunction with the rgb input to produce the desired result our approach to unmixing is motivated by the spatial sparsity of the hyperspectral input and cast the unmixing problem a the search for a factorization of the input into a basis and a set of maximally sparse coefficient experiment show that this simple approach performs reasonably well on both simulation and real data example 
d shape matching is an important problem in computer vision one of the major difficulty in finding dense correspondence between d shape is related to the topological discrepancy that often arise due to complex kinematic motion in this paper we propose a shape matching method that is robust to such change in topology the algorithm start from a sparse set of seed match and output dense matching we propose to use a shape descriptor based on property of the heat kernel and which provides an intrinsic scale space representation this descriptor incorporates i heat flow from already matched point and ii self diffusion at small scale the descriptor behaves locally and hence it is robust to global change in topology therefore it can be used to build a vertex to vertex matching score conditioned by an initial correspondence set this score is then used to iteratively add new correspondence based on a novel seed growing method that iteratively propagates the seed correspondence to nearby vertex the matching is farther densified via an em like method that explores the congruency between the two shape embeddings our method is compared with two recently proposed algorithm and we show that we can deal with substantial topological difference between the two shape 
human nameable visual attribute offer many advantage when used a mid level feature for object recognition but existing technique to gather relevant attribute can be inefficient costing substantial effort or expertise and or insufficient descriptive property need not be discriminative we introduce an approach to define a vocabulary of attribute that is both human understandable and discriminative the system take object scene labeled image a input and return a output a set of attribute elicited from human annotator that distinguish the category of interest to ensure a compact vocabulary and efficient use of annotator effort we show how to actively augment the vocabulary such that new attribute resolve inter class confusion and propose a novel nameability manifold that prioritizes candidate attribute by their likelihood of being associated with a nameable property we demonstrate the approach with multiple datasets and show it clear advantage over baseline that lack a nameability model or rely on a list of expert provided attribute 
this paper present an algorithm for order reduction of factor in high order markov random field homrfs standard technique for transforming arbitrary high order factor into pairwise one have been known for a long time in this work we take a fresh look at this problem with the following motivation it is important to keep in mind that order reduction is followed by an inference procedure on the order reduced mrf since there are many possible way of performing order reduction a technique that generates easier pairwise inference problem is a better reduction with this motivation in mind we introduce a new algorithm called order reduction inference ori that search over a space of order reduction method to minimize the difficulty of the resultant pairwise inference problem we set up this search problem a an energy minimization problem we show that application of ori for order reduction outperforms known order reduction technique both in simulated problem and in real world vision application 
detecting people remains a popular and challenging problem in computer vision in this paper we analyze part based model for person detection to determine which component of their pipeline could benefit the most if improved we accomplish this task by studying numerous detector formed from combination of component performed by human subject and machine the part based model we study can be roughly broken into four component feature detection part detection spatial part scoring and contextual reasoning including non maximal suppression our experiment conclude that part detection is the weakest link for challenging person detection datasets non maximal suppression and context can also significantly boost performance however the use of human or machine spatial model doe not significantly or consistently affect detection accuracy 
we present a human centric paradigm for scene understanding our approach go beyond estimating d scene geometry and predicts the workspace of a human which is represented by a data driven vocabulary of human interaction our method build upon the recent work in indoor scene understanding and the availability of motion capture data to create a joint space of human pose and scene geometry by modeling the physical interaction between the two this joint space can then be used to predict potential human pose and joint location from a single image in a way this work revisits the principle of gibsonian affordances reinterpreting it for the modern data driven era 
we present a technique for motion and size estimation of non line of sight nlos moving object in cluttered environment using a time of flight camera and multipath analysis we exploit relative time of arrival after reflection from a grid of point on a diffuse surface and create a virtual phased array by subtracting space time impulse response for successive frame we separate response of nlos moving object from those resulting from the cluttered environment after reconstructing the line of sight scene geometry we analyze the space of wavefront using the phased array and solve a constrained least square problem to recover the nlos target location importantly we can recover target s motion vector even in presence of uncalibrated time and pose bias common in time of flight system in addition we compute the upper bound on the size of the target by backprojecting the extremas of the time profile ability to track target inside room despite opaque occluders and multipath response ha numerous application in search and rescue medicine and defense we show centimeter accurate result by making appropriate modification to a time of flight system 
fast and reliable algorithm for estimating the head pose are essential for many application and higher level face analysis task we address the problem of head pose estimation from depth data which can be captured using the ever more affordable d sensing technology available today to achieve robustness we formulate pose estimation a a regression problem while detecting specific face part like the nose is sensitive to occlusion learning the regression on rather generic surface patch requires enormous amount of training data in order to achieve accurate estimate we propose to use random regression forest for the task at hand given their capability to handle large training datasets moreover we synthesize a great amount of annotated training data using a statistical model of the human face in our experiment we show that our approach can handle real data presenting large pose change partial occlusion and facial expression even though it is trained only on synthetic neutral face data we have thoroughly evaluated our system on a publicly available database on which we achieve state of the art performance without having to resort to the graphic card 
with the rise in popularity of digital camera the amount of visual data available on the web is growing exponentially some of these picture are extremely beautiful and aesthetically pleasing but the vast majority are uninteresting or of low quality this paper demonstrates a simple yet powerful method to automatically select high aesthetic quality image from large image collection our aesthetic quality estimation method explicitly predicts some of the possible image cue that a human might use to evaluate an image and then us them in a discriminative approach these cue or high level describable image attribute fall into three broad type compositional attribute related to image layout or configuration content attribute related to the object or scene type depicted and sky illumination attribute related to the natural lighting condition we demonstrate that an aesthetic classifier trained on these describable attribute can provide a significant improvement over baseline method for predicting human quality judgment we also demonstrate our method for predicting the interestingness of flickr photo and introduce a novel problem of estimating query specific interestingness 
automatic video segmentation and action recognition ha been a long standing problem in computer vision much work in the literature treat video segmentation and action recognition a two independent problem while segmentation is often done without a temporal model of the activity action recognition is usually performed on pre segmented clip in this paper we propose a novel method that avoids the limitation of the above approach by jointly performing video segmentation and action recognition unlike standard approach based on extension of dynamic bayesian network our method is based on a discriminative temporal extension of the spatial bag of word model that ha been very popular in object recognition the classification is performed robustly within a multi class svm framework whereas the inference over the segment is done efficiently with dynamic programming experimental result on honeybee weizmann and hollywood datasets illustrate the benefit of our approach compared to state of the art method 
we propose to bridge the gap between random field rf formulation for joint categorization and segmentation jcas which model local interaction among pixel and superpixels and bag of feature categorization algorithm which use global descriptor for this purpose we introduce new higher order potential that encode the classification cost of a histogram extracted from all the object in an image that belong to a particular category where the cost is given a the output of a classifier when applied to the histogram the potential efficiently encode the classification cost of several histogram resulting from the different possible segmentation of an image they can be integrated with existing potential hence providing a natural unification of global and local interaction the potential parameter can be treated a parameter of the rf and hence be jointly learnt along with the other parameter of the rf experiment show that our framework can be used to improve the performance of existing jcas algorithm 
the perspective three point p p problem aim at determining the position and orientation of the camera in the world reference frame from three d d point correspondence this problem is known to provide up to four solution that can then be disambiguated using a fourth point all existing solution attempt to first solve for the position of the point in the camera reference frame and then compute the position and orientation of the camera in the world frame which alignes the two point set in contrast in this paper we propose a novel closed form solution to the p p problem which computes the aligning transformation directly in a single stage without the intermediate derivation of the point in the camera frame this is made possible by introducing intermediate camera and world reference frame and expressing their relative position and orientation using only two parameter the projection of a world point into the parametrized camera pose then lead to two condition and finally a quartic equation for finding up to four solution for the parameter pair a subsequent backsubstitution directly lead to the corresponding camera pose with respect to the world reference frame we show that the proposed algorithm offer accuracy and precision comparable to a popular standard state of the art approach but at much lower computational cost time faster furthermore it provides improved numerical stability and is le affected by degenerate configuration of the selected world point the superior computational efficiency is particularly suitable for any ransac outlier rejection step which is always recommended before applying pnp or non linear optimization of the final solution 
current state of the art object classification system are trained using large amount of hand labeled image in this paper we present an approach that show how to use unlabeled video sequence comprising weakly related object category towards the target class to learn better classifier for tracking and detection the underlying idea is to exploit the space time consistency of moving object to learn classifier that are robust to local transformation in particular we use dense optical flow to find moving object in video in order to train part based random forest that are insensitive to natural transformation our method which is called video forest can be used in two setting first labeled training data can be regularized to force the trained classifier to generalize better towards small local transformation second a part of a tracking by detection approach it can be used to train a general codebook solely on pair wise data that can then be applied to tracking of instance of a priori unknown object category in the experimental part we show on benchmark datasets for both tracking and detection that incorporating unlabeled video into the learning of visual classifier lead to improved result 
we introduce an equi affine invariant diffusion geometry by which surface that go through squeeze and shear transformation can still be properly analyzed the definition of an affine invariant metric enables u to construct an invariant laplacian from which local and global geometric structure are extracted application of the proposed framework demonstrate it power in generalizing and enriching the existing set of tool for shape analysis 
many computer vision approach take for granted positive answer to question such a are semantic category visually separable and is visual similarity correlated to semantic similarity in this paper we study experimentally whether these assumption hold and show parallel to question investigated in cognitive science about the human visual system the insight gained from our analysis enable building a novel distance function between image assessing whether they are from the same basic level category this function go beyond direct visual distance a it also exploit semantic similarity measured through imagenet we demonstrate experimentally that it outperforms purely visual distance 
loopy belief propagation lbp is a powerful tool for approximate inference in markov random field mrfs however for problem with large state space the runtime cost are often prohibitively high in this paper we present a new lbp algorithm that represents all belief marginals and message in a wavelet representation which can encode the probabilistic information much more compactly unlike previous work our algorithm operates solely in the wavelet domain this yield an output sensitive algorithm where the running time depends mostly on the information content rather than the discretization resolution we apply the new technique to typical problem with large state space such a image matching and wide baseline optical flow where we observe a significantly improved scaling behavior with discretization resolution for large problem the new technique is significantly faster than even an optimized spatial domain implementation 
detection of line in raster image is often performed using hough transform this paper present a new parameterization of line and a modification of the hough transform pclines pclines are based on parallel coordinate a coordinate system used mostly or solely for high dimensional data visualization the pclines algorithm is described in the paper it accuracy is evaluated numerically and compared to the commonly used line detector based on the hough transform the result show that pclines outperform the existing approach in term of accuracy besides pclines are computationally extremely efficient require no floating point operation and can be easily accelerated by different hardware architecture 
structured light based pattern provide a mean to capture the state of an object shape however it may be inefficient when the object is freely moving when it surface contains high curvature part or in out of depth of field situation for image based robotic guidance in unstructured and dynamic environment only one shot is required for capturing the shape of a moving region of interest then robust pattern and real time capability must be targeted to this end we have developed a novel technique for the generation of coded pattern directly driven by the hamming distance the counterpart is the big amount of code the coding decoding algorithm have to face with a high desired hamming distance we show that the mean hamming distance is a useful criterion for driving the pattern generation process and we give a way to predict it value furthermore to ensure local uniqueness of codewords with consideration of many incomplete one the perfect map theory is involved then we describe a pseudorandom exhaustive algorithm to build pattern with more than feature in a very short time thanks to a splitting strategy which performs the hamming test in the codeword space instead of the pattern array this lead to a significant reduction of the computational complexity and it may be applied to other purpose finally real time reconstruction from single image are reported and result are compared to the best known which are outperformed in many case 
the traditional shape from shading problem with a single light source and lambertian reflectance is challenging since the constraint implied by the illumination are not sufficient to specify local orientation photometric stereo algorithm a variant of shape from shading simplify the problem by controlling the illumination to obtain additional constraint in this paper we demonstrate that many natural lighting environment already have sufficient variability to constrain local shape we describe a novel optimization scheme that exploit this variability to estimate surface normal from a single image of a diffuse object in natural illumination we demonstrate the effectiveness of our method on both simulated and real image 
we introduce a robust estimator called generalized projection based m estimator gpbm which doe not require the user to specify any scale parameter for multiple inlier structure with different noise covariance the estimator iteratively determines one inlier structure at a time unlike pbm where the scale of the inlier noise is estimated simultaneously with the model parameter gpbm ha three distinct stage scale estimation robust model estimation and inlier outlier dichotomy we evaluate our performance on challenging synthetic data face image clustering upto ten different face from yale face database b and multi body projective motion segmentation problem on hopkins dataset result of state of the art method are presented for comparison 
many successful model for predicting attention in a scene involve three main step convolution with a set of filter a center surround mechanism and spatial pooling to construct a saliency map however integrating spatial information and justifying the choice of various parameter value remain open problem in this paper we show that an efficient model of color appearance in human vision which contains a principled selection of parameter a well a an innate spatial pooling mechanism can be generalized to obtain a saliency model that outperforms state of the art model scale integration is achieved by an inverse wavelet transform over the set of scale weighted center surround response the scale weighting function termed ecsf ha been optimized to better replicate psychophysical data on color appearance and the appropriate size of the center surround inhibition window have been determined by training a gaussian mixture model on eye fixation data thus avoiding ad hoc parameter selection additionally we conclude that the extension of a color appearance model to saliency estimation add to the evidence for a common low level visual front end for different visual task 
we address the problem of labeling individual datapoints given some knowledge about small subset or group of them the knowledge we have for a group is the likelihood value for each group member to satisfy a certain model this problem is equivalent to hypergraph labeling problem where each datapoint corresponds to a node and the each subset correspond to a hyperedge with likelihood value a it weight we propose a novel method to model the label dependence using an undirected graphical model and reduce the problem of hypergraph labeling into an inference problem this paper describes the structure and necessary component of such model and proposes useful cost function we discus the behavior of proposed algorithm with different form of the cost function identify suitable algorithm for inference and analyze required property when it is theoretically guaranteed to have exact solution example of several real world problem are shown a application of the proposed method 
we present an algorithm for calibrated camera relative pose estimation from line given three line with two of the line parallel and orthogonal to the third we can compute the relative rotation between two image we can also compute the relative translation from two intersection point we also present a framework in which such line can be detected we evaluate the performance of the algorithm using synthetic and real data the intended use of the algorithm is with robust hypothesize and test framework such a ransac our approach is suitable for urban and indoor environment where most line are either parallel or orthogonal to each other 
we present a novel algorithm for automatically applying constrainable l optimal camera path to generate stabilized video by removing undesired motion our goal is to compute camera path that are composed of constant linear and parabolic segment mimicking the camera motion employed by professional cinematographer to this end our algorithm is based on a linear programming framework to minimize the first second and third derivative of the resulting camera path our method allows for video stabilization beyond the conventional filtering of camera path that only suppresses high frequency jitter we incorporate additional constraint on the path of the camera directly in our algorithm allowing for stabilized and retargeted video our approach accomplishes this without the need of user interaction or costly d reconstruction of the scene and work a a post process for video from any camera or from an online source 
blind image deconvolution is an ill posed problem that requires regularization to solve however many common form of image prior used in this setting have a major drawback in that the minimum of the resulting cost function doe not correspond to the true sharp solution accordingly a range of additional method are needed to yield good result bayesian method adaptive cost function alpha matte extraction and edge localization in this paper we introduce a new type of image regularization which give lowest cost for the true sharp image this allows a very simple cost formulation to be used for the blind deconvolution model obviating the need for additional method due to it simplicity the algorithm is fast and very robust we demonstrate our method on real image with both spatially invariant and spatially varying blur 
current face image retrieval method achieve impressive result but lack efficient way to refine the search particularly for geometric face attribute user cannot easily find face with slightly more furrowed brow or specific leftward pose shift for example to address this problem we propose a new face search technique based on shape manipulation that is complementary to current search engine user drag one or a small number of contour point like the bottom of the chin or the corner of an eyebrow to search for face similar in shape to the current face but with updated geometric attribute specific to their edits for example the user can drag a mouth corner to find face with wider smile or the tip of the nose to find face with a specific pose a part of our system we propose a novel confidence score for face alignment result that automatically construct a contour aligned face database with reasonable alignment accuracy a simple and straightforward extension of pca with missing data to tensor analysis and a new regularized tensor model to compute shape feature vector for each aligned face all built upon previous work to the best of our knowledge our system demonstrates the first face retrieval approach based chiefly on shape manipulation we show compelling result on a sizable database of over face image captured in uncontrolled environment 
cosegmentation is typically defined a the task of jointly segmenting something similar in a given set of image existing method are too generic and so far have not demonstrated competitive result for any specific task in this paper we overcome this limitation by adding two new aspect to cosegmentation the something ha to be an object and the similarity measure is learned in this way we are able to achieve excellent result on the recently introduced icoseg dataset which contains small set of image of either the same object instance or similar object of the same class the challenge of this dataset lie in the extreme change in viewpoint lighting and object deformation within each set we are able to considerably outperform several competitor to achieve this performance we borrow recent idea from object recognition the use of powerful feature extracted from a pool of candidate object like segmentation we believe that our work will be beneficial to several application area such a image retrieval 
for two consecutive frame in a video we identify which pixel in the first frame become occluded in the second such general purpose detection of occlusion region is difficult and important because one to one correspondence of imaged scene point is needed for many tracking video segmentation and reconstruction algorithm our hypothesis is that an effective trained occlusion detector can be generated on the basis of i a broad spectrum of visual feature and ii representative but synthetic training sequence by using a random forest based framework for feature selection and training we found that the proposed feature set wa sufficient to frequently assign a high probability of occlusion to just the pixel that were indeed becoming occluded our extensive experiment on many sequence support this finding and while accuracy is certainly still scene dependent the proposed classifier could be a useful preprocessing step to exploit temporal information in video 
the goal of object category discovery is to automatically identify group of image region which belong to some new previously unseen category this task is typically performed in a purely unsupervised setting and a a result performance depends critically upon accurate assessment of similarity between unlabeled image region to improve the accuracy of category discovery we develop a novel multiple kernel learning algorithm based on structural svm which optimizes a similarity space for nearest neighbor prediction the optimized space is then used to cluster unlabeled data and identify new category experimental result on the msrc and pascal voc data set indicate that using an optimized similarity metric can improve clustering for category discovery furthermore we demonstrate that including both labeled and unlabeled training data when optimizing the similarity metric can improve the overall quality of the system 
we describe a generative model of the relationship between two image the model is defined a a factored three way boltzmann machine in which hidden variable collaborate to define the joint correlation matrix for image pair modeling the joint distribution over pair make it possible to efficiently match image that are the same according to a learned measure of similarity we apply the model to several face matching task and show that it learns to represent the input image using task specific basis function matching performance is superior to previous similar generative model including recent conditional model of transformation we also show that the model can be used a a plug in matching score to perform invariant classification 
given a community contributed set of photo of a crowded public event this paper address the problem of finding all image of each person in the scene this problem is very challenging due to large change in camera viewpoint severe occlusion low resolution and photo from ten or hundred of different photographer despite these challenge the problem is made tractable by exploiting a variety of visual and contextual cue appearance time stamp camera pose and co occurrence of people this paper demonstrates an approach that integrates these cue to enable high quality person matching in community photo collection downloaded from flickr com 
we describe an imaging architecture for compressive video sensing termed programmable pixel compressive camera p c p c allows u to capture fast phenomenon at frame rate higher than the camera sensor in p c each pixel ha an independent shutter that is modulated at a rate higher than the camera frame rate the observed intensity at a pixel is an integration of the incoming light modulated by it specific shutter we propose a reconstruction algorithm that us the data from p c along with additional prior about video to perform temporal super resolution we model the spatial redundancy of video using sparse representation and the temporal redundancy using brightness constancy constraint inferred via optical flow we show that by modeling such spatio temporal redundancy in a video volume one can faithfully recover the underlying high speed video frame from the observed low speed coded video the imaging architecture and the reconstruction algorithm allows u to achieve temporal super resolution without loss in spatial resolution we implement a prototype of p c using an lcos modulator and recover several video at fps using a fps camera 
we present a method for estimating the relative pose of two calibrated or uncalibrated non overlapping surveillance camera from observing a moving object we show how to tackle the problem of missing point correspondence heavily required by sfm pipeline and how to go beyond this basic paradigm we relax the non linear nature of the problem by accepting two assumption which surveillance scenario offer i e the presence of a moving object and easily estimable gravity vector by those assumption we cast the problem a a quadratic eigenvalue problem offering an elegant way of treating nonlinear monomials and delivering a quasi closed form solution a a reliable starting point for a further bundle adjustment we are the first to bring the closed form solution to such a very practical problem arising in video surveillance result in different camera setup demonstrate the feasibility of the approach 
aesthetic quality classification play an important role in how people organize large photo collection in particular color harmony is a key factor in the various aspect that determine the perceived quality of a photo and it should be taken into account to improve the performance of automatic aesthetic quality classification however the existing model of color harmony take only simple color pattern into consideration e g patch consisting of a few color and thus cannot be used to ass photo with complicated color arrangement in this work we tackle the challenging problem of evaluating the color harmony of photo with a particular focus on aesthetic quality classification a key point is that a photograph can be seen a a collection of local region with color variation that are relatively simple this led u to develop a method for assessing the aesthetic quality of a photo based on the photo s color harmony we term the method bag of color pattern result of experiment on a large photo collection with user provided aesthetic quality score show that our aesthetic quality classification method which explicitly take into account the color harmony of a photo outperforms the existing method result also show that the classification performance is improved by combining our color harmony feature with blur edge and saliency feature that reflect the aesthetic of the photo 
supervised method for learning an embedding aim to map high dimensional image to a space in which perceptually similar observation have high measurable similarity most approach rely on binary similarity typically defined by class membership where label are expensive to obtain and or difficult to define in this paper we propose crowd sourcing similar image by soliciting human imitation we exploit temporal coherence in video to generate additional pairwise graded similarity between the user contributed imitation we introduce two method for learning nonlinear invariant mapping that exploit graded similarity we learn a model that is highly effective at matching people in similar pose it exhibit remarkable invariance to identity clothing background lighting shift and scale 
using optical triangulation method to measure the shape of translucent object is difficult because subsurface scattering contaminates measurement of the direct reflection at the surface a number of recent paper have shown that high frequency sinusoidal illumination pattern allow isolating this direct component which in turn enables accurate estimation of the shape of translucent object despite these encouraging result there is currently no rigorous mathematical analysis of the expected error in the measured surface a it relates to the parameter of these system the frequency of the projected sinusoid the geometric configuration of the source and camera and the optical property of the target object we present such an analysis which confirms earlier empirical result and provides a much needed tool for designing d scanner for translucent object 
we present an algorithm to simultaneously recover non rigid shape and camera pose from point correspondence between a reference shape and a sequence of input image the key novel contribution of our approach is in bringing the tool of the probabilistic slam methodology from a rigid to a deformable domain under the assumption that the shape may be represented a a weighted sum of deformation mode we show that the problem of estimating the modal weight along with the camera pose may be probabilistically formulated a a maximum a posterior estimate and solved using an iterative least square optimization an extensive evaluation on synthetic and real data show that our approach ha several significant advantage over current approach such a performing robustly under large amount of noise and outlier and neither requiring to track point over the whole sequence nor initialization close from the ground truth solution 
scene understanding from a monocular moving camera is a challenging problem with a number of application including robotics and automotive safety while recent system have shown that this is best accomplished with a d scene model handling of partial object occlusion is still unsatisfactory in this paper we propose an approach that tightly integrates monocular d scene tracking by detection with explicit object object occlusion reasoning full object and object part detector are combined in a mixture of expert based on their expected visibility which is obtained from the d scene model for the difficult case of multi people tracking we demonstrate that our approach yield more robust detection and tracking of partially visible pedestrian even when they are occluded over long period of time our approach is evaluated on two challenging sequence recorded from a moving camera in busy pedestrian zone and outperforms several state of the art approach 
non rigid structure from motion nr sfm is a difficult underconstrained problem in computer vision this paper proposes a new algorithm that revise the standard matrix factorization approach in nr sfm we consider two alternative representation for the linear space spanned by a small number k of d basis shape a compared to the standard approach using general rank k matrix factor we show that improved result are obtained by explicitly modeling k complementary space of rank our new method is positively compared to the state of the art in nr sfm providing improved result on high frequency deformation of both articulated and simpler deformable shape we also present an approach for nr sfm with occlusion 
we revisit the problem of matching a set of line in the d image to a set of corresponding line in the d model for the following reason a existing algorithm that treat line a infinitely long contain a flaw namely the solution found are not invariant with respect to the choice of the coordinate frame the source of this flaw is in the way line are represented we propose a frame independent representation for set of infinite line that remove the non invariance flaw b algorithm for finding the best rigid transform are nonlinear optimization that are sensitive to initialization and may result in unreliable and expensive solution we present a new recipe for initialization that exploit the d geometry of the problem and is applicable to all algorithm that perform the matching in the d scene experiment show that with this initialization all algorithm find the best transform c we present a new efficient matching algorithm that is significantly faster than existing alternative since it doe not require explicit evaluation of the cost function and it derivative 
recognizing face in unconstrained video is a task of mounting importance while obviously related to face recognition in still image it ha it own unique characteristic and algorithmic requirement over the year several method have been suggested for this problem and a few benchmark data set have been assembled to facilitate it study however there is a sizable gap between the actual application need and the current state of the art in this paper we make the following contribution a we present a comprehensive database of labeled video of face in challenging uncontrolled condition i e in the wild the youtube face database along with benchmark pair matching test b we employ our benchmark to survey and compare the performance of a large variety of existing video face recognition technique finally c we describe a novel set to set similarity measure the matched background similarity mbgs this similarity is shown to considerably improve performance on the benchmark test 
time of flight camera provide high frame rate depth measurement within a limited range of distance these reading can be extremely noisy and display unique error for instance where scene contain depth discontinuity or material with low infrared reflectivity previous work have treated the amplitude of each time of flight sample a a measure of confidence in this paper we demonstrate the shortcoming of this common lone heuristic and propose an improved per pixel confidence measure using a random forest regressor trained with real world data using an industrial laser scanner for ground truth acquisition we evaluate our technique on data from two different time of flight camera we argue that an improved confidence measure lead to superior reconstruction in subsequent step of traditional scan processing pipeline at the same time data with confidence reduces the need for point cloud smoothing and median filtering 
a convenient way of dealing with image set is to represent them a point on grassmannian manifold while several recent study explored the applicability of discriminant analysis on such manifold the conventional formalism of discriminant analysis suffers from not considering the local structure of the data we propose a discriminant analysis approach on grassmannian manifold based on a graph embedding framework we show that by introducing within class and between class similarity graph to characterise intra class compactness and inter class separability the geometrical structure of data can be exploited experiment on several image datasets pie banca mobo eth show that the proposed algorithm obtains considerable improvement in discrimination accuracy in comparison to three recent method grassmann discriminant analysis gda kernel gda and the kernel version of affine hull image set distance we further propose a grassmannian kernel based on canonical correlation between subspace which can increase discrimination accuracy when used in combination with previous grassmannian kernel 
in this paper we present an unsupervised method for mining activity in video from unlabeled video sequence of a scene our method can automatically recover what are the recurrent temporal activity pattern or motif and when they occur using non parametric bayesian method we are able to automatically find both the underlying number of motif and the number of motif occurrence in each document the model s robustness is first validated on synthetic data it is then applied on a large set of video data from state of the art paper we show that it can effectively recover temporal activity with high semantics for human and strong temporal information the model is also used for prediction where it is shown to be a efficient a other approach although illustrated on video sequence this model can be directly applied to various kind of time series where multiple activity occur simultaneously 
we present a novel approach for automatically discovering spatio temporal pattern in complex dynamic scene similarly to recent non object centric method we use low level visual cue to detect atomic activity and then construct clip histogram differently from previous work we formulate the task of discovering high level activity pattern a a prototype learning problem where the correlation among atomic activity is explicitly taken into account when grouping clip histogram interestingly at the core of our approach there is a convex optimization problem which allows u to efficiently extract pattern at multiple level of detail the effectiveness of our method is demonstrated on publicly available datasets 
we introduce three dimensional kaleidoscopic imaging a promising alternative for recording multi view imagery the main limitation of multi view reconstruction technique is the limited number of view that are available from multi camera system especially for dynamic scene our new system is based on imaging an object inside a kaleidoscopic mirror system we show that this approach can generate a large number of high quality view well distributed over the hemisphere surrounding the object in a single shot in comparison to existing multi view system our method offer a number of advantage it is possible to operate with a single camera the individual view are perfectly synchronized and they have the same radiometric and colorimetric property we describe the setup both theoretically and provide method for a practical implementation enabling interfacing to standard multi view algorithm for further processing is an important goal of our technique 
in this paper we cast the problem of graph matching a one of non rigid manifold alignment the low dimensional manifold are from the commute time embedding and are matched though coherent point drift although there have been a number of attempt to realise graph matching in this way in this paper we propose a novel information theoretic measure of alignment the so called symmetrized normalized entropy square variation we successfully test this dissimilarity measure between manifold on a a challenging database the measure is estimated by mean of the bypass leonenko entropy functional in addition we prove that the proposed measure induces a positive definite kernel between the probability density function associated with the manifold and hence between graph after deformation in our experiment we find that the optimal embedding is associated to the commute time distance and we also find that our approach which is purely topological outperforms several state of the art graph based algorithm for point matching 
we describe a vehicle tracking algorithm using input from a network of nonoverlapping camera our algorithm is based on a novel statistical formulation that us joint kinematic and image appearance information to link local track of the same vehicle into global track with longer persistence the algorithm can handle significant spatial separation between the camera and is robust to challenging tracking condition such a high traffic density or complex road infrastructure in these case traditional tracking formulation based on mht or jpda algorithm may fail to produce track association across camera due to the weak predictive model employed we make several new contribution in this paper firstly we model kinematic constraint between any two local track using road network and transit time distribution the transit time distribution are calculated dynamically a convolution of normalized transit time distribution that are learned and adapted separately for individual road secondly we present a complete statistical tracker formulation which combine kinematic and appearance likelihood within a multi hypothesis framework we have extensively evaluated the algorithm proposed using a network of ground based camera with narrow field of view the tracking result obtained on a large ground truthed dataset demonstrate the effectiveness of the algorithm proposed 
unsupervised categorization of object is a fundamental problem in computer vision while appearance based method have become popular recently other important cue like functionality are largely neglected motivated by psycho logical study giving evidence that human demonstration ha a facilitative effect on categorization in infancy we pro pose an approach for object categorization from depth video stream to this end we have developed a method for cap turing human motion in real time the captured data is then used to temporally segment the depth stream into action the set of segmented action are then categorized in an un supervised manner through a novel descriptor for motion capture data that is robust to subject variation further more we automatically localize the object that is manipulated within a video segment and categorize it using the corresponding action for evaluation we have recorded a dataset that comprises depth data with registered video sequence for subject action class and object manipulation 
with the explosion in the usage of mobile device and other smart electronics embedded device are becoming ubiquitous most such embedded architecture utilize fixed point rather than floating point computation to meet power heat and speed requirement leading to the need for integer based processing algorithm operation involving gaussian kernel are common to such algorithm but the standard method of constructing such kernel result in approximation and lack a property that enables efficient bitwise shift operation to overcome these limitation we present how to precisely combine the power of integer arithmetic and bitwise shift with intrinsically real valued gaussian kernel we prove mathematically that there exist a set of what we call magic sigma for which the integer kernel exactly represent the gaussian function whose value are all power of two and we discovered that the maximum sigma that lead to such property is about we also designed a simple and precise algorithm for designing kernel composed exclusively of integer given any arbitrary sigma and show how this can be exploited for gaussian filter design considering the ubiquity of gaussian filtering and the need for integer computation for increasing number of embedded device this is an important result for both theoretical and practical purpose 
people detection is an important task for a wide range of application in computer vision state of the art method learn appearance based model requiring tedious collection and annotation of large data corpus also obtaining data set representing all relevant variation with sufficient accuracy for the intended application domain at hand is often a non trivial task therefore this paper investigates how d shape model from computer graphic can be leveraged to ease training data generation in particular we employ a rendering based reshaping method in order to generate thousand of synthetic training sample from only a few person and view we evaluate our data generation method for two different people detection model our experiment on a challenging multi view dataset indicate that the data from a few a eleven person suffices to achieve good performance when we additionally combine our synthetic training sample with real data we even outperform existing state of the art method 
we propose a new family of non submodular global energy function that still use submodularity internally to couple edge in a graph cut we show it is possible to develop an efficient approximation algorithm that thanks to the internal submodularity can use standard graph cut a a subroutine we demonstrate the advantage of edge coupling in a natural setting namely image segmentation in particular for fine structured object and object with shading variation our structured edge coupling lead to significant improvement over standard approach 
in this work we consider the problem of tracking object from a moving airborne platform in wide area surveillance through long occlusion and or when their motion is unpredictable the main idea is to take advantage of the known d scene structure to estimate a dynamic occlusion map and to use the occlusion map to determine traffic entry and exit into these zone which we call source and sink then the track linking problem is formulated a an alignment of sequence of track entering a sink and leaving a source the sequence alignment problem is solved optimally and efficiently using dynamic programming we have evaluated our algorithm on a vehicle tracking task in wide area motion imagery and have shown that track fragmentation is significantly decreased and outperforms the hungarian algorithm 
we present a new paradigm for tracking object in video in the presence of other similar object this branch and track paradigm is also useful in the absence of motion for the discovery of repetitive pattern in image the object of interest is the lead object and the distracters are extra the lead tracker branch out tracker for extra when they are detected and all tracker share a common set of feature sometimes extra are tracked because they are of interest in their own right in other case and perhaps more importantly tracking extra make tracking the lead nimbler and more robust both because shared feature provide a richer object model and because tracking extra account for source of confusion explicitly sharing feature also make joint tracking le expensive and coordinating tracking across lead and extra allows optimizing window position jointly rather than separately for better result the joint tracking of both lead and extra can be solved optimally by dynamic programming and branching is quickly determined by efficient subwindow search matlab experiment show near real time performance at frame per second on a single core laptop for by image 
a new family of boosting algorithm denoted taylor boost is proposed it support any combination of loss function and first or second order optimization and includes classical algorithm such a adaboost gradient boost or logitboost a special case it restriction to the set of canonical loss make it possible to have boosting algorithm with explicit margin control a new large family of loss with this property based on the set of cumulative distribution of zero mean random variable is then proposed a novel loss function in this family the laplace loss is finally derived the combination of this loss and second order taylorboost produce a boosting algorithm with explicit margin control 
we analyze the computational problem of multi object tracking in video sequence we formulate the problem using a cost function that requires estimating the number of track a well a their birth and death state we show that the global solution can be obtained with a greedy algorithm that sequentially instantiates track using shortest path computation on a flow network greedy algorithm allow one to embed pre processing step such a nonmax suppression within the tracking algorithm furthermore we give a near optimal algorithm based on dynamic programming which run in time linear in the number of object and linear in the sequence length our algorithm are fast simple and scalable allowing u to process dense input data this result in state of the art performance 
attribute were recently shown to give excellent result for category recognition in this paper we demonstrate their performance in the context of image retrieval first we show that retrieving image of particular object based on attribute vector give result comparable to the state of the art second we demonstrate that combining attribute and fisher vector improves performance for retrieval of particular object a well a category third we implement an efficient coding technique for compressing the combined descriptor to very small code experimental result on the holiday dataset show that our approach significantly outperforms the state of the art even for a very compact representation of byte per image retrieving category image is evaluated on the web query dataset we show that attribute feature combined with fisher vector improve the performance and that combined image feature can supplement text feature 
identifying the surface of three dimensional static object or of two dimensional object over time are key to a variety of application throughout computer vision active surface technique have been widely applied to such task such that a deformable spline surface evolves by the influence of internal and external typically opposing energy until the model converges to the desired surface present deformable model surface extraction technique are computationally expensive and are not able to reliably identify surface in the presence of noise high curvature or clutter this paper proposes a novel active surface technique decoupled active surface with the specific objective of robustness and computational efficiency motivated by recent result in two dimensional object segmentation the internal and external energy are treated separately which lead to much faster convergence a truncated maximum likelihood estimator is applied to generate a surface consistent with the measurement external energy and a bayesian linear least square estimator is asserted to enforce the prior internal energy to maintain tractability for typical three dimensional problem the density of vertex is dynamically resampled based on curvature a novel quasi random search is used a a substitute for the ml estimator and sparse conjugate gradient is used to execute the bayesian estimator the performance of the proposed method is presented using two natural and two synthetic image volume 
we address the problem of articulated human pose estimation in video using an ensemble of tractable model with rich appearance shape contour and motion cue in previous articulated pose estimation work on unconstrained video using temporal coupling of limb position ha made little to no difference in performance over parsing frame individually one crucial reason for this is that joint parsing of multiple articulated part over time involves intractable inference and learning problem and previous work ha resorted to approximate inference and simplified model we overcome these computational and modeling limitation using an ensemble of tractable submodels which couple location of body joint within and across frame using expressive cue each submodel is responsible for tracking a single joint through time e g left elbow and also model the spatial arrangement of all joint in a single frame because of the tree structure of each submodel we can perform efficient exact inference and use rich temporal feature that depend on image appearance e g color tracking and optical flow contour we propose and experimentally investigate a hierarchy of submodel combination method and we find that a highly efficient max marginal combination method outperforms much slower by order of magnitude approximate inference using dual decomposition we apply our pose model on a new video dataset of highly varied and articulated pose from tv show we show significant quantitative and qualitative improvement over state of the art single frame pose estimation approach 
this paper show that an image can be approximately reconstructed based on the output of a blackbox local description software such a those classically used for image indexing our approach consists first in using an off the shelf image database to find patch that are visually similar to each region of interest of the unknown input image according to associated local descriptor these patch are then warped into input image domain according to interest region geometry and seamlessly stitched together final completion of still missing texture free region is obtained by smooth interpolation a demonstrated in our experiment visually meaningful reconstruction are obtained just based on image local descriptor like sift provided the geometry of region of interest is known the reconstruction most often allows the clear interpretation of the semantic image content a a result this work raise critical issue of privacy and right when local descriptor of photo or video are given away for indexing and search purpose 
a new paradigm for multivariate regression is proposed principal regression analysis pra it entail learning a low dimensional subspace over sample specific regressors for a given input the model predicts a subspace thought to contain the corresponding response using this subspace a a prior the search space is considerably more constrained an efficient local optimisation strategy is proposed for learning and a practical choice for it initialisation suggested the utility of pra is demonstrated on the task of non rigid face and car alignment using challenging in the wild datasets where substantial performance improvement are observed over alignment with a conventional prior 
while knowledge transfer kt between object class ha been accepted a a promising route towards scalable recognition most experimental kt study are surprisingly limited in the number of object class considered to support claim of kt w r t scalability we thus advocate to evaluate kt in a large scale setting to this end we provide an extensive evaluation of three popular approach to kt on a recently proposed large scale data set the imagenet large scale visual recognition competition data set in a first setting they are directly compared to one v all classification often neglected in kt paper and in a second setting we evaluate their ability to enable zero shot learning while none of the kt method can improve over one v all classification they prove valuable for zero shot learning especially hierarchical and direct similarity based kt we also propose and describe several extension of the evaluated approach that are necessary for this large scale study 
document registration is a problem where the image of a template document whose layout is known is registered with a test document image given the registration parameter layout of the template image is superimposed on the test document registration algorithm have been popular in application such a form processing where the superimposed layout is used to extract relevant field prior art ha been designed to work with scanned document under affine transformation we find that the proliferation of camera captured image make it necessary to address camera noise such a non uniform lighting clutter and highly variable scale resolution the absence of a scan bed also lead to challenging non rigid deformation being seen in paper image prior approach in point pattern based registration like random sample consensus ransac and thin plate spline robust point matching tps rpm form the basis of our work we propose enhancement to these method to enable registration of cell phone and camera captured document under non rigid transformation we embed three novel aspect into the framework i histogram based uniformly transformed correspondence estimation ii clustering of point located near the region of interest roi to select only close by region for matching iii validation of the registration in ransac and tps rpm algorithm for non rigid registration we consider scale invariant feature transform sift and speeded up robust feature surf a our feature result are reported a comparing prior art with our method on a dataset that will be made publicly available 
this paper present a novel method for so called hand eye calibration using a calibration target is not possible for many application of hand eye calibration in such situation structure from motion approach of hand eye calibration is commonly used to recover the camera pose up to scaling the presented method take advantage of recent result in the l norm optimization using second order cone programming socp to recover the correct scale further the correctly scaled displacement of the hand eye transformation is recovered solely from the image correspondence and robot measurement and is guaranteed to be globally optimal with respect to the l norm the method is experimentally validated using both synthetic and real world datasets 
we propose and evaluate improvement in motion field estimation in order to cope with challenge in real world scenario to build a real time stereo based three dimensional vision system which is able to handle illumination change textureless region and fast moving object observed by a moving platform we introduce a new approach to support the variational optical flow computation scheme with stereo and feature information the improved flow result is then used a input for a temporal integrated robust three dimensional motion field estimation technique we evaluate the result of our optical flow algorithm and the resulting three dimensional motion field against approach known from literature test on both synthetic realistic and real stereo sequence show that our approach is superior to approach known from literature with respect to density accuracy and robustness 
advance in d imaging have recently made d surface scanner capable of capturing textured surface at video rate affordable and common in computer vision this is a relatively new source of data the potential of which ha not yet been fully exploited a the problem of non rigid registration of surface is difficult while registration based on shape alone ha been an active research area for some time the problem of registering surface based on texture information ha not been addressed in a principled way we propose a novel efficient and reliable fully automatic method for performing groupwise non rigid registration of textured surface such a those obtained with d scanner we demonstrate the robustness of our approach on d scan of human face including the notoriously difficult case of inter subject registration we show how our method can be used to build high quality d model of appearance fully automatically 
we present a modification of normalized cut to incorporate prior which can be used for constrained image segmentation compared to previous generalization of normalized cut which incorporate constraint our technique ha two advantage first we seek solution which are sufficiently correlated with prior which allows u to use noisy top down information for example from an object detector second given the spectral solution of the unconstrained problem the solution of the constrained one can be computed in small additional time which allows u to run the algorithm in an interactive mode we compare our algorithm to other graph cut based algorithm and highlight the advantage 
d scene understanding is key for the success of application such a autonomous driving and robot navigation however existing approach either produce a mild level of understanding e g segmentation object detection or are not accurate enough for these application e g d pop ups in this paper we propose a principled generative model of d urban scene that take into account dependency between static and dynamic feature we derive a reversible jump mcmc scheme that is able to infer the geometric e g street orientation and topological e g number of intersecting street property of the scene layout a well a the semantic activity occurring in the scene e g traffic situation at an intersection furthermore we show that this global level of understanding provides the context necessary to disambiguate current state of the art detector we demonstrate the effectiveness of our approach on a dataset composed of short stereo video sequence of different scene captured by a car driving around a mid size city 
from conventional wisdom and empirical study of annotated data it ha been shown that visual statistic such a object frequency and segment size follow power law distribution previous work ha shown that both kind of power law behavior can be captured by using a hierarchical pitman yor process prior within a nonparametric bayesian approach to scene segmentation in this paper we add label information into the previously unsupervised model our approach exploit the labelled data by adding constraint on the parameter space during the variational learning phase we evaluate our formulation on the labelme natural scene dataset and show the effectiveness of our approach 
traditional computer vision and machine learning algorithm have been largely studied in a centralized setting where all the processing is performed at a single central location however a distributed approach might be more appropriate when a network with a large number of camera is used to analyze a scene in this paper we show how centralized algorithm based on linear algebraic operation can be made distributed by using simple distributed average we cover algorithm such a svd least square pca gpca d point triangulation pose estimation and affine sfm 
we address the problem of detecting action such a drinking or opening a door in hour of challenging video data we propose a model based on a sequence of atomic action unit termed actoms that are characteristic for the action our model represents the temporal structure of action a a sequence of histogram of actom anchored visual feature our representation which can be seen a a temporally structured extension of the bag of feature is flexible sparse and discriminative we refer to our model a actom sequence model asm training requires the annotation of actoms for action clip at test time actoms are detected automatically based on a non parametric model of the distribution of actoms which also act a a prior on an action s temporal structure we present experimental result on two recent benchmark for temporal action detection coffee and cigarette and the dataset of we show that our asm method outperforms the current state of the art in temporal action detection 
in this paper we propose a distributed message passing algorithm for inference in large scale graphical model our method can handle large problem efficiently by distributing and parallelizing the computation and memory requirement the convergence and optimality guarantee of recently developed message passing algorithm are preserved by introducing new type of consistency message sent between the distributed computer we demonstrate the effectiveness of our approach in the task of stereo reconstruction from high resolution imagery and show that inference is possible with more than label in image larger than mpixels 
this paper address the problem of automatic reconstruction of a d relief from a line drawing on top of a given base object reconstruction is challenging due to four reason the sparsity of the stroke their ambiguity their large number and their inter relation our approach is able to reconstruct a model from a complex drawing that consists of many inter related stroke rather than viewing the inter dependency a a problem we show how they can be exploited to automatically generate a good initial interpretation of the line drawing then given a base and an interpretation we propose an algorithm for reconstructing a consistent surface the strength of our approach is demonstrated in the reconstruction of archaeological artifact from drawing these drawing are highly challenging since artist created very complex and detailed description of artifact regardless of any consideration concerning their future use for shape reconstruction 
in this paper we address the two class classification problem within the tensor based framework by formulating the support tucker machine stums more precisely in the proposed stums the weight parameter are regarded to be a tensor calculated according to the tucker tensor decomposition a the multiplication of a core tensor with a set of matrix one along each mode we further extend the proposed stums to the w stums in order to fully exploit the information offered by the total or the within class covariance matrix and whiten the data thus providing in variance to affine transformation in the feature space we formulate the two above mentioned problem in such a way that they can be solved in an iterative manner where at each iteration the parameter corresponding to the projection along a single tensor mode are estimated by solving a typical support vector machine type problem the superiority of the proposed method in term of classification accuracy is illustrated on the problem of gait and action recognition 
conventional non blind image deblurring algorithm involve natural image prior and maximum a posteriori map estimation a a consequence of map estimation separate pre processing step such a noise estimation and training of the regularization parameter are necessary to avoid user interaction moreover map estimate involving standard natural image prior have been found lacking in term of restoration performance to address these issue we introduce an integrated bayesian framework that unifies non blind deblurring and noise estimation thus freeing the user of tediously pre determining a noise level a sampling based technique allows to integrate out the unknown noise level and to perform deblurring using the bayesian minimum mean squared error estimate mmse which requires no regularization parameter and yield higher performance than map estimate when combined with a learned high order image prior a quantitative evaluation demonstrates state of the art result for both non blind deblurring and noise estimation 
the perplexing effect of noise and high feature dimensionality greatly complicate functional magnetic resonance imaging fmri classification in this paper we present a novel formulation for constructing generalized group sparse classifier gssc to alleviate these problem in particular we propose an extension of group lasso that permit association between feature within predefined group to be modeled integrating this new penalty into classifier learning enables incorporation of additional prior information beyond group structure in the context of fmri ggsc provides a flexible mean for modeling how the brain is functionally organized into specialized module i e group of voxels with spatially proximal voxels often displaying similar level of brain activity i e feature association applying gssc to real fmri data improved predictive performance over standard classifier while providing more neurologically interpretable classifier weight pattern our result thus demonstrate the importance of incorporating prior knowledge into classification problem 
specular flow is the motion field induced on the image plane by the movement of point reflected by a curved mirror like surface this flow provides information about surface shape and when the camera and surface move a a fixed pair shape can be recovered by solving linear differential equation along integral curve of flow previous analysis ha shown that two distinct motion i e two flow field are generally sufficient to guarantee a unique solution without externally provided initial condition in this work we show that we can often succeed with only one flow the key idea is to exploit the fact that smooth surface induce integrability constraint on the surface normal field we show that this induces a new differential equation that facilitates the propagation of shape information between integral curve of flow and that combining this equation with known method often permit the recovery of unique shape from a single specular flow given only a single seed point 
the current paper proposes a new parametric local color correction technique initially several color transfer function are computed from the output of the mean shift color segmentation algorithm secondly color influence map are calculated finally the contribution of every color transfer function is merged using the weight from the color influence map the proposed approach is compared with both global and local color correction approach result show that our method outperforms the technique ranked first in a recent performance evaluation on this topic moreover the proposed approach is computed in about one tenth of the time 
symmetric positive definite spd matrix have become popular to encode image information accounting for the geometry of the riemannian manifold of spd matrix ha proven key to the success of many algorithm however most existing method only approximate the true shape of the manifold locally by it tangent plane in this paper inspired by kernel method we propose to map spd matrix to a high dimensional hilbert space where euclidean geometry applies to encode the geometry of the manifold in the mapping we introduce a family of provably positive definite kernel on the riemannian manifold of spd matrix these kernel are derived from the gaussian kernel but exploit different metric on the manifold this let u extend kernel based algorithm developed for euclidean space such a svm and kernel pca to the riemannian manifold of spd matrix we demonstrate the benefit of our approach on the problem of pedestrian detection object categorization texture analysis d motion segmentation and diffusion tensor imaging dti segmentation 
we introduce the concept of relative volume constraint in order to account for insufficient information in the reconstruction of d object from a single image the key idea is to formulate a variational reconstruction approach with shape prior in form of relative depth profile or volume ratio relating object part such shape prior can easily be derived either from a user sketch or from the object s shading profile in the image they can handle textured or shadowed object region by propagating information we propose a convex relaxation of the constrained optimization problem which can be solved optimally in a few second on graphic hardware in contrast to existing single view reconstruction algorithm the proposed algorithm provides substantially more flexibility to recover shape detail such a self occlusion dent and hole which are not visible in the object silhouette 
the development of complex powerful classifier and their constant improvement have contributed much to the progress in many field of computer vision however the trend towards large scale datasets revived the interest in simpler classifier to reduce runtime simple nearest neighbor classifier have several beneficial property such a low complexity and inherent multi class handling however they have a runtime linear in the size of the database recent related work represents data sample by assigning them to a set of prototype that partition the input feature space and afterwards applies linear classifier on top of this representation to approximate decision boundary locally linear in this paper we go a step beyond these approach and purely focus on nearest prototype classification where we propose a novel algorithm for deriving optimal prototype in a discriminative manner from the training sample our method is implicitly multi class capable parameter free avoids noise over fitting and since during testing only comparison to the derived prototype are required highly efficient experiment demonstrate that we are able to outperform related locally linear method while even getting close to the result of more complex classifier 
we introduce a generative model for learning person and costume specific detector from labeled example we demonstrate the model on the task of localizing and naming actor in long video sequence more specifically the actor s head and shoulder are each represented a a constellation of optional color region detection can proceed despite change in view point and partial occlusion we explain how to learn the model from a small number of labeled key frame or video track and how to detect novel appearance of the actor in a maximum likelihood framework we present result on a challenging movie example with recall in actor detection coverage and precision in actor identification naming 
temporal alignment of human behaviour from visual data is a very challenging problem due to a numerous reason including possible large temporal scale difference inter intra subject variability and more importantly due to the presence of gross error and outlier gross error are often in abundance due to incorrect localization and tracking presence of partial occlusion etc furthermore such error rarely follow a gaussian distribution which is the de facto assumption in machine learning method in this paper building on recent advance on rank minimization and compressive sensing a novel robust to gross error temporal alignment method is proposed while previous approach combine the dynamic time warping dtw with low dimensional projection that maximally correlate two sequence we aim to learn two underlying projection matrix one for each sequence which not only maximally correlate the sequence but at the same time efficiently remove the possible corruption in any datum in the sequence the projection are obtained by minimizing the weighted sum of nuclear and norm by solving a sequence of convex optimization problem while the temporal alignment is found by applying the dtw in an alternating fashion the superiority of the proposed method against the state of the art time alignment method namely the canonical time warping and the generalized time warping is indicated by the experimental result on both synthetic and real datasets 
we propose a new model for recognizing human attribute e g wearing a suit sitting short hair and action e g running riding a horse in still image the proposed model relies on a collection of part template which are learnt discriminatively to explain specific scale space location in the image in human centric coordinate it avoids the limitation of highly structured model which consist of a few i e a mixture of average template to learn our model we propose an algorithm which automatically mine out part and learns corresponding discriminative template with their respective location from a large number of candidate part we validate the method on recent challenging datasets i willow action ii human attribute hat and iii stanford action we obtain convincing qualitative and state of the art quantitative result on the three datasets 
image classification method have been significantly developed in the last decade most method stem from bag of feature bof approach and it is recently extended to a vector aggregation model such a using fisher kernel in this paper we propose a novel feature extraction method for image classification following the bof approach a plenty of local descriptor are first extracted in an image and the proposed method is built upon the probability density function p d f formed by those descriptor since the p d f essentially represents the image we extract the feature from the p d f by mean of the gradient on the p d f the gradient especially their orientation effectively characterize the shape of the p d f from the geometrical viewpoint we construct the feature by the histogram of the oriented p d f gradient via orientation coding followed by aggregation of the orientation code the proposed image feature imposing no specific assumption on the target are so general a to be applicable to any kind of task regarding image classification in the experiment on object recognition and scene classification using various datasets the proposed method exhibit superior performance compared to the other existing method 
the aim of this work is to localize a query photograph by finding other image depicting the same place in a large geotagged image database this is a challenging task due to change in viewpoint imaging condition and the large size of the image database the contribution of this work is two fold first we cast the place recognition problem a a classification task and use the available geotags to train a classifier for each location in the database in a similar manner to per exemplar svms in object recognition second a only few positive training example are available for each location we propose a new approach to calibrate all the per location svm classifier using only the negative example the calibration we propose relies on a significance measure essentially equivalent to the p value classically used in statistical hypothesis testing experiment are performed on a database of geotagged street view image of pittsburgh and demonstrate improved place recognition accuracy of the proposed approach over the previous work 
we propose a method to learn a diverse collection of discriminative part from object bounding box annotation part detector can be trained and applied individually which simplifies learning and extension to new feature or category we apply the part to object category detection pooling part detection within bottom up proposed region and using a boosted classifier with proposed sigmoid weak learner for scoring on pascal voc we evaluate the part detector ability to discriminate and localize annotated key point our detection system is competitive with the best existing system outperforming other hog based detector on the more deformable category 
the automatic discovery of distinctive part for an object or scene class is challenging since it requires simultaneously to learn the part appearance and also to identify the part occurrence in image in this paper we propose a simple efficient and effective method to do so we address this problem by learning part incrementally starting from a single part occurrence with an exemplar svm in this manner additional part instance are discovered and aligned reliably before being considered a training example we also propose entropy rank curve a a mean of evaluating the distinctiveness of part shareable between category and use them to select useful part out of a set of candidate we apply the new representation to the task of scene categorisation on the mit scene benchmark we show that our method can learn part which are significantly more informative and for a fraction of the cost compared to previous part learning method such a singh et al we also show that a well constructed bag of word or fisher vector model can substantially outperform the previous state of the art classification performance on this data 
a novel statistical textural distinctiveness approach for robustly detecting salient region in natural image is proposed rotational invariant neighborhood based textural representation are extracted and used to learn a set of representative texture atom for defining a sparse texture model for the image based on the learnt sparse texture model a weighted graphical model is constructed to characterize the statistical textural distinctiveness between all representative texture atom pair finally the saliency of each pixel in the image is computed based on the probability of occurrence of the representative texture atom their respective statistical textural distinctiveness based on the constructed graphical model and general visual attentive constraint experimental result using a public natural image dataset and a variety of performance evaluation metric show that the proposed approach provides interesting and promising result when compared to existing saliency detection method 
we present a novel stochastic framework for non blind deconvolution based on point sample obtained from random walk unlike previous method that must be tailored to specific regularization strategy the new stochastic deconvolution method allows arbitrary prior including non convex and data dependent regularizers to be introduced and tested with little effort stochastic deconvolution is straightforward to implement produce state of the art result and directly lead to a natural boundary condition for image boundary and saturated pixel 
we establish a link between fourier optic and a recent construction from the machine learning community termed the kernel mean map using the fraunhofer approximation it identifies the kernel with the squared fourier transform of the aperture this allows u to use result about the invertibility of the kernel mean map to provide a statement about the invertibility of fraunhofer diffraction showing that imaging process with arbitrarily small aperture can in principle be invertible i e do not lose information provided the object to be imaged satisfy a generic condition a real world experiment show that we can super resolve beyond the rayleigh limit 
we address the problem of estimating the latent image of a static bilayer scene consisting of a foreground and a background at different depth from motion blurred observation captured with a handheld camera the camera motion is considered to be composed of in plane rotation and translation since the blur at an image location depends both on camera motion and depth deblurring becomes a difficult task we initially propose a method to estimate the transformation spread function tsf corresponding to one of the depth layer the estimated tsf which reveals the camera motion during exposure is used to segment the scene into the foreground and background layer and determine the relative depth value the deblurred image of the scene is finally estimated within a regularization framework by accounting for blur variation due to camera motion a well a depth 
we introduce here an improved design of the uniform marker field and an algorithm for their fast and reliable detection our concept of the marker field is designed so that it can be detected and recognized for camera pose estimation in various lighting condition under a severe perspective while heavily occluded and under a strong motion blur our marker field detection harness the fact that the edge within the marker field meet at two vanishing point and that the projected planar grid of square can be defined by a detectable mathematical formalism the module of the grid are grey scale and the location within the marker field are defined by the edge between the module the assumption that the marker field is planar allows for a very cheap and reliable camera pose estimation in the captured scene the detection rate and accuracy are slightly better compared to state of the art marker based solution at the same time and more importantly our detector of the marker field is several time faster and the reliable real time detection can be thus achieved on mobile and low power device we show three targeted application where the planarity is assured and where the presented marker field design and detection algorithm provide a reliable and extremely fast solution 
in this paper we introduce unique publicly available dense an isotropic brdf data measurement we use this dense data a a reference for performance evaluation of the proposed brdf sparse angular sampling and interpolation approach the method is based on sampling of brdf subspace at fixed elevation by mean of several adaptively represented uniformly distributed perpendicular slice although this proposed method requires only a sparse sampling of material the interpolation provides a very accurate reconstruction visually and computationally comparable to densely measured reference due to the simple slice measurement and method s robustness it allows for a highly accurate acquisition of brdfs this in comparison with standard uniform angular sampling is considerably faster yet us far le sample 
in this work we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold a finding an atlas or a set of overlapping chart that accurately describe local structure we formulate the problem of learning the manifold a an optimisation that simultaneously refines the continuous parameter defining the chart and the discrete assignment of point to chart in contrast to existing method this direct formulation of a manifold doe not require unwrapping the manifold into a lower dimensional space and allows u to learn closed manifold of interest to vision such a those corresponding to gait cycle or camera pose we report state of the art result for manifold based nearest neighbour classification on vision datasets and show how the same technique can be applied to the d reconstruction of human motion from a single image 
we propose a new approach for template based extensible surface reconstruction from a single view we extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction our approach relies on the minimization of a proposed stretching energy formalized with respect to the poisson ratio parameter of the surface we derive a patch based formulation of this stretching energy by assuming local linear elasticity this formulation unifies geometrical and mechanical constraint in a single energy term we prevent local scale ambiguity by imposing a set of fixed boundary d point we experimentally prove the sufficiency of this set of boundary point and demonstrate the effectiveness of our approach on different developable and non developable surface with a wide range of extensibility 
trust region is a well known general iterative approach to optimization which offer many advantage over standard gradient descent technique in particular it allows more accurate nonlinear approximation model in each iteration this approach computes a global optimum of a suitable approximation model within a fixed radius around the current solution a k a trust region in general this approach can be used only when some efficient constrained optimization algorithm is available for the selected non linear more accurate approximation model in this paper we propose a fast trust region ftr approach for optimization of segmentation energy with non linear regional term which are known to be challenging for existing algorithm these energy include but are not limited to kl divergence and bhattacharyya distance between the observed and the target appearance distribution volume constraint on segment size and shape prior constraint in a form of l distance from target shape moment our method is order of magnitude faster than the existing state of the art method while converging to comparable or better solution 
we propose a new convex regularizer named the local color nuclear norm lcnn for color image recovery the lcnn is designed to promote a property inherent in natural color image in which their local color distribution often exhibit strong linearity and is thus expected to reduce color artifact effectively in addition the very nature of lcnn allows u to incorporate it into various type of color image recovery formulation with the associated convex optimization problem solvable using proximal splitting technique application of lcnn are demonstrated with illustrative numerical example 
in this paper we propose the first effective automated genetic algorithm ga based jigsaw puzzle solver we introduce a novel procedure of merging two parent solution to an improved child solution by detecting extracting and combining correctly assembled puzzle segment the solver proposed exhibit state of the art performance solving previously attempted puzzle faster and far more accurately and also puzzle of size never before attempted other contribution include the creation of a benchmark of large image previously unavailable we share the data set and all of our result for future testing and comparative evaluation of jigsaw puzzle solver 
we consider the problem of computing optical flow in monocular video taken from a moving vehicle in this setting the vast majority of image flow is due to the vehicle s ego motion we propose to take advantage of this fact and estimate flow along the epipolar line of the egomotion towards this goal we derive a slanted plane mrf model which explicitly reason about the ordering of plane and their physical validity at junction furthermore we present a bottom up grouping algorithm which produce over segmentation that respect flow boundary we demonstrate the effectiveness of our approach in the challenging kitti flow benchmark achieving half the error of the best competing general flow algorithm and one third of the error of the best epipolar flow algorithm 
in this paper we explore approach to accelerating segmentation and edge detection algorithm based on the emph gpb framework the paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offer performance that is competitive with the pb detector the paper also describes an approach for computing a reduced order normalized cut that capture the essential feature of the original problem but can be computed in le than half a second on a standard computing platform 
background modeling and subtraction is an essential task in video surveillance application most traditional study use information observed in past frame to create and update a background model to adapt to background change the background model ha been enhanced by introducing various form of information including spatial consistency and temporal tendency in this paper we propose a new framework that leverage information from a future period our proposed approach realizes a low cost and highly accurate background model the proposed framework is called bidirectional background modeling and performs background subtraction based on bidirectional analysis i e analysis from past to present and analysis from future to present although a result will be output with some delay because information is taken from a future period our proposed approach improves the accuracy by about if only a millisecond of delay is acceptable furthermore the memory cost can be reduced by about relative to typical background modeling 
in the context of shape segmentation and retrieval object wide distribution of measure are needed to accurately evaluate and compare local region of shape lien et al proposed two point wise concavity measure in the context of approximate convex decomposition of polygon measuring the distance from a point to the polygon s convex hull an accurate shortest path concavity spc measure and a straight line concavity slc approximation of the same while both are practicable on d shape the exponential cost of spc in d make it inhibitively expensive for a generalization to mesh in this paper we propose an efficient and straight forward approximation of the shortest path concavity measure to d mesh our approximation is based on discretizing the space between mesh and convex hull thereby reducing the continuous shortest path search to an efficiently solvable graph problem our approach work out of the box on complex mesh topology and requires no complicated handling of genus besides presenting a rigorous evaluation of our method on a variety of input mesh we also define an spc based shape descriptor and show it superior retrieval and runtime performance compared with the recently presented result on the convexity distribution by lian et al 
in this work we consider image of a scene with a moving object captured by a static camera a the object human or otherwise move about the scene it reveals pairwise depth ordering or occlusion cue the goal of this work is to use these sparse occlusion cue along with monocular depth occlusion cue to densely segment the scene into depth layer we cast the problem of depth layer segmentation a a discrete labeling problem on a spatio temporal markov random field mrf that us the motion occlusion cue along with monocular cue and a smooth motion prior for the moving object we quantitatively show that depth ordering produced by the proposed combination of the depth cue from object motion and monocular occlusion cue are superior to using either feature independently and using a naive combination of the feature 
a novel correspondence le approach is proposed to find a thin plate spline map between a pair of deformable d object represented by triangular surface mesh the proposed method work without landmark extraction and feature correspondence the aligning transformation is found simply by solving a system of nonlinear equation each equation is generated by integrating a nonlinear function over the object s domain we derive recursive formula for the efficient computation of these integral based on a series of comparative test on a large synthetic dataset our triangular mesh based algorithm outperforms state of the art method both in term of computing time and accuracy the applicability of the proposed approach ha been demonstrated on the registration of d lung ct volume 
how should a video be represented we propose a new representation for video based on mid level discriminative spatio temporal patch these spatio temporal patch might correspond to a primitive human action a semantic object or perhaps a random but informative spatio temporal patch in the video what defines these spatio temporal patch is their discriminative and representative property we automatically mine these patch from hundred of training video and experimentally demonstrate that these patch establish correspondence across video and align the video for label transfer technique furthermore these patch can be used a a discriminative vocabulary for action classification where they demonstrate state of the art performance on ucf and olympics datasets 
in this paper we develop a new model for recognizing human action an action is modeled a a very sparse sequence of temporally local discriminative key frame collection of partial key pose of the actor s depicting key state in the action sequence we cast the learning of key frame in a max margin discriminative framework where we treat key frame a latent variable this allows u to jointly learn a set of most discriminative key frame while also learning the local temporal context between them key frame are encoded using a spatially localizable pose let like representation with hog and bow component learned from weak annotation we rely on structured svm formulation to align our component and mine for hard negative to boost localization performance this result in a model that support spatio temporal localization and is insensitive to dropped frame or partial observation we show classification performance that is competitive with the state of the art on the benchmark ut interaction dataset and illustrate that our model outperforms prior method in an on line streaming setting 
color description is a challenging task because of large variation in rgb value which occur due to scene accidental event such a shadow shading specularities illuminant color change and change in viewing geometry traditionally this challenge ha been addressed by capturing the variation in physic based model and deriving invariant for the undesired variation the drawback of this approach is that set of distinguishable color in the original color space are mapped to the same value in the photometric invariant space this result in a drop of discriminative power of the color description in this paper we take an information theoretic approach to color description we cluster color value together based on their discriminative power in a classification problem the clustering ha the explicit objective to minimize the drop of mutual information of the final representation we show that such a color description automatically learns a certain degree of photometric invariance we also show that a universal color representation which is based on other data set than the one at hand can obtain competing performance experiment show that the proposed descriptor outperforms existing photometric invariant furthermore we show that combined with shape description these color descriptor obtain excellent result on four challenging datasets namely pascal voc flower stanford dog and bird 
junction are strong cue for understanding the geometry of a scene in this paper we consider the problem of detecting junction and using them for recovering the spatial layout of an indoor scene junction detection ha always been challenging due to missing and spurious line we work in a constrained manhattan world setting where the junction are formed by only line segment along the three principal orthogonal direction junction can be classified into several category based on the number and orientation of the incident line segment we provide a simple and efficient voting scheme to detect and classify these junction in real image indoor scene are typically modeled a cuboid and we formulate the problem of the cuboid layout estimation a an inference problem in a conditional random field our formulation allows the incorporation of junction feature and the training is done using structured prediction technique we outperform other single view geometry estimation method on standard datasets 
this paper present a system for image parsing or labeling each pixel in an image with it semantic category aimed at achieving broad coverage across hundred of object category many of them sparsely sampled the system combine region level feature with per exemplar sliding window detector per exemplar detector are better suited for our parsing task than traditional bounding box detector they perform well on class with little training data and high intra class variation and they allow object mask to be transferred into the test image for pixel level segmentation the proposed system achieves state of the art accuracy on three challenging datasets the largest of which contains image and label 
we present a novel algorithm for estimating the broad d geometric structure of outdoor video scene leveraging spatio temporal video segmentation we decompose a dynamic scene captured by a video into geometric class based on prediction made by region classifier that are trained on appearance and motion feature by examining the homogeneity of the prediction we combine prediction across multiple segmentation hierarchy level alleviating the need to determine the granularity a priori we built a novel extensive dataset on geometric context of video to evaluate our method consisting of over ground truth annotated outdoor video with over frame to further scale beyond this dataset we propose a semi supervised learning framework to expand the pool of labeled data with high confidence prediction obtained from unlabeled data our system produce an accurate prediction of geometric context of video achieving accuracy across main geometric class 
we address the problem of inferring the pose of an rgb d camera relative to a known d scene given only a single acquired image our approach employ a regression forest that is capable of inferring an estimate of each pixel s correspondence to d point in the scene s world coordinate frame the forest us only simple depth and rgb pixel comparison feature and doe not require the computation of feature descriptor the forest is trained to be capable of predicting correspondence at any pixel so no interest point detector are required the camera pose is inferred using a robust optimization scheme this start with an initial set of hypothesized camera pose constructed by applying the forest at a small fraction of image pixel preemptive ransac then iterates sampling more pixel at which to evaluate the forest counting inliers and refining the hypothesized pose we evaluate on several varied scene captured with an rgb d camera and observe that the proposed technique achieves highly accurate relocalization and substantially out performs two state of the art baseline 
how many labeled example are needed to estimate a classifier s performance on a new dataset we study the case where data is plentiful but label are expensive we show that by making a few reasonable assumption on the structure of the data it is possible to estimate performance curve with confidence bound using a small number of ground truth label our approach which we call semi supervised performance evaluation spe is based on a generative model for the classifier s confidence score in addition to estimating the performance of classifier on new datasets spe can be used to recalibrate a classifier by re estimating the class conditional confidence distribution 
in this paper we are interested in how semantic segmentation can help object detection towards this goal we propose a novel deformable part based model which exploit region based segmentation algorithm that compute candidate object region by bottom up clustering followed by ranking of those region our approach allows every detection hypothesis to select a segment including void and score each box in the image using both the traditional hog filter a well a a set of novel segmentation feature thus our model blend between the detector and segmentation model since our feature can be computed very efficiently given the segment we maintain the same complexity a the original dpm we demonstrate the effectiveness of our approach in pascal voc and show that when employing only a root filter our approach outperforms dalal triggs detector on all class achieving higher average ap when employing the part we outperform the original dpm in out of class achieving an improvement of ap furthermore we outperform the previous state of the art on voc test by 
despite the success of recent object class recognition system the long standing problem of partial occlusion remains a major challenge and a principled solution is yet to be found in this paper we leave the beaten path of method that treat occlusion a just another source of noise instead we include the occluder itself into the modelling by mining distinctive reoccurring occlusion pattern from annotated training data these pattern are then used a training data for dedicated detector of varying sophistication in particular we evaluate and compare model that range from standard object class detector to hierarchical part based representation of occluder occludee pair in an extensive evaluation we derive insight that can aid further development in tackling the occlusion challenge 
we introduce a new problem domain for activity recognition the analysis of child s social and communicative behavior based on video and audio data we specifically target interaction between child aged year and an adult such interaction arise naturally in the diagnosis and treatment of developmental disorder such a autism we introduce a new publicly available dataset containing over session of a minute child adult interaction in each session the adult examiner followed a semi structured play interaction protocol which wa designed to elicit a broad range of social behavior we identify the key technical challenge in analyzing these behavior and describe method for decoding the interaction we present experimental result that demonstrate the potential of the dataset to drive interesting research question and show preliminary result for multi modal activity recognition 
