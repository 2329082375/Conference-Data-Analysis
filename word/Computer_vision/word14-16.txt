a surrogate function of norm many nonconvex penalty function have been proposed to enhance the sparse vector recovery it is easy to extend these nonconvex penalty function on singular value of a matrix to enhance low rank matrix recovery however different from convex optimization solving the nonconvex low rank minimization problem is much more challenging than the nonconvex sparse minimization problem we observe that all the existing nonconvex penalty function are concave and monotonically increasing on thus their gradient are decreasing function based on this property we propose an iteratively reweighted nuclear norm irnn algorithm to solve the nonconvex nonsmooth low rank minimization problem irnn iteratively solves a weighted singular value thresholding wsvt problem by setting the weight vector a the gradient of the concave penalty function the wsvt problem ha a closed form solution in theory we prove that irnn decrease the objective function value monotonically and any limit point is a stationary point extensive experiment on both synthetic data and real image demonstrate that irnn enhances the low rank matrix recovery compared with state of the art convex algorithm 
we revisit a pioneer unsupervised learning technique called archetypal analysis which is related to successful data analysis method such a sparse coding and non negative matrix factorization since it wa proposed archetypal analysis did not gain a lot of popularity even though it produce more interpretable model than other alternative because no efficient implementation ha ever been made publicly available it application to important scientific problem may have been severely limited our goal is to bring back into favour archetypal analysis we propose a fast optimization scheme using an active set strategy and provide an efficient open source implementation interfaced with matlab r and python then we demonstrate the usefulness of archetypal analysis for computer vision task such a codebook learning signal classification and large image collection visualization 
a surrogate function of norm many nonconvex penalty function have been proposed to enhance the sparse vector recovery it is easy to extend these nonconvex penalty function on singular value of a matrix to enhance low rank matrix recovery however different from convex optimization solving the nonconvex low rank minimization problem is much more challenging than the nonconvex sparse minimization problem we observe that all the existing nonconvex penalty function are concave and monotonically increasing on thus their gradient are decreasing function based on this property we propose an iteratively reweighted nuclear norm irnn algorithm to solve the nonconvex nonsmooth low rank minimization problem irnn iteratively solves a weighted singular value thresholding wsvt problem by setting the weight vector a the gradient of the concave penalty function the wsvt problem ha a closed form solution in theory we prove that irnn decrease the objective function value monotonically and any limit point is a stationary point extensive experiment on both synthetic data and real image demonstrate that irnn enhances the low rank matrix recovery compared with state of the art convex algorithm 
we revisit a pioneer unsupervised learning technique called archetypal analysis which is related to successful data analysis method such a sparse coding and non negative matrix factorization since it wa proposed archetypal analysis did not gain a lot of popularity even though it produce more interpretable model than other alternative because no efficient implementation ha ever been made publicly available it application to important scientific problem may have been severely limited our goal is to bring back into favour archetypal analysis we propose a fast optimization scheme using an active set strategy and provide an efficient open source implementation interfaced with matlab r and python then we demonstrate the usefulness of archetypal analysis for computer vision task such a codebook learning signal classification and large image collection visualization 
we present a system that demonstrates how the compositional structure of event in concert with the compositional structure of language can interplay with the underlying focusing mechanism in video action recognition providing a medium for top down and bottom up integration a well a multi modal integration between vision and language we show how the role played by participant noun their characteristic adjective the action performed verb the manner of such action adverb and changing spatial relation between participant preposition in the form of whole sentence description mediated by a grammar guide the activity recognition process further the utility and expressiveness of our framework is demonstrated by performing three separate task in the domain of multi activity video sentence guided focus of attention generation of sentential description and query based search simply by leveraging the framework in different manner 
learning fine grained image similarity is a challenging task it need to capture between class and within class image difference this paper proposes a deep ranking model that employ deep learning technique to learn similarity metric directly from image it ha higher learning capability than model based on hand crafted feature a novel multiscale network structure ha been developed to describe the image effectively an efficient triplet sampling algorithm is also proposed to learn the model with distributed asynchronized stochastic gradient extensive experiment show that the proposed algorithm outperforms model based on hand crafted visual feature and deep classification model 
motivated by multi distribution divergence which originate in information theory we propose a notion of multi point kernel and study their application we study a class of kernel based on jensen type divergence and show that these can be extended to measure similarity among multiple point we study tensor flattening method and develop a multi point kernel spectral clustering msc method we further emphasize on a special case of the proposed kernel which is a multi point extension of the linear dot product kernel and show the existence of cubic time tensor flattening algorithm in this case finally we illustrate the usefulness of our contribution using standard data set and image segmentation task 
we develop a method for optimization in shape space i e set of surface modulo re parametrization unlike previously proposed gradient flow we achieve superlinear convergence rate through an approximation of the shape hessian which is generally hard to compute and suffers from a series of degeneracy our analysis highlight the role of mean curvature motion in comparison with first order scheme instead of surface area our approach penalizes deformation either by it dirichlet energy or total variation and hence doe not suffer from shrinkage the latter regularizer spark the development of an alternating direction method of multiplier on triangular mesh therein a conjugate gradient solver enables u to bypass formation of the gaussian normal equation appearing in the course of the overall optimization we combine all of these idea in a versatile geometric variation regularized levenberg marquardt type method applicable to a variety of shape functionals depending on intrinsic property of the surface such a normal field and curvature a well a it embedding into space promising experimental result are reported 
in large scale query by example retrieval embedding image signature in a binary space offer two benefit data compression and search efficiency while most embedding algorithm binarize both query and database signature it ha been noted that this is not strictly a requirement indeed asymmetric scheme that binarize the database signature but not the query still enjoy the same two benefit but may provide superior accuracy in this work we propose two general asymmetric distance that are applicable to a wide variety of embedding technique including locality sensitive hashing lsh locality sensitive binary code lsbc spectral hashing sh pca embedding pcae pcae with random rotation pcae rr and pcae with iterative quantization pcae itq we experiment on four public benchmark containing up to m image and show that the proposed asymmetric distance consistently lead to large improvement over the symmetric hamming distance for all binary embedding technique 
supervised hashing aim to map the original feature to compact binary code that are able to preserve label based similarity in the hamming space non linear hash function have demonstrated their advantage over linear one due to their powerful generalization capability in the literature kernel function are typically used to achieve non linearity in hashing which achieve encouraging retrieval performance at the price of slow evaluation and training time here we propose to use boosted decision tree for achieving non linearity in hashing which are fast to train and evaluate hence more suitable for hashing with high dimensional data in our approach we first propose sub modular formulation for the hashing binary code inference problem and an efficient graphcut based block search method for solving large scale inference then we learn hash function by training boosted decision tree to fit the binary code experiment demonstrate that our proposed method significantly outperforms most state of the art method in retrieval precision and training time especially for highdimensional data our method is order of magnitude faster than many method in term of training time 
pattern and texture are key characteristic of many natural object a shirt can be striped the wing of a butterfly can be veined and the skin of an animal can be scaly aiming at supporting this dimension in image understanding we address the problem of describing texture with semantic attribute we identify a vocabulary of forty seven texture term and use them to describe a large dataset of pattern collected in the wild the resulting describable texture dataset dtd is a basis to seek the best representation for recognizing describable texture attribute in image we port from object recognition to texture recognition the improved fisher vector ifv and deep convolutional network activation feature decaf and show that surprisingly they both outperform specialized texture descriptor not only on our problem but also in established material recognition datasets we also show that our describable attribute are excellent texture descriptor transferring between datasets and task in particular combined with ifv and decaf they significantly outperform the state of the art by more than on both fmd and kth tip b benchmark we also demonstrate that they produce intuitive description of material and internet image 
a number of psychological and physiological evidence suggest that early visual attention work in a coarse to fine way which lay a basis for the reverse hierarchy theory rht this theory state that attention propagates from the top level of the visual hierarchy that process gist and abstract information of input to the bottom level that process local detail inspired by the theory we develop a computational model for saliency detection in image first the original image is downsampled to different scale to constitute a pyramid then saliency on each layer is obtained by image super resolution reconstruction from the layer above which is defined a unpredictability from this coarse to fine reconstruction finally saliency on each layer of the pyramid is fused into stochastic fixation through a probabilistic model where attention initiate from the top layer and propagates downward through the pyramid extensive experiment on two standard eye tracking datasets show that the proposed method can achieve competitive result with state of the art model 
in the bag of word bow model the vocabulary is of key importance typically multiple vocabulary are generated to correct quantization artifact and improve recall however this routine is corrupted by vocabulary correlation i e overlapping among different vocabulary vocabulary correlation lead to an over counting of the indexed feature in the overlapped area or the intersection set thus compromising the retrieval accuracy in order to address the correlation problem while preserve the benefit of high recall this paper proposes a bayes merging approach to down weight the indexed feature in the intersection set through explicitly modeling the correlation problem in a probabilistic view a joint similarity on both imageand feature level is estimated for the indexed feature in the intersection set we evaluate our method on three benchmark datasets albeit simple bayes merging can be well applied in various merging task and consistently improves the baseline on multi vocabulary merging moreover bayes merging is efficient in term of both time and memory cost and yield competitive performance with the state of the art method 
recent study have demonstrated advantage of information fusion based on sparsity model for multimodal classification among several sparsity model tree structured sparsity provides a flexible framework for extraction of cross correlated information from different source and for enforcing group sparsity at multiple granularity however the existing algorithm only solves an approximated version of the cost functional and the resulting solution is not necessarily sparse at group level this paper reformulates the tree structured sparse model for multimodal classification task an accelerated proximal algorithm is proposed to solve the optimization problem which is an efficient tool for feature level fusion among either homogeneous or heterogeneous source of information in addition a fuzzy set theoretic possibilistic scheme is proposed to weight the available modality based on their respective reliability in a joint optimization problem for finding the sparsity code this approach provides a general framework for quality based fusion that offer added robustness to several sparsity based multimodal classification algorithm to demonstrate their efficacy the proposed method are evaluated on three different application multiview face recognition multimodal face recognition and target classification 
we consider discrete pairwise energy minimization problem weighted constraint satisfaction max sum labeling and method that identify a globally optimal partial assignment of variable when finding a complete optimal assignment is intractable determining optimal value for a part of variable is an interesting possibility existing method are based on different sufficient condition we propose a new sufficient condition for partial optimality which is verifiable in polynomial time invariant to reparametrization of the problem and permutation of label and includes many existing sufficient condition a special case it is derived by using a relaxation technique coherent with the relaxation for energy minimization we pose the problem of finding the maximum optimal partial assignment identifiable by the new sufficient condition a polynomial method is proposed which is guaranteed to assign same or larger part of variable find the same or larger part of optimal assignment than several existing approach the core of the method is a specially constructed linear program that identifies persistent assignment in an arbitrary multi label setting 
a simple and inexpensive low power and low bandwidth modification is made to a conventional off the shelf color video camera from which we recover multiple color frame for each of the original measured frame and each of the recovered frame can be focused at a different depth the recovery of multiple frame for each measured frame is made possible via high speed coding manifested via translation of a single coded aperture the inexpensive translation is constituted by mounting the binary code on a piezoelectric device to simultaneously recover depth information a liquid lens is modulated at high speed via a variable voltage consequently during the aforementioned coding process the liquid lens allows the camera to sweep the focus through multiple depth in addition to designing and implementing the camera fast recovery is achieved by an anytime algorithm exploiting the group sparsity of wavelet dct coefficient 
feature tracking in video is a crucial task in computer vision usually the tracking problem is handled one feature at a time using a single feature tracker like the kanade lucas tomasi algorithm or one of it derivative while this approach work quite well when dealing with high quality video and strong feature it often falter when faced with dark and noisy video containing low quality feature we present a framework for jointly tracking a set of feature which enables sharing information between the different feature in the scene we show that our method can be employed to track feature for both rigid and non rigid motion possibly of few moving body even when some feature are occluded furthermore it can be used to significantly improve tracking result in poorly lit scene where there is a mix of good and bad feature our approach doe not require direct modeling of the structure or the motion of the scene and run in real time on a single cpu core 
we propose a method for human pose estimation based on deep neural network dnns the pose estimation is formulated a a dnn based regression problem towards body joint we present a cascade of such dnn regressors which result in high precision pose estimate the approach ha the advantage of reasoning about pose in a holistic fashion and ha a simple but yet powerful formulation which capitalizes on recent advance in deep learning we present a detailed empirical analysis with state ofart or better performance on four academic benchmark of diverse real world image 
existing method on video based action recognition are generally view dependent i e performing recognition from the same view seen in the training data we present a novel multiview spatio temporal and or graph mst aog representation for cross view action recognition i e the recognition is performed on the video from an unknown and unseen view a a compositional model mst aog compactly represents the hierarchical combinatorial structure of cross view action by explicitly modeling the geometry appearance and motion variation this paper proposes effective method to learn the structure and parameter of mst aog the inference based on mst aog enables action recognition from novel view the training of mst aog take advantage of the d human skeleton data obtained from kinect camera to avoid annotating enormous multi view video frame which is error prone and time consuming but the recognition doe not need d information and is based on d video input a new multiview action d dataset ha been created and will be released extensive experiment have demonstrated that this new action representation significantly improves the accuracy and robustness for cross view action recognition on d video 
compact and discriminative visual codebooks are preferred in many visual recognition task in the literature a number of work have taken the approach of hierarchically merging visual word of an initial large sized codebook but implemented this approach with different merging criterion in this work we propose a single probabilistic framework to unify these merging criterion by identifying two key factor the function used to model class conditional distribution and the method used to estimate the distribution parameter more importantly by adopting new distribution function and or parameter estimation method our framework can readily produce a spectrum of novel merging criterion three of them are specifically focused in this work in the first criterion we adopt the multinomial distribution with bayesian method in the second criterion we integrate gaussian distribution with maximum likelihood parameter estimation in the third criterion which show the best merging performance we propose a max margin based parameter estimation method and apply it with multinomial distribution extensive experimental study is conducted to systematically analyse the performance of the above three criterion and compare them with existing one a demonstrated the best criterion obtained in our framework achieves the overall best merging performance among the comparable merging criterion developed in the literature 
in bag of word bow based image retrieval the sift visual word ha a low discriminative power so false positive match occur prevalently apart from the information loss during quantization another cause is that the sift feature only describes the local gradient distribution to address this problem this paper proposes a coupled multi index c mi framework to perform feature fusion at indexing level basically complementary feature are coupled into a multi dimensional inverted index each dimension of c mi corresponds to one kind of feature and the retrieval process vote for image similar in both sift and other feature space specifically we exploit the fusion of local color feature into c mi while the precision of visual match is greatly enhanced we adopt multiple assignment to improve recall the joint cooperation of sift and color feature significantly reduces the impact of false positive match extensive experiment on several benchmark datasets demonstrate that c mi improves the retrieval accuracy significantly while consuming only half of the query time compared to the baseline importantly we show that c mi is well complementary to many prior technique assembling these method we have obtained an map of and n s score of on holiday and ukbench datasets respectively which compare favorably with the state of the art 
we propose a method for inferring human attribute such a gender hair style clothes style expression action from image of people under large variation of viewpoint pose appearance articulation and occlusion convolutional neural net cnn have been shown to perform very well on large scale object recognition problem in the context of attribute classification however the signal is often subtle and it may cover only a small part of the image while the image is dominated by the effect of pose and viewpoint discounting for pose variation would require training on very large labeled datasets which are not presently available part based model such a poselets and dpm have been shown to perform well for this problem but they are limited by shallow low level feature we propose a new method which combine part based model and deep learning by training pose normalized cnns we show substantial improvement v state of the art method on challenging attribute classification task in unconstrained setting experiment confirm that our method outperforms both the best part based method on this problem and conventional cnns trained on the full bounding box of the person 
deep convolutional neural network have recently achieved state of the art performance on a number of image recognition benchmark including the imagenet large scale visual recognition challenge ilsvrc the winning model on the localization sub task wa a network that predicts a single bounding box and a confidence score for each object category in the image such a model capture the whole image context around the object but cannot handle multiple instance of the same object in the image without naively replicating the number of output for each instance in this work we propose a saliency inspired neural network model for detection which predicts a set of class agnostic bounding box along with a single score for each box corresponding to it likelihood of containing any object of interest the model naturally handle a variable number of instance for each class and allows for cross class generalization at the highest level of the network we are able to obtain competitive recognition performance on voc and ilsvrc while using only the top few predicted location in each image and a small number of neural network evaluation 
we propose a method for knowledge transfer between semantically related class in imagenet by transferring knowledge from the image that have bounding box annotation to the others our method is capable of automatically populating imagenet with many more bounding box the underlying assumption that object from semantically related class look alike is formalized in our novel associative embedding ae representation ae recovers the latent low dimensional space of appearance variation among image window the dimension of ae space tend to correspond to aspect of window appearance e g side view close up background we model the overlap of a window with an object using gaussian process gp regression which spread annotation smoothly through ae space the probabilistic nature of gp allows our method to perform self assessment i e assigning a quality estimate to it own output it enables trading off the amount of returned annotation for their quality a large scale experiment on class and million image demonstrates that our method outperforms state of the art method and baseline for object localization using self assessment we can automatically return bounding box annotation for of all image with high localization accuracy i e average overlap with ground truth 
the speed of optical flow algorithm is crucial for many video editing task such a slow motion synthesis selection propagation tone adjustment propagation and so on variational coarse to fine optical flow algorithm can generally produce high quality result but cannot fulfil the speed requirement of many practical application besides large motion in real world video also pose a difficult problem to coarse to fine variational approach we in this paper present a fast optical flow algorithm that can handle large displacement motion our algorithm is inspired by recent success of local method in visual correspondence searching a well a approximate nearest neighbor field algorithm the main novelty is a fast randomized edge preserving approximate nearest neighbor field algorithm which propagates self similarity pattern in addition to offset experimental result on public optical flow benchmark show that our method is significantly faster than state of the art method without compromising on quality especially when scene contain large motion finally we show some demo application by applying our technique into real world video editing task 
we introduce a simple modification of local image descriptor such a sift based on pooling gradient orientation across different domain size in addition to spatial location the resulting descriptor which we call dsp sift outperforms other method in wide baseline matching benchmark including those based on convolutional neural network despite having the same dimension of sift and requiring no training 
in this paper we provide an extensive evaluation of fixation prediction and salient object segmentation algorithm a well a statistic of major datasets our analysis identifies serious design flaw of existing salient object benchmark called the dataset design bias by over emphasising the stereotypical concept of saliency the dataset design bias doe not only create the discomforting disconnection between fixation and salient object segmentation but also misleads the algorithm designing based on our analysis we propose a new high quality dataset that offer both fixation and salient object segmentation ground truth with fixation and salient object being presented simultaneously we are able to bridge the gap between fixation and salient object and propose a novel method for salient object segmentation finally we report significant benchmark progress on existing datasets of segmenting salient object 
in this paper we propose novel method for completion from limited sample and de noising of multilinear tensor data and a an application consider d and d color video data completion and de noising we exploit the recently proposed tensor singular value decomposition t svd based on t svd the notion of multilinear rank and a related tensor nuclear norm wa proposed in to characterize informational and structural complexity of multilinear data we first show that video with linear camera motion can be represented more efficiently using t svd compared to the approach based on vectorizing or flattening of the tensor since efficiency in representation implies efficiency in recovery we outline a tensor nuclear norm penalized algorithm for video completion from missing entry application of the proposed algorithm for video recovery from missing entry is shown to yield a superior performance over existing method we also consider the problem of tensor robust principal component analysis pca for de noising d video data from sparse random corruption we show superior performance of our method compared to the matrix robust pca adapted to this setting a proposed in 
state of the art patch based image representation involve a pooling operation that aggregate statistic computed from local descriptor standard pooling operation include sumand max pooling sum pooling lack discriminability because the resulting representation is strongly influenced by frequent yet often uninformative descriptor but only weakly influenced by rare yet potentially highly informative one max pooling equalizes the influence of frequent and rare descriptorsbut is only applicable to representation that rely on count statistic such a the bag of visual word bov and it softand sparse coding extension we propose a novel pooling mechanism that achieves the same effect a max pooling but is applicable beyond the bov and especially to the state of the art fisher vector hence the name generalized max pooling gmp it involves equalizing the similarity between each patch and the pooled representation which is shown to be equivalent to re weighting the per patch statistic we show on five public image classification benchmark that the proposedgmp can lead to significant performance gain with respect toheuristic alternative 
dictionary learning algorithm or supervised deep convolution network have considerably improved the efficiency of predefined feature representation such a sift we introduce a deep scattering convolution network with complex wavelet filter over spatial and angular variable this representation brings an important improvement to result previously obtained with predefined feature over object image database such a caltech and cifar the resulting accuracy is comparable to result obtained with unsupervised deep learning and dictionary based representation this show that refining image representation by using geometric prior is a promising direction to improve image classification and it understanding 
human pose estimation is a key step to action recognition we propose a method of estimating d human pose from a single image which work in conjunction with an existing d pose joint detector d pose estimation is challenging because multiple d pose may correspond to the same d pose after projection due to the lack of depth information moreover current d pose estimator are usually inaccurate which may cause error in the d estimation we address the challenge in three way i we represent a d pose a a linear combination of a sparse set of base learned from d human skeleton ii we enforce limb length constraint to eliminate anthropomorphically implausible skeleton iii we estimate a d pose by minimizing the norm error between the projection of the d pose and the corresponding d detection the norm loss term is robust to inaccurate d joint estimation we use the alternating direction method adm to solve the optimization problem efficiently our approach outperforms the state of the art on three benchmark datasets 
to train good supervised and semi supervised object classifier it is critical that we not waste the time of the human expert who are providing the training label existing active learning strategy can have uneven performance being efficient on some datasets but wasteful on others or inconsistent just between run on the same dataset we propose perplexity based graph construction and a new hierarchical subquery evaluation algorithm to combat this variability and to release the potential of expected error reduction under some specific circumstance expected error reduction ha been one of the strongest performing informativeness criterion for active learning until now it ha also been prohibitively costly to compute for sizeable datasets we demonstrate our highly practical algorithm comparing it to other active learning measure on classification datasets that vary in sparsity dimensionality and size our algorithm is consistent over multiple run and achieves high accuracy while querying the human expert for label at a frequency that match their desired time budget 
we present a simple efficient model for learning boundary detection based on a random forest classifier our approach combine efficient clustering of training example based on a simple partitioning of the space of local edge orientation and scale dependent calibration of individual tree output probability prior to multiscale combination the resulting model outperforms published result on the challenging bsds boundary detection benchmark further on large datasets our model requires substantially le memory for training and speed up training time by a factor of over the structured forest model 
we introduce a multi scale framework for low level vision where the goal is estimating physical scene value from image data such a depth from stereo image pair the framework us a dense overlapping set of image region at multiple scale and a local model such a a slanted plane model for stereo disparity that is expected to be valid piecewise across the visual field estimation is cast a optimization over a dichotomous mixture of variable simultaneously determining which region are inliers with respect to the local model binary variable and the correct co ordinate in the local model space for each inlying region continuous variable when the region are organized into a multi scale hierarchy optimization can occur in an efficient and parallel architecture where distributed computational unit iteratively perform calculation and share information through sparse connection between parent and child the framework performs well on a standard benchmark for binocular stereo and it produce a distributional scene representation that is appropriate for combining with higher level reasoning and other low level cue 
the notion of creativity a opposed to related concept such a beauty or interestingness ha not been studied from the perspective of automatic analysis of multimedia content meanwhile short online video shared on social medium platform or micro video have arisen a a new medium for creative expression in this paper we study creative micro video in an effort to understand the feature that make a video creative and to address the problem of automatic detection of creative content defining creative video a those that are novel and have aesthetic value we conduct a crowdsourcing experiment to create a dataset of over micro video labelled a creative and non creative we propose a set of computational feature that we map to the component of our definition of creativity and conduct an analysis to determine which of these feature correlate most with creative video finally we evaluate a supervised approach to automatically detect creative video with promising result showing that it is necessary to model both aesthetic value and novelty to achieve optimal classification accuracy 
we tackle the problem of optimizing over all possible positive definite radial kernel on riemannian manifold for classification kernel method on riemannian manifold have recently become increasingly popular in computer vision however the number of known positive definite kernel on manifold remain very limited furthermore most kernel typically depend on at least one parameter that need to be tuned for the problem at hand a poor choice of kernel or of parameter value may yield significant performance drop off here we show that positive definite radial kernel on the unit n sphere the grassmann manifold and kendall s shape manifold can be expressed in a simple form whose parameter can be automatically optimized within a support vector machine framework we demonstrate the benefit of our kernel learning algorithm on object face action and shape recognition 
this paper aim at developing an integrated system of clothing co parsing in order to jointly parse a set of clothing image unsegmented but annotated with tag into semantic configuration we propose a data driven framework consisting of two phase of inference the first phase referred a image co segmentation iterates to extract consistent region on image and jointly refines the region over all image by employing the exemplar svm esvm technique in the second phase i e region colabeling we construct a multi image graphical model by taking the segmented region a vertex and incorporate several context of clothing configuration e g item location and mutual interaction the joint label assignment can be solved using the efficient graph cut algorithm in addition to evaluate our framework on the fashionista dataset we construct a dataset called ccp consisting of high resolution street fashion photo to demonstrate the performance of our system we achieve segmentation accuracy and recognition rate on the fashionista and the ccp datasets respectively which are superior compared with state of the art method 
detecting object becomes difficult when we need to deal with large shape deformation occlusion and low resolution we propose a novel approach to i handle large deformation and partial occlusion in animal a example of highly deformable object ii describe them in term of body part and iii detect them when their body part are hard to detect e g animal depicted at low resolution we represent the holistic object and body part separately and use a fully connected model to arrange template for the holistic object and body part our model automatically decouples the holistic object or body part from the model when they are hard to detect this enables u to represent a large number of holistic object and body part combination to better deal with different detectability pattern caused by deformation occlusion and or low resolution we apply our method to the six animal category in the pascal voc dataset and show that our method significantly improves state of the art by ap and provides a richer representation for object during training we use annotation for body part e g head torso etc making use of a new dataset of fully annotated object part for pascal voc which provides a mask for each part 
deformable part model and convolutional network each have achieved notable performance in object detection yet these two approach find their strength in complementary area dpms are well versed in object composition modeling fine grained spatial relationship between part likewise convnets are adept at producing powerful image feature having been discriminatively trained directly on the pixel in this paper we propose a new model that combine these two approach obtaining the advantage of each we train this model using a new structured loss function that considers all bounding box within an image rather than isolated object instance this enables the non maximal suppression nm operation previously treated a a separate post processing stage to be integrated into the model this allows for discriminative training of our combined convnet dpm nm model in end to end fashion we evaluate our system on pascal voc and datasets achieving competitive result on both benchmark 
this paper present a novel guided image filtering method using multipoint local polynomial approximation lpa with range guidance in our method the lpa is extended from a pointwise model into a multipoint model for reliable filtering and better preserving image spatial variation which usually contains the essential information in the input image in addition we develop a scheme with constant computational complexity invariant to the size of filtering kernel for generating a spatial adaptive support region around a point by using the hybrid of the local polynomial model and color intensity based range guidance the proposed method not only preserve edge but also doe a much better job in preserving spatial variation than existing popular filtering method our method prof to be effective in a number of application depth image upsampling joint image denoising detail enhancement and image abstraction experimental result show that our method produce better result than state of the art method and it is also computationally efficient 
video event detection allows intelligent indexing of video content based on event traditional approach extract feature from video frame or shot then quantize and pool the feature to form a single vector representation for the entire video though simple and efficient the final pooling step may lead to loss of temporally local information which is important in indicating which part in a long video signifies presence of the event in this work we propose a novel instance based video event detection approach we represent each video a multiple instance defined a video segment of different temporal interval the objective is to learn an instance level event detection model based on only video level label to solve this problem we propose a large margin formulation which treat the instance label a hidden latent variable and simultaneously infers the instance label a well a the instance level classification model our framework infers optimal solution that assume positive video have a large number of positive instance while negative video have the fewest one extensive experiment on large scale video event datasets demonstrate significant performance gain the proposed method is also useful in explaining the detection result by localizing the temporal segment in a video which is responsible for the positive detection 
modeling interaction of multiple co occurring object in a complex activity is becoming increasingly popular in the video domain the dynamic bayesian network dbn ha been applied to this problem in the past due to it natural ability to statistically capture complex temporal dependency however standard dbn structure learning algorithm are generatively learned require manual structure definition and or are computationally complex or restrictive we propose a novel structure learning solution that fuse the granger causality statistic a direct measure of temporal dependence with the adaboost feature selection algorithm to automatically constrain the temporal link of a dbn in a discriminative manner this approach enables u to completely define the dbn structure prior to parameter learning which reduces computational complexity in addition to providing a more descriptive structure we refer to this modeling approach a the granger constraint dbn gcdbn our experiment show how the gcdbn outperforms two of the most relevant state of the art graphical model in complex activity classification on handball video data surveillance data and synthetic data 
when building vision system that predict structured object such a image segmentation or human pose a crucial concern is performance under task specific evaluation measure e g jaccard index or average precision an ongoing research challenge is to optimize prediction so a to maximize performance on such complex measure in this work we present a simple meta algorithm that is surprisingly effective empirical min bayes risk embr take a input a pre trained model that would normally be the final product and learns three additional parameter so a to optimize performance on the complex high order task specific measure we demonstrate embr in several domain taking existing state of the art algorithm and improving performance up to simply with three extra parameter 
the underlying idea of multitask learning is that learning task jointly is better than learning each task individually in particular if only a few training example are available for each task sharing a jointly trained representation improves classification performance in this paper we propose a novel multitask learning method that learns a low dimensional representation jointly with the corresponding classifier which are then able to profit from the latent inter class correlation our method scale with respect to the original feature dimension and can be used with high dimensional image descriptor such a the fisher vector furthermore it consistently outperforms the current state of the art on the sun scene classification benchmark with varying amount of training data 
curvature ha received increasing attention a an important alternative to length based regularization in computer vision in contrast to length it preserve elongated structure and fine detail existing approach are either inefficient or have low angular resolution and yield result with strong block artifact we derive a new model for computing squared curvature based on integral geometry the model count response of straight line triple clique the corresponding energy decomposes into submodular and supermodular pairwise potential we show that this energy can be efficiently minimized even for high angular resolution using the trust region framework our result confirm that we obtain accurate and visually pleasing solution without strong artifact at reasonable runtimes 
in this work we describe a convolutional neural network cnn to accurately predict image quality without a reference image taking image patch a input the cnn work in the spatial domain without using hand crafted feature that are employed by most previous method the network consists of one convolutional layer with max and min pooling two fully connected layer and an output node within the network structure feature learning and regression are integrated into one optimization process which lead to a more effective model for estimating image quality this approach achieves state of the art performance on the live dataset and show excellent generalization ability in cross dataset experiment further experiment on image with local distortion demonstrate the local quality estimation ability of our cnn which is rarely reported in previous literature 
retinal image contain forest of mutually intersecting and overlapping venous and arterial vascular tree the geometry of these tree show adaptation to vascular disease including diabetes stroke and hypertension segmentation of the retinal vascular network is complicated by inconsistent vessel contrast fuzzy edge variable image quality medium opacity complex intersection and overlap this paper present a bayesian approach to resolving the configuration of vascular junction to correctly construct the vascular tree a probabilistic model of vascular joint terminal bridge and bifurcation and their configuration in junction is built and maximum a posteriori map estimation used to select most likely configuration the model is built using a reference set of joint extracted from the drive public domain vascular segmentation dataset and evaluated on joint from the drive test set demonstrating an accuracy of 
in this paper we introduce a new distance for robustly matching vector of d rotation a special representation of d rotation which we coin full angle quaternion faq allows u to express this distance a euclidean we apply the distance to the problem of d shape recognition from point cloud and d object tracking in color video for the former we introduce a hashing scheme for scale and translation which outperforms the previous state of the art approach on a public dataset for the latter we incorporate online subspace learning with the proposed faq representation to highlight the benefit of the new representation 
we have discovered that d reconstruction can be achieved from asingle still photographic capture due to accidental motion of thephotographer even while attempting to hold the camera still although these motion result in little baseline and therefore high depth uncertainty in theory we can combine many such measurement over the duration of the capture process a few second to achieve usable depth estimate wepresent a novel d reconstruction system tailored for this problemthat produce depth map from short video sequence from standard cameraswithout the need for multi lens optic active sensor or intentionalmotions by the photographer this result lead to the possibilitythat depth map of sufficient quality for rgb d photography application likeperspective change simulated aperture and object segmentation cancome for free for a significant fraction of still photographsunder reasonable condition 
reconstructing the shape of a d object from multi view image under unknown general illumination is a fundamental problem in computer vision and high quality reconstruction is usually challenging especially when high detail is needed this paper present a total variation tv based approach for recovering surface detail using shading and multi view stereo mv behind the approach are our two important observation the illumination over the surface of an object tends to be piecewise smooth and the recovery of surface orientation is not sufficient for reconstructing geometry which were previously overlooked thus we introduce tv to regularize the lighting and use visual hull to constrain partial vertex the reconstruction is formulated a a constrained tvminimization problem that treat the shape and lighting a unknown simultaneously an augmented lagrangian method is proposed to quickly solve the tv minimization problem a a result our approach is robust stable and is able to efficiently recover high quality of surface detail even starting with a coarse mv these advantage are demonstrated by the experiment with synthetic and real world example 
despite the fact that face detection ha been studied intensively over the past several decade the problem is still not completely solved challenging condition such a extreme pose lighting and occlusion have historically hampered traditional model based method in contrast exemplar based face detection ha been shown to be effective even under these challenging condition primarily because a large exemplar database is leveraged to cover all possible visual variation however relying heavily on a large exemplar database to deal with the face appearance variation make the detector impractical due to the high space and time complexity we construct an efficient boosted exemplar based face detector which overcomes the defect of the previous work by being faster more memory efficient and more accurate in our method exemplar a weak detector are discriminatively trained and selectively assembled in the boosting framework which largely reduces the number of required exemplar notably we propose to include non face image a negative exemplar to actively suppress false detection to further improve the detection accuracy we verify our approach over two public face detection benchmark and one personal photo album and achieve significant improvement over the state of the art algorithm in term of both accuracy and efficiency 
in this paper we present a novel online visual tracking method based on linear representation first we present a novel probability continuous outlier model pcom to depict the continuous outlier that occur in the linear representation model in the proposed model the element of the noisy observation sample can be either represented by a pca subspace with small guassian noise or treated a an arbitrary value with a uniform prior in which the spatial consistency prior is exploited by using a binary markov random field model then we derive the objective function of the pcom method the solution of which can be iteratively obtained by the outlier free least square and standard max flow min cut step finally based on the proposed pcom method we design an effective observation likelihood function and a simple update scheme for visual tracking both qualitative and quantitative evaluation demonstrate that our tracker achieves very favorable performance in term of both accuracy and speed 
interactive segmentation in which a user provides a bounding box to an object of interest for image segmentation ha been applied to a variety of application in image editing crowdsourcing computer vision and medical imaging the challenge of this semi automatic image segmentation task lie in dealing with the uncertainty of the foreground object within a bounding box here we formulate the interactive segmentation problem a a multiple instance learning mil task by generating positive bag from pixel of sweeping line within a bounding box we name this approach milcut we provide a justification to our formulation and develop an algorithm with significant performance and efficiency gain over existing state of the art system extensive experiment demonstrate the evident advantage of our approach 
a training process for facial expression recognition is usually performed sequentially in three individual stage feature learning feature selection and classifier construction extensive empirical study are needed to search for an optimal combination of feature representation feature set and classifier to achieve good recognition performance this paper present a novel boosted deep belief network bdbn for performing the three training stage iteratively in a unified loopy framework through the proposed bdbn framework a set of feature which is effective to characterize expression related facial appearance shape change can be learned and selected to form a boosted strong classifier in a statistical way a learning continues the strong classifier is improved iteratively and more importantly the discriminative capability of selected feature are strengthened a well according to their relative importance to the strong classifier via a joint fine tune process in the bdbn framework extensive experiment on two public database showed that the bdbn framework yielded dramatic improvement in facial expression analysis 
recent progress in salient object detection have exploited the boundary prior or background information to assist other saliency cue such a contrast achieving state of the art result however their usage of boundary prior is very simple fragile and the integration with other cue is mostly heuristic in this work we present new method to address these issue first we propose a robust background measure called boundary connectivity it characterizes the spatial layout of image region with respect to image boundary and is much more robust it ha an intuitive geometrical interpretation and present unique benefit that are absent in previous saliency measure second we propose a principled optimization framework to integrate multiple low level cue including our background measure to obtain clean and uniform saliency map our formulation is intuitive efficient and achieves state of the art result on several benchmark datasets 
we propose a robust and accurate method to extract the centerline and scale of tubular structure in d image and d volume existing technique rely either on filter designed to respond to ideal cylindrical structure which lose accuracy when the linear structure become very irregular or on classification which is inaccurate because location on centerline and location immediately next to them are extremely difficult to distinguish we solve this problem by reformulating centerline detection in term of a regression problem we first train regressors to return the distance to the closest centerline in scale space and we apply them to the input image or volume the centerline and the corresponding scale then correspond to the regressors local maximum which can be easily identified we show that our method outperforms state of the art technique for various d and d datasets 
in this paper we study the problem of estimating relative pose between two camera in the presence of radial distortion specifically we consider minimal problem where one of the camera ha no or known radial distortion there are three useful case for this setup with a single unknown distortion i fundamental matrix estimation where the two camera are uncalibrated ii essential matrix estimation for a partially calibrated camera pair iii essential matrix estimation for one calibrated camera and one camera with unknown focal length we study the parameterization of these three problem and derive fast polynomial solver based on gr bner basis method we demonstrate the numerical stability of the solver on synthetic data the minimal solver have also been applied to real imagery with convincing result 
most of the previous work on video action recognition use complex hand designed local feature such a sift hog and surf but these approach are implemented sophisticatedly and difficult to be extended to other sensor modality recent study discover that there are no universally best hand engineered feature for all datasets and learning feature directly from the data may be more advantageous one such endeavor is slow feature analysis sfa proposed by wiskott and sejnowski sfa can learn the invariant and slowly varying feature from input signal and ha been proved to be valuable in human action recognition it is also observed that the multi layer feature representation ha succeeded remarkably in widespread machine learning application in this paper we propose to combine sfa with deep learning technique to learn hierarchical representation from the video data itself specifically we use a two layered sfa learning structure with d convolution and max pooling operation to scale up the method to large input and capture abstract and structural feature from the video thus the proposed method is suitable for action recognition at the same time sharing the same merit of deep learning the proposed method is generic and fully automated our classification result on hollywood kth and ucf sport are competitive with previously published result to highlight some on the kth dataset our recognition rate show approximately improvement in comparison to state of the art method even without supervision or dense sampling 
ubiquitous image blur brings out a practically important question what are effective feature to differentiate between blurred and unblurred image region we address it by studying a few blur feature representation in image gradient fourier domain and data driven local filter unlike previous method which are often based on restoration mechanism our feature are constructed to enhance discriminative power and are adaptive to various blur scale in image to avail evaluation we build a new blur perception dataset containing thousand of image with labeled ground truth our result are applied to several application including blur region segmentation deblurring and blur magnification 
we consider the problem of deliberately manipulating the direct and indirect light flowing through a time varying fully general scene in order to simplify it visual analysis our approach rest on a crucial link between stereo geometry and light transport while direct light always obeys the epipolar geometry of a projector camera pair indirect light overwhelmingly doe not we show that it is possible to turn this observation into an imaging method that analyzes light transport in real time in the optical domain prior to acquisition this yield three key ability that we demonstrate in an experimental camera prototype producing a live indirect only video stream for any scene regardless of geometric or photometric complexity capturing image that make existing structured light shape recovery algorithm robust to indirect transport and turning them into one shot method for dynamic d shape capture 
in modern face recognition the conventional pipeline consists of four stage detect align represent classify we revisit both the alignment step and the representation step by employing explicit d face modeling in order to apply a piecewise affine transformation and derive a face representation from a nine layer deep neural network this deep network involves more than million parameter using several locally connected layer without weight sharing rather than the standard convolutional layer thus we trained it on the largest facial dataset to date an identity labeled dataset of four million facial image belonging to more than identity the learned representation coupling the accurate model based alignment with the large facial database generalize remarkably well to face in unconstrained environment even with a simple classifier our method reach an accuracy of on the labeled face in the wild lfw dataset reducing the error of the current state of the art by more than closely approaching human level performance 
the objective of this study is to reconstruct image from bag of visual word bovw which is the de facto standard feature for image retrieval and recognition bovw is defined here a a histogram of quantized descriptor extracted densely on a regular grid at a single scale despite it wide use no report describes reconstruction of the original image of a bovw this task is challenging for two reason bovw includes quantization error when local descriptor are assigned to visual word bovw lack spatial information of local descriptor when we count the occurrence of visual word to tackle this difficult task we use a large scale image database to estimate the spatial arrangement of local descriptor then this task creates a jigsaw puzzle problem with adjacency and global location cost of visual word solving this optimization problem is also challenging because it is known a an np hard problem we propose a heuristic but efficient method to optimize it to underscore the effectiveness of our method we apply it to bovws extracted from about different category and demonstrate that it can reconstruct the original image although the image feature lack spatial information and include quantization error 
recently the emergence of kinect system ha demonstrated the benefit of predicting an intermediate body part labeling for d human pose estimation in conjunction with rgb d imagery the availability of depth information play a critical role so an important question is whether a similar representation can be developed with sufficient robustness in order to estimate d pose from rgb image this paper provides evidence for a positive answer by leveraging a d human body part labeling in image b second order label sensitive pooling over dynamically computed region resulting from a hierarchical decomposition of the body and c iterative structured output modeling to contextualize the process based on d pose estimate for robustness and generalization we take advantage of a recent large scale d human motion capture dataset human m that also ha human body part labeling annotation available with image we provide extensive experimental study where alternative intermediate representation are compared and report a substantial error reduction over competitive discriminative baseline that regress d human pose against global hog feature 
many prevalent multi class classification approach can be unified and generalized by the output coding framework which usually consists of three phase coding learning binary classifier and decoding most of these approach focus on the first two phase and predefined distance function is used for decoding in this paper however we propose to perform learning in coding space for more adaptive decoding thereby improving overall performance ramp loss is exploited for measuring multi class decoding error the proposed algorithm ha uniform stability it is insensitive to data noise and scalable with large scale datasets generalization error bound and numerical result are given with promising outcome 
we argue that object subcategories follow a long tail distribution a few subcategories are common while many are rare we describe distributed algorithm for learning largemixture model that capture long tail distribution which are hard to model with current approach we introduce a generalized notion of mixture or subcategories that allow for example to be shared across multiple subcategories we optimize our model with a discriminative clustering algorithm that search over mixture in a distributed brute force fashion we used our scalable system to train ten of thousand of deformable mixture for voc object we demonstrate significant performance improvement particularly for object class that are characterized by large appearance variation 
a a convex relaxation of the low rank matrix factorization problem the nuclear norm minimization ha been attracting significant research interest in recent year the standard nuclear norm minimization regularizes each singular value equally to pursue the convexity of the objective function however this greatly restricts it capability and flexibility in dealing with many practical problem e g denoising where the singular value have clear physical meaning and should be treated differently in this paper we study the weighted nuclear norm minimization wnnm problem where the singular value are assigned different weight the solution of the wnnm problem are analyzed under different weighting condition we then apply the proposed wnnm algorithm to image denoising by exploiting the image nonlocal self similarity experimental result clearly show that the proposed wnnm algorithm outperforms many state of the art denoising algorithm such a bm d in term of both quantitative measure and visual perception quality 
most motion estimation algorithm optical flow layered model cannot handle large amount of occlusion in textureless region a motion is often initialized with no occlusion assumption despite that occlusion may be included in the final objective to handle such situation we propose a local layering model where motion and occlusion relationship are inferred jointly in particular the uncertainty of occlusion relationship are retained so that motion is inferred by considering all the possibility of local occlusion relationship in addition the local layering model handle articulated object with self occlusion we demonstrate that the local layering model can handle motion and occlusion well for both challenging synthetic and real sequence 
it is useful to automatically compare image based on their visual property to predict which image is brighter more feminine more blurry etc however comparative model are inherently more costly to train than their classification counterpart manually labeling all pairwise comparison is intractable so which pair should a human supervisor compare we explore active learning strategy for training relative attribute ranking function with the goal of requesting human comparison only where they are most informative we introduce a novel criterion that request a partial ordering for a set of example that minimizes the total rank margin in attribute space subject to a visual diversity constraint the setwise criterion help amortize effort by identifying mutually informative comparison and the diversity requirement safeguard against request a human viewer will find ambiguous we develop an efficient strategy to search for set that meet this criterion on three challenging datasets and experiment with live online annotator the proposed method outperforms both traditional passive learning a well a existing active rank learning method 
visual tracking is a challenging problem in computer vision most state of the art visual tracker either rely on luminance information or use simple color representation for image description contrary to visual tracking for object recognition and detection sophisticated color feature when combined with luminance have shown to provide excellent performance due to the complexity of the tracking problem the desired color feature should be computationally efficient and posse a certain amount of photometric invariance while maintaining high discriminative power this paper investigates the contribution of color in a tracking by detection framework our result suggest that color attribute provides superior performance for visual tracking we further propose an adaptive low dimensional variant of color attribute both quantitative and attribute based evaluation are performed on challenging benchmark color sequence the proposed approach improves the baseline intensity based tracker by in median distance precision furthermore we show that our approach outperforms state of the art tracking method while running at more than frame per second 
in this paper we propose a new methodology for segmenting non rigid visual object where the search procedure is onducted directly on a sparse low dimensional manifold guided by the classification result computed from a deep belief network our main contribution is the fact that we do not rely on the typical sub division of segmentation task into rigid detection and non rigid delineation instead the non rigid segmentation is performed directly where point in the sparse low dimensional can be mapped to an explicit contour representation in image space our proposal show significantly smaller search and training complexity given that the dimensionality of the manifold is much smaller than the dimensionality of the search space for rigid detection and non rigid delineation aforementioned and that we no longer require a two stage segmentation process we focus on the problem of left ventricle endocardial segmentation from ultrasound image and lip segmentation from frontal facial image using the extended cohn kanade ck database our experiment show that the use of sparse low dimensional manifold reduces the search and training complexity of current segmentation approach without a significant impact on the segmentation accuracy shown by state of the art approach 
hashing is very useful for fast approximate similarity search on large database in the unsupervised setting most hashing method aim at preserving the similarity defined by euclidean distance hash code generated by these approach only keep their hamming distance corresponding to the pairwise euclidean distance ignoring the local distribution of each data point this objective doe not hold for k nearest neighbor search in this paper we firstly propose a new adaptive similarity measure which is consistent with k nn search and prove that it lead to a valid kernel then we propose a hashing scheme which us binary code to preserve the kernel function using low rank approximation our hashing framework is more effective than existing method that preserve similarity over arbitrary kernel the proposed kernel function hashing framework and their combination have demonstrated significant advantage compared with several state of the art method 
psychophysical study show motion cue inform about shape even with unknown reflectance recent work in computer vision have considered shape recovery for an object of unknown brdf using light source or object motion this paper address the remaining problem of determining shape from the small or differential motion of the camera for unknown isotropic brdfs our theory derives a differential stereo relation that relates camera motion to depth of a surface with unknown isotropic brdf which generalizes traditional lambertian assumption under orthographic projection we show shape may not be constrained in general but two motion suffice to yield an invariant for several restricted still unknown brdfs exhibited by common material for the perspective case we show that three differential motion suffice to yield surface depth for unknown isotropic brdf and unknown directional lighting while additional constraint are obtained with restriction on brdf or lighting the limit imposed by our theory are intrinsic to the shape recovery problem and independent of choice of reconstruction method we outline with experiment how potential reconstruction method may exploit our theory we illustrate trend shared by theory on shape from motion of light object or camera relating reconstruction hardness to imaging complexity 
subspace clustering is a powerful technology for clustering data according to the underlying subspace representation based method are the most popular subspace clustering approach in recent year in this paper we analyze the grouping effect of representation based method in depth in particular we introduce the enforced grouping effect condition which greatly facilitate the analysis of grouping effect we further find that grouping effect is important for subspace clustering which should be explicitly enforced in the data self representation model rather than implicitly implied by the model a in some prior work based on our analysis we propose the smooth representation smr model we also propose a new affinity measure based on the grouping effect which prof to be much more effective than the commonly used one a a result our smr significantly outperforms the state of the art one on benchmark datasets 
given a static scene a human can trivially enumerate the myriad of thing that can happen next and characterize the relative likelihood of each in the process we make use of enormous amount of commonsense knowledge about how the world work in this paper we investigate learning this commonsense knowledge from data to overcome a lack of densely annotated spatiotemporal data we learn from sequence of abstract image gathered using crowdsourcing the abstract scene provide both object location and attribute information we demonstrate qualitatively and quantitatively that our model produce plausible scene prediction on both the abstract image a well a natural image taken from the internet 
low rank matrix recovery from a corrupted observation ha many application in computer vision conventional method address this problem by iterating between nuclear norm minimization and sparsity minimization however iterative nuclear norm minimization is computationally prohibitive for large scale data e g video analysis in this paper we propose a robust orthogonal subspace learning rosl method to achieve efficient low rank recovery our intuition is a novel rank measure on the low rank matrix that imposes the group sparsity of it coefficient under orthonormal subspace we present an efficient sparse coding algorithm to minimize this rank measure and recover the low rank matrix at quadratic complexity of the matrix size we give theoretical proof to validate that this rank measure is lower bounded by nuclear norm and it ha the same global minimum a the latter to further accelerate rosl to linear complexity we also describe a faster version rosl empowered by random sampling our extensive experiment demonstrate that both rosl and rosl provide superior efficiency against the state of the art method at the same level of recovery accuracy 
curse of dimensionality is a practical and challenging problem in image categorization especially in case with a large number of class multi class classification encounter severe computational and storage problem when dealing with these large scale task in this paper we propose hierarchical feature hashing to effectively reduce dimensionality of parameter space without sacrificing classification accuracy and at the same time exploit information in semantic taxonomy among category we provide detailed theoretical analysis on our proposed hashing method moreover experimental result on object recognition and scene classification further demonstrate the effectiveness of hierarchical feature hashing 
joint segmentation of image set is a challenging problem especially when there are multiple object with variable appearance shared among the image in the collection and the set of object present in each particular image is itself varying and unknown in this paper we present a novel method to jointly segment a set of image containing object from multiple class we first establish consistent functional map across the input image and introduce a formulation that explicitly model partial similarity across image instead of global consistency given the optimized map between pair of image multiple group of consistent segmentation function are found such that they align with segmentation cue in the image agree with the functional map and are mutually exclusive the proposed fully unsupervised approach exhibit a significant improvement over the state of the art method a shown on the co segmentation data set msrc flickr and pascal 
a k poselet is a deformable part model dpm with k part where each of the part is a poselet aligned to a specific configuration of keypoints based on ground truth annotation a separate template is used to learn the appearance of each part the part are allowed to move with respect to each other with a deformation cost that is learned at training time this model is richer than both the traditional version of poselets and dpms it enables a unified approach to person detection and keypoint prediction which barring contemporaneous approach based on cnn feature achieves state of the art keypoint prediction while maintaining competitive detection performance 
we describe an information driven active selection approach to determine which detector to deploy at which location in which frame of a video to minimize semantic class label uncertainty at every pixel with the smallest computational cost that ensures a given uncertainty bound we show minimal performance reduction compared to a paragon algorithm running all detector at all location in all frame at a small fraction of the computational cost our method can handle uncertainty in the labeling mechanism so it can handle both oracle manual annotation or noisy detector automated annotation 
the subspace segmentation problem is addressed in this paper by effectively constructing an exactly block diagonal sample affinity matrix the block diagonal structure is heavily desired for accurate sample clustering but is rather difficult to obtain most current state of the art subspace segmentation method such a ssc and lrr resort to alternative structural prior such a sparseness and low rankness to construct the affinity matrix in this work we directly pursue the block diagonal structure by proposing a graph laplacian constraint based formulation and then develop an efficient stochastic subgradient algorithm for optimization moreover two new subspace segmentation method the block diagonal ssc and lrr are devised in this work to the best of our knowledge this is the first research attempt to explicitly pursue such a block diagonal structure extensive experiment on face clustering motion segmentation and graph construction for semi supervised learning clearly demonstrate the superiority of our novelly proposed subspace segmentation method 
we present the first automatic method to remove shadow from single rgb d image using normal cue directly derived from depth we can remove hard and soft shadow while preserving surface texture and shading our key assumption is pixel with similar normal spatial location and chromaticity should have similar color a modified nonlocal matching is used to compute a shadow confidence map that localizes well hard shadow boundary thus handling hard and soft shadow within the same framework we compare our result produced using state of the art shadow removal on single rgb image and intrinsic image decomposition on standard rgb d datasets 
relative attribute learning aim to learn ranking function describing the relative strength of attribute most of current learning approach learn ranking function for each attribute independently without considering possible intrinsic relatedness among the attribute for a problem involving multiple attribute it is reasonable to assume that utilizing such relatedness among the attribute would benefit learning especially when the number of labeled training pair are very limited in this paper we proposed a relative multi attribute learning framework that integrates relative attribute into a multi task learning scheme the formulation allows u to exploit the advantage of the state of the art regularization based multi task learning for improved attribute learning in particular using joint feature learning a the case study we evaluated our framework with both synthetic data and two real datasets experimental result suggest that the proposed framework ha clear performance gain in ranking accuracy and zero shot learning accuracy over existing method of independent relative attribute learning and multi task learning 
we propose ordered subspace clustering osc to segment data drawn from a sequentially ordered union of subspace current subspace clustering technique learn the relationship within a set of data and then use a separate clustering algorithm such a ncut for final segmentation in contrast our technique under certain condition is capable of segmenting cluster intrinsically without providing the number of cluster a a parameter similar to sparse subspace clustering ssc we formulate the problem a one of finding a sparse representation but include a new penalty term to take care of sequential data we test our method on data drawn from infrared hyper spectral data video sequence and face image our experiment show that our method osc outperforms the state of the art method spatial subspace clustering spatsc low rank representation lrr and ssc 
recently there ha been a surge of interest to use branch and bound bnb optimisation for d point cloud registration while bnb guarantee globally optimal solution it is usually too slow to be practical a fundamental source of difficulty is the search for the rotation parameter in the d rigid transform in this work assuming that the translation parameter are known we focus on constructing a fast rotation search algorithm with respect to an inherently robust geometric matching criterion we propose a novel bounding function for bnb that allows rapid evaluation underpinning our bounding function is the usage of stereographic projection to precompute and spatially index all possible point match this yield a robust and global algorithm that is significantly faster than previous method to conduct full d registration the translation can be supplied by d feature matching or by another optimisation framework that provides the translation on various challenging point cloud including those taken out of lab setting our approach demonstrates superior efficiency 
the initial step of many computer vision algorithm are interest point extraction and matching in larger image set the pairwise matching of interest point descriptor between image is an important bottleneck for each descriptor in one image the approximate nearest neighbor in the other one ha to be found and checked against the second nearest neighbor to ensure the correspondence is unambiguous here we asked the question how to best decimate the list of interest point without losing match i e we aim to speed up matching by filtering out in advance those point which would not survive the matching stage it turn out that the best filtering criterion is not the response of the interest point detector which in fact is not surprising the goal of detection are repeatable and well localized point whereas the objective of the selection are point whose descriptor can be matched successfully we show that one can in fact learn to predict which descriptor are matchable and thus reduce the number of interest point significantly without losing too many match we show that this strategy a simple a it is greatly improves the matching success with the same number of point per image moreover we embed the prediction in a state of the art structure from motion pipeline and demonstrate that it also outperforms other selection method at system level 
in this paper we address the problem of jointly summarizing large set of flickr image and youtube video starting from the intuition that the characteristic of the two medium type are different yet complementary we develop a fast and easily parallelizable approach for creating not only high quality video summary but also novel structural summary of online image a storyline graph the storyline graph can illustrate various event or activity associated with the topic in a form of a branching network the video summarization is achieved by diversity ranking on the similarity graph between image and video frame the reconstruction of storyline graph is formulated a the inference of sparse time varying directed graph from a set of photo stream with assistance of video for evaluation we collect the datasets of outdoor activity consisting of m flickr image and k youtube video due to the large scale nature of our problem we evaluate our algorithm via crowdsourcing using amazon mechanical turk in our experiment we demonstrate that the proposed joint summarization approach outperforms other baseline and our own method using video or image only 
we introduce an asymmetric sparse approximate embedding optimized for fast kernel comparison operation arising in large scale visual search in contrast to other method that perform an explicit approximate embedding using kernel pca followed by a distance compression technique in ropf d which loses information at both step our method utilizes the implicit kernel representation directly in addition we empirically demonstrate that our method need no explicit training step and can operate with a dictionary of random exemplar from the dataset we evaluate our method on three benchmark image retrieval datasets sift m imagenet and m tinyimages 
in this paper higher order correlation clustering hocc is used for text line detection in natural image we treat text line detection a a graph partitioning problem where each vertex is represented by a maximally stable extremal region mser first weak hypothesis are proposed by coarsely grouping msers based on their spatial alignment and appearance consistency then higher order correlation clustering hocc is used to partition the msers into text line candidate using the hypothesis a soft constraint to enforce long range interaction we further propose a regularization method to solve the semidefinite programming problem in the inference finally we use a simple texton based texture classifier to filter out the non text area this framework allows u to naturally handle multiple orientation language and font experiment show that our approach achieves competitive performance compared to the state of the art 
we consider the design of a single vector representation for an image that embeds and aggregate a set of local patch descriptor such a sift more specifically we aim to construct a dense representation like the fisher vector or vlad though of small or intermediate size we make two contribution both aimed at regularizing the individual contribution of the local descriptor in the final representation the first is a novel embedding method that avoids the dependency on absolute distance by encoding direction the second contribution is a democratization strategy that further limit the interaction of unrelated descriptor in the aggregation stage these method are complementary and give a substantial performance boost over the state of the art in image search with short or mid size vector a demonstrated by our experiment on standard public image retrieval benchmark 
we present a new globally optimal algorithm for self calibrating a moving camera with constant parameter our method aim at estimating the dual absolute quadric daq under the rank and optionally camera center chirality constraint we employ the branch and prune paradigm and explore the space of only parameter pruning in our method relies on solving linear matrix inequality lmi feasibility and generalized eigenvalue gev problem that solely depend upon the entry of the daq these lmi and gev problem are used to rule out branch in the search tree in which a quadric not satisfying the rank and chirality condition on camera center is guaranteed not to exist the chirality lmi condition are obtained by relying on the mild assumption that the camera undergoes a rotation of no more than between consecutive view furthermore our method doe not rely on calculating bound on any particular cost function and hence can virtually optimize any objective while achieving global optimality in a very competitive running time 
computer vision algorithm make mistake in human centric application some mistake are more annoying to user than others in order to design algorithm that minimize the annoyance to user we need access to an annoyance or cost matrix that hold the annoyance of each type of mistake such matrix are not readily available especially for a wide gamut of human centric application where annoyance is tied closely to human perception to avoid having to conduct extensive user study to gather the annoyance matrix for all possible mistake we propose predicting the annoyance of previously unseen mistake by learning from example mistake and their corresponding annoyance we promote the use of attribute based representation to transfer this knowledge of annoyance our experimental result with face and scene demonstrate that our approach can predict annoyance more accurately than baseline we show that a a result our approach make le annoying mistake in a real world image retrieval application 
the essential matrix which encodes the epipolar constraint between point in two projective view is a cornerstone of modern computer vision previous work have proposed different characterization of the space of essential matrix a a riemannian manifold however they either do not consider the symmetric role played by the two view or do not fully take into account the geometric peculiarity of the epipolar constraint we address these limitation with a characterization a a quotient manifold which can be easily interpreted in term of camera pose while our main focus in on theoretical aspect we include experiment in pose averaging and show that the proposed formulation produce a meaningful distance between essential matrix 
example based texture synthesis ets ha been widely used to generate high quality texture of desired size from a small example however not all texture are equally well reproducible that way we predict how synthesizable a particular texture is by ets we introduce a dataset texture of which all image have been annotated in term of their synthesizability we design a set of texture feature such a textureness homogeneity repetitiveness and irregularity and train a predictor using these feature on the data collection this work is the first attempt to quantify this image property and we find that texture synthesizability can be learned and predicted we use this insight to trim image to part that are more synthesizable also we suggest which texture synthesis method is best suited to synthesise a given texture our approach can be seen a winner us all picking one method among several alternative ending up with an overall superior ets method such strategy could also be considered for other vision task rather than building an even stronger method choose from existing method based on some simple preprocessing 
we propose a very intuitive and simple approximation for the conventional spectral clustering method it effectively alleviates the computational burden of spectral clustering reducing the time complexity from o n to o n while capable of gaining better performance in our experiment specifically by involving a more realistic and effective distance and the k mean duality property our algorithm can handle datasets with complex cluster shape multi scale cluster and noise we also show it superiority in a series of it real application on task including digit clustering a well a image segmentation 
kurtosis of d projection provides important statistical characteristic of natural image in this work we first provide a theoretical underpinning to a recently observed phenomenon known a projection kurtosis concentration that the kurtosis of natural image over different band pas channel tend to concentrate around a typical value based on this analysis we further describe a new method to estimate the covariance matrix of correlated gaussian noise from a noise corrupted image using random band pas filter we demonstrate the effectiveness of our blind noise covariance matrix estimation method on natural image 
we present an accurate and efficient stereo matching method using locally shared label a new labeling scheme that enables spatial propagation in mrf inference using graph cut they give each pixel and region a set of candidate disparity label which are randomly initialized spatially propagated and refined for continuous disparity estimation we cast the selection and propagation of locallydefined disparity label a fusion based energy minimization the joint use of graph cut and locally shared label ha advantage over previous approach based on fusion move or belief propagation it produce submodular move deriving a subproblem optimality enables powerful randomized search help to find good smooth locally planar disparity map which are reasonable for natural scene allows parallel computation of both unary and pairwise cost our method is evaluated using the middlebury stereo benchmark and achieves first place in sub pixel accuracy 
attribute are widely used a mid level descriptor of object property in object recognition and retrieval mostly such attribute are manually pre defined based on domain knowledge and their number is fixed however pre defined attribute may fail to adapt to the property of the data at hand may not necessarily be discriminative and or may not generalize well in this work we propose a dictionary learning framework that flexibly adapts to the complexity of the given data set and reliably discovers the inherent discriminative middle level binary feature in the data we use sample relatedness information to improve the generalization of the learned dictionary to steer the structure of the attribute representation for discrimination and generalization we demonstrate that our framework is applicable to both object recognition and complex image retrieval task even with few training example moreover the learned dictionary also help classify novel object category experimental result on the animal with attribute ilsvrc and pascal voc datasets indicate that using relatedness information lead to significant performance gain over established baseline 
human are capable of perceiving a scene at a glance and obtain deeper understanding with additional time similarly visual recognition deployment should be robust to varying computational budget such situation require anytime recognition ability which is rarely considered in computer vision research we present a method for learning dynamic policy to optimize anytime performance in visual architecture our model sequentially order feature computation and performs subsequent classification crucially decision are made at test time and depend on observed data and intermediate result we show the applicability of this system to standard problem in scene and object recognition on suitable datasets we can incorporate a semantic back off strategy that give maximally specific prediction for a desired level of accuracy this provides a new view on the time course of human visual perception 
in this paper we investigate an approach for reconstructing storyline graph from large scale collection of internet image and optionally other side information such a friendship graph the storyline graph can be an effective summary that visualizes various branching narrative structure of event or activity recurring across the input photo set of a topic class in order to explore further the usefulness of the storyline graph we leverage them to perform the image sequential prediction task from which photo recommendation application can benefit we formulate the storyline reconstruction problem a an inference of sparse time varying directed graph and develop an optimization algorithm that successfully address a number of key challenge of web scale problem including global optimality linear complexity and easy parallelization with experiment on more than million of image of class and user study via amazon mechanical turk we show that the proposed algorithm improves other candidate method for both storyline reconstruction and image prediction task 
while approach based on bag of feature excel at low level action classification they are ill suited for recognizing complex event in video where concept based temporal representation currently dominate this paper proposes a novel representation that capture the temporal dynamic of windowed mid level concept detector in order to improve complex event recognition we first express each video a an ordered vector time series where each time step consists of the vector formed from the concatenated confidence of the pre trained concept detector we hypothesize that the dynamic of time series for different instance from the same event class a captured by simple linear dynamical system lds model are likely to be similar even if the instance differ in term of low level visual feature we propose a two part representation composed of fusing a singular value decomposition of block hankel matrix ssid s and a harmonic signature h computed from the corresponding eigen dynamic matrix the proposed method offer several benefit over alternate approach our approach is straightforward to implement directly employ existing concept detector and can be plugged into linear classification framework result on standard datasets such a nist s trecvid multimedia event detection task demonstrate the improved accuracy of the proposed method 
this paper present a highly efficient very accurate regression approach for face alignment our approach ha two novel component a set of local binary feature and a locality principle for learning those feature the locality principle guide u to learn a set of highly discriminative local binary feature for each facial landmark independently the obtained local binary feature are used to jointly learn a linear regression for the final output our approach achieves the state of the art result when tested on the current most challenging benchmark furthermore because extracting and regressing local binary feature is computationally very cheap our system is much faster than previous method it achieves over fps on a desktop or fps on a mobile phone for locating a few dozen of landmark 
existing method to learn visual attribute are prone to learning the wrong thing namely property that are correlated with the attribute of interest among training sample yet many proposed application of attribute rely on being able to learn the correct semantic concept corresponding to each attribute we propose to resolve such confusion by jointly learning decorrelated discriminative attribute model leveraging side information about semantic relatedness we develop a multi task learning approach that us structured sparsity to encourage feature competition among unrelated attribute and feature sharing among related attribute on three challenging datasets we show that accounting for structure in the visual attribute space is key to learning attribute model that preserve semantics yielding improved generalizability that help in the recognition and discovery of unseen object category 
global bundle adjustment usually converges to a non zero residual and produce sub optimal camera pose for local area which lead to loss of detail for highresolution reconstruction instead of trying harder to optimize everything globally we argue that we should live with the non zero residual and adapt the camera pose to local area to this end we propose a segment based approach to readjust the camera pose locally and improve the reconstruction for fine geometry detail the key idea is to partition the globally optimized structure from motion point into well conditioned segment for re optimization reconstruct their geometry individually and fuse everything back into a consistent global model this significantly reduces severe propagated error and estimation bias caused by the initial global adjustment the result on several datasets demonstrate that this approach can significantly improve the reconstruction accuracy while maintaining the consistency of the d structure between segment 
the prevalent approach to image based localization is matching interest point detected in the query image to a sparse d point cloud representing the known world the obtained correspondence are then used to recover a precise camera pose the state of the art in this field often ignores the availability of a set of d descriptor per d point for example by representing each d point by only it centroid in this paper we demonstrate that these set contain useful information that can be exploited by formulating matching a a discriminative classification problem since memory demand and computational complexity are crucial in such a setup we base our algorithm on the efficient and effective random fern principle we propose an extension which project feature to fern specific embedding space which yield improved matching rate in short runtime experiment first show that our novel formulation provides improved matching performance in comparison to the standard nearest neighbor approach and that we outperform related randomization method in our localization scenario 
this paper present a photometric stereo method that is purely pixelwise and handle general isotropic surface in a stable manner following the recently proposed sum of lobe representation of the isotropic reflectance function we constructed a constrained bivariate regression problem where the regression function is approximated by smooth bivariate bernstein polynomial the unknown normal vector wa separated from the unknown reflectance function by considering the inverse representation of the image formation process and then we could accurately compute the unknown surface normal by solving a simple and efficient quadratic programming problem extensive evaluation that showed the state of the art performance using both synthetic and real world image were performed 
we pose unseen view synthesis a a probabilistic tensor completion problem given image of people organized by their rough viewpoint we form a d appearance tensor indexed by image pose example viewpoint and image position after discovering the low dimensional latent factor that approximate that tensor we can impute it missing entry in this way we generate novel synthetic view of people even when they are observed from just one camera viewpoint we show that the inferred view are both visually and quantitatively accurate furthermore we demonstrate their value for recognizing action in unseen view and estimating viewpoint in novel image while existing method are often forced to choose between data that is either realistic or multi view our virtual view offer both thereby allowing greater robustness to viewpoint in novel image 
this paper describes a method of gait recognition from image sequence wherein a subject is accelerating or decelerating a a speed change occurs due to a change of pitch the first order derivative of a phase namely a gait stance and or stride we model this speed change using a cylindrical manifold whose azimuth and height corresponds to the phase and the stride respectively a radial basis function rbf interpolation framework is used to learn subject specific mapping matrix for mapping from manifold to image space given an input image sequence of speed transited gait of a test subject we estimate the mapping matrix of the test subject a well a the phase and stride sequence using an energy minimization framework considering the following three point fitness of the synthesized image to the input image sequence a well a to an eigenspace constructed by exemplar of training subject smoothness of the phase and the stride sequence and pitch and stride fitness to the pitch stride preference model using the estimated mapping matrix we synthesize a constant speed gait image sequence and extract a conventional period based gait feature from it for matching we conducted experiment using real speed transited gait image sequence with subject and demonstrated the effectiveness of the proposed method 
we propose a sequential optimization technique for segmenting a rectified image of a facade into semantic category our method retrieves a parsing which respect common architectural constraint and also return a certificate for global optimality contrasting the suggested method the considered facade labeling problem is typically tackled a a classification task or a grammar parsing both approach are not capable of fully exploiting the regularity of the problem therefore our technique very significantly improves the accuracy compared to the state of the art while being an order of magnitude faster in addition in of the test image we obtain a certificate for optimality 
establishing dense correspondence reliably between a pair of image is an important vision task with many application though significant advance ha been made towards estimating dense stereo and optical flow field for two image adjacent in viewpoint or in time building reliable dense correspondence field for two general image still remains largely unsolved for instance two given image sharing some content exhibit dramatic photometric and geometric variation or they depict different d scene of similar scene characteristic fundamental challenge to such an image or scene alignment task are often multifold which render many existing technique fall short of producing dense correspondence robustly and efficiently this paper present a novel approach called daisy filter flow dff to address this challenging task inspired by the recent patchmatch filter technique we leverage and extend a few established method daisy descriptor filter based efficient flow inference and the patchmatch fast search coupling and optimizing these module seamlessly with image segment a the bridge the proposed dff approach enables efficiently performing dense descriptor based correspondence field estimation in a generalized high dimensional label space which is augmented by scale and rotation experiment on a variety of challenging scene show that our dff approach estimate spatially coherent yet discontinuity preserving image alignment result both robustly and efficiently 
we introduce a method that can register challenging image from specular and poorly textured d environment on which previous approach fail we assume that a small set of reference image of the environment and a partial d model are available like previous approach we register the input image by aligning them with one of the reference image using the d information however these approach typically rely on the pixel intensity for the alignment which is prone to fail in presence of specularities or in absence of texture our main contribution is an efficient novel local descriptor that we use to describe each image location we show that we can rely on this descriptor in place of the intensity to significantly improve the alignment robustness at a minor increase of the computational cost and we analyze the reason behind the success of our descriptor 
robust multi object tracking by detection requires the correct assignment of noisy detection result to object trajectory we address this problem by proposing an online approach based on the observation that object detector primarily fail if object are significantly occluded in contrast to most existing work we only rely on geometric information to efficiently overcome detection failure in particular we exploit the spatio temporal evolution of occlusion region detector reliability and target motion prediction to robustly handle missed detection in combination with a conservative association scheme for visible object this allows for real time tracking of multiple object from a single static camera even in complex scenario our evaluation on publicly available multi object tracking benchmark datasets demonstrate favorable performance compared to the state of the art in online and offline multi object tracking 
recent year have seen a major push for face recognition technology due to the large expansion of image sharing on social network in this paper we consider the difficult task of determining parent offspring resemblance using deep learning to answer the question who do i look like although human can perform this job at a rate higher than chance it is not clear how they do it however recent study in anthropology have determined which feature tend to be the most discriminative in this study we aim to not only create an accurate system for resemblance detection but bridge the gap between study in anthropology with computer vision technique further we aim to answer two key question do offspring resemble their parent and do offspring resemble one parent more than the other we propose an algorithm that fuse the feature and metric discovered via gated autoencoders with a discriminative neural network layer that learns the optimal or what we call genetic feature to delineate parent offspring relationship we further analyze the correlation between our automatically detected feature and those found in anthropological study meanwhile our method outperforms the state of the art in kinship verification by depending on the relationship using specific father son mother daughter etc and generic model 
we present max margin boltzmann machine mmbms for object segmentation mmbms are essentially a class of conditional boltzmann machine that model the joint distribution of hidden variable and output label conditioned on input observation in addition to image to label connection we build direct image to hidden connection to facilitate global shape prediction and thus derive a simple iterated conditional mode algorithm for efficient maximum a posteriori inference we formulate a max margin objective function for discriminative training and analyze the effect of different margin function on learning we evaluate mmbms using three datasets against state of the art method to demonstrate the strength of the proposed algorithm 
face detection and facial point localization are interconnected task recently it ha been shown that solving these two task jointly with a mixture of tree of part mtp lead to state of the art result however mtp a most other method for facial point localization proposed so far requires a complete annotation of the training data at facial point level this is used to predefine the structure of the tree and to place the part correctly in this work we extend the mixture from tree to more general loopy graph in this way we can learn in a weakly supervised manner using only the face location and orientation a powerful deformable detector that implicitly aligns it part to the detected face in the image by attaching some reference point to the correct part of our detector we can then localize the facial point in term of detection our method clearly outperforms the state of the art even if competing with method that use facial point annotation during training additionally without any facial point annotation at the level of individual training image our method can localize facial point with an accuracy similar to fully supervised approach 
the state of the art in image segmentation build hierarchical segmentation structure based on analyzing local feature cue in spectral setting due to their impressive performance such segmentation approach have become building block in many computer vision application nevertheless the main bottleneck are still the computationally demanding process of local feature processing and spectral analysis in this paper we demonstrate that based on a discrete continuous optimization of oriented gradient signal we are able to provide segmentation performance competitive to state of the art on bsds even without any spectral analysis while reducing computation time by a factor of and memory demand by a factor of 
we address the problem of joint detection and segmentation of multiple object instance in an image a key step towards scene understanding inspired by data driven method we propose an exemplar based approach to the task of instance segmentation in which a set of reference image shape mask is used to find multiple object we design a novel crf framework that jointly model object appearance shape deformation and object occlusion to tackle the challenging map inference problem we derive an alternating procedure that interleaf object segmentation and shape appearance adaptation we evaluate our method on two datasets with instance label and show promising result 
in diffusion based saliency detection an image is partitioned into superpixels and mapped to a graph with superpixels a node and edge strength proportional to superpixel similarity saliency information is then propagated over the graph using a diffusion process whose equilibrium state yield the object saliency map the optimal solution is the product of a propagation matrix and a saliency seed vector that contains a prior saliency assessment this is obtained from either a bottom up saliency detector or some heuristic in this work we propose a method to learn optimal seed for object saliency two type of feature are computed per superpixel the bottom up saliency of the superpixel region and a set of mid level vision feature informative of how likely the superpixel is to belong to an object the combination of feature that best discriminates between object and background saliency is then learned using a large margin formulation of the discriminant saliency principle the propagation of the resulting saliency seed using a diffusion process is finally shown to outperform the state of the art on a number of salient object detection datasets 
this paper proposes a novel photometric stereo solution to jointly estimate surface normal and scattering parameter from a globally planar homogeneous translucent object similar to classic photometric stereo our method only requires a few a three observation of the translucent object under directional lighting naively applying classic photometric stereo result in blurred photometric normal we develop a novel blind deconvolution algorithm based on inverse rendering for recovering the sharp surface normal and the material property we demonstrate our method on a variety of translucent object 
learning a low dimensional representation of image is useful for various application in graphic and computer vision existing solution either require manually specified landmark for corresponding point in the image or are restricted to specific object or shape deformation this paper alleviates these limitation by imposing a specific model for generating image the nested composition of color shape and appearance we show that each component can be approximated by a low dimensional subspace when the others are factored out our formulation allows for efficient learning and experiment show encouraging result 
in this paper we tackle the problem of estimating the depth of a scene from a single image this is a challenging task since a single image on it own doe not provide any depth cue to address this we exploit the availability of a pool of image for which the depth is known more specifically we formulate monocular depth estimation a a discrete continuous optimization problem where the continuous variable encode the depth of the superpixels in the input image and the discrete one represent relationship between neighboring superpixels the solution to this discrete continuous optimization problem is then obtained by performing inference in a graphical model using particle belief propagation the unary potential in this graphical model are computed by making use of the image with known depth we demonstrate the effectiveness of our model in both the indoor and outdoor scenario our experimental evaluation show that our depth estimate are more accurate than existing method on standard datasets 
document image captured by a digital camera often suffer from serious geometric distortion in this paper we propose an active method to correct geometric distortion in a camera captured document image unlike many passive rectification method that rely on text line or feature extracted from image our method us two structured beam illuminating upon the document page to recover two spatial curve a developable surface is then interpolated to the curve by finding the correspondence between them the developable surface is finally flattened onto a plane by solving a system of ordinary differential equation our method is a content independent approach and can restore a corrected document image of high accuracy with undistorted content experimental result on a variety of real captured document image demonstrate the effectiveness and efficiency of the proposed method 
human gesture similar to speech and handwriting are often unique to the individual training a generic classifier applicable to everyone can be very difficult and a such it ha become a standard to use personalized classifier in speech and handwriting recognition in this paper we address the problem of personalization in the context of gesture recognition and propose a novel and extremely efficient way of doing personalization unlike conventional personalization method which learn a single classifier that later get adapted our approach learns a set portfolio of classifier during training one of which is selected for each test subject based on the personalization data we formulate classifier personalization a a selection problem and propose several algorithm to compute the set of candidate classifier our experiment show that such an approach is much more efficient than adapting the classifier parameter but can still achieve comparable or better result 
visual domain adaptation which learns an accurate classifier for a new domain using labeled image from an old domain ha shown promising value in computer vision yet still been a challenging problem most prior work have explored two learning strategy independently for domain adaptation feature matching and instance reweighting in this paper we show that both strategy are important and inevitable when the domain difference is substantially large we therefore put forward a novel transfer joint matching tjm approach to model them in a unified optimization problem specifically tjm aim to reduce the domain difference by jointly matching the feature and reweighting the instance across domain in a principled dimensionality reduction procedure and construct new feature representation that is invariant to both the distribution difference and the irrelevant instance comprehensive experimental result verify that tjm can significantly outperform competitive method for cross domain image recognition problem 
we present an efficient and scalable algorithm for segmenting d rgbd point cloud by combining depth color and temporal information using a multistage hierarchical graph based approach our algorithm process a moving window over several point cloud to group similar region over a graph resulting in an initial over segmentation these region are then merged to yield a dendrogram using agglomerative clustering via a minimum spanning tree algorithm bipartite graph matching at a given level of the hierarchical tree yield the final segmentation of the point cloud by maintaining region identity over arbitrarily long period of time we show that a multistage segmentation with depth then color yield better result than a linear combination of depth and color due to it incremental processing our algorithm can process video of any length and in a streaming pipeline the algorithm s ability to produce robust efficient segmentation is demonstrated with numerous experimental result on challenging sequence from our own a well a public rgbd data set 
we propose a real time robust to outlier and accurate solution to the perspective n point pnp problem the main advantage of our solution are twofold first it integrates the outlier rejection within the pose estimation pipeline with a negligible computational overhead and second it scalability to arbitrarily large number of correspondence given a set of d to d match we formulate pose estimation problem a a low rank homogeneous system where the solution lie on it d null space outlier correspondence are those row of the linear system which perturb the null space and are progressively detected by projecting them on an iteratively estimated solution of the null space since our outlier removal process is based on an algebraic criterion which doe not require computing the full pose and reprojecting back all d point on the image plane at each step we achieve speed gain of more than compared to ransac strategy an extensive experimental evaluation will show that our solution yield accurate result in situation with up to of outlier and can process more than correspondence in le than m 
we present a video co segmentation method that us category independent object proposal a it basic element and can extract multiple foreground object in a video set the use of object element overcomes limitation of low level feature representation in separating complex foreground and background we formulate object based co segmentation a a co selection graph in which region with foreground like characteristic are favored while also accounting for intra video and inter video foreground coherence to handle multiple foreground object we expand the co selection graph model into a proposed multi state selection graph model msg that optimizes the segmentation of different object jointly this extension into the msg can be applied not only to our co selection graph but also can be used to turn any standard graph model into a multi state selection solution that can be optimized directly by the existing energy minimization technique our experiment show that our object based multiple foreground video co segmentation method obmic compare well to related technique on both single and multiple foreground case 
photometric stereo offer the possibility of object shape reconstruction via reasoning about the amount of light reflected from oriented surface however in murky medium such a sea water the illuminating light interacts with the medium and some of it is backscattered towards the camera due to this additive light component the standard photometric stereo equation lead to poor quality shape estimation previous author have attempted to reformulate the approach but have either neglected backscatter entirely or disregarded it non uniformity on the sensor when camera and light are close to each other we show that by compensating effectively for the backscatter component a linear formulation of photometric stereo is allowed which recovers an accurate normal map using only light our backscatter compensation method for point source can be used for estimating the uneven backscatter directly from single image without any prior knowledge about the characteristic of the medium or the scene we compare our method with previous approach through extensive experimental result where a variety of object are imaged in a big water tank whose turbidity is systematically increased and show reconstruction quality which degrades little relative to clean water result even with a very significant scattering level 
while machine learning ha been instrumental to the ongoing progress in most area of computer vision it ha not been applied to the problem of stereo matching with similar frequency or success we present a supervised learning approach for predicting the correctness of stereo match based on a random forest and a set of feature that capture various form of information about each pixel we show highly competitive result in predicting the correctness of match and in confidence estimation which allows u to rank pixel according to the reliability of their assigned disparity moreover we show how these confidence value can be used to improve the accuracy of disparity map by integrating them with an mrf based stereo algorithm this is an important distinction from current literature that ha mainly focused on sparsification by removing potentially erroneous disparity to generate quasi dense disparity map 
there ha been a lot of work on face modeling analysis and landmark detection with active appearance model being one of the most successful technique a major drawback of these model is the large number of detailed annotated training example needed for learning therefore we present a transfer learning method that is able to learn from related training data using an instance weighted transfer technique our method is derived using a generalization of importance sampling and in contrast to previous work we explicitly try to tackle the transfer already during learning instead of adapting the fitting process in our studied application of face landmark detection we efficiently transfer facial expression from other human individual and are thus able to learn a precise face active appearance model only from neutral face of a single individual our approach is evaluated on two common face datasets and outperforms previous transfer method 
markov chain monte carlo mcmc is an elegant tool widely used in variety of area in computer vision it ha been used for the inference on the markov random field model mrf however mcmc le concerned than other deterministic approach although it converges to global optimal solution in theory the major obstacle is it slow convergence to come up with faster sampling method we investigate two idea breaking detailed balance and updating multiple node at a time although detailed balance is considered to be essential element of mcmc it actually is not the necessary condition for the convergence in addition exploiting the structure of mrf we introduce a new kernel which update multiple node in a scanline rather than a single node those two idea are integrated in a novel way to develop an efficient method called scanline sampler without detailed balance in experimental section we apply our method to the opengm benchmark of mrf optimization and show the proposed method achieves faster convergence than the conventional approach 
in this paper we address the problem of synthesizing novel view from a set of input image state of the art method such a the unstructured lumigraph have been using heuristic to combine information from the original view often using an explicit or implicit approximation of the scene geometry while the proposed heuristic have been largely explored and proven to work effectively a bayesian formulation wa recently introduced formalizing some of the previously proposed heuristic pointing out which physical phenomenon could lie behind each however some important heuristic were still not taken into account and lack proper formalization we contribute a new physic based generative model and the corresponding maximum a posteriori estimate providing the desired unification between heuristic based method and a bayesian formulation the key point is to systematically consider the error induced by the uncertainty in the geometric proxy we provide an extensive discussion analyzing how the obtained equation explain the heuristic developed in previous method furthermore we show that our novel bayesian model significantly improves the quality of novel view in particular if the scene geometry estimate is inaccurate 
in this paper we address the problem of object tracking in intensity image and depth data we propose a generic framework that can be used either for tracking d template in intensity image or for tracking d object in depth image to overcome problem like partial occlusion strong illumination change and motion blur that notoriously make energy minimization based tracking method get trapped in a local minimum we propose a learning based method that is robust to all these problem we use random forest to learn the relation between the parameter that defines the object s motion and the change they induce on the image intensity or the point cloud of the template it follows that to track the template when it move we use the change on the image intensity or point cloud to predict the parameter of this motion our algorithm ha an extremely fast tracking performance running at le than m per frame and is robust to partial occlusion moreover it demonstrates robustness to strong illumination change when tracking template using intensity image and robustness in tracking d object from arbitrary viewpoint even in the presence of motion blur that cause missing or erroneous data in depth image extensive experimental evaluation and comparison to the related approach strongly demonstrates the benefit of our method 
this paper present a novel and general method for the detection rectification and segmentation of imaged coplanar repeated pattern the only assumption made of the scene geometry is that repeated scene element are mapped to each other by planar euclidean transformation the class of pattern covered is broad and includes nearly all commonly seen planar man made repeated pattern in addition novel linear constraint are used to reduce geometric ambiguity between the rectified imaged pattern and the scene pattern rectification to within a similarity of the scene plane is achieved from one rotated repeat or to within a similarity with a scale ambiguity along the axis of symmetry from one reflected repeat a stratum of constraint is derived that give the necessary configuration of repeat for each successive level of rectification a generative model for the imaged pattern is inferred and used to segment the pattern with pixel accuracy qualitative result are shown on a broad range of image type on which state of the art method fail 
convolutional neural network cnns have been established a a powerful class of model for image recognition problem encouraged by these result we provide an extensive empirical evaluation of cnns on large scale video classification using a new dataset of million youtube video belonging to class we study multiple approach for extending the connectivity of a cnn in time domain to take advantage of local spatio temporal information and suggest a multiresolution foveated architecture a a promising way of speeding up the training our best spatio temporal network display significant performance improvement compared to strong feature based baseline to but only a surprisingly modest improvement compared to single frame model to we further study the generalization performance of our best model by retraining the top layer on the ucf action recognition dataset and observe significant performance improvement compared to the ucf baseline model up from 
in this work we propose a new framework for recognizing rgb image captured by the conventional camera by leveraging a set of labeled rgb d data in which the depth feature can be additionally extracted from the depth image we formulate this task a a new unsupervised domain adaptation uda problem in which we aim to take advantage of the additional depth feature in the source domain and also cope with the data distribution mismatch between the source and target domain to effectively utilize the additional depth feature we seek two optimal projection matrix to map the sample from both domain into a common space by preserving a much a possible the correlation between the visual feature and depth feature to effectively employ the training sample from the source domain for learning the target classifier we reduce the data distribution mismatch by minimizing the maximum mean discrepancy mmd criterion which compare the data distribution for each type of feature in the common space based on the above two motivation we propose a new svm based objective function to simultaneously learn the two projection matrix and the optimal target classifier in order to well separate the source sample from different class when using each type of feature in the common space an efficient alternating optimization algorithm is developed to solve our new objective function comprehensive experiment for object recognition and gender recognition demonstrate the effectiveness of our proposed approach for recognizing rgb image by learning from rgb d data 
how much data do we need to describe a location we explore this question in the context of d scene reconstruction created from running structure from motion on large internet photo collection where reconstruction can contain many million of d point we consider several method for computing much more compact representation of such reconstruction for the task of location recognition with the goal of maintaining good performance with very small model in particular we introduce a new method for computing compact model that take into account both image point relationship and feature distinctiveness and we show that this method produce small model that yield better recognition performance than previous model reduction technique 
we introduce a new approach for recognizing and reconstructing d object in image our approach is based on an analysis by synthesis strategy a forward synthesis model construct possible geometric interpretation of the world and then selects the interpretation that best agrees with the measured visual evidence the forward model synthesizes visual template defined on invariant hog feature these visual template are discriminatively trained to be accurate for inverse estimation we introduce an efficient brute force approach to inference that search through a large number of candidate reconstruction returning the optimal one one benefit of such an approach is that recognition is inherently re constructive we show state of the art performance for detection and reconstruction on two challenging d object recognition datasets of car and cuboid 
several decade of research in computer and primate vision have resulted in many model some specialized for one problem others more general and invaluable experimental data here to help focus research effort onto the hardest unsolved problem and bridge computer and human vision we define a battery of test that measure the gap between human and machine performance in several dimension generalization across scene category generalization from image to edge map and line drawing invariance to rotation and scaling local global information with jumbled image and object recognition performance we measure model accuracy and the correlation between model and human error pattern experimenting over datasets where human data is available and gauging well established model we find that none fully resembles human in all aspect and we learn from each test which model and feature are more promising in approaching human in the tested dimension across all test we find that model based on local edge histogram consistently resemble human more while several scene statistic or gist model do perform well with both scene and object while computer vision ha long been inspired by human vision we believe systematic effort such a this will help better identify shortcoming of model and find new path forward 
in this paper we focus on the d modeling of flower in particular the petal the complex structure severe occlusion and wide variation make the reconstruction of their d model a challenging task therefore even though the flower is the most distinctive part of a plant there ha been little modeling study devoted to it we overcome these challenge by combining data driven modeling technique with domain knowledge from botany taking a d point cloud of an input flower scanned from a single view our method start with a level set based segmentation of each individual petal using both appearance and d information each segmented petal is then fitted with a scale invariant morphable petal shape model which is constructed from individually scanned exemplar petal novel constraint based on botany study such a the number and spatial layout of petal are incorporated into the fitting process for realistically reconstructing occluded region and maintaining correct d spatial relation finally the reconstructed petal shape is texture mapped using the registered color image with occluded region filled in by content from visible one experiment show that our approach can obtain realistic modeling of flower even with severe occlusion and large shape size variation 
in this work we reconsider labeling problem with virtually continuous state space which are of relevance in low level computer vision in order to cope with such huge state space multi scale method have been proposed to approximately solve such labeling task although performing well in many case these method do usually not come with any guarantee on the returned solution a general and principled approach to solve labeling problem is based on the well known linear programming relaxation which appears to be prohibitive for large state space at the first glance we demonstrate that a coarse to fine exploration strategy in the label space is able to optimize the lp relaxation for non trivial problem instance with reasonable run time and moderate memory requirement 
arguably deformable part model dpms are one of the most prominent approach for face alignment with impressive result being recently reported for both controlled lab and unconstrained setting fitting in most dpm method is typically formulated a a two step process during which discriminatively trained part template are first correlated with the image to yield a filter response for each landmark and then shape optimization is performed over these filter response this process although computationally efficient is based on fixed part template which are assumed to be independent and ha been shown to result in imperfect filter response and detection ambiguity to address this limitation in this paper we propose to jointly optimize a part based trained in the wild flexible appearance model along with a global shape model which result in a joint translational motion model for the model part via gauss newton gn optimization we show how significant computational reduction can be achieved by building a full model during training but then efficiently optimizing the proposed cost function on a sparse grid using weighted least square during fitting we coin the proposed formulation gauss newton deformable part model gn dpm finally we compare it performance against the state of the art and show that the proposed gn dpm outperforms it in some case by a large margin code for our method is available from http ibug doc ic ac uk resource 
we present a method for generating object segmentation proposal from group of superpixels the goal is to propose accurate segmentation for all object of an image the proposed object hypothesis can be used a input to object detection system and thereby improve efficiency by replacing exhaustive search the segmentation are generated in a class independent manner and therefore the computational cost of the approach is independent of the number of object class our approach combine both global and local search in the space of set of superpixels the local search is implemented by greedily merging adjacent pair of superpixels to build a bottom up segmentation hierarchy the region from such a hierarchy directly provide a part of our region proposal the global search provides the other part by performing a set of graph cut segmentation on a superpixel graph obtained from an intermediate level of the hierarchy the parameter of the graph cut problem are learnt in such a manner that they provide complementary set of region experiment with pascal voc image show that we reach state of the art with greatly reduced computational cost 
recent study show that mental disorder change the functional organization of the brain which could be investigated via various imaging technique analyzing such change is becoming critical a it could provide new biomarkers for diagnosing and monitoring the progression of the disease functional connectivity analysis study the covary activity of neuronal population in different brain region the sparse inverse covariance estimation sice also known a graphical lasso is one of the most important tool for functional connectivity analysis which estimate the interregional partial correlation of the brain although being increasingly used for predicting mental disorder sice is basically a generative method that may not necessarily perform well on classifying neuroimaging data in this paper we propose a learning framework to effectively improve the discriminative power of sices by taking advantage of the sample in the opposite class we formulate our objective a convex optimization problem for both one class and two class classification by analyzing these optimization problem we not only solve them efficiently in their dual form but also gain insight into this new learning framework the proposed framework is applied to analyzing the brain metabolic covariant network built upon fdg pet image for the prediction of the alzheimer s disease and show significant improvement of classification performance for both one class and two class scenario moreover a sice is a general method for learning undirected gaussian graphical model this paper ha broader meaning beyond the scope of brain research 
capturing and understanding visual signal is one of the core interest of computer vision much progress ha been made w r t many aspect of imaging but the reconstruction of refractive phenomenon such a turbulence gas and heat flow liquid or transparent solid ha remained a challenging problem in this paper we derive an intuitive formulation of light transport in refractive medium using light field and the transport of intensity equation we show how coded illumination in combination with pair of recorded image allow for robust computational reconstruction of dynamic two and three dimensional refractive phenomenon 
we introduce a method of sparse dictionary learning for edit propagation of high resolution image or video previous approach for edit propagation typically employ a global optimization over the whole set of image pixel incurring a prohibitively high memory and time consumption for high resolution image rather than propagating an edit pixel by pixel we follow the principle of sparse representation to obtain a compact set of representative sample or feature and perform edit propagation on the sample instead the sparse set of sample provides an intrinsic basis for an input image and the coding coefficient capture the linear relationship between all pixel and the sample the representative set of sample is then optimized by a novel scheme which maximizes the kl divergence between each sample pair to remove redundant sample we show several application of sparsity based edit propagation including video recoloring theme editing and seamless cloning operating on both color and texture feature we demonstrate that with a sample to pixel ratio in the order of signifying a significant reduction on memory consumption our method still maintains a high degree of visual fidelity 
this paper describes a patchwork assembly algorithm for depth image super resolution an input low resolution depth image is disassembled into part by matching similar region on a set of high resolution training image and a super resolution image is then assembled using these corresponding matched counterpart we convert the super resolution problem into a markov random field mrf labeling problem and propose a unified formulation embedding the consistency between the resolution enhanced image and the original input the similarity of disassembled part with the corresponding region on training image the depth smoothness in local neighborhood the additional geometric constraint from self similar structure in the scene and the boundary coincidence between the resolution enhanced depth image and an optional aligned high resolution intensity image experimental result on both synthetic and real world data demonstrate that the proposed algorithm is capable of recovering high quality depth image with x resolution enhancement along each coordinate direction and that it outperforms state of the art in both qualitative and quantitative evaluation 
this paper present a framework for simultaneously tracking learning and parsing object with a hierarchical and compositional and or graph aog representation the aog is discriminatively learned online to account for the appearance e g lighting and partial occlusion and structural e g different pose and viewpoint variation of the object itself a well a the distractors e g similar object in the scene background in tracking the state of the object i e bounding box is inferred by parsing with the current aog using a spatial temporal dynamic programming dp algorithm when the aog grows big for handling object with large variation in long term tracking we propose a bottom up top down scheduling scheme for efficient inference which performs focused inference with the most stable and discriminative small sub aog during online learning the aog is re learned iteratively with two step i identifying the false positive and false negative of the current aog in a new frame by exploiting the spatial and temporal constraint observed in the trajectory ii updating the structure of the aog and re estimating the parameter based on the augmented training dataset in experiment the proposed method outperforms state of theart tracking algorithm on a recent public tracking benchmark with testing video and publicly available tracker evaluated 
we describe an approach for simultaneous localization and calibration of a stream of range image our approach jointly optimizes the camera trajectory and a calibration function that corrects the camera s unknown nonlinear distortion experiment with real world benchmark data and synthetic data show that our approach increase the accuracy of camera trajectory and geometric model estimated from range video produced by consumer grade camera 
action analysis in image and video ha been attracting more and more attention in computer vision recognizing specific action in video clip ha been the main focus we move in a new more general direction in this paper and ask the critical fundamental question what is action how is action different from motion and in a given image or video where is the action we study the philosophical and visual characteristic of action which lead u to define actionness intentional bodily movement of biological agent people animal to solve the general problem we propose the lattice conditional ordinal random field model that incorporates local evidence a well a neighboring order agreement we implement the new model in the continuous domain and apply it to scoring actionness in both image and video datasets our experiment demonstrate not only that our new model can outperform the popular ranking svm but also that indeed action is distinct from motion 
we propose an optimization algorithm for mutual information based unsupervised figure ground separation the algorithm jointly estimate the color distribution of the foreground and background and separate them based on their mutual information with geometric regularity to this end we revisit the notion of mutual information and reformulate it in term of the photometric variable and the indicator function and propose a sequential convex optimization strategy for solving the nonconvex optimization problem that arises by minimizing a sequence of convex sub problem for the mutual information based nonconvex energy we efficiently attain high quality solution for challenging unsupervised figure ground segmentation problem we demonstrate the capacity of our approach in numerous experiment that show convincing fully unsupervised figure ground separation in term of both segmentation quality and robustness to initialization 
driven by the wide range of application scene text detection and recognition have become active research topic in computer vision though extensively studied localizing and reading text in uncontrolled environment remain extremely challenging due to various interference factor in this paper we propose a novel multi scale representation for scene text recognition this representation consists of a set of detectable primitive termed a strokelets which capture the essential substructure of character at different granularity strokelets posse four distinctive advantage usability automatically learned from bounding box label robustness insensitive to interference factor generality applicable to variant language and expressivity effective at describing character extensive experiment on standard benchmark verify the advantage of strokelets and demonstrate the effectiveness of the proposed algorithm for text recognition 
detecting pedestrian at a distance from large format wide area imagery is a challenging problem because of low ground sampling distance gsd and low frame rate of the imagery in such a scenario the approach based on appearance cue alone mostly fail because pedestrian are only a few pixel in size frame differencing and optical flow based approach also give poor detection result due to noise camera jitter and parallax in aerial video to overcome these challenge we propose a novel approach to extract multi scale intrinsic motion structure feature from pedestrian s motion pattern for pedestrian detection the mims feature encodes the intrinsic motion property of an object which are location velocity and trajectory shape invariant the extracted mims representation is robust to noisy flow estimate in this paper we give a comparative evaluation of the proposed method and demonstrate that mims outperforms the state of the art approach in identifying pedestrian from low resolution airborne video 
this paper present a novel introduction of online target specific metric learning in track fragment tracklet association by network flow optimization for long term multi person tracking different from other network flow formulation each node in our network represents a tracklet and each edge represents the likelihood of neighboring tracklets belonging to the same trajectory a measured by our proposed affinity score in our method target specific similarity metric are learned which give rise to the appearance based model used in the tracklet affinity estimation trajectory based tracklets are refined by using the learned metric to account for appearance consistency and to identify reliable tracklets the metric are then re learned using reliable tracklets for computing tracklet affinity score long term trajectory are then obtained through network flow optimization occlusion and missed detection are handled by a trajectory completion step our method is effective for long term tracking even when the target are spatially close or completely occluded by others we validate our proposed framework on several public datasets and show that it outperforms several state of art method 
in this paper we present a novel real time algorithm for simultaneous pose and shape estimation for articulated object such a human being and animal the key of our pose estimation component is to embed the articulated deformation model with exponential map based parametrization into a gaussian mixture model benefiting from the probabilistic measurement model our algorithm requires no explicit point correspondence a opposed to most existing method consequently our approach is le sensitive to local minimum and well handle fast and complex motion extensive evaluation on publicly available datasets demonstrate that our method outperforms most state of art pose estimation algorithm with large margin especially in the case of challenging motion moreover our novel shape adaptation algorithm based on the same probabilistic model automatically capture the shape of the subject during the dynamic pose estimation process experiment show that our shape estimation method achieves comparable accuracy with state of the art yet requires neither parametric model nor extra calibration procedure 
in recent year fluorescence analysis of scene ha received attention fluorescence can provide additional information about scene and ha been used in application such a camera spectral sensitivity estimation d reconstruction and color relighting in particular hyperspectral image of reflective fluorescent scene provide a rich amount of data however due to the complex nature of fluorescence hyperspectral imaging method rely on specialized equipment such a hyperspectral camera and specialized illuminant in this paper we propose a more practical approach to hyperspectral imaging of reflective fluorescent scene using only a conventional rgb camera and varied colored illuminant the key idea of our approach is to exploit a unique property of fluorescence the chromaticity of fluorescence emission are invariant under different illuminant this allows u to robustly estimate spectral reflectance and fluorescence emission chromaticity we then show that given the spectral reflectance and fluorescent chromaticity the fluorescence absorption and emission spectrum can also be estimated we demonstrate in result that all scene spectrum can be accurately estimated from rgb image finally we show that our method can be used to accurately relight scene under novel lighting 
the goal of image pre compensation is to process an image such that after being convolved with a known kernel will appear close to the sharp reference image in a practical setting the pre compensated image ha significantly higher dynamic range than the latent image a a result some form of tone mapping is needed in this paper we show how global tone mapping function affect contrast and ringing in image pre compensation in particular we show that linear tone mapping eliminates ringing but incurs severe contrast loss while non linear tone mapping function such a gamma curve slightly enhances contrast but introduces ringing to enable quantitative analysis we design new metric to measure the contrast of an image with ringing specifically we set out to find it equivalent ringing free image that match it intensity histogram and us it contrast a the measure we illustrate our approach on projector defocus compensation and visual acuity enhancement compared with the state of the art our approach significantly improves the contrast we believe our technique is the first to analytically trade off between contrast and ringing 
training a generic objectness measure to produce a small set of candidate object window ha been shown to speed up the classical sliding window object detection paradigm we observe that generic object with well defined closed boundary can be discriminated by looking at the norm of gradient with a suitable resizing of their corresponding image window in to a small fixed size based on this observation and computational reason we propose to resize the window to and use the norm of the gradient a a simple d feature to describe it for explicitly training a generic objectness measure we further show how the binarized version of this feature namely binarized normed gradient bing can be used for efficient objectness estimation which requires only a few atomic operation e g add bitwise shift etc experiment on the challenging pascal voc dataset show that our method efficiently fps on a single laptop cpu generates a small set of category independent high quality object window yielding object detection rate dr with proposal increasing the number of proposal and color space for computing bing feature our performance can be further improved to dr 
sparse coding and dictionary learning have seen their application in many vision task which usually is formulated a a non convex optimization problem many iterative method have been proposed to tackle such an optimization problem however it remains an open problem to have a method that is not only practically fast but also is globally convergent in this paper we proposed a fast proximal method for solving norm based dictionary learning problem and we proved that the whole sequence generated by the proposed method converges to a stationary point with sub linear convergence rate the benefit of having a fast and convergent dictionary learning method is demonstrated in the application of image recovery and face recognition 
the functional difference between a diffuse wall and a mirror is well understood one scatter back into all direction and the other one preserve the directionality of reflected light the temporal structure of the light however is left intact by both assuming simple surface reflection photon that arrive first are reflected first in this paper we exploit this insight to recover object outside the line of sight from second order diffuse reflection effectively turning wall into mirror we formulate the reconstruction task a a linear inverse problem on the transient response of a scene which we acquire using an affordable setup consisting of a modulated light source and a time of flight image sensor by exploiting sparsity in the reconstruction domain we achieve resolution in the order of a few centimeter for object shape depth and laterally and albedo our method is robust to ambient light and work for large room sized scene it is drastically faster and le expensive than previous approach using femtosecond laser and streak camera and doe not require any moving part 
nearest neighbor search method based on hashing have attracted considerable attention for effective and efficient large scale similarity search in computer vision and information retrieval community in this paper we study the problem of learning hash function in the context of multimodal data for cross view similarity search we put forward a novel hashing method which is referred to collective matrix factorization hashing cmfh cmfh learns unified hash code by collective matrix factorization with latent factor model from different modality of one instance which can not only support cross view search but also increase the search accuracy by merging multiple view information source we also prove that cmfh a similarity preserving hashing learning method ha upper and lower boundary extensive experiment verify that cmfh significantly outperforms several state of the art method on three different datasets 
this paper considers human tracking in multi view setup and investigates a robust strategy that learns online key pose to drive a shape tracking method the interest arises in realistic dynamic scene where occlusion or segmentation error occur the corrupted observation present missing data and outlier that deteriorate tracking result we propose to use key pose of the tracked person a multiple reference model in contrast to many existing approach that rely on a single reference model multiple template represent a larger variability of human pose they provide therefore better initial hypothesis when tracking with noisy data our approach identifies these reference model online a distinctive keyframes during tracking the most suitable one is then chosen a the reference at each frame in addition taking advantage of the proximity between successive frame an efficient outlier handling technique is proposed to prevent from associating the model to irrelevant outlier the two strategy are successfully experimented with a surface deformation framework that recovers both the pose and the shape evaluation on existing datasets also demonstrate their benefit with respect to the state of the art 
fisher kernel and deep learning were two development with significant impact on large scale object categorization in the last year both approach were shown to achieve state of the art result on large scale object categorization datasets such a imagenet conceptually however they are perceived a very different and it is not uncommon for heated debate to spring up when advocate of both paradigm meet at conference or workshop in this work we emphasize the similarity between both architecture rather than their difference and we argue that such a unified view allows u to transfer idea from one domain to the other a a concrete example we introduce a method for learning a support vector machine classifier with fisher kernel at the same time a a task specific data representation we reinterpret the setting a a multi layer feed forward network it final layer is the classifier parameterized by a weight vector and the two previous layer compute fisher vector parameterized by the coefficient of a gaussian mixture model we introduce a gradient descent based learning algorithm that in contrast to other feature learning technique is not just derived from intuition or biological analogy but ha a theoretical justification in the framework of statistical learning theory our experiment show that the new training procedure lead to significant improvement in classification accuracy while preserving the modularity and geometric interpretability of a support vector machine setup 
we introduce a new compression scheme for high dimensional vector that approximates the vector using sum of m codewords coming from m different codebooks we show that the proposed scheme permit efficient distance and scalar product computation between compressed and uncompressed vector we further suggest vector encoding and codebook learning algorithm that can minimize the coding error within the proposed scheme in the experiment we demonstrate that the proposed compression can be used instead of or together with product quantization compared to product quantization and it optimized version the proposed compression approach lead to lower coding approximation error higher accuracy of approximate nearest neighbor search in the datasets of visual descriptor and lower image classification error whenever the classifier are learned on or applied to compressed vector 
when do the visual ray associated with triplet of point correspondence converge that is intersect in a common point classical model of trinocular geometry based on the fundamental matrix and trifocal tensor associated with the corresponding camera only provide partial answer to this fundamental question in large part because of underlying but seldom explicit general configuration assumption this paper us elementary tool from projective line geometry to provide necessary and sufficient geometric and analytical condition for convergence in term of transversals to triplet of visual ray without any such assumption in turn this yield a novel and simple minimal parameterization of trinocular geometry for camera with non collinear or collinear pinhole 
we are dealing with the face cluster recognition problem where there are multiple image per subject in both gallery and probe set it is never guaranteed to have a clear spatio temporal relation among the multiple image of each subject considering that the image vector of each subject either in gallery or in probe span a subspace an algorithm dual linear regression classification dlrc for the face cluster recognition problem is developed where the distance between two subspace is defined a the similarity value between a gallery subject and a probe subject dlrc attempt to find a virtual face image located in the intersection of the subspace spanning from both cluster of face image the distance between the virtual face image reconstructed from both subspace is then taken a the distance between these two subspace we further prove that such distance can be formulated under a single linear regression model where we indeed can find the distance without reconstructing the virtual face image extensive experimental evaluation demonstrated the effectiveness of dlrc algorithm compared to other algorithm 
interactive object segmentation ha great practical importance in computer vision many interactive method have been proposed utilizing user input in the form of mouse click and mouse stroke and often requiring a lot of user intervention in this paper we present a system with a far simpler input method the user need only give the name of the desired object with the tag provided by the user we do a text query of an image database to gather exemplar of the object using object proposal and borrowing idea from image retrieval and object detection the object is localized in the target image an appearance model generated from the exemplar and the location prior are used in an energy minimization framework to select the object our method outperforms the state of the art on existing datasets and on a more challenging dataset we collected 
a transient image is the optical impulse response of a scene which visualizes light propagation during an ultra short time interval in this paper we discover that the data captured by a multifrequency time of flight tof camera is the fourier transform of a transient image and identify the source of systematic error based on the discovery we propose a novel framework of frequency domain transient imaging a well a algorithm to remove systematic error the whole process of our approach is of much lower computational cost especially lower memory usage than heide et al s approach using the same device we evaluate our approach on both synthetic and real datasets 
this paper present a framework for object recognition using topological persistence in particular we show that the so called persistence diagram built from function defined on the object can serve a compact and informative descriptor for image and shape complementary to the bag of feature representation which capture the distribution of value of a given function persistence diagram can be used to characterize it structural property reflecting spatial information in an invariant way in practice the choice of function is simple each dimension of the feature vector can be viewed a a function the proposed method is general it can work on various multimedia data including d shape texture and triangle mesh extensive experiment on d shape retrieval hand gesture recognition and texture classification demonstrate the performance of the proposed method in comparison with state of the art method additionally our approach yield higher recognition accuracy when used in conjunction with the bag of feature 
assessing the visual realism of image is increasingly becoming an essential aspect of field ranging from computer graphic cg rendering to photo manipulation in this paper we systematically evaluate factor underlying human perception of visual realism and use that information to create an automated assessment of visual realism we make the following unique contribution first we established a benchmark dataset of image with empirically determined visual realism score second we identified attribute potentially related to image realism and used correlational technique to determine that realism wa most related to image naturalness familiarity aesthetic and semantics third we created an attribute motivated automated computational model that estimated image visual realism quantitatively using human assessment a a benchmark the model wa below human performance but outperformed other state of the art algorithm 
in this paper we revisit the pose determination problem of a partially calibrated camera with unknown focal length hereafter referred to a the p n pf problem by using n n d to d point correspondence our core contribution is to introduce the angle constraint and derive a compact bivariate polynomial equation for each point triplet based on this polynomial equation we propose a truly general method for the p n pf problem which is suited both to the minimal point based ransac application and also to large scale scenario with thousand of point irrespective of the d point configuration in addition by solving bivariate polynomial system via the sylvester resultant our method is very simple and easy to implement it simplicity is especially obvious when one need to develop a fast solver for the point case on the basis of the characteristic polynomial technique experiment result have also demonstrated it superiority in accuracy and efficiency when compared with the existing state of the art solution 
the basic idea of shape from shading is to infer the shape of a surface from it shading information in a single image since this problem is ill posed a number of simplifying assumption have been often used however they rarely hold in practice this paper present a simple shading correction algorithm that transforms the image to a new image that better satisfies the assumption typically needed by existing algorithm thus improving the accuracy of shape recovery the algorithm take advantage of some local shading measure that have been driven under these assumption the method is successfully evaluated on real data of human teeth with ground truth d shape 
we present a robust model to locate facial landmark under different view and possibly severe occlusion to build reliable relationship between face appearance and shape with large view variation we propose to formulate face alignment a an l induced stagewise relational dictionary srd learning problem during each training stage the srd model learns a relational dictionary to capture consistent relationship between face appearance and shape which are respectively modeled by the pose indexed image feature and the shape displacement for current estimated landmark during testing the srd model automatically selects a sparse set of the most related shape displacement for the testing face and us them to refine it shape iteratively to locate facial landmark under occlusion we further propose to learn an occlusion dictionary to model different kind of partial face occlusion by deploying the occlusion dictionary into the srd model the alignment performance for occluded face can be further improved our algorithm is simple effective and easy to implement extensive experiment on two benchmark datasets and two newly built datasets have demonstrated it superior performance over the state of the art method especially for face with large view variation and or occlusion 
in this paper we revisit the phase field approximation of ambrosio and tortorelli for the mumford shah functional we then propose a convex relaxation for it to attempt to compute globally optimal solution rather than solving the nonconvex functional directly which is the main contribution of this paper inspired by mccormick s seminal work on factorable nonconvex problem we split a nonconvex product term that appears in the ambrosio tortorelli elliptic functionals in a way that a typical alternating gradient method guarantee a globally optimal solution without completely removing coupling effect furthermore not only do we provide a fruitful analysis of the proposed relaxation but also demonstrate the capacity of our relaxation in numerous experiment that show convincing result compared to a naive extension of the mccormick relaxation and it quadratic variant indeed we believe the proposed relaxation and the idea behind would open up a possibility for convexifying a new class of function in the context of energy minimization for computer vision 
while most existing multilabel ranking method assume the availability of a single objective label ranking for each instance in the training set this paper deal with a more common case where subjective inconsistent ranking from multiple ranker are associated with each instance the key idea is to learn a latent preference distribution for each instance the proposed method mainly includes two step the first step is to generate a common preference distribution that is most compatible to all the personal ranking the second step is to learn a mapping from the instance to the preference distribution the proposed preference distribution learning pdl method is applied to the problem of multilabel ranking for natural scene image experimental result show that pdl can effectively incorporate the information given by the inconsistent ranker and perform remarkably better than the compared state of the art multilabel ranking algorithm 
recognition is graduating from lab to real world application while it is encouraging to see it potential being tapped it brings forth a fundamental challenge to the vision researcher scalability how can we learn a model for any concept that exhaustively cover all it appearance variation while requiring minimal or no human supervision for compiling the vocabulary of visual variance gathering the training image and annotation and learning the model in this paper we introduce a fully automated approach for learning extensive model for a wide range of variation e g action interaction attribute and beyond within any concept our approach leverage vast resource of online book to discover the vocabulary of variance and intertwines the data collection and modeling step to alleviate the need for explicit human supervision in training the model our approach organizes the visual knowledge about a concept in a convenient and useful way enabling a variety of application across vision and nlp our online system ha been queried by user to learn model for several interesting concept including breakfast gandhi beautiful etc to date our system ha model available for over variation within concept and ha annotated more than million image with bounding box 
over the last few year with the immense popularity of the kinect there ha been renewed interest in developing method for human gesture and action recognition from d skeletal data a number of approach have been proposed to extract representative feature from d skeletal data most commonly hard wired geometric or bio inspired shape context feature we propose a hierarchial dynamic framework that first extract high level skeletal joint feature and then us the learned representation for estimating emission probability to infer action sequence currently gaussian mixture model are the dominant technique for modeling the emission distribution of hidden markov model we show that better action recognition using skeletal feature can be achieved by replacing gaussian mixture model by deep neural network that contain many layer of feature to predict probability distribution over state of hidden markov model the framework can be easily extended to include a ergodic state to segment and recognize action simultaneously 
hashing technique ha become a promising approach for fast similarity search most of existing hashing research pursue the binary code for the same type of entity by preserving their similarity in practice there are many scenario involving nearest neighbor search on the data given in matrix form where two different type of yet naturally associated entity respectively correspond to it two dimension or view to fully explore the duality between the two view we propose a collaborative hashing scheme for the data in matrix form to enable fast search in various application such a image search using bag of word and recommendation using user item rating by simultaneously preserving both the entity similarity in each view and the interrelationship between view our collaborative hashing effectively learns the compact binary code and the explicit hash function for out of sample extension in an alternating optimization way extensive evaluation are conducted on three well known datasets for search inside a single view and search across different view demonstrating that our proposed method outperforms state of the art baseline with significant accuracy gain ranging from to relatively 
new scanning technology are increasing the importance of d mesh data and the need for algorithm that can reliably align it surface registration is important for building full d model from partial scan creating statistical shape model shape retrieval and tracking the problem is particularly challenging for non rigid and articulated object like human body while the challenge of real world data registration are not present in existing synthetic datasets establishing ground truth correspondence for real d scan is difficult we address this with a novel mesh registration technique that combine d shape and appearance information to produce high quality alignment we define a new dataset called faust that contains scan of people in a wide range of pose together with an evaluation methodology to achieve accurate registration we paint the subject with high frequency texture and use an extensive validation process to ensure accurate ground truth we find that current shape registration method have trouble with this real world data the dataset and evaluation website are available for research purpose at http faust is tue mpg de 
this paper introduces a regularization method to explicitly control the rank of a learned symmetric positive semidefinite distance matrix in distance metric learning to this end we propose to incorporate in the objective function a linear regularization term that minimizes the k smallest eigenvalue of the distance matrix it is equivalent to minimizing the trace of the product of the distance matrix with a matrix in the convex hull of rank k projection matrix called a fantope based on this new regularization method we derive an optimization scheme to efficiently learn the distance matrix we demonstrate the effectiveness of the method on synthetic and challenging real datasets of face verification and image classification with relative attribute on which our method outperforms state of the art metric learning algorithm 
the fisher vector fv representation is a high dimensional extension of the popular bag of word representation transformation of the fv by power and l normalization ha shown to significantly improve it performance and led to state of the art result for a range of image and video classification and retrieval task these normalization however render the representation non additive over local descriptor combined with it high dimensionality this make the fv computationally expensive for the purpose of localization task in this paper we present approximation to both these normalization which yield significant improvement in the memory and computational cost of the fv when used for localization second we show how these approximation can be used to define upper bound on the score function that can be efficiently evaluated which enables the use of branch and bound search a an alternative to exhaustive sliding window search we present experimental evaluation result on classification and temporal localization of action in video these show that the our approximation lead to a speedup of at least one order of magnitude while maintaining state of the art action recognition and localization performance 
in this paper we aim for zero shot classification that is visual recognition of an unseen class by using knowledge transfer from known class our main contribution is costa which exploit co occurrence of visual concept in image for knowledge transfer these inter dependency arise naturally between concept and are easy to obtain from existing annotation or web search hit count we estimate a classifier for a new label a a weighted combination of related class using the co occurrence to define the weight we propose various metric to leverage these co occurrence and a regression model for learning a weight for each related class we also show that our zero shot classifier can serve a prior for few shot learning experiment on three multi labeled datasets reveal that our proposed zero shot method are approaching and occasionally outperforming fully supervised svms we conclude that co occurrence statistic suffice for zero shot classification 
we present a distance metric based upon the notion of minimum cost injective mapping between set our function satisfies metric property a long a the cost of the minimum mapping is derived from a semimetric for which the triangle inequality is not necessarily satisfied we show that the jaccard distance alternatively biotope tanimoto or marczewski steinhaus distance may be considered the special case for finite set where cost are derived from the discrete metric extension that allow premetrics not necessarily symmetric multisets generalized to include probability distribution and asymmetric mapping are given that expand the versatility of the metric without sacrificing metric property the function ha potential application in pattern recognition machine learning and information retrieval 
partial differential equation pdes have been successful in solving many low level vision task however it is a challenging task to directly utilize pdes for visual saliency detection due to the difficulty in incorporating human perception and high level prior to a pde system instead of designing pdes with fixed formulation and boundary condition this paper proposes a novel framework for adaptively learning a pde system from an image for visual saliency detection we assume that the saliency of image element can be carried out from the relevance to the saliency seed i e the most representative salient element in this view a general linear elliptic system with dirichlet boundary lesd is introduced to model the diffusion from seed to other relevant point for a given image we first learn a guidance map to fuse human prior knowledge to the diffusion system then by optimizing a discrete submodular function constrained with this lesd and a uniform matroid the saliency seed i e boundary condition can be learnt for this image thus achieving an optimal pde system to model the evolution of visual saliency experimental result on various challenging image set show the superiority of our proposed learning based pdes for visual saliency detection 
it is often desirable to evaluate image quality with a perceptually relevant measure that doe not require a reference image recent approach to this problem use human provided quality score with machine learning to learn a measure the biggest hurdle to these effort are the difficulty of generalizing across diverse type of distortion and collecting the enormity of human scored training data that is needed to learn the measure we present a new blind image quality measure that address these difficulty by learning a robust nonlinear kernel regression function using a rectifier neural network the method is pre trained with unlabeled data and fine tuned with labeled data it generalizes across a large set of image and distortion type without the need for a large amount of labeled data we evaluate our approach on two benchmark datasets and show that it not only outperforms the current state of the art in blind image quality estimation but also outperforms the state of the art in non blind measure furthermore we show that our semi supervised approach is robust to using varying amount of labeled data 
we propose a new fully automated non rigid segmentation approach based on the distance regularized level set method that is initialized and constrained by the result of a structured inference using deep belief network this recently proposed level set formulation achieves reasonably accurate result in several segmentation problem and ha the advantage of eliminating periodic re initialization during the optimization process and a a result it avoids numerical error nevertheless when applied to challenging problem such a the left ventricle segmentation from short axis cine magnetic ressonance mr image the accuracy obtained by this distance regularized level set is lower than the state of the art the main reason behind this lower accuracy are the dependence on good initial guess for the level set optimization and on reliable appearance model we address these two issue with an innovative structured inference using deep belief network that produce reliable initial guess and appearance model the effectiveness of our method is demonstrated on the miccai left ventricle segmentation challenge where we show that our approach achieves one of the most competitive result in term of segmentation accuracy in the field 
most pedestrian detection approach that achieve high accuracy and precision rate and that can be used for real time application are based on histogram of gradient orientation usually multiscale detection is attained by resizing the image several time and by recomputing the image feature or using multiple classifier for different scale in this paper we present a pedestrian detection approach that us the same classifier for all pedestrian scale based on image feature computed for a single scale we go beyond the low level pixel wise gradient orientation bin and use higher level visual word organized into word channel boosting is used to learn classification feature from the integral word channel the proposed approach is evaluated on multiple datasets and achieves outstanding result on the inria and caltech usa benchmark by using a gpu implementation we achieve a classification rate of over million bounding box per second and a fps rate for multiscale detection in a image 
in this paper we would like to evaluate online learning algorithm for large scale visual recognition using state of the art feature which are preselected and held fixed today combination of high dimensional feature and linear classifier are widely used for large scale visual recognition numerous so called mid level feature have been developed and mutually compared on an experimental basis although various learning method for linear classification have also been proposed in the machine learning and natural language processing literature they have rarely been evaluated for visual recognition therefore we give guideline via investigation of state of the art online learning method of linear classifier many method have been evaluated using toy data and natural language processing problem such a document classification consequently we gave those method a unified interpretation from the viewpoint of visual recognition result of controlled comparison indicate three guideline that might change the pipeline for visual recognition 
reconstructing a surface image from corrupted gradient field is a crucial step in many imaging application where a gradient field is subject to both noise and unlocalized outlier resulting typically in a non integrable field we present in this paper a new optimization method for robust surface reconstruction the proposed formulation is based on a triple sparsity prior a sparse prior on the residual gradient field and a double sparse prior on the surface gradient we develop an efficient alternate minimization strategy to solve the proposed optimization problem the method is able to recover a good quality surface from severely corrupted gradient thanks to it ability to handle both noise and outlier we demonstrate the performance of the proposed method on synthetic and real data experiment show that the proposed solution outperforms some existing method in the three possible case noise only outlier only and mixed noise outlier 
topic modeling based on latent dirichlet allocation lda ha been a framework of choice to deal with multimodal data such a in image annotation task recently a new type of topic model called the document neural autoregressive distribution estimator docnade wa proposed and demonstrated state of the art performance for text document modeling in this work we show how to successfully apply and extend this model to multimodal data such a simultaneous image classification and annotation specifically we propose supdocnade a supervised extension of docnade that increase the discriminative power of the hidden topic feature by incorporating label information into the training objective of the model and show how to employ supdocnade to learn a joint representation from image visual word annotation word and class label information we also describe how to leverage information about the spatial position of the visual word for supdocnade to achieve better performance in a simple yet effective manner we test our model on the labelme and uiuc sport datasets and show that it compare favorably to other topic model such a the supervised variant of lda and a spatial matching pyramid spm approach 
scribble in scribble based interactive segmentation such a graph cut are usually assumed to be perfectly accurate i e foreground scribble pixel will never be segmented a background in the final segmentation however it can be hard to draw perfectly accurate scribble especially on fine structure of the image or on mobile touch screen device in this paper we propose a novel ratio energy function that tolerates error in the user input while encouraging maximum use of the user input information more specifically the ratio energy aim to minimize the graph cut energy while maximizing the user input respected in the segmentation the ratio energy function can be exactly optimized using an efficient iterated graph cut algorithm the robustness of the proposed method is validated on the grabcut dataset using both synthetic scribble and manual scribble the experimental result show that the proposed algorithm is robust to the error in the user input and preserve the anchoring capability of the user input 
in this paper we present the first local descriptor designed for dynamic surface a dynamic surface is a surface that can undergo non rigid deformation e g human body surface using state of the art technology detail on dynamic surface such a cloth wrinkle or facial expression can be accurately reconstructed hence various result e g surface rigidity or elasticity could be derived by microscopic categorization of surface element we propose a timing based descriptor to model local spatiotemporal variation of surface intrinsic property the low level descriptor encodes gap between local event dynamic of neighboring keypoints using timing structure of linear dynamical system lds we also introduce the bag of timing bot paradigm for surface dynamic characterization experiment are performed on synthesized and real world datasets we show the proposed descriptor can be used for challenging dynamic surface classification and segmentation with respect to rigidity at surface keypoints 
real world video of human activity exhibit temporal structure at various scale long video are typically composed out of multiple action instance where each instance is itself composed of sub action with variable duration and ordering temporal grammar can presumably model such hierarchical structure but are computationally difficult to apply for long video stream we describe simple grammar that capture hierarchical temporal structure while admitting inference with a finite state machine this make parsing linear time constant storage and naturally online we train grammar parameter using a latent structural svm where latent subactions are learned automatically we illustrate the effectiveness of our approach over common baseline on a new half million frame dataset of continuous youtube video 
in this paper we present a conceptually simple but surprisingly powerful method for visual prediction which combine the effectiveness of mid level visual element with temporal modeling our framework can be learned in a completely unsupervised manner from a large collection of video however more importantly because our approach model the prediction framework on these mid level element we can not only predict the possible motion in the scene but also predict visual appearance how are appearance going to change with time this yield a visual hallucination of probable event on top of the scene we show that our method is able to accurately predict and visualize simple future event we also show that our approach is comparable to supervised method for event prediction 
this paper present a novel method to generate a hypothesis set of class independent object region it ha been shown that such object region can be used to focus computer vision technique on the part of an image that matter most leading to significant improvement in both object localisation and semantic segmentation in recent year of course the higher quality of class independent object region the better subsequent computer vision algorithm can perform in this paper we focus on generating higher quality object hypothesis we start from an oversegmentation for which we propose to extract a wide variety of region feature we group region together in a hierarchical fashion for which we train a random forest which predicts at each stage of the hierarchy the best possible merge hence unlike other approach we use relatively powerful feature and classifier at an early stage of the generation of likely object region finally we identify and combine stable region in order to capture object which consist of dissimilar part we show on the pascal and datasets that our method yield higher quality region than competing approach while it is at the same time more computationally efficient 
several popular and effective object detector separately model intra class variation arising from deformation and appearance change this reduces model complexity while enabling the detection of object across change in viewpoint object pose etc the deformable part model dpm is perhaps the most successful such model to date a common assumption is that the exponential number of template enabled by a dpm is critical to it success in this paper we show the counter intuitive result that it is possible to achieve similar accuracy using a small dictionary of deformation each component in our model is represented by a single hog template and a dictionary of flow field that determine the deformation the template may undergo while the number of candidate deformation is dramatically fewer than that for a dpm the deformed template tend to be plausible and interpretable in addition we discover that the set of deformation base is actually transferable across object category and that learning shared base across similar category can boost accuracy 
a video capture a sequence and interaction of concept that can be static for instance object or scene or dynamic such a action for large datasets containing hundred of thousand of image or video it is impractical to manually annotate all the concept or all the instance of a single concept however a dictionary with visuallydistinct element can be created automatically from unlabeled video which can capture and express the entire dataset the downside to this machine discovered dictionary is meaninglessness i e it element are devoid of semantics and interpretation in this paper we present an approach that leverage the strength of semantic concept and the machine discovered dove by learning a relationship between them since instance of a semantic concept share visual similarity the proposed approach us softconsensus regularization to learn the mapping that enforces instance from each semantic concept to have similar representation the testing is performed by projecting the query onto the dove a well a new representation of semantic concept from training with non negativity and unit summation constraint for probabilistic interpretation we tested our formulation on trecvid med and sin task and obtained encouraging result 
outlier are pervasive in many computer vision and pattern recognition problem automatically eliminating outlier scattering among practical data collection becomes increasingly important especially for internet inspired vision application in this paper we propose a novel one class learning approach which is robust to contamination of input training data and able to discover the outlier that corrupt one class of data source our approach work under a fully unsupervised manner differing from traditional one class learning supervised by known positive label by design our approach optimizes a kernel based max margin objective which jointly learns a large margin one class classifier and a soft label assignment for inliers and outlier an alternating optimization algorithm is then designed to iteratively refine the classifier and the labeling achieving a provably convergent solution in only a few iteration extensive experiment conducted on four image datasets in the presence of artificial and real world outlier demonstrate that the proposed approach is considerably superior to the state of the art in obliterating outlier from contaminated one class of image exhibiting strong robustness at a high outlier proportion up to 
dynamic bayesian network such a hidden markov model hmms are successfully used a probabilistic model for human motion the use of hidden variable make them expressive model but inference is only approximate and requires procedure such a particle filter or markov chain monte carlo method in this work we propose to instead use simple markov model that only model observed quantity we retain a highly expressive dynamic model by using interaction that are nonlinear and non parametric a presentation of our approach in term of latent variable show logarithmic growth for the computation of exact log likelihood in the number of latent state we validate our model on human motion capture data and demonstrate state of the art performance on action recognition and motion completion task 
the main contribution of this work is a framework to register anatomical structure characterized a a point set where each point ha an associated symmetric matrix these matrix can represent problem dependent characteristic of the registered structure for example in airway matrix can represent the orientation and thickness of the structure our framework relies on a dense tensor field representation which we implement sparsely a a kernel mixture of tensor field we equip the space of tensor field with a norm that serf a a similarity measure to calculate the optimal transformation between two structure we minimize this measure using an analytical gradient for the similarity measure and the deformation field which we restrict to be a diffeomorphism we illustrate the value of our tensor field model by comparing our result with scalar and vector field based model finally we evaluate our registration algorithm on synthetic data set and validate our approach on manually annotated airway tree 
in this work we propose a technique to combine bottom up segmentation coming in the form of slic superpixels with sliding window detector such a deformable part model dpms the merit of our approach lie in cleaning up the low level hog feature by exploiting the spatial support of slic superpixels this can be understood a using segmentation to split the feature variation into object specific and background change rather than committing to a single segmentation we use a large pool of slic superpixels and combine them in a scale positionand object dependent manner to build soft segmentation mask the segmentation mask can be computed fast enough to repeat this process over every candidate window during training and detection for both the root and part filter of dpms we use these mask to construct enhanced background invariant feature to train dpms we test our approach on the pascal voc outperforming the standard dpm in out of class yielding an average increase of ap additionally we demonstrate the robustness of this approach extending it to dense sift descriptor for large displacement optical flow 
we address the false response influence problem when learning and applying discriminative part to construct the mid level representation in scene classification it is often caused by the complexity of latent image structure when convolving part filter with input image this problem make mid level representation even after pooling not distinct enough to classify input data correctly to category our solution is to learn important spatial pooling region along with their appearance the experiment show that this new framework suppresses false response and produce improved result on several datasets including mit indoor scene and uiuc sport when combined with global image feature our method achieves state of the art performance on these datasets 
scan line optimization via cost accumulation ha become very popular for stereo estimation in computer vision application and is often combined with a semi global cost integration strategy known a sgm this paper introduces this combination a a general and effective optimization technique it is the first time that this concept is applied to d medical image registration the presented algorithm sgm d employ a coarse to fine strategy and reduces the search space dimension for consecutive pyramid level by a fixed linear rate this allows it to handle large displacement to an extent that is required for clinical application in high dimensional data sgm d is evaluated in context of pulmonary motion analysis on the recently extended dir lab benchmark that provides ten d computed tomography ct image data set a well a ten challenging d ct scan pair from the copdgene study archive result show that both registration error a well a run time performance are very competitive with current state of the art method 
many computer vision algorithm employ subspace model to represent data many of these approach benefit from the ability to create an average or prototype for a set of subspace the most popular method in these situation is the karcher mean also known a the riemannian center of mass the prevalence of the karcher mean may lead some to assume that it provides the best average in all scenario however other subspace average that appear le frequently in the literature may be more appropriate for certain task the extrinsic manifold mean the l median and the flag mean are alternative average that can be substituted directly for the karcher mean in many application this paper evaluates the characteristic and performance of these four average on synthetic and real world data while the karcher mean generalizes the euclidean mean to the grassman manifold we show that the extrinsic manifold mean the l median and the flag mean behave more like median and are therefore more robust to the presence of outlier among the subspace being averaged we also show that while the karcher mean and l median are computed using iterative algorithm the extrinsic manifold mean and flag mean can be found analytically and are thus order of magnitude faster in practice finally we show that the flag mean is a generalization of the extrinsic manifold mean that permit subspace with different number of dimension to be averaged the result is a cookbook that map algorithm constraint and data property to the most appropriate subspace mean for a given application 
this paper proposes a new vectorial total variation prior vtv for color image different from existing vtvs our vtv named the decorrelated vectorial total variation prior d vtv measure the discrete gradient of the luminance component and that of the chrominance one in a separated manner which significantly reduces undesirable uneven color effect moreover a higher order generalization of the d vtv which we call the decorrelated vectorial total generalized variation prior d vtgv is also developed for avoiding the staircasing effect that accompanies the use of vtvs a noteworthy property of the d vt g v is that it enables u to efficiently minimize objective function involving it by a primal dual splitting method experimental result illustrate their utility 
current human in the loop fine grained visual categorization system depend on a predefined vocabulary of attribute and part usually determined by expert in this work we move away from that expert driven and attribute centric paradigm and present a novel interactive classification system that incorporates computer vision and perceptual similarity metric in a unified framework at test time user are asked to judge relative similarity between a query image and various set of image these general query do not require expert defined terminology and are applicable to other domain and basic level category enabling a flexible efficient and scalable system for fine grained categorization with human in the loop our system outperforms existing state of the art system for relevance feedback based image retrieval a well a interactive classification resulting in a reduction of up to in the average number of question needed to correctly classify an image 
given two image we want to predict which exhibit a particular visual attribute more than the other even when the two image are quite similar existing relative attribute method rely on global ranking function yet rarely will the visual cue relevant to a comparison be constant for all data nor will human perception of the attribute necessarily permit a global ordering to address these issue we propose a local learning approach for fine grained visual comparison given a novel pair of image we learn a local ranking model on the fly using only analogous training comparison we show how to identify these analogous pair using learned metric with result on three challenging datasets including a large newly curated dataset for fine grained comparison our method outperforms state of the art method for relative attribute prediction 
low cost rgb d imaging system such a kinect is widely utilized for dense d reconstruction however rgb d system generally suffers from two main problem the spatial resolution of the depth image is low the depth image often contains numerous hole where no depth measurement are available this can be due to bad infra red reflectance property of some object in the scene since the spatial resolution of the color image is generally higher than that of the depth image this paper introduces a new method to enhance the depth image captured by a moving rgb d system using the depth cue from the induced optical flow we not only fill the hole in the raw depth image but also recover fine detail of the imaged scene we address the problem of depth image enhancement by minimizing an energy functional in order to reduce the computational complexity we have treated the textured and homogeneous region in the color image differently experimental result on several rgb d sequence are provided to show the effectiveness of the proposed method 
the objective of this work is to accurately and efficiently detect configuration of one or more people in edited tv material such configuration often appear in standard arrangement due to cinematic style and we take advantage of this to provide scene context we make the following contribution first we introduce a new learnable context aware configuration model for detecting set of people in tv material that predicts the scale and location of each upper body in the configuration second we show that inference of the model can be solved globally and efficiently using dynamic programming and implement a maximum margin learning framework and third we show that the configuration model substantially outperforms a deformable part model dpm for predicting upper body location in video frame even when the dpm is equipped with the context of other upper body experiment are performed over two datasets the tv human interaction dataset and episode from four different tv show we also demonstrate the benefit of the model in recognizing interaction in tv show 
state of the art general purpose blind image quality assessment biqa model rely on example of distorted image and corresponding human opinion score to learn a regression function that map image feature to a quality score these type of model are considered opinion aware oa biqa model a large set of human scored training example is usually required to train a reliable oa biqa model however obtaining human opinion score through subjective testing is often expensive and time consuming it is therefore desirable to develop opinion free of biqa model that do not require human opinion score for training this paper proposes bliss blind learning of image quality using synthetic score bliss is a simple yet effective method for extending oa biqa model to of biqa model instead of training on human opinion score we propose to train biqa model on synthetic score derived from full reference fr iqa measure state of the art fr measure yield high correlation with human opinion score and can serve a approximation to human opinion score unsupervised rank aggregation is applied to combine different fr measure to generate a synthetic score which serf a a better gold standard extensive experiment on standard iqa datasets show that bliss significantly outperforms previous of biqa method and is comparable to state of the art oa biqa method 
in this paper we propose a novel labeling cost for multiview reconstruction existing approach use data term with specific weakness that are vulnerable to common challenge such a low textured region or specularities our new probabilistic method implicitly discard outlier and can be shown to become more exact the closer we get to the true object surface our approach achieves top result among all published method on the middlebury dino sparse dataset and also delivers accurate result on several other datasets with widely varying challenge for which it work in unchanged form 
this paper introduces a new color transfer method which is a process of transferring color of an image to match the color of another image of the same scene the color of a scene may vary from image to image because the photograph are taken at different time with different camera and under different camera setting to solve for a full nonlinear and nonparametric color mapping in the d rgb color space we propose a scattered point interpolation scheme using moving least square and strengthen it with a probabilistic modeling of the color transfer in the d color space to deal with mi alignment and noise experiment show the effectiveness of our method over previous color transfer method both quantitatively and qualitatively in addition our framework can be applied for various instance of color transfer such a transferring color between different camera model camera setting and illumination condition a well a for video color transfer 
we present a video object segmentation approach that extends the particle filter to a region based image representation image partition is considered part of the particle filter measurement which enriches the available information and lead to a re formulation of the particle filter the prediction step us a co clustering between the previous image object partition and a partition of the current one which allows u to tackle the evolution of non rigid structure particle are defined a union of region in the current image partition and their propagation is computed through a single co clustering the proposed technique is assessed on the segtrack dataset leading to satisfactory perceptual result and obtaining very competitive pixel error rate compared with the state of the art method 
we present a novel way to automatically summarize and represent the storyline of a tv episode by visualizing character interaction a a chart we also propose a scene detection method that lends itself well to generate over segmented scene which is used to partition the video the positioning of character line in the chart is formulated a an optimization problem which trade between the aesthetic and functionality of the chart using automatic person identification we present storygraphs for diverse tv series encompassing a total of episode we define quantitative criterion to evaluate storygraphs and also compare them against episode summary to evaluate their ability to provide an overview of the episode 
the presence of occluders significantly impact performance of system for object recognition however occlusion is typically treated a an unstructured source of noise and explicit model for occluders have lagged behind those for object appearance and shape in this paper we describe a hierarchical deformable part model for face detection and keypoint localization that explicitly model occlusion of part the proposed model structure make it possible to augment positive training data with large number of synthetically occluded instance this allows u to easily incorporate the statistic of occlusion pattern in a discriminatively trained model we test the model on several benchmark for keypoint localization including challenging set featuring significant occlusion we find that the addition of an explicit model of occlusion yield a system that outperforms existing approach in keypoint localization accuracy 
a probabilistic model allows u to reason about the world and make statistically optimal decision using bayesian decision theory however in practice the intractability of the decision problem force u to adopt simplistic loss function such a the loss or hamming loss and a result we make poor decision through map estimate or through low order marginal statistic in this work we investigate optimal decision making for more realistic loss function specifically we consider the popular intersection over union iou score used in image segmentation benchmark and show that it result in a hard combinatorial decision problem to make this problem tractable we propose a statistical approximation to the objective function a well a an approximate algorithm based on parametric linear programming we apply the algorithm on three benchmark datasets and obtain improved intersection over union score compared to maximum posterior marginal decision our work point out the difficulty of using realistic loss function with probabilistic computer vision model 
occlusion pose a significant difficulty for object recognition due to the combinatorial diversity of possible occlusion pattern we take a strongly supervised non parametric approach to modeling occlusion by learning deformable model with many local part mixture template using large quantity of synthetically generated training data this allows the model to learn the appearance of different occlusion pattern including figure ground cue such a the shape of occluding contour a well a the co occurrence statistic of occlusion between neighboring part the underlying part mixture structure also allows the model to capture coherence of object support mask between neighboring part and make compelling prediction of figure ground occluder segmentation we test the resulting model on human pose estimation under heavy occlusion and find it produce improved localization accuracy 
dictionary learning dl for sparse coding ha shown promising result in classification task while how to adaptively build the relationship between dictionary atom and class label is still an important open question the existing dictionary learning approach simply fix a dictionary atom to be either class specific or shared by all class beforehand ignoring that the relationship need to be updated during dl to address this issue in this paper we propose a novel latent dictionary learning ldl method to learn a discriminative dictionary and build it relationship to class label adaptively each dictionary atom is jointly learned with a latent vector which associate this atom to the representation of different class more specifically we introduce a latent representation model in which discrimination of the learned dictionary is exploited via minimizing the within class scatter of coding coefficient and the latent value weighted dictionary coherence the optimal solution is efficiently obtained by the proposed solving algorithm correspondingly a latent sparse representation based classifier is also presented experimental result demonstrate that our algorithm outperforms many recently proposed sparse representation and dictionary learning approach for action gender and face recognition 
image matching is one of the most challenging stage in d reconstruction which usually occupies half of computational cost and inaccurate matching may lead to failure of reconstruction therefore fast and accurate image matching is very crucial for d reconstruction in this paper we proposed a cascade hashing strategy to speed up the image matching in order to accelerate the image matching the proposed cascade hashing method is designed to be three layer structure hashing lookup hashing remapping and hashing ranking each layer adopts different measure and filtering strategy which is demonstrated to be le sensitive to noise extensive experiment show that image matching can be accelerated by our approach in hundred time than brute force matching even achieves ten time or more than kd tree based matching while retaining comparable accuracy 
group are the primary entity that make up a crowd understanding group level dynamic and property is thus scientifically important and practically useful in a wide range of application especially for crowd understanding in this study we show that fundamental group level property such a intra group stability and inter group conflict can be systematically quantified by visual descriptor this is made possible through learning a novel collective transition prior which lead to a robust approach for group segregation in public space from the prior we further devise a rich set of group property visual descriptor these descriptor are scene independent and can be effectively applied to public scene with variety of crowd density and distribution extensive experiment on hundred of public scene video clip demonstrate that such property descriptor are not only useful but also necessary for group state analysis and crowd scene understanding 
we present a stereo algorithm designed for speed and efficiency that us local slanted plane sweep to propose disparity hypothesis for a semi global matching algorithm our local plane hypothesis are derived from initial sparse feature correspondence followed by an iterative clustering step local plane sweep are then performed around each slanted plane to produce out of plane parallax and matching cost estimate a final global optimization stage implemented using semi global matching assigns each pixel to one of the local plane hypothesis by only exploring a small fraction of the whole disparity space volume our technique achieves significant speedup over previous algorithm and achieves state of the art accuracy on high resolution stereo pair of up to megapixels 
the capture of multiple image is a simple way to increase the chance of capturing a good photo with a light weight hand held camera for which the camera shake blur is typically a nuisance problem the naive approach of selecting the single best captured photo a output doe not take full advantage of all the observation conventional multi image blind deblurring method can take all observation a input but usually require the multiple image are well aligned however the multiple blurry image captured in the presence of camera shake are rarely free from mi alignment registering multiple blurry image is a challenging task due to the presence of blur while deblurring of multiple blurry image requires accurate alignment leading to an intrinsically coupled problem in this paper we propose a blind multi image restoration method which can achieve joint alignment non uniform deblurring together with resolution enhancement from multiple low quality image experiment on several real world image with comparison to some previous method validate the effectiveness of the proposed method 
long term modeling of background motion in video is an important and challenging problem used in numerous application such a segmentation and event recognition a major challenge in modeling the background from point trajectory lie in dealing with the variable length duration of trajectory which can be due to such factor a trajectory entering and leaving the frame or occlusion from different depth layer this work proposes an online method for background modeling of dynamic point trajectory via tracking of a linear subspace describing the background motion to cope with variability in trajectory duration we cast subspace tracking a an instance of subspace estimation under missing data using a least absolute deviation formulation to robustly estimate the background in the presence of arbitrary foreground motion relative to previous work our approach is very fast and scale to arbitrarily long video a our method process new frame sequentially a they arrive 
parallax handling is a challenging task for image stitching this paper present a local stitching method to handle parallax based on the observation that input image do not need to be perfectly aligned over the whole overlapping region for stitching instead they only need to be aligned in a way that there exists a local region where they can be seamlessly blended together we adopt a hybrid alignment model that combine homography and content preserving warping to provide flexibility for handling parallax and avoiding objectionable local distortion we then develop an efficient randomized algorithm to search for a homography which combined with content preserving warping allows for optimal stitching we predict how well a homography enables plausible stitching by finding a plausible seam and using the seam cost a the quality metric we develop a seam finding method that estimate a plausible seam from only roughly aligned image by considering both geometric alignment and image content we then pre align input image using the optimal homography and further use content preserving warping to locally refine the alignment we finally compose aligned image together using a standard seam cutting algorithm and a multi band blending algorithm our experiment show that our method can effectively stitch image with large parallax that are difficult for existing method 
many binary code embedding technique have been proposed for large scale approximate nearest neighbor search in computer vision recently product quantization that encodes the cluster index in each subspace ha been shown to provide impressive accuracy for nearest neighbor search in this paper we explore a simple question is it best to use all the bit budget for encoding a cluster index in each subspace we have found that a data point are located farther away from the center of their cluster the error of estimated distance among those point becomes larger to address this issue we propose a novel encoding scheme that distributes the available bit budget to encoding both the cluster index and the quantized distance between a point and it cluster center we also propose two different distance metric tailored to our encoding scheme we have tested our method against the state of the art technique on several well known benchmark and found that our method consistently improves the accuracy over other tested method this result is achieved mainly because our method accurately estimate distance between two data point with the new binary code and distance metric 
this paper pose object category detection in image a a type of d to d alignment problem utilizing the large quantity of d cad model that have been made publicly available online using the chair class a a running example we propose an exemplar based d category representation which can explicitly model chair of different style a well a the large variation in viewpoint we develop an approach to establish part based correspondence between d cad model and real photograph this is achieved by i representing each d model using a set of view dependent mid level visual element learned from synthesized view in a discriminative fashion ii carefully calibrating the individual element detector on a common dataset of negative image and iii matching visual element to the test image allowing for small mutual deformation but preserving the viewpoint and style constraint we demonstrate the ability of our system to align d model with d object in the challenging pascal voc image which depict a wide variety of chair in complex scene 
this paper introduces a novel image representation capturing feature dependency through the mining of meaningful combination of visual feature this representation lead to a compact and discriminative encoding of image that can be used for image classification object detection or object recognition the method relies on i multiple random projection of the input space followed by local binarization of projected histogram encoded a set of item and ii the representation of image a histogram of pattern set hop the approach is validated on four publicly available datasets daimler pedestrian oxford flower kth texture and pascal voc allowing comparison with many recent approach the proposed image representation reach state of the art performance on each one of these datasets 
this paper tackle the problem of spotting a set of sign occuring in video with sequence of sign to achieve this we propose to model the spatio temporal signature of a sign using an extension of sequential pattern that contain temporal interval called sequential interval pattern sip we then propose a novel multi class classifier that organises different sequential interval pattern in a hierarchical tree structure called a hierarchical sip tree hsp tree this allows one to exploit any subsequence sharing that exists between different sip of different class multiple tree are then combined together into a forest of hsp tree resulting in a strong classifier that can be used to spot sign we then show how the hsp forest can be used to spot sequence of sign that occur in an input video we have evaluated the method on both concatenated sequence of isolated sign and continuous sign sequence we also show that the proposed method is superior in robustness and accuracy to a state of the art sign recogniser when applied to spotting a sequence of sign 
spectral clustering requires robust and meaningful affinity graph a input in order to form cluster with desired structure that can well support human intuition to construct such affinity graph is non trivial due to the ambiguity and uncertainty inherent in the raw data in contrast to most existing clustering method that typically employ all available feature to construct affinity matrix with the euclidean distance which is often not an accurate representation of the underlying data structure we propose a novel unsupervised approach to generating more robust affinity graph via identifying and exploiting discriminative feature for improving spectral clustering specifically our model is capable of capturing and combining subtle similarity information distributed over discriminative feature subspace for more accurately revealing the latent data distribution and thereby leading to improved data clustering especially with heterogeneous data source we demonstrate the efficacy of the proposed approach on challenging image and video datasets 
in this paper we introduce a bilateral consistency metric on the surface camera scam for light field stereo matching to handle significant occlusion the concept of scam is used to model angular radiance distribution with respect to a d point our bilateral consistency metric is used to indicate the probability of occlusion by analyzing the scam we further show how to distinguish between on surface and free space textured and non textured and lambertian and specular through bilateral scam analysis to speed up the matching process we apply the edge preserving guided filter on the consistency disparity curve experimental result show that our technique outperforms both the state of the art and the recent light field stereo matching method especially near occlusion boundary 
this paper proposes a framework for recognizing complex human activity in video our method describes human activity in a hierarchical discriminative model that operates at three semantic level at the lower level body pose are encoded in a representative but discriminative pose dictionary at the intermediate level encoded pose span a space where simple human action are composed at the highest level our model capture temporal and spatial composition of action into complex human activity our human activity classifier simultaneously model which body part are relevant to the action of interest a well a their appearance and composition using a discriminative approach by formulating model learning in a max margin framework our approach achieves powerful multi class discrimination while providing useful annotation at the intermediate semantic level we show how our hierarchical compositional model provides natural handling of occlusion to evaluate the effectiveness of our proposed framework we introduce a new dataset of composed human activity we provide empirical evidence that our method achieves state of the art activity classification performance on several benchmark datasets 
this paper proposes a novel parametric warp which is a spatial combination of a projective transformation and a similarity transformation given the projective transformation relating two input image based on an analysis of the projective transformation our method smoothly extrapolates the projective transformation of the overlapping region into the non overlapping region and the resultant warp gradually change from projective to similarity across the image the proposed warp ha the strength of both projective and similarity warp it provides good alignment accuracy a projective warp while preserving the perspective of individual image a similarity warp it can also be combined with more advanced local warp based alignment method such a the a projective a possible warp for better alignment accuracy with the proposed warp the field of view can be extended by stitching image with le projective distortion stretched shape and enlarged size 
in this paper we present a method for estimating articulated human pose in video we cast this a an optimization problem defined on body part with spatio temporal link between them the resulting formulation is unfortunately intractable and previous approach only provide approximate solution although such method perform well on certain body part e g head their performance on lower arm i e elbow and wrist remains poor we present a new approximate scheme with two step dedicated to pose estimation first our approach take into account temporal link with subsequent frame for the le certain part namely elbow and wrist second our method decomposes pose into limb generates limb sequence across time and recomposes pose by mixing these body part sequence we introduce a new dataset pose in the wild which is more challenging than the existing one with sequence containing background clutter occlusion and severe camera motion we experimentally compare our method with recent approach on this new dataset a well a on two other benchmark datasets and show significant improvement 
we propose an approach to reconstructing tree structure that evolve over time in d image and d image stack such a neuronal axon or plant branch instead of reconstructing structure in each image independently we do so for all image simultaneously to take advantage of temporal consistency constraint we show that this problem can be formulated a a quadratic mixed integer program and solved efficiently the outcome of our approach is a framework that provides substantial improvement in reconstruction over traditional single time instance formulation furthermore an added benefit of our approach is the ability to automatically detect place where significant change have occurred over time which is challenging when considering large amount of data 
a recent trend of research ha shown how contextual information related to an action such a a scene or object can enhance the accuracy of human action recognition system however using context to improve unsupervised human action clustering ha never been considered before and cannot be achieved using existing clustering method to solve this problem we introduce a novel general purpose algorithm dual assignment k mean dakm which is uniquely capable of performing two co occurring clustering task simultaneously while exploiting the correlation information to enhance both clustering furthermore we describe a spectral extension of dakm sdakm for better performance on realistic data extensive experiment on synthetic data and on three realistic human action datasets with scene context show that dakm sdakm can significantly outperform the state of the art clustering method by taking into account the contextual relationship between action and scene 
we propose to decompose the fine grained human activity analysis problem into two sequential task with increasing granularity firstly we infer the coarse interaction status i e which object is being manipulated and where it is knowing that the major challenge is frequent mutual occlusion during manipulation we propose an interaction tracking framework in which hand object position and interaction status are jointly tracked by explicitly modeling the contextual information between mutual occlusion and interaction status secondly the inferred hand object position and interaction status are utilized to provide more compact feature pooling by effectively pruning large number of motion feature from irrelevant spatio temporal position and discriminative action detection by a granularity fusion strategy comprehensive experiment on two challenging fine grained activity datasets i e cooking action show that the proposed framework achieves high accuracy robustness in tracking multiple mutually occluded hand object during manipulation a well a significant performance improvement on fine grained action detection over state of the art method 
we propose an online solution to non rigid structure from motion that performs camera pose and d shape estimation of highly deformable surface on a frame by frame basis our method model non rigid deformation a a linear combination of some mode shape obtained using modal analysis from continuum mechanic the shape is first discretized into linear elastic triangle modelled by mean of finite element which are used to pose the force balance equation for an undamped free vibration model the shape basis computation come down to solving an eigenvalue problem without the requirement of a learning step the camera pose and time varying weight that define the shape at each frame are then estimated on the fly in an online fashion using bundle adjustment over a sliding window of image frame the result is a low computational cost method that can run sequentially in real time we show experimental result on synthetic sequence with ground truth d data and real video for different scenario ranging from sparse to dense scene our system exhibit a good trade off between accuracy and computational budget it can handle missing data and performs favourably compared to competing method 
when one record a video image sequence through a transparent medium e g glass the image is often a superposition of a transmitted layer scene behind the medium and a reflected layer recovering the two layer from such image seems to be a highly ill posed problem since the number of unknown to recover is twice a many a the given measurement in this paper we propose a robust method to separate these two layer from multiple image which exploit the correlation of the transmitted layer across multiple image and the sparsity and independence of the gradient field of the two layer a novel augmented lagrangian multiplier based algorithm is designed to efficiently and effectively solve the decomposition problem the experimental result on both simulated and real data demonstrate the superior performance of the proposed method over the state of the art in term of accuracy and simplicity 
over the past year multiple instance learning mil ha proven to be an effective framework for learning with weakly labeled data application of mil to object detection however were limited to handling the uncertainty of manual annotation in this paper we propose a new mil method for object detection that is capable of handling the noisier automatically obtained annotation our approach consists in first obtaining confidence estimate over the label space and second incorporating these estimate within a new boosting procedure we demonstrate the efficiency of our procedure on two detection task namely horse detection and pedestrian detection where the training data is primarily annotated by a coarse area of interest detector we show dramatic improvement over existing mil method in both case we demonstrate that an efficient appearance model can be learned using our approach 
sparse coding is a widely involved technique in computer vision however the expensive computational cost can hamper it application typically when the codebook size must be limited due to concern on running time in this paper we study a special case of sparse coding in which the codebook is a cartesian product of two subcodebooks we present algorithm to decompose this sparse coding problem into smaller subproblems which can be separately solved our solution named a product sparse coding psc reduces the time complexity from o k to o root k in the codebook size k in practice this can be x faster than standard sparse coding in experiment we demonstrate the efficiency and quality of this method on the application of image classification and image retrieval 
in this paper we propose a novel approach of learning mid level filter from automatically discovered patch cluster for person re identification it is well motivated by our study on what are good filter for person re identification our mid level filter are discriminatively learned for identifying specific visual pattern and distinguishing person and have good cross view invariance first local patch are qualitatively measured and classified with their discriminative power discriminative and representative patch are collected for filter learning second patch cluster with coherent appearance are obtained by pruning hierarchical clustering tree and a simple but effective cross view training strategy is proposed to learn filter that are view invariant and discriminative third filter response are integrated with patch matching score in ranksvm training the effectiveness of our approach is validated on the viper dataset and the cuhk dataset the learned mid level feature are complementary to existing handcrafted low level feature and improve the best rank matching rate on the viper dataset by 
this paper present a new discriminative deep metric learning ddml method for face verification in the wild different from existing metric learning based face verification method which aim to learn a mahalanobis distance metric to maximize the inter class variation and minimize the intra class variation simultaneously the proposed ddml train a deep neural network which learns a set of hierarchical nonlinear transformation to project face pair into the same feature subspace under which the distance of each positive face pair is le than a smaller threshold and that of each negative pair is higher than a larger threshold respectively so that discriminative information can be exploited in the deep network our method achieves very competitive face verification performance on the widely used lfw and youtube face ytf datasets 
this paper proposes to learn a set of high level feature representation through deep learning referred to a deep hidden identity feature deepid for face verification we argue that deepid can be effectively learned through challenging multi class face identification task whilst they can be generalized to other task such a verification and new identity unseen in the training set moreover the generalization capability of deepid increase a more face class are to be predicted at training deepid feature are taken from the last hidden layer neuron activation of deep convolutional network convnets when learned a classifier to recognize about face identity in the training set and configured to keep reducing the neuron number along the feature extraction hierarchy these deep convnets gradually form compact identity related feature in the top layer with only a small number of hidden neuron the proposed feature are extracted from various face region to form complementary and over complete representation any state of the art classifier can be learned based on these high level representation for face verification verification accuracy on lfw is achieved with only weakly aligned face 
object and structure within man made environment typically exhibit a high degree of organization in the form of orthogonal and parallel plane traditional approach to scene representation exploit this phenomenon via the somewhat restrictive assumption that every plane is perpendicular to one of the ax of a single coordinate system known a the manhattan world model this assumption is widely used in computer vision and robotics the complexity of many real world scene however necessitates a more flexible model we propose a novel probabilistic model that describes the world a a mixture of manhattan frame each frame defines a different orthogonal coordinate system this result in a more expressive model that still exploit the orthogonality constraint we propose an adaptive markov chain monte carlo sampling algorithm with metropolis hastings split merge move that utilizes the geometry of the unit sphere we demonstrate the versatility of our mixture of manhattan frame model by describing complex scene using depth image of indoor scene a well a aerial lidar measurement of an urban center additionally we show that the model lends itself to focal length calibration of depth camera and to plane segmentation 
in this paper we present the latent regression forest lrf a novel framework for real time d hand pose estimation from a single depth image in contrast to prior forest based method which take dense pixel a input classify them independently and then estimate joint position afterwards our method can be considered a a structured coarse to fine search starting from the centre of mass of a point cloud until locating all the skeletal joint the searching process is guided by a learnt latent tree model which reflects the hierarchical topology of the hand our main contribution can be summarised a follows i learning the topology of the hand in an unsupervised data driven manner ii a new forest based discriminative framework for structured search in image a well a an error regression step to avoid error accumulation iii a new multi view hand pose dataset containing k annotated image from different subject our experiment show that the lrf out performs state of the art method in both accuracy and efficiency 
a novel visual tracking algorithm using patch based appearance model is proposed in this paper we first divide the bounding box of a target object into multiple patch and then select only pertinent patch which occur repeatedly near the center of the bounding box to construct the foreground appearance model we also divide the input image into non overlapping block construct a background model at each block location and integrate these background model for tracking using the appearance model we obtain an accurate foreground probability map finally we estimate the optimal object position by maximizing the likelihood which is obtained by convolving the foreground probability map with the pertinence mask experimental result demonstrate that the proposed algorithm outperforms state of the art tracking algorithm significantly in term of center position error and success rate 
identifying subject with variation caused by pose is one of the most challenging task in face recognition since the difference in appearance caused by pose may be even larger than the difference due to identity inspired by the observation that pose variation change non linearly but smoothly we propose to learn pose robust feature by modeling the complex non linear transform from the non frontal face image to frontal one through a deep network in a progressive way termed a stacked progressive auto encoders spae specifically each shallow progressive auto encoder of the stacked network is designed to map the face image at large pose to a virtual view at smaller one and meanwhile keep those image already at smaller pose unchanged then stacking multiple these shallow auto encoders can convert non frontal face image to frontal one progressively which mean the pose variation are narrowed down to zero step by step a a result the output of the topmost hidden layer of the stacked network contain very small pose variation which can be used a the pose robust feature for face recognition an additional attractiveness of the proposed method is that no pose estimation is needed for the test image the proposed method is evaluated on two datasets with pose variation i e multipie and feret datasets and the experimental result demonstrate the superiority of our method to the existing work especially to those d one 
recent study on alzheimer s disease ad or it prodromal stage mild cognitive impairment mci diagnosis presented that the task of identifying brain disease status and predicting clinical score based on neuroimaging feature were highly related to each other however these task were often conducted independently in the previous study regarding the feature selection to our best knowledge most of the previous work considered a loss function defined a an element wise difference between the target value and the predicted one in this paper we consider the problem of joint regression and classification for ad mci diagnosis and propose a novel matrix similarity based loss function that us high level information inherent in the target response matrix and imposes the information to be preserved in the predicted response matrix the newly devised loss function is combined with a group lasso method for joint feature selection across task i e clinical score prediction and disease status identification we conducted experiment on the alzheimer s disease neuroimaging initiative adni dataset and showed that the newly devised loss function wa effective to enhance the performance of both clinical score prediction and disease status identification outperforming the state of the art method 
in classification of object substantial work ha gone into improving the low level representation of an image by considering various aspect such a different feature a number of feature pooling and coding technique and considering different kernel unlike these work in this paper we propose to enhance the semantic representation of an image we aim to learn the most important visual component of an image and how they interact in order to classify the object correctly to achieve our objective we propose a new latent svm model for category level object classification starting from image level annotation we jointly learn the object class and it context in term of spatial location where and appearance what furthermore to regularize the complexity of the model we learn the spatial and co occurrence relation between adjacent region such that unlikely configuration are penalized experimental result demonstrate that the proposed method can consistently enhance result on the challenging pascal voc dataset in term of classification and weakly supervised detection we also show how semantic representation can be exploited for finding similar content 
state of the art multi view stereo mv algorithm deliver dense depth map or complex mesh with very high detail and redundancy over regular surface in turn our interest lie in an approximate but light weight method that is better to consider for large scale application such a urban scene reconstruction from ground based image we present a novel approach for producing dense reconstruction from multiple image and from the underlying sparse structure from motion sfm data in an efficient way to overcome the problem of sfm sparsity and textureless area we assume piecewise planarity of man made scene and exploit both sparse visibility and a fast over segmentation of the image reconstruction is formulated a an energy driven multi view plane assignment problem which we solve jointly over superpixels from all view while avoiding expensive photoconsistency computation the resulting planar primitive defined by detailed superpixel boundary are computed in about second per image 
in this paper we present an attributed grammar for parsing man made outdoor scene into semantic surface and recovering it d model simultaneously the grammar take superpixels a it terminal node and use five production rule to generate the scene into a hierarchical parse graph each graph node actually correlate with a surface or a composite of surface in the d world or the d image they are described by attribute for the global scene model e g focal length vanishing point or the surface property e g surface normal contact line with other surface and relative spatial location etc each production rule is associated with some equation that constraint the attribute of the parent node and those of their child node given an input image our goal is to construct a hierarchical parse graph by recursively applying the five grammar rule while preserving the attribute constraint we develop an effective top down bottom up cluster sampling procedure which can explore this constrained space efficiently we evaluate our method on both public benchmark and newly built datasets and achieve state of the art performance in term of layout estimation and region segmentation we also demonstrate that our method is able to recover detailed d model with relaxed manhattan structure which clearly advance the state of the art of singleview d reconstruction 
we present a novel solution to compute the relative pose of a generalized camera existing solution are either not general have too high computational complexity or require too many correspondence which impedes an efficient or accurate usage within ransac scheme we factorize the problem a a low dimensional iterative optimization over relative rotation only directly derived from well known epipolar constraint common generalized camera often consist of camera cluster and give rise to omni directional landmark observation we prove that our iterative scheme performs well in such practically relevant situation eventually resulting in computational efficiency similar to linear solver and accuracy close to bundle adjustment while using le correspondence experiment on both virtual and real multi camera system prove superior overall performance for robust real time multi camera motion estimation 
in this paper we introduce a novel technique to automatically detect salient region of an image via high dimensional color transform our main idea is to represent a saliency map of an image a a linear combination of high dimensional color space where salient region and background can be distinctively separated this is based on an observation that salient region often have distinctive color compared to the background in human perception but human perception is often complicated and highly nonlinear by mapping a low dimensional rgb color to a feature vector in a high dimensional color space we show that we can linearly separate the salient region from the background by finding an optimal linear combination of color coefficient in the high dimensional color space our high dimensional color space incorporates multiple color representation including rgb cielab hsv and with gamma correction to enrich it representative power our experimental result on three benchmark datasets show that our technique is effective and it is computationally efficient in comparison to previous state of the art technique 
we propose binary range sample feature in depth it is based on test and achieves reasonable invariance with respect to possible change in scale viewpoint and background it is robust to occlusion and data corruption a well the descriptor work in a high speed thanks to it binary property working together with standard learning algorithm the proposed descriptor achieves state of theart result on benchmark datasets in our experiment impressively short running time is also yielded 
this paper address the problem of face alignment for a single image we show how an ensemble of regression tree can be used to estimate the face s landmark position directly from a sparse subset of pixel intensity achieving super realtime performance with high quality prediction we present a general framework based on gradient boosting for learning an ensemble of regression tree that optimizes the sum of square error loss and naturally handle missing or partially labelled data we show how using appropriate prior exploiting the structure of image data help with efficient feature selection different regularization strategy and it importance to combat overfitting are also investigated in addition we analyse the effect of the quantity of training data on the accuracy of the prediction and explore the effect of data augmentation using synthesized data 
we study the problem of understanding object in detail intended a recognizing a wide array of fine grained object attribute to this end we introduce a dataset of airplane annotated in detail with part and their attribute leveraging image donated by airplane spotter and crowdsourcing both the design and collection of the detailed annotation we provide a number of insight that should help researcher interested in designing fine grained datasets for other basic level category we show that the collected data can be used to study the relation between part detection and attribute prediction by diagnosing the performance of classifier that pool information from different part of an object we note that the prediction of certain attribute can benefit substantially from accurate part detection we also show that differently from previous result in object detection employing a large number of part template can improve detection accuracy at the expense of detection speed we finally propose a coarse to fine approach to speed up detection through a hierarchical cascade algorithm 
this paper present a new framework for human activity recognition from video sequence captured by a depth camera we cluster hypersurface normal in a depth sequence to form the polynormal which is used to jointly characterize the local motion and shape information in order to globally capture the spatial and temporal order an adaptive spatio temporal pyramid is introduced to subdivide a depth video into a set of space time grid we then propose a novel scheme of aggregating the low level polynormals into the super normal vector snv which can be seen a a simplified version of the fisher kernel representation in the extensive experiment we achieve classification result superior to all previous published result on the four public benchmark datasets i e msraction d msrdailyactivity d msrgesture d and msractionpairs d 
this paper present a method for acquiring dense nonrigid shape and deformation from a single monocular depth sensor we focus on modeling the human hand and assume that a single rough template model is available we combine and extend existing work on model based tracking subdivision surface fitting and mesh deformation to acquire detailed hand model from a few a frame of depth data we propose an objective that measure the error of fit between each sampled data point and a continuous model surface defined by a rigged control mesh and us a rigid a possible arap regularizers to cleanly separate the model and template geometry a key contribution is our use of a smooth model based on subdivision surface that allows simultaneous optimization over both correspondence and model parameter this avoids the use of iterated closest point icp algorithm which often lead to slow convergence automatic initialization is obtained using a regression forest trained to infer approximate correspondence experiment show that the resulting mesh model the user s hand shape more accurately than just adapting the shape parameter of the skeleton and that the retargeted skeleton accurately model the user s articulation we investigate the effect of various modeling choice and show the benefit of using subdivision surface and arap regularization 
most modern object tracker combine a motion prior with sliding window detection using binary classifier that predict the presence of the target object based on histogram feature although the accuracy of such tracker is generally very good they are often impractical because of their high computational requirement to resolve this problem the paper present a new approach that limit the computational cost of tracker by ignoring feature in image region that after inspecting a few feature are unlikely to contain the target object to this end we derive an upper bound on the probability that a location is most likely to contain the target object and we ignore feature in location for which this upper bound is small we demonstrate the effectiveness of our new approach in experiment with model free and model based tracker that use linear model in combination with hog feature the result of our experiment demonstrate that our approach allows u to reduce the average number of inspected feature by up to without affecting the accuracy of the tracker 
we investigate an inhomogeneous version of the frame filter random field and maximum entropy model and apply it to modeling object pattern the inhomogeneous frame is a non stationary markov random field model that reproduces the observed marginal distribution or statistic of filter response at all the different location scale and orientation our experiment show that the inhomogeneous frame model is capable of generating a wide variety of object pattern in natural image we then propose a sparsified version of the inhomogeneous frame model where the model reproduces observed statistical property of filter response at a small number of selected location scale and orientation we propose to select these location scale and orientation by a shared sparse coding scheme and we explore the connection between the sparse frame model and the linear additive sparse coding model our experiment show that it is possible to learn sparse frame model in unsupervised fashion and the learned model are useful for object classification 
the notion of relative attribute a introduced by parikh and grauman iccv provides an appealing way of comparing two image based on their visual property or attribute such a smiling for face image naturalness for outdoor image etc for learning such attribute a ranking svm based formulation wa proposed that us globally represented pair of annotated image in this paper we extend this idea towards learning relative attribute using local part that are shared across category first instead of using a global representation we introduce a part based representation combining a pair of image that specifically compare corresponding part then with each part we associate a locally adaptive significance coefficient that represents it discriminative ability with respect to a particular attribute for each attribute the significance coefficient are learned simultaneously with a max margin ranking model in an iterative manner compared to the baseline method the new method is shown to achieve significant improvement in relative attribute prediction accuracy additionally it is also shown to improve relative feedback based interactive image search 
this paper proposes a novel mean field based chamfer template matching method in our method each template is represented a a field model and matching a template with an input image is formulated a estimation of a maximum of posteriori in the field model variational approach is then adopted to approximate the estimation the proposed method wa applied for two different variant of chamfer template matching and evaluated through the task of object detection experimental result on benchmark datasets including ethzshapeclass and inriahorse have shown that the proposed method could significantly improve the accuracy of template matching while not sacrificing much of the efficiency comparison with other recent template matching algorithm have also shown the robustness of the proposed method 
labeling large scale datasets with very accurate object segmentation is an elaborate task that requires a high degree of quality control and a budget of ten or hundred of thousand of dollar thus developing solution that can automatically perform the labeling given only weak supervision is key to reduce this cost in this paper we show how to exploit d information to automatically generate very accurate object segmentation given annotated d bounding box we formulate the problem a the one of inference in a binary markov random field which exploit appearance model stereo and or noisy point cloud a repository of d cad model a well a topological constraint we demonstrate the effectiveness of our approach in the context of autonomous driving and show that we can segment car with the accuracy of intersection over union performing a well a highly recommended mturkers 
registering or more range scan is a fundamental problem with application to d modeling while this problem is well addressed by existing technique such a icp when the view overlap significantly at a good initialization no satisfactory solution exists for wide baseline registration we propose here a novel approach which leverage contour coherence and allows u to align two wide baseline range scan with limited overlap from a poor initialization inspired by icp we maximize the contour coherence by building robust corresponding pair on apparent contour and minimizing their distance in an iterative fashion we use the contour coherence under a multi view rigid registration framework and this enables the reconstruction of accurate and complete d model from a few a frame we further extend it to handle articulation and this allows u to model articulated object such a human body experimental result on both synthetic and real data demonstrate the effectiveness and robustness of our contour coherence based registration approach to wide baseline range scan and to d modeling 
we present a nonrigid shape matching technique for establishing correspondence of incomplete d surface that exhibit intrinsic reflectional symmetry the key for solving the symmetry ambiguity problem is to use a point wise local mesh descriptor that ha orientation and is thus sensitive to local reflectional symmetry e g discriminating the left hand and the right hand we devise a way to compute the descriptor orientation by taking the gradient of a scalar field called the average diffusion distance add because add is smoothly defined on a surface invariant under isometry scale and robust to topological error the robustness of the descriptor to non rigid deformation is improved in addition we propose a graph matching algorithm called iterative spectral relaxation which combine spectral embedding and spectral graph matching this formulation allows u to define pairwise constraint in a scale invariant manner from k nearest neighbor local pair such that non isometric deformation can be robustly handled experimental result show that our method can match challenging surface with global intrinsic symmetry data incompleteness and non isometric deformation 
we present a novel method for automatic vanishing point detection based on primal and dual point alignment detection the very same point alignment detection algorithm is used twice first in the image domain to group line segment endpoint into more precise line second it is used in the dual domain where converging line become aligned point the use of the recently introduced pclines dual space and a robust point alignment detector lead to a very accurate algorithm experimental result on two public standard datasets show that our method significantly advance the state of the art in the manhattan world scenario while producing state of the art performance in non manhattan scene 
we tackle stationary crowd analysis in this paper which is similarly important a modeling mobile group in crowd scene and find many application in surveillance our key contribution is to propose a robust algorithm of estimating how long a foreground pixel becomes stationary it is much more challenging than only subtracting background because failure at a single frame due to local movement of object lighting variation and occlusion could lead to large error on stationary time estimation to accomplish decent result sparse constraint along spatial and temporal dimension are jointly added by mixed partial to shape a d stationary time map it is formulated a a l optimization problem besides background subtraction it distinguishes among different foreground object which are close or overlapped in the spatio temporal space by using a locally shared foreground codebook the proposed technology are used to detect four type of stationary group activity and analyze crowd scene structure we provide the first public benchmark dataset for stationary time estimation and stationary group analysis 
we present a novel object recognition framework based on multiple figure ground hypothesis with a large object spatial support generated by bottom up process and mid level cue in an unsupervised manner we exploit the benefit of regression for discriminating segment category and quality where a regressor is trained to each category using the overlapping observation between each figure ground segment hypothesis and the ground truth of the target category in an image object recognition is achieved by maximizing a submodular objective function which maximizes the similarity between the selected segment i e facility location and their group element i e client penalizes the number of selected segment and more importantly encourages the consistency of object category corresponding to maximum regression value from different category specific regressors for the selected segment the proposed framework achieves impressive recognition result on three benchmark datasets including pascal voc caltech and ethz shape 
many learning problem in computer vision can be posed a structured prediction problem where the input and output instance are structured object such a tree graph or string rather than single label or scalar kernel method such a structured support vector machine twin gaussian process tgp structured gaussian process and vector valued reproducing kernel hilbert space rkhs offer powerful way to perform learning and inference over these domain positive definite kernel function allow u to quantitatively capture similarity between a pair of instance over these arbitrary domain a poor choice of the kernel function which decides the rkhs feature space often result in poor performance automatic kernel selection method have been developed but have focused only on kernel on the input domain i e one way in this work we propose a novel and efficient algorithm for learning kernel function simultaneously on both input and output domain we introduce the idea of learning polynomial kernel transformation and call this method simultaneous twin kernel learning stkl stkl can learn arbitrary but continuous kernel function including one way kernel learning a a special case we formulate this problem for learning covariance kernel of twin gaussian process our experimental evaluation using learned kernel on synthetic and several real world datasets demonstrate consistent improvement in performance of tgp s 
it ha long been recognized that one of the fundamental difficulty in theestimation of two view epipolar geometry is the capability of handling outlier in this paper we develop a fast and tractable algorithm that maximizes the number of inliers under the assumption of a purely translating camera compared to classical random sampling method our approach is guaranteed to compute the optimal solution of a cost function based on reprojection error and it ha better time complexity the performance is in fact independent of the inlier outlier ratio of the data this open up for a more reliable approach to robust ego motion estimation our basic translation estimator can be embedded into a system that computes the full camera rotation we demonstrate the applicability in several difficult setting with large amount of outlier it turn out to be particularly well suited for small rotation and rotation around a known axis which is the case for cellular phone where the gravitation axis can be measured experimental result show that compared to standard ransac method based on minimal solver ouralgorithm produce more accurate estimate in the presence of large outlier ratio 
image taken in low light condition with handheld camera are often blurry due to the required long exposure time although significant progress ha been made recently on image deblurring state of the art approach often fail on low light image a these image do not contain a sufficient number of salient feature that deblurring method rely on on the other hand light streak are common phenomenon in low light image that contain rich blur information but have not been extensively explored in previous approach in this work we propose a new method that utilizes light streak to help deblur low light image we introduce a non linear blur model that explicitly model light streak and their underlying light source and pose them a constraint for estimating the blur kernel in an optimization framework our method also automatically detects useful light streak in the input image experimental result show that our approach obtains good result on challenging real world example that no other method could achieve before 
we describe a new approach for generating regular speed low frame rate lfr video from a high frame rate hfr input while preserving the important moment in the original we call this time mapping a time based analogy to high dynamic range to low dynamic range spatial tone mapping our approach make these contribution a robust space time saliency method for evaluating visual importance a re timing technique to temporally resample based on frame importance and temporal filter to enhance the rendering of salient motion result of our space time saliency method on a benchmark dataset show it is state of the art in addition the benefit of our approach to hfr to lfr time mapping over more direct method are demonstrated in a user study 
in this work we use loopy part model to segment ensemble of organ in medical image each organ s shape is represented a a cyclic graph while shape consistency is enforced through inter shape connection our contribution are two fold firstly we use an efficient decomposition coordination algorithm to solve the resulting optimization problem we decompose the model s graph into a set of open chain structured graph each of which is efficiently optimized using dynamic programming with generalized distance transforms we use the alternating direction method of multiplier admm to fix the potential inconsistency of the individual solution and show that admm yield substantially faster convergence than plain dual decomposition based method secondly we employ structured prediction to encompass loss function that better reflect the performance criterion used in medical image segmentation by using the mean contour distance mcd a a structured loss during training we obtain clear test time performance gain we demonstrate the merit of exact and efficient inference with rich structured model in a large x ray image segmentation benchmark where we obtain systematic improvement over the current state of the art 
in this paper we propose a robust method for visual tracking relying on mean shift sparse coding and spatial pyramid firstly we extend the original mean shift approach to handle orientation space and scale space and name this new method a mean transform the mean transform method estimate the motion including the location orientation and scale of the interested object window simultaneously and effectively secondly a pixel wise dense patch sampling technique and a region wise trivial template designing scheme are introduced which enable our approach to run very accurately and efficiently in addition instead of using either holistic representation or local representation only we apply spatial pyramid by combining these two representation into our approach to deal with partial occlusion problem robustly observed from the experimental result our approach outperforms state of the art method in many benchmark sequence 
saliency prediction typically relies on hand crafted multiscale feature that are combined in different way to form a master saliency map which encodes local image conspicuity recent improvement to the state of the art on standard benchmark such a mit have been achieved mostly by incrementally adding more and more hand tuned feature such a car or face detector to existing model in contrast we here follow an entirely automatic data driven approach that performs a large scale search for optimal feature we identify those instance of a richly parameterized bio inspired model family hierarchical neuromorphic network that successfully predict image saliency because of the high dimensionality of this parameter space we use automated hyperparameter optimization to efficiently guide the search the optimal blend of such multilayer feature combined with a simple linear classifier achieves excellent performance on several image saliency benchmark our model outperform the state of the art on mit on which feature and classifier are learned without additional training these model generalize well to two other image saliency data set toronto and nusef despite their different image content finally our algorithm score best of all the model evaluated to date on the mit saliency challenge which us a hidden test set to facilitate an unbiased comparison 
image based classification of histology section play an important role in predicting clinical outcome however this task is very challenging due to the presence of large technical variation e g fixation staining and biological heterogeneity e g cell type cell state in the field of biomedical imaging for the purpose of visualization and or quantification different stain are typically used for different target of interest e g cellular subcellular event which generates multi spectrum data image through various type of microscope and a a result provides the possibility of learning biological component specific feature by exploiting multispectral information we propose a multispectral feature learning model that automatically learns a set of convolution filter bank from separate spectrum to efficiently discover the intrinsic tissue morphometric signature based on convolutional sparse coding csc the learned feature representation are then aggregated through the spatial pyramid matching framework spm and finally classified using a linear svm the proposed system ha been evaluated using two large scale tumor cohort collected from the cancer genome atlas tcga experimental result show that the proposed model outperforms system utilizing sparse coding for unsupervised feature learning e g psd spm is competitive with system built upon feature with biological prior knowledge e g smlspm 
many computer vision problem require optimization of binary non submodular energy we propose a general optimization framework based on local submodular approximation lsa unlike standard lp relaxation method that linearize the whole energy globally our approach iteratively approximates the energy locally on the other hand unlike standard local optimization method e g gradient descent or projection technique we use non linear submodular approximation and optimize them without leaving the domain of integer solution we discus two specific lsa algorithm based on trust region and auxiliary function principle lsa tr and lsa aux these method obtain state of the art result on a wide range of application outperforming many standard technique such a lbp qpbo and trws while our paper is focused on pairwise energy our idea extend to higher order problem the code is available online 
scene recognition is a basic task towards image understanding spatial pyramid matching spm ha been shown to be an efficient solution for spatial context modeling in this paper we introduce an alternative approach orientational pyramid matching opm for orientational context modeling our approach is motivated by the observation that the d orientation of object are a crucial factor to discriminate indoor scene the novelty lie in that opm us the d orientation to form the pyramid and produce the pooling region which is unlike spm that us the spatial position to form the pyramid experimental result on challenging scene classification task show that opm achieves the performance comparable with spm and that opm and spm make complementary contribution so that their combination give the state of the art performance 
interaction between moving target often provide discriminative clue for multiple target tracking mtt though many existing approach ignore such interaction due to difficulty in effectively handling them in this paper we model interaction between neighbor target by pair wise motion context and further encode such context into the global association optimization to solve the resulting global non convex maximization we propose an effective and efficient power iteration framework this solution enjoys two advantage for mtt first it allows u to combine the global energy accumulated from individual trajectory and the between trajectory interaction energy into a united optimization which can be solved by the proposed power iteration algorithm second the framework is flexible to accommodate various type of pairwise context model and we in fact studied two different context model in this paper for evaluation we apply the proposed method to four public datasets involving different challenging scenario such a dense aerial borne traffic tracking dense point set tracking and semi crowded pedestrian tracking in all the experiment our approach demonstrate very promising result in comparison with state of the art tracker 
graph cut method such a expansion and fusion move have been successful at solving many optimization problem in computer vision higher order markov random field mrf s which are important for numerous application have proven to be very difficult especially for multilabel mrf s i e more than label in this paper we propose a new primal dual energy minimization method for arbitrary higher order multilabel mrf s primal dual method provide guaranteed approximation bound and can exploit information in the dual variable to improve their efficiency our algorithm generalizes the pd technique for first order mrfs and relies on a variant of max flow that can exactly optimize certain higher order binary mrf s we provide approximation bound similar to pd and the method is fast in practice it can optimize non submodular mrf s and additionally can incorporate problem specific knowledge in the form of fusion proposal we compare experimentally against the existing approach that can efficiently handle these difficult energy function for higher order denoising and stereo mrf s we produce lower energy while running significantly faster 
in crowded space such a city center or train station human mobility look complex but is often influenced only by a few cause we propose to quantitatively study crowded environment by introducing a dataset of million trajectory collected in train station given this dataset we address the problem of forecasting pedestrian destination a central problem in understanding large scale crowd mobility we need to overcome the challenge posed by a limited number of observation e g sparse camera and change in pedestrian appearance cue across different camera in addition we often have restriction in the way pedestrian can move in a scene encoded a prior over origin and destination od preference we propose a new descriptor coined a social affinity map sam to link broken or unobserved trajectory of individual in the crowd while using the od prior in our framework our experiment show improvement in performance through the use of sam feature and od prior to the best of our knowledge our work is one of the first study that provides encouraging result towards a better understanding of crowd behavior at the scale of million pedestrian 
the desirability of being able to search for specific person in surveillance video captured by different camera ha increasingly motivated interest in the problem of person re identification which is a critical yet under addressed challenge in multi camera tracking system the main difficulty of person re identification arises from the variation in human appearance from different camera view in this paper to bridge the human appearance variation across camera two coupled dictionary that relate to the gallery and probe camera are jointly learned in the training phase from both labeled and unlabeled image the labeled training image carry the relationship between feature from different camera and the abundant unlabeled training image are introduced to exploit the geometry of the marginal distribution for obtaining robust sparse representation in the testing phase the feature of each target image from the probe camera is first encoded by the sparse representation and then recovered in the feature space spanned by the image from the gallery camera the feature of the same person from different camera are similar following the above transformation experimental result on publicly available datasets demonstrate the superiority of our method 
our goal is to obtain a noise free high resolution hr image from an observed noisy low resolution lr image the conventional approach of preprocessing the image with a denoising algorithm followed by applying a super resolution sr algorithm ha an important limitation along with noise some high frequency content of the image particularly textural detail is invariably lost during the denoising step this denoising loss restricts the performance of the subsequent sr step wherein the challenge is to synthesize such textural detail in this paper we show that high frequency content in the noisy image which is ordinarily removed by denoising algorithm can be effectively used to obtain the missing textural detail in the hr domain to do so we first obtain hr version of both the noisy and the denoised image using a patch similarity based sr algorithm we then show that by taking a convex combination of orientation and frequency selective band of the noisy and the denoised hr image we can obtain a desired hr image where i some of the textural signal lost in the denoising step is effectively recovered in the hr domain and ii additional texture can be easily synthesized by appropriately constraining the parameter of the convex combination we show that this part recovery and part synthesis of texture through our algorithm yield hr image that are visually more pleasing than those obtained using the conventional processing pipeline furthermore our result show a consistent improvement in numerical metric further corroborating the ability of our algorithm to recover lost signal 
existing saliency detection approach use image a input and are sensitive to foreground background similarity complex background texture and occlusion we explore the problem of using light field a input for saliency detection our technique is enabled by the availability of commercial plenoptic camera that capture the light field of a scene in a single shot we show that the unique refocusing capability of light field provides useful focusness depth and objectness cue we further develop a new saliency detection algorithm tailored for light field to validate our approach we acquire a light field database of a range of indoor and outdoor scene and generate the ground truth saliency map experiment show that our saliency detection scheme can robustly handle challenging scenario such a similar foreground and background cluttered background complex occlusion etc and achieve high accuracy and robustness 
we present a realtime hand tracking system using a depth sensor it track a fully articulated hand under large viewpoint in realtime fps on a desktop without using a gpu and with high accuracy error below mm to our knowledge it is the first system that achieves such robustness accuracy and speed simultaneously a verified on challenging real data our system is made of several novel technique we model a hand simply using a number of sphere and define a fast cost function those are critical for realtime performance we propose a hybrid method that combine gradient based and stochastic optimization method to achieve fast convergence and good accuracy we present new finger detection and hand initialization method that greatly enhance the robustness of tracking 
we proposed a deformable patch based method for single image super resolution by the concept of deformation a patch is not regarded a a fixed vector but a flexible deformation flow via deformable patch the dictionary can cover more pattern that do not appear thus becoming more expressive we present the energy function with slow smooth and flexible prior for deformation model during example based super resolution we develop the deformation similarity based on the minimized energy function for basic patch matching for robustness we utilize multiple deformed patch combination for the final reconstruction experiment evaluate the deformation effectiveness and super resolution performance showing that the deformable patch help improve the representation accuracy and perform better than the state of art method 
we address the problem of populating object category detection datasets with dense per object d reconstruction bootstrapped from class label ground truth figure ground segmentation and a small set of keypoint annotation our proposed algorithm first estimate camera viewpoint using rigid structure from motion then reconstructs object shape by optimizing over visual hull proposal guided by loose within class shape similarity assumption the visual hull sampling process attempt to intersect an object s projection cone with the cone of minimal subset of other similar object among those pictured from certain vantage point we show that our method is able to produce convincing per object d reconstruction on one of the most challenging existing object category detection datasets pascal voc our result may re stimulate once popular geometry oriented model based recognition approach 
we address the problem of classifying complex video based on their content a typical approach to this problem is performing the classification using semantic attribute commonly termed concept which occur in the video in this paper we propose a contextual approach to video classification based on generalized maximum clique problem gmcp which us the co occurrence of concept a the context model to be more specific we propose to represent a class based on the co occurrence of it concept and classify a video based on matching it semantic co occurrence pattern to each class representation we perform the matching using gmcp which find the strongest clique of co occurring concept in a video we argue that in principal the co occurrence of concept yield a richer representation of a video compared to most of the current approach additionally we propose a novel optimal solution to gmcp based on mixed binary integer programming mbip the evaluation show our approach which open new opportunity for further research in this direction outperforms several well established video classification method 
in large scale image classification feature such a fisher vector or vlad have achieved state of the art result however the combination of large number of example and high dimensional vector necessitates dimensionality reduction in order to reduce it storage and cpu cost to a reasonable range in spite of the popularity of various feature compression method this paper argues that feature selection is a better choice than feature compression we show that strong multicollinearity among feature dimension may not exist which undermines feature compression s effectiveness and render feature selection a natural choice we also show that many dimension are noise and throwing them away is helpful for classification we propose a supervised mutual information mi based importance sorting algorithm to choose feature combining with bit quantization mi feature selection ha achieved both higher accuracy and le computational cost than feature compression method such a product quantization and bpbc 
camera image saved in raw format are being adopted in computer vision task since raw value represent minimally processed sensor response camera manufacturer however have yet to adopt a standard for raw image and current raw rgb value are device specific due to different sensor spectral sensitivity this result in significantly different raw image for the same scene captured with different camera this paper focus on estimating a mapping that can convert a raw image of an arbitrary scene and illumination from one camera s raw space to another to this end we examine various mapping strategy including linear and non linear transformation applied both in a global and illumination specific manner we show that illumination specific mapping give the best result however at the expense of requiring a large number of transformation to address this issue we introduce an illumination independent mapping approach that us white balancing to assist in reducing the number of required transformation we show that this approach achieves state of the art result on a range of consumer camera and image of arbitrary scene and illumination 
active contour especially in conjunction with prior shape model ha become an important tool in image segmentation however most contour method use shape prior based on similarity shape analysis i e analysis that is invariant to rotation translation and scale in practice the training shape used for prior shape model may be collected from viewing angle different from those for the test image and require invariance to a larger class of transformation using an elastic affine invariant shape modeling of planar curve we propose an active contour algorithm in which the training and test shape can be at arbitrary affine transformation and the resulting segmentation is robust to perspective skews we construct a shape space of affine standardized curve and derive a statistical model for capturing class specific shape variability the active contour is then driven by the true gradient of a total energy composed of a data term a smoothing term and an affine invariant shape prior term this framework is demonstrated using a number of example involving the segmentation of occluded or noisy image of target subject to perspective skew 
a novel model based approach is introduced for real time detection and tracking of the pose of general articulated object a variety of dense motion and depth cue are integrated into a novel articulated iterative closest point approach the proposed method can independently track the six degree of freedom pose of over a hundred of rigid part in real time while at the same time imposing articulation constraint on the relative motion of different part we propose a novel rigidization framework for optimally handling unobservable part during tracking this involves rigidly attaching the minimal amount of unseen part to the rest of the structure in order to most effectively use the currently available knowledge we show how this framework can be used also for detection rather than tracking which allows for automatic system initialization and for incorporating pose estimate obtained from independent object part detector improved performance over alternative solution is demonstrated on real world sequence 
we describe a new approach to transfer knowledge across view for action recognition by using example from a large collection of unlabelled mocap data we achieve this by directly matching purely motion based feature from video to mocap our approach recovers d pose sequence without performing any body part tracking we use these match to generate multiple motion projection and thus add view invariance to our action recognition model we also introduce a closed form solution for approximate non linear circulant temporal encoding ncte which allows u to efficiently perform the match in the frequency domain we test our approach on the challenging unsupervised modality of the ixmas dataset and use publicly available motion capture data for matching without any additional annotation effort we are able to significantly outperform the current state of the art 
this paper proposes a robust tracking method that us interval analysis any single posterior model necessarily includes a modeling uncertainty error and thus the posterior should be represented a an interval of probability then the objective of visual tracking becomes to find the best state that maximizes the posterior and minimizes it interval simultaneously by minimizing the interval of the posterior our method can reduce the modeling uncertainty in the posterior in this paper the aforementioned objective is achieved by using the m estimation which combine the maximum a posterior map estimation with minimum mean square error mmse maximum likelihood ml and minimum interval length mil estimation in the m estimation our method maximizes the posterior over the state obtained by the mmse estimation the method also minimizes interval of the posterior by reducing the gap between the lower and upper bound of the posterior the gap is reduced when the likelihood is maximized by the ml estimation and the interval length of the state is minimized by the mil estimation the experimental result demonstrate that m estimation can be easily integrated into conventional tracking method and can greatly enhance their tracking accuracy in several challenging datasets our method outperforms state of the art tracking method 
in this paper we introduce the novel problem of understanding visual persuasion modern mass medium make extensive use of image to persuade people to make commercial and political decision these effect and technique are widely studied in the social science but behavioral study do not scale to massive datasets computer vision ha made great stride in building syntactical representation of image such a detection and identification of object however the pervasive use of image for communicative purpose ha been largely ignored we extend the significant advance in syntactic analysis in computer vision to the higher level challenge of understanding the underlying communicative intent implied in image we begin by identifying nine dimension of persuasive intent latent in image of politician such a socially dominant energetic and trustworthy and propose a hierarchical model that build on the layer of syntactical attribute such a smile and waving hand to predict the intent presented in the image to facilitate progress we introduce a new dataset of image of politician labeled with ground truth intent in the form of ranking this study demonstrates that a systematic focus on visual persuasion open up the field of computer vision to a new class of investigation around mediated image intersecting with medium analysis psychology and political communication 
this paper present a scalable scene parsing algorithm based on image retrieval and superpixel matching we focus on rare object class which play an important role in achieving richer semantic understanding of visual scene compared to common background class towards this end we make two novel contribution rare class expansion and semantic context description first considering the long tailed nature of the label distribution we expand the retrieval set by rare class exemplar and thus achieve more balanced superpixel classification result second we incorporate both global and local semantic context information through a feedback based mechanism to refine image retrieval and superpixel matching result on the siftflow and lmsun datasets show the superior performance of our algorithm especially on the rare class without sacrificing overall labeling accuracy 
d reconstruction of transparent and specular object is a very challenging topic in computer vision for transparent and specular object which have complex interior and exterior structure that can reflect and refract light in a complex fashion it is difficult if not impossible to use either passive stereo or the traditional structured light method to do the reconstruction we propose a frequency based d reconstruction method which incorporates the frequency based matting method similar to the structured light method a set of frequency based pattern are projected onto the object and a camera capture the scene each pixel of the captured image is analyzed along the time axis and the corresponding signal is transformed to the frequency domain using the discrete fourier transform since the frequency is only determined by the source that creates it the frequency of the signal can uniquely identify the location of the pixel in the pattern in this way the correspondence between the pixel in the captured image and the point in the pattern can be acquired using a new labelling procedure the surface of transparent and specular object can be reconstructed with very encouraging result 
we study the theory of projective reconstruction for multiple projection from an arbitrary dimensional projective space into lower dimensional space this problem is important due to it application in the analysis of dynamical scene the current theory due to hartley and schaffalitzky is based on the grassmann tensor generalizing the idea of fundamental matrix trifocal tensor and quadrifocal tensor used in the well studied case of d to d projection we present a theory whose point of departure is the projective equation rather than the grassmann tensor this is a better fit for the analysis of approach such a bundle adjustment and projective factorization which seek to directly solve the projective equation in a first step we prove that there is a unique grassmann tensor corresponding to each set of image point a question that remained open in the work of hartley and schaffalitzky then we prove that projective equivalence follows from the set of projective equation given certain condition on the estimated camera point setup or the estimated projective depth finally we demonstrate how wrong solution to the projective factorization problem can happen and classify such degenerate solution based on the zero pattern in the estimated depth matrix 
the task of estimating complex non rigid d motion through a monocular camera is of increasing interest to the wider scientific community assuming one ha the d point track of the non rigid object in question the vision community refers to this problem a non rigid structure from motion nrsfm in this paper we make two contribution first we demonstrate empirically that the current state of the art approach to nrsfm i e dai et al exhibit poor reconstruction performance on complex motion i e motion involving a sequence of primitive action such a walk sit and stand involving a human object second we propose that this limitation can be circumvented by modeling complex motion a a union of subspace this doe not naturally occur in dai et al s approach which instead make a le compact summation of subspace assumption experiment on both synthetic and real video illustrate the benefit of our approach for the complex nonrigid motion analysis 
based on the concept of lacunarity in fractal geometry we developed a statistical approach to texture description which yield highly discriminative feature with strong robustness to a wide range of transformation including photometric change and geometric change the texture feature is constructed by concatenating the lacunarity related parameter estimated from the multi scale local binary pattern of image benefiting from the ability of lacunarity analysis to distinguish spatial pattern our method is able to characterize the spatial distribution of local image structure from multiple scale the proposed feature wa applied to texture classification and ha demonstrated excellent performance in comparison with several state of theart approach on four benchmark datasets 
algorithm for solving system of polynomial equation are key component for solving geometry problem in computer vision fast and stable polynomial solver are essential for numerous application e g minimal problem or finding for all stationary point of certain algebraic error recently full symmetry in the polynomial system ha been utilized to simplify and speed up state of the art polynomial solver based on gr bner basis method in this paper we further explore partial symmetry i e where the symmetry lie in a subset of the variable in the polynomial system we develop novel numerical scheme to utilize such partial symmetry we then demonstrate the advantage of our scheme in several computer vision problem in both synthetic and real experiment we show that utilizing partial symmetry allow u to obtain faster and more accurate polynomial solver than the general solver 
camera shake during exposure time often result in spatially variant blur effect of the image the non uniform blur effect is not only caused by the camera motion but also the depth variation of the scene the object close to the camera sensor are likely to appear more blurry than those at a distance in such case however recent non uniform deblurring method do not explicitly consider the depth factor or assume fronto parallel scene with constant depth for simplicity while single image non uniform deblurring is a challenging problem the blurry result in fact contain depth information which can be exploited we propose to jointly estimate scene depth and remove non uniform blur caused by camera motion by exploiting their underlying geometric relationship with only single blurry image a input to this end we present a unified layer based model for depth involved deblurring we provide a novel layer based solution using matting to partition the layer and an expectation maximization scheme to solve this problem this approach largely reduces the number of unknown and make the problem tractable experiment on challenging example demonstrate that both depth and camera shake removal can be well addressed within the unified framework 
a key problem often encountered by many learning algorithm in computer vision dealing with high dimensional data is the so called curse of dimensionality which arises when the available training sample are le than the input feature space dimensionality to remedy this problem we propose a joint dimensionality reduction and classification framework by formulating an optimization problem within the maximum margin class separation task the proposed optimization problem is solved using alternative optimization where we jointly compute the low dimensional maximum margin projection and the separating hyperplanes in the projection subspace moreover in order to reduce the computational cost of the developed optimization algorithm we incorporate orthogonality constraint on the derived projection base and show that the resulting combined model is an alternation between identifying the optimal separating hyperplanes and performing a linear discriminant analysis on the support vector experiment on face facial expression and object recognition validate the effectiveness of the proposed method against state of the art dimensionality reduction algorithm 
convolutional neural network cnn have recently shown outstanding image classification performance in the largescale visual recognition challenge ilsvrc the success of cnns is attributed to their ability to learn rich midlevel image representation a opposed to hand designed low level feature used in other image classification method learning cnns however amount to estimating million of parameter and requires a very large number of annotated image sample this property currently prevents application of cnns to problem with limited training data in this work we show how image representation learned with cnns on large scale annotated datasets can be efficiently transferred to other visual recognition task with limited amount of training data we design a method to reuse layer trained on the imagenet dataset to compute mid level image representation for image in the pascal voc dataset we show that despite difference in image statistic and task in the two datasets the transferred representation lead to significantly improved result for object and action classification outperforming the current state of the art on pascal voc and datasets we also show promising result for object and action localization 
we present a practical framework to automatically detect shadow in real world scene from a single photograph previous work on shadow detection put a lot of effort in designing shadow variant and invariant hand crafted feature in contrast our framework automatically learns the most relevant feature in a supervised manner using multiple convolutional deep neural network convnets the layer network architecture of each convnet consists of alternating convolution and sub sampling layer the proposed framework learns feature at the super pixel level and along the object boundary in both case feature are extracted using a context aware window centered at interest point the predicted posterior based on the learned feature are fed to a conditional random field model to generate smooth shadow contour our proposed framework consistently performed better than the state of the art on all major shadow database collected under a variety of condition 
while clustering ha been well studied in the past decade model selection ha drawn le attention this paper address both problem in a joint manner with an indicator matrix formulation in which the clustering cost is penalized by a frobenius inner product term and the group number estimation is achieved by a rank minimization a affinity graph generally contain positive edge value a sparsity term is further added to avoid the trivial solution rather than adopting the conventional convex relaxation approach wholesale we represent the original problem more faithfully by taking full advantage of the particular structure present in the optimization problem and solving it efficiently using the alternating direction method of multiplier the highly constrained nature of the optimization provides our algorithm with the robustness to deal with the varying and often imperfect input affinity matrix arising from different application and different group number evaluation on the synthetic data a well a two real world problem show the superiority of the method across a large variety of setting 
we propose a technique to use the structural information extracted from a set of d model of an object class to improve novel view synthesis for image showing unknown instance of this class these novel view can be used to amplify training image collection that typically contain only a low number of view or lack certain class of view entirely e g top view we extract the correlation of position normal reflectance and appearance from computer generated image of a few exemplar and use this information to infer new appearance for new instance we show that our approach can improve performance of state of the art detector using real world training data additional application include guided version of inpainting d to d conversion superresolution and non local smoothing 
we study the problem of cross population age estimation human aging is determined by the gene and influenced by many factor different population e g male and female caucasian and asian may age differently previous research ha discovered the aging difference among different population and reported large error in age estimation when crossing gender and or ethnicity in this paper we propose novel method for cross population age estimation with a good performance the proposed method are based on projecting the different aging pattern into a common space where the aging pattern can be correlated even though they come from different population the projection are also discriminative between age class due to the integration of the classical discriminant analysis technique further we study the amount of data needed in the target population to learn a cross population age estimator finally we study the feasibility of multi source cross population age estimation experiment are conducted on a large database of more than face image selected from the morph our study are valuable to significantly reduce the burden of training data collection for age estimation on a new population utilizing existing aging pattern even from different population 
the use of wearable camera make it possible to record life logging egocentric video browsing such long unstructured video is time consuming and tedious segmentation into meaningful chapter is an important first step towards adding structure to egocentric video enabling efficient browsing indexing and summarization of the long video two source of information for video segmentation are i the motion of the camera wearer and ii the object and activity recorded in the video in this paper we address the motion cue for video segmentation motion based segmentation is especially difficult in egocentric video when the camera is constantly moving due to natural head movement of the wearer we propose a robust temporal segmentation of egocentric video into a hierarchy of motion class using a new cumulative displacement curve unlike instantaneous motion vector segmentation using integrated motion vector performs well even in dynamic and crowded scene no assumption are made on the underlying scene structure and the method work in indoor a well a outdoor situation we demonstrate the effectiveness of our approach using publicly available video a well a choreographed video we also suggest an approach to detect the fixation of wearer s gaze in the walking portion of the egocentric video 
we use weakly supervised structured learning to track and disambiguate the identity of multiple indistinguishable translucent and deformable object that can overlap for many frame for this challenging problem we propose a novel model which handle occlusion complex motion and non rigid deformation by jointly optimizing the flow of multiple latent intensity across frame these flow are latent variable for which the user cannot directly provide label instead we leverage a structured learning formulation that us weak user annotation to find the best hyperparameters of this model the approach is evaluated on a challenging dataset for the tracking of multiple drosophila larva which we make publicly available our method track multiple larva in spite of their poor distinguishability and minimizes the number of identity switch during prolonged mutual occlusion 
many state of the art image restoration approach do not scale well to larger image such a megapixel image common in the consumer segment computationally expensive optimization is often the culprit while efficient alternative exist they have not reached the same level of image quality the goal of this paper is to develop an effective approach to image restoration that offer both computational efficiency and high restoration quality to that end we propose shrinkage field a random field based architecture that combine the image model and the optimization algorithm in a single unit the underlying shrinkage operation bear connection to wavelet approach but is used here in a random field context computational efficiency is achieved by construction through the use of convolution and dft a the core component high restoration quality is attained through loss based training of all model parameter and the use of a cascade architecture unlike heavily engineered solution our learning approach can be adapted easily to different trade offs between efficiency and image quality we demonstrate state of the art restoration result with high level of computational efficiency and significant speedup potential through inherent parallelism 
when using plenoptic camera for digital refocusing angular undersampling can cause severe angular aliasing artifact previous approach have focused on avoiding aliasing by pre processing the acquired light field via prefiltering demosaicing reparameterization etc in this paper we present a different solution that first detects and then remove aliasing at the light field refocusing stage different from previous frequency domain aliasing analysis we carry out a spatial domain analysis to reveal whether the aliasing would occur and uncover where in the image it would occur the spatial analysis also facilitates easy separation of the aliasing v non aliasing region and aliasing removal experiment on both synthetic scene and real light field camera array data set demonstrate that our approach ha a number of advantage over the classical prefiltering and depth dependent light field rendering technique 
intrinsic characterization of scene is often the best way to overcome the illumination variability artifact that complicate most computer vision problem from d reconstruction to object or material recognition this paper examines the deficiency of existing intrinsic image model to accurately account for the effect of illuminant color and sensor characteristic in the estimation of intrinsic image and present a generic framework which incorporates insight from color constancy research to the intrinsic image decomposition problem the proposed mathematical formulation includes information about the color of the illuminant and the effect of the camera sensor both of which modify the observed color of the reflectance of the object in the scene during the acquisition process by modeling these effect we get a truly intrinsic reflectance image which we call absolute reflectance which is invariant to change of illuminant or camera sensor this model allows u to represent a wide range of intrinsic image decomposition depending on the specific assumption on the geometric property of the scene configuration and the spectral property of the light source and the acquisition system thus unifying previous model in a single general framework we demonstrate that even partial information about sensor improves significantly the estimated reflectance image thus making our method applicable for a wide range of sensor we validate our general intrinsic image framework experimentally with both synthetic data and natural image 
graph matching and graph mining are two typical area in artificial intelligence in this paper we define the soft attributed pattern sap to describe the common subgraph pattern among a set of attributed relational graph args considering both the graphical structure and graph attribute we propose a direct solution to extract the sap with the maximal graph size without node enumeration given an initial graph template and a number of args we modify the graph template into the maximal sap among the args in an unsupervised fashion the maximal sap extraction is equivalent to learning a graphical model i e an object model from large args i e cluttered rgb rgb d image for graph matching which extends the concept of unsupervised learning for graph matching furthermore this study can be also regarded a the first known approach to formulating maximal graph mining in the graph domain of args our method exhibit superior performance on rgb and rgb d image 
with the goal of accelerating the training and testing complexity of nonlinear kernel method several recent paper have proposed explicit embeddings of the input data into low dimensional feature space where fast linear method can instead be used to generate approximate solution analogous to random fourier feature map to approximate shift invariant kernel such a the gaussian kernel on ropf d we develop a new randomized technique called random laplace feature to approximate a family of kernel function adapted to the semigroup structure of ropf d this is the natural algebraic structure on the set of histogram and other non negative data representation we provide theoretical result on the uniform convergence of random laplace feature empirical analysis on image classification and surveillance event detection task demonstrate the attractiveness of using random laplace feature relative to several other feature map proposed in the literature 
we present a machine learned ranking approach for automatically enhancing the color of a photograph unlike previous technique that train on pair of image before and after adjustment by a human user our method take into account the intermediate step taken in the enhancement process which provide detailed information on the person s color preference to make use of this data we formulate the color enhancement task a a learning to rank problem in which ordered pair of image are used for training and then various color enhancement of a novel input image can be evaluated from their corresponding rank value from the parallel between the decision tree structure we use for ranking and the decision made by a human during the editing process we posit that breaking a full enhancement sequence into individual step can facilitate training our experiment show that this approach compare well to existing method for automatic color enhancement 
video motion segmentation technique automatically segment and track object and region from video or image sequence a a primary processing step for many computer vision application we propose a novel motion segmentation approach for both rigid and non rigid object using adaptive manifold denoising we first introduce an adaptive kernel space in which two feature trajectory are mapped into the same point if they belong to the same rigid object after that we employ an embedded manifold denoising approach with the adaptive kernel to segment the motion of rigid and non rigid object the major observation is that the non rigid object often lie on a smooth manifold with deviation which can be removed by manifold denoising we also show that performing manifold denoising on the kernel space is equivalent to doing so on it range space which theoretically justifies the embedded manifold denoising on the adaptive kernel space experimental result indicate that our algorithm named adaptive manifold denoising amd is suitable for both rigid and non rigid motion segmentation our algorithm work well in many case where several state of the art algorithm fail 
the use of multiple feature for tracking ha been proved a an effective approach because limitation of each feature could be compensated since different type of variation such a illumination occlusion and pose may happen in a video sequence especially long sequence video how to dynamically select the appropriate feature is one of the key problem in this approach to address this issue in multicue visual tracking this paper proposes a new joint sparse representation model for robust feature level fusion the proposed method dynamically remove unreliable feature to be fused for tracking by using the advantage of sparse representation a a result robust tracking performance is obtained experimental result on publicly available video show that the proposed method outperforms both existing sparse representation based and fusion based tracker 
we advocate the inference of qualitative information about d human pose called posebits from image posebits represent boolean geometric relationship between body part e g left leg in front of right leg or hand close to each other the advantage of posebits a a mid level representation are for many task of interest such qualitative pose information may be sufficient e g semantic image retrieval it is relatively easy to annotate large image corpus with posebits a it simply requires answer to yes no question and they help resolve challenging pose ambiguity and therefore facilitate the difficult talk of image based d pose estimation we introduce posebits a posebit database a method for selecting useful posebits for pose estimation and a structural svm model for posebit inference experiment show the use of posebits for semantic image retrieval and for improving d pose estimation 
this paper present a new approach to tracking people in crowded scene where people are subject to long term partial occlusion and may assume varying posture and articulation in such video detection based tracker give poor performance since detecting people occurrence is not reliable and common assumption about locally smooth trajectory do not hold rather we use temporal mid level feature e g supervoxels or dense point trajectory a a more coherent spatiotemporal basis for handling occlusion and pose variation thus we formulate tracking a labeling mid level feature by object identifier and specify a new approach called constrained sequential labeling csl for performing this labeling csl us a cost function to sequentially assign label while respecting the implication of hard constraint computed via constraint propagation a key feature of this approach is that it allows for the use of flexible cost function and constraint that capture complex dependency that cannot be represented in standard network flow formulation to exploit this flexibility we describe how to learn constraint and give a provably correct learning algorithm for cost function that achieves finitetime convergence at a rate that improves with the strength of the constraint our experimental result indicate that csl outperforms the state of the art on challenging real world video of volleyball basketball and pedestrian walking 
tractography refers to the process of tracing out the nerve fiber bundle from diffusion magnetic resonance image dmri data acquired either in vivo or ex vivo tractography is a mature research topic within the field of diffusion mri analysis nevertheless several new method are being proposed on a regular basis thereby justifying the need a the problem is not fully solved tractography is usually applied to the model used to represent the diffusion mr signal or a derived quantity reconstructed from the acquired data separating shape and orientation of these model wa previously shown to approximately preserve diffusion anisotropy a useful bio marker in the ubiquitous problem of interpolation however no further intrinsic geometric property of this framework were exploited to date in literature in this paper we propose a new intrinsic recursive filter on the product manifold of shape and orientation the recursive filter dubbed iukfpro is a generalization of the unscented kalman filter ukf to this product manifold the salient contribution of this work are a new intrinsic ukf for the product manifold of shape and orientation derivation of the riemannian geometry of the product manifold iukfpro is tested on synthetic and real data set from various tractography challenge competition from the experimental result it is evident that iukfpro performs better than several competing scheme in literature with regard to some of the error measure used in the competition and is competitive with respect to others 
we present an approach msil crf that incorporates multiple instance learning mil into conditional random field crfs it can generalize crfs to work on training data with uncertain label by the principle of mil in this work it is applied to saving manual effort on annotating training data for semantic segmentation specifically we consider the setting in which the training dataset for semantic segmentation is a mixture of a few object segment and an abundant set of object bounding box our goal is to infer the unknown object segment enclosed by the bounding box so that they can serve a training data for semantic segmentation to this end we generate multiple segment hypothesis for each bounding box with the assumption that at least one hypothesis is close to the ground truth by treating a bounding box a a bag with it segment hypothesis a structured instance msil crf selects the most likely segment hypothesis by leveraging the knowledge derived from both the labeled and uncertain training data the experimental result on the pascal voc segmentation task demonstrate that msil crf can provide effective alternative to manually labeled segment for semantic segmentation 
computer vision system today fail frequently they also fail abruptly without warning or explanation alleviating the former ha been the primary focus of the community in this work we hope to draw the community s attention to the latter which is arguably equally problematic for real application we promote two metric to evaluate failure prediction we show that a surprisingly straightforward and general approach that we call alert can predict the likely accuracy or failure of a variety of computer vision system semantic segmentation vanishing point and camera parameter estimation and image memorability prediction on individual input image we also explore attribute prediction where classifier are typically meant to generalize to new unseen category we show that alert can be useful in predicting failure of this transfer finally we leverage alert to improve the performance of a downstream application of attribute prediction zero shot learning we show that alert can outperform several strong baseline for zero shot learning on four datasets 
the real world image database such a flickr are characterized by continuous addition of new image the recent approach for image annotation i e the problem of assigning tag to image have two major drawback first either model are learned using the entire training data or to handle the issue of dataset imbalance tag specific discriminative model are trained such model become obsolete and require relearning when new image and tag are added to database second the task of feature fusion is typically dealt using ad hoc approach in this paper we present a weighted extension of multi view non negative matrix factorization nmf to address the aforementioned drawback the key idea is to learn query specific generative model on the feature of nearest neighbor and tag using the proposed nmf knn approach which imposes consensus constraint on the coefficient matrix across different feature this result in coefficient vector across feature to be consistent and thus naturally solves the problem of feature fusion while the weight matrix introduced in the proposed formulation alleviate the issue of dataset imbalance furthermore our approach being query specific is unaffected by addition of image and tag in a database we tested our method on two datasets used for evaluation of image annotation and obtained competitive result 
in this paper we cast the problem of point cloud matching a a shape matching problem by transforming each of the given point cloud into a shape representation called the schr dinger distance transform sdt representation this is achieved by solving a static schr dinger equation instead of the corresponding static hamilton jacobi equation in this setting the sdt representation is an analytic expression and following the theoretical physic literature can be normalized to have unit l norm making it a square root density which is identified with a point on a unit hilbert sphere whose intrinsic geometry is fully known the fisher rao metric a natural metric for the space of density lead to analytic expression for the geodesic distance between point on this sphere in this paper we use the well known riemannian framework never before used for point cloud matching and present a novel matching algorithm we pose point set matching under rigid and non rigid transformation in this framework and solve for the transformation using standard nonlinear optimization technique finally to evaluate the performance of our algorithm dubbed sdtm we present several synthetic and real data example along with extensive comparison to state of the art technique the experiment show that our algorithm outperforms state of the art point set registration algorithm on many quantitative metric 
we consider the intersection of two research field transfer learning and statistic on manifold in particular we consider for manifold valued data transfer learning of tangent space model such a gaussians distribution pca regression or classifier though one would hope to simply use ordinary rn transfer learning idea the manifold structure prevents it we overcome this by basing our method on inner product preserving parallel transport a well known tool widely used in other problem of statistic on manifold in computer vision at first this straightforward idea seems to suffer from an obvious shortcoming transporting large datasets is prohibitively expensive hindering scalability fortunately with our approach we never transport data rather we show how the statistical model themselves can be transported and prove that for the tangent space model above the transport commute with learning consequently our compact framework applicable to a large class of manifold is not restricted by the size of either the training or test set we demonstrate the approach by transferring pca and logistic regression model of real world data involving d shape and image descriptor 
in this paper we propose a label propagation framework to handle the multiple object tracking mot problem for a generic object type cf pedestrian tracking given a target object by an initial bounding box all object of the same type are localized together with their identity we treat this a a problem of propagating bi label i e a binary class label for detection and individual object label for tracking to propagate the class label we adopt clustered multiple task learning cmtl while enforcing spatio temporal consistency and show that this improves the performance when given limited training data to track object we propagate label from trajectory to detection based on affinity using appearance motion and context experiment on public and challenging new sequence show that the proposed method improves over the current state of the art on this task 
we propose a novel motion model steadyflow to represent the motion between neighboring video frame for stabilization a steadyflow is a specific optical flow by enforcing strong spatial coherence such that smoothing feature trajectory can be replaced by smoothing pixel profile which are motion vector collected at the same pixel location in the steadyflow over time in this way we can avoid brittle feature tracking in a video stabilization system besides steadyflow is a more general d motion model which can deal with spatially variant motion we initialize the steadyflow by optical flow and then discard discontinuous motion by a spatial temporal analysis and fill in missing region by motion completion our experiment demonstrate the effectiveness of our stabilization on real world challenging video 
this paper address extracting two layer from an image where one layer is smoother than the other this problem arises most notably in intrinsic image decomposition and reflection interference removal layer decomposition from a single image is inherently ill posed and solution require additional constraint to be enforced we introduce a novel strategy that regularizes the gradient of the two layer such that one ha a long tail distribution and the other a short tail distribution while imposing the long tail distribution is a common practice our introduction of the short tail distribution on the second layer is unique we formulate our problem in a probabilistic framework and describe an optimization scheme to solve this regularization with only a few iteration we apply our approach to the intrinsic image and reflection removal problem and demonstrate high quality layer separation on par with other technique but being significantly faster than prevailing method 
visual distracters are detrimental and generally very difficult to handle in target tracking because they generate false positive candidate for target matching the resilience of region based matching to the distracters depends not only on the matching metric but also on the characteristic of the target region to be matched the two task i e learning the best metric and selecting the distracter resilient target region actually correspond to the attribute selection and spatial selection process in the human visual perception this paper present an initial attempt to unify the modeling of these two task for an effective solution based on the introduction of a new quantity called soft visual margin a a function of both matching metric and spatial location it measure the discrimination between the target and it spatial distracters and characterizes the reliability of matching different from other formulation of margin this new quantity is analytical and is insensitive to noisy data this paper present a novel method to jointly determine the best spatial location and the optimal metric based on that a solid distracter resilient region tracker is designed and it effectiveness is validated and demonstrated through extensive experiment 
an action is typically composed of different part of the object moving in particular sequence the presence of different motion represented a a d histogram ha been used in the traditional bag of word bow approach for recognizing action however the interaction among the motion also form a crucial part of an action different object part have varying degree of interaction with the other part during an action cycle it is these interaction we want to quantify in order to bring in additional information about the action in this paper we propose a causality based approach for quantifying the interaction to aid action classification granger causality is used to compute the cause and effect relationship for pair of motion trajectory of a video a d histogram descriptor for the video is constructed using these pairwise measure our proposed method of obtaining pairwise measure for video is also applicable for large datasets we have conducted experiment on challenging action recognition database such a hmdb and ucf and shown that our causality descriptor help in encoding additional information regarding the action and performs on par with the state of the art approach due to the complementary nature a further increase in performance can be observed by combining our approach with state of the art approach 
the paper proposes a diversity enhanced condensation algorithm to address the particle impoverishment problem which stochastic filtering usually suffers from the particle diversity play an important role a it affect the performance of filtering although the condensation algorithm is widely used in computer vision it easily get trapped in local minimum due to the particle degeneracy we introduce a modified evolutionary computing method adaptive differential evolution to resolve the particle impoverishment under a proper size of particle population we apply our proposed method to endoscope tracking for estimating three dimensional motion of the endoscopic camera the experimental result demonstrate that our proposed method offer more robust and accurate tracking than previous method the current tracking smoothness and error were significantly reduced from to mm mm which approximates the clinical requirement of mm 
the number of gps tagged image available on the web is increasing at a rapid rate the majority of such location tag are specified by the user either through manual tagging or localization chip embedded in the camera however a known issue with user shared image is the unreliability of such gps tag in this paper we propose a method for addressing this problem we assume a large dataset of gps tagged image which includes an unknown subset with contaminated tag is available we develop a robust method for identification and refinement of this subset using the rest of the image in the dataset in the proposed method we form a large number of triplet of matching image and use them for estimating the location of the query image utilizing structure from motion some of the generated estimation may be inaccurate due to the noisy gps tag in the dataset therefore we perform random walk on the estimation in order to identify the subset with the maximal agreement finally we estimate the gps tag of the query utilizing the identified consistent subset using a weighted mean we propose a new damping factor for random walk which conforms to the level of noise in the input and consequently robustifies random walk we evaluated the proposed framework on a dataset of over k user shared image the experiment show our method robustly improves the accuracy of gps tag under diverse scenario 
a major challenge in real world feature matching problem is to tolerate the numerous outlier arising in typical visual task variation in object appearance shape and structure within the same object class make it harder to distinguish inliers from outlier due to clutter in this paper we propose a max pooling approach to graph matching which is not only resilient to deformation but also remarkably tolerant to outlier the proposed algorithm evaluates each candidate match using it most promising neighbor and gradually propagates the corresponding score to update the neighbor a final output it assigns a reliable score to each match together with it supporting neighbor thus providing contextual information for further verification we demonstrate the robustness and utility of our method with synthetic and real image experiment 
facial feature detection from facial image ha attracted great attention in the field of computer vision it is a nontrivial task since the appearance and shape of the face tend to change under different condition in this paper we propose a hierarchical probabilistic model that could infer the true location of facial feature given the image measurement even if the face is with significant facial expression and pose the hierarchical model implicitly capture the lower level shape variation of facial component using the mixture model furthermore in the higher level it also learns the joint relationship among facial component the facial expression and the pose information through automatic structure learning and parameter estimation of the probabilistic model experimental result on benchmark database demonstrate the effectiveness of the proposed hierarchical probabilistic model 
image and video are often characterized by multiple type of local descriptor such a sift hog and hof each of which describes certain aspect of object feature recognition system benefit from fusing multiple type of these descriptor two widely applied fusion pipeline are descriptor concatenation and kernel average the first one is effective when different descriptor are strongly correlated while the second one is probably better when descriptor are relatively independent in practice however different descriptor are neither fully independent nor fully correlated and previous fusion method may not be satisfying in this paper we propose a new global representation multi view super vector mvsv which is composed of relatively independent component derived from a pair of descriptor kernel average is then applied on these component to produce recognition result to obtain mvsv we develop a generative mixture model of probabilistic canonical correlation analyzer m pcca and utilize the hidden factor and gradient vector of m pcca to construct mvsv for video representation experiment on video based action recognition task show that mvsv achieves promising result and outperforms fv and vlad with descriptor concatenation or kernel average fusion strategy 
facial expression is temporally dynamic event which can be decomposed into a set of muscle motion occurring in different facial region over various time interval for dynamic expression recognition two key issue temporal alignment and semantics aware dynamic representation must be taken into account in this paper we attempt to solve both problem via manifold modeling of video based on a novel mid level representation i e expressionlet specifically our method contains three key component each expression video clip is modeled a a spatio temporal manifold stm formed by dense low level feature a universal manifold model umm is learned over all low level feature and represented a a set of local st mode to statistically unify all the stm the local mode on each stm can be instantiated by fitting to umm and the corresponding expressionlet is constructed by modeling the variation in each local st mode with above strategy expression video are naturally aligned both spatially and temporally to enhance the discriminative power the expressionlet based stm representation is further processed with discriminant embedding our method is evaluated on four public expression database ck mmi oulu casia and afew in all case our method report result better than the known state of the art 
object category localization is a challenging problem in computer vision standard supervised training requires bounding box annotation of object instance this time consuming annotation process is sidestepped in weakly supervised learning in this case the supervised information is restricted to binary label that indicate the absence presence of object instance in the image without their location we follow a multiple instance learning approach that iteratively train the detector and infers the object location in the positive training image our main contribution is a multi fold multiple instance learning procedure which prevents training from prematurely locking onto erroneous object location this procedure is particularly important when high dimensional representation such a the fisher vector are used we present a detailed experimental evaluation using the pascal voc dataset compared to state of the art weakly supervised detector our approach better localizes object in the training image which translates into improved detection performance 
in this paper we present a novel autonomous pipeline to build a personalized parametric model pose driven avatar using a single depth sensor our method first capture a few high quality scan of the user rotating herself at multiple pose from different view we fit each incomplete scan using template fitting technique with a generic human template and register all scan to every pose using global consistency constraint after registration these watertight model with different pose are used to train a parametric model in a fashion similar to the scape method once the parametric model is built it can be used a an animitable avatar or more interestingly synthesizing dynamic d model from single view depth video experimental result demonstrate the effectiveness of our system to produce dynamic model 
the limitation of current state of the art method for single view depth estimation and semantic segmentation are closely tied to the property of perspective geometry that the perceived size of the object scale inversely with the distance in this paper we show that we can use this property to reduce the learning of a pixel wise depth classifier to a much simpler classifier predicting only the likelihood of a pixel being at an arbitrarily fixed canonical depth the likelihood for any other depth can be obtained by applying the same classifier after appropriate image manipulation such transformation of the problem to the canonical depth remove the training data bias towards certain depth and the effect of perspective the approach can be straight forwardly generalized to multiple semantic class improving both depth estimation and semantic segmentation performance by directly targeting the weakness of independent approach conditioning the semantic label on the depth provides a way to align the data to their physical scale allowing to learn a more discriminative classifier conditioning depth on the semantic class help the classifier to distinguish between ambiguity of the otherwise ill posed problem we tested our algorithm on the kitti road scene dataset and nyu indoor dataset and obtained obtained result that significantly outperform current state of the art in both single view depth and semantic segmentation domain 
this paper describes the development and application of a new approach to total variation tv minimization for reconstruction problem on geometrically complex and unstructured volumetric mesh the driving application of this study is the reconstruction of d ischemic region in the heart from noninvasive body surface potential data where the use of a tv prior can be expected to promote the reconstruction of two piecewise smooth region of healthy and ischemic electrical property with localized gradient in between compared to tv minimization on regular grid of pixel voxels the complex unstructured volumetric mesh of the heart pose unique challenge including the impact of mesh resolution on the tv prior and the difficulty of gradient calculation in this paper we introduce a variational tv prior and when combined with the iteratively re weighted least square concept a new algorithm to tv minimization that is computationally efficient and robust to the discretization resolution in a large set of simulation study a well a two initial real data study we show that the use of the proposed tv prior outperforms l based penalty in reconstruct ischemic region and it show higher robustness and efficiency compared to the commonly used discrete tv prior we also investigate the performance of the proposed tv prior in combination with a l versus l based data fidelity term the proposed method can extend tv minimization to a border range of application that involves physical domain of complex shape and unstructured volumetric mesh 
we propose a unified framework discover to simultaneously discover important segment classify high level event and generate recounting for large amount of unconstrained web video the motivation is our observation that many video event are characterized by certain important segment our goal is to find the important segment and capture their information for event classification and recounting we introduce an evidence localization model where evidence location are modeled a latent variable we impose constraint on global video appearance local evidence appearance and the temporal structure of the evidence the model is learned via a max margin framework and allows efficient inference our method doe not require annotating source of evidence and is jointly optimized for event classification and recounting experimental result are shown on the challenging trecvid medtest dataset 
we propose a joint foreground background mixture model fbm that simultaneously performs background estimation and motion segmentation in complex dynamic scene our fbm consist of a set of location specific dynamic texture dt component for modeling local background motion and set of global dt component for modeling consistent foreground motion we derive an em algorithm for estimating the parameter of the fbm we also apply spatial constraint to the fbm using an markov random field grid and derive a corresponding variational approximation for inference unlike existing approach to background subtraction our fbm doe not require a manually selected threshold or a separate training video unlike existing motion segmentation technique our fbm can segment foreground motion over complex background with mixed motion and detect stopped object since most dynamic scene datasets only contain video with a single foreground object over a simple background we develop a new challenging dataset with multiple foreground object over complex dynamic background in experiment we show that jointly modeling the background and foreground segment with fbm yield significant improvement in accuracy on both background estimation and motion segmentation compared to state of the art method 
deformable object matching which is also called elastic matching or deformation matching is an important and challenging problem in computer vision although numerous deformation model have been proposed in different matching task not many of them investigate the intrinsic physic underlying deformation due to the lack of physical analysis these model cannot describe the structure change of deformable object very well motivated by this we analyze the deformation physically and propose a novel deformation decomposition model to represent various deformation based on the physical model we formulate the matching problem a a two mensional label markov random field the mrf energy function is derived from the deformation decomposition model furthermore we propose a two stage method to optimize the mrf energy function to provide a quantitative benchmark we build a deformation matching database with an evaluation criterion experimental result show that our method outperforms previous approach especially on complex deformation 
in statistical analysis of video sequence for speech recognition and more generally activity recognition it is natural to treat temporal evolution of feature a trajectory on riemannian manifold however different evolution pattern result in arbitrary parameterizations of these trajectory we investigate a recent framework from statistic literature that handle this nuisance variability using a cost function distance for temporal registration and statistical summarization modeling of trajectory it is based on a mathematical representation of trajectory termed transported square root vector field tsrvf and the l norm on the space of tsrvfs we apply this framework to the problem of speech recognition using both audio and visual component in each case we extract feature form trajectory on corresponding manifold and compute parametrization invariant distance using tsrvfs for speech classification on the ouluvs database the classification performance under metric increase significantly by nearly under both modality and for all choice of feature we obtained speaker dependent classification rate of and for visual and audio component respectively 
weighted median in the form of either solver or filter ha been employed in a wide range of computer vision solution for it beneficial property in sparsity representation but it is hard to be accelerated due to the spatially varying weight and the median property we propose a few efficient scheme to reduce computation complexity from o r to o r where r is the kernel size our contribution is on a new joint histogram representation median tracking and a new data structure that enables fast data access the effectiveness of these scheme is demonstrated on optical flow estimation stereo matching structure texture separation image filtering to name a few the running time is largely shortened from several minute to le than second the source code is provided in the project website 
we propose filter forest ff an efficient new discriminative approach for predicting continuous variable given a signal and it context ff can be used for general signal restoration task that can be tackled via convolutional filtering where it attempt to learn the optimal filtering kernel to be applied to each data point the model can learn both the size of the kernel and it value conditioned on the observation and it spatial or temporal context we show that ff compare favorably to both markov random field based and recently proposed regression forest based approach for labeling problem in term of efficiency and accuracy in particular we demonstrate how ff can be used to learn optimal denoising filter for natural image a well a for other task such a depth image refinement and d signal magnitude estimation numerous experiment and quantitative comparison show that ffs achieve accuracy at par or superior to recent state of the art technique while being several order of magnitude faster 
in recent year large image data set such a imagenet tinyimages or ever growing social network like flickr have emerged posing new challenge to image classification that were not apparent in smaller image set in particular the efficient handling of dynamically growing data set where not only the amount of training image but also the number of class increase over time is a relatively unexplored problem to remedy this we introduce nearest class mean forest ncmf a variant of random forest where the decision node are based on nearest class mean ncm classification ncmfs not only outperform conventional random forest but are also well suited for integrating new class to this end we propose and compare several approach to incorporate data from new class so a to seamlessly extend the previously trained forest instead of re training them from scratch in our experiment we show that ncmfs trained on small data set with class can be extended to large data set with class without significant loss of accuracy compared to training from scratch on the full data 
in this paper we propose an unsupervised framework for action spotting in video that doe not depend on any specific feature e g hog hof stip silhouette bag of word etc furthermore our solution requires no human localization segmentation or framewise tracking this is achieved by treating the problem holistically a that of extracting the internal dynamic of video cuboid by modeling them in their natural form a multilinear tensor to extract their internal dynamic we devised a novel two phase decomposition tp decomp of a tensor that generates very compact and discriminative representation that are robust to even heavily perturbed data technically a rank based tensor core pyramid rank tcp descriptor is generated by combining multiple tensor core under multiple rank allowing to represent video cuboid in a hierarchical tensor pyramid the problem then reduces to a template matching problem which is solved efficiently by using two boosting strategy to reduce search space we filter the dense trajectory cloud extracted from the target video to boost the matching speed we perform matching in an iterative coarse to fine manner experiment on benchmark show that our method outperforms current state of the art under various challenging condition we also created a challenging dataset called heavily perturbed video array hpva to validate the robustness of our framework under heavily perturbed situation 
computational and memory cost restrict spectral technique to rather small graph which is a serious limitation especially in video segmentation in this paper we propose the use of a reduced graph based on superpixels in contrast to previous work the reduced graph is reweighted such that the resulting segmentation is equivalent under certain assumption to that of the full graph we consider equivalence in term of the normalized cut and of it spectral clustering relaxation the proposed method reduces runtime and memory consumption and yield on par result in image and video segmentation further it enables an efficient data representation and update for a new streaming video segmentation approach that also achieves state of the art performance 
the objective of this work is object category detection in large scale image datasets in the manner of video google an object category is specified by a hog classifier template and retrieval is immediate at run time we make the following three contribution i a new image representation based on mid level discriminative patch that is designed to be suited to immediate object category detection and inverted file indexing ii a sparse representation of a hog classifier using a set of mid level discriminative classifier patch and iii a fast method for spatial reranking image on their detection we evaluate the detection method on the standard pascal voc dataset together with a k image subset of imagenet and demonstrate near state of the art detection performance at low rank whilst maintaining immediate retrieval speed application are also demonstrated using an exemplar svm for pose matched retrieval 
this paper address the large scale visual font recognition vfr problem which aim at automatic identification of the typeface weight and slope of the text in an image or photo without any knowledge of content although visual font recognition ha many practical application it ha largely been neglected by the vision community to address the vfr problem we construct a large scale dataset containing font class which easily exceeds the scale of most image categorization datasets in computer vision a font recognition is inherently dynamic and open ended i e new class and data for existing category are constantly added to the database over time we propose a scalable solution based on the nearest class mean classifier ncm the core algorithm is built on local feature embedding local feature metric learning and max margin template selection which is naturally amenable to ncm and thus to such open ended classification problem the new algorithm can generalize to new class and new data at little added cost extensive experiment demonstrate that our approach is very effective on our synthetic test image and achieves promising result on real world test image 
a the image enhancement algorithm developed in recent year how to compare the performance of different image enhancement algorithm becomes a novel task in this paper we propose a framework to do quality assessment for comparing image enhancement algorithm not like traditional image quality assessment approach we focus on the relative quality ranking between enhanced image rather than giving an absolute quality score for a single enhanced image we construct a dataset which contains source image in bad visibility and their enhanced image processed by different enhancement algorithm and then do subjective assessment in a pair wise way to get the relative ranking of these enhanced image a rank function is trained to fit the subjective assessment result and can be used to predict rank of new enhanced image which indicate the relative quality of enhancement algorithm the experimental result show that our proposed approach statistically outperforms state of the art general purpose nr iqa algorithm 
recently multi atlas segmentation ma ha achieved a great success in the medical imaging area the key assumption of ma is that multiple atlas encompass richer anatomical variability than a single atlas therefore we can label the target image more accurately by mapping the label information from the appropriate atlas image that have the most similar structure the problem of atlas selection however still remains unexplored current state of the art ma method rely on image similarity to select a set of atlas unfortunately this heuristic criterion is not necessarily related to segmentation performance and thus may undermine segmentation result to solve this simple but critical problem we propose a learning based atlas selection method to pick up the best atlas that would eventually lead to more accurate image segmentation our idea is to learn the relationship between the pairwise appearance of observed instance a pair of atlas and target image and their final labeling performance in term of dice ratio in this way we can select the best atlas according to their expected labeling accuracy it is worth noting that our atlas selection method is general enough to be integrated with existing ma method a is shown in the experiment we achieve significant improvement after we integrate our method with widely used ma method on adni and loni lpba datasets 
the development of facial database with an abundance of annotated facial data captured under unconstrained in the wild condition have made discriminative facial deformable model the de facto choice for generic facial landmark localization even though very good performance for the facial landmark localization ha been shown by many recently proposed discriminative technique when it come to the application that require excellent accuracy such a facial behaviour analysis and facial motion capture the semi automatic person specific or even tedious manual tracking is still the preferred choice one way to construct a person specific model automatically is through incremental updating of the generic model this paper deal with the problem of updating a discriminative facial deformable model a problem that ha not been thoroughly studied in the literature in particular we study for the first time to the best of our knowledge the strategy to update a discriminative model that is trained by a cascade of regressors we propose very efficient strategy to update the model and we show that is possible to automatically construct robust discriminative person and imaging condition specific model in the wild that outperform state of the art generic face alignment strategy 
we pose the following question what happens when test data not only differs from training data but differs from it in a continually evolving way the classic domain adaptation paradigm considers the world to be separated into stationary domain with clear boundary between them however in many real world application example cannot be naturally separated into discrete domain but arise from a continuously evolving underlying process example include video with gradually changing lighting and spam email with evolving spammer tactic we formulate a novel problem of adapting to such continuous domain and present a solution based on smoothly varying embeddings recent work ha shown the utility of considering discrete visual domain a fixed point embedded in a manifold of lower dimensional subspace adaptation can be achieved via transforms or kernel learned between such stationary source and target subspace we propose a method to consider non stationary domain which we refer to a continuous manifold adaptation cma we treat each target sample a potentially being drawn from a different subspace on the domain manifold and present a novel technique for continuous transform based adaptation our approach can learn to distinguish category using training data collected at some point in the past and continue to update it model of the category for some time into the future without receiving any additional label experiment on two visual datasets demonstrate the value of our approach for several popular feature representation 
in this paper we propose a novel two step scheme to filter heavy noise from image with the assistance of retrieved web image there are two key technical contribution in our scheme first for every noisy image block we build two three dimensional d data cube by using similar block in retrieved web image and similar nonlocal block within the noisy image respectively to better use their correlation we propose different denoising strategy the denoising in the d cube built upon the retrieved image is performed a median filtering in the spatial domain whereas the denoising in the other d cube is performed in the frequency domain these two denoising result are then combined in the frequency domain to produce a denoising image second to handle heavy noise we further propose using the denoising image to improve image registration of the retrieved web image d cube building and the estimation of filtering parameter in the frequency domain afterwards the proposed denoising is performed on the noisy image again to generate the final denoising result our experimental result show that when the noise is high the proposed scheme is better than bm d by more than db in psnr and the visual quality improvement is clear to see 
this paper leverage occluding contour aka internal silhouette to improve the performance of multi view stereo method the contribution are a new technique to identify free space region arising from occluding contour and a new approach for incorporating the resulting free space constraint into poisson surface reconstruction the proposed approach outperforms state of the art mv technique for challenging internet datasets yielding dramatic quality improvement both around object contour and in surface detail 
this paper address the problem of assigning object class label to image pixel following recent holistic formulation we cast scene labeling a inference of a conditional random field crf grounded onto superpixels the crf inference is specified a quadratic program qp with mutual exclusion mutex constraint on class label assignment the qp is solved using a beam search b which is well suited for scene labeling because it explicitly account for spatial extent of object conforms to inconsistency constraint from domain knowledge and ha low computational cost b gradually build a search tree whose node correspond to candidate scene labelings successor node are repeatedly generated from a select set of their parent node until convergence we prove that our b efficiently maximizes the qp objective of crf inference effectiveness of our b for scene labeling is evaluated on the benchmark msrc stanford backgroud pascal voc and datasets 
in this work we present neural decision forest a novel approach to jointly tackle data representationand discriminative learning within randomized decision tree recent advance of deep learning architecture demonstrate the power of embedding representation learning within the classifier an idea that is intuitively supported by the hierarchical nature of the decision forest model where the input space is typically left unchanged during training and testing we bridge this gap by introducing randomized multilayer perceptrons rmlp a new split node which are capable of learning non linear data specific representation and taking advantage of them by finding optimal prediction for the emerging child node to prevent overfitting we i randomly select the image data fed to the input layer ii automatically adapt the rmlp topology to meet the complexity of the data arriving at the node and iii introduce an l norm based regularization that additionally sparsifies the network the key finding in our experiment on three different semantic image labelling datasets are consistently improved result and significantly compressed tree compared to conventional classification tree 
a the collection of large datasets becomes increasingly automated the occurrence of outlier will increase big data implies big outlier while principal component analysis pca is often used to reduce the size of data and scalable solution exist it is well known that outlier can arbitrarily corrupt the result unfortunately state of the art approach for robust pca do not scale beyond small to medium sized datasets to address this we introduce the grassmann average ga which express dimensionality reduction a an average of the subspace spanned by the data because average can be efficiently computed we immediately gain scalability ga is inherently more robust than pca but we show that they coincide for gaussian data we exploit that average can be made robust to formulate the robust grassmann average rga a a form of robust pca robustness can be with respect to vector subspace or element of vector we focus on the latter and use a trimmed average the resulting trimmed grassmann average tga is particularly appropriate for computer vision because it is robust to pixel outlier the algorithm ha low computational complexity and minimal memory requirement making it scalable to big noisy data we demonstrate tga for background modeling video restoration and shadow removal we show scalability by performing robust pca on the entire star war iv movie 
current state of the art system for visual content analysis require large training set for each class of interest and performance degrades rapidly with fewer example in this paper we present a general framework for the zeroshot learning problem of performing high level event detection with no training exemplar using only textual description this task go beyond the traditional zero shot framework of adapting a given set of class with training data to unseen class we leverage video and image collection with free form text description from widely available web source to learn a large bank of concept in addition to using several off the shelf concept detector speech and video text for representing video we utilize natural language processing technology to generate event description feature the extracted feature are then projected to a common high dimensional space using text expansion and similarity is computed in this space we present extensive experimental result on the large trecvid med corpus to demonstrate our approach our result show that the proposed concept detection method significantly outperform current attribute classifier such a classemes objectbank and sun attribute further we find that fusion both within a well a between modality is crucial for optimal performance 
in this work we address the problem of d pose estimation of multiple human from multiple view this is a more challenging problem than single human d pose estimation due to the much larger state space partial occlusion a well a across view ambiguity when not knowing the identity of the human in advance to address these problem we first create a reduced state space by triangulation of corresponding body joint obtained from part detector in pair of camera view in order to resolve the ambiguity of wrong and mixed body part of multiple human after triangulation and also those coming from false positive body part detection we introduce a novel d pictorial structure dp model our model infers d human body configuration from our reduced state space the dp model is generic and applicable to both single and multiple human pose estimation in order to compare to the state of the art we first evaluate our method on single human d pose estimation on humaneva i and kth multiview football dataset ii datasets then we introduce and evaluate our method on two datasets for multiple human d pose estimation 
this paper proposes a method for estimating the d body shape of a person with robustness to clothing we formulate the problem a optimization over the manifold of valid depth map of body shape learned from synthetic training data the manifold itself is represented using a novel data structure a multi resolution manifold forest mrmf which contains vertical edge between tree node a well a horizontal edge between node across tree that correspond to overlapping partition we show that this data structure allows both efficient localization and navigation on the manifold for on the fly building of local linear model manifold charting we demonstrate shape estimation of clothed user showing significant improvement in accuracy over global shape model and model using pre computed cluster we further compare the mrmf with alternative manifold charting method on a public dataset for estimating d motion from noisy d marker observation obtaining state of the art result 
this paper present a novel methodology for modelling pedestrian trajectory over a scene based in the hypothesis that when people try to reach a destination they use the path that take le time taking into account environmental information like the type of terrain or what other people did before thus a minimal path approach can be used to model human trajectory behaviour we develop a modified fast marching method that allows u to include both velocity and orientation in the front propagation approach without increasing it computational complexity combining all the information we create a time surface that show the time a target need to reach any given position in the scene we also create different metric in order to compare the time surface against the real behaviour experimental result over a public dataset prove the initial hypothesis correctness 
we introduce an online approach to learn possible elementary group group that contain only two target for inferring high level context that can be used to improve multi target tracking in a data association based framework unlike most existing association based tracking approach that use only low level information e g time appearance and motion to build the affinity model and consider each target a an independent agent we online learn social grouping behavior to provide additional information for producing more robust tracklets affinity social grouping behavior of pairwise target is first learned from confident tracklets and encoded in a disjoint grouping graph the grouping graph is further completed with the help of group tracking the proposed method is efficient handle group merge and split and can be easily integrated into any basic affinity model we evaluate our approach on two public datasets and show significant improvement compared with state of the art method 
this paper describes a framework for modeling human activity a temporally structured process our approach is motivated by the inherently hierarchical nature of human activity and the close correspondence between human action and speech we model action unit using hidden markov model much like word in speech these action unit then form the building block to model complex human activity a sentence using an action grammar to evaluate our approach we collected a large dataset of daily cooking activity the dataset includes a total of participant each performing a total of cooking activity in multiple real life kitchen resulting in over hour of video footage we evaluate the htk toolkit a state of the art speech recognition engine in combination with multiple video feature descriptor for both the recognition of cooking activity e g making pancake a well a the semantic parsing of video into action unit e g cracking egg our result demonstrate the benefit of structured temporal generative approach over existing discriminative approach in coping with the complexity of human daily life activity 
d reconstruction from a single image is a classical problem in computer vision however it still pose great challenge for the reconstruction of daily use object with irregular shape in this paper we propose to learn d reconstruction knowledge from informally captured rgb d image which will probably be ubiquitously used in daily life the learning of d reconstruction is defined a a category modeling problem in which a model for each category is trained to encode category specific knowledge for d reconstruction the category model estimate the pixel level d structure of an object from it d appearance by taking into account considerable variation in rotation d structure and texture learning d reconstruction from ubiquitous rgb d image creates a new set of challenge experimental result have demonstrated the effectiveness of the proposed approach 
image deblurring to remove blur caused by camera shake ha been intensively studied nevertheless most method are brittle and computationally expensive in this paper we analyze multi image approach which capture and combine multiple frame in order to make deblurring more robust and tractable in particular we compare the performance of two approach align and average and multi image deconvolution our deconvolution is non blind using a blur model obtained from real camera motion a measured by a gyroscope we show that in most situation such deconvolution outperforms align and average we also show perhaps surprisingly that deconvolution doe not benefit from increasing exposure time beyond a certain threshold to demonstrate the effectiveness and efficiency of our method we apply it to still resolution imagery of natural scene captured using a mobile camera with flexible camera control and an attached gyroscope 
a scene category imposes tight distribution over the kind of object that might appear in the scene the appearance of those object and their layout in this paper we propose a method to learn scene structure that can encode three main interlacing component of a scene the scene category the context specific appearance of object and their layout our experimental evaluation show that our learned scene structure outperform state of the art method of deformable part model in detecting object in a scene our scene structure provides a level of scene understanding that is amenable to deep visual inference the scene structure can also generate feature that can later be used for scene categorization using these feature we also show promising result on scene categorization 
most state of the art dynamic scene deblurring method based on accurate motion segmentation assume that motion blur is small or that the specific type of motion causing the blur is known in this paper we study a motion segmentation free dynamic scene deblurring method which is unlike other conventional method when the motion can be approximated to linear motion that is locally pixel wise varying we can handle various type of blur caused by camera shake including out of plane motion depth variation radial distortion and so on thus we propose a new energy model simultaneously estimating motion flow and the latent image based on robust total variation tv l model this approach is necessary to handle abrupt change in motion without segmentation furthermore we address the problem of the traditional coarse to fine deblurring framework which give rise to artifact when restoring small structure with distinct motion we thus propose a novel kernel re initialization method which reduces the error of motion flow propagated from a coarser level moreover a highly effective convex optimization based solution mitigating the computational difficulty of the tv l model is established comparative experimental result on challenging real blurry image demonstrate the efficiency of the proposed method 
we present a novel co segmentation method for textured d shape our algorithm take a collection of textured shape belonging to the same category and sparse annotation of foreground segment and produce a joint dense segmentation of the shape in the collection we model the segment by a collectively trained gaussian mixture model the final model segmentation is formulated a an energy minimization across all model jointly where intra model edge control the smoothness and separation of model segment and inter model edge impart global consistency we show promising result on two large real world datasets and also compare with previous shape only d segmentation method using publicly available datasets 
we present a novel approach for event detection in video by temporal sequence modeling exploiting temporal information ha lain at the core of many approach for video analysis i e action activity and event recognition unlike previous work doing temporal modeling at semantic event level we propose to model temporal dependency in the data at sub event level without using event annotation this free our model from ground truth and address several limitation in previous work on temporal modeling based on this idea we represent a video by a sequence of visual word learnt from the video and apply the sequence memoizer to capture long range dependency in a temporal context in the visual sequence this data driven temporal model is further integrated with event classification for jointly performing segmentation and classification of event in a video we demonstrate the efficacy of our approach on two challenging datasets for visual recognition 
accurate ground truth pose is essential to the training of most existing head pose estimation algorithm however in many case the ground truth pose is obtained in rather subjective way such a asking the human subject to stare at different marker on the wall in such case it is better to use soft label rather than explicit hard label therefore this paper proposes to associate a multivariate label distribution mld to each image an mld cover a neighborhood around the original pose labeling the image with mld can not only alleviate the problem of inaccurate pose label but also boost the training example associated to each pose without actually increasing the total amount of training example two algorithm are proposed to learn from the mld by minimizing the weighted jeffrey s divergence between the predicted mld and the ground truth mld experimental result show that the mld based method perform significantly better than the compared state of the art head pose estimation algorithm 
the construction of facial deformable model fdms is a very challenging computer vision problem since the face is a highly deformable object and it appearance drastically change under different pose expression and illumination although several method for generic fdms construction have been proposed for facial landmark localization in still image they are insufficient for task such a facial behaviour analysis and facial motion capture where perfect landmark localization is required in this case person specific fdms psms are mainly employed requiring manual facial landmark annotation for each person and person specific training in this paper a novel method for the automatic construction of psms is proposed to this end an orthonormal subspace which is suitable for facial image reconstruction is learnt next to correct the fitting of a generic model image congealing i e batch image aliment is performed by employing only the learnt orthonormal subspace finally the corrected fitting are used to construct the psm the image congealing problem is solved by formulating a suitable sparsity regularized rank minimization problem the proposed method outperforms the state of the art method that is compared to in term of both landmark localization accuracy and computational time 
expression and pose variation are major challenge for reliable face recognition fr in d in this paper we aim to endow state of the art face recognition sdks with robustness to facial expression variation and pose change by using an extended d morphable model dmm which isolates identity variation from those due to facial expression specifically given a probe with expression a novel view of the face is generated where the pose is rectified and the expression neutralized we present two method of expression neutralization the first one us prior knowledge to infer the neutral expression image from an input image the second method specifically designed for verification is based on the transfer of the gallery face expression to the probe experiment using rectified and neutralized view with a standard commercial fr sdk on two d face database namely multi pie and ar show significant performance improvement of the commercial sdk to deal with expression and pose variation and demonstrates the effectiveness of the proposed approach 
inferring human gaze from low resolution eye image is still a challenging task despite it practical importance in many application scenario this paper present a learning by synthesis approach to accurate image based gaze estimation that is personand head pose independent unlike existing appearance based method that assume person specific training data we use a large amount of cross subject training data to train a d gaze estimator we collect the largest and fully calibrated multi view gaze dataset and perform a d reconstruction in order to generate dense training data of eye image by using the synthesized dataset to learn a random regression forest we show that our method outperforms existing method that use low resolution eye image 
in this paper we deal with the image deblurring problem in a completely new perspective by proposing separable kernel to represent the inherent property of the camera and scene system specifically we decompose a blur kernel into three individual descriptor trajectory intensity and point spread function so that they can be optimized separately to demonstrate the advantage we extract one pixel width trajectory of blur kernel and propose a random perturbation algorithm to optimize them but still keeping their continuity for many case where current deblurring approach fall into local minimum excellent deblurred result and correct blur kernel can be obtained by individually optimizing the kernel trajectory our work strongly suggests that more constraint and prior should be introduced to blur kernel in solving the deblurring problem because blur kernel have lower dimension than image 
in this paper we tackle the problem of co localization in real world image co localization is the problem of simultaneously localizing with bounding box object of the same class across a set of distinct image although similar problem such a co segmentation and weakly supervised localization have been previously studied we focus on being able to perform co localization in real world setting which are typically characterized by large amount of intra class variation inter class diversity and annotation noise to address these issue we present a joint image box formulation for solving the co localization problem and show how it can be relaxed to a convex quadratic program which can be efficiently solved we perform an extensive evaluation of our method compared to previous state of the art approach on the challenging pascal voc and object discovery datasets in addition we also present a large scale study of co localization on imagenet involving ground truth annotation for class and approximately million image 
in this paper we propose a switchable deep network sdn for pedestrian detection the sdn automatically learns hierarchical feature salience map and mixture representation of different body part pedestrian detection face the challenge of background clutter and large variation of pedestrian appearance due to pose and viewpoint change and other factor one of our key contribution is to propose a switchable restricted boltzmann machine srbm to explicitly model the complex mixture of visual variation at multiple level at the feature level it automatically estimate saliency map for each test sample in order to separate background clutter from discriminative region for pedestrian detection at the part and body level it is able to infer the most appropriate template for the mixture model of each part and the whole body we have devised a new generative algorithm to effectively pretrain the sdn and then fine tune it with back propagation our approach is evaluated on the caltech and eth datasets and achieves the state of the art detection performance 
in this paper we consider the approximate weighted graph matching problem and introduce stable and informative first and second order compatibility term suitable for inclusion into the popular integer quadratic program formulation our approach relies on a rigorous analysis of stability of spectral signature based on the graph laplacian in the case of the first order term we derive an objective function that measure both the stability and informativeness of a given spectral signature by optimizing this objective we design new spectral node signature tuned to a specific graph to be matched we also introduce the pairwise heat kernel distance a a stable second order compatibility term we justify it plausibility by showing that in a certain limiting case it converges to the classical adjacency matrix based second order compatibility function we have tested our approach on a set of synthetic graph the widely used cmu house sequence and a set of real image these experiment show the superior performance of our first and second order compatibility term a compared with the commonly used one 
high dimensional representation such a vlad or fv have shown excellent accuracy in action recognition this paper show that a proper encoding built upon vlad can achieve further accuracy boost with only negligible computational cost we empirically evaluated various vlad improvement technology to determine good practice in vlad based video encoding furthermore we propose an interpretation that vlad is a maximum entropy linear feature learning process combining this new perspective with observed vlad data distribution property we propose a simple lightweight but powerful bimodal encoding method evaluated on benchmark action recognition datasets ucf hmdb and youtube the bimodal encoding improves vlad by large margin in action recognition 
in this paper we present a depth guided photometric d reconstruction method that work solely with a depth camera like the kinect existing method that fuse depth with normal estimate use an external rgb camera to obtain photometric information and treat the depth camera a a black box that provides a low quality depth estimate our contribution to such method are two fold firstly instead of using an extra rgb camera we use the infra red ir camera of the depth camera system itself to directly obtain high resolution photometric information we believe that ours is the first method to use an ir depth camera system in this manner secondly photometric method applied to complex object result in numerous hole in the reconstructed surface due to shadow and self occlusion to mitigate this problem we develop a simple and effective multiview reconstruction approach that fuse depth and normal information from multiple viewpoint to build a complete consistent and accurate d surface representation we demonstrate the efficacy of our method to generate high quality d surface reconstruction for some complex d figurine 
a method for online real time learning of individual object detector is presented starting with a pre trained boosted category detector an individual object detector is trained with near zero computational cost the individual detector is obtained by using the same feature cascade a the category detector along with elementary manipulation of the threshold of the weak classifier this is ideal for online operation on a video stream or for interactive learning application addressed by this technique are reidentification and individual tracking experiment on four challenging pedestrian and face datasets indicate that it is indeed possible to learn identity classifier in real time besides being faster trained our classifier ha better detection rate than previous method on two of the datasets 
depth captured by consumer rgb d camera is often noisy and miss value at some pixel especially around object boundary most existing method complete the missing depth value guided by the corresponding color image when the color image is noisy or the correlation between color and depth is weak the depth map cannot be properly enhanced in this paper we present a depth map enhancement algorithm that performs depth map completion and de noising simultaneously our method is based on the observation that similar rgb d patch lie in a very low dimensional subspace we can then assemble the similar patch into a matrix and enforce this low rank subspace constraint this low rank subspace constraint essentially capture the underlying structure in the rgb d patch and enables robust depth enhancement against the noise or weak correlation between color and depth based on this subspace constraint our method formulates depth map enhancement a a low rank matrix completion problem since the rank of a matrix change over matrix we develop a data driven method to automatically determine the rank number for each matrix the experiment on both public benchmark and our own captured rgb d image show that our method can effectively enhance depth map 
in the following paper we present an approach for fine grained recognition based on a new part detection method in particular we propose a nonparametric label transfer technique which transfer part constellation from object with similar global shape the possibility for transferring part annotation to unseen image allows for coping with a high degree of pose and view variation in scenario where traditional detection model such a deformable part model fail our approach is especially valuable for fine grained recognition scenario where intraclass variation are extremely high and precisely localized feature need to be extracted furthermore we show the importance of carefully designed visual extraction strategy such a combination of complementary feature type and iterative image segmentation and the resulting impact on the recognition performance in experiment our simple yet powerful approach achieves and accuracy on the cub and bird datasets which is the current best performance for these benchmark 
recently introduced cost effective depth sensor coupled with the real time skeleton estimation algorithm of shotton et al have generated a renewed interest in skeleton based human action recognition most of the existing skeleton based approach use either the joint location or the joint angle to represent a human skeleton in this paper we propose a new skeletal representation that explicitly model the d geometric relationship between various body part using rotation and translation in d space since d rigid body motion are member of the special euclidean group se the proposed skeletal representation lie in the lie group se se which is a curved manifold using the proposed representation human action can be modeled a curve in this lie group since classification of curve in this lie group is not an easy task we map the action curve from the lie group to it lie algebra which is a vector space we then perform classification using a combination of dynamic time warping fourier temporal pyramid representation and linear svm experimental result on three action datasets show that the proposed representation performs better than many existing skeletal representation the proposed approach also outperforms various state of the art skeleton based human action recognition approach 
gaussian mixture model have become one of the major tool in modern statistical image processing and allowed performance breakthrough in patch based image denoising and restoration problem nevertheless their adoption level wa kept relatively low because of the computational cost associated to learning such model on large image database this work provides a flexible and generic tool for dealing with such model without the computational penalty or parameter tuning difficulty associated to a na ve implementation of gmm based image restoration task it doe so by organising the data manifold in a hirerachical multiscale structure the covariance tree that can be queried at various scale level around any point in feature space we start by explaining how to construct a covariance tree from a subset of the input data how to enrich it statistic from a larger set in a streaming process and how to query it efficiently at any scale we then demonstrate it usefulness on several application including non local image filtering data driven denoising reconstruction from random sample and surface modeling from unorganized d point set 
we introduce a general framework for quickly annotating an image dataset when previous annotation exist the new annotation e g part location may be quite different from the old annotation e g segmentation human annotator may be thought of a helping translate the old annotation into the new one a annotator label image our algorithm incrementally learns a translator from source to target label a well a a computer vision based structured predictor these two component are combined to form an improved prediction system which accelerates the annotator work through a smart gui we show how the method can be applied to translate between a wide variety of annotation type including bounding box segmentation d and d part based system and class and attribute label the proposed system will be a useful tool toward exploring new type of representation beyond simple bounding box object segmentation and class label and toward finding new way to exploit existing large datasets with traditional type of annotation like sun image net and pascal voc experiment on the cub and h d datasets demonstrate our method accelerates collection of part annotation by a factor of compared to manual labeling our system can be used effectively in a scheme where definition of part attribute or action vocabulary are evolved interactively without relabeling the entire dataset and toward collecting pose annotation segmentation are more useful than bounding box and part level annotation are more effective than segmentation 
we address the challenging problem of utilizing related exemplar for complex event detection while multiple feature are available related exemplar share certain positive element of the event but have no uniform pattern due to the huge variance of relevance level among different related exemplar none of the existing multiple feature fusion method can deal with the related exemplar in this paper we propose an algorithm which adaptively utilizes the related exemplar by cross feature learning ordinal label are used to represent the multiple relevance level of the related video label candidate of related exemplar are generated by exploring the possible relevance level of each related exemplar via a cross feature voting strategy maximum margin criterion is then applied in our framework to discriminate the positive and negative exemplar a well a the related exemplar from different relevance level we test our algorithm using the large scale trecvid dataset and it gain promising performance 
this paper aim for generic instance search from a single example where the state of the art relies on global image representation for the search we proceed by including locality at all step of the method a the first novelty we consider many box per database image a candidate target to search locally in the picture using an efficient point indexed representation the same representation allows a the second novelty the application of very large vocabulary in the powerful fisher vector and vlad to search locally in the feature space a the third novelty we propose an exponential similarity function to further emphasize locality in the feature space locality is advantageous in instance search a it will rest on the matching unique detail we demonstrate a substantial increase in generic instance search performance from one example on three standard datasets with building logo and scene from to in map 
recently there ha been a great interest in computeraided alzheimer s disease ad and mild cognitive impairment mci diagnosis previous learning based method defined the diagnosis process a a classification task and directly used the low level feature extracted from neuroimaging data without considering relation among them however from a neuroscience point of view it s well known that a human brain is a complex system that multiple brain region are anatomically connected and functionally interact with each other therefore it is natural to hypothesize that the low level feature extracted from neuroimaging data are related to each other in some way to this end in this paper we first devise a coupled feature representation by utilizing intra coupled and inter coupled interaction relationship regarding multi modal data fusion we propose a novel coupled boosting algorithm that analyzes the pairwise coupled diversity correlation between modality specifically we formulate a new weight updating function which considers both incorrectly and inconsistently classified sample in our experiment on the adni dataset the proposed method presented the best performance with accuracy of and for ad v normal control nc and mci v nc classification respectively outperforming the competing method and the state of the art method 
laser range sensor are often demanded to mount on a moving platform for achieving the good efficiency of d reconstruction however such moving system often suffer from the difficulty of matching the distorted range scan in this paper we propose novel d feature which can be robustly extracted and matched even for the distorted d surface captured by a moving system our feature extraction employ morse theory to construct morse function which capture the critical point approximately invariant to the d surface distortion then for each critical point we extract support region with the maximally stable region defined by extremal region or disconnectivity our feature description is designed a two step we normalize the detected local region to canonical shape for robust matching we encode each key point with multiple vector at different morse function value in experiment we demonstrate that the proposed d feature achieve substantially better performance for distorted surface matching than the state of the art method 
dense d reconstruction of real world object containing textureless reflective and specular part is a challenging task using general smoothness prior such a surface area regularization can lead to defect in the form of disconnected part or unwanted indentation we argue that this problem can be solved by exploiting the object class specific local surface orientation e g a car is always close to horizontal in the roof area therefore we formulate an object class specific shape prior in the form of spatially varying anisotropic smoothness term the parameter of the shape prior are extracted from training data we detail how our shape prior formulation directly fit into recently proposed volumetric multi label reconstruction approach this allows a segmentation between the object and it supporting ground in our experimental evaluation we show reconstruction using our trained shape prior on several challenging datasets 
we show that a non isotropic near point light source rigidly attached to a camera can be calibrated using multiple image of a weakly textured planar scene we prove that if the radiant intensity distribution rid of a light source is radially symmetric with respect to it dominant direction then the shading observed on a lambertian scene plane is bilaterally symmetric with respect to a d line on the plane the symmetry axis detected in an image provides a linear constraint for estimating the dominant light axis the light position and rid parameter can then be estimated using a linear method specular highlight if available can also be used for light position estimation we also extend our method to handle non lambertian reflectance which we model using a biquadratic brdf we have evaluated our method on synthetic data quantitavely our experiment on real scene show that our method work well in practice and enables light calibration without the need of a specialized hardware 
the recent advance in rgb d camera have allowed u to better solve increasingly complex computer vision task however modern rgb d camera are still restricted by the short effective distance the limitation may make rgb d camera not online accessible in practice and degrade their applicability we propose an alternative scenario to address this problem and illustrate it with the application to action recognition we use kinect to offline collect an auxiliary multi modal database in which not only the rgb video but also the depth map and skeleton structure of action of interest are available our approach aim to enhance action recognition in rgb video by leveraging the extra database specifically it optimizes a feature transformation by which the action to be recognized can be concisely reconstructed by entry in the auxiliary database in this way the inter database variation are adapted more importantly each action can be augmented with additional depth and skeleton image retrieved from the auxiliary database the proposed approach ha been evaluated on three benchmark of action recognition the promising result manifest that the augmented depth and skeleton feature can lead to remarkable boost in recognition accuracy 
robust tracking of deformable object like catheter or vascular structure in x ray image is an important technique used in image guided medical intervention for effective motion compensation and dynamic multi modality image fusion tracking of such anatomical structure and device is very challenging due to large degree of appearance change low visibility of x ray image and the deformable nature of the underlying motion field a a result of complex d anatomical movement projected into d image to address these issue we propose a new deformable tracking method using the tensor based algorithm with model propagation specifically the deformable tracking is formulated a a multi dimensional assignment problem which is solved by rank l tensor approximation the model prior is propagated in the course of deformable tracking both the higher order information and the model prior provide powerful discriminative cue for reducing ambiguity arising from the complex background and consequently improve the tracking robustness to validate the proposed approach we applied it to catheter and vascular structure tracking and tested on x ray fluoroscopic sequence obtained from clinical case the result show both quantitatively and qualitatively that our approach achieves a mean tracking error of pixel for vascular structure and pixel for catheter tracking 
in this paper we propose a novel formulation for multi feature clustering using minimax optimization to find a consensus clustering result that is agreeable to all feature modality our objective is to find a universal feature embedding which not only fit each individual feature modality well but also unifies different feature modality by minimizing their pairwise disagreement the loss function consists of both unary embedding cost for each modality and pairwise disagreement cost for each pair of modality with weighting parameter automatically selected to maximize the loss by performing minimax optimization we can minimize the loss for the worst case with maximum disagreement thus can better reconcile different feature modality to solve the minimax optimization an iterative solution is proposed to update the universal embedding individual embedding and fusion weight separately our minimax optimization ha only one global parameter the superior result on various multi feature clustering task validate the effectiveness of our approach when compared with the state of the art method 
this paper present a unified bag of visual word bow framework for dynamic scene recognition the approach build on primitive feature that uniformly capture spatial and temporal orientation structure of the imagery e g video a extracted via application of a bank of spatiotemporally oriented filter various feature encoding technique are investigated to abstract the primitive to an intermediate representation that is best suited to dynamic scene representation further a novel approach to adaptive pooling of the encoded feature is presented that capture spatial layout of the scene even while being robust to situation where camera motion and scene dynamic are confounded the resulting overall approach ha been evaluated on two standard publically available dynamic scene datasets the result show that in comparison to a representative set of alternative the proposed approach outperforms the previous state of the art in classification accuracy by 
persistent surveillance of large geographic area from unmanned aerial vehicle allows u to learn much about the daily activity in the region of interest nearly all of the approach addressing tracking in this imagery are detection based and rely on background subtraction or frame differencing to provide detection this however make it difficult to track target once they slow down or stop which is not acceptable for persistent tracking our goal we present a multiple target tracking approach that doe not exclusively rely on background subtraction and is better able to track target through stop it accomplishes this by effectively running two tracker in parallel one based on detection from background subtraction providing target initialization and reacquisition and one based on a target state regressor providing frame to frame tracking we evaluated the proposed approach on a long sequence from a wide area aerial imagery dataset and the result show improved object detection rate and id switch rate with limited increase in false alarm compared to the competition 
recently unsupervised image segmentation ha become increasingly popular starting from a superpixel segmentation an edge weighted region adjacency graph is constructed amongst all segmentation of the graph the one which best conforms to the given image evidence a measured by the sum of cut edge weight is chosen since this problem is np hard we propose a new approximate solver based on the move making paradigm first the graph is recursively partitioned into small region cut phase then for any two adjacent region we consider alternative cut of these two region defining possible move glue cut phase for planar problem the optimal move can be found whereas for non planar problem efficient approximation exist we evaluate our algorithm on published and new benchmark datasets which we make available here the proposed algorithm find segmentation that a measured by a loss function are a close to the ground truth a the global optimum found by exact solver it doe so significantly faster then existing approximate method which is important for large scale problem 
we present an image set classification algorithm based on unsupervised clustering of labeled training and unlabeled test data where label are only used in the stopping criterion the probability distribution of each class over the set of cluster is used to define a true set based similarity measure to this end we propose an iterative sparse spectral clustering algorithm in each iteration a proximity matrix is efficiently recomputed to better represent the local subspace structure initial cluster capture the global data structure and finer cluster at the later stage capture the subtle class difference not visible at the global scale image set are compactly represented with multiple grassmannian manifold which are subsequently embedded in euclidean space with the proposed spectral clustering algorithm we also propose an efficient eigenvector solver which not only reduces the computational cost of spectral clustering by many fold but also improves the clustering quality and final classification result experiment on five standard datasets and comparison with seven existing technique show the efficacy of our algorithm 
motivated by a bayesian vision of the d multi view reconstruction from image problem we propose a dense d reconstruction technique that jointly refines the shape and the camera parameter of a scene by minimizing the photometric reprojection error between a generated model and the observed image hence considering all pixel in the original image the minimization is performed using a gradient descent scheme coherent with the shape representation here a triangular mesh where we derive evolution equation in order to optimize both the shape and the camera parameter this can be used at a last refinement step in d reconstruction pipeline and help improving the d reconstruction s quality by estimating the d shape and camera calibration more accurately example are shown for multi view stereo where the texture is also jointly optimized and improved but could be used for any generative approach dealing with multi view reconstruction setting ie depth map fusion multi view photometric stereo 
we propose a data structure that capture global geometric property in image histogram of mirror symmetry coefficient we compute such a coefficient for every pair of pixel and group them in a dimensional histogram by marginalizing the hmsc in various way we develop algorithm for a range of application detection of nearly circular cell location of the main axis of reflection symmetry detection of cell division in movie of developing embryo detection of worm tip and indirect cell counting via supervised classification our approach generalizes a series of histogram related method and the proposed algorithm perform with state of the art accuracy 
in this paper we address the problem of recognizing image with weakly annotated text tag most previous work either cannot be applied to the scenario where the tag are loosely related to the image or simply take a pre fusion at the feature level or a post fusion at the decision level to combine the visual and textual content instead we first encode the text tag a the relation among the image and then propose a semi supervised relational topic model s rtm to explicitly model the image content and their relation in such way we can efficiently leverage the loosely related tag and build an intermediate level representation for a collection of weakly annotated image the intermediate level representation can be regarded a a mid level fusion of the visual and textual content which is able to explicitly model their intrinsic relationship moreover image category label are also modeled in the s rtm and recognition can be conducted without training an additional discriminative classifier our extensive experiment on social multimedia datasets image tag demonstrated the advantage of the proposed model 
in this paper we provide the first to the best of our knowledge bayesian formulation of one of the most successful and well studied statistical model of shape and texture i e active appearance model aams to this end we use a simple probabilistic model for texture generation assuming both gaussian noise and a gaussian prior over a latent texture space we retrieve the shape parameter by formulating a novel cost function obtained by marginalizing out the latent texture space this result in a fast implementation when compared to other simultaneous algorithm for fitting aams mainly due to the removal of the calculation of texture parameter we demonstrate that contrary to what is believed regarding the performance of aams in generic fitting scenario optimization of the proposed cost function produce result that outperform discriminatively trained state of the art method in the problem of facial alignment in the wild 
in this paper we propose an efficient method to reconstruct surface from gradient sfg our method is formulated under the framework of discrete geometry processing unlike the existing sfg approach we transfer the continuous reconstruction problem into a discrete space and efficiently solve the problem via a sequence of least square optimization step our discrete formulation brings three advantage the reconstruction preserve sharp feature sparse incomplete set of gradient can be well handled and domain of computation can have irregular boundary our formulation is direct and easy to implement and the comparison with state of the art show the effectiveness of our method 
given a single outdoor image this paper proposes a collaborative learning approach for labeling it a either sunny or cloudy never adequately addressed this twoclass classification problem is by no mean trivial given the great variety of outdoor image our weather feature combine special cue after properly encoding them into feature vector they then work collaboratively in synergy under a unified optimization framework that is aware of the presence or absence of a given weather cue during learning and classification extensive experiment and comparison are performed to verify our method we build a new weather image dataset consisting of k sunny and cloudy image which is available online together with the executable 
we propose a purely geometric correspondence free approach to urban geo localization using d point ray feature extracted from the digital elevation map of an urban environment we derive a novel formulation for estimating the camera pose locus using d to d correspondence of a single point and a single direction alone we show how this allows u to compute putative correspondence between building corner in the dem and the query image by exhaustively combining pair of point ray feature then we employ the two point method to estimate both the camera pose and compute correspondence between building in the dem and the query image finally we show that the computed camera pose can be efficiently ranked by a simple skyline projection step using building edge from the dem our experimental evaluation illustrates the promise of a purely geometric approach to the urban geo localization problem 
the output of many algorithm in computer vision is either non binary map or binary map e g salient object detection and object segmentation several measure have been suggested to evaluate the accuracy of these foreground map in this paper we show that the most commonly used measure for evaluating both non binary map and binary map do not always provide a reliable evaluation this includes the area under the curve measure the average precision measure the f measure and the evaluation measure of the pascal voc segmentation challenge we start by identifying three cause of inaccurate evaluation we then propose a new measure that amends these flaw an appealing property of our measure is being an intuitive generalization of the f measure finally we propose four meta measure to compare the adequacy of evaluation measure we show via experiment that our novel measure is preferable 
we propose a shape matching method that produce dense correspondence tuned to a specific class of shape and deformation in a scenario where this class is represented by a small set of example shape the proposed method learns a shape descriptor capturing the variability of the deformation in the given class the approach enables the wave kernel signature to extend the class of recognized deformation from near isometry to the deformation appearing in the example set by mean of a random forest classifier with the help of the introduced spatial regularization the proposed method achieves significant improvement over the baseline approach and obtains state of the art result while keeping short computation time 
local video feature provide state of the art performance for action recognition while the accuracy of action recognition ha been continuously improved over the recent year the low speed of feature extraction and subsequent recognition prevents current method from scaling up to real size problem we address this issue and first develop highly efficient video feature using motion information in video compression we next explore feature encoding by fisher vector and demonstrate accurate action recognition using fast linear classifier our method improves the speed of video feature extraction feature encoding and action classification by two order of magnitude at the cost of minor reduction in recognition accuracy we validate our approach and compare it to the state of the art on four recent action recognition datasets 
gradient domain method are popular for image processing however these method even the edge preserving one cannot preserve edge well in some case in this paper we present new constraint explicitly to better preserve edge for general gradient domain image filtering and theoretically analyse why these constraint are edge aware our edge aware constraint are easy to implement fast to compute and can be seamlessly integrated into the general gradient domain optimization framework the improved framework can better preserve edge while maintaining similar image filtering effect a the original image filter we also demonstrate the strength of our edge aware constraint on various application such a image smoothing image colorization and poisson image cloning 
we address the problem of estimating the pose of a camera relative to a known d scene from a single rgb d frame we formulate this problem a inversion of the generative rendering procedure i e we want to find the camera pose corresponding to a rendering of the d scene model that is most similar with the observed input this is a non convex optimization problem with many local optimum we propose a hybrid discriminative generative learning architecture that consists of i a set of m predictor which generate m camera pose hypothesis and ii a selector or aggregator that infers the best pose from the multiple pose hypothesis based on a similarity function we are interested in predictor that not only produce good hypothesis but also hypothesis that are different from each other thus we propose and study method for learning marginally relevant predictor and compare their performance when used with different selection procedure we evaluate our method on a recently released d reconstruction dataset with challenging camera pose and scene variability experiment show that our method learns to make multiple prediction that are marginally relevant and can effectively select an accurate prediction furthermore our method outperforms the state of the art discriminative approach for camera relocalization 
we consider the problem of localizing a novel image in a large d model in principle this is just an instance of camera pose estimation but the scale introduces some challenging problem for one it make the correspondence problem very difficult and it is likely that there will be a significant rate of outlier to handle in this paper we use recent theoretical a well a technical advance to tackle these problem many modern camera and phone have gravitational sensor that allow u to reduce the search space further there are new technique to efficiently and reliably deal with extreme rate of outlier we extend these method to camera pose estimation by using accurate approximation and fast polynomial solver experimental result are given demonstrating that it is possible to reliably estimate the camera pose despite more than of outlier correspondence 
in this paper we tackle the problem of unsupervised domain adaptation for classification in the unsupervised scenario where no labeled sample from the target domain are provided a popular approach consists in transforming the data such that the source and target distribution become similar to compare the two distribution existing approach make use of the maximum mean discrepancy mmd however this doe not exploit the fact that probability distribution lie on a riemannian manifold here we propose to make better use of the structure of this manifold and rely on the distance on the manifold to compare the source and target distribution in this framework we introduce a sample selection method and a subspace based method for unsupervised domain adaptation and show that both these manifold based technique outperform the corresponding approach based on the mmd furthermore we show that our subspace based approach yield state of the art result on a standard object recognition benchmark 
in this paper we propose a weighted supervised pooling method for visual recognition system we combine a standard spatial pyramid representation which is commonly adopted to encode spatial information with an appropriate feature space representation favoring semantic information in an appropriate feature space for the latter we propose a weighted pooling strategy exploiting data supervision to weigh each local descriptor coherently with it likelihood to belong to a given object class the two representation are then combined adaptively with multiple kernel learning experiment on common benchmark caltech and pascal voc show that our image representation improves the current visual recognition pipeline and it is competitive with similar state of art pooling method we also evaluate our method on a real human robot interaction setting where the pure spatial pyramid representation doe not provide sufficient discriminative power obtaining a remarkable improvement 
in this paper we propose a technique for video object segmentation using patch seam across frame typically seam which are connected path of low energy are utilised for retargeting where the primary aim is to reduce the image size while preserving the salient image content here we adapt the formulation of seam for temporal label propagation the energy function associated with the proposed video seam provides temporal linking of patch across frame to accurately segment the object the proposed energy function take into account the similarity of patch along the seam temporal consistency of motion and spatial coherency of seam label propagation is achieved with high fidelity in the critical boundary region utilising the proposed patch seam to achieve this without additional overhead we curtail the error propagation by formulating boundary region a rough set the proposed approach out perform state of the art supervised and unsupervised algorithm on benchmark datasets 
we present a new method for tracking the d position global orientation and full articulation of human hand following recent advance in model based hypothesize and test method the high dimensional parameter space of hand configuration is explored with a novel evolutionary optimization technique specifically tailored to the problem the proposed method capitalizes on the fact that sample from quasi random sequence such a the sobol have low discrepancy and exhibit a more uniform coverage of the sampled space compared to random sample obtained from the uniform distribution the method ha been tested for the problem of tracking the articulation of a single hand d parameter space and two hand d space extensive experiment have been carried out with synthetic and real data in comparison with state of the art method the quantitative evaluation show that for case of limited computational resource the new approach achieves a speed up of four single hand tracking and eight two hand tracking without compromising tracking accuracy interestingly the proposed method is preferable compared to the state of the art either in the case of limited computational resource or in the case of more complex i e higher dimensional problem thus improving the applicability of the method in a number of application domain 
this paper present a novel algorithm which us compact hash bit to greatly improve the efficiency of non linear kernel svm in very large scale visual classification problem our key idea is to represent each sample with compact hash bit over which an inner product is defined to serve a the surrogate of the original nonlinear kernel then the problem of solving the nonlinear svm can be transformed into solving a linear svm over the hash bit the proposed hash svm enjoys dramatic storage cost reduction owing to the compact binary representation a well a a sub linear training complexity via linear svm a a critical component of hash svm we propose a novel hashing scheme for arbitrary non linear kernel via random subspace projection in reproducing kernel hilbert space our comprehensive analysis reveals a well behaved theoretic bound of the deviation between the proposed hashing based kernel approximation and the original kernel function we also derive requirement on the hash bit for achieving a satisfactory accuracy level several experiment on large scale visual classification benchmark are conducted including one with over million image the result show that hash svm greatly reduces the computational complexity more than ten time faster in many case while keeping comparable accuracy 
several descriptor have been proposed in the past for d shape analysis yet none of them achieves best performance on all shape class in this paper we propose a novel method for d shape analysis using the covariance matrix of the descriptor rather than the descriptor themselves covariance matrix enable efficient fusion of different type of feature and modality they capture using the same representation not only the geometric and the spatial property of a shape region but also the correlation of these property within the region covariance matrix however lie on the manifold of symmetric positive definite spd tensor a special type of riemannian manifold which make comparison and clustering of such matrix challenging in this paper we study covariance matrix in their native space and make use of geodesic distance on the manifold a a dissimilarity measure we demonstrate the performance of this metric on d face matching and recognition task we then generalize the bag of feature paradigm originally designed in euclidean space to the riemannian manifold of spd matrix we propose a new clustering procedure that take into account the geometry of the riemannian manifold we evaluate the performance of the proposed bag of covariance matrix framework on d shape matching and retrieval application and demonstrate it superiority compared to descriptor based technique 
we tackle the problem of weakly labeled semantic segmentation where the only source of annotation are image tag encoding which class are present in the scene this is an extremely difficult problem a no pixel wise labelings are available not even at training time in this paper we show that this problem can be formalized a an instance of learning in a latent structured prediction framework where the graphical model encodes the presence and absence of a class a well a the assignment of semantic label to superpixels a a consequence we are able to leverage standard algorithm with good theoretical property we demonstrate the effectiveness of our approach using the challenging sift flow dataset and show average per class accuracy improvement of over the state of the art 
this paper solves the speed bottleneck of deformable part model dpm while maintaining the accuracy in detection on challenging datasets three prohibitive step in cascade version of dpm are accelerated including d correlation between root filter and feature map cascade part pruning and hog feature extraction for d correlation the root filter is constrained to be low rank so that d correlation can be calculated by more efficient linear combination of d correlation a proximal gradient algorithm is adopted to progressively learn the low rank filter in a discriminative manner for cascade part pruning neighborhood aware cascade is proposed to capture the dependence in neighborhood region for aggressive pruning instead of explicit computation of part score hypothesis can be pruned by score of neighborhood under the first order approximation for hog feature extraction look up table are constructed to replace expensive calculation of orientation partition and magnitude with simpler matrix index operation extensive experiment show that a the proposed method is time faster than the current fastest dpm method with similar accuracy on pascal voc b the proposed method achieves state of the art accuracy on pedestrian and face detection task with frame rate speed 
we develop a sequential optimal sampling framework for stereo disparity estimation by adapting the sequential probability ratio test sprt model we operate over local image neighborhood by iteratively estimating single pixel disparity value until sufficient evidence ha been gathered to either validate or contradict the current hypothesis regarding local scene structure the output of our sampling is a set of sampled pixel position along with a robust and compact estimate of the set of disparity contained within a given region we further propose an efficient plane propagation mechanism that leverage the pre computed sampling position and the local structure model described by the reduced local disparity set our sampling framework is a general pre processing mechanism aimed at reducing computational complexity of disparity search algorithm by ascertaining a reduced set of disparity hypothesis for each pixel experiment demonstrate the effectiveness of the proposed approach when compared to state of the art method 
we present the discriminative fern ensemble dfe classifier for efficient visual object recognition the classifier architecture is designed to optimize both classification speed and accuracy when a large training set is available speed is obtained using simple binary feature and direct indexing into a set of table and accuracy by using a large capacity model and careful discriminative optimization the proposed framework is applied to the problem of hand pose recognition in depth and infra red image using a very large training set both the accuracy and the classification time obtained are considerably superior to relevant competing method allowing one to reach accuracy target with run time order of magnitude faster than the competition we show empirically that using dfe we can significantly reduce classification time by increasing training sample size for a fixed target accuracy finally a dfe result is shown for the mnist dataset showing the method s merit extends beyond depth image 
the problem of how to arrive at an appropriate d segmentation of a scene remains difficult while current state of the art method continue to gradually improve in benchmark performance they also grow more and more complex for example by incorporating chain of classifier which require training on large manually annotated data set a an alternative to this we present a new efficient learningand model free approach for the segmentation of d point cloud into object part the algorithm begin by decomposing the scene into an adjacency graph of surface patch based on a voxel grid edge in the graph are then classified a either convex or concave using a novel combination of simple criterion which operate on the local geometry of these patch this way the graph is divided into locally convex connected subgraphs which with high accuracy represent object part additionally we propose a novel depth dependent voxel grid to deal with the decreasing point density at far distance in the point cloud this improves segmentation allowing the use of fixed parameter for vastly different scene the algorithm is straightforward to implement and requires no training data while nevertheless producing result that are comparable to state of the art method which incorporate high level concept involving classification learning and model fitting 
we present a novel method for multiple people tracking that leverage a generalized model for capturing interaction among individual at the core of our model lie a learned dictionary of interaction feature string which capture relationship between the motion of target these feature string created from low level image feature lead to a much richer representation of the physical interaction between target compared to hand specified social force model that previous work have introduced for tracking one disadvantage of using social force is that all pedestrian must be detected in order for the force to be applied while our method is able to encode the effect of undetected target making the tracker more robust to partial occlusion the interaction feature string are used in a random forest framework to track target according to the feature surrounding them result on six publicly available sequence show that our method outperforms state of the art approach in multiple people tracking 
in this paper we study the problem of blind deconvolution our analysis is based on the algorithm of chan and wong which popularized the use of sparse gradient prior via total variation we use this algorithm because many method in the literature are essentially adaptation of this framework such algorithm is an iterative alternating energy minimization where at each step either the sharp image or the blur function are reconstructed recent work of levin et al showed that any algorithm that try to minimize that same energy would fail a the desired solution ha a higher energy than the no blur solution where the sharp image is the blurry input and the blur is a dirac delta however experimentally one can observe that chan and wong s algorithm converges to the desired solution even when initialized with the no blur one we provide both analysis and experiment to resolve this paradoxical conundrum we find that both claim are right the key to understanding how this is possible lie in the detail of chan and wong s implementation and in how seemingly harmless choice result in dramatic effect our analysis reveals that the delayed scaling normalization in the iterative step of the blur kernel is fundamental to the convergence of the algorithm this then result in a procedure that eludes the no blur solution despite it being a global minimum of the original energy we introduce an adaptation of this algorithm and show that in spite of it extreme simplicity it is very robust and achieves a performance comparable to the state of the art 
we present a novel feature description algorithm to describe d local spatio temporal feature for human action recognition our descriptor avoids the singularity and limited discrimination power issue of traditional d descriptor by quantizing and describing visual feature in the simplex topological vector space specifically given a feature s support region containing a set of d visual cue we decompose the cue orientation into three angle transform the decomposed angle into the simplex space and describe them in such a space then quadrant decomposition is performed to improve discrimination and a final feature vector is composed from the resulting histogram we develop intuitive visualization tool for analyzing feature characteristic in the simplex topological vector space experimental result demonstrate that our novel simplex based orientation decomposition sod descriptor substantially outperforms traditional d descriptor for the kth ucf sport and hollywood benchmark action datasets in addition the result show that our sod descriptor is a superior individual descriptor for action recognition 
previous effort in hashing intend to preserve data variance or pairwise affinity but neither is adequate in capturing the manifold structure hidden in most visual data in this paper we tackle this problem by reconstructing the locally linear structure of manifold in the binary hamming space which can be learned by locality sensitive sparse coding we cast the problem a a joint minimization of reconstruction error and quantization loss and show that despite it np hardness a local optimum can be obtained efficiently via alternative optimization our method distinguishes itself from existing method in it remarkable ability to extract the nearest neighbor of the query from the same manifold instead of from the ambient space on extensive experiment on various image benchmark our result improve previous state of the art by typically and on the yale face data 
in this paper we tackle the problem of retrieving video using complex natural language query towards this goal we first parse the sentential description into a semantic graph which is then matched to visual concept using a generalized bipartite matching algorithm our approach exploit object appearance motion and spatial relation and learns the importance of each term using structure prediction we demonstrate the effectiveness of our approach on a new dataset designed for semantic search in the context of autonomous driving which exhibit complex and highly dynamic scene with many object we show that our approach is able to locate a major portion of the object described in the query with high accuracy and improve the relevance in video retrieval 
this paper attempt to address the problem of recognizing human action while training and testing on distinct datasets when test video are neither labeled nor available during training in this scenario learning of a joint vocabulary or domain transfer technique are not applicable we first explore reason for poor classifier performance when tested on novel datasets and quantify the effect of scene background on action representation and recognition using only the background feature and partitioning of gist feature space we show that the background scene in recent datasets are quite discriminative and can be used classify an action with reasonable accuracy we then propose a new process to obtain a measure of confidence in each pixel of the video being a foreground region using motion appearance and saliency together in a d mrf based framework we also propose multiple way to exploit the foreground confidence to improve bag of word vocabulary histogram representation of a video and a novel histogram decomposition based representation and kernel we used these foreground confidence to recognize action trained on one data set and test on a different data set we have performed extensive experiment on several datasets that improve cross dataset recognition accuracy a compared to baseline method 
while technique that segment shape into visually meaningful part have generated impressive result these technique also have only focused on relatively simple shape such a those composed of a single object either without hole or with few simple hole in many application shape created from image can contain many overlapping object and hole these hole may come from sensor noise may have important part of the shape or may be arbitrarily complex these complexity that appear in real world d shape can pose grand challenge to the existing part segmentation method in this paper we propose a new decomposition method called dual space decomposition that handle complex d shape by recognizing the importance of hole and classifying hole a either topological noise or structurally important feature our method creates a nearly convex decomposition of a given shape by segmenting both the polygon itself and it complementary we compare our result to segmentation produced by nonexpert human subject based on two evaluation method we show that this new decomposition method creates statistically similar to those produced by human subject 
we present a method for finding correspondence between d model from an initial set of feature correspondence our method us a fast voting scheme to separate the inliers from the outlier the novelty of our method lie in the use of a combination of local and global constraint to determine if a vote should be cast on a local scale we use simple low level geometric invariant on a global scale we apply covariant constraint for finding compatible correspondence we guide the sampling for collecting voter by downward dependency on previous voting stage all of this together result in an accurate matching procedure we evaluate our algorithm by controlled and comparative testing on different datasets giving superior performance compared to state of the art method in a final experiment we apply our method for d object detection showing potential use of our method within higher level vision 
we propose a novel solution to the generalized camera pose problem which includes the internal scale of the generalized camera a an unknown parameter this further generalization of the well known absolute camera pose problem ha application in multi frame loop closure while a well calibrated camera rig ha a fixed and known scale camera trajectory produced by monocular motion estimation necessarily lack a scale estimate thus when performing loop closure in monocular visual odometry or registering separate structure from motion reconstruction we must estimate a seven degree of freedom similarity transform from corresponding observation existing approach solve this problem in specialized configuration by aligning d triangulated point or individual camera pose estimate our approach handle general configuration of ray and point and directly estimate the full similarity transformation from the d d correspondence four correspondence are needed in the minimal case which ha eight possible solution the minimal solver can be used in a hypothesize and test architecture for robust transformation estimation our solver also produce a least square estimate in the overdetermined case the approach is evaluated experimentally on synthetic and real datasets and is shown to produce higher accuracy solution to multi frame loop closure than existing approach 
part based visual tracking is advantageous due to it robustness against partial occlusion however how to effectively exploit the confidence score of individual part to construct a robust tracker is still a challenging problem in this paper we address this problem by simultaneously matching part in each of multiple frame which is realized by a locality constrained low rank sparse learning method that establishes multi frame part correspondence through optimization of partial permutation matrix the proposed part matching tracker pmt ha a number of attractive property it exploit the spatial temporal localityconstrained property for robust part matching it match local part from multiple frame jointly by considering their low rank and sparse structure information which can effectively handle part appearance variation due to occlusion or noise the proposed pmt model ha the inbuilt mechanism of leveraging multi mode target template so that the dilemma of template updating when encountering occlusion in tracking can be better handled this contrast with existing method that only do part matching between a pair of frame we evaluate pmt and compare with popular state of the art method on challenging benchmark experimental result show that pmt consistently outperform these existing tracker 
recently a concave optimization approach ha been proposed to solve the robust point matching rpm problem this method is globally optimal but it requires that each model point ha a counterpart in the data point set unfortunately such a requirement may not be satisfied in certain application when there are outlier in both point set to address this problem we relax this condition and reduce the objective function of rpm to a function with few nonlinear term by eliminating the transformation variable the resulting function however is no longer quadratic we prove that it is still concave over the feasible region of point correspondence the branch and bound bnb algorithm can then be used for optimization to further improve the efficiency of the bnb algorithm whose bottleneck lie in the costly computation of the lower bound we propose a new lower bounding scheme which ha a k cardinality linear assignment formulation and can be efficiently solved experimental result show that the proposed algorithm outperforms state of the art in it robustness to disturbance and point matching accuracy 
the transfer learning and domain adaptation problem originate from a distribution mismatch between the source and target data distribution the cause of such mismatch are traditionally considered different thus transfer learning and domain adaptation algorithm are designed to address different issue and cannot be used in both setting unless substantially modified still one might argue that these problem are just different declination of learning to learn i e the ability to leverage over prior knowledge when attempting to solve a new task we propose a learning to learn framework able to leverage over source data regardless of the origin of the distribution mismatch we consider prior model a expert and use their output confidence value a feature we use them to build the new target model combined with the feature from the target data through a high level cue integration scheme this result in a class of algorithm usable in a plug and play fashion over any learning to learn scenario from binary and multi class transfer learning to single and multiple source domain adaptation setting experiment on several public datasets show that our approach consistently achieves the state of the art 
with the widespread availability of video camera we are facing an ever growing enormous collection of unedited and unstructured video data due to lack of an automatic way to generate summary from this large collection of consumer video they can be tedious and time consuming to index or search in this work we propose online video highlighting a principled way of generating short video summarizing the most important and interesting content of an unedited and unstructured video costly both time wise and financially for manual processing specifically our method learns a dictionary from given video using group sparse coding and update atom in the dictionary on the fly a summary video is then generated by combining segment that cannot be sparsely reconstructed using the learned dictionary the online fashion of our proposed method enables it to process arbitrarily long video and start generating summary before seeing the end of the video moreover the processing time required by our proposed method is close to the original video length achieving quasi real time summarization speed theoretical analysis together with experimental result on more than hour of surveillance and youtube video are provided demonstrating the effectiveness of online video highlighting 
we study the problem of human body configuration analysis more specifically human parsing and human pose estimation these two task ie identifying the semantic region and body joint respectively over the human body image are intrinsically highly correlated however previous work generally solve these two problem separately or iteratively in this work we propose a unified framework for simultaneous human parsing and pose estimation based on semantic part by utilizing parselets and mixture of joint group template a the representation for these semantic part we seamlessly formulate the human parsing and pose estimation problem jointly within a unified framework via a tailored and or graph a novel grid layout feature is then designed to effectively capture the spatial co occurrence occlusion information between within the parselets and mjgts thus the mutually complementary nature of these two task can be harnessed to boost the performance of each other the resultant unified model can be solved using the structure learning framework in a principled way comprehensive evaluation on two benchmark datasets for both task demonstrate the effectiveness of the proposed framework when compared with the state of the art method 
we propose a simple yet effective regularized prior based on intensity and gradient for text image deblurring the proposed image prior is motivated by observing distinct property of text image based on this prior we develop an efficient optimization method to generate reliable intermediate result for kernel estimation the proposed method doe not require any complex filtering strategy to select salient edge which are critical to the state of the art deblurring algorithm we discus the relationship with other deblurring algorithm based on edge selection and provide insight on how to select salient edge in a more principled way in the final latent image restoration step we develop a simple method to remove artifact and render better deblurred image experimental result demonstrate that the proposed algorithm performs favorably against the state of the art text image deblurring method in addition we show that the proposed method can be effectively applied to deblur low illumination image 
this work proposes a method to interpret a scene by assigning a semantic label at every pixel and inferring the spatial extent of individual object instance together with their occlusion relationship starting with an initial pixel labeling and a set of candidate object mask for a given test image we select a subset of object that explain the image well and have valid overlap relationship and occlusion ordering this is done by minimizing an integer quadratic program either using a greedy method or a standard solver then we alternate between using the object prediction to refine the pixel label and vice versa the proposed system obtains promising result on two challenging subset of the labelme and sun datasets the largest of which contains image and class 
a common thread that tie together many prior work in scene understanding is their focus on the aspect directly present in a scene such a it categorical classification or the set of object in this work we propose to look beyond the visible element of a scene we demonstrate that a scene is not just a collection of object and their configuration or the label assigned to it pixel it is so much more from a simple observation of a scene we can tell a lot about the environment surrounding the scene such a the potential establishment near it the potential crime rate in the area or even the economic climate here we explore several of these aspect from both the human perception and computer vision perspective specifically we show that it is possible to predict the distance of surrounding establishment such a mcdonald s or hospital even by using scene located far from them we go a step further to show that both human and computer perform well at navigating the environment based only on visual cue from scene lastly we show that it is possible to predict the crime rate in an area simply by looking at a scene without any real time criminal activity simply put here we illustrate that it is possible to look beyond the visible scene 
a compared to the conventional rgb or gray scale image multispectral image msi can deliver more faithful representation for real scene and enhance the performance of many computer vision task in practice however an msi is always corrupted by various noise in this paper we propose an effective msi denoising approach by combinatorially considering two intrinsic characteristic underlying an msi the nonlocal similarity over space and the global correlation across spectrum in specific by explicitly considering spatial self similarity of an msi we construct a nonlocal tensor dictionary learning model with a group block sparsity constraint which make similar full band patch fbp share the same atom from the spatial and spectral dictionary furthermore through exploiting spectral correlation of an msi and assuming over redundancy of dictionary the constrained nonlocal msi dictionary learning model can be decomposed into a series of unconstrained low rank tensor approximation problem which can be readily solved by off the shelf higher order statistic experimental result show that our method outperforms all state of the art msi denoising method under comprehensive quantitative performance measure 
first order greedy selection algorithm have been widely applied to sparsity constrained optimization the main theme of this type of method is to evaluate the function gradient in the previous iteration to update the non zero entry and their value in the next iteration in contrast relatively le effort ha been made to study the second order greedy selection method additionally utilizing the hessian information inspired by the classic constrained newton method we propose in this paper the newton greedy pursuit ntgp method to approximately minimizes a twice differentiable function over sparsity constraint at each iteration ntgp construct a second order taylor expansion to approximate the cost function and estimate the next iterate a the solution of the constructed quadratic model over sparsity constraint parameter estimation error and convergence property of ntgp are analyzed the superiority of ntgp to several representative first order greedy selection method is demonstrated in synthetic and real sparse logistic regression task 
we propose a kernel based framework for computing component from a set of surface normal this framework allows u to easily demonstrate that component analysis can be performed directly upon normal we link previously proposed mapping function the azimuthal equidistant projection aep and principal geodesic analysis pga to our kernel based framework we also propose a new mapping function based upon the cosine distance between normal we demonstrate the robustness of our proposed kernel when trained with noisy training set we also compare our kernel within an existing shape from shading sfs algorithm our spherical representation of normal when combined with the robust property of cosine kernel produce a very robust subspace analysis technique in particular our result within sfs show a substantial qualitative and quantitative improvement over existing technique 
we present an approach that take a single photograph of a child a input and automatically produce a series of age progressed output between and year of age accounting for pose expression and illumination leveraging thousand of photo of child and adult at many age from the internet we first show how to compute average image subspace that are pixel to pixel aligned and model variable lighting these average depict a prototype man and woman aging from to under any desired illumination and capture the difference in shape and texture between age applying these difference to a new photo yield an age progressed result contribution include relightable age subspace a novel technique for subspace to subspace alignment and the most extensive evaluation of age progression technique in the literature 
visual appearance score appearance mixture type and deformation are three important information source for human pose estimation this paper proposes to build a multi source deep model in order to extract non linear representation from these different aspect of information source with the deep model the global high order human body articulation pattern in these information source are extracted for pose estimation the task for estimating body location and the task for human detection are jointly learned using a unified deep model the proposed approach can be viewed a a post processing of pose estimation result and can flexibly integrate with existing method by taking their information source a input by extracting the non linear representation from multiple information source the deep model outperforms state of the art by up to percent on three public benchmark datasets 
we address the problem of large scale fine grained visual categorization describing new method we have used to produce an online field guide to north american bird specie we focus on the challenge raised when such a system is asked to distinguish between highly similar specie of bird first we introduce one v most classifier by eliminating highly similar specie during training these classifier achieve more accurate and intuitive result than common one v all classifier second we show how to estimate spatio temporal class prior from observation that are sampled at irregular and biased location we show how these prior can be used to significantly improve performance we then show state of the art recognition performance on a new large dataset that we make publicly available these recognition method are integrated into the online field guide which is also publicly available 
due to great challenge such a tremendous intra class variation and low image resolution context information ha been playing a more and more important role for accurate and robust event recognition in surveillance video the context information can generally be divided into the feature level context the semantic level context and the prior level context these three level of context provide crucial bottom up middle level and top down information that can benefit the recognition task itself unlike existing research that generally integrate the context information at one of the three level we propose a hierarchical context model that simultaneously exploit context at all three level and systematically incorporate them into event recognition to tackle the learning and inference challenge brought in by the model hierarchy we develop complete learning and inference algorithm for the proposed hierarchical context model based on variational bayes method experiment on virat and ground datasets demonstrate the effectiveness of the proposed hierarchical context model for improving the event recognition performance even under great challenge like large intra class variation and low image resolution 
in this paper we present a novel method to synthesize dynamic texture sequence from extremely few sample e g merely two possibly disparate frame leveraging both markov random field mrfs and manifold learning decomposing a textural image a a set of patch we achieve dynamic texture synthesis by estimating sequence of temporal patch we select candidate for each temporal patch from spatial patch based on mrfs and regard them a sample from a low dimensional manifold after mapping candidate to a low dimensional latent space we estimate the sequence of temporal patch by finding an optimal trajectory in the latent space guided by some key property of trajectory of realistic temporal patch we derive a curvature based trajectory selection algorithm in contrast to the method based on mrfs or dynamic system that rely on a large amount of sample our method is able to deal with the case of extremely few sample and requires no training phase we compare our method with the state of the art and show that our method not only exhibit superior performance on synthesizing texture but it also produce result with pleasing visual effect 
the probabilistic method based on symmetrical gauss mixture model sgmm have achieved great success in point set registration but are seldom used to find the correspondence between two image due to the complexity of the non rigid transformation and too many outlier in this paper we propose an asymmetrical gmm agmm for point set matching between a pair of image different from the previous sgmm the agmm give each gauss component a different weight which is related to the feature similarity between the data point and model point which lead to two effective algorithm the single gauss model for mismatch rejection sgmr algorithm and the agmm algorithm for point set matching the sgmr algorithm iteratively filter mismatch by estimating a non rigid transformation between two image based on the spatial coherence of point set the agmm algorithm combine the feature information with position information of the sift feature point extracted from the image to achieve point set matching so that much more correct correspondence with high precision can be found a number of comparison and evaluation experiment reveal the excellent performance of the proposed sgmr algorithm and agmm algorithm 
in this paper we propose a novel rigid motion segmentation algorithm called randomized voting rv this algorithm is based on epipolar geometry and computes a score using the distance between the feature point and the corresponding epipolar line this score is accumulated and utilized for final grouping our algorithm basically deal with two frame so it is also applicable to the two view motion segmentation problem for evaluation of our algorithm hopkins dataset which is a representative test set for rigid motion segmentation is adopted it consists of two and three rigid motion our algorithm ha provided the most accurate motion segmentation result among all of the state of the art algorithm the average error rate is in addition when there is measurement noise our algorithm is comparable with other state of the art algorithm 
this paper considers the problem of action localization where the objective is to determine when and where certain action appear we introduce a sampling strategy to produce d t sequence of bounding box called tubelets compared to state of the art alternative this drastically reduces the number of hypothesis that are likely to include the action of interest our method is inspired by a recent technique introduced in the context of image localization beyond considering this technique for the first time for video we revisit this strategy for d t sequence obtained from super voxels our sampling strategy advantageously exploit a criterion that reflects how action related motion deviate from background motion we demonstrate the interest of our approach by extensive experiment on two public datasets ucf sport and msr ii our approach significantly outperforms the state of the art on both datasets while restricting the search of action to a fraction of possible bounding box sequence 
the quantification of similarity between image segmentation is a complex yet important task the ideal similarity measure should be unbiased to segmentation of different volume and complexity and be able to quantify and visualise segmentation bias similarity measure based on overlap e g dice score or surface distance e g hausdorff distance clearly do not satisfy all of these property to address this problem we introduce patch based evaluation of image segmentation pei a general method to ass segmentation quality our method is based on finding patch correspondence and the associated patch displacement which allow the estimation of segmentation bias we quantify both the agreement of the segmentation boundary and the conservation of the segmentation shape we further ass the segmentation complexity within patch to weight the contribution of local segmentation similarity to the global score we evaluate pei on both synthetic data and two medical imaging datasets on synthetic segmentation of different shape we provide evidence that pei in comparison to the dice score produce more comparable score ha increased sensitivity and estimate segmentation bias accurately on cardiac magnetic resonance mr image we demonstrate that pei can evaluate the performance of a segmentation method independent of the size or complexity of the segmentation under consideration on brain mr image we compare five different automatic hippocampus segmentation technique using pei finally we visualise the segmentation bias on a selection of the case 
deformable object are everywhere face car bicycle chair etc recently there ha been a wealth of research on training deformable model for object detection part localization and recognition using annotated data in order to train deformable model with good generalization ability a large amount of carefully annotated data is required which is a highly time consuming and costly task we propose the first to the best of our knowledge method for automatic construction of deformable model using image captured in totally unconstrained condition recently referred to a in the wild the only requirement of the method are a crude bounding box object detector and a priori knowledge of the object s shape e g a point distribution model the object detector can be a simple a the viola jones algorithm e g even the cheapest digital camera feature a robust face detector the d shape model can be created by using only a few shape example with deformation in our experiment on facial deformable model we show that the proposed automatically built model not only performs well but also outperforms discriminative model trained on carefully annotated data to the best of our knowledge this is the first time it is shown that an automatically constructed model can perform a well a method trained directly on annotated data 
we derive an easy to implement and efficient algorithm for solving multi label image partitioning problem in the form of the problem addressed by region competition these problem jointly determine a parameter for each of the region in the partition given an estimate of the parameter a fast approximate solution to the multi label sub problem is derived by a global update that us smoothing and thresholding the method is empirically validated to be robust to fine detail of the image that plague local solution further in comparison to global method for the multi label problem the method is more efficient and it is easy for a non specialist to implement we give sample matlab code for the multi label chan vese problem in this paper experimental comparison to the state of the art in multi label solution to region competition show that our method achieves equal or better accuracy with the main advantage being speed and ease of implementation 
we propose a novel discriminative model for semantic labeling in video by incorporating a prior to model both the shape and temporal dependency of an object in video a typical approach for this task is the conditional random field crf which can model local interaction among adjacent region in a video frame recent work ha shown how to incorporate a shape prior into a crf for improving labeling performance but it may be difficult to model temporal dependency present in video by using this prior the conditional restricted boltzmann machine crbm can model both shape and temporal dependency and ha been used to learn walking style from motioncapture data in this work we incorporate a crbm prior into a crf framework and present a new state of the art model for the task of semantic labeling in video in particular we explore the task of labeling part of complex face scene from video in the youtube face database yfdb our combined model outperforms competitive baseline both qualitatively and quantitatively 
in this paper we present a novel refractive calibration method for an underwater stereo camera system where both camera are looking through multiple parallel flat refractive interface at the heart of our method is an important finding that the thickness of the interface can be estimated from a set of pixel correspondence in the stereo image when the refractive axis is given to our best knowledge such a finding ha not been studied or reported moreover by exploring the search space for the refractive axis and using reprojection error a a measure both the refractive axis and the thickness of the interface can be recovered simultaneously our method doe not require any calibration target such a a checkerboard pattern which may be difficult to manipulate when the camera are deployed deep undersea the implementation of our method is simple in particular it only requires solving a set of linear equation of the form ax b and applies sparse bundle adjustment to refine the initial estimated result extensive experiment have been carried out which include simulation with and without outlier to verify the correctness of our method a well a to test it robustness to noise and outlier the result of real experiment are also provided the accuracy of our result is comparable to that of a state of the art method that requires known d geometry of a scene 
haze is one of the major factor that degrade outdoor image removing haze from a single image is known to be severely ill posed and assumption made in previous method do not hold in many situation in this paper we systematically investigate different haze relevant feature in a learning framework to identify the best feature combination for image dehazing we show that the dark channel feature is the most informative one for this task which confirms the observation of he et al from a learning perspective while other haze relevant feature also contribute significantly in a complementary way we also find that surprisingly the synthetic hazy image patch we use for feature investigation serve well a training data for realworld image which allows u to train specific model for specific application experiment result demonstrate that the proposed algorithm outperforms state of the art method on both synthetic and real world datasets 
the goal of this paper is to question the necessity of feature like sift in categorical visual recognition task a an alternative we develop a generative model for the raw intensity of image patch and show that it can support image classification performance on par with optimized sift based technique in a bag of visual word setting key ingredient of the proposed model is a compact dictionary of mini epitome learned in an unsupervised fashion on a large collection of image the use of epitome allows u to explicitly account for photometric and position variability in image appearance we show that this flexibility considerably increase the capacity of the dictionary to accurately approximate the appearance of image patch and support recognition task for image classification we develop histogram based image encoding method tailored to the epitomic representation a well a an epitomic footprint encoding which is easy to visualize and highlight the generative nature of our model we discus in detail computational aspect and develop efficient algorithm to make the model scalable to large task the proposed technique are evaluated with experiment on the challenging pascal voc image classification benchmark 
human pose estimation ha made significant progress during the last year however current datasets are limited in their coverage of the overall pose estimation challenge still these serve a the common source to evaluate train and compare different model on in this paper we introduce a novel benchmark mpii human pose that make a significant advance in term of diversity and difficulty a contribution that we feel is required for future development in human body model this comprehensive dataset wa collected using an established taxonomy of over human activity the collected image cover a wider variety of human activity than previous datasets including various recreational occupational and householding activity and capture people from a wider range of viewpoint we provide a rich set of label including position of body joint full d torso and head orientation occlusion label for joint and body part and activity label for each image we provide adjacent video frame to facilitate the use of motion information given these rich annotation we perform a detailed analysis of leading human pose estimation approach and gaining insight for the success and failure of these method 
graph are a powerful tool to model structured object but it is nontrivial to measure the similarity between two graph in this paper we construct a two graph model to represent human action by recording the spatial and temporal relationship among local feature we also propose a novel family of context dependent graph kernel cgks to measure similarity between graph first local feature are used a the vertex of the two graph model and the relationship among local feature in the intra frame and inter frame are characterized by the edge then the proposed cgks are applied to measure the similarity between action represented by the two graph model graph can be decomposed into number of primary walk group with different walk length and our cgks are based on the context dependent primary walk group matching taking advantage of the context information make the correctly matched primary walk group dominate in the cgks and improves the performance of similarity measurement between graph finally a generalized multiple kernel learning algorithm with a proposed l norm regularization is applied to combine these cgks optimally together and simultaneously train a set of action classifier we conduct a series of experiment on several public action datasets our approach achieves a comparable performance to the state of the art approach which demonstrates the effectiveness of the two graph model and the cgks in recognizing human action 
reconstructing d object from single line drawing is often desirable in computer vision and graphic application if the line drawing of a complex d object is decomposed into primitive of simple shape the object can be easily reconstructed we propose an effective method to conduct the line drawing separation and turn a complex line drawing into parametric d model this is achieved by recursively separating the line drawing using two type of split face our experiment show that the proposed separation method can generate more basic and simple line drawing and it combination with the example based reconstruction can robustly recover wider range of complex parametric d object than previous method 
we propose a multi view depthmap estimation approach aimed at adaptively ascertaining the pixel level data association between a reference image and all the element of a source image set namely we address the question what aggregation subset of the source image set should we use to estimate the depth of a particular pixel in the reference image we pose the problem within a probabilistic framework that jointly model pixel level view selection and depthmap estimation given the local pairwise image photoconsistency the corresponding graphical model is solved by em based view selection probability inference and patchmatch like depth sampling and propagation experimental result on standard multi view benchmark convey the state of the art estimation accuracy afforded by mitigating spurious pixel level data association additionally experiment on large internet crowd sourced data demonstrate the robustness of our approach against unstructured and heterogeneous image capture characteristic moreover the linear computational and storage requirement of our formulation a well a it inherent parallelism enables an efficient and scalable gpu based implementation 
we focus on the problem of estimating the ground plane orientation and location in monocular video sequence from a moving observer our only assumption are that the d ego motion t and the ground plane normal n are orthogonal and that n and t are smooth over time we formulate the problem a a state continuous hidden markov model hmm where the hidden state contains t and n and may be estimated by sampling and decomposing homographies we show that using blocked gibbs sampling we can infer the hidden state with high robustness towards outlier drifting trajectory rolling shutter and an imprecise intrinsic calibration since our approach doe not need any initial orientation prior it work for arbitrary camera orientation in which the ground is visible 
histogram based feature have significantly contributed to recent development of image classification such a by sift local descriptor in this paper we propose a method to efficiently transform those histogram feature for improving the classification performance the l normalized histogram feature is regarded a a probability mass function which is modeled by dirichlet distribution based on the probabilistic modeling we induce the dirichlet fisher kernel for transforming the histogram feature vector the method work on the individual histogram feature to enhance the discriminative power at a low computational cost on the other hand in the bag of feature bof framework the dirichlet mixture model can be extended to gaussian mixture by transforming histogram based local descriptor e g sift and thereby we propose the method of dirichlet derived gmm fisher kernel in the experiment on diverse image classification task including recognition of subordinate object and material texture the proposed method improve the performance of the histogrambased feature and bof based fisher kernel being favorably competitive with the state of the art 
many traditional challenge in reconstructing d motion such a matching across wide baseline and handling occlusion reduce in significance a the number of unique viewpoint increase however to obtain this benefit a new challenge arises estimating precisely which camera observe which point at each instant in time we present a maximum a posteriori map estimate of the time varying visibility of the target point to reconstruct the d motion of an event from a large number of camera our algorithm take a input camera pose and image sequence and output the time varying set of the camera in which a target patch is visibile and it reconstructed trajectory we model visibility estimation a a map estimate by incorporating various cue including photometric consistency motion consistency and geometric consistency in conjunction with a prior that reward consistent visibility in proximal camera an optimal estimate of visibility is obtained by finding the minimum cut of a capacitated graph over camera we demonstrate that our method estimate visibility with greater accuracy and increase tracking performance producing longer trajectory at more location and at higher accuracy than method that ignore visibility or use photometric consistency alone 
in this paper we present a unified method for joint face image analysis i e simultaneously estimating head pose facial expression and landmark position in real world face image to achieve this goal we propose a novel iterative multi output random forest imorf algorithm which explicitly model the relation among multiple task and iteratively exploit such relation to boost the performance of all task specifically a hierarchical face analysis forest is learned to perform classification of pose and expression at the top level while performing landmark position regression at the bottom level on one hand the estimated pose and expression provide strong shape prior to constrain the variation of landmark position on the other hand more discriminative shape related feature could be extracted from the estimated landmark position to further improve the prediction of pose and expression this relatedness of face analysis task is iteratively exploited through several cascaded hierarchical face analysis forest until convergence experiment conducted on publicly available real world face datasets demonstrate that the performance of all individual task are significantly improved by the proposed imorf algorithm in addition our method outperforms state of the art for all three face analysis task 
rotation in closed contour recognition is a puzzling nuisance in most algorithm in this paper we address three fundamental issue brought by rotation in shape is alignment among shape necessary if the answer is no how to exploit information in different rotation and how to use rotation unaware local feature for rotation aware shape recognition we argue that the origin of these issue is the use of hand crafted rotation unfriendly feature and measurement therefore our goal is to learn a set of hierarchical feature that describe all rotated version of a shape a a class with the capability of distinguishing different such class we propose to rotate shape a many time a possible a training sample and learn the hierarchical feature representation by effectively adopting a convolutional neural network we further show that our method is very efficient because the network response of all possible shifted version of the same shape can be computed effectively by re using information in the overlapping area we tested the algorithm on three real datasets swedish leaf dataset eth shape and a subset of the recently collected leafsnap dataset our approach used the curvature scale space and outperformed the state of the art 
current system for scene understanding typically represent object a d or d bounding box while these representation have proven robust in a variety of application they provide only coarse approximation to the true d and d extent of object a a result object object interaction such a occlusion or ground plane contact can be represented only superficially in this paper we approach the problem of scene understanding from the perspective of d shape modeling and design a d scene representation that reason jointly about the d shape of multiple object this representation allows to express d geometry and occlusion on the fine detail level of individual vertex of d wireframe model and make it possible to treat dependency between object such a occlusion reasoning in a deterministic way in our experiment we demonstrate the benefit of jointly estimating the d shape of multiple object in a scene over working with coarse box on the recently proposed kitti dataset of realistic street scene 
the desire of enabling computer to learn semantic concept from large quantity of internet video ha motivated increasing interest on semantic video understanding while video segmentation is important yet challenging for understanding video the main difficulty of video segmentation arises from the burden of labeling training sample making the problem largely unsolved in this paper we present a novel nearest neighbor based label transfer scheme for weakly supervised video segmentation whereas previous weakly supervised video segmentation method have been limited to the two class case our proposed scheme focus on more challenging multiclass video segmentation which find a semantically meaningful label for every pixel in a video our scheme enjoys several favorable property when compared with conventional method first a weakly supervised hashing procedure is carried out to handle both metric and semantic similarity second the proposed nearest neighbor based label transfer algorithm effectively avoids overfitting caused by weakly supervised data third a multi video graph model is built to encourage smoothness between region that are spatiotemporally adjacent and similar in appearance we demonstrate the effectiveness of the proposed scheme by comparing it with several other state of the art weakly supervised segmentation method on one new wild dataset and two other publicly available datasets 
we propose a novel regularity driven framework for facade detection from aerial image of urban scene gini index is used in our work to form an edge based regularity metric relating regularity and distribution sparsity facade region are chosen so that these local regularity are maximized we apply a greedy adaptive region expansion procedure for facade region detection and growing followed by integer quadratic programming for removing overlapping facade to optimize facade coverage our algorithm can handle image that have wide viewing angle and contain more than facade per image the experimental result on image from three different city nyc rome san francisco demonstrate superior performance on facade detection in both accuracy and speed over state of the art method we also show an application of our facade detection for effective cross view facade matching 
mutual occlusion among target can cause track loss or target position deviation because the observation likelihood of an occluded target may vanish even when we have the estimated location of the target this paper present a novel probability framework for multitarget tracking with mutual occlusion the primary contribution of this work is the introduction of a vectorial occlusion variable a part of the solution the occlusion variable describes occlusion state of the target this form the basis of the proposed probability framework with the following further contribution likelihood a new observation likelihood model is presented in which the likelihood of an occluded target is computed by referring to both of the occluded and oc cluding target priori markov random field mrf is used to model the occlusion priori such that le likely circular or cascading type of occlusion have lower priori probability both the occlusion priori and the motion priori take into consideration the state of occlusion optimization a realtime rjmcmc based algorithm with a newmove type called occlusion state update is presented experimental result show that the proposed framework can handle occlusion well even including long duration full occlusion which may cause tracking failure in the traditional method 
in this paper we propose a method to refine geometry of d mesh from the kinect fusion by exploiting shading cue captured from the infrared ir camera of kinect a major benefit of using the kinect ir camera instead of a rgb camera is that the ir image captured by kinect are narrow band image which filtered out most undesired ambient light that make our system robust to natural indoor illumination we define a near light ir shading model which describes the captured intensity a a function of surface normal albedo lighting direction and distance between a light source and surface point to resolve ambiguity in our model between normal and distance we utilize an initial d mesh from the kinect fusion and multi view information to reliably estimate surface detail that were not reconstructed by the kinect fusion our approach directly operates on a d mesh model for geometry refinement the effectiveness of our approach is demonstrated through several challenging real world example 
our goal is to learn a compact discriminative vector representation of a face track suitable for the face recognition task of verification and classification to this end we propose a novel face track descriptor based on the fisher vector representation and demonstrate that it ha a number of favourable property first the descriptor is suitable for track of both frontal and profile face and is insensitive to their pose second the descriptor is compact due to discriminative dimensionality reduction and it can be further compressed using binarization third the descriptor can be computed quickly using hard quantization and it compact size and fast computation render it very suitable for large scale visual repository finally the descriptor demonstrates good generalization when trained on one dataset and tested on another reflecting it tolerance to the dataset bias in the experiment we show that the descriptor exceeds the state of the art on both face verification task youtube face without outside training data and inria buffy benchmark and face classification task using the oxford buffy dataset 
in this paper we propose a novel algorithm for structured sparsity reconstruction this algorithm is based on the iterative reweighted least square irls framework and accelerated by the preconditioned conjugate gradient method the convergence rate of the proposed algorithm is almost the same a that of the traditional irls algorithm that is exponentially fast moreover with the devised preconditioner the computational cost for each iteration is significantly le than that of traditional irls algorithm which make it feasible for large scale problem besides the fast convergence this algorithm can be flexibly applied to standard sparsity group sparsity and overlapping group sparsity problem experiment are conducted on a practical application compressive sensing magnetic resonance imaging result demonstrate that the proposed algorithm achieves superior performance over state of the art algorithm in term of both accuracy and computational cost 
a main theme in object detection are currently discriminative part based model the powerful model that combine all part is then typically only feasible for few constituent which are in turn iteratively trained to make them a strong a possible we follow the opposite strategy by randomly sampling a large number of instance specific part classifier due to their number we cannot directly train a powerful classifier to combine all part therefore we randomly group them into fewer overlapping composition that are trained using a maximum margin approach in contrast to the common rationale of compositional approach we do not aim for semantically meaningful ensemble rather we seek randomized composition that are discriminative and generalize over all instance of a category our approach not only localizes object in cluttered scene but also explains them by parsing with composition and their constituent part we conducted experiment on pascal voc on the voc evaluation server and on the mitindoor scene dataset to the best of our knowledge our randomized max margin composition rm c are the currently best performing single class object detector using only hog feature moreover the individual contribution of composition and their part are evaluated in separate experiment that demonstrate their potential 
in this paper we focus on the problem of point to set classification where single point are matched against set of correlated point since the point commonly lie in euclidean space while the set are typically modeled a element on riemannian manifold they can be treated a euclidean point and riemannian point respectively to learn a metric between the heterogeneous point we propose a novel euclidean to riemannian metric learning framework specifically by exploiting typical riemannian metric the riemannian manifold is first embedded into a high dimensional hilbert space to reduce the gap between the heterogeneous space and meanwhile respect the riemannian geometry of the manifold the final distance metric is then learned by pursuing multiple transformation from the hilbert space and the original euclidean space or it corresponding hilbert space to a common euclidean subspace where classical euclidean distance of transformed heterogeneous point can be measured extensive experiment clearly demonstrate the superiority of our proposed approach over the state of the art method 
we propose a simple yet effective detector for pedestrian detection the basic idea is to incorporate common sense and everyday knowledge into the design of simple and computationally efficient feature a pedestrian usually appear up right in image or video data the problem of pedestrian detection is considerably simpler than general purpose people detection we therefore employ a statistical model of the up right human body where the head the upper body and the lower body are treated a three distinct component our main contribution is to systematically design a pool of rectangular template that are tailored to this shape model a we incorporate different kind of low level measurement the resulting multi modal multi channel haar like feature represent characteristic difference between part of the human body yet are robust against variation in clothing or environmental setting our approach avoids exhaustive search over all possible configuration of rectangle feature and neither relies on random sampling it thus mark a middle ground among recently published technique and yield efficient low dimensional yet highly discriminative feature experimental result on the inria and caltech pedestrian datasets show that our detector reach state of the art performance at low computational cost and that our feature are robust against occlusion 
we explore whether we can observe time s arrow in a temporal sequence is it possible to tell whether a video is running forward or backwards we investigate this somewhat philosophical question using computer vision and machine learning technique we explore three method by which we might detect time s arrow in video sequence based on distinct way in which motion in video sequence might be asymmetric in time we demonstrate good video forward backwards classification result on a selection of youtube video clip and on natively captured sequence with no temporally dependent video compression and examine what motion the model have learned that help discriminate forward from backwards time 
this paper present a system to reconstruct piecewise planar and compact floorplans from image which are then converted to high quality texture mapped model for freeviewpoint visualization there are two main challenge in image based floorplan reconstruction the first is the lack of d information that can be extracted from image by structure from motion and multi view stereo a indoor scene abound with non diffuse and homogeneous surface plus clutter the second challenge is the need of a sophisticated regularization technique that enforces piecewise planarity to suppress clutter and yield high quality texture mapped model our technical contribution are twofold first we propose a novel structure classification technique to classify each pixel to three region floor ceiling and wall which provide d cue even from a single image second we cast floorplan reconstruction a a shortest path problem on a specially crafted graph which enables u to enforce piecewise planarity besides producing compact piecewise planar model this formulation allows u to directly control the number of vertex i e density of the output mesh we evaluate our system on real indoor scene and show that our texture mapped mesh model provide compelling free viewpoint visualization experience when compared against the state of the art and ground truth 
popular figure ground segmentation algorithm generate a pool of boundary aligned segment proposal that can be used in subsequent object recognition engine these algorithm can recover most image object with high accuracy but are usually computationally intensive since many graph cut are computed with different enumeration of segment seed in this paper we propose an algorithm rigor for efficiently generating a pool of overlapping segment proposal in image by precomputing a graph which can be used for parametric min cut over different seed we speed up the generation of the segment pool in addition we have made design choice that avoid extensive computation without losing performance in particular we demonstrate that the segmentation performance of our algorithm is slightly better than the state of the art on the pascal voc dataset while being an order of magnitude faster 
graph based method are a useful class of method for improving the performance of unsupervised and semi supervised machine learning task such a clustering or information retrieval however the performance of existing graph based method is highly dependent on how well the affinity graph reflects the original data structure we propose that multimedia such a image or video consist of multiple separate component and therefore more than one graph is required to fully capture the relationship between them accordingly we present a new spectral method the feature grouped spectral multigraph fgsm which comprises the following step first mutually independent subset of the original feature space are generated through feature clustering secondly a separate graph is generated from each feature subset finally a spectral embedding is calculated on each graph and the embeddings are scaled aggregated into a single representation using this representation a variety of experiment are performed on three learning task clustering retrieval and recognition on human action datasets demonstrating considerably better performance than the state of the art 
in this paper we propose a novel method for image fusion from a high resolution panchromatic image and a low resolution multispectral image at the same geographical location different from previous method we do not make any assumption about the upsampled multispectral image but only assume that the fused image after downsampling should be close to the original multispectral image this is a severely ill posed problem and a dynamic gradient sparsity penalty is thus proposed for regularization incorporating the intracorrelations of different band this penalty can effectively exploit the prior information e g sharp boundary from the panchromatic image a new convex optimization algorithm is proposed to efficiently solve this problem extensive experiment on four multispectral datasets demonstrate that the proposed method significantly outperforms the state of the art in term of both spatial and spectral quality 
we address the problem of camouflaging a d object from the many viewpoint that one might see it from given photograph of an object s surroundings we produce a surface texture that will make the object difficult for a human to detect to do this we introduce several background matching algorithm that attempt to make the object look like whatever is behind it of course it is impossible to exactly match the background from every possible viewpoint thus our model are forced to make trade offs between different perceptual factor such a the conspicuousness of the occlusion boundary and the amount of texture distortion we use experiment with human subject to evaluate the effectiveness of these model for the task of camouflaging a cube finding that they significantly outperform na ve strategy 
we describe a simple and fast algorithm for optimizing markov random field over image the algorithm performs block coordinate descent by optimally updating a horizontal or vertical line in each step while the algorithm is not a accurate a state of the art mrf solver on traditional benchmark problem it is trivially parallelizable and produce competitive result in a fraction of a second a an application we develop an approach to increasing the accuracy of consumer depth camera the presented algorithm enables high resolution mrf optimization at multiple frame per second and substantially increase the accuracy of the produced range image 
in this paper we propose an efficient and accurate scheme for the integration of multiple stereo based depth measurement for each provided depth map a confidence based weight is assigned to each depth estimate by evaluating local geometry orientation underlying camera setting and photometric evidence subsequently all hypothesis are fused together into a compact and consistent d model thereby visibility conflict are identified and resolved and fitting measurement are averaged with regard to their confidence score the individual stage of the proposed approach are validated by comparing it to two alternative technique which rely on a conceptually different fusion scheme and a different confidence inference respectively pursuing live d reconstruction on mobile device a a primary goal we demonstrate that the developed method can easily be integrated into a system for monocular interactive d modeling by substantially improving it accuracy while adding a negligible overhead to it performance and retaining it interactive potential 
it ha been recently shown that reconstructing an isometric surface from a single d input image matched to a d template wa a well posed problem this however doe not tell u how reconstruction algorithm will behave in practical condition where the amount of perspective is generally small and the projection thus behaves like weak perspective or orthography we here bring answer to what is theoretically recoverable in such imaging condition and explain why existing convex numerical solution and analytical solution to d reconstruction may be unstable we then propose a new algorithm which work under all imaging condition from strong to loose perspective we empirically show that the gain in stability is tremendous bringing our result close to the iterative minimization of a statisticallyoptimal cost our algorithm ha a low complexity is simple and us only one round of linear least square 
this paper proposes an unsupervised method for learning dictionary of hierarchical compositional model for representing natural image each model is in the form of a template that consists of a small group of part template that are allowed to shift their location and orientation relative to each other and each part template is in turn a composition of gabor wavelet that are also allowed to shift their location and orientation relative to each other given a set of unannotated training image a dictionary of such hierarchical template are learned so that each training image can be represented by a small number of template that are spatially translated rotated and scaled version of the template in the learned dictionary the learning algorithm iterates between the following two step image encoding by a template matching pursuit process that involves a bottom up template matching sub process and a top down template localization sub process dictionary re learning by a shared matching pursuit process experimental result show that the proposed approach is capable of learning meaningful template and the learned template are useful for task such a domain adaption and image cosegmentation 
we examine the problem of retrieving high resolution texture of object observed in multiple video under small object deformation in the monocular case the data redundancy necessary to reconstruct a high resolution image stem from temporal accumulation this ha been vastly explored and is known a image super resolution on the other hand a handful of method have considered the texture of a static d object observed from several camera where the data redundancy is obtained through the different viewpoint we introduce a unified framework to leverage both possibility for the estimation of an object s high resolution texture this framework uniformly deal with any related geometric variability introduced by the acquisition chain or by the evolution over time to this goal we use d warp for all viewpoint and all temporal frame and a linear image formation model from texture to image space despite it simplicity the method is able to successfully handle different view over space and time a shown experimentally it demonstrates the interest of temporal information to improve the texture quality additionally we also show that our method outperforms state of the art multi view super resolution method existing for the static case 
preprocessing a d image often produce a noisy cloud of interest point we study the problem of counting hole in noisy cloud in the plane the hole in a given cloud are quantified by the topological persistence of their boundary contour when the cloud is analyzed at all possible scale we design the algorithm to count hole that are most persistent in the filtration of offset neighborhood around given point the input is a cloud of n point in the plane without any user defined parameter the algorithm ha a near linear time and a linear space o n the output is the array number of hole relative persistence in the filtration we prove theoretical guarantee when the algorithm find the correct number of hole component in the complement of an unknown shape approximated by a cloud 
there have been some recent effort to build visual knowledge base from internet image but most of these approach have focused on bounding box representation of object in this paper we propose to enrich these knowledge base by automatically discovering object and their segmentation from noisy internet image specifically our approach combine the power of generative modeling for segmentation with the effectiveness of discriminative model for detection the key idea behind our approach is to learn and exploit top down segmentation prior based on visual subcategories the strong prior learned from these visual subcategories are then combined with discriminatively trained detector and bottom up cue to produce clean object segmentation our experimental result indicate state of the art performance on the difficult dataset introduced by rubinstein et al we have integrated our algorithm in neil for enriching it knowledge base a of th april neil ha automatically generated approximately k segmentation using web data 
this work proposes a novel framework for optimization in the constrained diffeomorphism space for deformable surface registration first the diffeomorphism space is modeled a a special complex functional space on the source surface the beltrami coefficient space the physically plausible constraint in term of feature landmark and deformation type define subspace in the beltrami coefficient space then the harmonic energy of the registration is minimized in the constrained subspace the minimization is achieved by alternating two step optimization diffuse the beltrami coefficient and projection first deform the conformal structure by the current beltrami coefficient and then compose with a harmonic map from the deformed conformal structure to the target the registration result is diffeomorphic satisfies the physical landmark and deformation constraint and minimizes the conformality distortion experiment on human facial surface demonstrate the efficiency and efficacy of the proposed registration framework 
a new method for learning pooling receptive field for recognition is presented the method exploit the statistic of the d tensor of sift response to an image it is argued that the eigentensors of this tensor contain the information necessary for learning class specific pooling receptive field it is shown that this information can be extracted by a simple pca analysis of a specific tensor flattening a novel algorithm is then proposed for fitting box like receptive field to the eigenimages extracted from a collection of image the resulting receptive field can be combined with any of the recently popular coding strategy for image classification this combination is experimentally shown to improve classification accuracy for both vector quantization and fisher vector fv encoding it is then shown that the combination of the fv encoding with the proposed receptive field ha state of the art performance for both object recognition and scene classification finally when compared with previous attempt at learning receptive field for pooling the method is simpler and achieves better result 
a simple approach to learning invariance in image classification consists in augmenting the training set with transformed version of the original image however given a large set of possible transformation selecting a compact subset is challenging indeed all transformation are not equally informative and adding uninformative transformation increase training time with no gain in accuracy we propose a principled algorithm image transformation pursuit itp for the automatic selection of a compact set of transformation itp work in a greedy fashion by selecting at each iteration the one that yield the highest accuracy gain itp also allows to efficiently explore complex transformation that combine basic transformation we report result on two public benchmark the cub dataset of bird image and the imagenet challenge using fisher vector representation we achieve an improvement from to in top accuracy on cub and an improvement from to in top accuracy on imagenet we also show significant improvement for deep convnet feature from to on cub and from to on imagenet 
subjective image quality assessment iqa is the most reliable way to evaluate the visual quality of digital image perceived by the end user it is often used to construct image quality datasets and provide the groundtruth for building and evaluating objective quality measure subjective test based on the mean opinion score mo have been widely used in previous study but have many known problem such a an ambiguous scale definition and dissimilar interpretation of the scale among subject to overcome these limitation paired comparison pc test have been proposed a an alternative and are expected to yield more reliable result however pc test can be expensive and time consuming since for n image they require n comparison we present a hybrid subjective test which combine mo and pc test via a unified probabilistic model and an active sampling method the proposed method actively construct a set of query consisting of mo and pc test based on the expected information gain provided by each test and can effectively reduce the number of test required for achieving a target accuracy our method can be used in conventional laboratory study a well a crowdsourcing experiment experimental result show the proposed method outperforms state of the art subjective iqa test in a crowdsourced setting 
in this study we propose the application of principal component analysis pca to scale space pca is a standard method used in computer vision the translation of an input image into scale space is a continuous operation which requires the extension of conventional finite matrixbased pca to an infinite number of dimension in this study we use spectral decomposition to resolve this infinite eigenproblem by integration and we propose an approximate solution based on polynomial equation to clarify it eigensolutions we apply spectral decomposition to the gaussian scale space and scale normalized laplacian of gaussian log space a an application of this proposed method we introduce a method for generating gaussian blur image and scale normalized log image where we demonstrate that the accuracy of these image can be very high when calculating an arbitrary scale using a simple linear combination we also propose a new scale invariant feature transform sift detector a a more practical example 
in this paper we present our minimal point and linear point algorithm to estimate the relative pose of a multi camera system with known vertical direction i e known absolute roll and pitch angle we solve the minimal point algorithm with the hidden variable resultant method and show that it lead to an degree univariate polynomial that give up to real solution we identify a degenerated case from the linear point algorithm when it is solved with the standard singular value decomposition svd method and adopt a simple alternative solution which is easy to implement we show that our proposed algorithm can be efficiently used within ransac for robust estimation we evaluate the accuracy of our proposed algorithm by comparison with various existing algorithm for the multi camera system on simulation and show the feasibility of our proposed algorithm with result from multiple real world datasets 
the world is full of object with complex reflectance situated in complex illumination environment past work on full d geometry recovery however ha tried to handle this complexity by framing it into simplistic model of reflectance lambetian mirrored or diffuse plus specular or illumination one or more point light source though there ha been some recent progress in directly utilizing such complexity for recovering a single view geometry it is not clear how such single view method can be extended to reconstruct the full geometry to this end we derive a probabilistic geometry estimation method that fully exploit the rich signal embedded in complex appearance though each observation provides partial and unreliable information we show how to estimate the reflectance responsible for the diverse appearance and unite the orientation cue embedded in each observation to reconstruct the underlying geometry we demonstrate the effectiveness of our method on synthetic and real world object the result show that our method performs accurately across a wide range of real world environment and reflectance that lie between the extreme that have been the focus of past work 
in this paper we present a novel object detection approach that is capable of regressing the aspect ratio of object this result in accurately predicted bounding box having high overlap with the ground truth in contrast to most recent work we employ a random forest for learning a template based model but exploit the nature of this learning algorithm to predict arbitrary output space in this way we can simultaneously predict the object probability of a window in a sliding window approach a well a regress it aspect ratio with a single model furthermore we also exploit the additional information of the aspect ratio during the training of the joint classification regression random forest resulting in better detection model our experiment demonstrate several benefit i our approach give competitive result on standard detection benchmark ii the additional aspect ratio regression delivers more accurate bounding box than standard object detection approach in term of overlap with ground truth especially when tightening the evaluation criterion iii the detector itself becomes better by only including the aspect ratio information during training 
the appearance of an attribute can vary considerably from class to class e g a fluffy dog v a fluffy towel making standard class independent attribute model break down yet training object specific model for each attribute can be impractical and defeat the purpose of using attribute to bridge category boundary we propose a novel form of transfer learning that address this dilemma we develop a tensor factorization approach which given a sparse set of class specific attribute classifier can infer new one for object attribute pair unobserved during training for example even though the system ha no labeled image of striped dog it can use it knowledge of other attribute and object to tailor stripedness to the dog category with two large scale datasets we demonstrate both the need for category sensitive attribute a well a our method s successful transfer our inferred attribute classifier perform similarly well to those trained with the luxury of labeled class specific instance and much better than those restricted to traditional mode of transfer 
heart rate is an important indicator of people s physiological state recently several paper reported method to measure heart rate remotely from face video those method work well on stationary subject under well controlled condition but their performance significantly degrades if the video are recorded under more challenging condition specifically when subject motion and illumination variation are involved we propose a framework which utilizes face tracking and normalized least mean square adaptive filtering method to counter their influence we test our framework on a large difficult and public database mahnob hci and demonstrate that our method substantially outperforms all previous method we also use our method for long term heart rate monitoring in a game evaluation scenario and achieve promising result 
we propose a probabilistic method for parsing a temporal sequence such a a complex activity defined a composition of sub activity action the temporal structure of the high level activity is represented by a string length limited stochastic context free grammar given the grammar a bayes network which we term sequential interval network sin is generated where the variable node correspond to the start and end time of component action the network integrates information about the duration of each primitive action visual detection result for each primitive action and the activity s temporal structure at any moment in time during the activity message passing is used to perform exact inference yielding the posterior probability of the start and end time for each different activity action we provide demonstration of this framework being applied to vision task such a action prediction classification of the high level activity or temporal segmentation of a test sequence the method is also applicable in human robot interaction domain where continual prediction of human action is needed 
we extend the classical linear discriminant analysis lda technique to linear ranking analysis lra by considering the ranking order of class centroid on the projected subspace under the constrain on the ranking order of the class two criterion are proposed minimization of the classification error with the assumption that each class is homogenous guassian distributed maximization of the sum average of the k minimum distance of all neighboring class centroid pair both criterion can be efficiently solved by the convex optimization for one dimensional subspace greedy algorithm is applied to extend the result to the multi dimensional subspace experimental result show that lra with both criterion achieve state of the art performance on the task of ranking learning and zero shot learning and the maximum margin criterion provides a discriminative subspace selection method which can significantly remedy the class separation problem in comparing with several representative extension of lda 
recovering a non rigid d structure from a series of d observation is still a difficult problem to solve accurately many constraint have been proposed to facilitate the recovery and one of the most successful constraint is smoothness due to the fact that most real world object change continuously however many existing method require to determine the degree of smoothness beforehand which is not viable in practical situation in this paper we propose a new probabilistic model that incorporates the smoothness constraint without requiring any prior knowledge our approach regard the sequence of d shape a a simple stationary markov process with procrustes alignment whose parameter are learned during the fitting process the markov process is assumed to be stationary because deformation is finite and recurrent in general and the d shape are assumed to be procrustes aligned in order to discriminate deformation from motion the proposed method outperforms the state of the art method even though the computation time is rather moderate compared to the other existing method 
in kernel based learning the kernel trick transforms the original representation of a feature instance into a vector of similarity with the training feature instance known a kernel representation however feature instance are sometimes ambiguous and the kernel representation calculated based on them do not posse any discriminative information which can eventually harm the trained classifier to address this issue we propose to automatically select good feature instance when calculating the kernel representation in multiple kernel learning specifically for the kernel representation calculated for each input feature instance we multiply it element wise with a latent binary vector named a instance selection variable which target at selecting good instance and attenuate the effect of ambiguous one in the resulting new kernel representation beta process is employed for generating the prior distribution for the latent instance selection variable we then propose a bayesian graphical model which integrates both mkl learning and inference for the distribution of the latent instance selection variable variational inference is derived for model learning under a max margin principle our method is called beta process multiple kernel learning extensive experiment demonstrate the effectiveness of our method on instance selection and it high discriminative capability for various classification problem in vision 
in this paper we exploit natural sentential description of rgb d scene in order to improve d semantic parsing importantly in doing so we reason about which particular object each noun pronoun is referring to in the image this allows u to utilize visual information in order to disambiguate the so called coreference resolution problem that arises in text towards this goal we propose a structure prediction model that exploit potential computed from text and rgb d imagery to reason about the class of the d object the scene type a well a to align the noun pronoun with the referred visual object we demonstrate the effectiveness of our approach on the challenging nyu rgbd v dataset which we enrich with natural lingual description we show that our approach significantly improves d detection and scene classification accuracy and is able to reliably estimate the text to image alignment furthermore by using textual and visual information we are also able to successfully deal with coreference in text improving upon the state of the art stanford coreference system 
we present a new feature representation method for scene text recognition problem particularly focusing on improving scene character recognition many existing method rely on histogram of oriented gradient hog or part based model which do not span the feature space well for character in natural scene image especially given large variation in font with cluttered background in this work we propose a discriminative feature pooling method that automatically learns the most informative sub region of each scene character within a multi class classification framework whereas each sub region seamlessly integrates a set of low level image feature through integral image the proposed feature representation is compact computationally efficient and able to effectively model distinctive spatial structure of each individual character class extensive experiment conducted on challenging datasets char k icdar icdar svt show that our method significantly outperforms existing method on scene character classification and scene text recognition task 
multi target tracking is an interesting but challenging task in computer vision field most previous data association based method merely consider the relationship e g appearance and motion pattern similarity between detection in local limited temporal domain leading to their difficulty in handling long term occlusion and distinguishing the spatially close target with similar appearance in crowded scene in this paper a novel data association approach based on undirected hierarchical relation hypergraph is proposed which formulates the tracking task a a hierarchical dense neighborhood searching problem on the dynamically constructed undirected affinity graph the relationship between different detection across the spatiotemporal domain are considered in a high order way which make the tracker robust to the spatially close target with similar appearance meanwhile the hierarchical design of the optimization process fuel our tracker to long term occlusion with more robustness extensive experiment on various challenging datasets i e pet dataset parkinglot including both low and high density sequence demonstrate that the proposed method performs favorably against the state of the art method 
we take a new approach to computing dense scene flow between a pair of consecutive rgb d frame we exploit the availability of depth data by seeking correspondence with respect to patch specified not a the pixel inside square window but a the d point that are the inliers of sphere in world space our primary contribution is to show that by reasoning in term of such patch under dof rigid body motion in d we succeed in obtaining compelling result at displacement large and small without relying on either of two simplifying assumption that pervade much of the earlier literature brightness constancy or local surface planarity a a consequence of our approach our output is a dense field of d rigid body motion in contrast to the d translation that are the norm in scene flow reasoning in our manner additionally allows u to carry out occlusion handling using a dof consistency check for the flow computed in both direction and a patchwise silhouette check to help reason about alignment in occlusion area and to promote smoothness of the flow field using an intuitive local rigidity prior we carry out our optimization in two step obtaining a first correspondence field using an adaptation of patchmatch and subsequently using alpha expansion to jointly handle occlusion and perform regularization we show attractive flow result on challenging synthetic and real world scene that push the practical limit of the aforementioned assumption 
photo sharing website have become very popular in the last few year leading to huge collection of online image in addition to image data these website collect a variety of multimodal metadata about photo including text tag caption gps coordinate camera metadata user profile etc however this metadata is not well constrained and is often noisy sparse or missing altogether in this paper we propose a framework to model these loosely organized multimodal datasets and show how to perform loosely supervised learning using a novel latent conditional random field framework we learn parameter of the lcrf automatically from a small set of validation data using information theoretic metric learning itml to learn distance function and a structural svm formulation to learn the potential function we apply our framework on four datasets of image from flickr evaluating both qualitatively and quantitatively against several baseline 
we present a tool for re ranking the result of a specific query by considering the n n matrix of pairwise similarity among the element of the set of n retrieved result and the query itself the re ranking thus make use of the similarity between the various result and doe not employ additional source of information the tool is based on graphical bayesian model which reinforce retrieved item strongly linked to other retrieval and on repeated clustering to measure the stability of the obtained association the utility of the tool is demonstrated within the context of visual search of document from the cairo genizah and for retrieval of painting by the same artist and in the same style 
we consider the problem of tracking multiple interacting object in d using rgbd input and by considering a hypothesize and test approach due to their interaction object to be tracked are expected to occlude each other in the field of view of the camera observing them a naive approach would be to employ a set of independent tracker sit and to assign one tracker to each object this approach scale well with the number of object but fails a occlusion become stronger due to their disjoint consideration the solution representing the current state of the art employ a single joint tracker jt that account for all object simultaneously this directly resolve ambiguity due to occlusion but ha a computational complexity that grows geometrically with the number of tracked object we propose a middle ground namely an ensemble of collaborative tracker ect that combine best trait from both world to deliver a practical and accurate solution to the multi object d tracking problem we present quantitative and qualitative experiment with several synthetic and real world sequence of diverse complexity experiment demonstrate that ect manages to track far more complex scene than jt at a computational time that is only slightly larger than that of sit 
we propose a deep learning framework for image set classification with application to face recognition an adaptive deep network template adnt is defined whose parameter are initialized by performing unsupervised pre training in a layer wise fashion using gaussian restricted boltzmann machine grbms the pre initialized adnt is then separately trained for image of each class and class specific model are learnt based on the minimum reconstruction error from the learnt class specific model a majority voting strategy is used for classification the proposed framework is extensively evaluated for the task of image set classification based face recognition on honda ucsd cmu mobo youtube celebrity and a kinect dataset our experimental result and comparison with existing state of the art method show that the proposed method consistently achieves the best performance on all these datasets 
in this paper we study the role of context in existing state of the art detection and segmentation approach towards this goal we label every pixel of pascal voc detection challenge with a semantic category we believe this data will provide plenty of challenge to the community a it contains additional class for semantic segmentation and object detection our analysis show that nearest neighbor based approach perform poorly on semantic segmentation of contextual class showing the variability of pascal imagery furthermore improvement of exist ing contextual model for detection is rather modest in order to push forward the performance in this difficult scenario we propose a novel deformable part based model which exploit both local context around each candidate detection a well a global context at the level of the scene we show that this contextual reasoning significantly help in detecting object at all scale 
we propose an integrated probabilistic model for multi modal fusion of aerial imagery lidar data and optional gps measurement the model allows for analysis and dense reconstruction in term of both geometry and appearance of large d scene an advantage of the approach is that it explicitly model uncertainty and allows for missing data a compared with image based method dense reconstruction of complex urban scene are feasible with fewer observation moreover the proposed model allows one to estimate absolute scale and orientation and reason about other aspect of the scene e g detection of moving object a formulated the model lends itself to massively parallel computing we exploit this in an efficient inference scheme that utilizes both general purpose and domain specific hardware component we demonstrate result on large scale reconstruction of urban terrain from lidar and aerial photography data 
the surface bi directional reflectance distribution function brdf can be used to distinguish different material the brdfs of many real material are near isotropic and can be approximated well by a d function when the camera principal axis is coincident with the surface normal of the material sample the captured brdf slice is nearly d which suffers from significant information loss thus improvement in classification performance can be achieved by simply setting the camera at a slanted view to capture a larger portion of the brdf domain we further use a handheld flashlight camera to capture a d brdf slice for material classification this d slice capture important reflectance property such a specular reflection and retro reflectance we apply these result on ink classification which can be used in forensics and analyzing historical manuscript for the first time we show that most of the ink on the market can be well distinguished by their reflectance property 
scale drift is a crucial challenge for monocular autonomous driving to emulate the performance of stereo this paper present a real time monocular sfm system that corrects for scale drift using a novel cue combination framework for ground plane estimation yielding accuracy comparable to stereo over long driving sequence our ground plane estimation us multiple cue like sparse feature dense inter frame stereo and when applicable object detection a data driven mechanism is proposed to learn model from training data that relate observation covariance for each cue to error behavior of it underlying variable during testing this allows per frame adaptation of observation covariance based on relative confidence inferred from visual data our framework significantly boost not only the accuracy of monocular self localization but also that of application like object localization that rely on the ground plane experiment on the kitti dataset demonstrate the accuracy of our ground plane estimation monocular sfm and object localization relative to ground truth with detailed comparison to prior art 
in this paper we study the configuration of motion and structure that lead to inherent ambiguity in radial distortion estimation or d reconstruction with unknown radial distortion by analyzing the motion field of radially distorted image we solve for critical surface pair that can lead to the same motion field under different radial distortion and possibly different camera motion we study the property of the discovered critical configuration and discus the practically important configuration that often occur in real application we demonstrate the impact of the radial distortion ambiguity on multi view reconstruction with synthetic experiment and real experiment 
this paper present an improvement of the j linkage algorithm for fitting multiple instance of a model to noisy data corrupted by outlier the binary preference analysis implemented by j linkage is replaced by a continuous soft or fuzzy generalization that prof to perform better than j linkage on simulated data and compare favorably with state of the art method on public domain real datasets 
the output of many algorithm in computer vision is either non binary map or binary map e g salient object detection and object segmentation several measure have been suggested to evaluate the accuracy of these foreground map in this paper we show that the most commonly used measure for evaluating both non binary map and binary map do not always provide a reliable evaluation this includes the area under the curve measure the average precision measure the f measure and the evaluation measure of the pascal voc segmentation challenge we start by identifying three cause of inaccurate evaluation we then propose a new measure that amends these flaw an appealing property of our measure is being an intuitive generalization of the f measure finally we propose four meta measure to compare the adequacy of evaluation measure we show via experiment that our novel measure is preferable 
this paper proposes a framework for recognizing complex human activity in video our method describes human activity in a hierarchical discriminative model that operates at three semantic level at the lower level body pose are encoded in a representative but discriminative pose dictionary at the intermediate level encoded pose span a space where simple human action are composed at the highest level our model capture temporal and spatial composition of action into complex human activity our human activity classifier simultaneously model which body part are relevant to the action of interest a well a their appearance and composition using a discriminative approach by formulating model learning in a max margin framework our approach achieves powerful multi class discrimination while providing useful annotation at the intermediate semantic level we show how our hierarchical compositional model provides natural handling of occlusion to evaluate the effectiveness of our proposed framework we introduce a new dataset of composed human activity we provide empirical evidence that our method achieves state of the art activity classification performance on several benchmark datasets 
this paper describes a method of gait recognition from image sequence wherein a subject is accelerating or decelerating a a speed change occurs due to a change of pitch the first order derivative of a phase namely a gait stance and or stride we model this speed change using a cylindrical manifold whose azimuth and height corresponds to the phase and the stride respectively a radial basis function rbf interpolation framework is used to learn subject specific mapping matrix for mapping from manifold to image space given an input image sequence of speed transited gait of a test subject we estimate the mapping matrix of the test subject a well a the phase and stride sequence using an energy minimization framework considering the following three point fitness of the synthesized image to the input image sequence a well a to an eigenspace constructed by exemplar of training subject smoothness of the phase and the stride sequence and pitch and stride fitness to the pitch stride preference model using the estimated mapping matrix we synthesize a constant speed gait image sequence and extract a conventional period based gait feature from it for matching we conducted experiment using real speed transited gait image sequence with subject and demonstrated the effectiveness of the proposed method 
a scene category imposes tight distribution over the kind of object that might appear in the scene the appearance of those object and their layout in this paper we propose a method to learn scene structure that can encode three main interlacing component of a scene the scene category the context specific appearance of object and their layout our experimental evaluation show that our learned scene structure outperform state of the art method of deformable part model in detecting object in a scene our scene structure provides a level of scene understanding that is amenable to deep visual inference the scene structure can also generate feature that can later be used for scene categorization using these feature we also show promising result on scene categorization 
we present a novel co segmentation method for textured d shape our algorithm take a collection of textured shape belonging to the same category and sparse annotation of foreground segment and produce a joint dense segmentation of the shape in the collection we model the segment by a collectively trained gaussian mixture model the final model segmentation is formulated a an energy minimization across all model jointly where intra model edge control the smoothness and separation of model segment and inter model edge impart global consistency we show promising result on two large real world datasets and also compare with previous shape only d segmentation method using publicly available datasets 
we propose an image based facial reenactment system that replaces the face of an actor in an existing target video with the face of a user from a source video while preserving the original target performance our system is fully automatic and doe not require a database of source expression instead it is able to produce convincing reenactment result from a short source video captured with an off the shelf camera such a a webcam where the user performs arbitrary facial gesture our reenactment pipeline is conceived a part image retrieval and part face transfer the image retrieval is based on temporal clustering of target frame and a novel image matching metric that combine appearance and motion to select candidate frame from the source video while the face transfer us a d warping strategy that preserve the user s identity our system excels in simplicity a it doe not rely on a d face model it is robust under head motion and doe not require the source and target performance to be similar we show convincing reenactment result for video that we recorded ourselves and for low quality footage taken from the internet 
current human in the loop fine grained visual categorization system depend on a predefined vocabulary of attribute and part usually determined by expert in this work we move away from that expert driven and attribute centric paradigm and present a novel interactive classification system that incorporates computer vision and perceptual similarity metric in a unified framework at test time user are asked to judge relative similarity between a query image and various set of image these general query do not require expert defined terminology and are applicable to other domain and basic level category enabling a flexible efficient and scalable system for fine grained categorization with human in the loop our system outperforms existing state of the art system for relevance feedback based image retrieval a well a interactive classification resulting in a reduction of up to in the average number of question needed to correctly classify an image 
online multi object tracking aim at producing complete track of multiple object using the information accumulated up to the present moment it still remains a difficult problem in complex scene because of frequent occlusion by clutter or other object similar appearance of different object and other factor in this paper we propose a robust online multi object tracking method that can handle these difficulty effectively we first propose the tracklet confidence using the detectability and continuity of a tracklet and formulate a multi object tracking problem based on the tracklet confidence the multi object tracking problem is then solved by associating tracklets in different way according to their confidence value based on this strategy tracklets sequentially grow with online provided detection and fragmented tracklets are linked up with others without any iterative and expensive association here for reliable association between tracklets and detection we also propose a novel online learning method using an incremental linear discriminant analysis for discriminating the appearance of object by exploiting the proposed learning method tracklet association can be successfully achieved even under severe occlusion experiment with challenging public datasets show distinct performance improvement over other batch and online tracking method 
many learning problem in computer vision can be posed a structured prediction problem where the input and output instance are structured object such a tree graph or string rather than single label or scalar kernel method such a structured support vector machine twin gaussian process tgp structured gaussian process and vector valued reproducing kernel hilbert space rkhs offer powerful way to perform learning and inference over these domain positive definite kernel function allow u to quantitatively capture similarity between a pair of instance over these arbitrary domain a poor choice of the kernel function which decides the rkhs feature space often result in poor performance automatic kernel selection method have been developed but have focused only on kernel on the input domain i e one way in this work we propose a novel and efficient algorithm for learning kernel function simultaneously on both input and output domain we introduce the idea of learning polynomial kernel transformation and call this method simultaneous twin kernel learning stkl stkl can learn arbitrary but continuous kernel function including one way kernel learning a a special case we formulate this problem for learning covariance kernel of twin gaussian process our experimental evaluation using learned kernel on synthetic and several real world datasets demonstrate consistent improvement in performance of tgp s 
we present a novel method for automatic vanishing point detection based on primal and dual point alignment detection the very same point alignment detection algorithm is used twice first in the image domain to group line segment endpoint into more precise line second it is used in the dual domain where converging line become aligned point the use of the recently introduced pclines dual space and a robust point alignment detector lead to a very accurate algorithm experimental result on two public standard datasets show that our method significantly advance the state of the art in the manhattan world scenario while producing state of the art performance in non manhattan scene 
we have discovered that d reconstruction can be achieved from asingle still photographic capture due to accidental motion of thephotographer even while attempting to hold the camera still although these motion result in little baseline and therefore high depth uncertainty in theory we can combine many such measurement over the duration of the capture process a few second to achieve usable depth estimate wepresent a novel d reconstruction system tailored for this problemthat produce depth map from short video sequence from standard cameraswithout the need for multi lens optic active sensor or intentionalmotions by the photographer this result lead to the possibilitythat depth map of sufficient quality for rgb d photography application likeperspective change simulated aperture and object segmentation cancome for free for a significant fraction of still photographsunder reasonable condition 
the real world image database such a flickr are characterized by continuous addition of new image the recent approach for image annotation i e the problem of assigning tag to image have two major drawback first either model are learned using the entire training data or to handle the issue of dataset imbalance tag specific discriminative model are trained such model become obsolete and require relearning when new image and tag are added to database second the task of feature fusion is typically dealt using ad hoc approach in this paper we present a weighted extension of multi view non negative matrix factorization nmf to address the aforementioned drawback the key idea is to learn query specific generative model on the feature of nearest neighbor and tag using the proposed nmf knn approach which imposes consensus constraint on the coefficient matrix across different feature this result in coefficient vector across feature to be consistent and thus naturally solves the problem of feature fusion while the weight matrix introduced in the proposed formulation alleviate the issue of dataset imbalance furthermore our approach being query specific is unaffected by addition of image and tag in a database we tested our method on two datasets used for evaluation of image annotation and obtained competitive result 
we consider the intersection of two research field transfer learning and statistic on manifold in particular we consider for manifold valued data transfer learning of tangent space model such a gaussians distribution pca regression or classifier though one would hope to simply use ordinary rn transfer learning idea the manifold structure prevents it we overcome this by basing our method on inner product preserving parallel transport a well known tool widely used in other problem of statistic on manifold in computer vision at first this straight forward idea seems to suffer from an obvious shortcoming transporting large datasets is prohibitively expensive hindering scalability fortunately with our approach we never transport data rather we show how the statistical model themselves can be transported and prove that for the tangent space model above the transport commute with learning consequently our compact framework applicable to a large class of manifold is not restricted by the size of either the training or test set we demonstrate the approach by transferring pca and logistic regression model of real world data involving d shape and image descriptor 
we pose the following question what happens when test data not only differs from training data but differs from it in a continually evolving way the classic domain adaptation paradigm considers the world to be separated into stationary domain with clear boundary between them however in many real world application example cannot be naturally separated into discrete domain but arise from a continuously evolving underlying process example include video with gradually changing lighting and spam email with evolving spammer tactic we formulate a novel problem of adapting to such continuous domain and present a solution based on smoothly varying embeddings recent work ha shown the utility of considering discrete visual domain a fixed point embedded in a manifold of lower dimensional subspace adaptation can be achieved via transforms or kernel learned between such stationary source and target subspace we propose a method to consider non stationary domain which we refer to a continuous manifold adaptation cma we treat each target sample a potentially being drawn from a different subspace on the domain manifold and present a novel technique for continuous transform based adaptation our approach can learn to distinguish category using training data collected at some point in the past and continue to update it model of the category for some time into the future without receiving any additional label experiment on two visual datasets demonstrate the value of our approach for several popular feature representation 
modeling interaction of multiple co occurring object in a complex activity is becoming increasingly popular in the video domain the dynamic bayesian network dbn ha been applied to this problem in the past due to it natural ability to statistically capture complex temporal dependency however standard dbn structure learning algorithm are generatively learned require manual structure definition and or are computationally complex or restrictive we propose a novel structure learning solution that fuse the granger causality statistic a direct measure of temporal dependence with the adaboost feature selection algorithm to automatically constrain the temporal link of a dbn in a discriminative manner this approach enables u to completely define the dbn structure prior to parameter learning which reduces computational complexity in addition to providing a more descriptive structure we refer to this modeling approach a the granger constraint dbn gcdbn our experiment show how the gcdbn outperforms two of the most relevant state of the art graphical model in complex activity classification on handball video data surveillance data and synthetic data 
the objective of this study is to reconstruct image from bag of visual word bovw which is the de facto standard feature for image retrieval and recognition bovw is defined here a a histogram of quantized descriptor extracted densely on a regular grid at a single scale despite it wide use no report describes reconstruction of the original image of a bovw this task is challenging for two reason bovw includes quantization error when local descriptor are assigned to visual word bovw lack spatial information of local descriptor when we count the occurrence of visual word to tackle this difficult task we use a large scale image database to estimate the spatial arrangement of local descriptor then this task creates a jigsaw puzzle problem with adjacency and global location cost of visual word solving this optimization problem is also challenging because it is known a an np hard problem we propose a heuristic but efficient method to optimize it to underscore the effectiveness of our method we apply it to bovws extracted from about different category and demonstrate that it can reconstruct the original image although the image feature lack spatial information and include quantization error 
we address the problem of estimating the pose of a camera relative to a known d scene from a single rgb d frame we formulate this problem a inversion of the generative rendering procedure i e we want to find the camera pose corresponding to a rendering of the d scene model that is most similar with the observed input this is a non convex optimization problem with many local optimum we propose a hybrid discriminative generative learning architecture that consists of i a set of m predictor which generate m camera pose hypothesis and ii a selector or aggregator that infers the best pose from the multiple pose hypothesis based on a similarity function we are interested in predictor that not only produce good hypothesis but also hypothesis that are different from each other thus we propose and study method for learning marginally relevant predictor and compare their performance when used with different selection procedure we evaluate our method on a recently released d reconstruction dataset with challenging camera pose and scene variability experiment show that our method learns to make multiple prediction that are marginally relevant and can effectively select an accurate prediction furthermore our method outperforms the state of the art discriminative approach for camera relocalization 
it ha long been recognized that one of the fundamental difficulty in the estimation of two view epipolar geometry is the capability of handling outlier in this paper we develop a fast and tractable algorithm that maximizes the number of inlier under the assumption of a purely translating camera compared to classical random sampling method our approach is guaranteed to compute the optimal solution of a cost function based on reprojection error and it ha better time complexity the performance is in fact independent of the inlier outlier ratio of the data this open up for a more reliable approach to robust ego motion estimation our basic translation estimator can be embedded into a system that computes the full camera rotation we demonstrate the applicability in several difficult setting with large amount of outlier it turn out to be particularly well suited for small rotation and rotation around a known axis which is the case for cellular phone where the gravitation axis can be measured experimental result show that compared to standard ransac method based on minimal solver our algorithm produce more accurate estimate in the presence of large outlier ratio 
the prevalent approach to image based localization is matching interest point detected in the query image to a sparse d point cloud representing the known world the obtained correspondence are then used to recover a precise camera pose the state of the art in this field often ignores the availability of a set of d descriptor per d point for example by representing each d point by only it centroid in this paper we demonstrate that these set contain useful information that can be exploited by formulating matching a a discriminative classification problem since memory demand and computational complexity are crucial in such a setup we base our algorithm on the efficient and effective random fern principle we propose an extension which project feature to fern specific embedding space which yield improved matching rate in short runtime experiment first show that our novel formulation provides improved matching performance in comparison to the standard nearest neighbor approach and that we outperform related randomization method in our localization scenario 
this paper present a unified bag of visual word bow framework for dynamic scene recognition the approach build on primitive feature that uniformly capture spatial and temporal orientation structure of the imagery e g video a extracted via application of a bank of spatiotemporally oriented filter various feature encoding technique are investigated to abstract the primitive to an intermediate representation that is best suited to dynamic scene representation further a novel approach to adaptive pooling of the encoded feature is presented that capture spatial layout of the scene even while being robust to situation where camera motion and scene dynamic are confounded the resulting overall approach ha been evaluated on two standard publically available dynamic scene datasets the result show that in comparison to a representative set of alternative the proposed approach outperforms the previous state of the art in classification accuracy by 
this paper proposes a new vectorial total variation prior vtv for color image different from existing vtvs our vtv named the decorrelated vectorial total variation prior d vtv measure the discrete gradient of the luminance component and that of the chrominance one in a separated manner which significantly reduces undesirable uneven color effect moreover a higher order generalization of the d vtv which we call the decorrelated vectorial total generalized variation prior d vtgv is also developed for avoiding the staircasing effect that accompanies the use of vtvs a noteworthy property of the d vt g v is that it enables u to efficiently minimize objective function involving it by a primal dual splitting method experimental result illustrate their utility 
we present a video object segmentation approach that extends the particle filter to a region based image representation image partition is considered part of the particle filter measurement which enriches the available information and lead to a re formulation of the particle filter the prediction step us a co clustering between the previous image object partition and a partition of the current one which allows u to tackle the evolution of non rigid structure particle are defined a union of region in the current image partition and their propagation is computed through a single co clustering the proposed technique is assessed on the segtrack dataset leading to satisfactory perceptual result and obtaining very competitive pixel error rate compared with the state of the art method 
we focus on the problem of estimating the ground plane orientation and location in monocular video sequence from a moving observer our only assumption are that the d ego motion t and the ground plane normal n are orthogonal and that n and t are smooth over time we formulate the problem a a state continuous hidden markov model hmm where the hidden state contains t and n and may be estimated by sampling and decomposing homographies we show that using blocked gibbs sampling we can infer the hidden state with high robustness towards outlier drifting trajectory rolling shutter and an imprecise intrinsic calibration since our approach doe not need any initial orientation prior it work for arbitrary camera orientation in which the ground is visible 
we present a practical framework to automatically detect shadow in real world scene from a single photograph previous work on shadow detection put a lot of effort in designing shadow variant and invariant hand crafted feature in contrast our framework automatically learns the most relevant feature in a supervised manner using multiple convolutional deep neural network convnets the layer network architecture of each convnet consists of alternating convolution and sub sampling layer the proposed framework learns feature at the super pixel level and along the object boundary in both case feature are extracted using a context aware window centered at interest point the predicted posterior based on the learned feature are fed to a conditional random field model to generate smooth shadow contour our proposed framework consistently performed better than the state of the art on all major shadow database collected under a variety of condition 
given two image we want to predict which exhibit a particular visual attribute more than the other even when the two image are quite similar existing relative attribute method rely on global ranking function yet rarely will the visual cue relevant to a comparison be constant for all data nor will human perception of the attribute necessarily permit a global ordering to address these issue we propose a local learning approach for fine grained visual comparison given a novel pair of image we learn a local ranking model on the fly using only analogous training comparison we show how to identify these analogous pair using learned metric with result on three challenging datasets including a large newly curated dataset for fine grained comparison our method outperforms stateof the art method for relative attribute prediction 
a novel model based approach is introduced for real time detection and tracking of the pose of general articulated object a variety of dense motion and depth cue are integrated into a novel articulated iterative closest point approach the proposed method can independently track the six degree of freedom pose of over a hundred of rigid part in real time while at the same time imposing articulation constraint on the relative motion of different part we propose a novel rigidization framework for optimally handling unobservable part during tracking this involves rigidly attaching the minimal amount of unseen part to the rest of the structure in order to most effectively use the currently available knowledge we show how this framework can be used also for detection rather than tracking which allows for automatic system initialization and for incorporating pose estimate obtained from independent object part detector improved performance over alternative solution is demonstrated on real world sequence 
many computer vision problem require optimization of binary non submodular energy we propose a general optimization framework based on local submodular approximation lsa unlike standard lp relaxation method that linearize the whole energy globally our approach iteratively approximates the energy locally on the other hand unlike standard local optimization method e g gradient descent or projection technique we use non linear submodular approximation and optimize them without leaving the domain of integer solution we discus two specific lsa algorithm based on trust region and auxiliary function principle lsa tr and lsa aux these method obtain state of the art result on a wide range of application outperforming many standard technique such a lbp qpbo and trws while our paper is focused on pairwise energy our idea extend to higher order problem the code is available online 
the initial step of many computer vision algorithm are interest point extraction and matching in larger image set the pairwise matching of interest point descriptor between image is an important bottleneck for each descriptor in one image the approximate nearest neighbor in the other one ha to be found and checked against the second nearest neighbor to ensure the correspondence is unambiguous here we asked the question how to best decimate the list of interest point without losing match i e we aim to speed up matching by filtering out in advance those point which would not survive the matching stage it turn out that the best filtering criterion is not the response of the interest point detector which in fact is not surprising the goal of detection are repeatable and well localized point whereas the objective of the selection are point whose descriptor can be matched successfully we show that one can in fact learn to predict which descriptor are matchable and thus reduce the number of interest point significantly without losing too many match we show that this strategy a simple a it is greatly improves the matching success with the same number of point per image moreover we embed the prediction in a state of the art structure from motion pipeline and demonstrate that it also outperforms other selection method at system level 
we use weakly supervised structured learning to track and disambiguate the identity of multiple indistinguishable translucent and deformable object that can overlap for many frame for this challenging problem we propose a novel model which handle occlusion complex motion and non rigid deformation by jointly optimizing the flow of multiple latent intensity across frame these flow are latent variable for which the user cannot directly provide label instead we leverage a structured learning formulation that us weak user annotation to find the best hyperparameters of this model the approach is evaluated on a challenging dataset for the tracking of multiple drosophila larva which we make publicly available our method track multiple larva in spite of their poor distinguishability and minimizes the number of identity switch during prolonged mutual occlusion 
we present a novel way to automatically summarize and represent the storyline of a tv episode by visualizing character interaction a a chart we also propose a scene detection method that lends itself well to generate over segmented scene which is used to partition the video the positioning of character line in the chart is formulated a an optimization problem which trade between the aesthetic and functionality of the chart using automatic person identification we present storygraphs for diverse tv series encompassing a total of episode we define quantitative criterion to evaluate storygraphs and also compare them against episode summary to evaluate their ability to provide an overview of the episode 
the fisher vector fv representation is a high dimensional extension of the popular bag of word representation transformation of the fv by power and normalization ha shown to significantly improve it performance and led to state of the art result for a range of image and video classification and retrieval task these normalization however render the representation non additive over local descriptor combined with it high dimensionality this make the fv computationally expensive for the purpose of localization task in this paper we present approximation to both these normalization which yield significant improvement in the memory and computational cost of the fv when used for localization second we show how these approximation can be used to define upper bound on the score function that can be efficiently evaluated which enables the use of branch and bound search a an alternative to exhaustive sliding window search we present experimental evaluation result on classification and temporal localization of action in video these show that the our approximation lead to a speedup of at least one order of magnitude while maintaining state of the art action recognition and localization performance 
this paper describes a framework for modeling human activity a temporally structured process our approach is motivated by the inherently hierarchical nature of human activity and the close correspondence between human action and speech we model action unit using hidden markov model much like word in speech these action unit then form the building block to model complex human activity a sentence using an action grammar to evaluate our approach we collected a large dataset of daily cooking activity the dataset includes a total of participant each performing a total of cooking activity in multiple real life kitchen resulting in over hour of video footage we evaluate the htk toolkit a state of the art speech recognition engine in combination with multiple video feature descriptor for both the recognition of cooking activity e g making pancake a well a the semantic parsing of video into action unit e g cracking egg our result demonstrate the benefit of structured temporal generative approach over existing discriminative approach in coping with the complexity of human daily life activity 
in this paper we aim for zero shot classification that is visual recognition of an unseen class by using knowledge transfer from known class our main contribution is costa which exploit co occurrence of visual concept in image for knowledge transfer these inter dependency arise naturally between concept and are easy to obtain from existing annotation or web search hit count we estimate a classifier for a new label a a weighted combination of related class using the co occurrence to define the weight we propose various metric to leverage these co occurrence and a regression model for learning a weight for each related class we also show that our zero shot classifier can serve a prior for few shot learning experiment on three multi labeled datasets reveal that our proposed zero shot method are approaching and occasionally outperforming fully supervised svms we conclude that co occurrence statistic suffice for zero shot classification 
this paper present a novel and general method for the detection rectification and segmentation of imaged coplanar repeated pattern the only assumption made of the scene geometry is that repeated scene element are mapped to each other by planar euclidean transformation the class of pattern covered is broad and includes nearly all commonly seen planar man made repeated pattern in addition novel linear constraint are used to reduce geometric ambiguity between the rectified imaged pattern and the scene pattern rectification to within a similarity of the scene plane is achieved from one rotated repeat or to within a similarity with a scale ambiguity along the axis of symmetry from one reflected repeat a stratum of constraint is derived that give the necessary configuration of repeat for each successive level of rectification a generative model for the imaged pattern is inferred and used to segment the pattern with pixel accuracy qualitative result are shown on a broad range of image type on which state of the art method fail 
this paper proposes a method for estimating the d body shape of a person with robustness to clothing we formulate the problem a optimization over the manifold of valid depth map of body shape learned from synthetic training data the manifold itself is represented using a novel data structure a multi resolution manifold forest mrmf which contains vertical edge between tree node a well a horizontal edge between node across tree that correspond to overlapping partition we show that this data structure allows both efficient localization and navigation on the manifold for on the fly building of local linear model manifold charting we demonstrate shape estimation of clothed user showing significant improvement in accuracy over global shape model and model using pre computed cluster we further compare the mrmf with alternative manifold charting method on a public dataset for estimating d motion from noisy d marker observation obtaining state of the art result 
object detection performance a measured on the canonical pascal voc dataset ha plateaued in the last few year the best performing method are complex ensemble system that typically combine multiple low level image feature with high level context in this paper we propose a simple and scalable detection algorithm that improves mean average precision map by more than relative to the previous best result on voc achieving a map of our approach combine two key insight one can apply high capacity convolutional neural network cnns to bottom up region proposal in order to localize and segment object and when labeled training data is scarce supervised pre training for an auxiliary task followed by domain specific fine tuning yield a significant performance boost since we combine region proposal with cnns we call our method r cnn region with cnn feature we also present experiment that provide insight into what the network learns revealing a rich hierarchy of image feature source code for the complete system is available at http www c berkeley edu rbg rcnn 
there ha been a lot of work on face modeling analysis and landmark detection with active appearance model being one of the most successful technique a major drawback of these model is the large number of detailed annotated training example needed for learning therefore we present a transfer learning method that is able to learn from related training data using an instance weighted transfer technique our method is derived using a generalization of importance sampling and in contrast to previous work we explicitly try to tackle the transfer already during learning instead of adapting the fitting process in our studied application of face landmark detection we efficiently transfer facial expression from other human individual and are thus able to learn a precise face active appearance model only from neutral face of a single individual our approach is evaluated on two common face datasets and outperforms previous transfer method 
human are capable of perceiving a scene at a glance and obtain deeper understanding with additional time similarly visual recognition deployment should be robust to varying computational budget such situation require anytime recognition ability which is rarely considered in computer vision research we present a method for learning dynamic policy to optimize anytime performance in visual architecture our model sequentially order feature computation and performs subsequent classification crucially decision are made at test time and depend on observed data and intermediate result we show the applicability of this system to standard problem in scene and object recognition on suitable datasets we can incorporate a semantic back off strategy that give maximally specific prediction for a desired level of accuracy this provides a new view on the time course of human visual perception 
photometric stereo offer the possibility of object shape reconstruction via reasoning about the amount of light reflected from oriented surface however in murky medium such a sea water the illuminating light interacts with the medium and some of it is backscattered towards the camera due to this additive light component the standard photometric stereo equation lead to poor quality shape estimation previous author have attempted to reformulate the approach but have either neglected backscatter entirely or disregarded it non uniformity on the sensor when camera and light are close to each other we show that by compensating effectively for the backscatter component a linear formulation of photometric stereo is allowed which recovers an accurate normal map using only light our backscatter compensation method for point source can be used for estimating the uneven backscatter directly from single image without any prior knowledge about the characteristic of the medium or the scene we compare our method with previous approach through extensive experimental result where a variety of object are imaged in a big water tank whose turbidity is systematically increased and show reconstruction quality which degrades little relative to clean water result even with a very significant scattering level 
we explore whether we can observe time s arrow in a temporal sequence is it possible to tell whether a video is running forward or backwards we investigate this somewhat philosophical question using computer vision and machine learning technique we explore three method by which we might detect time s arrow in video sequence based on distinct way in which motion in video sequence might be asymmetric in time we demonstrate good video forward backwards classification result on a selection of youtube video clip and on natively captured sequence with no temporally dependent video compression and examine what motion the model have learned that help discriminate forward from backwards time 
in this paper we address the problem of synthesizing novel view from a set of input image state of the art method such a the unstructured lumigraph have been using heuristic to combine information from the original view often using an explicit or implicit approximation of the scene geometry while the proposed heuristic have been largely explored and proven to work effectively a bayesian formulation wa recently introduced formalizing some of the previously proposed heuristic pointing out which physical phenomenon could lie behind each however some important heuristic were still not taken into account and lack proper formalization we contribute a new physic based generative model and the corresponding maximum a posteriori estimate providing the desired unification between heuristic based method and a bayesian formulation the key point is to systematically consider the error induced by the uncertainty in the geometric proxy we provide an extensive discussion analyzing how the obtained equation explain the heuristic developed in previous method furthermore we show that our novel bayesian model significantly improves the quality of novel view in particular if the scene geometry estimate is inaccurate 
the surface bi directional reflectance distribution function brdf can be used to distinguish different material the brdfs of many real material are near isotropic and can be approximated well by a d function when the camera principal axis is coincident with the surface normal of the material sample the captured brdf slice is nearly d which suffers from significant information loss thus improvement in classification performance can be achieved by simply setting the camera at a slanted view to capture a larger portion of the brdf domain we further use a handheld flashlight camera to capture a d brdf slice for material classification this d slice capture important reflectance property such a specular reflection and retro reflectance we apply these result on ink classification which can be used in forensics and analyzing historical manuscript for the first time we show that most of the ink on the market can be well distinguished by their reflectance property 
convolutional neural network cnn have recently shown outstanding image classification performance in the largescale visual recognition challenge ilsvrc the success of cnns is attributed to their ability to learn rich mid level image representation a opposed to hand designed low level feature used in other image classification method learning cnns however amount to estimating million of parameter and requires a very large number of annotated image sample this property currently prevents application of cnns to problem with limited training data in this work we show how image representation learned with cnns on large scale annotated datasets can be efficiently transferred to other visual recognition task with limited amount of training data we design a method to reuse layer trained on the imagenet dataset to compute mid level image representation for image in the pascal voc dataset we show that despite difference in image statistic and task in the two datasets the transferred representation lead to significantly improved result for object and action classification outperforming the current state of the art on pascal voc and datasets we also show promising result for object and action localization 
in this paper we introduce a fully automated multistage graphical probabilistic framework to segment brain tumour from multimodal magnetic resonance image mri acquired from real patient an initial bayesian tumour classification based on gabor texture feature permit subsequent computation to be focused on area where the probability of tumour is deemed high an iterative multistage markov random field mrf framework is then devised to classify the various tumour subclass e g edema solid tumour enhancing tumour and necrotic core specifically an adapted voxel based mrf provides tumour candidate to a higher level regional mrf which then leverage both contextual texture information and relative spatial consistency of the tumour subclass position to provide updated regional information down to the voxel based mrf for further local refinement the two stage iterate until convergence experiment are performed on publicly available patient brain tumour image from the miccai and brain tumour segmentation challenge the result demonstrate that the proposed method achieves the top performance in the segmentation of tumour core and enhancing tumour and performs comparably to the winner in other tumour category 
robust multi object tracking by detection requires the correct assignment of noisy detection result to object trajectory we address this problem by proposing an online approach based on the observation that object detector primarily fail if object are significantly occluded in contrast to most existing work we only rely on geometric information to efficiently overcome detection failure in particular we exploit the spatio temporal evolution of occlusion region detector reliability and target motion prediction to robustly handle missed detection in combination with a conservative association scheme for visible object this allows for real time tracking of multiple object from a single static camera even in complex scenario our evaluation on publicly available multi object tracking benchmark datasets demonstrate favorable performance compared to the state of the art in online and offline multi object tracking 
motivated by multi distribution divergence which originate in information theory we propose a notion of multi point kernel and study their application we study a class of kernel based on jensen type divergence and show that these can be extended to measure similarity among multiple point we study tensor flattening method and develop a multi point kernel spectral clustering msc method we further emphasize on a special case of the proposed kernel which is a multi point extension of the linear dot product kernel and show the existence of cubic time tensor flattening algorithm in this case finally we illustrate the usefulness of our contribution using standard data set and image segmentation task 
this work proposes a method to interpret a scene by assigning a semantic label at every pixel and inferring the spatial extent of individual object instance together with their occlusion relationship starting with an initial pixel labeling and a set of candidate object mask for a given test image we select a subset of object that explain the image well and have valid overlap relationship and occlusion ordering this is done by minimizing an integer quadratic program either using a greedy method or a standard solver then we alternate between using the object prediction to refine the pixel label and vice versa the proposed system obtains promising result on two challenging subset of the labelme and sun datasets the largest of which contains image and class 
we introduce a new approach for recognizing and reconstructing d object in image our approach is based on an analysis by synthesis strategy a forward synthesis model construct possible geometric interpretation of the world and then selects the interpretation that best agrees with the measured visual evidence the forward model synthesizes visual template defined on invariant hog feature these visual template are discriminatively trained to be accurate for inverse estimation we introduce an efficient brute force approach to inference that search through a large number of candidate reconstruction returning the optimal one one benefit of such an approach is that recognition is inherently re constructive we show state of the art performance for detection and reconstruction on two challenging d object recognition datasets of car and cuboid 
in this study we propose the application of principal component analysis pca to scale space pca is a standard method used in computer vision the translation of an input image into scale space is a continuous operation which requires the extension of conventional finite matrixbased pca to an infinite number of dimension in this study we use spectral decomposition to resolve this infinite eigenproblem by integration and we propose an approximate solution based on polynomial equation to clarify it eigensolutions we apply spectral decomposition to the gaussian scale space and scale normalized laplacian of gaussian log space a an application of this proposed method we introduce a method for generating gaussian blur image and scale normalized log image where we demonstrate that the accuracy of these image can be very high when calculating an arbitrary scale using a simple linear combination we also propose a new scale invariant feature transform sift detector a a more practical example 
human gesture similar to speech and handwriting are often unique to the individual training a generic classifier applicable to everyone can be very difficult and a such it ha become a standard to use personalized classifier in speech and handwriting recognition in this paper we address the problem of personalization in the context of gesture recognition and propose a novel and extremely efficient way of doing personalization unlike conventional personalization method which learn a single classifier that later get adapted our approach learns a set portfolio of classifier during training one of which is selected for each test subject based on the personalization data we formulate classifier personalization a a selection problem and propose several algorithm to compute the set of candidate classifier our experiment show that such an approach is much more efficient than adapting the classifier parameter but can still achieve comparable or better result 
saliency prediction typically relies on hand crafted multiscale feature that are combined in different way to form a master saliency map which encodes local image conspicuity recent improvement to the state of the art on standard benchmark such a mit have been achieved mostly by incrementally adding more and more hand tuned feature such a car or face detector to existing model in contrast we here follow an entirely automatic data driven approach that performs a large scale search for optimal feature we identify those instance of a richly parameterized bio inspired model family hierarchical neuromorphic network that successfully predict image saliency because of the high dimensionality of this parameter space we use automated hyperparameter optimization to efficiently guide the search the optimal blend of such multilayer feature combined with a simple linear classifier achieves excellent performance on several image saliency benchmark our model outperform the state of the art on mit on which feature and classifier are learned without additional training these model generalize well to two other image saliency data set toronto and nusef despite their different image content finally our algorithm score best of all the model evaluated to date on the mit saliency challenge which us a hidden test set to facilitate an unbiased comparison 
a method for online real time learning of individual object detector is presented starting with a pre trained boosted category detector an individual object detector is trained with near zero computational cost the individual detector is obtained by using the same feature cascade a the category detector along with elementary manipulation of the threshold of the weak classifier this is ideal for online operation on a video stream or for interactive learning application addressed by this technique are reidentification and individual tracking experiment on four challenging pedestrian and face datasets indicate that it is indeed possible to learn identity classifier in real time besides being faster trained our classifier ha better detection rate than previous method on two of the datasets 
algorithm for solving system of polynomial equation are key component for solving geometry problem in computer vision fast and stable polynomial solver are essential for numerous application e g minimal problem or finding for all stationary point of certain algebraic error recently full symmetry in the polynomial system ha been utilized to simplify and speed up state of the art polynomial solver based on gro bner basis method in this paper we further explore partial symmetry i e where the symmetry lie in a subset of the variable in the polynomial system we develop novel numerical scheme to utilize such partial symmetry we then demonstrate the advantage of our scheme in several computer vision problem in both synthetic and real experiment we show that utilizing partial symmetry allow u to obtain faster and more accurate polynomial solver than the general solver 
the basic idea of shape from shading is to infer the shape of a surface from it shading information in a single image since this problem is ill posed a number of simplifying assumption have been often used however they rarely hold in practice this paper present a simple shading correction algorithm that transforms the image to a new image that better satisfies the assumption typically needed by existing algorithm thus improving the accuracy of shape recovery the algorithm take advantage of some local shading measure that have been driven under these assumption the method is successfully evaluated on real data of human teeth with ground truth d shape 
this paper present a novel method to generate a hypothesis set of class independent object region it ha been shown that such object region can be used to focus computer vision technique on the part of an image that matter most leading to significant improvement in both object localisation and semantic segmentation in recent year of course the higher quality of class independent object region the better subsequent computer vision algorithm can perform in this paper we focus on generating higher quality object hypothesis we start from an oversegmentation for which we propose to extract a wide variety of region feature we group region together in a hierarchical fashion for which we train a random forest which predicts at each stage of the hierarchy the best possible merge hence unlike other approach we use relatively powerful feature and classifier at an early stage of the generation of likely object region finally we identify and combine stable region in order to capture object which consist of dissimilar part we show on the pascal and datasets that our method yield higher quality region than competing approach while it is at the same time more computationally efficient 
we consider discrete pairwise energy minimization problem weighted constraint satisfaction max sum labeling and method that identify a globally optimal partial assignment of variable when finding a complete optimal assignment is intractable determining optimal value for a part of variable is an interesting possibility existing method are based on different sufficient condition we propose a new sufficient condition for partial optimality which is verifiable in polynomial time invariant to reparametrization of the problem and permutation of label and includes many existing sufficient condition a special case it is derived by using a relaxation technique coherent with the relaxation for energy minimization we pose the problem of finding the maximum optimal partial assignment identifiable by the new sufficient condition a polynomial method is proposed which is guaranteed to assign same or larger part of variable find the same or larger part of optimal assignment than several existing approach the core of the method is a specially constructed linear program that identifies persistent assignment in an arbitrary multi label setting 
we present a distance metric based upon the notion of minimum cost injective mapping between set our function satisfies metric property a long a the cost of the minimum mapping is derived from a semimetric for which the triangle inequality is not necessarily satisfied we show that the jaccard distance alternatively biotope tanimoto or marczewski steinhaus distance may be considered the special case for finite set where cost are derived from the discrete metric extension that allow premetrics not necessarily symmetric multisets generalized to include probability distribution and asymmetric mapping are given that expand the versatility of the metric without sacrificing metric property the function ha potential application in pattern recognition machine learning and information retrieval 
dense d reconstruction of real world object containing textureless reflective and specular part is a challenging task using general smoothness prior such a surface area regularization can lead to defect in the form of disconnected part or unwanted indentation we argue that this problem can be solved by exploiting the object class specific local surface orientation e g a car is always close to horizontal in the roof area therefore we formulate an object class specific shape prior in the form of spatially varying anisotropic smoothness term the parameter of the shape prior are extracted from training data we detail how our shape prior formulation directly fit into recently proposed volumetric multi label reconstruction approach this allows a segmentation between the object and it supporting ground in our experimental evaluation we show reconstruction using our trained shape prior on several challenging datasets 
preprocessing a d image often produce a noisy cloud of interest point we study the problem of counting hole in noisy cloud in the plane the hole in a given cloud are quantified by the topological persistence of their boundary contour when the cloud is analyzed at all possible scale we design the algorithm to count hole that are most persistent in the filtration of offset neighborhood around given point the input is a cloud of n point in the plane without any user defined parameter the algorithm ha a near linear time and a linear space o n the output is the array number of hole relative persistence in the filtration we prove theoretical guarantee when the algorithm find the correct number of hole component in the complement of an unknown shape approximated by a cloud 
we present a new globally optimal algorithm for self calibrating a moving camera with constant parameter our method aim at estimating the dual absolute quadric daq under the rank and optionally camera center chirality constraint we employ the branch and prune paradigm and explore the space of only parameter pruning in our method relies on solving linear matrix inequality lmi feasibility and generalized eigenvalue gev problem that solely depend upon the entry of the daq these lmi and gev problem are used to rule out branch in the search tree in which a quadric not satisfying the rank and chirality condition on camera center is guaranteed not to exist the chirality lmi condition are obtained by relying on the mild assumption that the camera undergoes a rotation of no more than between consecutive view furthermore our method doe not rely on calculating bound on any particular cost function and hence can virtually optimize any objective while achieving global optimality in a very competitive running time 
the functional difference between a diffuse wall and a mirror is well understood one scatter back into all direction and the other one preserve the directionality of reflected light the temporal structure of the light however is left intact by both assuming simple surface reflection photon that arrive first are reflected first in this paper we exploit this insight to recover object outside the line of sight from second order diffuse reflection effectively turning wall into mirror we formulate the reconstruction task a a linear inverse problem on the transient response of a scene which we acquire using an affordable setup consisting of a modulated light source and a time of flight image sensor by exploiting sparsity in the reconstruction domain we achieve resolution in the order of a few centimeter for object shape depth and laterally and albedo our method is robust to ambient light and work for large room sized scene it is drastically faster and le expensive than previous approach using femtosecond laser and streak camera and doe not require any moving part 
we propose ordered subspace clustering osc to segment data drawn from a sequentially ordered union of subspace current subspace clustering technique learn the relationship within a set of data and then use a separate clustering algorithm such a ncut for final segmentation in contrast our technique under certain condition is capable of segmenting cluster intrinsically without providing the number of cluster a a parameter similar to sparse subspace clustering ssc we formulate the problem a one of finding a sparse representation but include a new penalty term to take care of sequential data we test our method on data drawn from infrared hyper spectral data video sequence and face image our experiment show that our method osc outperforms the state of the art method spatial subspace clustering spatsc low rank representation lrr and ssc 
this paper present a method for acquiring dense nonrigid shape and deformation from a single monocular depth sensor we focus on modeling the human hand and assume that a single rough template model is available we combine and extend existing work on model based tracking subdivision surface fitting and mesh deformation to acquire detailed hand model from a few a frame of depth data we propose an objective that measure the error of fit between each sampled data point and a continuous model surface defined by a rigged control mesh and us a rigid a possible arap regularizers to cleanly separate the model and template geometry a key contribution is our use of a smooth model based on subdivision surface that allows simultaneous optimization over both correspondence and model parameter this avoids the use of iterated closest point icp algorithm which often lead to slow convergence automatic initialization is obtained using a regression forest trained to infer approximate correspondence experiment show that the resulting mesh model the user s hand shape more accurately than just adapting the shape parameter of the skeleton and that the retargeted skeleton accurately model the user s articulation we investigate the effect of various modeling choice and show the benefit of using subdivision surface and arap regularization 
learning a low dimensional representation of image is useful for various application in graphic and computer vision existing solution either require manually specified landmark for corresponding point in the image or are restricted to specific object or shape deformation this paper alleviates these limitation by imposing a specific model for generating image the nested composition of color shape and appearance we show that each component can be approximated by a low dimensional subspace when the others are factored out our formulation allows for efficient learning and experiment show encouraging result 
a main theme in object detection are currently discriminative part based model the powerful model that combine all part is then typically only feasible for few constituent which are in turn iteratively trained to make them a strong a possible we follow the opposite strategy by randomly sampling a large number of instance specific part classifier due to their number we cannot directly train a powerful classifier to combine all part therefore we randomly group them into fewer overlapping composition that are trained using a maximum margin approach in contrast to the common rationale of compositional approach we do not aim for semantically meaningful ensemble rather we seek randomized composition that are discriminative and generalize over all instance of a category our approach not only localizes object in cluttered scene but also explains them by parsing with composition and their constituent part we conducted experiment on pascal voc on the voc evaluation server and on the mitindoor scene dataset to the best of our knowledge our randomized max margin composition rm c are the currently best performing single class object detector using only hog feature moreover the individual contribution of composition and their part are evaluated in separate experiment that demonstrate their potential 
in modern face recognition the conventional pipeline consists of four stage detect align represent classify we revisit both the alignment step and the representation step by employing explicit d face modeling in order to apply a piecewise affine transformation and derive a face representation from a nine layer deep neural network this deep network involves more than million parameter using several locally connected layer without weight sharing rather than the standard convolutional layer thus we trained it on the largest facial dataset to date an identity labeled dataset of four million facial image belonging to more than identity the learned representation coupling the accurate model based alignment with the large facial database generalize remarkably well to face in unconstrained environment even with a simple classifier our method reach an accuracy of on the labeled face in the wild lfw dataset reducing the error of the current state of the art by more than closely approaching human level performance 
graph cut method such a alpha expansion and fusion move have been successful at solving many optimization problem in computer vision higher order markov random field mrf s which are important for numerous application have proven to be very difficult especially for multilabel mrf s i e more than label in this paper we propose a new primal dual energy minimization method for arbitrary higher order multilabel mrf s primal dual method provide guaranteed approximation bound and can exploit information in the dual variable to improve their efficiency our algorithm generalizes the pd technique for first order mrfs and relies on a variant of max flow that can exactly optimize certain higher order binary mrf s we provide approximation bound similar to pd and the method is fast in practice it can optimize non submodular mrf s and additionally can incorporate problem specific knowledge in the form of fusion proposal we compare experimentally against the existing approach that can efficiently handle these difficult energy function for higher order denoising and stereo mrf s we produce lower energy while running significantly faster 
this paper address the problem of face alignment for a single image we show how an ensemble of regression tree can be used to estimate the face s landmark position directly from a sparse subset of pixel intensity achieving super realtime performance with high quality prediction we present a general framework based on gradient boosting for learning an ensemble of regression tree that optimizes the sum of square error loss and naturally handle missing or partially labelled data we show how using appropriate prior exploiting the structure of image data help with efficient feature selection different regularization strategy and it importance to combat overfitting are also investigated in addition we analyse the effect of the quantity of training data on the accuracy of the prediction and explore the effect of data augmentation using synthesized data 
the problem of how to arrive at an appropriate d segmentation of a scene remains difficult while current state of the art method continue to gradually improve in benchmark performance they also grow more and more complex for example by incorporating chain of classifier which require training on large manually annotated data set a an alternative to this we present a new efficient learningand model free approach for the segmentation of d point cloud into object part the algorithm begin by decomposing the scene into an adjacency graph of surface patch based on a voxel grid edge in the graph are then classified a either convex or concave using a novel combination of simple criterion which operate on the local geometry of these patch this way the graph is divided into locally convex connected subgraphs which with high accuracy represent object part additionally we propose a novel depth dependent voxel grid to deal with the decreasing point density at far distance in the point cloud this improves segmentation allowing the use of fixed parameter for vastly different scene the algorithm is straightforward to implement and requires no training data while nevertheless producing result that are comparable to state of the art method which incorporate high level concept involving classification learning and model fitting 
we introduce an approach to computing and comparing covariance descriptor covds in infinite dimensional space covds have become increasingly popular to address classification problem in computer vision while covds offer some robustness to measurement variation they also throw away part of the information contained in the original data by only retaining the second order statistic over the measurement here we propose to overcome this limitation by first mapping the original data to a high dimensional hilbert space and only then compute the covds we show that several bregman divergence can be computed between the resulting covds in hilbert space via the use of kernel we then exploit these divergence for classification purpose our experiment demonstrate the benefit of our approach on several task such a material and texture recognition person re identification and action recognition from motion capture data 
while machine learning ha been instrumental to the ongoing progress in most area of computer vision it ha not been applied to the problem of stereo matching with similar frequency or success we present a supervised learning approach for predicting the correctness of stereo match based on a random forest and a set of feature that capture various form of information about each pixel we show highly competitive result in predicting the correctness of match and in confidence estimation which allows u to rank pixel according to the reliability of their assigned disparity moreover we show how these confidence value can be used to improve the accuracy of disparity map by integrating them with an mrf based stereo algorithm this is an important distinction from current literature that ha mainly focused on sparsification by removing potentially erroneous disparity to generate quasi dense disparity map 
we present a new method for tracking the d position global orientation and full articulation of human hand following recent advance in model based hypothesize and test method the high dimensional parameter space of hand configuration is explored with a novel evolutionary optimization technique specifically tailored to the problem the proposed method capitalizes on the fact that sample from quasi random sequence such a the sobol have low discrepancy and exhibit a more uniform coverage of the sampled space compared to random sample obtained from the uniform distribution the method ha been tested for the problem of tracking the articulation of a single hand d parameter space and two hand d space extensive experiment have been carried out with synthetic and real data in comparison with state of the art method the quantitative evaluation show that for case of limited computational resource the new approach achieves a speed up of four single hand tracking and eight two hand tracking without compromising tracking accuracy interestingly the proposed method is preferable compared to the state of the art either in the case of limited computational resource or in the case of more complex i e higher dimensional problem thus improving the applicability of the method in a number of application domain 
we study the theory of projective reconstruction for multiple projection from an arbitrary dimensional projective space into lower dimensional space this problem is important due to it application in the analysis of dynamical scene the current theory due to hartley and schaffalitzky is based on the grassmann tensor generalizing the idea of fundamental matrix trifocal tensor and quadrifocal tensor used in the well studied case of d to d projection we present a theory whose point of departure is the projective equation rather than the grassmann tensor this is a better fit for the analysis of approach such a bundle adjustment and projective factorization which seek to directly solve the projective equation in a first step we prove that there is a unique grassmann tensor corresponding to each set of image point a question that remained open in the work of hartley and schaffalitzky then we prove that projective equivalence follows from the set of projective equation given certain condition on the estimated camera point setup or the estimated projective depth finally we demonstrate how wrong solution to the projective factorization problem can happen and classify such degenerate solution based on the zero pattern in the estimated depth matrix 
we present an image set classification algorithm based on unsupervised clustering of labeled training and unlabeled test data where label are only used in the stopping criterion the probability distribution of each class over the set of cluster is used to define a true set based similarity measure to this end we propose an iterative sparse spectral clustering algorithm in each iteration a proximity matrix is efficiently recomputed to better represent the local subspace structure initial cluster capture the global data structure and finer cluster at the later stage capture the subtle class difference not visible at the global scale image set are compactly represented with multiple grassmannian manifold which are subsequently embedded in euclidean space with the proposed spectral clustering algorithm we also propose an efficient eigenvector solver which not only reduces the computational cost of spectral clustering by many fold but also improves the clustering quality and final classification result experiment on five standard datasets and comparison with seven existing technique show the efficacy of our algorithm 
camera image saved in raw format are being adopted in computer vision task since raw value represent minimally processed sensor response camera manufacturer however have yet to adopt a standard for raw image and current raw rgb value are device specific due to different sensor spectral sensitivity this result in significantly different raw image for the same scene captured with different camera this paper focus on estimating a mapping that can convert a raw image of an arbitrary scene and illumination from one camera s raw space to another to this end we examine various mapping strategy including linear and non linear transformation applied both in a global and illumination specific manner we show that illumination specific mapping give the best result however at the expense of requiring a large number of transformation to address this issue we introduce an illumination independent mapping approach that us white balancing to assist in reducing the number of required transformation we show that this approach achieves state of the art result on a range of consumer camera and image of arbitrary scene and illumination 
this paper present a photometric stereo method that is purely pixelwise and handle general isotropic surface in a stable manner following the recently proposed sum of lobe representation of the isotropic reflectance function we constructed a constrained bivariate regression problem where the regression function is approximated by smooth bivariate bernstein polynomial the unknown normal vector wa separated from the unknown reflectance function by considering the inverse representation of the image formation process and then we could accurately compute the unknown surface normal by solving a simple and efficient quadratic programming problem extensive evaluation that showed the state of the art performance using both synthetic and real world image were performed 
we present a simple vector quantizer that combine low distortion with fast search and apply it to approximate nearest neighbor ann search in high dimensional space leveraging the very same data structure that is used to provide non exhaustive search i e inverted list or a multi index the idea is to locally optimize an individual product quantizer pq per cell and use it to encode residual local optimization is over rotation and space decomposition interestingly we apply a parametric solution that assumes a normal distribution and is extremely fast to train with a reasonable space and time overhead that is constant in the data size we set a new state of the art on several public datasets including a billion scale one 
in this paper we tackle the problem of estimating the depth of a scene from a single image this is a challenging task since a single image on it own doe not provide any depth cue to address this we exploit the availability of a pool of image for which the depth is known more specifically we formulate monocular depth estimation a a discrete continuous optimization problem where the continuous variable encode the depth of the superpixels in the input image and the discrete one represent relationship between neighboring superpixels the solution to this discrete continuous optimization problem is then obtained by performing inference in a graphical model using particle belief propagation the unary potential in this graphical model are computed by making use of the image with known depth we demonstrate the effectiveness of our model in both the indoor and outdoor scenario our experimental evaluation show that our depth estimate are more accurate than existing method on standard datasets 
convolutional neural network cnns have been established a a powerful class of model for image recognition problem encouraged by these result we provide an extensive empirical evaluation of cnns on large scale video classification using a new dataset of million youtube video belonging to class we study multiple approach for extending the connectivity of a cnn in time domain to take advantage of local spatio temporal information and suggest a multiresolution foveated architecture a a promising way of speeding up the training our best spatio temporal network display significant performance improvement compared to strong feature based baseline to but only a surprisingly modest improvement compared to single frame model to we further study the generalization performance of our best model by retraining the top layer on the ucf action recognition dataset and observe significant performance improvement compared to the ucf baseline model up from 
we consider the problem of tracking multiple interacting object in d using rgbd input and by considering a hypothesize and test approach due to their interaction object to be tracked are expected to occlude each other in the field of view of the camera observing them a naive approach would be to employ a set of independent tracker sit and to assign one tracker to each object this approach scale well with the number of object but fails a occlusion become stronger due to their disjoint consideration the solution representing the current state of the art employ a single joint tracker jt that account for all object simultaneously this directly resolve ambiguity due to occlusion but ha a computational complexity that grows geometrically with the number of tracked object we propose a middle ground namely an ensemble of collaborative tracker ect that combine best trait from both world to deliver a practical and accurate solution to the multi object d tracking problem we present quantitative and qualitative experiment with several synthetic and real world sequence of diverse complexity experiment demonstrate that ect manages to track far more complex scene than jt at a computational time that is only slightly larger than that of sit 
given a static scene a human can trivially enumerate the myriad of thing that can happen next and characterize the relative likelihood of each in the process we make use of enormous amount of commonsense knowledge about how the world work in this paper we investigate learning this commonsense knowledge from data to overcome a lack of densely annotated spatiotemporal data we learn from sequence of abstract image gathered using crowd sourcing the abstract scene provide both object location and attribute information we demonstrate qualitatively and quantitatively that our model produce plausible scene prediction on both the abstract image a well a natural image taken from the internet 
local video feature provide state of the art performance for action recognition while the accuracy of action recognition ha been continuously improved over the recent year the low speed of feature extraction and subsequent recognition prevents current method from scaling up to real size problem we address this issue and first develop highly efficient video feature using motion information in video compression we next explore feature encoding by fisher vector and demonstrate accurate action recognition using fast linear classifier our method improves the speed of video feature extraction feature encoding and action classification by two order of magnitude at the cost of minor reduction in recognition accuracy we validate our approach and compare it to the state of the art on four recent action recognition datasets 
most of the state of the art approach to human activity recognition in video need an intensive training stage and assume that all of the training example are labeled and available beforehand but these assumption are unrealistic for many application where we have to deal with streaming video in these video a new activity are seen they can be leveraged upon to improve the current activity recognition model in this work we develop an incremental activity learning framework that is able to continuously update the activity model and learn new one a more video are seen our proposed approach leverage upon state of the art machine learning tool most notably active learning system it doe not require tedious manual labeling of every incoming example of each activity class we perform rigorous experiment on challenging human activity datasets which demonstrate that the incremental activity modeling framework can achieve performance very close to the case when all example are available a priori 
real world video of human activity exhibit temporal structure at various scale long video are typically composed out of multiple action instance where each instance is itself composed of sub action with variable duration and ordering temporal grammar can presumably model such hierarchical structure but are computationally difficult to apply for long video stream we describe simple grammar that capture hierarchical temporal structure while admitting inference with a finite state machine this make parsing linear time constant storage and naturally online we train grammar parameter using a latent structural svm where latent subactions are learned automatically we illustrate the effectiveness of our approach over common baseline on a new half million frame dataset of continuous youtube video 
popular figure ground segmentation algorithm generate a pool of boundary aligned segment proposal that can be used in subsequent object recognition engine these algorithm can recover most image object with high accuracy but are usually computationally intensive since many graph cut are computed with different enumeration of segment seed in this paper we propose an algorithm rigor for efficiently generating a pool of overlapping segment proposal in image by precomputing a graph which can be used for parametric min cut over different seed we speed up the generation of the segment pool in addition we have made design choice that avoid extensive computation without losing performance in particular we demonstrate that the segmentation performance of our algorithm is slightly better than the state of the art on the pascal voc dataset while being an order of magnitude faster 
recently unsupervised image segmentation ha become increasingly popular starting from a superpixel segmentation an edge weighted region adjacency graph is constructed amongst all segmentation of the graph the one which best conforms to the given image evidence a measured by the sum of cut edge weight is chosen since this problem is np hard we propose a new approximate solver based on the move making paradigm first the graph is recursively partitioned into small region cut phase then for any two adjacent region we consider alternative cut of these two region defining possible move glue cut phase for planar problem the optimal move can be found whereas for non planar problem efficient approximation exist we evaluate our algorithm on published and new benchmark datasets which we make available here the proposed algorithm find segmentation that a measured by a loss function are a close to the ground truth a the global optimum found by exact solver it doe so significantly faster then existing approximate method which is important for large scale problem 
a probabilistic model allows u to reason about the world and make statistically optimal decision using bayesian decision theory however in practice the intractability of the decision problem force u to adopt simplistic loss function such a the loss or hamming loss and a result we make poor decision through map estimate or through low order marginal statistic in this work we investigate optimal decision making for more realistic loss function specifically we consider the popular intersection over union iou score used in image segmentation benchmark and show that it result in a hard combinatorial decision problem to make this problem tractable we propose a statistical approximation to the objective function a well a an approximate algorithm based on parametric linear programming we apply the algorithm on three benchmark datasets and obtain improved intersection over union score compared to maximum posterior marginal decision our work point out the difficulty of using realistic loss function with probabilistic computer vision model 
we describe an information driven active selection approach to determine which detector to deploy at which location in which frame of a video to minimize semantic class label uncertainty at every pixel with the smallest computational cost that ensures a given uncertainty bound we show minimal performance reduction compared to a paragon algorithm running all detector at all location in all frame at a small fraction of the computational cost our method can handle uncertainty in the labeling mechanism so it can handle both oracle manual annotation or noisy detector automated annotation 
we propose a probabilistic method for parsing a temporal sequence such a a complex activity defined a composition of sub activity action the temporal structure of the high level activity is represented by a string length limited stochastic context free grammar given the grammar a bayes network which we term sequential interval network sin is generated where the variable node correspond to the start and end time of component action the network integrates information about the duration of each primitive action visual detection result for each primitive action and the activity s temporal structure at any moment in time during the activity message passing is used to perform exact inference yielding the posterior probability of the start and end time for each different activity action we provide demonstration of this framework being applied to vision task such a action prediction classification of the high level activity or temporal segmentation of a test sequence the method is also applicable in human robot interaction domain where continual prediction of human action is needed 
the notion of creativity a opposed to related concept such a beauty or interestingness ha not been studied from the perspective of automatic analysis of multimedia content meanwhile short online video shared on social medium platform or micro video have arisen a a new medium for creative expression in this paper we study creative micro video in an effort to understand the feature that make a video creative and to address the problem of automatic detection of creative content defining creative video a those that are novel and have aesthetic value we conduct a crowdsourcing experiment to create a dataset of over micro video labelled a creative and non creative we propose a set of computational feature that we map to the component of our definition of creativity and conduct an analysis to determine which of these feature correlate most with creative video finally we evaluate a supervised approach to automatically detect creative video with promising result showing that it is necessary to model both aesthetic value and novelty to achieve optimal classification accuracy 
we propose a real time robust to outlier and accurate solution to the perspective n point pnp problem the main advantage of our solution are twofold first it integrates the outlier rejection within the pose estimation pipeline with a negligible computational overhead and second it scalability to arbitrarily large number of correspondence given a set of d to d match we formulate pose estimation problem a a low rank homogeneous system where the solution lie on it d null space outlier correspondence are those row of the linear system which perturb the null space and are progressively detected by projecting them on an iteratively estimated solution of the null space since our outlier removal process is based on an algebraic criterion which doe not require computing the full pose and reprojecting back all d point on the image plane at each step we achieve speed gain of more than time compared to ransac strategy an extensive experimental evaluation will show that our solution yield accurate result in situation with up to of outlier and can process more than correspondence in le than m 
a common thread that tie together many prior work in scene understanding is their focus on the aspect directly present in a scene such a it categorical classification or the set of object in this work we propose to look beyond the visible element of a scene we demonstrate that a scene is not just a collection of object and their configuration or the label assigned to it pixel it is so much more from a simple observation of a scene we can tell a lot about the environment surrounding the scene such a the potential establishment near it the potential crime rate in the area or even the economic climate here we explore several of these aspect from both the human perception and computer vision perspective specifically we show that it is possible to predict the distance of surrounding establishment such a mcdonald s or hospital even by using scene located far from them we go a step further to show that both human and computer perform well at navigating the environment based only on visual cue from scene lastly we show that it is possible to predict the crime rate in an area simply by looking at a scene without any real time criminal activity simply put here we illustrate that it is possible to look beyond the visible scene 
we examine the problem of retrieving high resolution texture of object observed in multiple video under small object deformation in the monocular case the data redundancy necessary to reconstruct a high resolution image stem from temporal accumulation this ha been vastly explored and is known a image super resolution on the other hand a handful of method have considered the texture of a static d object observed from several camera where the data redundancy is obtained through the different viewpoint we introduce a unified framework to leverage both possibility for the estimation of an object s high resolution texture this framework uniformly deal with any related geometric variability introduced by the acquisition chain or by the evolution over time to this goal we use d warp for all viewpoint and all temporal frame and a linear image formation model from texture to image space despite it simplicity the method is able to successfully handle different view over space and time a shown experimentally it demonstrates the interest of temporal information to improve the texture quality additionally we also show that our method outperforms state of the art multi view super resolution method existing for the static case 
when do the visual ray associated with triplet of point correspondence converge that is intersect in a common point classical model of trinocular geometry based on the fundamental matrix and trifocal tensor associated with the corresponding camera only provide partial answer to this fundamental question in large part because of underlying but seldom explicit general configuration assumption this paper us elementary tool from projective line geometry to provide necessary and sufficient geometric and analytical condition for convergence in term of transversals to triplet of visual ray without any such assumption in turn this yield a novel and simple minimal parameterization of trinocular geometry for camera with non collinear or collinear pinhole 
a key problem often encountered by many learning algorithm in computer vision dealing with high dimensional data is the so called curse of dimensionality which arises when the available training sample are le than the input feature space dimensionality to remedy this problem we propose a joint dimensionality reduction and classification framework by formulating an optimization problem within the maximum margin class separation task the proposed optimization problem is solved using alternative optimization where we jointly compute the low dimensional maximum margin projection and the separating hyperplanes in the projection subspace moreover in order to reduce the computational cost of the developed optimization algorithm we incorporate orthogonality constraint on the derived projection base and show that the resulting combined model is an alternation between identifying the optimal separating hyperplanes and performing a linear discriminant analysis on the support vector experiment on face facial expression and object recognition validate the effectiveness of the proposed method against state of the art dimensionality reduction algorithm 
we describe a new approach to transfer knowledge across view for action recognition by using example from a large collection of unlabelled mocap data we achieve this by directly matching purely motion based feature from video to mocap our approach recovers d pose sequence without performing any body part tracking we use these match to generate multiple motion projection and thus add view invariance to our action recognition model we also introduce a closed form solution for approximate non linear circulant temporal encoding ncte which allows u to efficiently perform the match in the frequency domain we test our approach on the challenging unsupervised modality of the ixmas dataset and use publicly available motion capture data for matching without any additional annotation effort we are able to significantly outperform the current state of the art 
recognition is graduating from lab to real world application while it is encouraging to see it potential being tapped it brings forth a fundamental challenge to the vision researcher scalability how can we learn a model for any concept that exhaustively cover all it appearance variation while requiring minimal or no human supervision for compiling the vocabulary of visual variance gathering the training image and annotation and learning the model in this paper we introduce a fully automated approach for learning extensive model for a wide range of variation e g action interaction attribute and beyond within any concept our approach leverage vast resource of online book to discover the vocabulary of variance and intertwines the data collection and modeling step to alleviate the need for explicit human supervision in training the model our approach organizes the visual knowledge about a concept in a convenient and useful way enabling a variety of application across vision and nlp our online system ha been queried by user to learn model for several interesting concept including breakfast gandhi beautiful etc to date our system ha model available for over variation within concept and ha annotated more than million image with bounding box 
we propose a technique to use the structural information extracted from a set of d model of an object class to improve novel view synthesis for image showing unknown instance of this class these novel view can be used to amplify training image collection that typically contain only a low number of view or lack certain class of view entirely e g top view we extract the correlation of position normal reflectance and appearance from computer generated image of a few exemplar and use this information to infer new appearance for new instance we show that our approach can improve performance of state of the art detector using real world training data additional application include guided version of inpainting d to d conversion superresolution and non local smoothing 
this paper introduces a regularization method to explicitly control the rank of a learned symmetric positive semidefinite distance matrix in distance metric learning to this end we propose to incorporate in the objective function a linear regularization term that minimizes the k smallest eigenvalue of the distance matrix it is equivalent to minimizing the trace of the product of the distance matrix with a matrix in the convex hull of rank k projection matrix called a fantope based on this new regularization method we derive an optimization scheme to efficiently learn the distance matrix we demonstrate the effectiveness of the method on synthetic and challenging real datasets of face verification and image classification with relative attribute on which our method outperforms state of the art metric learning algorithm 
deep convolutional neural network have recently achieved state of the art performance on a number of image recognition benchmark including the imagenet large scale visual recognition challenge ilsvrc the winning model on the localization sub task wa a network that predicts a single bounding box and a confidence score for each object category in the image such a model capture the whole image context around the object but cannot handle multiple instance of the same object in the image without naively replicating the number of output for each instance in this work we propose a saliency inspired neural network model for detection which predicts a set of class agnostic bounding box along with a single score for each box corresponding to it likelihood of containing any object of interest the model naturally handle a variable number of instance for each class and allows for cross class generalization at the highest level of the network we are able to obtain competitive recognition performance on voc and ilsvrc while using only the top few predicted location in each image and a small number of neural network evaluation 
scan line optimization via cost accumulation ha become very popular for stereo estimation in computer vision application and is often combined with a semi global cost integration strategy known a sgm this paper introduces this combination a a general and effective optimization technique it is the first time that this concept is applied to d medical image registration the presented algorithm sgm d employ a coarse to fine strategy and reduces the search space dimension for consecutive pyramid level by a fixed linear rate this allows it to handle large displacement to an extent that is required for clinical application in high dimensional data sgm d is evaluated in context of pulmonary motion analysis on the recently extended dir lab benchmark that provides ten d computed tomography ct image data set a well a ten challenging d ct scan pair from the copdgene study archive result show that both registration error a well a run time performance are very competitive with current state of the art method 
the goal of this paper is to question the necessity of feature like sift in categorical visual recognition task a an alternative we develop a generative model for the raw intensity of image patch and show that it can support image classification performance on par with optimized sift based technique in a bag of visual word setting key ingredient of the proposed model is a compact dictionary of mini epitome learned in an unsupervised fashion on a large collection of image the use of epitome allows u to explicitly account for photometric and position variability in image appearance we show that this flexibility considerably increase the capacity of the dictionary to accurately approximate the appearance of image patch and support recognition task for image classification we develop histogram based image encoding method tailored to the epitomic representation a well a an epitomic footprint encoding which is easy to visualize and highlight the generative nature of our model we discus in detail computational aspect and develop efficient algorithm to make the model scalable to large task the proposed technique are evaluated with experiment on the challenging pascal voc image classification benchmark 
in this work we reconsider labeling problem with virtually continuous state space which are of relevance in low level computer vision in order to cope with such huge state space multi scale method have been proposed to approximately solve such labeling task although performing well in many case these method do usually not come with any guarantee on the returned solution a general and principled approach to solve labeling problem is based on the well known linear programming relaxation which appears to be prohibitive for large state space at the first glance we demonstrate that a coarse to fine exploration strategy in the label space is able to optimize the lp relaxation for non trivial problem instance with reasonable run time and moderate memory requirement 
we propose an algorithm called multi label generic cut mlgc for computing optimal solution to mrf map problem with submodular multi label multi clique potential a transformation is introduced to convert a m label k clique problem to an equivalent label mk clique problem we show that if the original multi label problem is submodular then the transformed label multi clique problem is also submodular we exploit sparseness in the feasible configuration of the transformed label problem to suggest an improvement to generic cut to solve the label problem efficiently the algorithm run in time o mk n in the worst case n is the number of pixel generalizing o k n running time of generic cut we show experimentally that mlgc is an order of magnitude faster than the current state of the art while the result of mlgc is optimal for submodular clique potential it is significantly better than the compared method even for problem with non submodular clique potential 
persistent surveillance of large geographic area from unmanned aerial vehicle allows u to learn much about the daily activity in the region of interest nearly all of the approach addressing tracking in this imagery are detection based and rely on background subtraction or frame differencing to provide detection this however make it difficult to track target once they slow down or stop which is not acceptable for persistent tracking our goal we present a multiple target tracking approach that doe not exclusively rely on background subtraction and is better able to track target through stop it accomplishes this by effectively running two tracker in parallel one based on detection from background subtraction providing target initialization and reacquisition and one based on a target state regressor providing frame to frame tracking we evaluated the proposed approach on a long sequence from a wide area aerial imagery dataset and the result show improved object detection rate and id switch rate with limited increase in false alarm compared to the competition 
in this paper we study optimization method for minimizing large scale pseudoconvex l problem in multiview geometry we present a novel algorithm for solving this class of problem based on proximal splitting method we provide a brief derivation of the proposed method along with a general convergence analysis the resulting meta algorithm requires very little effort in term of implementation and instead make use of existing advanced solver for non linear optimization preliminary experiment on a number of real image datasets indicate that the proposed method experimentally match or outperforms current state of the art solver for this class of problem 
the world is full of object with complex reflectance situated in complex illumination environment past work on full d geometry recovery however ha tried to handle this complexity by framing it into simplistic model of reflectance lambetian mirrored or diffuse plus specular or illumination one or more point light source though there ha been some recent progress in directly utilizing such complexity for recovering a single view geometry it is not clear how such single view method can be extended to reconstruct the full geometry to this end we derive a probabilistic geometry estimation method that fully exploit the rich signal embedded in complex appearance though each observation provides partial and unreliable information we show how to estimate the reflectance responsible for the diverse appearance and unite the orientation cue embedded in each observation to reconstruct the underlying geometry we demonstrate the effectiveness of our method on synthetic and real world object the result show that our method performs accurately across a wide range of real world environment and reflectance that lie between the extreme that have been the focus of past work 
we present the discriminative fern ensemble dfe classifier for efficient visual object recognition the classifier architecture is designed to optimize both classification speed and accuracy when a large training set is available speed is obtained using simple binary feature and direct indexing into a set of table and accuracy by using a large capacity model and careful discriminative optimization the proposed framework is applied to the problem of hand pose recognition in depth and infra red image using a very large training set both the accuracy and the classification time obtained are considerably superior to relevant competing method allowing one to reach accuracy target with run time order of magnitude faster than the competition we show empirically that using dfe we can significantly reduce classification time by increasing training sample size for a fixed target accuracy finally a dfe result is shown for the mnist dataset showing the method s merit extends beyond depth image 
we tackle the problem of optimizing over all possible positive definite radial kernel on riemannian manifold for classification kernel method on riemannian manifold have recently become increasingly popular in computer vision however the number of known positive definite kernel on manifold remain very limited furthermore most kernel typically depend on at least one parameter that need to be tuned for the problem at hand a poor choice of kernel or of parameter value may yield significant performance drop off here we show that positive definite radial kernel on the unit n sphere the grassmann manifold and kendall s shape manifold can be expressed in a simple form whose parameter can be automatically optimized within a support vector machine framework we demonstrate the benefit of our kernel learning algorithm on object face action and shape recognition 
this paper considers the problem of action localization where the objective is to determine when and where certain action appear we introduce a sampling strategy to produce d t sequence of bounding box called tubelets compared to state of the art alternative this drastically reduces the number of hypothesis that are likely to include the action of interest our method is inspired by a recent technique introduced in the context of image localization beyond considering this technique for the first time for video we revisit this strategy for d t sequence obtained from super voxels our sampling strategy advantageously exploit a criterion that reflects how action related motion deviate from background motion we demonstrate the interest of our approach by extensive experiment on two public datasets ucf sport and msr ii our approach significantly outperforms the state of the art on both datasets while restricting the search of action to a fraction of possible bounding box sequence 
photo sharing website have become very popular in the last few year leading to huge collection of online image in addition to image data these website collect a variety of multimodal metadata about photo including text tag caption gps coordinate camera metadata user profile etc however this metadata is not well constrained and is often noisy sparse or missing altogether in this paper we propose a framework to model these loosely organized multimodal datasets and show how to perform loosely supervised learning using a novel latent conditional random field framework we learn parameter of the lcrf automatically from a small set of validation data using information theoretic metric learning itml to learn distance function and a structural svm formulation to learn the potential function we apply our framework on four datasets of image from flickr evaluating both qualitatively and quantitatively against several baseline 
recently multi atlas segmentation ma ha achieved a great success in the medical imaging area the key assumption of ma is that multiple atlas encompass richer anatomical variability than a single atlas therefore we can label the target image more accurately by mapping the label information from the appropriate atlas image that have the most similar structure the problem of atlas selection however still remains unexplored current state of the art ma method rely on image similarity to select a set of atlas unfortunately this heuristic criterion is not necessarily related to segmentation performance and thus may undermine segmentation result to solve this simple but critical problem we propose a learning based atlas selection method to pick up the best atlas that would eventually lead to more accurate image segmentation our idea is to learn the relationship between the pairwise appearance of observed instance a pair of atlas and target image and their final labeling performance in term of dice ratio in this way we can select the best atlas according to their expected labeling accuracy it is worth noting that our atlas selection method is general enough to be integrated with existing ma method a is shown in the experiment we achieve significant improvement after we integrate our method with widely used ma method on adni and loni lpba datasets 
arguably deformable part model dpms are one of the most prominent approach for face alignment with impressive result being recently reported for both controlled lab and unconstrained setting fitting in most dpm method is typically formulated a a two step process during which discriminatively trained part template are first correlated with the image to yield a filter response for each landmark and then shape optimization is performed over these filter response this process although computationally efficient is based on fixed part template which are assumed to be independent and ha been shown to result in imperfect filter response and detection ambiguity to address this limitation in this paper we propose to jointly optimize a part based trained in the wild flexible appearance model along with a global shape model which result in a joint translational motion model for the model part via gauss newton gn optimization we show how significant computational reduction can be achieved by building a full model during training but then efficiently optimizing the proposed cost function on a sparse grid using weighted least square during fitting we coin the proposed formulation gauss newton deformable part model gn dpm finally we compare it performance against the state of the art and show that the proposed gn dpm outperforms it in some case by a large margin code for our method is available from http ibug doc ic ac uk resource 
we propose filter forest ff an efficient new discriminative approach for predicting continuous variable given a signal and it context ff can be used for general signal restoration task that can be tackled via convolutional filtering where it attempt to learn the optimal filtering kernel to be applied to each data point the model can learn both the size of the kernel and it value conditioned on the observation and it spatial or temporal context we show that ff compare favorably to both markov random field based and recently proposed regression forest based approach for labeling problem in term of efficiency and accuracy in particular we demonstrate how ff can be used to learn optimal denoising filter for natural image a well a for other task such a depth image refinement and d signal magnitude estimation numerous experiment and quantitative comparison show that ffs achieve accuracy at par or superior to recent state of the art technique while being several order of magnitude faster 
our goal is to obtain a noise free high resolution hr image from an observed noisy low resolution lr image the conventional approach of preprocessing the image with a denoising algorithm followed by applying a super resolution sr algorithm ha an important limitation along with noise some high frequency content of the image particularly textural detail is invariably lost during the denoising step this denoising loss restricts the performance of the subsequent sr step wherein the challenge is to synthesize such textural detail in this paper we show that high frequency content in the noisy image which is ordinarily removed by denoising algorithm can be effectively used to obtain the missing textural detail in the hr domain to do so we first obtain hr version of both the noisy and the denoised image using a patch similarity based sr algorithm we then show that by taking a convex combination of orientation and frequency selective band of the noisy and the denoised hr image we can obtain a desired hr image where i some of the textural signal lost in the denoising step is effectively recovered in the hr domain and ii additional texture can be easily synthesized by appropriately constraining the parameter of the convex combination we show that this part recovery and part synthesis of texture through our algorithm yield hr image that are visually more pleasing than those obtained using the conventional processing pipeline furthermore our result show a consistent improvement in numerical metric further corroborating the ability of our algorithm to recover lost signal 
our goal is to learn a compact discriminative vector representation of a face track suitable for the face recognition task of verification and classification to this end we propose a novel face track descriptor based on the fisher vector representation and demonstrate that it ha a number of favourable property first the descriptor is suitable for track of both frontal and profile face and is insensitive to their pose second the descriptor is compact due to discriminative dimensionality reduction and it can be further compressed using binarization third the descriptor can be computed quickly using hard quantization and it compact size and fast computation render it very suitable for large scale visual repository finally the descriptor demonstrates good generalization when trained on one dataset and tested on another reflecting it tolerance to the dataset bias in the experiment we show that the descriptor exceeds the state of the art on both face verification task youtube face without outside training data and inria buffy benchmark and face classification task using the oxford buffy dataset 
in this paper we introduce a new distance for robustly matching vector of d rotation a special representation of d rotation which we coin full angle quaternion faq allows u to express this distance a euclidean we apply the distance to the problem of d shape recognition from point cloud and d object tracking in color video for the former we introduce a hashing scheme for scale and translation which outperforms the previous state of the art approach on a public dataset for the latter we incorporate online subspace learning with the proposed faq representation to highlight the benefit of the new representation 
we present a method for generating object segmentation proposal from group of superpixels the goal is to propose accurate segmentation for all object of an image the proposed object hypothesis can be used a input to object detection system and thereby improve efficiency by replacing exhaustive search the segmentation are generated in a class independent manner and therefore the computational cost of the approach is independent of the number of object class our approach combine both global and local search in the space of set of superpixels the local search is implemented by greedily merging adjacent pair of superpixels to build a bottom up segmentation hierarchy the region from such a hierarchy directly provide a part of our region proposal the global search provides the other part by performing a set of graph cut segmentation on a superpixel graph obtained from an intermediate level of the hierarchy the parameter of the graph cut problem are learnt in such a manner that they provide complementary set of region experiment with pascal voc image show that we reach state of the art with greatly reduced computational cost 
we propose a novel solution to the generalized camera pose problem which includes the internal scale of the generalized camera a an unknown parameter this further generalization of the well known absolute camera pose problem ha application in multi frame loop closure while a well calibrated camera rig ha a fixed and known scale camera trajectory produced by monocular motion estimation necessarily lack a scale estimate thus when performing loop closure in monocular visual odometry or registering separate structure from motion reconstruction we must estimate a seven degree of freedom similarity transform from corresponding observation existing approach solve this problem in specialized configuration by aligning d triangulated point or individual camera pose estimate our approach handle general configuration of ray and point and directly estimate the full similarity transformation from the d d correspondence four correspondence are needed in the minimal case which ha eight possible solution the minimal solver can be used in a hypothesize and test architecture for robust transformation estimation our solver also produce a least square estimate in the overdetermined case the approach is evaluated experimentally on synthetic and real datasets and is shown to produce higher accuracy solution to multi frame loop closure than existing approach 
face detection and facial point localization are interconnected task recently it ha been shown that solving these two task jointly with a mixture of tree of part mtp lead to state of the art result however mtp a most other method for facial point localization proposed so far requires a complete annotation of the training data at facial point level this is used to predefine the structure of the tree and to place the part correctly in this work we extend the mixture from tree to more general loopy graph in this way we can learn in a weakly supervised manner using only the face location and orientation a powerful deformable detector that implicitly aligns it part to the detected face in the image by attaching some reference point to the correct part of our detector we can then localize the facial point in term of detection our method clearly outperforms the state of the art even if competing with method that use facial point annotation during training additionally without any facial point annotation at the level of individual training image our method can localize facial point with an accuracy similar to fully supervised approach 
in this paper we would like to evaluate online learning algorithm for large scale visual recognition using state of the art feature which are preselected and held fixed today combination of high dimensional feature and linear classifier are widely used for large scale visual recognition numerous so called mid level feature have been developed and mutually compared on an experimental basis although various learning method for linear classification have also been proposed in the machine learning and natural language processing literature they have rarely been evaluated for visual recognition therefore we give guideline via investigation of state of the art online learning method of linear classifier many method have been evaluated using toy data and natural language processing problem such a document classification consequently we gave those method a unified interpretation from the viewpoint of visual recognition result of controlled comparison indicate three guideline that might change the pipeline for visual recognition 
the quantification of similarity between image segmentation is a complex yet important task the ideal similarity measure should be unbiased to segmentation of different volume and complexity and be able to quantify and visualise segmentation bias similarity measure based on overlap e g dice score or surface distance e g hausdorff distance clearly do not satisfy all of these property to address this problem we introduce patch based evaluation of image segmentation pei a general method to ass segmentation quality our method is based on finding patch correspondence and the associated patch displacement which allow the estimation of segmentation bias we quantify both the agreement of the segmentation boundary and the conservation of the segmentation shape we further ass the segmentation complexity within patch to weight the contribution of local segmentation similarity to the global score we evaluate pei on both synthetic data and two medical imaging datasets on synthetic segmentation of different shape we provide evidence that pei in comparison to the dice score produce more comparable score ha increased sensitivity and estimate segmentation bias accurately on cardiac magnetic resonance mr image we demonstrate that pei can evaluate the performance of a segmentation method independent of the size or complexity of the segmentation under consideration on brain mr image we compare five different automatic hippocampus segmentation technique using pei finally we visualise the segmentation bias on a selection of the case 
we propose a method for knowledge transfer between semantically related class in imagenet by transferring knowledge from the image that have bounding box annotation to the others our method is capable of automatically populating imagenet with many more bounding box the underlying assumption that object from semantically related class look alike is formalized in our novel associative embedding ae representation ae recovers the latent low dimensional space of appearance variation among image window the dimension of ae space tend to correspond to aspect of window appearance e g side view close up background we model the overlap of a window with an object using gaussian process gp regression which spread annotation smoothly through ae space the probabilistic nature of gp allows our method to perform self assessment i e assigning a quality estimate to it own output it enables trading off the amount of returned annotation for their quality a large scale experiment on class and million image demonstrates that our method outperforms state of the art method and baseline for object localization using self assessment we can automatically return bounding box annotation for of all image with high localization accuracy i e average overlap with ground truth 
we propose a joint foreground background mixture model fbm that simultaneously performs background estimation and motion segmentation in complex dynamic scene our fbm consist of a set of location specific dynamic texture dt component for modeling local background motion and set of global dt component for modeling consistent foreground motion we derive an em algorithm for estimating the parameter of the fbm we also apply spatial constraint to the fbm using an markov random field grid and derive a corresponding variational approximation for inference unlike existing approach to background subtraction our fbm doe not require a manually selected threshold or a separate training video unlike existing motion segmentation technique our fbm can segment foreground motion over complex background with mixed motion and detect stopped object since most dynamic scene datasets only contain video with a single foreground object over a simple background we develop a new challenging dataset with multiple foreground object over complex dynamic background in experiment we show that jointly modeling the background and foreground segment with fbm yield significant improvement in accuracy on both background estimation and motion segmentation compared to state of the art method 
we propose a simple yet effective detector for pedestrian detection the basic idea is to incorporate common sense and everyday knowledge into the design of simple and computationally efficient feature a pedestrian usually appear up right in image or video data the problem of pedestrian detection is considerably simpler than general purpose people detection we therefore employ a statistical model of the up right human body where the head the upper body and the lower body are treated a three distinct component our main contribution is to systematically design a pool of rectangular template that are tailored to this shape model a we incorporate different kind of low level measurement the resulting multi modal multi channel haar like feature represent characteristic difference between part of the human body yet are robust against variation in clothing or environmental setting our approach avoids exhaustive search over all possible configuration of rectangle feature and neither relies on random sampling it thus mark a middle ground among recently published technique and yield efficient low dimensional yet highly discriminative feature experimental result on the inria and caltech pedestrian datasets show that our detector reach state of the art performance at low computational cost and that our feature are robust against occlusion 
existing method to learn visual attribute are prone to learning the wrong thing namely property that are correlated with the attribute of interest among training sample yet many proposed application of attribute rely on being able to learn the correct semantic concept corresponding to each attribute we propose to resolve such confusion by jointly learning decorrelated discriminative attribute model leveraging side information about semantic relatedness we develop a multi task learning approach that us structured sparsity to encourage feature competition among unrelated attribute and feature sharing among related attribute on three challenging datasets we show that accounting for structure in the visual attribute space is key to learning attribute model that preserve semantics yielding improved generalizability that help in the recognition and discovery of unseen object category 
we propose a kernel based framework for computing component from a set of surface normal this framework allows u to easily demonstrate that component analysis can be performed directly upon normal we link previously proposed mapping function the azimuthal equidistant projection aep and principal geodesic analysis pga to our kernel based framework we also propose a new mapping function based upon the cosine distance between normal we demonstrate the robustness of our proposed kernel when trained with noisy training set we also compare our kernel within an existing shape from shading sfs algorithm our spherical representation of normal when combined with the robust property of cosine kernel produce a very robust subspace analysis technique in particular our result within sfs show a substantial qualitative and quantitative improvement over existing technique 
we propose a data driven approach to facial landmark localization that model the correlation between each landmark and it surrounding appearance feature at runtime each feature cast a weighted vote to predict landmark location where the weight is precomputed to take into account the feature s discriminative power the feature voting based landmark detection is more robust than previous local appearance based detector we combine it with nonparametric shape regularization to build a novel facial landmark localization pipeline that is robust to scale in plane rotation occlusion expression and most importantly extreme head pose we achieve state of the art performance on two especially challenging in the wild datasets populated by face with extreme head pose and expression 
in this paper we propose a new methodology for segmenting non rigid visual object where the search procedure is onducted directly on a sparse low dimensional manifold guided by the classification result computed from a deep belief network our main contribution is the fact that we do not rely on the typical sub division of segmentation task into rigid detection and non rigid delineation instead the non rigid segmentation is performed directly where point in the sparse low dimensional can be mapped to an explicit contour representation in image space our proposal show significantly smaller search and training complexity given that the dimensionality of the manifold is much smaller than the dimensionality of the search space for rigid detection and non rigid delineation aforementioned and that we no longer require a two stage segmentation process we focus on the problem of left ventricle endocardial segmentation from ultrasound image and lip segmentation from frontal facial image using the extended cohn kanade ck database our experiment show that the use of sparse low dimensional manifold reduces the search and training complexity of current segmentation approach without a significant impact on the segmentation accuracy shown by state of the art approach 
we propose an approach for segmenting the individual building in typical skyline image our approach is based on a markov random field mrf formulation that exploit the fact that such image contain overlapping object of similar shape exhibiting a tiered structure our contribution are the following a dataset of high resolution skyline image from twelve different city with over individually labeled building that allows u to quantitatively evaluate the performance of various segmentation method an analysis of low level feature that are useful for segmentation of building and a shape constrained mrf formulation that enforces shape prior over the region for simple shape such a rectangle our formulation is significantly faster to optimize than a standard mrf approach while also being more accurate we experimentally evaluate various mrf formulation and demonstrate the effectiveness of our approach in segmenting skyline image 
this paper introduces a novel image representation capturing feature dependency through the mining of meaningful combination of visual feature this representation lead to a compact and discriminative encoding of image that can be used for image classification object detection or object recognition the method relies on i multiple random projection of the input space followed by local binarization of projected histogram encoded a set of item and ii the representation of image a histogram of pattern set hop the approach is validated on four publicly available datasets daimler pedestrian oxford flower kth texture and pascal voc allowing comparison with many recent approach the proposed image representation reach state of the art performance on each one of these datasets 
many computer vision algorithm employ subspace model to represent data many of these approach benefit from the ability to create an average or prototype for a set of subspace the most popular method in these situation is the karcher mean also known a the riemannian center of mass the prevalence of the karcher mean may lead some to assume that it provides the best average in all scenario however other subspace average that appear le frequently in the literature may be more appropriate for certain task the extrinsic manifold mean the l median and the flag mean are alternative average that can be substituted directly for the karcher mean in many application this paper evaluates the characteristic and performance of these four average on synthetic and real world data while the karcher mean generalizes the euclidean mean to the grassman manifold we show that the extrinsic manifold mean the l median and the flag mean behave more like median and are therefore more robust to the presence of outlier among the subspace being averaged we also show that while the karcher mean and l median are computed using iterative algorithm the extrinsic manifold mean and flag mean can be found analytically and are thus order of magnitude faster in practice finally we show that the flag mean is a generalization of the extrinsic manifold mean that permit subspace with different number of dimension to be averaged the result is a cookbook that map algorithm constraint and data property to the most appropriate subspace mean for a given application 
the paper proposes an advanced driver assistance system that correlate the driver s head pose to road hazard by analyzing both simultaneously in particular we aim at the prevention of rear end crash due to driver fatigue or distraction we contribute by three novel idea asymmetric appearance modeling d to d pose estimation enhanced by the introduced fermat point transform and adaptation of global haar ghaar classifier for vehicle detection under challenging lighting condition the system defines the driver s direction of attention in degree of freedom yawning and head nodding detection a well a vehicle detection and distance estimation having both road and driver s behaviour information and implementing a fuzzy fusion system we develop an integrated framework to cover all of the above subject we provide real time performance analysis for real world driving scenario 
standard geometric model fitting method take a an input a fixed set of feature pair greedily matched based only on their appearance inadvertently many valid match are discarded due to repetitive texture or large baseline between view point to address this problem matching should consider both feature appearance and geometric fitting error we jointly solve feature matching and multi model fitting problem by optimizing one energy the formulation is based on our generalization of the assignment problem and it efficient min cost max flow solver our approach significantly increase the number of correctly matched feature improves the accuracy of fitted model and is robust to larger baseline 
in this paper we study the problem of estimating relative pose between two camera in the presence of radial distortion specifically we consider minimal problem where one of the camera ha no or known radial distortion there are three useful case for this setup with a single unknown distortion i fundamental matrix estimation where the two camera are uncalibrated ii essential matrix estimation for a partially calibrated camera pair iii essential matrix estimation for one calibrated camera and one camera with unknown focal length we study the parameterization of these three problem and derive fast polynomial solver based on gro bner basis method we demonstrate the numerical stability of the solver on synthetic data the minimal solver have also been applied to real imagery with convincing result 
fisher kernel and deep learning were two development with significant impact on large scale object categorization in the last year both approach were shown to achieve state of the art result on large scale object categorization datasets such a imagenet conceptually however they are perceived a very different and it is not uncommon for heated debate to spring up when advocate of both paradigm meet at conference or workshop in this work we emphasize the similarity between both architecture rather than their difference and we argue that such a unified view allows u to transfer idea from one domain to the other a a concrete example we introduce a method for learning a support vector machine classifier with fisher kernel at the same time a a task specific data representation we reinterpret the setting a a multi layer feed forward network it final layer is the classifier parameterized by a weight vector and the two previous layer compute fisher vector parameterized by the coefficient of a gaussian mixture model we introduce a gradient descent based learning algorithm that in contrast to other feature learning technique is not just derived from intuition or biological analogy but ha a theoretical justification in the framework of statistical learning theory our experiment show that the new training procedure lead to significant improvement in classification accuracy while preserving the modularity and geometric interpretability of a support vector machine setup 
we consider the design of a single vector representation for an image that embeds and aggregate a set of local patch descriptor such a sift more specifically we aim to construct a dense representation like the fisher vector or vlad though of small or intermediate size we make two contribution both aimed at regularizing the individual contribution of the local descriptor in the final representation the first is a novel embedding method that avoids the dependency on absolute distance by encoding direction the second contribution is a democratization strategy that further limit the interaction of unrelated descriptor in the aggregation stage these method are complementary and give a substantial performance boost over the state of the art in image search with short or mid size vector a demonstrated by our experiment on standard public image retrieval benchmark 
current system for scene understanding typically represent object a d or d bounding box while these representation have proven robust in a variety of application they provide only coarse approximation to the true d and d extent of object a a result object object interaction such a occlusion or ground plane contact can be represented only superficially in this paper we approach the problem of scene understanding from the perspective of d shape modeling and design a d scene representation that reason jointly about the d shape of multiple object this representation allows to express d geometry and occlusion on the fine detail level of individual vertex of d wireframe model and make it possible to treat dependency between object such a occlusion reasoning in a deterministic way in our experiment we demonstrate the benefit of jointly estimating the d shape of multiple object in a scene over working with coarse box on the recently proposed kitti dataset of realistic street scene 
a method for identifying shape feature of local nature on the shape s boundary in a way that is facilitated by the presence of noise is presented the boundary is seen a a real function a study of a certain distance function reveals almost counter intuitively that vertex can be defined and localized better in the presence of noise thus the concept of noising a opposed to smoothing is conceived and presented the method work on both smooth and noisy shape the presence of noise having an effect of improving on the result of the smoothed version experiment with noise and a comparison to state of the art validate the method 
recently the emergence of kinect system ha demonstrated the benefit of predicting an intermediate body part labeling for d human pose estimation in conjunction with rgb d imagery the availability of depth information play a critical role so an important question is whether a similar representation can be developed with sufficient robustness in order to estimate d pose from rgb image this paper provides evidence for a positive answer by leveraging a d human body part labeling in image b second order label sensitive pooling over dynamically computed region resulting from a hierarchical decomposition of the body and c iterative structured output modeling to contextualize the process based on d pose estimate for robustness and generalization we take advantage of a recent large scale d human motion capture dataset human m that also ha human body part labeling annotation available with image we provide extensive experimental study where alternative intermediate representation are compared and report a substantial error reduction over competitive discriminative baseline that regress d human pose against global hog feature 
many state of the art image restoration approach do not scale well to larger image such a megapixel image common in the consumer segment computationally expensive optimization is often the culprit while efficient alternative exist they have not reached the same level of image quality the goal of this paper is to develop an effective approach to image restoration that offer both computational efficiency and high restoration quality to that end we propose shrinkage field a random field based architecture that combine the image model and the optimization algorithm in a single unit the underlying shrinkage operation bear connection to wavelet approach but is used here in a random field context computational efficiency is achieved by construction through the use of convolution and dft a the core component high restoration quality is attained through loss based training of all model parameter and the use of a cascade architecture unlike heavily engineered solution our learning approach can be adapted easily to different trade offs between efficiency and image quality we demonstrate state of the art restoration result with high level of computational efficiency and significant speedup potential through inherent parallelism 
object and structure within man made environment typically exhibit a high degree of organization in the form of orthogonal and parallel plane traditional approach to scene representation exploit this phenomenon via the somewhat restrictive assumption that every plane is perpendicular to one of the ax of a single coordinate system known a the manhattan world model this assumption is widely used in computer vision and robotics the complexity of many real world scene however necessitates a more flexible model we propose a novel probabilistic model that describes the world a a mixture of manhattan frame each frame defines a different orthogonal coordinate system this result in a more expressive model that still exploit the orthogonality constraint we propose an adaptive markov chain monte carlo sampling algorithm with metropolis hastings split merge move that utilizes the geometry of the unit sphere we demonstrate the versatility of our mixture of manhattan frame model by describing complex scene using depth image of indoor scene a well a aerial lidar measurement of an urban center additionally we show that the model lends itself to focal length calibration of depth camera and to plane segmentation 
intrinsic characterization of scene is often the best way to overcome the illumination variability artifact that complicate most computer vision problem from d reconstruction to object or material recognition this paper examines the deficiency of existing intrinsic image model to accurately account for the effect of illuminant color and sensor characteristic in the estimation of intrinsic image and present a generic framework which incorporates insight from color constancy research to the intrinsic image decomposition problem the proposed mathematical formulation includes information about the color of the illuminant and the effect of the camera sensor both of which modify the observed color of the reflectance of the object in the scene during the acquisition process by modeling these effect we get a truly intrinsic reflectance image which we call absolute reflectance which is invariant to change of illuminant or camera sensor this model allows u to represent a wide range of intrinsic image decomposition depending on the specific assumption on the geometric property of the scene configuration and the spectral property of the light source and the acquisition system thus unifying previous model in a single general framework we demonstrate that even partial information about sensor improves significantly the estimated reflectance image thus making our method applicable for a wide range of sensor we validate our general intrinsic image framework experimentally with both synthetic data and natural image 
the state of the art in image segmentation build hierarchical segmentation structure based on analyzing local feature cue in spectral setting due to their impressive performance such segmentation approach have become building block in many computer vision application nevertheless the main bottleneck are still the computationally demanding process of local feature processing and spectral analysis in this paper we demonstrate that based on a discrete continuous optimization of oriented gradient signal we are able to provide segmentation performance competitive to state of the art on bsds even without any spectral analysis while reducing computation time by a factor of and memory demand by a factor of 
use of higher order clique potential for modeling inference problem ha exploded in last few year the algorithmic scheme proposed so far do not scale well with increasing clique size thus limiting their use to clique of size at most in practice generic cut gc of arora et al show that when potential are submodular inference problem can be solved optimally in polynomial time for fixed size clique in this paper we report an algorithm called approximate cut ac which us a generalization of the gadget of gc and provides an approximate solution to inference in label mrf map problem with clique of size k the algorithm give optimal solution for submodular potential when potential are non submodular we show that important property such a weak persistency hold for solution inferred by ac ac is a polynomial time primal dual approximation algorithm for fixed clique size we show experimentally that ac not only provides significantly better solution in practice it is an order of magnitude faster than message passing scheme like dual decomposition and gtrws or reduction based technique like 
recently introduced cost effective depth sensor coupled with the real time skeleton estimation algorithm of shotton et al have generated a renewed interest in skeleton based human action recognition most of the existing skeleton based approach use either the joint location or the joint angle to represent a human skeleton in this paper we propose a new skeletal representation that explicitly model the d geometric relationship between various body part using rotation and translation in d space since d rigid body motion are member of the special euclidean group se the proposed skeletal representation lie in the lie group se se which is a curved manifold using the proposed representation human action can be modeled a curve in this lie group since classification of curve in this lie group is not an easy task we map the action curve from the lie group to it lie algebra which is a vector space we then perform classification using a combination of dynamic time warping fourier temporal pyramid representation and linear svm experimental result on three action datasets show that the proposed representation performs better than many existing skeletal representation the proposed approach also outperforms various state of the art skeleton based human action recognition approach 
in this paper we address the problem of object tracking in intensity image and depth data we propose a generic framework that can be used either for tracking d template in intensity image or for tracking d object in depth image to overcome problem like partial occlusion strong illumination change and motion blur that notoriously make energy minimization based tracking method get trapped in a local minimum we propose a learning based method that is robust to all these problem we use random forest to learn the relation between the parameter that defines the object s motion and the change they induce on the image intensity or the point cloud of the template it follows that to track the template when it move we use the change on the image intensity or point cloud to predict the parameter of this motion our algorithm ha an extremely fast tracking performance running at le than m per frame and is robust to partial occlusion moreover it demonstrates robustness to strong illumination change when tracking template using intensity image and robustness in tracking d object from arbitrary viewpoint even in the presence of motion blur that cause missing or erroneous data in depth image extensive experimental evaluation and comparison to the related approach strongly demonstrates the benefit of our method 
a the collection of large datasets becomes increasingly automated the occurrence of outlier will increase big data implies big outlier while principal component analysis pca is often used to reduce the size of data and scalable solution exist it is well known that outlier can arbitrarily corrupt the result unfortunately state of the art approach for robust pca do not scale beyond small to medium sized datasets to address this we introduce the grassmann average ga which express dimensionality reduction a an average of the subspace spanned by the data because average can be efficiently computed we immediately gain scalability ga is inherently more robust than pca but we show that they coincide for gaussian data we exploit that average can be made robust to formulate the robust grassmann average rga a a form of robust pca robustness can be with respect to vector subspace or element of vector we focus on the latter and use a trimmed average the resulting trimmed grassmann average tga is particularly appropriate for computer vision because it is robust to pixel outlier the algorithm ha low computational complexity and minimal memory requirement making it scalable to big noisy data we demonstrate tga for background modeling video restoration and shadow removal we show scalability by performing robust pca on the entire star war iv movie 
we propose a robust and accurate method to extract the centerline and scale of tubular structure in d image and d volume existing technique rely either on filter designed to respond to ideal cylindrical structure which lose accuracy when the linear structure become very irregular or on classification which is inaccurate because location on centerline and location immediately next to them are extremely difficult to distinguish we solve this problem by reformulating centerline detection in term of a regression problem we first train regressors to return the distance to the closest centerline in scale space and we apply them to the input image or volume the centerline and the corresponding scale then correspond to the regressors local maximum which can be easily identified we show that our method outperforms state of the art technique for various d and d datasets 
the use of wearable camera make it possible to record life logging egocentric video browsing such long unstructured video is time consuming and tedious segmentation into meaningful chapter is an important first step towards adding structure to egocentric video enabling efficient browsing indexing and summarization of the long video two source of information for video segmentation are i the motion of the camera wearer and ii the object and activity recorded in the video in this paper we address the motion cue for video segmentation motion based segmentation is especially difficult in egocentric video when the camera is constantly moving due to natural head movement of the wearer we propose a robust temporal segmentation of egocentric video into a hierarchy of motion class using a new cumulative displacement curve unlike instantaneous motion vector segmentation using integrated motion vector performs well even in dynamic and crowded scene no assumption are made on the underlying scene structure and the method work in indoor a well a outdoor situation we demonstrate the effectiveness of our approach using publicly available video a well a choreographed video we also suggest an approach to detect the fixation of wearer s gaze in the walking portion of the egocentric video 
we propose a novel discriminative model for semantic labeling in video by incorporating a prior to model both the shape and temporal dependency of an object in video a typical approach for this task is the conditional random field crf which can model local interaction among adjacent region in a video frame recent work ha shown how to incorporate a shape prior into a crf for improving labeling performance but it may be difficult to model temporal dependency present in video by using this prior the conditional restricted boltzmann machine crbm can model both shape and temporal dependency and ha been used to learn walking style from motioncapture data in this work we incorporate a crbm prior into a crf framework and present a new state of the art model for the task of semantic labeling in video in particular we explore the task of labeling part of complex face scene from video in the youtube face database yfdb our combined model outperforms competitive baseline both qualitatively and quantitatively 
we take a new approach to computing dense scene flow between a pair of consecutive rgb d frame we exploit the availability of depth data by seeking correspondence with respect to patch specified not a the pixel inside square window but a the d point that are the inliers of sphere in world space our primary contribution is to show that by reasoning in term of such patch under dof rigid body motion in d we succeed in obtaining compelling result at displacement large and small without relying on either of two simplifying assumption that pervade much of the earlier literature brightness constancy or local surface planarity a a consequence of our approach our output is a dense field of d rigid body motion in contrast to the d translation that are the norm in scene flow reasoning in our manner additionally allows u to carry out occlusion handling using a dof consistency check for the flow computed in both direction and a patchwise silhouette check to help reason about alignment in occlusion area and to promote smoothness of the flow field using an intuitive local rigidity prior we carry out our optimization in two step obtaining a first correspondence field using an adaptation of patchmatch and subsequently using alpha expansion to jointly handle occlusion and perform regularization we show attractive flow result on challenging synthetic and real world scene that push the practical limit of the aforementioned assumption 
this paper attempt to address the problem of recognizing human action while training and testing on distinct datasets when test video are neither labeled nor available during training in this scenario learning of a joint vocabulary or domain transfer technique are not applicable we first explore reason for poor classifier performance when tested on novel datasets and quantify the effect of scene background on action representation and recognition using only the background feature and partitioning of gist feature space we show that the background scene in recent datasets are quite discriminative and can be used classify an action with reasonable accuracy we then propose a new process to obtain a measure of confidence in each pixel of the video being a foreground region using motion appearance and saliency together in a d mrf based framework we also propose multiple way to exploit the foreground confidence to improve bag of word vocabulary histogram representation of a video and a novel histogram decomposition based representation and kernel we used these foreground confidence to recognize action trained on one data set and test on a different data set we have performed extensive experiment on several datasets that improve cross dataset recognition accuracy a compared to baseline method 
in this paper we tackle the problem of co localization in real world image co localization is the problem of simultaneously localizing with bounding box object of the same class across a set of distinct image although similar problem such a co segmentation and weakly supervised localization have been previously studied we focus on being able to perform co localization in real world setting which are typically characterized by large amount of intra class variation inter class diversity and annotation noise to address these issue we present a joint image box formulation for solving the co localization problem and show how it can be relaxed to a convex quadratic program which can be efficiently solved we perform an extensive evaluation of our method compared to previous state of the art approach on the challenging pascal voc and object discovery datasets in addition we also present a large scale study of co localization on imagenet involving ground truth annotation for class and approximately million image 
we consider the problem of deliberately manipulating the direct and indirect light flowing through a time varying fully general scene in order to simplify it visual analysis our approach rest on a crucial link between stereo geometry and light transport while direct light always obeys the epipolar geometry of a projector camera pair indirect light overwhelmingly doe not we show that it is possible to turn this observation into an imaging method that analyzes light transport in real time in the optical domain prior to acquisition this yield three key ability that we demonstrate in an experimental camera prototype producing a live indirect only video stream for any scene regardless of geometric or photometric complexity capturing image that make existing structured light shape recovery algorithm robust to indirect transport and turning them into one shot method for dynamic d shape capture 
we propose an approach to reconstructing tree structure that evolve over time in d image and d image stack such a neuronal axon or plant branch instead of reconstructing structure in each image independently we do so for all image simultaneously to take advantage of temporal consistency constraint we show that this problem can be formulated a a quadratic mixed integer program and solved efficiently the outcome of our approach is a framework that provides substantial improvement in reconstruction over traditional single time instance formulation furthermore an added benefit of our approach is the ability to automatically detect place where significant change have occurred over time which is challenging when considering large amount of data 
inferring human gaze from low resolution eye image is still a challenging task despite it practical importance in many application scenario this paper present a learning by synthesis approach to accurate image based gaze estimation that is personand head pose independent unlike existing appearance based method that assume person specific training data we use a large amount of cross subject training data to train a d gaze estimator we collect the largest and fully calibrated multi view gaze dataset and perform a d reconstruction in order to generate dense training data of eye image by using the synthesized dataset to learn a random regression forest we show that our method outperforms existing method that use low resolution eye image 
in this paper we propose a technique for video object segmentation using patch seam across frame typically seam which are connected path of low energy are utilised for retargeting where the primary aim is to reduce the image size while preserving the salient image content here we adapt the formulation of seam for temporal label propagation the energy function associated with the proposed video seam provides temporal linking of patch across frame to accurately segment the object the proposed energy function take into account the similarity of patch along the seam temporal consistency of motion and spatial coherency of seam label propagation is achieved with high fidelity in the critical boundary region utilising the proposed patch seam to achieve this without additional overhead we curtail the error propagation by formulating boundary region a rough set the proposed approach out perform state of the art supervised and unsupervised algorithm on benchmark datasets 
feature tracking in video is a crucial task in computer vision usually the tracking problem is handled one feature at a time using a single feature tracker like the kanade lucas tomasi algorithm or one of it derivative while this approach work quite well when dealing with high quality video and strong feature it often falter when faced with dark and noisy video containing low quality feature we present a framework for jointly tracking a set of feature which enables sharing information between the different feature in the scene we show that our method can be employed to track feature for both rigid and non rigid motion possibly of few moving body even when some feature are occluded furthermore it can be used to significantly improve tracking result in poorly lit scene where there is a mix of good and bad feature our approach doe not require direct modeling of the structure or the motion of the scene and run in real time on a single cpu core 
curvature ha received increasing attention a an important alternative to length based regularization in computer vision in contrast to length it preserve elongated structure and fine detail existing approach are either inefficient or have low angular resolution and yield result with strong block artifact we derive a new model for computing squared curvature based on integral geometry the model count response of straight line triple clique the corresponding energy decomposes into submodular and supermodular pairwise potential we show that this energy can be efficiently minimized even for high angular resolution using the trust region framework our result confirm that we obtain accurate and visually pleasing solution without strong artifact at reasonable runtimes 
the main contribution of this work is a framework to register anatomical structure characterized a a point set where each point ha an associated symmetric matrix these matrix can represent problem dependent characteristic of the registered structure for example in airway matrix can represent the orientation and thickness of the structure our framework relies on a dense tensor field representation which we implement sparsely a a kernel mixture of tensor field we equip the space of tensor field with a norm that serf a a similarity measure to calculate the optimal transformation between two structure we minimize this measure using an analytical gradient for the similarity measure and the deformation field which we restrict to be a diffeomorphism we illustrate the value of our tensor field model by comparing our result with scalar and vector field based model finally we evaluate our registration algorithm on synthetic data set and validate our approach on manually annotated airway tree 
the seminal multiple view stereo benchmark evaluation from middlebury and by strecha et al have played a major role in propelling the development of multi view stereopsis methodology although seminal these benchmark datasets are limited in scope with few reference scene here we try to take these work a step further by proposing a new multi view stereo dataset which is an order of magnitude larger in number of scene and with a significant increase in diversity specifically we propose a dataset containing scene of large variability each scene consists of or accurate camera position and reference structured light scan all acquired by a axis industrial robot to apply this dataset we propose an extension of the evaluation protocol from the middlebury evaluation reflecting the more complex geometry of some of our scene the proposed dataset is used to evaluate the state of the art multiview stereo algorithm of tola et al campbell et al and furukawa et al hereby we demonstrate the usability of the dataset a well a gain insight into the working and challenge of multi view stereopsis through these experiment we empirically validate some of the central hypothesis of multi view stereopsis a well a determining and reaffirming some of the central challenge 
a recent trend of research ha shown how contextual information related to an action such a a scene or object can enhance the accuracy of human action recognition system however using context to improve unsupervised human action clustering ha never been considered before and cannot be achieved using existing clustering method to solve this problem we introduce a novel general purpose algorithm dual assignment k mean dakm which is uniquely capable of performing two co occurring clustering task simultaneously while exploiting the correlation information to enhance both clustering furthermore we describe a spectral extension of dakm sdakm for better performance on realistic data extensive experiment on synthetic data and on three realistic human action datasets with scene context show that dakm sdakm can significantly outperform the state of the art clustering method by taking into account the contextual relationship between action and scene 
we present an approach that take a single photograph of a child a input and automatically produce a series of age progressed output between and year of age accounting for pose expression and illumination leveraging thousand of photo of child and adult at many age from the internet we first show how to compute average image subspace that are pixel to pixel aligned and model variable lighting these average depict a prototype man and woman aging from to under any desired illumination and capture the difference in shape and texture between age applying these difference to a new photo yield an age progressed result contribution include relightable age subspace a novel technique for subspace to subspace alignment and the most extensive evaluation of age progression technique in the literature 
the construction of facial deformable model fdms is a very challenging computer vision problem since the face is a highly deformable object and it appearance drastically change under different pose expression and illumination although several method for generic fdms construction have been proposed for facial landmark localization in still image they are insufficient for task such a facial behaviour analysis and facial motion capture where perfect landmark localization is required in this case person specific fdms psms are mainly employed requiring manual facial landmark annotation for each person and person specific training in this paper a novel method for the automatic construction of psms is proposed to this end an orthonormal subspace which is suitable for facial image reconstruction is learnt next to correct the fitting of a generic model image congealing i e batch image aliment is performed by employing only the learnt orthonormal subspace finally the corrected fitting are used to construct the psm the image congealing problem is solved by formulating a suitable sparsity regularized rank minimization problem the proposed method outperforms the state of the art method that is compared to in term of both landmark localization accuracy and computational time 
state of the art patch based image representation involve a pooling operation that aggregate statistic computed from local descriptor standard pooling operation include sumand max pooling sum pooling lack discriminability because the resulting representation is strongly influenced by frequent yet often uninformative descriptor but only weakly influenced by rare yet potentially highly informative one max pooling equalizes the influence of frequent and rare descriptor but is only applicable to representation that rely on count statistic such a the bag of visual word bov and it softand sparse coding extension we propose a novel pooling mechanism that achieves the same effect a max pooling but is applicable beyond the bov and especially to the state of the art fisher vector hence the name generalized max pooling gmp it involves equalizing the similarity between each patch and the pooled representation which is shown to be equivalent to re weighting the per patch statistic we show on five public image classification benchmark that the proposed gmp can lead to significant performance gain with respect to heuristic alternative 
we consider the problem of localizing a novel image in a large d model in principle this is just an instance of camera pose estimation but the scale introduces some challenging problem for one it make the correspondence problem very difficult and it is likely that there will be a significant rate of outlier to handle in this paper we use recent theoretical a well a technical advance to tackle these problem many modern camera and phone have gravitational sensor that allow u to reduce the search space further there are new technique to efficiently and reliably deal with extreme rate of outlier we extend these method to camera pose estimation by using accurate approximation and fast polynomial solver experimental result are given demonstrating that it is possible to reliably estimate the camera pose despite more than of outlier correspondence 
the underlying idea of multitask learning is that learning task jointly is better than learning each task individually in particular if only a few training example are available for each task sharing a jointly trained representation improves classification performance in this paper we propose a novel multitask learning method that learns a low dimensional representation jointly with the corresponding classifier which are then able to profit from the latent inter class correlation our method scale with respect to the original feature dimension and can be used with high dimensional image descriptor such a the fisher vector furthermore it consistently outperforms the current state of the art on the sun scene classification benchmark with varying amount of training data 
we study the problem of understanding object in detail intended a recognizing a wide array of fine grained object attribute to this end we introduce a dataset of airplane annotated in detail with part and their attribute leveraging image donated by airplane spotter and crowd sourcing both the design and collection of the detailed annotation we provide a number of insight that should help researcher interested in designing fine grained datasets for other basic level category we show that the collected data can be used to study the relation between part detection and attribute prediction by diagnosing the performance of classifier that pool information from different part of an object we note that the prediction of certain attribute can benefit substantially from accurate part detection we also show that differently from previous result in object detection employing a large number of part template can improve detection accuracy at the expense of detection speed we finally propose a coarse to fine approach to speed up detection through a hierarchical cascade algorithm 
we present a stereo algorithm designed for speed and efficiency that us local slanted plane sweep to propose disparity hypothesis for a semi global matching algorithm our local plane hypothesis are derived from initial sparse feature correspondence followed by an iterative clustering step local plane sweep are then performed around each slanted plane to produce out of plane parallax and matching cost estimate a final global optimization stage implemented using semi global matching assigns each pixel to one of the local plane hypothesis by only exploring a small fraction of the whole disparity space volume our technique achieves significant speedup over previous algorithm and achieves state of the art accuracy on high resolution stereo pair of up to megapixels 
previous effort in hashing intend to preserve data variance or pairwise affinity but neither is adequate in capturing the manifold structure hidden in most visual data in this paper we tackle this problem by reconstructing the locally linear structure of manifold in the binary hamming space which can be learned by locality sensitive sparse coding we cast the problem a a joint minimization of reconstruction error and quantization loss and show that despite it np hardness a local optimum can be obtained efficiently via alternative optimization our method distinguishes itself from existing method in it remarkable ability to extract the nearest neighbor of the query from the same manifold instead of from the ambient space on extensive experiment on various image benchmark our result improve previous state of the art by typically and on the yale face data 
we advocate the inference of qualitative information about d human pose called posebits from image posebits represent boolean geometric relationship between body part e g left leg in front of right leg or hand close to each other the advantage of posebits a a mid level representation are for many task of interest such qualitative pose information may be sufficient e g semantic image retrieval it is relatively easy to annotate large image corpus with posebits a it simply requires answer to yes no question and they help resolve challenging pose ambiguity and therefore facilitate the difficult talk of image based d pose estimation we introduce posebits a posebit database a method for selecting useful posebits for pose estimation and a structural svm model for posebit inference experiment show the use of posebits for semantic image retrieval and for improving d pose estimation 
we present an efficient and scalable algorithm for segmenting d rgbd point cloud by combining depth color and temporal information using a multistage hierarchical graph based approach our algorithm process a moving window over several point cloud to group similar region over a graph resulting in an initial over segmentation these region are then merged to yield a dendrogram using agglomerative clustering via a minimum spanning tree algorithm bipartite graph matching at a given level of the hierarchical tree yield the final segmentation of the point cloud by maintaining region identity over arbitrarily long period of time we show that a multistage segmentation with depth then color yield better result than a linear combination of depth and color due to it incremental processing our algorithm can process video of any length and in a streaming pipeline the algorithm s ability to produce robust efficient segmentation is demonstrated with numerous experimental result on challenging sequence from our own a well a public rgbd data set 
several popular and effective object detector separately model intra class variation arising from deformation and appearance change this reduces model complexity while enabling the detection of object across change in viewpoint object pose etc the deformable part model dpm is perhaps the most successful such model to date a common assumption is that the exponential number of template enabled by a dpm is critical to it success in this paper we show the counter intuitive result that it is possible to achieve similar accuracy using a small dictionary of deformation each component in our model is represented by a single hog template and a dictionary of flow field that determine the deformation the template may undergo while the number of candidate deformation is dramatically fewer than that for a dpm the deformed template tend to be plausible and interpretable in addition we discover that the set of deformation base is actually transferable across object category and that learning shared base across similar category can boost accuracy 
we introduce a method to reduce most higher order term of markov random field with binary label into lower order one without introducing any new variable while keeping the minimizer of the energy unchanged while the method doe not reduce all term it can be used with existing technique that transformsarbitrary term by introducing auxiliary variable and improve the speed the method eliminates a higher order term in the polynomial representation of the energy by finding the value assignment to the variable involved that cannot be part of a global minimizer and increasing the potential value only when that particular combination occurs by the exact amount that make the potential of lower order we also introduce a faster approximation that forego the guarantee of exact equivalence of minimizer in favor of speed with experiment on the same field of expert dataset used in previous work we show that the roof dual algorithm after the reduction label significantly more variable and the energy converges more rapidly 
dynamic bayesian network such a hidden markov model hmms are successfully used a probabilistic model for human motion the use of hidden variable make them expressive model but inference is only approximate and requires procedure such a particle filter or markov chain monte carlo method in this work we propose to instead use simple markov model that only model observed quantity we retain a highly expressive dynamic model by using interaction that are nonlinear and non parametric a presentation of our approach in term of latent variable show logarithmic growth for the computation of exact log likelihood in the number of latent state we validate our model on human motion capture data and demonstrate state of the art performance on action recognition and motion completion task 
histogram based feature have significantly contributed to recent development of image classification such a by sift local descriptor in this paper we propose a method to efficiently transform those histogram feature for improving the classification performance the l normalized histogram feature is regarded a a probability mass function which is modeled by dirichlet distribution based on the probabilistic modeling we induce the dirichlet fisher kernel for transforming the histogram feature vector the method work on the individual histogram feature to enhance the discriminative power at a low computational cost on the other hand in the bag of feature bof framework the dirichlet mixture model can be extended to gaussian mixture by transforming histogram based local descriptor e g sift and thereby we propose the method of dirichlet derived gmm fisher kernel in the experiment on diverse image classification task including recognition of subordinate object and material texture the proposed method improve the performance of the histogrambased feature and bof based fisher kernel being favorably competitive with the state of the art 
this paper address the problem of assigning object class label to image pixel following recent holistic formulation we cast scene labeling a inference of a conditional random field crf grounded onto superpixels the crf inference is specified a quadratic program qp with mutual exclusion mutex constraint on class label assignment the qp is solved using a beam search b which is well suited for scene labeling because it explicitly account for spatial extent of object conforms to inconsistency constraint from domain knowledge and ha low computational cost b gradually build a search tree whose node correspond to candidate scene labelings successor node are repeatedly generated from a select set of their parent node until convergence we prove that our b efficiently maximizes the qp objective of crf inference effectiveness of our b for scene labeling is evaluated on the benchmark msrc stanford backgroud pascal voc and datasets 
in this paper we present a depth guided photometric d reconstruction method that work solely with a depth camera like the kinect existing method that fuse depth with normal estimate use an external rgb camera to obtain photometric information and treat the depth camera a a black box that provides a low quality depth estimate our contribution to such method are two fold firstly instead of using an extra rgb camera we use the infra red ir camera of the depth camera system itself to directly obtain high resolution photometric information we believe that ours is the first method to use an ir depth camera system in this manner secondly photometric method applied to complex object result in numerous hole in the reconstructed surface due to shadow and self occlusion to mitigate this problem we develop a simple and effective multiview reconstruction approach that fuse depth and normal information from multiple viewpoint to build a complete consistent and accurate d surface representation we demonstrate the efficacy of our method to generate high quality d surface reconstruction for some complex d figurine 
the number of gps tagged image available on the web is increasing at a rapid rate the majority of such location tag are specified by the user either through manual tagging or localization chip embedded in the camera however a known issue with user shared image is the unreliability of such gps tag in this paper we propose a method for addressing this problem we assume a large dataset of gps tagged image which includes an unknown subset with contaminated tag is available we develop a robust method for identification and refinement of this subset using the rest of the image in the dataset in the proposed method we form a large number of triplet of matching image and use them for estimating the location of the query image utilizing structure from motion some of the generated estimation may be inaccurate due to the noisy gps tag in the dataset therefore we perform random walk on the estimation in order to identify the subset with the maximal agreement finally we estimate the gps tag of the query utilizing the identified consistent subset using a weighted mean we propose a new damping factor for random walk which conforms to the level of noise in the input and consequently robustifies random walk we evaluated the proposed framework on a dataset of over k user shared image the experiment show our method robustly improves the accuracy of gps tag under diverse scenario 
we address the problem of populating object category detection datasets with dense per object d reconstruction bootstrapped from class label ground truth figure ground segmentation and a small set of keypoint annotation our proposed algorithm first estimate camera viewpoint using rigid structure from motion then reconstructs object shape by optimizing over visual hull proposal guided by loose within class shape similarity assumption the visual hull sampling process attempt to intersect an object s projection cone with the cone of minimal subset of other similar object among those pictured from certain vantage point we show that our method is able to produce convincing per object d reconstruction on one of the most challenging existing object category detection datasets pascal voc our result may re stimulate once popular geometry oriented model based recognition approach 
in this paper we study the problem of blind deconvolution our analysis is based on the algorithm of chan and wong which popularized the use of sparse gradient prior via total variation we use this algorithm because many method in the literature are essentially adaptation of this framework such algorithm is an iterative alternating energy minimization where at each step either the sharp image or the blur function are reconstructed recent work of levin et al showed that any algorithm that try to minimize that same energy would fail a the desired solution ha a higher energy than the no blur solution where the sharp image is the blurry input and the blur is a dirac delta however experimentally one can observe that chan and wong s algorithm converges to the desired solution even when initialized with the no blur one we provide both analysis and experiment to resolve this paradoxical conundrum we find that both claim are right the key to understanding how this is possible lie in the detail of chan and wong s implementation and in how seemingly harmless choice result in dramatic effect our analysis reveals that the delayed scaling normalization in the iterative step of the blur kernel is fundamental to the convergence of the algorithm this then result in a procedure that eludes the no blur solution despite it being a global minimum of the original energy we introduce an adaptation of this algorithm and show that in spite of it extreme simplicity it is very robust and achieves a performance comparable to the state of the art 
several descriptor have been proposed in the past for d shape analysis yet none of them achieves best performance on all shape class in this paper we propose a novel method for d shape analysis using the covariance matrix of the descriptor rather than the descriptor themselves covariance matrix enable efficient fusion of different type of feature and modality they capture using the same representation not only the geometric and the spatial property of a shape region but also the correlation of these property within the region covariance matrix however lie on the manifold of symmetric positive definite spd tensor a special type of riemannian manifold which make comparison and clustering of such matrix challenging in this paper we study covariance matrix in their native space and make use of geodesic distance on the manifold a a dissimilarity measure we demonstrate the performance of this metric on d face matching and recognition task we then generalize the bag of feature paradigm originally designed in euclidean space to the riemannian manifold of spd matrix we propose a new clustering procedure that take into account the geometry of the riemannian manifold we evaluate the performance of the proposed bag of covariance matrix framework on d shape matching and retrieval application and demonstrate it superiority compared to descriptor based technique 
we propose a shape matching method that produce dense correspondence tuned to a specific class of shape and deformation in a scenario where this class is represented by a small set of example shape the proposed method learns a shape descriptor capturing the variability of the deformation in the given class the approach enables the wave kernel signature to extend the class of recognized deformation from near isometry to the deformation appearing in the example set by mean of a random forest classifier with the help of the introduced spatial regularization the proposed method achieves significant improvement over the baseline approach and obtains state of the art result while keeping short computation time 
we address the problem of camouflaging a d object from the many viewpoint that one might see it from given photograph of an object s surroundings we produce a surface texture that will make the object difficult for a human to detect to do this we introduce several background matching algorithm that attempt to make the object look like whatever is behind it of course it is impossible to exactly match the background from every possible viewpoint thus our model are forced to make trade offs between different perceptual factor such a the conspicuousness of the occlusion boundary and the amount of texture distortion we use experiment with human subject to evaluate the effectiveness of these model for the task of camouflaging a cube finding that they significantly outperform nai ve strategy 
computational and memory cost restrict spectral technique to rather small graph which is a serious limitation especially in video segmentation in this paper we propose the use of a reduced graph based on superpixels in contrast to previous work the reduced graph is reweighted such that the resulting segmentation is equivalent under certain assumption to that of the full graph we consider equivalence in term of the normalized cut and of it spectral clustering relaxation the proposed method reduces runtime and memory consumption and yield on par result in image and video segmentation further it enables an efficient data representation and update for a new streaming video segmentation approach that also achieves state of the art performance 
in this work we propose a technique to combine bottom up segmentation coming in the form of slic superpixels with sliding window detector such a deformable part model dpms the merit of our approach lie in cleaning up the low level hog feature by exploiting the spatial support of slic superpixels this can be understood a using segmentation to split the feature variation into object specific and background change rather than committing to a single segmentation we use a large pool of slic superpixels and combine them in a scale positionand object dependent manner to build soft segmentation mask the segmentation mask can be computed fast enough to repeat this process over every candidate window during training and detection for both the root and part filter of dpms we use these mask to construct enhanced background invariant feature to train dpms we test our approach on the pascal voc outperforming the standard dpm in out of class yielding an average increase of ap additionally we demonstrate the robustness of this approach extending it to dense sift descriptor for large displacement optical flow 
we present a novel solution to compute the relative pose of a generalized camera existing solution are either not general have too high computational complexity or require too many correspondence which impedes an efficient or accurate usage within ransac scheme we factorize the problem a a low dimensional iterative optimization over relative rotation only directly derived from well known epipolar constraint common generalized camera often consist of camera cluster and give rise to omni directional landmark observation we prove that our iterative scheme performs well in such practically relevant situation eventually resulting in computational efficiency similar to linear solver and accuracy close to bundle adjustment while using le correspondence experiment on both virtual and real multi camera system prove superior overall performance for robust real time multi camera motion estimation 
gaussian mixture model have become one of the major tool in modern statistical image processing and allowed performance breakthrough in patch based image denoising and restoration problem nevertheless their adoption level wa kept relatively low because of the computational cost associated to learning such model on large image database this work provides a flexible and generic tool for dealing with such model without the computational penalty or parameter tuning difficulty associated to a nai ve implementation of gmm based image restoration task it doe so by organising the data manifold in a hirerachical multiscale structure the covariance tree that can be queried at various scale level around any point in feature space we start by explaining how to construct a covariance tree from a subset of the input data how to enrich it statistic from a larger set in a streaming process and how to query it efficiently at any scale we then demonstrate it usefulness on several application including non local image filtering data driven denoising reconstruction from random sample and surface modeling from unorganized d point set 
graph based method are a useful class of method for improving the performance of unsupervised and semi supervised machine learning task such a clustering or information retrieval however the performance of existing graph based method is highly dependent on how well the affinity graph reflects the original data structure we propose that multimedia such a image or video consist of multiple separate component and therefore more than one graph is required to fully capture the relationship between them accordingly we present a new spectral method the feature grouped spectral multigraph fgsm which comprises the following step first mutually independent subset of the original feature space are generated through feature clustering secondly a separate graph is generated from each feature subset finally a spectral embedding is calculated on each graph and the embeddings are scaled aggregated into a single representation using this representation a variety of experiment are performed on three learning task clustering retrieval and recognition on human action datasets demonstrating considerably better performance than the state of the art 
in this paper we propose a weighted supervised pooling method for visual recognition system we combine a standard spatial pyramid representation which is commonly adopted to encode spatial information with an appropriate feature space representation favoring semantic information in an appropriate feature space for the latter we propose a weighted pooling strategy exploiting data supervision to weigh each local descriptor coherently with it likelihood to belong to a given object class the two representation are then combined adaptively with multiple kernel learning experiment on common benchmark caltech and pascal voc show that our image representation improves the current visual recognition pipeline and it is competitive with similar state of art pooling method we also evaluate our method on a real human robot interaction setting where the pure spatial pyramid representation doe not provide sufficient discriminative power obtaining a remarkable improvement 
when building vision system that predict structured object such a image segmentation or human pose a crucial concern is performance under task specific evaluation measure e g jaccard index or average precision an ongoing research challenge is to optimize prediction so a to maximize performance on such complex measure in this work we present a simple meta algorithm that is surprisingly effective empirical min bayes risk embr take a input a pre trained model that would normally be the final product and learns three additional parameter so a to optimize performance on the complex high order task specific measure we demonstrate embr in several domain taking existing state of the art algorithm and improving performance up to simply with three extra parameter 
in this paper we study the role of context in existing state of the art detection and segmentation approach towards this goal we label every pixel of pascal voc detection challenge with a semantic category we believe this data will provide plenty of challenge to the community a it contains additional class for semantic segmentation and object detection our analysis show that nearest neighbor based approach perform poorly on semantic segmentation of contextual class showing the variability of pascal imagery furthermore improvement of existing contextual model for detection is rather modest in order to push forward the performance in this difficult scenario we propose a novel deformable part based model which exploit both local context around each candidate detection a well a global context at the level of the scene we show that this contextual reasoning significantly help in detecting object at all scale 
in this paper we propose a novel labeling cost for multiview reconstruction existing approach use data term with specific weakness that are vulnerable to common challenge such a low textured region or specularities our new probabilistic method implicitly discard outlier and can be shown to become more exact the closer we get to the true object surface our approach achieves top result among all published method on the middlebury dino sparse dataset and also delivers accurate result on several other datasets with widely varying challenge for which it work in unchanged form 
the essential matrix which encodes the epipolar constraint between point in two projective view is a cornerstone of modern computer vision previous work have proposed different characterization of the space of essential matrix a a riemannian manifold however they either do not consider the symmetric role played by the two view or do not fully take into account the geometric peculiarity of the epipolar constraint we address these limitation with a characterization a a quotient manifold which can be easily interpreted in term of camera pose while our main focus in on theoretical aspect we include experiment in pose averaging and show that the proposed formulation produce a meaningful distance between essential matrix 
the transfer learning and domain adaptation problem originate from a distribution mismatch between the source and target data distribution the cause of such mismatch are traditionally considered different thus transfer learning and domain adaptation algorithm are designed to address different issue and cannot be used in both setting unless substantially modified still one might argue that these problem are just different declination of learning to learn i e the ability to leverage over prior knowledge when attempting to solve a new task we propose a learning to learn framework able to leverage over source data regardless of the origin of the distribution mismatch we consider prior model a expert and use their output confidence value a feature we use them to build the new target model combined with the feature from the target data through a high level cue integration scheme this result in a class of algorithm usable in a plug and play fashion over any learning to learn scenario from binary and multi class transfer learning to single and multiple source domain adaptation setting experiment on several public datasets show that our approach consistently achieves the state of the art 
we propose a method for human pose estimation based on deep neural network dnns the pose estimation is formulated a a dnn based regression problem towards body joint we present a cascade of such dnn regressors which result in high precision pose estimate the approach ha the advantage of reasoning about pose in a holistic fashion and ha a simple but yet powerful formulation which capitalizes on recent advance in deep learning we present a detailed empirical analysis with state ofart or better performance on four academic benchmark of diverse real world image 
in the following paper we present an approach for fine grained recognition based on a new part detection method in particular we propose a nonparametric label transfer technique which transfer part constellation from object with similar global shape the possibility for transferring part annotation to unseen image allows for coping with a high degree of pose and view variation in scenario where traditional detection model such a deformable part model fail our approach is especially valuable for fine grained recognition scenario where intraclass variation are extremely high and precisely localized feature need to be extracted furthermore we show the importance of carefully designed visual extraction strategy such a combination of complementary feature type and iterative image segmentation and the resulting impact on the recognition performance in experiment our simple yet powerful approach achieves and accuracy on the cub and bird datasets which is the current best performance for these benchmark 
an action is typically composed of different part of the object moving in particular sequence the presence of different motion represented a a d histogram ha been used in the traditional bag of word bow approach for recognizing action however the interaction among the motion also form a crucial part of an action different object part have varying degree of interaction with the other part during an action cycle it is these interaction we want to quantify in order to bring in additional information about the action in this paper we propose a causality based approach for quantifying the interaction to aid action classification granger causality is used to compute the cause and effect relationship for pair of motion trajectory of a video a d histogram descriptor for the video is constructed using these pairwise measure our proposed method of obtaining pairwise measure for video is also applicable for large datasets we have conducted experiment on challenging action recognition database such a hmdb and ucf and shown that our causality descriptor help in encoding additional information regarding the action and performs on par with the state of the art approach due to the complementary nature a further increase in performance can be observed by combining our approach with state of the art approach 
we propose a deep learning framework for image set classification with application to face recognition an adaptive deep network template adnt is defined whose parameter are initialized by performing unsupervised pre training in a layer wise fashion using gaussian restricted boltzmann machine grbms the pre initialized adnt is then separately trained for image of each class and class specific model are learnt based on the minimum reconstruction error from the learnt class specific model a majority voting strategy is used for classification the proposed framework is extensively evaluated for the task of image set classification based face recognition on honda ucsd cmu mobo youtube celebrity and a kinect dataset our experimental result and comparison with existing state of the art method show that the proposed method consistently achieves the best performance on all these datasets 
we derive an easy to implement and efficient algorithm for solving multi label image partitioning problem in the form of the problem addressed by region competition these problem jointly determine a parameter for each of the region in the partition given an estimate of the parameter a fast approximate solution to the multi label sub problem is derived by a global update that us smoothing and thresholding the method is empirically validated to be robust to fine detail of the image that plague local solution further in comparison to global method for the multi label problem the method is more efficient and it is easy for a non specialist to implement we give sample matlab code for the multi label chan vese problem in this paper experimental comparison to the state of the art in multi label solution to region competition show that our method achieves equal or better accuracy with the main advantage being speed and ease of implementation 
retinal image contain forest of mutually intersecting and overlapping venous and arterial vascular tree the geometry of these tree show adaptation to vascular disease including diabetes stroke and hypertension segmentation of the retinal vascular network is complicated by inconsistent vessel contrast fuzzy edge variable image quality medium opacity complex intersection and overlap this paper present a bayesian approach to resolving the configuration of vascular junction to correctly construct the vascular tree a probabilistic model of vascular joint terminal bridge and bifurcation and their configuration in junction is built and maximum a posteriori map estimation used to select most likely configuration the model is built using a reference set of joint extracted from the drive public domain vascular segmentation dataset and evaluated on joint from the drive test set demonstrating an accuracy of 
in this paper we present a conceptually simple but surprisingly powerful method for visual prediction which combine the effectiveness of mid level visual element with temporal modeling our framework can be learned in a completely unsupervised manner from a large collection of video however more importantly because our approach model the prediction framework on these mid level element we can not only predict the possible motion in the scene but also predict visual appearance how are appearance going to change with time this yield a visual hallucination of probable event on top of the scene we show that our method is able to accurately predict and visualize simple future event we also show that our approach is comparable to supervised method for event prediction 
a simple approach to learning invariance in image classification consists in augmenting the training set with transformed version of the original image however given a large set of possible transformation selecting a compact subset is challenging indeed all transformation are not equally informative and adding uninformative transformation increase training time with no gain in accuracy we propose a principled algorithm image transformation pursuit itp for the automatic selection of a compact set of transformation itp work in a greedy fashion by selecting at each iteration the one that yield the highest accuracy gain itp also allows to efficiently explore complex transformation that combine basic transformation we report result on two public benchmark the cub dataset of bird image and the imagenet challenge using fisher vector representation we achieve an improvement from to in top accuracy on cub and an improvement from to in top accuracy on imagenet we also show significant improvement for deep convnet feature from to on cub and from to on imagenet 
the notion of relative attribute a introduced by parikh and grauman iccv provides an appealing way of comparing two image based on their visual property or attribute such a smiling for face image naturalness for outdoor image etc for learning such attribute a ranking svm based formulation wa proposed that us globally represented pair of annotated image in this paper we extend this idea towards learning relative attribute using local part that are shared across category first instead of using a global representation we introduce a part based representation combining a pair of image that specifically compare corresponding part then with each part we associate a locally adaptive significance coefficient that represents it discriminative ability with respect to a particular attribute for each attribute the significance coefficient are learned simultaneously with a max margin ranking model in an iterative manner compared to the baseline method the new method is shown to achieve significant improvement in relative attribute prediction accuracy additionally it is also shown to improve relative feedback based interactive image search 
in recent year large image data set such a imagenet tinyimages or ever growing social network like flickr have emerged posing new challenge to image classification that were not apparent in smaller image set in particular the efficient handling of dynamically growing data set where not only the amount of training image but also the number of class increase over time is a relatively unexplored problem to remedy this we introduce nearest class mean forest ncmf a variant of random forest where the decision node are based on nearest class mean ncm classification ncmfs not only outperform conventional random forest but are also well suited for integrating new class to this end we propose and compare several approach to incorporate data from new class so a to seamlessly extend the previously trained forest instead of re training them from scratch in our experiment we show that ncmfs trained on small data set with class can be extended to large data set with class without significant loss of accuracy compared to training from scratch on the full data 
this paper present an improvement of the j linkage algorithm for fitting multiple instance of a model to noisy data corrupted by outlier the binary preference analysis implemented by j linkage is replaced by a continuous soft or fuzzy generalization that prof to perform better than j linkage on simulated data and compare favorably with state of the art method on public domain real datasets 
we present a co clustering framework that can be used to discover multiple semantic and visual sens of a given noun phrase np unlike traditional clustering approach which assume a one to one mapping between the cluster in the text based feature space and the visual space we adopt a one to many mapping between the two space this is primarily because each semantic sense concept can correspond to different visual sens due to viewpoint and appearance variation our structure em style optimization not only extract the multiple sens in both semantic and visual feature space but also discovers the mapping between the sens we introduce a challenging dataset cmu polysemy for this problem consisting of np labeled instance out of k total instance we have also conducted a large scale experiment that performs sense disambiguation for np 
this paper develops a novel framework for semantic image retrieval based on the notion of a scene graph our scene graph represent object man boat attribute of object boat is white and relationship between object man standing on boat we use these scene graph a query to retrieve semantically related image to this end we design a conditional random field model that reason about possible grounding of scene graph to test image the likelihood of these grounding are used a ranking score for retrieval we introduce a novel dataset of human generated scene graph grounded to image and use this dataset to evaluate our method for image retrieval in particular we evaluate retrieval using full scene graph and small scene subgraphs and show that our method outperforms retrieval method that use only object or low level image feature in addition we show that our full model can be used to improve object localization compared to baseline method 
in this paper we introduce a spherical embedding technique to position a given set of silhouette of an object a observed from a set of camera arbitrarily positioned around the object our technique estimate dissimilarity among the silhouette and embeds them directly in the rotation space so the embedding is obtained by an optimization scheme applied over the rotation represented with exponential map since the measure for inter silhouette dissimilarity contains many outlier our key idea is to perform the embedding by only using a subset of the estimated dissimilarity we present a technique that carefully screen for inlier distance and the pairwise scaled dissimilarity are embedded in a spherical space diffeomorphic to so we show that our method outperforms spherical md embedding demonstrate it performance on various multi view set and highlight it robustness to outlier 
in this paper we address the problem of model free online object tracking based on color representation according to the finding of recent benchmark evaluation such tracker often tend to drift towards region which exhibit a similar appearance compared to the object of interest to overcome this limitation we propose an efficient discriminative object model which allows u to identify potentially distracting region in advance furthermore we exploit this knowledge to adapt the object representation beforehand so that distractors are suppressed and the risk of drifting is significantly reduced we evaluate our approach on recent online tracking benchmark datasets demonstrating state of the art result in particular our approach performs favorably both in term of accuracy and robustness compared to recent tracking algorithm moreover the proposed approach allows for an efficient implementation to enable online object tracking in real time 
depth camera have helped commoditize d digitization of the real world it is now feasible to use a single kinect like camera to scan in an entire building or other large scale scene at large scale however there is an inherent challenge of dealing with distortion and drift due to accumulated pose estimation error existing technique suffer from one or more of the following a requiring an expensive offline global optimization step taking hour to compute b needing a full second pas over the input depth frame to correct for accumulated error c relying on rgb data alongside depth data to optimize pose or d requiring the user to create explicit loop closure to allow gross alignment error to be resolved in this paper we present a method that address all of these issue our method support online model correction without needing to reprocess or store any input depth data even while performing global correction of a large d model our method take only minute rather than hour to compute our model doe not require any explicit loop closure to be detected and finally relies on depth data alone allowing operation in low lighting condition we show qualitative result on many large scale scene highlighting the lack of error and drift in our reconstruction we compare to state of the art technique and demonstrate large scale dense surface reconstruction in the dark a capability not offered by rgb d technique 
light field camera are now used in consumer and industrial application recent paper and product have demonstrated practical depth recovery algorithm from a passive single shot capture however current light field capture device have narrow baseline and constrained spatial resolution therefore the accuracy of depth recovery is limited requiring heavy regularization and producing planar depth that do not resemble the actual geometry using shading information is essential to improve the shape estimation we develop an improved technique for local shape estimation from defocus and correspondence cue and show how shading can be used to further refine the depth light field camera are able to capture both spatial and angular data suitable for refocusing by locally refocusing each spatial pixel to it respective estimated depth we produce an all in focus image where all viewpoint converge onto a point in the scene therefore the angular pixel have angular coherence which exhibit three property photo consistency depth consistency and shading consistency we propose a new framework that us angular coherence to optimize depth and shading the optimization framework estimate both general lighting in natural scene and shading to improve depth regularization our method outperforms current state of the art light field depth estimation algorithm in multiple scenario including real image 
in this paper we show that multiple object tracking mot can be formulated in a framework where the detection and data association are performed simultaneously our method allows u to overcome the confinement of data association based mot approach where the performance is dependent on the object detection result provided at input level at the core of our method lie structured learning which learns a model for each target and infers the best location of all target simultaneously in a video clip the inference of our structured learning is done through a new target identity aware network flow tinf where each node in the network encodes the probability of each target identity belonging to that node the proposed lagrangian relaxation optimization find the high quality solution to the network during optimization a soft spatial constraint is enforced between the node of the graph which help reducing the ambiguity caused by nearby target with similar appearance in crowded scenario we show that automatically detecting and tracking target in a single framework can help resolve the ambiguity due to frequent occlusion and heavy articulation of target our experiment involve challenging yet distinct datasets and show that our method can achieve result better than the state of art 
we tackle the problem of large scale visual place recognition where the task is to quickly and accurately recognize the location of a given query photograph we present the following four principal contribution first we develop a convolutional neural network cnn architecture that is trainable in an end to end manner directly for the place recognition task the main component of this architecture netvlad is a new generalized vlad layer inspired by the vector of locally aggregated descriptor image representation commonly used in image retrieval the layer is readily pluggable into any cnn architecture and amenable to training via backpropagation second we create a new weakly supervised ranking loss which enables end to end learning of the architecture s parameter from image depicting the same place over time downloaded from google street view time machine third we develop an efficient training procedure which can be applied on very large scale weakly labelled task finally we show that the proposed architecture and training procedure significantly outperform non learnt image representation and off the shelf cnn descriptor on challenging place recognition and image retrieval benchmark 
the state of the art salient object detection model are able to perform well for relatively simple scene yet for more complex one they still have difficulty in highlighting salient object completely from background largely due to the lack of sufficiently robust feature for saliency prediction to address such an issue this paper proposes a novel hierarchy associated feature construction framework for salient object detection which is based on integrating elementary feature from multi level region in a hierarchy furthermore multi layered deep learning feature are introduced and incorporated a elementary feature into this framework through a compact integration scheme this lead to a rich feature representation which is able to represent the context of the whole object background and is much more discriminative a well a robust for salient object detection extensive experiment on the most widely used and challenging benchmark datasets demonstrate that the proposed approach substantially outperforms the state of the art on salient object detection 
deep learning technique have been successfully applied in many area of computer vision including low level image restoration problem for image super resolution several model based on deep neural network have been recently proposed and attained superior performance that overshadows all previous handcrafted model the question then arises whether large capacity and data driven model have become the dominant solution to the ill posed super resolution problem in this paper we argue that domain expertise represented by the conventional sparse coding model is still valuable and it can be combined with the key ingredient of deep learning to achieve further improved result we show that a sparse coding model particularly designed for super resolution can be incarnated a a neural network and trained in a cascaded structure from end to end the interpretation of the network based on sparse coding lead to much more efficient and effective training a well a a reduced model size our model is evaluated on a wide range of image and show clear advantage over existing state of the art method in term of both restoration accuracy and human subjective quality 
in this work we address the human parsing task with a novel contextualized convolutional neural network co cnn architecture which well integrates the cross layer context global image level context semantic edge context within super pixel context and cross super pixel neighborhood context into a unified network given an input human image co cnn produce the pixel wise categorization in an end to end way first the cross layer context is captured by our basic local to global to local structure which hierarchically combine the global semantic information and the local fine detail across different convolutional layer second the global image level label prediction is used a an auxiliary objective in the intermediate layer of the co cnn and it output are further used for guiding the feature learning in subsequent convolutional layer to leverage the global image level context third semantic edge context is further incorporated into co cnn where the high level semantic boundary are leveraged to guide pixel wise labeling finally to further utilize the local super pixel context the within super pixel smoothing and cross super pixel neighbourhood voting are formulated a natural sub component of the co cnn to achieve the local label consistency in both training and testing process comprehensive evaluation on two public datasets well demonstrate the significant superiority of our co cnn over other state of the art for human parsing in particular the f score on the large dataset reach text percent by co cnn significantly higher than text percent and text percent by the state of the art algorithm m cnn and atr respectively by utilizing our newly collected large dataset for training our co cnn can achieve text percent in f score 
the depth image based rendering dibr play a key role in d video synthesis by which other virtual view can be generated from a d video and it depth map however in the synthesis process the background occluded by the foreground object might be exposed in the new view resulting in some hole in the synthetized video in this paper a hole filling approach based on background reconstruction is proposed in which the temporal correlation information in both the d video and it corresponding depth map are exploited to construct a background video to construct a clean background video the foreground object are detected and removed also motion compensation is applied to make the background reconstruction model suitable for moving camera scenario each frame is projected to the current plane where a modified gaussian mixture model is performed the constructed background video is used to eliminate the hole in the synthetized video our experimental result have indicated that the proposed approach ha better quality of the synthetized d video compared with the other method 
statistical model such a linear regression drive numerous application in computer vision and machine learning the landscape of practical deployment of these formulation is dominated by forward regression model that estimate the parameter of a function mapping a set of p covariates x to a response variable y the le known alternative inverse regression offer various benefit that are much le explored in vision problem the goal of this paper is to show how inverse regression in the abundant feature setting i e many subset of feature are associated with the target label or response a is the case for image together with a statistical construction called sufficient reduction yield highly flexible model that are a natural fit for model estimation task in vision specifically we obtain formulation that provide relevance of individual covariates used in prediction at the level of specific example sample in a sense explaining why a particular prediction wa made with no compromise in performance relative to other method an ability to interpret why a learning algorithm is behaving in a specific way for each prediction add significant value in numerous application we illustrate these property and the benefit of abundant inverse regression air on three distinct application 
convolutional neural network cnn are state of the art model for many image classification task however to recognize cancer subtypes automatically training a cnn on gigapixel resolution whole slide tissue image wsi is currently computationally impossible the differentiation of cancer subtypes is based on cellular level visual feature observed on image patch scale therefore we argue that in this situation training a patch level classifier on image patch will perform better than or similar to an image level classifier the challenge becomes how to intelligently combine patch level classification result and model the fact that not all patch will be discriminative we propose to train a decision fusion model to aggregate patch level prediction given by patch level cnns which to the best of our knowledge ha not been shown before furthermore we formulate a novel expectation maximization em based method that automatically locates discriminative patch robustly by utilizing the spatial relationship of patch we apply our method to the classification of glioma and non small cell lung carcinoma case into subtypes the classification accuracy of our method is similar to the inter observer agreement between pathologist although it is impossible to train cnns on wsis we experimentally demonstrate using a comparable non cancer dataset of smaller image that a patch based cnn can outperform an image based cnn 
cascade ha been widely used in face detection where classifier with low computation cost can be firstly used to shrink most of the background while keeping the recall the cascade in detection is popularized by seminal viola jones framework and then widely used in other pipeline such a dpm and cnn however to our best knowledge most of the previous detection method use cascade in a greedy manner where previous stage in cascade are fixed when training a new stage so optimization of different cnns are isolated in this paper we propose joint training to achieve end to end optimization for cnn cascade we show that the back propagation algorithm used in training cnn can be naturally used in training cnn cascade we present how jointly training can be conducted on naive cnn cascade and more sophisticated region proposal network rpn and fast r cnn experiment on face detection benchmark verify the advantage of the joint training 
