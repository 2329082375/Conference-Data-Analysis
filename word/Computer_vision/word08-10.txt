we address the problem of inferring homogeneous reflectance brdf from a single image of a known shape in an unknown real world lighting environment with appropriate representation of lighting and reflectance the image provides bilinear constraint on the two signal and our task is to blindly isolate the latter we achieve this by leveraging the statistic of real world illumination and estimating the reflectance that is most likely under a distribution of probable illumination environment experimental result with a variety of real and synthetic image suggest that useable reflectance information can be inferred in many case and that these estimate are stable under change in lighting 
in this paper we investigate brain hallucination or generating a high resolution brain image from an input low resolution image with the help of another high resolution brain image contrary to interpolation technique the reconstruction process is based on a physical model of image acquisition our contribution is a new regularization approach that us an example based framework integrating non local similarity constraint to handle in a better way repetitive structure and texture the effectiveness of our approach is demonstrated by experiment on realistic magnetic resonance brain image generating automatically high quality hallucinated brain image from low resolution input 
we present a catadioptric projector analogous to a catadioptric camera by combining a commodity digital projector with additional optical unit we show that by using specially shaped reflector refractors catadioptric projector can offer an unprecedented level of flexibility in aspect ratio size and field of view we also present efficient algorithm to reduce projection artifact in catadioptric projector such a distortion scattering and defocusing instead of recovering the reflector refractor geometry our approach directly model the light transport between the projector and the viewpoint using the light transport matrix ltm we show how to efficiently approximate the pseudo inverse of the ltm and apply it to find the optimal input image that produce least projection distortion furthermore we present a projection defocus analysis for reflector and thin refractor based catadioptric projector we show that defocus blur can be interpreted a spatially varying gaussian blur on the input image we then measure the kernel directly from the ltm and apply deconvolution to optimize the input image we demonstrate the practical us of catadioptric projector in panoramic and omni directional projection our new system achieves much wider field of view projection while maintaining sharpness and low geometric and photometric distortion 
in this paper we investigate how to incorporate spatial and or temporal contextual information into classical histogram feature with the aim of boosting visual classification performance firstly we show that the stationary distribution derived from the normalized histogrambin co occurrence matrix characterizes the row sum of the original histogram bin co occurrence matrix this underlying rationale of the histogram bin co occurrence feature then motivates u to propose the concept of general contextualizing histogram process which encodes the spatial and or temporal context a local homogeneity distribution and produce the so called contextualized histogram by convoluting these local homogeneity distribution with the histogram bin index image video finally the third and even higher order contextualized histogram are instantiated for encoding more complicated and informative spatial and or temporal contextual information into histogram we evaluate these proposed method on face recognition and group activity classification problem and the result demonstrate that the contextualized histogram significantly boost the visual classification performance 
matching based on local brightness is quite limited because small change on local appearance invalidate the constancy in brightness the root of this limitation is it treatment regardless of the information from the spatial context this paper leap from brightness constancy to context constancy and thus from optical flow to contextual flow it present a new approach that incorporates context to constrain motion estimation for target tracking in this approach one individual spatial context of a given pixel is represented by the posterior density of the associated feature class in it contextual domain each individual context give a linear contextual flow constraint to the motion so that the motion can be estimated in an over determined contextual system based on this contextual flow model this paper present a new and powerful target tracking method that integrates the process of salient contextual point selection robust contextual matching and dynamic context selection extensive experiment result show the effectiveness of the proposed approach 
in the matching task which form an integral part of all type of tracking and geometrical vision there are invariably prior available on the absolute and or relative image location of feature of interest usually these prior are used post hoc in the process of resolving feature match and obtaining final scene estimate via first get candidate match then resolve consensus algorithm such a ransac in this paper we show that the dramatically different approach of using prior dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operation and lower overall computational cost essentially we put image processing into the loop of the search for global consensus in particular our approach is able to cope with significant image ambiguity thanks to a dynamic mixture of gaussians treatment in our fully bayesian algorithm the choice of the most efficient search action at each step is guided intuitively and rigorously by expected shannon information gain we demonstrate the algorithm in feature matching a part of a sequential slam system for d camera tracking robust real time matching can be achieved even in the previously unmanageable case of jerky rapid motion necessitating weak motion modelling and large search region 
a it ha been noted several time in literature the difficult part of autocalibration effort resides in the structural non linearity of the search for the plane at infinity in this paper we present a robust and versatile autocalibration method based on the enumeration of the inherently bounded space of the intrinsic parameter of two camera in order to find the collineation of space that upgrade a given projective reconstruction to euclidean each sample of the search space which reduces to a finite subset of under mild assumption defines a consistent plane at infinity this in turn produce a tentative approximate euclidean upgrade of the whole reconstruction which is then scored according to the expected intrinsic parameter of a euclidean camera this approach ha been compared with several other algorithm on both synthetic and concrete case obtaining favourable result 
we introduce a morphological approach to curve evolution the differential operator used in the standard pde snake model can be approached using morphological operation on a binary level set by combining the morphological operator associated to the pde component we achieve a new snake evolution algorithm this new solution is based on numerical method which are very simple fast and stable moreover since the level set is just a binary piecewise constant function this approach doe not require to estimate a contour distance function to illustrate the result obtained we present some numerical experiment on real image 
most motion based tracking algorithm assume that object undergo rigid motion which is most likely disobeyed in real world in this paper we present a novel motion based tracking framework which make no such assumption object is represented by a set of local invariant feature whose motion are observed by a feature correspondence process a generative model is proposed to depict the relationship between local feature motion and object global motion whose parameter are learned efficiently by an on line em algorithm and the object global motion is estimated in term of maximum likelihood of observation then an updating mechanism is employed to adapt object representation experiment show that our framework is flexible and robust in dealing with appearance change background clutter illumination change and occlusion 
we present spectral matting a new approach to natural image matting that automatically computes a basis set of fuzzy matting component from the smallest eigenvectors of a suitably defined laplacian matrix thus our approach extends spectral segmentation technique whose goal is to extract hard segment to the extraction of soft matting component these component may then be used a building block to easily construct semantically meaningful foreground matte either in an unsupervised fashion or based on a small amount of user input 
in this paper we propose a novel feature localization method based on a global vector concentration approach our approach doe not rely on the detection of local salient feature around feature point instead we exploit global structural information of the object extracted by calculating the concentration of directional vector from sampling point those vector are combined with local pattern descriptor of a query image and selected from preliminarily trained extended template by nearest neighbor search due to the insensitivity of local change our method can handle partially occluded and noisy object we apply the proposed method to fully automatic feature localization of the left ventricular in echocardiogram the result show the effectiveness of our method in comparison with a conventional edge based method in term of accuracy and robustness 
learning a new object class from cluttered training image is very challenging when the location of object instance is unknown previous work generally require object covering a large portion of the image we present a novel approach that can cope with extensive clutter a well a large scale and appearance variation between object instance to make this possible we propose a conditional random field that start from generic knowledge and then progressively adapts to the new class our approach simultaneously localizes object instance while learning an appearance model specific for the class we demonstrate this on the challenging pascal voc dataset furthermore our method enables to train any state of the art object detector in a weakly supervised fashion although it would normally require object location annotation 
given a photo of person a we seek a photo of person b with similar pose and expression solving this problem enables a form of puppetry in which one person appears to control the face of another when deployed on a webcam equipped computer our approach enables a user to control another person s face in real time this image retrieval inspired approach employ a fully automated pipeline of face analysis technique and is extremely general we can puppet anyone directly from their photo collection or video in which they appear we show several example using image and video of celebrity from the internet 
most existing method of semi supervised clustering introduce supervision from outside e g manually label some data sample or introduce constrains into clustering result this paper study an interesting problem can the supervision come from inside i e the unsupervised training data themselves if the data sample are not independent we can capture the contextual information reflecting the dependency among the data sample and use it a supervision to improve the clustering this is called context aware clustering the investigation is substantialized on two scenario of clustering primitive visual feature e g sift feature with help of spatial context and clustering hand written digit with help of contextual pattern among different type of feature our context aware clustering can be well formulated in a closed form where the contextual information serf a a regularization term to balance the data fidelity in original feature space and the influence of contextual pattern a nested em algorithm is proposed to obtain an efficient solution which prof to converge by exploring the dependent structure of the data sample this method is completely unsupervised a no outside supervision is introduced 
computer user with visual impairment cannot access the rich graphical content in print or digital medium unless relying on visual to tactile conversion which is done primarily by human specialist automated approach to this conversion are an emerging research field in which currently only simple graphic such a diagram are handled this paper proposes a systematic method for automatically converting a human portrait image into it tactile form we model the face based on deformable active shape model asm cootes et al which is enriched by local appearance model in term of gradient profile along the shape the generic face model including the appearance component is learnt from a set of training face image given a new portrait image the prior model is updated through bayesian inference to facilitate the incorporation of a pose dependent appearance model we propose a statistical sampling scheme for the inference task furthermore to compensate for the simplicity of the face model edge segment of a given image are used to enrich the basic face model in generating the final tactile printout experiment are designed to evaluate the performance of the proposed method 
many previous study have shown that naturally occurring data cannot possibly fill up the high dimensional space uniformly rather it must concentrate around lower dimensional structure the typical supervised subspace learning algorithm to discover this low dimensional structure include linear discriminant analysis lda for lda the training data point are usually pre given however in some real world application like relevance feedback image retrieval there is opportunity to interact with the user and actively select the training point for labeling in this paper we propose a novel active subspace learning algorithm which selects the most informative data point and us them for learning an optimal subspace using technique from experimental design we discus how to perform data selection in supervised or semi supervised subspace learning by minimizing the expected error experiment on image retrieval show improvement over state of the art method 
we propose interest seam image an efficient visual synopsis for video to extract an interest seam image a spatiotemporal energy map is constructed for the target video shot then an optimal seam which encompasses the highest energy is identified by an efficient dynamic programming algorithm the optimal seam is used to extract a seam of pixel from each video frame to form one column of an image based on which an interest seam image is finally composited the interest seam image is efficient both in term of computation and memory cost therefore it is able to power a wide variety of web scale video content analysis application such a near duplicate video clip search video genre recognition and classification a well a video clustering etc the representation capacity of the proposed interest seam image is demonstrated in a large scale video retrieval task it advantage are clearly exhibited when compared with previous work a reported in our experiment 
we introduce a novel image segmentation algorithm that us translational symmetry a the primary foreground background separation cue we investigate the process of identifying and analyzing image region that present approximate translational symmetry for the purpose of image fourground background separation in conjunction with texture based inpainting understanding the different see through layer allows u to perform powerful image manipulation such a recovering a meshoccluded background a much a occluded area to achieve the effect of image and photo de fencing our algorithm consists of three distinct phase automatically finding the skeleton structure of a potential frontal layer fence in the form of a deformed lattice separating foreground background layer using appearance regularity and occluded foreground inpainting to reveal a complete non occluded image each of these three task present it own special computational challenge that are not encountered in previous general image de layering or texture inpainting application 
this paper present a novel method for location recognition which exploit an epitomic representation to achieve both high efficiency and good generalization a generative model based on epitomic image analysis capture the appearance and geometric structure of an environment while allowing for variation due to motion occlusion and non lambertian effect the ability to model translation and scale invariance together with the fusion of diverse visual feature yield enhanced generalization with economical training experiment on both existing and new labeled image database result in recognition accuracy superior to state of the art with real time computational performance 
in this paper we propose a new shape decomposition method called convex shape decomposition we formalize the convex decomposition problem a an integer linear programming problem and obtain approximate optimal solution by minimizing the total cost of decomposition under some concavity constraint our method is based on morse theory and combine information from multiple morse function the obtained decomposition provides a compact representation both geometrical and topological of original object our experiment show that such representation is very useful in many application 
an optical diffuser is an element that scatter light and is commonly used to soften or shape illumination in this paper we propose a novel depth estimation method that place a diffuser in the scene prior to image capture we call this approach depth from diffusion dfdiff we show that dfdiff is analogous to conventional depth from defocus dfd where the scatter angle of the diffuser determines the effective aperture of the system the main benefit of dfdiff is that while dfd requires very large aperture to improve depth sensitivity dfdiff only requires an increase in the diffusion angle a much le expensive proposition we perform a detailed analysis of the image formation property of a dfdiff system and show a variety of example demonstrating greater precision in depth estimation when using dfdiff 
fisher s linear discriminant analysis lda one of the most popular dimensionality reduction algorithm for classification ha three particular problem it fails to find the nonlinear structure hidden in the high dimensional data it assumes all sample contribute equivalently to reduce dimension for classification and it suffers from the matrix singularity problem in this paper we propose a new algorithm termed discriminative locality alignment dla to deal with these problem the algorithm operates in the following three stage first in part optimization discriminative information is imposed over patch each of which is associated with one sample and it neighbor then in sample weighting each part optimization is weighted by the margin degree a measure of the importance of a given sample and finally in whole alignment the alignment trick is used to align all weighted part optimization to the whole optimization furthermore dla is extended to the semi supervised case i e semi supervised dla sdla which utilizes unlabeled sample to improve the classification performance thorough empirical study on the face recognition demonstrate the effectiveness of both dla and sdla 
motion blur due to camera shake is an annoying yet common problem in low light photography in this paper we propose a novel method to recover a sharp image from a pair of motion blurred and flash image consecutively captured using a hand held camera we first introduce a robust flash gradient constraint by exploiting the correlation between a sharp image and it corresponding flash image then we formulate our flash deblurring a solving a maximum a posteriori problem under the flash gradient constraint we solve the problem by performing kernel estimation and non blind deconvolution iteratively leading to an accurate blur kernel and a reconstructed image with fine image detail experiment on both synthetic and real image show the superiority of our method compared with existing method 
in this work we propose a hierarchical approach for labeling semantic object and region in scene our approach is reminiscent of early vision literature in that we use a decomposition of the image in order to encode relational and spatial information in contrast to much existing work on structured prediction for scene understanding we bypass a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanic of some approximate inference procedure in graphical model this approach mitigates both the theoretical and empirical difficulty of learning probabilistic model when exact inference is intractable in particular we draw from recent work in machine learning and break the complex inference process into a hierarchical series of simple machine learning subproblems each subproblem in the hierarchy is designed to capture the image and contextual statistic in the scene this hierarchy span coarse to fine region and explicitly model the mixture of semantic label that may be present due to imperfect segmentation to avoid cascading of error and overfitting we train the learning problem in sequence to ensure robustness to likely error earlier in the inference sequence and leverage the stacking approach developed by cohen et al 
we propose an efficient method for complex optimization problem that often arise in computer vision while our method is general and could be applied to various task it wa mainly inspired from problem in computer vision and it borrows idea from scale space theory one of the main motivation for our approach is that searching for the global maximum through the scale space of a function is equivalent to looking for the maximum of the original function with the advantage of having to handle fewer local optimum our method work with any non negative possibly non smooth function and requires only the ability of evaluating the function at any specific point the algorithm is based on a growth transformation which is guaranteed to increase the value of the scale space function at every step unlike gradient method to demonstrate it effectiveness we present it performance on a few computer vision application and show that in our experiment it is more effective than some well established method such a mcmc simulated annealing and the more local nelder mead optimization method 
this paper address the problem of segmenting an image into region consistent with user supplied seed e g a sparse set of broad brush stroke we view this task a a statistical transductive inference in which some pixel are already associated with given zone and the remaining one need to be classified our method relies on the laplacian graph regularizer a powerful manifold learning tool that is based on the estimation of variant of the laplace beltrami operator and is tightly related to diffusion process segmentation is modeled a the task of finding matting coefficient for unclassified pixel given known matting coefficient for seed pixel the proposed algorithm essentially relies on a high margin assumption in the space of pixel characteristic it is simple fast and accurate a demonstrated by qualitative result on natural image and a quantitative comparison with state of the art method on the microsoft grabcut segmentation database 
we propose a method based on sparse representation sr to cluster data drawn from multiple low dimensional linear or affine subspace embedded in a high dimensional space our method is based on the fact that each point in a union of subspace ha a sr with respect to a dictionary formed by all other data point in general finding such a sr is np hard our key contribution is to show that under mild assumption the sr can be obtained exactly by using optimization the segmentation of the data is obtained by applying spectral clustering to a similarity matrix built from this sr our method can handle noise outlier a well a missing data we apply our subspace clustering algorithm to the problem of segmenting multiple motion in video experiment on video sequence show that our approach significantly outperforms state of the art method 
capturing multiple photo at different focus setting is a powerful approach for reducing optical blur but how many photo should we capture within a fixed time budget we develop a framework to analyze optimal capture strategy balancing the tradeoff between defocus and sensor noise incorporating uncertainty in resolving scene depth we derive analytic formula for restoration error and use monte carlo integration over depth to derive optimal capture strategy for different camera design under a wide range of photographic scenario we also derive a new upper bound on how well spatial frequency can be preserved over the depth of field our result show that by capturing the optimal number of photo a standard camera can achieve performance at the level of more complex computational camera in all but the most demanding of case we also show that computational camera although specifically designed to improve one shot performance generally benefit from capturing multiple photo a well 
linear discriminant analysis lda is a popular tool for multiclass discriminative dimensionality reduction however lda suffers from two major problem it only optimizes the bayes error for the case of unimodal gaussian class with equal covariance assuming full rank matrix and the multiclass extension maximizes the sum of pairwise distance between the class and doe not simultaneously maximize each pairwise distance between the class this typically result in serious overlapping in the projected space between class that are close in the input space to solve these two problem this paper proposes pareto discriminant analysis parda firstly parda explicitly model each of the class a a multidimensional gaussian with a sample covariance secondly parda decomposes the multiclass problem to a set of pairwise objective function representing the pairwise distance between different class unlike existing extension of fisher discriminant analysis fda to multiclass problem that typically maximize the sum of pairwise distance between class parda simultaneously maximizes each pairwise distance thus encouraging the case that all class are equidistant from each other in the lower dimensional space solving parda is a multiobjective optimization problem simultaneously optimizing more than one possibly conflicting objective function and the resulting solution is known to be pareto optimal experimental result on synthetic data several image data set and data set from the uci repository show positive and encouraging result in favor of parda when compared with standard and state of the art multiclass extension of lda 
multi view stereo mv algorithm now produce reconstruction that rival laser range scanner accuracy however stereo algorithm require textured surface and therefore work poorly for many architectural scene e g building interior with textureless painted wall this paper present a novel mv approach to overcome these limitation for manhattan world scene i e scene that consists of piece wise planar surface with dominant direction given a set of calibrated photograph we first reconstruct textured region using an existing mv algorithm then extract dominant plane direction generate plane hypothesis and recover per view depth map using markov random field we have tested our algorithm on several datasets ranging from office interior to outdoor building and demonstrate result that outperform the current state of the art for such texture poor scene 
a a fundamental problem in pattern recognition graph matching ha application in a variety of field from computer vision to computational biology in graph matching pattern are modeled a graph and pattern recognition amount to finding a correspondence between the node of different graph many formulation of this problem can be cast in general a a quadratic assignment problem where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility the main research focus in this theme is about designing efficient algorithm for approximately solving the quadratic assignment problem since it is np hard in this paper we turn our attention to a different question how to estimate compatibility function such that the solution of the resulting graph matching problem best match the expected solution that a human would manually provide we present a method for learning graph matching the training example are pair of graph and the label are match between them our experimental result reveal that learning can substantially improve the performance of standard graph matching algorithm in particular we find that simple linear assignment with such a learning scheme outperforms graduated assignment with bistochastic normalisation a state of the art quadratic assignment relaxation algorithm 
motion blur retains some information about motion based on which motion may be recovered from blurred image this is a difficult problem a the situation of motion blur can be quite complicated such a they may be space variant nonlinear and local this paper address a very challenging problem can we recover motion blindly from a single motion blurred image a major contribution of this paper is a new finding of an elegant motion blur constraint exhibiting a very similar mathematical form a the optical flow constraint this linear constraint applies locally to pixel in the image therefore a number of challenging problem can be addressed including estimating global affine motion blur estimating global rotational motion blur estimating and segmenting multiple motion blur and estimating nonparametric motion blur field extensive experiment on blur estimation and image deblurring on both synthesized and real data demonstrate the accuracy and general applicability of the proposed approach 
periodicity is at the core of the recognition of many action this paper take the following step to detect and measure periodicity we establish a conceptual framework of classifying periodicity in essential case the most important of which are flashing of a traffic light pulsing of an anemone swinging of wing spinning of a swimmer turning of a conductor shuttling of a brush drifting of an escalator and thrusting of a kangaroo we present an algorithm to detect all case by the one and the same algorithm it track the object independent of the object s appearance then performs probabilistic pca and spectral analysis followed by detection and frequency measurement the method show good performance with fixed parameter for example of all above case assembled from the internet application of the method completely unaltered to a random half hour of cnn news ha led to an score 
we propose a novel tracking algorithm that can work robustly in a challenging scenario such that several kind of appearance and motion change of an object occur at the same time our algorithm is based on a visual tracking decomposition scheme for the efficient design of observation and motion model a well a tracker in our scheme the observation model is decomposed into multiple basic observation model that are constructed by sparse principal component analysis spca of a set of feature template each basic observation model cover a specific appearance of the object the motion model is also represented by the combination of multiple basic motion model each of which cover a different type of motion then the multiple basic tracker are designed by associating the basic observation model and the basic motion model so that each specific tracker take charge of a certain change in the object all basic tracker are then integrated into one compound tracker through an interactive markov chain monte carlo imcmc framework in which the basic tracker communicate with one another interactively while run in parallel by exchanging information with others each tracker further improves it performance which result in increasing the whole performance of tracking experimental result show that our method track the object accurately and reliably in realistic video where the appearance and motion are drastically changing over time 
in this paper we address the issue of transducing the object cutout model from an example image to novel image instance we observe that although object and background are very likely to contain similar color in natural image it is much le probable that they share similar color configuration motivated by this observation we propose a local color pattern model to characterize the color configuration in a robust way additionally we propose an edge profile model to modulate the contrast of the image which enhances edge along object boundary and attenuates edge inside object or background the local color pattern model and edge model are integrated in a graph cut framework higher accuracy and improved robustness of the proposed method are demonstrated through experimental comparison with state of the art algorithm 
in this paper we investigate the detection of semantic human action in complex scene unlike conventional action recognition in well controlled environment action detection in complex scene suffers from cluttered background heavy crowd occluded body and spatial temporal boundary ambiguity caused by imperfect human detection and tracking conventional algorithm are likely to fail with such spatial temporal ambiguity in this work the candidate region of an action are treated a a bag of instance then a novel multiple instance learning framework named smile svm simulated annealing multiple instance learning support vector machine is presented for learning human action detector based on imprecise action location smile svm is extensively evaluated with satisfactory performance on two task human action detection on a public video action database with cluttered background and a real world problem of detecting whether the customer in a shopping mall show an intention to purchase the merchandise on shelf even if they didn t buy it eventually in addition the complementary nature of motion and appearance feature in action detection are also validated demonstrating a boosted performance in our experiment 
prominent feature point descriptor such a sift and surf allow reliable real time matching but at a computational cost that limit the number of point that can be handled on pc and even more on le powerful mobile device a recently proposed technique that relies on statistical classification to compute signature ha the potential to be much faster but at the cost of using very large amount of memory which make it impractical for implementation on low memory device in this paper we show that we can exploit the sparseness of these signature to compact them speed up the computation and drastically reduce memory usage we base our approach on compressive sensing theory we also highlight it effectiveness by incorporating it into two very different slam package and demonstrating substantial performance increase 
we explore the problem of reconstructing an image from a bag of square non overlapping image patch the jigsaw puzzle problem completing jigsaw puzzle is challenging and requires expertise even for human and is known to be np complete we depart from previous method that treat the problem a a constraint satisfaction problem and develop a graphical model to solve it each patch location is a node and each patch is a label at node in the graph a graphical model requires a pairwise compatibility term which measure an affinity between two neighboring patch and a local evidence term which we lack this paper discus way to obtain these term for the jigsaw puzzle problem we evaluate several patch compatibility metric including the natural image statistic measure and experimentally show that the dissimilarity based compatibility measuring the sum of squared color difference along the abutting boundary give the best result we compare two form of local evidence for the graphical model a sparse and accurate evidence and a dense and noisy evidence we show that the sparse and accurate evidence fixing a few a patch at their correct location is enough to reconstruct image consisting of over patch to the best of our knowledge this is the largest puzzle solved in the literature we also show that one can coarsely estimate the low resolution image from a bag of patch suggesting that a bag of image patch encodes some geometric information about the original image 
image matting is the task of estimating a foreand background layer from a single image to solve this ill posed problem an accurate modeling of the scene s appearance is necessary existing method that provide a closed form solution to this problem assume that the color of the foreground and background layer are locally linear in this paper we show that such model can be an overfit when the color of the two layer are locally constant we derive new closed form expression in such case and show that our model are more compact than existing one in particular the null space of our cost function is a subset of the null space constructed by existing approach we discus the bias towards specific solution for each formulation experiment on synthetic and real data confirm that our compact model estimate alpha matte more accurately than existing technique without the need of additional user interaction 
abstract high angular resolution diffusion imaging ha become an important magnetic resonance technique for in vivo imaging most current research in this field focus on developing method for computing the orientation distribution function odf which is the probability distribution function of water molecule diffusion along any angle on the sphere in this paper we present a riemannian framework to carry out computation on an odf field the proposed framework doe not require that the odfs be represented by any fixed parameterization such a a mixture of von mi fisher distribution or a spherical harmonic expansion instead we use a non parametric representation of the odf and exploit the fact that under the square root re parameterization the space of odfs form a riemannian manifold namely the unit hilbert sphere specifically we use riemannian operation to perform various geometric data processing algorithm such a interpolation convolution and linear and nonlinear filtering we illustrate these concept with numerical experiment on synthetic and real datasets 
this paper address the problem of recognizing shadow from monochromatic natural image without chromatic information shadow classification is very challenging because the invariant color cue are unavailable natural scene make this problem even harder because of ambiguity from many near black object we propose to use both shadow variant and shadow invariant cue from illumination textural and odd order derivative characteristic such feature are used to train a classifier from boosting a decision tree and integrated into a conditional random field which can enforce local consistency over pixel label the proposed approach is evaluated using both qualitative and quantitative result based on a novel database of hand labeled shadow our result show shadowed area of an image can be identified using proposed monochromatic cue 
pictorial structure p model are extensively used for part based recognition of scene people animal and multi part object to achieve tractability the structure and parameterization of the model is often restricted for example by assuming tree dependency structure and unimodal data independent pairwise interaction these expressivity restriction fail to capture important pattern in the data on the other hand local method such a nearest neighbor classification and kernel density estimation provide nonparametric flexibility but require large amount of data to generalize well we propose a simple semi parametric approach that combine the tractability of pictorial structure inference with the flexibility of non parametric method by expressing a subset of model parameter a kernel regression estimate from a learned sparse set of exemplar this yield query specific image dependent pose prior we develop an effective shape based kernel for upper body pose similarity and propose a leave one out loss function for learning a sparse subset of exemplar for kernel regression we apply our technique to two challenging datasets of human figure parsing and advance the state of the art from to on the buffy dataset while using only of the training data a exemplar 
action in real world application typically take place in cluttered environment with large variation in the orientation and scale of the actor we present an approach to simultaneously track and recognize known action that is robust to such variation starting from a person detection in the standing pose in our approach we first render synthetic pose from multiple viewpoint using mocap data for known action and represent them in a conditional random field crf whose observation potential are computed using shape similarity and the transition potential are computed using optical flow we enhance these basic potential with term to represent spatial and temporal constraint and call our enhanced model the shape flow durationconditional random field sfd crf we find the best sequence of action using viterbi search in the sfd crf we demonstrate our approach on video from multiple viewpoint and in the presence of background clutter 
we propose a branch and bound algorithm to obtain the globally optimal relative rotation between a camera and the rotation sensor attached to it compared to previous method our approach directly minimizes the image space error related to the measurement which is very natural for camera based system our algorithm is based on the observation that we may evaluate the residual when the rotation matrix is known we propose a feasibility test algorithm for the branch and bound to efficiently reduce the search volume of the rotation domain experimental result are provided using synthetic and real data set 
we propose a new method for detecting object such a bag carried by pedestrian depicted in short video sequence in common with earlier work on the same problem the method start by averaging aligned foreground region of a walking pedestrian to produce a representation of motion and shape known a a temporal template that ha some immunity to noise in foreground segmentation and phase of the walking cycle our key novelty is for carried object to be revealed by comparing the temporal template against view specific exemplar generated offline for unencumbered pedestrian a likelihood map obtained from this match is combined in a markov random field with a map of prior probability for carried object and a spatial continuity assumption from which we obtain a segmentation of carried object using the map solution we have re implemented the earlier state of the art method and demonstrate a substantial improvement in performance for the new method on the challenging pet dataset although developed for a specific problem the method could be applied to the detection of irregularity in appearance for other category of object that move in a periodic fashion 
learning a discriminant becomes substantially more difficult when the datasets are high dimensional and the available sample are few this is often the case in computer vision and medical diagnosis application a novel conic section classifier csc wa recently introduced in the literature to handle such datasets wherein each class wa represented by a conic section parameterized by it focus directrix and eccentricity the discriminant boundary wa the locus of all point that are equi eccentric relative to each class representative conic section simpler boundary were preferred for the sake of generalizability in this paper we improve the performance of the two class classifier via a large margin pursuit when formulated a a non linear optimization problem the margin computation is demonstrated to be hard especially due to the high dimensionality of the data instead we present a geometric algorithm to compute the distance of a point to the nonlinear discriminant boundary generated by the csc in the input space we then introduce a large margin pursuit in the learning phase so a to enhance the generalization capacity of the classifier we validate the algorithm on real datasets and show favorable classification rate in comparison to many existing state of the art binary classifier a well a the csc without margin pursuit 
this paper address the problem of recovering d human pose from a single monocular image using a discriminative bag of word approach in previous work the visual word are learned by unsupervised clustering algorithm they capture the most common pattern and are good feature for coarse grain recognition task like object classification but for those task which deal with subtle difference such a pose estimation such representation may lack the needed discriminative power in this paper we propose to jointly learn the visual word and the pose regressors in a supervised manner more specifically we learn an individual distance metric for each visual word to optimize the pose estimation performance the learned metric rescale the visual word to suppress unimportant dimension such a those corresponding to background another contribution is that we design an appearance and position context apc local descriptor that achieves both selectivity and invariance while requiring no background subtraction we test our approach on both a quasi synthetic dataset and a real dataset humaneva to verify it effectiveness our approach also achieves fast computational speed thanks to the integral histogram used in apc descriptor extraction and fast inference of pose regressors 
with the rise of photo sharing website such a facebook and flickr ha come dramatic growth in the number of photograph online recent research in object recognition ha used such site a a source of image data but the test image have been selected and labeled by hand yielding relatively small validation set in this paper we study image classification on a much larger dataset of million image including nearly million of which have been labeled into one of category the dataset and category are formed automatically from geotagged photo from flickr by looking for peak in the spatial geotag distribution corresponding to frequently photographed landmark we learn model for these landmark with a multiclass support vector machine using vector quantized interest point descriptor a feature we also explore the non visual information available on modern photo sharing site showing that using textual tag and temporal constraint lead to significant improvement in classification rate we find that in some case image feature alone yield comparable classification accuracy to using text tag a well a to the performance of human observer 
we present a method for learning discriminative linear feature extraction using independent task more concretely given a target classification task we consider a complementary classification task that is independent of the target one for example in face classification field subject recognition can be a target task while facial expression classification can be a complementary task then we use label of the complementary task in order to obtain a more robust feature extraction being the new feature space le sensitive to the complementary classification to learn the proposed feature extraction we use the mutual information measure between the projected data and both label from the target and the complementary task in our experiment this framework ha been applied to a face recognition problem in order to inhibit this classification task from environmental artifact and to mitigate the effect of the small sample size problem our classification experiment show an improved feature extraction process using the proposed method 
recent work in multiple view geometry ha focused on obtaining globally optimal solution at the price of computational time efciency on the other hand traditional bundle adjustment algorithm have been found to provide good solution even though there may be multiple local minimum in this paper we justify this observation by giving a simple sufcient condition for global optimality that can be used to verify that a solution obtained from any local method is indeed global the method is tested on numerous problem instance of both synthetic and real data set in the vast majority of case we are able to verify that the solution are optimal in particular for small scale problem we also develop a branch and bound procedure that go beyond verication in case where the sufcient condition doe not hold the algorithm return either of the following two result i a certicate of global optimality for the local solution or ii the global solution 
image contour detection is fundamental to many image analysis application including image segmentation object recognition and classification however highly accurate image contour detection algorithm are also very computationally intensive which limit their applicability even for offline batch processing in this work we examine efficient parallel algorithm for performing image contour detection with particular attention paid to local image analysis a well a the generalized eigensolver used in normalized cut combining these algorithm into a contour detector along with careful implementation on highly parallel commodity processor from nvidia our contour detector provides uncompromised contour accuracy with an f metric of on the berkeley segmentation dataset runtime is reduced from minute to second the efficiency gain we realize enable high quality image contour detection on much larger image than previously practical and the algorithm we propose are applicable to several image segmentation approach efficient scalable yet highly accurate image contour detection will facilitate increased performance in many computer vision application 
in this paper we propose a new approach to camera calibration from silhouette under circular motion with minimal data we exploit the mirror symmetry property and derive a common homography that relates silhouette with epipoles under circular motion with the epipoles determined the homography can be computed from the frontier point induced by epipolar tangency on the other hand given the homography the epipoles can be located directly from the bitangent line of silho uettes with the homography recovered the image invariant under circular motion and camera parameter can be determined if the epipoles are not available camera parameter can be determined by a lowdimensional s earch of the optimal homography in a bounded region in the degenerate case when the camera optical ax intersect at one point we derive a closedform solution for the focal length to solve the problem by using the proposed algorithm we can achieve camera calibration simply from silhouette of three image captured under circular motion experimental result on synthetic and real image are presented to show it performance 
most current d face recognition algorithm are designed based on the data collected in controlled situation which lead to the un guaranteed performance in practical system in this paper we propose a robust local loggabor histogram rllgh method to handle the uncontrolled problem encountered in d face recognition in this challenging topic large expression and data noise are two main obstacle to overcome the large expression we choose log gabor feature lgf to extract the distinctive and robust information embedded in d face which will be represented a d log gabor face data noise are summarized a distorted mesh hair occlusion and misalignment to overcome these problem we introduce a robust local histogram rlh strategy which take advantage of the robustness of the accurate local statistical information the combination of lgf and rlh lead to rllgh the novelty of this paper come from our work aimsat studying d facerecognitionperformancein uncontrolled environment we find that embedding lgf into the lvc framework lead to robustness in handling large expression variation the rlh strategy give a promising way to solve the data noise problem our experiment are based on the large expression subset in frgc d face database and the expression subset in casia d face database experimental result show the efficiency robustness and generalization of our proposed method 
for most iris capturing scenario captured iris image could easily blur when the user is out of the depth of field dof of the camera or when he or she is moving the common solution is to let the user try the capturing process again a the quality of these blurred iris image is not good enough for recognition in this paper we propose a novel iris deblurring algorithm that can be used to improve the robustness and nonintrusiveness for iris capture unlike other iris deblurring algorithm the key feature of our algorithm is that we use the domain knowledge inherent in iris image and iris capture setting to improve the performance which could be in the form of iris image statistic characteristic of pupil or highlight or even depth information from the iris capturing system itself our experiment on both synthetic and real data demonstrate that our deblurring algorithm can significantly restore blurred iris pattern and therefore improve the robustness of iris capture 
we present a theoretical analysis for characterizing the shadow cast by a point light source given it relative position to the camera in particular we analyze the epipolar geometry of camera light pair including unusual cameralight configuration such a light source aligned with the camera s optical axis a well a convenient arrangement such a light placed in the camera plane a mathematical characterization of the shadow is derived to determine the orientation and location of depth discontinuity when projected onto the image plane that could potentially be associated with cast shadow the resulting theory is applied to compute a lower bound on the number of light needed to extract all depth discontinuity from a general scene using a multiflash camera we also provide a characterization of which discontinuity are missed and which are correctly detected by the algorithm and a foundation for choosing an optimal light placement experiment with depth edge computed using two flash setup and a four flash setup illustrate the theory and an additional configuration with a flash at the camera s center of projection is exploited a a solution for some degenerate case 
this article present a new method for non rigid surface registration between a surface model and a surface of an internal organ in a given d medical image the surface is represented with a set of feature point of which location are represented by a graphical model for constructing the representation a set of corresponding point is distributed on each of training surface based on an entropy based particle system from these corresponding point we estimate probability density of the location of each feature point the conditional probability distribution of the local image pattern around each feature point and the probability distribution of relative position between two neighboring feature point when a new image is given these density are used for estimating the location of each feature point by mean of a non parametric belief propagation the proposed method can estimate not only the location of the feature point but also their conditional marginal distribution in a given image some experimental result obtained from real x ct image are presented to show it performance 
a new hierarchical bayesian model is proposed for image segmentation based on gaussian mixture model gmm with a prior enforcing spatial smoothness according to this prior the local difference of thecontextual mixing proportion i e the probability of class label are student s t distributed the generative property of the student s t pdf allow this prior to impose smoothness and simultaneously model the edge between the segment of the image a maximum a posteriori map expectationmaximization em based algorithm is used for bayesian inference an important feature of this algorithm is that all the parameter are automatically estimated from the data in closed form numerical experiment are presented that demonstrate the superiority of the proposed model for image segmentation a compared to standard gmm based approach and to gmm segmentation technique with standard spatial smoothness constraint 
we propose a novel probabilistic framework for learning visual model of d object category by combining appearance information and geometric constraint object are represented a a coherent ensemble of part that are consistent under d viewpoint transformation each part is a collection of salient image feature a generative framework is used for learning a model that capture the relative position of part within each of the discretized viewpoint contrary to most of the existing mixture of viewpoint model our model establishes explicit correspondence of par t across different viewpoint of the object class given a new image detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition score of the candidate object our approach is among the first to propose a generative probabilistic framework for d object categorization we test ou r algorithm on the detection task and the viewpoint classification task by using car category from both the savarese et al and pascal voc datasets we show promising result in both the detection and viewpoint classification task on these two challenging datasets 
in this paper we present a multi label sparse coding framework for feature extraction and classification within the context of automatic image annotation first each image is encoded into a so called supervector derived from the universal gaussian mixture model on orderless image patch then a label sparse coding based subspace learning algorithm is derived to effectively harness multi label information for dimensionality reduction finally the sparse coding method for multi label data is proposed to propagate the multi label of the training image to the query image with the sparse reconstruction coefficient extensive image annotation experiment on the corel k and corel k database both show the superior performance of the proposed multi label sparse coding framework over the state of the art algorithm 
we study the problem of estimating the epipolar geometry from apparent contour of smooth curved surface with affine camera model since apparent contour are viewpoint dependent the only true image correspondence are projection of the frontier point i e surface point whose tangent plane are also their epipolar plane however frontier point are unknown a priori and must be estimated simultaneously with epipolar geometry previous approach to this problem adopt local greedy search method which are sensitive to initialization and may get trapped in local minimum we propose the first algorithm that guarantee global optimality for this problem we first reformulate the problem using a separable form that allows u to search effectively in a d space instead of on a d hypersphere in the classical formulation next in a branch and bound algorithm we introduce a novel lower bounding function through interval matrix analysis experimental result on both synthetic and real scene demonstrate that the proposed method is able to quickly obtain the optimal solution 
this paper proposes a new joint parametric and nonparametric curve evolution algorithm of the level set function for medical image segmentation traditional level set algorithm employ non parametric curve evolution for object matching although matching image boundary accurately they often suffer from local minimum and generate incorrect segmentation of object shape especially for image with noise occlusion and low contrast on the other hand statistical model based segmentation method allow parametric object shape variation subject to some shape prior constraint and they are more robust in dealing with noise and low contrast in this paper we combine the advantage of both of these method and jointly use parametric and non parametric curve evolution in object matching our new joint curve evolution algorithm is a robust a and at the same time yield more accurate segmentation result than the parametric method using shape prior information comparative result on segmenting ventricle frontal horn and putamen shape in mr brain image confirm both robustness and accuracy of the proposed joint curve evolution algorithm 
most algorithm for real time tracking of deformable shape provide sub optimal solution for a suitable energy minimization task the search space is typically considered too large to allow for globally optimal solution in this paper we show that under reasonable constraint on the object motion one can guarantee global optimality while maintaining real time requirement the problem is cast a finding the optimal cycle in a graph spanned by the prior template and the image the underlying combinatorial algorithm is implemented on state ofthe art graphic hardware solution on fpgas are conceivable experimental result demonstrate long term tracking of car in real time while coping with challenging weather condition in particular we show that the proposed tracking algorithm is highly robust to illumination change and that it outperforms local tracking method such a the level set method 
we present an approach for online learning of discriminative appearance model for robust multi target tracking in a crowded scene from a single camera although much progress ha been made in developing method for optimal data association there ha been comparatively le work on the appearance model which are key element for good performance many previous method either use simple feature such a color histogram or focus on the discriminability between a target and the background which doe not resolve ambiguity between the different target we propose an algorithm for learning a discriminative appearance model for different target training sample are collected online from tracklets within a time sliding window based on some spatial temporal constraint this allows the model to adapt to target instance learning us an ad aboost algorithm that combine effective image descriptor and their corresponding similarity measurement we term the learned model a oldams our evaluation indicate that oldams have significantly higher discrimination between different target than conventional holistic color histogram and when integrated into a hierarchical association framework they help improve the tracking accuracy particularly reducing the false alarm and identity switch 
image annotation ha been an active research topic in the recent year due to it potentially large impact on both image understanding and web database image search in this paper we target at solving the automatic image annotation problem in a novel semi supervised learning framework a novel multi label correlated green s function approach is proposed to annotate image over a graph the correlation among label are integrated into the objective function which improves the performance significantly we also propose a new adaptive decision boundary method for multi label assignment to deal with the difficulty of label assignment in most of the existing rank based multi label classification algorithm instead of setting the threshold heuristically or by experience our method principally compute it upon the prior knowledge in the training data we perform our method on three commonly used image annotation testing data set experimental result show significant improvement on classification performance over four other state of the art method a a general semi supervised learning framework other local feature based image annotation method could be easily incorporated into our framework to improve the performance 
over the year many tensor based algorithm e g two dimensional principle component analysis dpca two dimensional singular value decomposition dsvd high order svd have been proposed for the study of high dimensional data in a large variety of computer vision application an intrinsic limitation of previous tensor reduction method is the sensitivity to the presence of outlier because they minimize the sum of square error l norm in this paper we propose a novel robust tensor factorization method using r norm for error accumulation function using robust covariance matrix allowing the method to be efficiently implemented instead of resorting to quadratic programming software package a in other l norm approach experimental result on face representation and reconstruction show that our new robust tensor factorization method can effectively handle outlier compared to previous tensor based pca method 
this paper address human pose recognition from video sequence by formulating it a a classification problem unlike much previous work we do not make any assumption on the availability of clean segmentation the first step of this work consists in a novel method of aligning the training image using d mocap data next we define class by discretizing a d manifold whose two dimension are camera viewpoint and action our main contribution is a pose detection algorithm based on random forest a bottomup approach is followed to build a decision tree by recursively clustering and merging the class at each level for each node of the decision tree we build a list of potentially discriminative feature using the alignment of training image in this paper we consider histogram of orientated gradient hog we finally grow an ensemble of tree by randomly sampling one of the selected hog block at each node our proposed approach give promising result with both fixed and moving camera 
in this paper we propose a new computational model for visual saliency derived from the information maximization principle the model is inspired by a few well acknowledged biological fact to compute the saliency spot of an image the model first extract a number of sub band feature map using learned sparse code it adopts a fully connected graph representation for each feature map and run random walk on the graph to simulate the signal information transmission among the interconnected neuron we propose a new visual saliency measure called site entropy rate ser to compute the average information transmitted from a node neuron to all the others during the random walk on the graph network this saliency definition also explains the center surround mechanism from computation aspect we further extend our model to spatial temporal domain so a to detect salient spot in video to evaluate the proposed model we do extensive experiment on psychological stimulus two well known image data set a well a a public video dataset the experiment demonstrate encouraging result that the proposed model achieves the state of the art performance of saliency detection in both still image and video 
this paper describes a coarse to fine learning based image registration algorithm which ha particular advantage in dealing with multi modality image many existing image registration algorithm use a few designed term or mutual information to measure the similarity between image pair instead we push the learning aspect by selecting and fusing a large number of feature for measuring the similarity moreover the similarity measure is carried in a coarse to fine strategy global similarity measure is first performed to roughly locate the component we then learn compute similarity on the local image patch to capture the fine level information when estimating the transformation parameter we also engage a coarse tofine strategy off the shelf interest point detector such a sift have degraded result on medical image we further push the learning idea to extract the main structure landmark our algorithm is illustrated on three application registration of mouse brain image of different modality registering human brain image of mri t and t image face of different expression we show greatly improved result over the existing algorithm based on either mutual information or geometric structure 
oriented pattern e g fingerprint consist of smoothly varying flow like pattern together with important singular point i e core and delta where the orientation change abruptly gabor filter and anisotropic diffusion method have been widely used to enhance oriented pattern however none of them can well cope with region of varying curvature or region surrounding singular point by incorporating the ridge curvature and the singularity into the diffusion model we propose a new diffusion method to better exploit the global characteristic of oriented pattern specifically we first locate the singular point and regularize the estimated orientation field by using a singularity driven nonlinear diffusion process we then enhance the oriented pattern by applying an oriented diffusion process which is driven by the curvature and singularity experiment on synthetic data and real fingerprint image validated that the proposed method is capable of consistently enhancing oriented pattern while well preserving the ridge structure in singular region 
nonlinear registration is mostly performed after initialization by a global linear transformation in this work we focus on similarity transformation computed by a linear registration method for the further processing of the result it is mostly assumed that this preregistration step completely remove the respective linear transformation however we show that in deformable setting this is not the case a a consequence a significant linear component is still existent in the deformation computed by the nonlinear registration algorithm for construction of statistical shape model ssm from deformation this is an unwanted property ssms should not contain similarity transformation since these do not capture information about shape we propose a method which performs an a posteriori extraction of a similarity transformation from a given nonlinear deformation field and we use the processed field a input for ssm construction for computation of minimal displacement a closed form solution minimizing the squared euclidean norm of the displacement field subject to similarity parameter is used experiment on real inter subject data and on a synthetic example show that the theoretically justified removal of the similarity component by the proposed method ha a large influence on the shape model and significantly improves the result 
we propose a novel nonparametric bayesian model dual hierarchical dirichlet process dual hdp for trajectory analysis and semantic region modeling in surveillance setting in an unsupervised way in our approach trajectory are treated a document and observation of an object on a trajectory are treated a word in a document trajectory are clustered into different activity abnormal trajectory are detected a sample with low likelihood the semantic region which are intersection of path commonly taken by object related to activity in the scene are also modeled dual hdp advance the existing hierarchical dirichlet process hdp language model hdp only cluster co occurring word from document into topic and automatically decides the number of topic dual hdp co cluster both word and document it learns both the number of word topic and document cluster from data under our problem setting hdp only cluster observation of object while dual hdp cluster both observation and trajectory experiment are evaluated on two data set radar track collected from a maritime port and visual track collected from a parking lot 
hidden state shape model hssms were previously proposed to represent and detect object in image that exhibit not just deformation of their shape but also variation in their structure in this paper we introduce dynamic hidden state shape model dhssms to track and recognize the non rigid motion of such object for example human hand our recursive bayesian filtering method called dp tracking combine an exhaustive local search for a match between image feature and model state with a dynamic programming approach to find a global registration between the model and the object in the image our contribution is a technique to exploit the hierarchical structure of the dynamic programming approach that on average considerably speed up the search for match we also propose to embed an online learning approach into the tracking mechanism that update the dhssm dynamically the learning approach ensures that the dhssm accurately represents the tracked object and distinguishes any clutter potentially present in the image our experiment show that our method can recognize the digit of a hand while the finger are being moved and curled to various degree the method is robust to various illumination condition the presence of clutter occlusion and some type of self occlusion the experiment demonstrate a significant improvement in both efficiency and accuracy of recognition compared to the non recursive way of frame by frame detection 
estimating the illumination and the reflectance property of an object surface from a sparse set of image is an important but inherently ill posed problem the problem becomes even harder if we wish to account for the spatial variation of material property on the surface in this paper we derive a novel method for estimating the spatially varying specular reflectance property of a surface of known geometry a well a the illumination distribution from a specular only image for instance captured using polarization to separate reflection component unlike previous work we do not assume the illumination to be a single point light source we model specular reflection with a spherical statistical distribution and encode the spatial variation with radial basis function of it parameter this allows u to formulate the simultaneous estimation of spatially varying specular reflectance and illumination a a sound probabilistic inference problem in particular using csiszar s i divergence measure to solve it we derive an iterative algorithm similar to expectation maximization we demonstrate the effectiveness of the method on synthetic and real world scene 
identifying handled object i e object being manipulated by a user is essential for recognizing the person s activity an egocentric camera a worn on the body enjoys many advantage such a having a natural first person view and not needing to instrument the environment it is also a challenging setting where background clutter is known to be a major source of problem and is difficult to handle with the camera constantly and arbitrarily moving in this work we develop a bottom up motion based approach to robustly segment out foreground object in egocentric video and show that it greatly improves object recognition accuracy our key insight is that egocentric video of object manipulation is a special domain and many domain specific cue can readily help we compute dense optical flow and fit it into multiple affine layer we then use a max margin classifier to combine motion with empirical knowledge of object location and background movement a well a temporal cue of support region and color appearance we evaluate our segmentation algorithm on the large intel egocentric object recognition dataset with object and k frame we show that when combined with temporal integration figure ground segmentation improves the accuracy of a sift based recognition system from to and that of a latent hog system from to 
constrained local model clms have recently demonstrated good performance in non rigid object alignment tracking in comparison to leading holistic approach e g aams a major problem hindering the development of clms further for non rigid object alignment tracking is how to jointly optimize the global warp update across all local search response previous method have either used general purpose optimizers e g simplex method or graph based optimization technique unfortunately problem exist with both these approach when applied to clms in this paper we propose a new approach for optimizing the global warp update in an efficient manner by enforcing convexity at each local patch response surface furthermore we show that the classic lucas kanade approach to gradient descent image alignment can be viewed a a special case of our proposed framework finally we demonstrate that our approach receives improved performance for the task of non rigid face alignment tracking on the multipie database and the unbc mcmaster archive 
object recognition accuracy can be improved when information from multiple view is integrated but information in each view can often be highly redundant we consider the problem of distributed object recognition or indexing from multiple camera where the computational power available at each camera sensor is limited and communication between camera is prohibitively expensive in this scenario it is desirable to avoid sending redundant visual feature from multiple view traditional supervised feature selection approach are inapplicable a the class label is unknown at each camera in this paper we propose an unsupervised multi view feature selection algorithm based on a distributed coding approach with our method a gaussian process model of the joint view statistic is used at the receiver to obtain a joint encoding of the view without directly sharing information across encoders we demonstrate our approach on recognition and indexing task with multi view image database and show that our method compare favorably to an independent encoding of the feature from each camera 
this article proposes a method for learning object template composed of local sketch and local texture and investigates the relative importance of the sketch and texture for different object category local sketch and local texture in the object template account for shape and appearance respectively both local sketch and local texture are extracted from the map of gabor filter response the local sketch are captured by the local maximum of gabor response where the local maximum pooling account for shape deformation in object the local texture are captured by the local average of gabor filter response where the local average pooling extract texture information for appearance the selection of local sketch variable and local texture variable can be accomplished by a projection pursuit type of learning process where both type of variable can be compared and merged within a common framework the learning process return a generative model for image intensity from a relatively small number of training image the recognition or classification by template matching can then be based on log likelihood ratio score we apply the learning method to a variety of object and texture category the result show that both the sketch and texture are useful for classification and they complement each other 
the bilateral filter is a nonlinear filter that smoothes a signal while preserving strong edge it ha demonstrated great effectiveness for a variety of problem in computer vision and computer graphic and fast version have been proposed unfortunately little is known about the accuracy of such acceleration in this paper we propose a new signal processing analysis of the bilateral filter which complement the recent study that analyzed it a a pde or a a robust statistical estimator the key to our analysis is to express the filter in a higher dimensional space where the signal intensity is added to the original domain dimension importantly this signal processing perspective allows u to develop a novel bilateral filtering acceleration using downsampling in space and intensity this affords a principled expression of accuracy in term of bandwidth and sampling the bilateral filter can be expressed a linear convolution in this augmented space followed by two simple nonlinearities this allows u to derive criterion for downsampling the key operation and achieving important acceleration of the bilateral filter we show that for the same running time our method is more accurate than previous acceleration technique typically we are able to process a megapixel image using our acceleration technique in le than a second and have the result be visually similar to the exact computation that take several ten of minute the acceleration is most effective with large spatial kernel furthermore this approach extends naturally to color image and cross bilateral filtering 
this paper describes a new algorithm for recovering the d shape and motion of deformable and articulated object purely from uncalibrated d image measurement using an iterative factorization approach most solution to nonrigid and articulated structure from motion require metric constraint to be enforced on the motion matrix to solve for the transformation that upgrade the solution to metric space while in the case of rigid structure the metric upgrade step is simple since the motion constraint are linear deformability in the shape introduces non linearity in this paper we propose an alternating least square approach associated with a globally optimal projection step onto the manifold of metric constraint an important advantageof this new algorithm is it ability to handle missing data which becomes crucial when dealing with real video sequence with self occlusion we show successful result of our algorithm on synthetic and real sequence of both deformable and articulated data 
face detection ha advanced dramatically over the past three decade algorithm can now quite reliably detect face in clutter in or near real time however much still need to be done to provide an accurate and detailed description of external and internal feature this paper present an approach to achieve this goal previous learning algorithm have had limited success on this task because the shape and texture of facial feature varies widely under changing expression pose and illumination we address this problem with the use of subclass division in this approach we use an algorithm to automatically divide the training sample of each facial feature into a set of subclass each representing a distinct construction of the same facial component e g close versus open eye lid the key idea used to achieve accurate detection is to not only learn the textural information of the facial feature to be detected but that of it context i e surroundings this process permit a precise detection of key facial feature we then combine this approach with edge and color segmentation to provide an accurate and detailed detection of the shape of the major facial feature brow eye nose mouth and chin we use this face detection algorithm to obtain precise description of the facial feature in video sequence of american sign language asl sentence where the variability in expression can be extreme extensive experimental validation demonstrates our method is almost a precise a manual detection error 
when fitting finite mixture to multivariate data it is crucial to select the appropriate number of component under regularization theory we aim to resolve this ldquounsupervisedrdquo learning problem via regularizing the likelihood by the full entropy of posterior probability for finite mixture fitting two deterministic annealing implementation are further proposed for this entropy regularized likelihood erl learning through some asymptotic analysis of the deterministic annealing erl daerl learning we find that the global minimization of the erl function in an annealing way can lead to automatic model selection on finite mixture and also make our daerl algorithm le sensitive to initialization than the standard em algorithm the simulation experiment then demonstrate that our algorithm can provide some promising result just a our theoretic analysis moreover our algorithm are evaluated in the application of unsupervised image segmentation and shown to outperform other state of the art method 
partial differential equation pdes have been successfully applied to many computer vision and image processing problem however designing pdes requires high mathematical skill and good insight into the problem in this paper we show that the design of pdes could be made easier by borrowing the learning strategy from machine learning in our learning based pde l pde framework for image restoration there are two term in our pde model i a regularizer which encodes the prior knowledge of the image model and ii a linear combination of differential invariant which is data driven and can effectively adapt to different problem and complex condition the l pde is learnt from some input output pair of training sample via an optimal control technique the effectiveness of our l pde framework for image restoration is demonstrated with two exemplary application image denoising and inpainting where the pdes are obtained easily and the produced result are comparable to or better than those of traditional pdes which were elaborately designed 
in this paper we describe a nonlinear image representation based on divisive normalization that is designed to match the statistical property of photographic image a well a the perceptual sensitivity of biological visual system we decompose an image using a multi scale oriented representation and use student s t a a model of the dependency within local cluster of coefficient we then show that normalization of each coefficient by the square root of a linear combination of the amplitude of the coefficient in the cluster reduces statistical dependency we further show that the resulting divisive normalization transform is invertible and provide an efficient iterative inversion algorithm finally we probe the statistical and perceptual advantage of this image representation by examining it robustness to added noise and using it to enhance image contrast 
many perception problem involve datasets that are naturally comprised of multiple stream or modality for which supervised training data is only sparsely available in case where there is a degree of conditional independence between such view a class of semisupervised learning technique that are based on maximizing view agreement over unlabeled data ha been proven successful in a wide range of machine learning domain however these co training or multi view learning method have had relatively limited application in vision due in part to the assumption of constant perchannel noise model in this paper we propose a probabilistic heteroscedastic approach to co training that simultaneously discovers the amount of noise on a persample basis while solving the classic ation task this result in high performance in the presence of occlusion or other complex observation noise process we demonstrate our approach in two domain multi view object recognition from low delity sensor network and audio visual classic ation 
this paper present three novel method that enable bilateral filtering in constant time o without sampling constant time mean that the computation time of the filtering remains same even if the filter size becomes very large our first method take advantage of the integral histogram to avoid the redundant operation for bilateral filter with box spatial and arbitrary range kernel for bilateral filter constructed by polynomial range and arbitrary spatial filter our second method provides a direct formulation by using linear filter of image power without any approximation lastly we show that gaussian range and arbitrary spatial bilateral filter can be expressed by taylor series a linear filter decomposition without any noticeable degradation of filter response all these method drastically decrease the computation time by cutting it down constant time e g to second per mb image while achieving very high psnr s over db in addition to the computational advantage our method are straightforward to implement 
in this paper we aim at reconstructing d scene from image with unknown focal length downloaded from photosharing website such a flickr first we provide a minimal solution to finding the relative pose between a completely calibrated camera and a camera with an unknown focal length given six point correspondence we show that this problem ha up to nine solution in general and present two efficient solver to the problem they are based on gr obner basis resp on generalized eigenvalue computation we demonstrate by experiment with synthetic and real data that both solver are correct fast numerically stable and work well even in some situation when the classical point algorithm fails e g when optical ax of the camera are parallel or intersecting based on this solution we present a new efficient method for large scale structure from motion from unordered data set downloaded from the internet we show that this method can be effectively used to reconstruct d scene from collection of image with very few in principle single image with known focal length 
we present a new shape prior segmentation method using graph cut capable of segmenting multiple object the shape prior energy is based on a shape distance popular with level set approach we also present a multiphase graph cut framework to simultaneously segment multiple possibly overlapping object the multiphase formulation differs from multiway cut in that the former can account for object overlap by allowing a pixel to have multiple label we then extend the shape prior energy to encompass multiple shape prior unlike variational method a major advantage of our approach is that the segmentation energy is minimized directly without having to compute it gradient which can be a cumbersome task and often relies on approximation experiment demonstrate that our algorithm can cope with image noise and clutter a well a partial occlusion and affine transformation of the shape 
we address the problem of inferring homogeneous reflectance brdf from a single image of a known shape in an unknown real world lighting environment with appropriate representation of lighting and reflectance the image provides bilinear constraint on the two signal and our task is to blindly isolate the latter we achieve this by leveraging the statistic of real world illumination and estimating the reflectance that is most likely under a distribution of probable illumination environment experimental result with a variety of real and synthetic image suggest that useable reflectance information can be inferred in many case and that these estimate are stable under change in lighting 
in this paper we investigate brain hallucination or generating a high resolution brain image from an input low resolution image with the help of another high resolution brain image contrary to interpolation technique the reconstruction process is based on a physical model of image acquisition our contribution is a new regularization approach that us an example based framework integrating non local similarity constraint to handle in a better way repetitive structure and texture the effectiveness of our approach is demonstrated by experiment on realistic magnetic resonance brain image generating automatically high quality hallucinated brain image from low resolution input 
we present a catadioptric projector analogous to a catadioptric camera by combining a commodity digital projector with additional optical unit we show that by using specially shaped reflector refractors catadioptric projector can offer an unprecedented level of flexibility in aspect ratio size and field of view we also present efficient algorithm to reduce projection artifact in catadioptric projector such a distortion scattering and defocusing instead of recovering the reflector refractor geometry our approach directly model the light transport between the projector and the viewpoint using the light transport matrix ltm we show how to efficiently approximate the pseudo inverse of the ltm and apply it to find the optimal input image that produce least projection distortion furthermore we present a projection defocus analysis for reflector and thin refractor based catadioptric projector we show that defocus blur can be interpreted a spatially varying gaussian blur on the input image we then measure the kernel directly from the ltm and apply deconvolution to optimize the input image we demonstrate the practical us of catadioptric projector in panoramic and omni directional projection our new system achieves much wider field of view projection while maintaining sharpness and low geometric and photometric distortion 
in this paper we investigate how to incorporate spatial and or temporal contextual information into classical histogram feature with the aim of boosting visual classification performance firstly we show that the stationary distribution derived from the normalized histogrambin co occurrence matrix characterizes the row sum of the original histogram bin co occurrence matrix this underlying rationale of the histogram bin co occurrence feature then motivates u to propose the concept of general contextualizing histogram process which encodes the spatial and or temporal context a local homogeneity distribution and produce the so called contextualized histogram by convoluting these local homogeneity distribution with the histogram bin index image video finally the third and even higher order contextualized histogram are instantiated for encoding more complicated and informative spatial and or temporal contextual information into histogram we evaluate these proposed method on face recognition and group activity classification problem and the result demonstrate that the contextualized histogram significantly boost the visual classification performance 
matching based on local brightness is quite limited because small change on local appearance invalidate the constancy in brightness the root of this limitation is it treatment regardless of the information from the spatial context this paper leap from brightness constancy to context constancy and thus from optical flow to contextual flow it present a new approach that incorporates context to constrain motion estimation for target tracking in this approach one individual spatial context of a given pixel is represented by the posterior density of the associated feature class in it contextual domain each individual context give a linear contextual flow constraint to the motion so that the motion can be estimated in an over determined contextual system based on this contextual flow model this paper present a new and powerful target tracking method that integrates the process of salient contextual point selection robust contextual matching and dynamic context selection extensive experiment result show the effectiveness of the proposed approach 
in the matching task which form an integral part of all type of tracking and geometrical vision there are invariably prior available on the absolute and or relative image location of feature of interest usually these prior are used post hoc in the process of resolving feature match and obtaining final scene estimate via first get candidate match then resolve consensus algorithm such a ransac in this paper we show that the dramatically different approach of using prior dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operation and lower overall computational cost essentially we put image processing into the loop of the search for global consensus in particular our approach is able to cope with significant image ambiguity thanks to a dynamic mixture of gaussians treatment in our fully bayesian algorithm the choice of the most efficient search action at each step is guided intuitively and rigorously by expected shannon information gain we demonstrate the algorithm in feature matching a part of a sequential slam system for d camera tracking robust real time matching can be achieved even in the previously unmanageable case of jerky rapid motion necessitating weak motion modelling and large search region 
a it ha been noted several time in literature the difficult part of autocalibration effort resides in the structural non linearity of the search for the plane at infinity in this paper we present a robust and versatile autocalibration method based on the enumeration of the inherently bounded space of the intrinsic parameter of two camera in order to find the collineation of space that upgrade a given projective reconstruction to euclidean each sample of the search space which reduces to a finite subset of under mild assumption defines a consistent plane at infinity this in turn produce a tentative approximate euclidean upgrade of the whole reconstruction which is then scored according to the expected intrinsic parameter of a euclidean camera this approach ha been compared with several other algorithm on both synthetic and concrete case obtaining favourable result 
we introduce a morphological approach to curve evolution the differential operator used in the standard pde snake model can be approached using morphological operation on a binary level set by combining the morphological operator associated to the pde component we achieve a new snake evolution algorithm this new solution is based on numerical method which are very simple fast and stable moreover since the level set is just a binary piecewise constant function this approach doe not require to estimate a contour distance function to illustrate the result obtained we present some numerical experiment on real image 
most motion based tracking algorithm assume that object undergo rigid motion which is most likely disobeyed in real world in this paper we present a novel motion based tracking framework which make no such assumption object is represented by a set of local invariant feature whose motion are observed by a feature correspondence process a generative model is proposed to depict the relationship between local feature motion and object global motion whose parameter are learned efficiently by an on line em algorithm and the object global motion is estimated in term of maximum likelihood of observation then an updating mechanism is employed to adapt object representation experiment show that our framework is flexible and robust in dealing with appearance change background clutter illumination change and occlusion 
we present spectral matting a new approach to natural image matting that automatically computes a basis set of fuzzy matting component from the smallest eigenvectors of a suitably defined laplacian matrix thus our approach extends spectral segmentation technique whose goal is to extract hard segment to the extraction of soft matting component these component may then be used a building block to easily construct semantically meaningful foreground matte either in an unsupervised fashion or based on a small amount of user input 
in this paper we propose a novel feature localization method based on a global vector concentration approach our approach doe not rely on the detection of local salient feature around feature point instead we exploit global structural information of the object extracted by calculating the concentration of directional vector from sampling point those vector are combined with local pattern descriptor of a query image and selected from preliminarily trained extended template by nearest neighbor search due to the insensitivity of local change our method can handle partially occluded and noisy object we apply the proposed method to fully automatic feature localization of the left ventricular in echocardiogram the result show the effectiveness of our method in comparison with a conventional edge based method in term of accuracy and robustness 
learning a new object class from cluttered training image is very challenging when the location of object instance is unknown previous work generally require object covering a large portion of the image we present a novel approach that can cope with extensive clutter a well a large scale and appearance variation between object instance to make this possible we propose a conditional random field that start from generic knowledge and then progressively adapts to the new class our approach simultaneously localizes object instance while learning an appearance model specific for the class we demonstrate this on the challenging pascal voc dataset furthermore our method enables to train any state of the art object detector in a weakly supervised fashion although it would normally require object location annotation 
given a photo of person a we seek a photo of person b with similar pose and expression solving this problem enables a form of puppetry in which one person appears to control the face of another when deployed on a webcam equipped computer our approach enables a user to control another person s face in real time this image retrieval inspired approach employ a fully automated pipeline of face analysis technique and is extremely general we can puppet anyone directly from their photo collection or video in which they appear we show several example using image and video of celebrity from the internet 
most existing method of semi supervised clustering introduce supervision from outside e g manually label some data sample or introduce constrains into clustering result this paper study an interesting problem can the supervision come from inside i e the unsupervised training data themselves if the data sample are not independent we can capture the contextual information reflecting the dependency among the data sample and use it a supervision to improve the clustering this is called context aware clustering the investigation is substantialized on two scenario of clustering primitive visual feature e g sift feature with help of spatial context and clustering hand written digit with help of contextual pattern among different type of feature our context aware clustering can be well formulated in a closed form where the contextual information serf a a regularization term to balance the data fidelity in original feature space and the influence of contextual pattern a nested em algorithm is proposed to obtain an efficient solution which prof to converge by exploring the dependent structure of the data sample this method is completely unsupervised a no outside supervision is introduced 
computer user with visual impairment cannot access the rich graphical content in print or digital medium unless relying on visual to tactile conversion which is done primarily by human specialist automated approach to this conversion are an emerging research field in which currently only simple graphic such a diagram are handled this paper proposes a systematic method for automatically converting a human portrait image into it tactile form we model the face based on deformable active shape model asm cootes et al which is enriched by local appearance model in term of gradient profile along the shape the generic face model including the appearance component is learnt from a set of training face image given a new portrait image the prior model is updated through bayesian inference to facilitate the incorporation of a pose dependent appearance model we propose a statistical sampling scheme for the inference task furthermore to compensate for the simplicity of the face model edge segment of a given image are used to enrich the basic face model in generating the final tactile printout experiment are designed to evaluate the performance of the proposed method 
many previous study have shown that naturally occurring data cannot possibly fill up the high dimensional space uniformly rather it must concentrate around lower dimensional structure the typical supervised subspace learning algorithm to discover this low dimensional structure include linear discriminant analysis lda for lda the training data point are usually pre given however in some real world application like relevance feedback image retrieval there is opportunity to interact with the user and actively select the training point for labeling in this paper we propose a novel active subspace learning algorithm which selects the most informative data point and us them for learning an optimal subspace using technique from experimental design we discus how to perform data selection in supervised or semi supervised subspace learning by minimizing the expected error experiment on image retrieval show improvement over state of the art method 
we propose interest seam image an efficient visual synopsis for video to extract an interest seam image a spatiotemporal energy map is constructed for the target video shot then an optimal seam which encompasses the highest energy is identified by an efficient dynamic programming algorithm the optimal seam is used to extract a seam of pixel from each video frame to form one column of an image based on which an interest seam image is finally composited the interest seam image is efficient both in term of computation and memory cost therefore it is able to power a wide variety of web scale video content analysis application such a near duplicate video clip search video genre recognition and classification a well a video clustering etc the representation capacity of the proposed interest seam image is demonstrated in a large scale video retrieval task it advantage are clearly exhibited when compared with previous work a reported in our experiment 
we introduce a novel image segmentation algorithm that us translational symmetry a the primary foreground background separation cue we investigate the process of identifying and analyzing image region that present approximate translational symmetry for the purpose of image fourground background separation in conjunction with texture based inpainting understanding the different see through layer allows u to perform powerful image manipulation such a recovering a meshoccluded background a much a occluded area to achieve the effect of image and photo de fencing our algorithm consists of three distinct phase automatically finding the skeleton structure of a potential frontal layer fence in the form of a deformed lattice separating foreground background layer using appearance regularity and occluded foreground inpainting to reveal a complete non occluded image each of these three task present it own special computational challenge that are not encountered in previous general image de layering or texture inpainting application 
this paper present a novel method for location recognition which exploit an epitomic representation to achieve both high efficiency and good generalization a generative model based on epitomic image analysis capture the appearance and geometric structure of an environment while allowing for variation due to motion occlusion and non lambertian effect the ability to model translation and scale invariance together with the fusion of diverse visual feature yield enhanced generalization with economical training experiment on both existing and new labeled image database result in recognition accuracy superior to state of the art with real time computational performance 
in this paper we propose a new shape decomposition method called convex shape decomposition we formalize the convex decomposition problem a an integer linear programming problem and obtain approximate optimal solution by minimizing the total cost of decomposition under some concavity constraint our method is based on morse theory and combine information from multiple morse function the obtained decomposition provides a compact representation both geometrical and topological of original object our experiment show that such representation is very useful in many application 
an optical diffuser is an element that scatter light and is commonly used to soften or shape illumination in this paper we propose a novel depth estimation method that place a diffuser in the scene prior to image capture we call this approach depth from diffusion dfdiff we show that dfdiff is analogous to conventional depth from defocus dfd where the scatter angle of the diffuser determines the effective aperture of the system the main benefit of dfdiff is that while dfd requires very large aperture to improve depth sensitivity dfdiff only requires an increase in the diffusion angle a much le expensive proposition we perform a detailed analysis of the image formation property of a dfdiff system and show a variety of example demonstrating greater precision in depth estimation when using dfdiff 
fisher s linear discriminant analysis lda one of the most popular dimensionality reduction algorithm for classification ha three particular problem it fails to find the nonlinear structure hidden in the high dimensional data it assumes all sample contribute equivalently to reduce dimension for classification and it suffers from the matrix singularity problem in this paper we propose a new algorithm termed discriminative locality alignment dla to deal with these problem the algorithm operates in the following three stage first in part optimization discriminative information is imposed over patch each of which is associated with one sample and it neighbor then in sample weighting each part optimization is weighted by the margin degree a measure of the importance of a given sample and finally in whole alignment the alignment trick is used to align all weighted part optimization to the whole optimization furthermore dla is extended to the semi supervised case i e semi supervised dla sdla which utilizes unlabeled sample to improve the classification performance thorough empirical study on the face recognition demonstrate the effectiveness of both dla and sdla 
motion blur due to camera shake is an annoying yet common problem in low light photography in this paper we propose a novel method to recover a sharp image from a pair of motion blurred and flash image consecutively captured using a hand held camera we first introduce a robust flash gradient constraint by exploiting the correlation between a sharp image and it corresponding flash image then we formulate our flash deblurring a solving a maximum a posteriori problem under the flash gradient constraint we solve the problem by performing kernel estimation and non blind deconvolution iteratively leading to an accurate blur kernel and a reconstructed image with fine image detail experiment on both synthetic and real image show the superiority of our method compared with existing method 
in this work we propose a hierarchical approach for labeling semantic object and region in scene our approach is reminiscent of early vision literature in that we use a decomposition of the image in order to encode relational and spatial information in contrast to much existing work on structured prediction for scene understanding we bypass a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanic of some approximate inference procedure in graphical model this approach mitigates both the theoretical and empirical difficulty of learning probabilistic model when exact inference is intractable in particular we draw from recent work in machine learning and break the complex inference process into a hierarchical series of simple machine learning subproblems each subproblem in the hierarchy is designed to capture the image and contextual statistic in the scene this hierarchy span coarse to fine region and explicitly model the mixture of semantic label that may be present due to imperfect segmentation to avoid cascading of error and overfitting we train the learning problem in sequence to ensure robustness to likely error earlier in the inference sequence and leverage the stacking approach developed by cohen et al 
we propose an efficient method for complex optimization problem that often arise in computer vision while our method is general and could be applied to various task it wa mainly inspired from problem in computer vision and it borrows idea from scale space theory one of the main motivation for our approach is that searching for the global maximum through the scale space of a function is equivalent to looking for the maximum of the original function with the advantage of having to handle fewer local optimum our method work with any non negative possibly non smooth function and requires only the ability of evaluating the function at any specific point the algorithm is based on a growth transformation which is guaranteed to increase the value of the scale space function at every step unlike gradient method to demonstrate it effectiveness we present it performance on a few computer vision application and show that in our experiment it is more effective than some well established method such a mcmc simulated annealing and the more local nelder mead optimization method 
this paper address the problem of segmenting an image into region consistent with user supplied seed e g a sparse set of broad brush stroke we view this task a a statistical transductive inference in which some pixel are already associated with given zone and the remaining one need to be classified our method relies on the laplacian graph regularizer a powerful manifold learning tool that is based on the estimation of variant of the laplace beltrami operator and is tightly related to diffusion process segmentation is modeled a the task of finding matting coefficient for unclassified pixel given known matting coefficient for seed pixel the proposed algorithm essentially relies on a high margin assumption in the space of pixel characteristic it is simple fast and accurate a demonstrated by qualitative result on natural image and a quantitative comparison with state of the art method on the microsoft grabcut segmentation database 
we propose a method based on sparse representation sr to cluster data drawn from multiple low dimensional linear or affine subspace embedded in a high dimensional space our method is based on the fact that each point in a union of subspace ha a sr with respect to a dictionary formed by all other data point in general finding such a sr is np hard our key contribution is to show that under mild assumption the sr can be obtained exactly by using optimization the segmentation of the data is obtained by applying spectral clustering to a similarity matrix built from this sr our method can handle noise outlier a well a missing data we apply our subspace clustering algorithm to the problem of segmenting multiple motion in video experiment on video sequence show that our approach significantly outperforms state of the art method 
capturing multiple photo at different focus setting is a powerful approach for reducing optical blur but how many photo should we capture within a fixed time budget we develop a framework to analyze optimal capture strategy balancing the tradeoff between defocus and sensor noise incorporating uncertainty in resolving scene depth we derive analytic formula for restoration error and use monte carlo integration over depth to derive optimal capture strategy for different camera design under a wide range of photographic scenario we also derive a new upper bound on how well spatial frequency can be preserved over the depth of field our result show that by capturing the optimal number of photo a standard camera can achieve performance at the level of more complex computational camera in all but the most demanding of case we also show that computational camera although specifically designed to improve one shot performance generally benefit from capturing multiple photo a well 
linear discriminant analysis lda is a popular tool for multiclass discriminative dimensionality reduction however lda suffers from two major problem it only optimizes the bayes error for the case of unimodal gaussian class with equal covariance assuming full rank matrix and the multiclass extension maximizes the sum of pairwise distance between the class and doe not simultaneously maximize each pairwise distance between the class this typically result in serious overlapping in the projected space between class that are close in the input space to solve these two problem this paper proposes pareto discriminant analysis parda firstly parda explicitly model each of the class a a multidimensional gaussian with a sample covariance secondly parda decomposes the multiclass problem to a set of pairwise objective function representing the pairwise distance between different class unlike existing extension of fisher discriminant analysis fda to multiclass problem that typically maximize the sum of pairwise distance between class parda simultaneously maximizes each pairwise distance thus encouraging the case that all class are equidistant from each other in the lower dimensional space solving parda is a multiobjective optimization problem simultaneously optimizing more than one possibly conflicting objective function and the resulting solution is known to be pareto optimal experimental result on synthetic data several image data set and data set from the uci repository show positive and encouraging result in favor of parda when compared with standard and state of the art multiclass extension of lda 
multi view stereo mv algorithm now produce reconstruction that rival laser range scanner accuracy however stereo algorithm require textured surface and therefore work poorly for many architectural scene e g building interior with textureless painted wall this paper present a novel mv approach to overcome these limitation for manhattan world scene i e scene that consists of piece wise planar surface with dominant direction given a set of calibrated photograph we first reconstruct textured region using an existing mv algorithm then extract dominant plane direction generate plane hypothesis and recover per view depth map using markov random field we have tested our algorithm on several datasets ranging from office interior to outdoor building and demonstrate result that outperform the current state of the art for such texture poor scene 
a a fundamental problem in pattern recognition graph matching ha application in a variety of field from computer vision to computational biology in graph matching pattern are modeled a graph and pattern recognition amount to finding a correspondence between the node of different graph many formulation of this problem can be cast in general a a quadratic assignment problem where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility the main research focus in this theme is about designing efficient algorithm for approximately solving the quadratic assignment problem since it is np hard in this paper we turn our attention to a different question how to estimate compatibility function such that the solution of the resulting graph matching problem best match the expected solution that a human would manually provide we present a method for learning graph matching the training example are pair of graph and the label are match between them our experimental result reveal that learning can substantially improve the performance of standard graph matching algorithm in particular we find that simple linear assignment with such a learning scheme outperforms graduated assignment with bistochastic normalisation a state of the art quadratic assignment relaxation algorithm 
motion blur retains some information about motion based on which motion may be recovered from blurred image this is a difficult problem a the situation of motion blur can be quite complicated such a they may be space variant nonlinear and local this paper address a very challenging problem can we recover motion blindly from a single motion blurred image a major contribution of this paper is a new finding of an elegant motion blur constraint exhibiting a very similar mathematical form a the optical flow constraint this linear constraint applies locally to pixel in the image therefore a number of challenging problem can be addressed including estimating global affine motion blur estimating global rotational motion blur estimating and segmenting multiple motion blur and estimating nonparametric motion blur field extensive experiment on blur estimation and image deblurring on both synthesized and real data demonstrate the accuracy and general applicability of the proposed approach 
periodicity is at the core of the recognition of many action this paper take the following step to detect and measure periodicity we establish a conceptual framework of classifying periodicity in essential case the most important of which are flashing of a traffic light pulsing of an anemone swinging of wing spinning of a swimmer turning of a conductor shuttling of a brush drifting of an escalator and thrusting of a kangaroo we present an algorithm to detect all case by the one and the same algorithm it track the object independent of the object s appearance then performs probabilistic pca and spectral analysis followed by detection and frequency measurement the method show good performance with fixed parameter for example of all above case assembled from the internet application of the method completely unaltered to a random half hour of cnn news ha led to an score 
we propose a novel tracking algorithm that can work robustly in a challenging scenario such that several kind of appearance and motion change of an object occur at the same time our algorithm is based on a visual tracking decomposition scheme for the efficient design of observation and motion model a well a tracker in our scheme the observation model is decomposed into multiple basic observation model that are constructed by sparse principal component analysis spca of a set of feature template each basic observation model cover a specific appearance of the object the motion model is also represented by the combination of multiple basic motion model each of which cover a different type of motion then the multiple basic tracker are designed by associating the basic observation model and the basic motion model so that each specific tracker take charge of a certain change in the object all basic tracker are then integrated into one compound tracker through an interactive markov chain monte carlo imcmc framework in which the basic tracker communicate with one another interactively while run in parallel by exchanging information with others each tracker further improves it performance which result in increasing the whole performance of tracking experimental result show that our method track the object accurately and reliably in realistic video where the appearance and motion are drastically changing over time 
in this paper we address the issue of transducing the object cutout model from an example image to novel image instance we observe that although object and background are very likely to contain similar color in natural image it is much le probable that they share similar color configuration motivated by this observation we propose a local color pattern model to characterize the color configuration in a robust way additionally we propose an edge profile model to modulate the contrast of the image which enhances edge along object boundary and attenuates edge inside object or background the local color pattern model and edge model are integrated in a graph cut framework higher accuracy and improved robustness of the proposed method are demonstrated through experimental comparison with state of the art algorithm 
in this paper we investigate the detection of semantic human action in complex scene unlike conventional action recognition in well controlled environment action detection in complex scene suffers from cluttered background heavy crowd occluded body and spatial temporal boundary ambiguity caused by imperfect human detection and tracking conventional algorithm are likely to fail with such spatial temporal ambiguity in this work the candidate region of an action are treated a a bag of instance then a novel multiple instance learning framework named smile svm simulated annealing multiple instance learning support vector machine is presented for learning human action detector based on imprecise action location smile svm is extensively evaluated with satisfactory performance on two task human action detection on a public video action database with cluttered background and a real world problem of detecting whether the customer in a shopping mall show an intention to purchase the merchandise on shelf even if they didn t buy it eventually in addition the complementary nature of motion and appearance feature in action detection are also validated demonstrating a boosted performance in our experiment 
prominent feature point descriptor such a sift and surf allow reliable real time matching but at a computational cost that limit the number of point that can be handled on pc and even more on le powerful mobile device a recently proposed technique that relies on statistical classification to compute signature ha the potential to be much faster but at the cost of using very large amount of memory which make it impractical for implementation on low memory device in this paper we show that we can exploit the sparseness of these signature to compact them speed up the computation and drastically reduce memory usage we base our approach on compressive sensing theory we also highlight it effectiveness by incorporating it into two very different slam package and demonstrating substantial performance increase 
we explore the problem of reconstructing an image from a bag of square non overlapping image patch the jigsaw puzzle problem completing jigsaw puzzle is challenging and requires expertise even for human and is known to be np complete we depart from previous method that treat the problem a a constraint satisfaction problem and develop a graphical model to solve it each patch location is a node and each patch is a label at node in the graph a graphical model requires a pairwise compatibility term which measure an affinity between two neighboring patch and a local evidence term which we lack this paper discus way to obtain these term for the jigsaw puzzle problem we evaluate several patch compatibility metric including the natural image statistic measure and experimentally show that the dissimilarity based compatibility measuring the sum of squared color difference along the abutting boundary give the best result we compare two form of local evidence for the graphical model a sparse and accurate evidence and a dense and noisy evidence we show that the sparse and accurate evidence fixing a few a patch at their correct location is enough to reconstruct image consisting of over patch to the best of our knowledge this is the largest puzzle solved in the literature we also show that one can coarsely estimate the low resolution image from a bag of patch suggesting that a bag of image patch encodes some geometric information about the original image 
image matting is the task of estimating a foreand background layer from a single image to solve this ill posed problem an accurate modeling of the scene s appearance is necessary existing method that provide a closed form solution to this problem assume that the color of the foreground and background layer are locally linear in this paper we show that such model can be an overfit when the color of the two layer are locally constant we derive new closed form expression in such case and show that our model are more compact than existing one in particular the null space of our cost function is a subset of the null space constructed by existing approach we discus the bias towards specific solution for each formulation experiment on synthetic and real data confirm that our compact model estimate alpha matte more accurately than existing technique without the need of additional user interaction 
abstract high angular resolution diffusion imaging ha become an important magnetic resonance technique for in vivo imaging most current research in this field focus on developing method for computing the orientation distribution function odf which is the probability distribution function of water molecule diffusion along any angle on the sphere in this paper we present a riemannian framework to carry out computation on an odf field the proposed framework doe not require that the odfs be represented by any fixed parameterization such a a mixture of von mi fisher distribution or a spherical harmonic expansion instead we use a non parametric representation of the odf and exploit the fact that under the square root re parameterization the space of odfs form a riemannian manifold namely the unit hilbert sphere specifically we use riemannian operation to perform various geometric data processing algorithm such a interpolation convolution and linear and nonlinear filtering we illustrate these concept with numerical experiment on synthetic and real datasets 
this paper address the problem of recognizing shadow from monochromatic natural image without chromatic information shadow classification is very challenging because the invariant color cue are unavailable natural scene make this problem even harder because of ambiguity from many near black object we propose to use both shadow variant and shadow invariant cue from illumination textural and odd order derivative characteristic such feature are used to train a classifier from boosting a decision tree and integrated into a conditional random field which can enforce local consistency over pixel label the proposed approach is evaluated using both qualitative and quantitative result based on a novel database of hand labeled shadow our result show shadowed area of an image can be identified using proposed monochromatic cue 
pictorial structure p model are extensively used for part based recognition of scene people animal and multi part object to achieve tractability the structure and parameterization of the model is often restricted for example by assuming tree dependency structure and unimodal data independent pairwise interaction these expressivity restriction fail to capture important pattern in the data on the other hand local method such a nearest neighbor classification and kernel density estimation provide nonparametric flexibility but require large amount of data to generalize well we propose a simple semi parametric approach that combine the tractability of pictorial structure inference with the flexibility of non parametric method by expressing a subset of model parameter a kernel regression estimate from a learned sparse set of exemplar this yield query specific image dependent pose prior we develop an effective shape based kernel for upper body pose similarity and propose a leave one out loss function for learning a sparse subset of exemplar for kernel regression we apply our technique to two challenging datasets of human figure parsing and advance the state of the art from to on the buffy dataset while using only of the training data a exemplar 
action in real world application typically take place in cluttered environment with large variation in the orientation and scale of the actor we present an approach to simultaneously track and recognize known action that is robust to such variation starting from a person detection in the standing pose in our approach we first render synthetic pose from multiple viewpoint using mocap data for known action and represent them in a conditional random field crf whose observation potential are computed using shape similarity and the transition potential are computed using optical flow we enhance these basic potential with term to represent spatial and temporal constraint and call our enhanced model the shape flow durationconditional random field sfd crf we find the best sequence of action using viterbi search in the sfd crf we demonstrate our approach on video from multiple viewpoint and in the presence of background clutter 
we propose a branch and bound algorithm to obtain the globally optimal relative rotation between a camera and the rotation sensor attached to it compared to previous method our approach directly minimizes the image space error related to the measurement which is very natural for camera based system our algorithm is based on the observation that we may evaluate the residual when the rotation matrix is known we propose a feasibility test algorithm for the branch and bound to efficiently reduce the search volume of the rotation domain experimental result are provided using synthetic and real data set 
we propose a new method for detecting object such a bag carried by pedestrian depicted in short video sequence in common with earlier work on the same problem the method start by averaging aligned foreground region of a walking pedestrian to produce a representation of motion and shape known a a temporal template that ha some immunity to noise in foreground segmentation and phase of the walking cycle our key novelty is for carried object to be revealed by comparing the temporal template against view specific exemplar generated offline for unencumbered pedestrian a likelihood map obtained from this match is combined in a markov random field with a map of prior probability for carried object and a spatial continuity assumption from which we obtain a segmentation of carried object using the map solution we have re implemented the earlier state of the art method and demonstrate a substantial improvement in performance for the new method on the challenging pet dataset although developed for a specific problem the method could be applied to the detection of irregularity in appearance for other category of object that move in a periodic fashion 
learning a discriminant becomes substantially more difficult when the datasets are high dimensional and the available sample are few this is often the case in computer vision and medical diagnosis application a novel conic section classifier csc wa recently introduced in the literature to handle such datasets wherein each class wa represented by a conic section parameterized by it focus directrix and eccentricity the discriminant boundary wa the locus of all point that are equi eccentric relative to each class representative conic section simpler boundary were preferred for the sake of generalizability in this paper we improve the performance of the two class classifier via a large margin pursuit when formulated a a non linear optimization problem the margin computation is demonstrated to be hard especially due to the high dimensionality of the data instead we present a geometric algorithm to compute the distance of a point to the nonlinear discriminant boundary generated by the csc in the input space we then introduce a large margin pursuit in the learning phase so a to enhance the generalization capacity of the classifier we validate the algorithm on real datasets and show favorable classification rate in comparison to many existing state of the art binary classifier a well a the csc without margin pursuit 
this paper address the problem of recovering d human pose from a single monocular image using a discriminative bag of word approach in previous work the visual word are learned by unsupervised clustering algorithm they capture the most common pattern and are good feature for coarse grain recognition task like object classification but for those task which deal with subtle difference such a pose estimation such representation may lack the needed discriminative power in this paper we propose to jointly learn the visual word and the pose regressors in a supervised manner more specifically we learn an individual distance metric for each visual word to optimize the pose estimation performance the learned metric rescale the visual word to suppress unimportant dimension such a those corresponding to background another contribution is that we design an appearance and position context apc local descriptor that achieves both selectivity and invariance while requiring no background subtraction we test our approach on both a quasi synthetic dataset and a real dataset humaneva to verify it effectiveness our approach also achieves fast computational speed thanks to the integral histogram used in apc descriptor extraction and fast inference of pose regressors 
with the rise of photo sharing website such a facebook and flickr ha come dramatic growth in the number of photograph online recent research in object recognition ha used such site a a source of image data but the test image have been selected and labeled by hand yielding relatively small validation set in this paper we study image classification on a much larger dataset of million image including nearly million of which have been labeled into one of category the dataset and category are formed automatically from geotagged photo from flickr by looking for peak in the spatial geotag distribution corresponding to frequently photographed landmark we learn model for these landmark with a multiclass support vector machine using vector quantized interest point descriptor a feature we also explore the non visual information available on modern photo sharing site showing that using textual tag and temporal constraint lead to significant improvement in classification rate we find that in some case image feature alone yield comparable classification accuracy to using text tag a well a to the performance of human observer 
we present a method for learning discriminative linear feature extraction using independent task more concretely given a target classification task we consider a complementary classification task that is independent of the target one for example in face classification field subject recognition can be a target task while facial expression classification can be a complementary task then we use label of the complementary task in order to obtain a more robust feature extraction being the new feature space le sensitive to the complementary classification to learn the proposed feature extraction we use the mutual information measure between the projected data and both label from the target and the complementary task in our experiment this framework ha been applied to a face recognition problem in order to inhibit this classification task from environmental artifact and to mitigate the effect of the small sample size problem our classification experiment show an improved feature extraction process using the proposed method 
recent work in multiple view geometry ha focused on obtaining globally optimal solution at the price of computational time efciency on the other hand traditional bundle adjustment algorithm have been found to provide good solution even though there may be multiple local minimum in this paper we justify this observation by giving a simple sufcient condition for global optimality that can be used to verify that a solution obtained from any local method is indeed global the method is tested on numerous problem instance of both synthetic and real data set in the vast majority of case we are able to verify that the solution are optimal in particular for small scale problem we also develop a branch and bound procedure that go beyond verication in case where the sufcient condition doe not hold the algorithm return either of the following two result i a certicate of global optimality for the local solution or ii the global solution 
image contour detection is fundamental to many image analysis application including image segmentation object recognition and classification however highly accurate image contour detection algorithm are also very computationally intensive which limit their applicability even for offline batch processing in this work we examine efficient parallel algorithm for performing image contour detection with particular attention paid to local image analysis a well a the generalized eigensolver used in normalized cut combining these algorithm into a contour detector along with careful implementation on highly parallel commodity processor from nvidia our contour detector provides uncompromised contour accuracy with an f metric of on the berkeley segmentation dataset runtime is reduced from minute to second the efficiency gain we realize enable high quality image contour detection on much larger image than previously practical and the algorithm we propose are applicable to several image segmentation approach efficient scalable yet highly accurate image contour detection will facilitate increased performance in many computer vision application 
in this paper we propose a new approach to camera calibration from silhouette under circular motion with minimal data we exploit the mirror symmetry property and derive a common homography that relates silhouette with epipoles under circular motion with the epipoles determined the homography can be computed from the frontier point induced by epipolar tangency on the other hand given the homography the epipoles can be located directly from the bitangent line of silho uettes with the homography recovered the image invariant under circular motion and camera parameter can be determined if the epipoles are not available camera parameter can be determined by a lowdimensional s earch of the optimal homography in a bounded region in the degenerate case when the camera optical ax intersect at one point we derive a closedform solution for the focal length to solve the problem by using the proposed algorithm we can achieve camera calibration simply from silhouette of three image captured under circular motion experimental result on synthetic and real image are presented to show it performance 
most current d face recognition algorithm are designed based on the data collected in controlled situation which lead to the un guaranteed performance in practical system in this paper we propose a robust local loggabor histogram rllgh method to handle the uncontrolled problem encountered in d face recognition in this challenging topic large expression and data noise are two main obstacle to overcome the large expression we choose log gabor feature lgf to extract the distinctive and robust information embedded in d face which will be represented a d log gabor face data noise are summarized a distorted mesh hair occlusion and misalignment to overcome these problem we introduce a robust local histogram rlh strategy which take advantage of the robustness of the accurate local statistical information the combination of lgf and rlh lead to rllgh the novelty of this paper come from our work aimsat studying d facerecognitionperformancein uncontrolled environment we find that embedding lgf into the lvc framework lead to robustness in handling large expression variation the rlh strategy give a promising way to solve the data noise problem our experiment are based on the large expression subset in frgc d face database and the expression subset in casia d face database experimental result show the efficiency robustness and generalization of our proposed method 
for most iris capturing scenario captured iris image could easily blur when the user is out of the depth of field dof of the camera or when he or she is moving the common solution is to let the user try the capturing process again a the quality of these blurred iris image is not good enough for recognition in this paper we propose a novel iris deblurring algorithm that can be used to improve the robustness and nonintrusiveness for iris capture unlike other iris deblurring algorithm the key feature of our algorithm is that we use the domain knowledge inherent in iris image and iris capture setting to improve the performance which could be in the form of iris image statistic characteristic of pupil or highlight or even depth information from the iris capturing system itself our experiment on both synthetic and real data demonstrate that our deblurring algorithm can significantly restore blurred iris pattern and therefore improve the robustness of iris capture 
we present a theoretical analysis for characterizing the shadow cast by a point light source given it relative position to the camera in particular we analyze the epipolar geometry of camera light pair including unusual cameralight configuration such a light source aligned with the camera s optical axis a well a convenient arrangement such a light placed in the camera plane a mathematical characterization of the shadow is derived to determine the orientation and location of depth discontinuity when projected onto the image plane that could potentially be associated with cast shadow the resulting theory is applied to compute a lower bound on the number of light needed to extract all depth discontinuity from a general scene using a multiflash camera we also provide a characterization of which discontinuity are missed and which are correctly detected by the algorithm and a foundation for choosing an optimal light placement experiment with depth edge computed using two flash setup and a four flash setup illustrate the theory and an additional configuration with a flash at the camera s center of projection is exploited a a solution for some degenerate case 
this article present a new method for non rigid surface registration between a surface model and a surface of an internal organ in a given d medical image the surface is represented with a set of feature point of which location are represented by a graphical model for constructing the representation a set of corresponding point is distributed on each of training surface based on an entropy based particle system from these corresponding point we estimate probability density of the location of each feature point the conditional probability distribution of the local image pattern around each feature point and the probability distribution of relative position between two neighboring feature point when a new image is given these density are used for estimating the location of each feature point by mean of a non parametric belief propagation the proposed method can estimate not only the location of the feature point but also their conditional marginal distribution in a given image some experimental result obtained from real x ct image are presented to show it performance 
a new hierarchical bayesian model is proposed for image segmentation based on gaussian mixture model gmm with a prior enforcing spatial smoothness according to this prior the local difference of thecontextual mixing proportion i e the probability of class label are student s t distributed the generative property of the student s t pdf allow this prior to impose smoothness and simultaneously model the edge between the segment of the image a maximum a posteriori map expectationmaximization em based algorithm is used for bayesian inference an important feature of this algorithm is that all the parameter are automatically estimated from the data in closed form numerical experiment are presented that demonstrate the superiority of the proposed model for image segmentation a compared to standard gmm based approach and to gmm segmentation technique with standard spatial smoothness constraint 
we propose a novel probabilistic framework for learning visual model of d object category by combining appearance information and geometric constraint object are represented a a coherent ensemble of part that are consistent under d viewpoint transformation each part is a collection of salient image feature a generative framework is used for learning a model that capture the relative position of part within each of the discretized viewpoint contrary to most of the existing mixture of viewpoint model our model establishes explicit correspondence of par t across different viewpoint of the object class given a new image detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition score of the candidate object our approach is among the first to propose a generative probabilistic framework for d object categorization we test ou r algorithm on the detection task and the viewpoint classification task by using car category from both the savarese et al and pascal voc datasets we show promising result in both the detection and viewpoint classification task on these two challenging datasets 
in this paper we present a multi label sparse coding framework for feature extraction and classification within the context of automatic image annotation first each image is encoded into a so called supervector derived from the universal gaussian mixture model on orderless image patch then a label sparse coding based subspace learning algorithm is derived to effectively harness multi label information for dimensionality reduction finally the sparse coding method for multi label data is proposed to propagate the multi label of the training image to the query image with the sparse reconstruction coefficient extensive image annotation experiment on the corel k and corel k database both show the superior performance of the proposed multi label sparse coding framework over the state of the art algorithm 
we study the problem of estimating the epipolar geometry from apparent contour of smooth curved surface with affine camera model since apparent contour are viewpoint dependent the only true image correspondence are projection of the frontier point i e surface point whose tangent plane are also their epipolar plane however frontier point are unknown a priori and must be estimated simultaneously with epipolar geometry previous approach to this problem adopt local greedy search method which are sensitive to initialization and may get trapped in local minimum we propose the first algorithm that guarantee global optimality for this problem we first reformulate the problem using a separable form that allows u to search effectively in a d space instead of on a d hypersphere in the classical formulation next in a branch and bound algorithm we introduce a novel lower bounding function through interval matrix analysis experimental result on both synthetic and real scene demonstrate that the proposed method is able to quickly obtain the optimal solution 
this paper proposes a new joint parametric and nonparametric curve evolution algorithm of the level set function for medical image segmentation traditional level set algorithm employ non parametric curve evolution for object matching although matching image boundary accurately they often suffer from local minimum and generate incorrect segmentation of object shape especially for image with noise occlusion and low contrast on the other hand statistical model based segmentation method allow parametric object shape variation subject to some shape prior constraint and they are more robust in dealing with noise and low contrast in this paper we combine the advantage of both of these method and jointly use parametric and non parametric curve evolution in object matching our new joint curve evolution algorithm is a robust a and at the same time yield more accurate segmentation result than the parametric method using shape prior information comparative result on segmenting ventricle frontal horn and putamen shape in mr brain image confirm both robustness and accuracy of the proposed joint curve evolution algorithm 
most algorithm for real time tracking of deformable shape provide sub optimal solution for a suitable energy minimization task the search space is typically considered too large to allow for globally optimal solution in this paper we show that under reasonable constraint on the object motion one can guarantee global optimality while maintaining real time requirement the problem is cast a finding the optimal cycle in a graph spanned by the prior template and the image the underlying combinatorial algorithm is implemented on state ofthe art graphic hardware solution on fpgas are conceivable experimental result demonstrate long term tracking of car in real time while coping with challenging weather condition in particular we show that the proposed tracking algorithm is highly robust to illumination change and that it outperforms local tracking method such a the level set method 
we present an approach for online learning of discriminative appearance model for robust multi target tracking in a crowded scene from a single camera although much progress ha been made in developing method for optimal data association there ha been comparatively le work on the appearance model which are key element for good performance many previous method either use simple feature such a color histogram or focus on the discriminability between a target and the background which doe not resolve ambiguity between the different target we propose an algorithm for learning a discriminative appearance model for different target training sample are collected online from tracklets within a time sliding window based on some spatial temporal constraint this allows the model to adapt to target instance learning us an ad aboost algorithm that combine effective image descriptor and their corresponding similarity measurement we term the learned model a oldams our evaluation indicate that oldams have significantly higher discrimination between different target than conventional holistic color histogram and when integrated into a hierarchical association framework they help improve the tracking accuracy particularly reducing the false alarm and identity switch 
image annotation ha been an active research topic in the recent year due to it potentially large impact on both image understanding and web database image search in this paper we target at solving the automatic image annotation problem in a novel semi supervised learning framework a novel multi label correlated green s function approach is proposed to annotate image over a graph the correlation among label are integrated into the objective function which improves the performance significantly we also propose a new adaptive decision boundary method for multi label assignment to deal with the difficulty of label assignment in most of the existing rank based multi label classification algorithm instead of setting the threshold heuristically or by experience our method principally compute it upon the prior knowledge in the training data we perform our method on three commonly used image annotation testing data set experimental result show significant improvement on classification performance over four other state of the art method a a general semi supervised learning framework other local feature based image annotation method could be easily incorporated into our framework to improve the performance 
over the year many tensor based algorithm e g two dimensional principle component analysis dpca two dimensional singular value decomposition dsvd high order svd have been proposed for the study of high dimensional data in a large variety of computer vision application an intrinsic limitation of previous tensor reduction method is the sensitivity to the presence of outlier because they minimize the sum of square error l norm in this paper we propose a novel robust tensor factorization method using r norm for error accumulation function using robust covariance matrix allowing the method to be efficiently implemented instead of resorting to quadratic programming software package a in other l norm approach experimental result on face representation and reconstruction show that our new robust tensor factorization method can effectively handle outlier compared to previous tensor based pca method 
this paper address human pose recognition from video sequence by formulating it a a classification problem unlike much previous work we do not make any assumption on the availability of clean segmentation the first step of this work consists in a novel method of aligning the training image using d mocap data next we define class by discretizing a d manifold whose two dimension are camera viewpoint and action our main contribution is a pose detection algorithm based on random forest a bottomup approach is followed to build a decision tree by recursively clustering and merging the class at each level for each node of the decision tree we build a list of potentially discriminative feature using the alignment of training image in this paper we consider histogram of orientated gradient hog we finally grow an ensemble of tree by randomly sampling one of the selected hog block at each node our proposed approach give promising result with both fixed and moving camera 
in this paper we propose a new computational model for visual saliency derived from the information maximization principle the model is inspired by a few well acknowledged biological fact to compute the saliency spot of an image the model first extract a number of sub band feature map using learned sparse code it adopts a fully connected graph representation for each feature map and run random walk on the graph to simulate the signal information transmission among the interconnected neuron we propose a new visual saliency measure called site entropy rate ser to compute the average information transmitted from a node neuron to all the others during the random walk on the graph network this saliency definition also explains the center surround mechanism from computation aspect we further extend our model to spatial temporal domain so a to detect salient spot in video to evaluate the proposed model we do extensive experiment on psychological stimulus two well known image data set a well a a public video dataset the experiment demonstrate encouraging result that the proposed model achieves the state of the art performance of saliency detection in both still image and video 
this paper describes a coarse to fine learning based image registration algorithm which ha particular advantage in dealing with multi modality image many existing image registration algorithm use a few designed term or mutual information to measure the similarity between image pair instead we push the learning aspect by selecting and fusing a large number of feature for measuring the similarity moreover the similarity measure is carried in a coarse to fine strategy global similarity measure is first performed to roughly locate the component we then learn compute similarity on the local image patch to capture the fine level information when estimating the transformation parameter we also engage a coarse tofine strategy off the shelf interest point detector such a sift have degraded result on medical image we further push the learning idea to extract the main structure landmark our algorithm is illustrated on three application registration of mouse brain image of different modality registering human brain image of mri t and t image face of different expression we show greatly improved result over the existing algorithm based on either mutual information or geometric structure 
oriented pattern e g fingerprint consist of smoothly varying flow like pattern together with important singular point i e core and delta where the orientation change abruptly gabor filter and anisotropic diffusion method have been widely used to enhance oriented pattern however none of them can well cope with region of varying curvature or region surrounding singular point by incorporating the ridge curvature and the singularity into the diffusion model we propose a new diffusion method to better exploit the global characteristic of oriented pattern specifically we first locate the singular point and regularize the estimated orientation field by using a singularity driven nonlinear diffusion process we then enhance the oriented pattern by applying an oriented diffusion process which is driven by the curvature and singularity experiment on synthetic data and real fingerprint image validated that the proposed method is capable of consistently enhancing oriented pattern while well preserving the ridge structure in singular region 
nonlinear registration is mostly performed after initialization by a global linear transformation in this work we focus on similarity transformation computed by a linear registration method for the further processing of the result it is mostly assumed that this preregistration step completely remove the respective linear transformation however we show that in deformable setting this is not the case a a consequence a significant linear component is still existent in the deformation computed by the nonlinear registration algorithm for construction of statistical shape model ssm from deformation this is an unwanted property ssms should not contain similarity transformation since these do not capture information about shape we propose a method which performs an a posteriori extraction of a similarity transformation from a given nonlinear deformation field and we use the processed field a input for ssm construction for computation of minimal displacement a closed form solution minimizing the squared euclidean norm of the displacement field subject to similarity parameter is used experiment on real inter subject data and on a synthetic example show that the theoretically justified removal of the similarity component by the proposed method ha a large influence on the shape model and significantly improves the result 
we propose a novel nonparametric bayesian model dual hierarchical dirichlet process dual hdp for trajectory analysis and semantic region modeling in surveillance setting in an unsupervised way in our approach trajectory are treated a document and observation of an object on a trajectory are treated a word in a document trajectory are clustered into different activity abnormal trajectory are detected a sample with low likelihood the semantic region which are intersection of path commonly taken by object related to activity in the scene are also modeled dual hdp advance the existing hierarchical dirichlet process hdp language model hdp only cluster co occurring word from document into topic and automatically decides the number of topic dual hdp co cluster both word and document it learns both the number of word topic and document cluster from data under our problem setting hdp only cluster observation of object while dual hdp cluster both observation and trajectory experiment are evaluated on two data set radar track collected from a maritime port and visual track collected from a parking lot 
hidden state shape model hssms were previously proposed to represent and detect object in image that exhibit not just deformation of their shape but also variation in their structure in this paper we introduce dynamic hidden state shape model dhssms to track and recognize the non rigid motion of such object for example human hand our recursive bayesian filtering method called dp tracking combine an exhaustive local search for a match between image feature and model state with a dynamic programming approach to find a global registration between the model and the object in the image our contribution is a technique to exploit the hierarchical structure of the dynamic programming approach that on average considerably speed up the search for match we also propose to embed an online learning approach into the tracking mechanism that update the dhssm dynamically the learning approach ensures that the dhssm accurately represents the tracked object and distinguishes any clutter potentially present in the image our experiment show that our method can recognize the digit of a hand while the finger are being moved and curled to various degree the method is robust to various illumination condition the presence of clutter occlusion and some type of self occlusion the experiment demonstrate a significant improvement in both efficiency and accuracy of recognition compared to the non recursive way of frame by frame detection 
estimating the illumination and the reflectance property of an object surface from a sparse set of image is an important but inherently ill posed problem the problem becomes even harder if we wish to account for the spatial variation of material property on the surface in this paper we derive a novel method for estimating the spatially varying specular reflectance property of a surface of known geometry a well a the illumination distribution from a specular only image for instance captured using polarization to separate reflection component unlike previous work we do not assume the illumination to be a single point light source we model specular reflection with a spherical statistical distribution and encode the spatial variation with radial basis function of it parameter this allows u to formulate the simultaneous estimation of spatially varying specular reflectance and illumination a a sound probabilistic inference problem in particular using csiszar s i divergence measure to solve it we derive an iterative algorithm similar to expectation maximization we demonstrate the effectiveness of the method on synthetic and real world scene 
identifying handled object i e object being manipulated by a user is essential for recognizing the person s activity an egocentric camera a worn on the body enjoys many advantage such a having a natural first person view and not needing to instrument the environment it is also a challenging setting where background clutter is known to be a major source of problem and is difficult to handle with the camera constantly and arbitrarily moving in this work we develop a bottom up motion based approach to robustly segment out foreground object in egocentric video and show that it greatly improves object recognition accuracy our key insight is that egocentric video of object manipulation is a special domain and many domain specific cue can readily help we compute dense optical flow and fit it into multiple affine layer we then use a max margin classifier to combine motion with empirical knowledge of object location and background movement a well a temporal cue of support region and color appearance we evaluate our segmentation algorithm on the large intel egocentric object recognition dataset with object and k frame we show that when combined with temporal integration figure ground segmentation improves the accuracy of a sift based recognition system from to and that of a latent hog system from to 
constrained local model clms have recently demonstrated good performance in non rigid object alignment tracking in comparison to leading holistic approach e g aams a major problem hindering the development of clms further for non rigid object alignment tracking is how to jointly optimize the global warp update across all local search response previous method have either used general purpose optimizers e g simplex method or graph based optimization technique unfortunately problem exist with both these approach when applied to clms in this paper we propose a new approach for optimizing the global warp update in an efficient manner by enforcing convexity at each local patch response surface furthermore we show that the classic lucas kanade approach to gradient descent image alignment can be viewed a a special case of our proposed framework finally we demonstrate that our approach receives improved performance for the task of non rigid face alignment tracking on the multipie database and the unbc mcmaster archive 
object recognition accuracy can be improved when information from multiple view is integrated but information in each view can often be highly redundant we consider the problem of distributed object recognition or indexing from multiple camera where the computational power available at each camera sensor is limited and communication between camera is prohibitively expensive in this scenario it is desirable to avoid sending redundant visual feature from multiple view traditional supervised feature selection approach are inapplicable a the class label is unknown at each camera in this paper we propose an unsupervised multi view feature selection algorithm based on a distributed coding approach with our method a gaussian process model of the joint view statistic is used at the receiver to obtain a joint encoding of the view without directly sharing information across encoders we demonstrate our approach on recognition and indexing task with multi view image database and show that our method compare favorably to an independent encoding of the feature from each camera 
this article proposes a method for learning object template composed of local sketch and local texture and investigates the relative importance of the sketch and texture for different object category local sketch and local texture in the object template account for shape and appearance respectively both local sketch and local texture are extracted from the map of gabor filter response the local sketch are captured by the local maximum of gabor response where the local maximum pooling account for shape deformation in object the local texture are captured by the local average of gabor filter response where the local average pooling extract texture information for appearance the selection of local sketch variable and local texture variable can be accomplished by a projection pursuit type of learning process where both type of variable can be compared and merged within a common framework the learning process return a generative model for image intensity from a relatively small number of training image the recognition or classification by template matching can then be based on log likelihood ratio score we apply the learning method to a variety of object and texture category the result show that both the sketch and texture are useful for classification and they complement each other 
the bilateral filter is a nonlinear filter that smoothes a signal while preserving strong edge it ha demonstrated great effectiveness for a variety of problem in computer vision and computer graphic and fast version have been proposed unfortunately little is known about the accuracy of such acceleration in this paper we propose a new signal processing analysis of the bilateral filter which complement the recent study that analyzed it a a pde or a a robust statistical estimator the key to our analysis is to express the filter in a higher dimensional space where the signal intensity is added to the original domain dimension importantly this signal processing perspective allows u to develop a novel bilateral filtering acceleration using downsampling in space and intensity this affords a principled expression of accuracy in term of bandwidth and sampling the bilateral filter can be expressed a linear convolution in this augmented space followed by two simple nonlinearities this allows u to derive criterion for downsampling the key operation and achieving important acceleration of the bilateral filter we show that for the same running time our method is more accurate than previous acceleration technique typically we are able to process a megapixel image using our acceleration technique in le than a second and have the result be visually similar to the exact computation that take several ten of minute the acceleration is most effective with large spatial kernel furthermore this approach extends naturally to color image and cross bilateral filtering 
this paper describes a new algorithm for recovering the d shape and motion of deformable and articulated object purely from uncalibrated d image measurement using an iterative factorization approach most solution to nonrigid and articulated structure from motion require metric constraint to be enforced on the motion matrix to solve for the transformation that upgrade the solution to metric space while in the case of rigid structure the metric upgrade step is simple since the motion constraint are linear deformability in the shape introduces non linearity in this paper we propose an alternating least square approach associated with a globally optimal projection step onto the manifold of metric constraint an important advantageof this new algorithm is it ability to handle missing data which becomes crucial when dealing with real video sequence with self occlusion we show successful result of our algorithm on synthetic and real sequence of both deformable and articulated data 
face detection ha advanced dramatically over the past three decade algorithm can now quite reliably detect face in clutter in or near real time however much still need to be done to provide an accurate and detailed description of external and internal feature this paper present an approach to achieve this goal previous learning algorithm have had limited success on this task because the shape and texture of facial feature varies widely under changing expression pose and illumination we address this problem with the use of subclass division in this approach we use an algorithm to automatically divide the training sample of each facial feature into a set of subclass each representing a distinct construction of the same facial component e g close versus open eye lid the key idea used to achieve accurate detection is to not only learn the textural information of the facial feature to be detected but that of it context i e surroundings this process permit a precise detection of key facial feature we then combine this approach with edge and color segmentation to provide an accurate and detailed detection of the shape of the major facial feature brow eye nose mouth and chin we use this face detection algorithm to obtain precise description of the facial feature in video sequence of american sign language asl sentence where the variability in expression can be extreme extensive experimental validation demonstrates our method is almost a precise a manual detection error 
when fitting finite mixture to multivariate data it is crucial to select the appropriate number of component under regularization theory we aim to resolve this ldquounsupervisedrdquo learning problem via regularizing the likelihood by the full entropy of posterior probability for finite mixture fitting two deterministic annealing implementation are further proposed for this entropy regularized likelihood erl learning through some asymptotic analysis of the deterministic annealing erl daerl learning we find that the global minimization of the erl function in an annealing way can lead to automatic model selection on finite mixture and also make our daerl algorithm le sensitive to initialization than the standard em algorithm the simulation experiment then demonstrate that our algorithm can provide some promising result just a our theoretic analysis moreover our algorithm are evaluated in the application of unsupervised image segmentation and shown to outperform other state of the art method 
partial differential equation pdes have been successfully applied to many computer vision and image processing problem however designing pdes requires high mathematical skill and good insight into the problem in this paper we show that the design of pdes could be made easier by borrowing the learning strategy from machine learning in our learning based pde l pde framework for image restoration there are two term in our pde model i a regularizer which encodes the prior knowledge of the image model and ii a linear combination of differential invariant which is data driven and can effectively adapt to different problem and complex condition the l pde is learnt from some input output pair of training sample via an optimal control technique the effectiveness of our l pde framework for image restoration is demonstrated with two exemplary application image denoising and inpainting where the pdes are obtained easily and the produced result are comparable to or better than those of traditional pdes which were elaborately designed 
in this paper we describe a nonlinear image representation based on divisive normalization that is designed to match the statistical property of photographic image a well a the perceptual sensitivity of biological visual system we decompose an image using a multi scale oriented representation and use student s t a a model of the dependency within local cluster of coefficient we then show that normalization of each coefficient by the square root of a linear combination of the amplitude of the coefficient in the cluster reduces statistical dependency we further show that the resulting divisive normalization transform is invertible and provide an efficient iterative inversion algorithm finally we probe the statistical and perceptual advantage of this image representation by examining it robustness to added noise and using it to enhance image contrast 
many perception problem involve datasets that are naturally comprised of multiple stream or modality for which supervised training data is only sparsely available in case where there is a degree of conditional independence between such view a class of semisupervised learning technique that are based on maximizing view agreement over unlabeled data ha been proven successful in a wide range of machine learning domain however these co training or multi view learning method have had relatively limited application in vision due in part to the assumption of constant perchannel noise model in this paper we propose a probabilistic heteroscedastic approach to co training that simultaneously discovers the amount of noise on a persample basis while solving the classic ation task this result in high performance in the presence of occlusion or other complex observation noise process we demonstrate our approach in two domain multi view object recognition from low delity sensor network and audio visual classic ation 
this paper present three novel method that enable bilateral filtering in constant time o without sampling constant time mean that the computation time of the filtering remains same even if the filter size becomes very large our first method take advantage of the integral histogram to avoid the redundant operation for bilateral filter with box spatial and arbitrary range kernel for bilateral filter constructed by polynomial range and arbitrary spatial filter our second method provides a direct formulation by using linear filter of image power without any approximation lastly we show that gaussian range and arbitrary spatial bilateral filter can be expressed by taylor series a linear filter decomposition without any noticeable degradation of filter response all these method drastically decrease the computation time by cutting it down constant time e g to second per mb image while achieving very high psnr s over db in addition to the computational advantage our method are straightforward to implement 
in this paper we aim at reconstructing d scene from image with unknown focal length downloaded from photosharing website such a flickr first we provide a minimal solution to finding the relative pose between a completely calibrated camera and a camera with an unknown focal length given six point correspondence we show that this problem ha up to nine solution in general and present two efficient solver to the problem they are based on gr obner basis resp on generalized eigenvalue computation we demonstrate by experiment with synthetic and real data that both solver are correct fast numerically stable and work well even in some situation when the classical point algorithm fails e g when optical ax of the camera are parallel or intersecting based on this solution we present a new efficient method for large scale structure from motion from unordered data set downloaded from the internet we show that this method can be effectively used to reconstruct d scene from collection of image with very few in principle single image with known focal length 
we present a new shape prior segmentation method using graph cut capable of segmenting multiple object the shape prior energy is based on a shape distance popular with level set approach we also present a multiphase graph cut framework to simultaneously segment multiple possibly overlapping object the multiphase formulation differs from multiway cut in that the former can account for object overlap by allowing a pixel to have multiple label we then extend the shape prior energy to encompass multiple shape prior unlike variational method a major advantage of our approach is that the segmentation energy is minimized directly without having to compute it gradient which can be a cumbersome task and often relies on approximation experiment demonstrate that our algorithm can cope with image noise and clutter a well a partial occlusion and affine transformation of the shape 
model based d tracker estimate the position rotation and joint angle of a given model from video data of one or multiple camera they often rely on image feature that are tracked over time but the accumulation of small error result in a drift away from the target object in this work we address the drift problem for the challenging task of human motion capture and tracking in the presence of multiple moving object where the error accumulation becomes even more problematic due to occlusion to this end we propose an analysis by synthesis framework for articulated model it combine the complementary concept of patchbased and region based matching to track both structured and homogeneous body part the performance of our method is demonstrated for rigid body body part and full human body where the sequence contain fast movement self occlusion multiple moving object and clutter we also provide a quantitative error analysis and comparison with other model based approach 
traditional face recognition system attempt to achieve a high recognition accuracy which implicitly assumes that the loss of all misclassifications are the same however in many real world task this assumption is not always reasonable for example it will be troublesome if a facerecognition based door locker misclassifies a family member a a stranger such that s he were not allowed to enter the house but it will be a much more serious disaster if a stranger were misclassified a a family member and allowed to enter the house in this paper we propose a framework which formulates the problem a a multi class costsensitive learning task and propose a theoretically sound method based on bayes decision theory to solve this problem experimental result demonstrate the effectiveness and efficiency of the proposed method 
we present an algorithm that quickly and accurately estimate vanishing point in image of man made environment contrary to previously proposed solution ours is neither iterative nor relies on voting in the space of vanishing point our formulation is based on a recently proposed algorithm for the simultaneous estimation of multiple model called j linkage our method avoids representing edge on the gaussian sphere and the computation and error measure are done in the image we show that a consistency measure between a vanishing point and an edge of the image can be computed in closed form while being geometrically meaningful finally given a set of estimated vanishing point we show how this consistency measure can be used to identify the three vanishing point corresponding to the manhattan direction we compare our algorithm with other approach on the york urban database and show significant performance improvement 
we propose a category independent method to produce a bag of region and rank them such that top ranked region are likely to be good segmentation of different object our key objective are completeness and diversity every object should have at least one good proposed region and a diverse set should be top ranked our approach is to generate a set of segmentation by performing graph cut based on a seed region and a learned affinity function then the region are ranked using structured learning based on various cue our experiment on bsds and pascal voc demonstrate our ability to find most object within a small bag of proposed region 
in recent year many research work have been carried out to recognize human action from video clip to learn an effective action classifier most of the previous approach rely on enough training label when being required to recognize the action in a different dataset these approach have to re train the model using new label however labeling video sequence is a very tedious and time consuming task especially when detailed spatial location and time duration are required in this paper we propose an adaptive action detection approach which reduces the requirement of training label and is able to handle the task of cross dataset action detection with few or no extra training label our approach combine model adaptation and action detection into a maximum a posterior map estimation framework which explores the spatial temporal coherence of action and make good use of the prior information which can be obtained without supervision our approach obtains state of the art result on kth action dataset using only of the training label in tradition approach furthermore we show that our approach is effective for the cross dataset detection which adapts the model trained on kth to two other challenging datasets 
a scattering vector is a local descriptor including multiscale and multi direction co occurrence information it is computed with a cascade of wavelet decomposition and complex modulus this scattering representation is locally translation invariant and linearizes deformation a supervised classification algorithm is computed with a pca model selection on scattering vector state of the art result are obtained for handwritten digit recognition and texture classification 
we present an efficient pixel sampling technique for histogram based search given a template image a a query a typical histogram based algorithm aim to find the location of the target in another large test image by evaluating a similarity measure for comparing the feature histogram of the template with that of each possible subwindow in the test image the computational cost would be high if each subwindow need to compute it histogram and evaluate the similarity measure in this paper we adopt the probability product kernel a the similarity measure and show that the computation of histogram and the evaluation of the kernel based similarity can be integrated through a sampling approach specifically we present a square root sampling method to avoid the computation of histogram and meanwhile reduce the number of pixel required for evaluating the similarity measure the proposed approximation algorithm is timeand memory efficient the time complexity of computing the similarity for each subwindow is o the memory requirement of our algorithm is not in proportion to the size of the template or the number of histogram bin which allows the use of more distinctive image representation for better search accuracy 
computational color constancy is the task of estimating the true reflectance of visible surface in an image in this paper we follow a line of research that assumes uniform illumination of a scene and that the principal step in estimating reflectance is the estimation of the scene illuminant we review recent approach to illuminant estimation firstly those based on formula for normalisation of the reflectance distribution in an image so called grey world algorithm and those based on a bayesian formulation of image formation in evaluating these previous approach we introduce a new tool in the form of a database of high quality indoor and outdoor image accurately labelled with illuminant and preserved in their raw form free of correction or normalisation this ha enabled u to establish several property experimentally firstly automatic selection of grey world algorithm according to image property is not nearly so effective a ha been thought secondly it is shown that bayesian illuminant estimation is significantly improved by the improved accuracy of prior for illuminant and reflectance that are obtained from the new dataset 
in this paper we introduce a new approach for modeling visual context for this purpose we consider the leaf of a hierarchical segmentation tree a elementary unit each leaf is described by feature of it ancestral set the region on the path linking the leaf to the root we construct region tree by using a high performance segmentation method we then learn the importance of different descriptor e g color texture shape of the ancestor for classification we report competitive result on the msrc segmentation dataset and the mit scene dataset showing that region ancestry efficiently encodes information about discriminative part object and scene 
gradient domain compositing is an essential tool in computer vision and it application e g seamless cloning panorama stitching shadow removal scene completion and reshuffling while easy to implement these gradient domain technique often generate bleeding artifact where the composited image region do not match one option is to modify the region boundary to minimize such mismatch however this option may not always be sufficient or applicable e g the user or algorithm may not allow the selection to be altered we propose a new approach to gradient domain compositing that is robust to inaccuracy and prevents color bleeding without changing the boundary location our approach improves standard gradient domain compositing in two way first we define the boundary gradient such that the produced gradient field is nearly integrable second we control the integration process to concentrate residual where they are le conspicuous we show that our approach can be formulated a a standard least square problem that can be solved with a sparse linear system akin to the classical poisson equation we demonstrate result on a variety of scene the visual quality and run time complexity compare favorably to other approach 
dynamic texture can be considered to be spatio temporally varying visual pattern in image sequence with certain temporal regularity we propose a novel and efficient approach to explore the violation of the brightness constancy assumption a an indication of presence of dynamic texture using simple optical flow technique we assume that dynamic texture region are those that have poor spatio temporal optical flow coherence further we propose a second approach that us robust global parametric motion estimator that effectively and efficiently detect motion outlier and which we exploit a powerful cue to localize dynamic texture experimental and comparative study on a range of synthetic and real world dynamic texture sequence show the feasibility of the proposed approach with result which are competitive to or better than recent state of art approach and significantly faster 
we study the object localization problem in image given a single hand drawn example or a gallery of shape a the object model although many shape matching algorithm have been proposed for the problem over the decade chamfer matching remains to be the preferred method when speed and robustness are considered in this paper we significantly improve the accuracy of chamfer matching while reducing the computational time from linear to sublinear shown empirically specifically we incorporate edge orientation information in the matching algorithm such that the resulting cost function is piecewise smooth and the cost variation is tightly bounded moreover we present a sublinear time algorithm for exact computation of the directional chamfer matching score using technique from d distance transforms and directional integral image in addition the smooth cost function allows to bound the cost distribution of large neighborhood and skip the bad hypothesis within experiment show that the proposed approach improves the speed of the original chamfer matching upto an order of and it is much faster than many state of art technique while the accuracy is comparable 
dynamic visual category learning call for efficient adaptation a new training image become available or new category are defined existing training image or category become modified or obsolete or when category are divided into subcategories or merged together we develop novel method for efficient incremental learning of svmbased visual category classifier to handle such dynamic task our method exploit previous classifier estimate to more efficiently learn the optimal parameter for the current set of training image and category we show empirically that for dynamic visual category task our incremental learning method are significantly faster than batch retraining 
in this paper we present a novel method for d structure acquisition based on structured light unlike classical structured light method in which a static projector illuminates a scene with time varying illumination pattern our technique make use of a moving projector emitting a static striped illumination pattern this projector is translated at a constant velocity in the direction of the projector s horizontal axis illuminating the object in this manner allows u to perform a per pixel analysis in which we decompose the recorded illumination sequence into a corresponding set of frequency component the dominant frequency in this set can be directly converted into a corresponding depth value this per pixel analysis allows u to preserve sharp edge in the depth image unlike classical structured light method the quality of our result is not limited by projector or camera resolution but is solely dependent on the temporal sampling density of the captured image sequence additional benefit include a significant robustness against common problem encountered with structured light method such a occlusion specular reflection subsurface scattering interreflection and to a certain extent projector defocus 
it ha been demonstrated by serre et al that the biologically inspired model bim is effective for object recognition it outperforms many state of the art method in challenging database however bim ha the following three problem a very heavycomputationalcost due to the dense input a disputable pooling operation in modeling relation of the visual cortex and blind feature selection in a feedforward framework to solve these problem we develop an enhanced bim ebim which remove uninformative input by imposing sparsity constraint utilizes a novel local weighted pooling operation with stronger physiological motivation and applies a feedback procedure that selects effective feature for combination empirical study on the caltech database and caltech database show that ebim is more effective and efficient than bim we also apply ebim to the mit cbcl street scene databaseto show it achieves comparable performance in comparison with the current best performance moreover the new system can process image with resolution at a rate of frame per second and enhances the speed time at least in comparison with bim in common application 
learning model for recognizing object with few or no training example is important due to the intrinsic long tailed distribution of object in the real world in this paper we propose an approach to use comparative object similarity the key insight is that given a set of object category which are similar and a set of category which are dissimilar a good object model should respond more strongly to example from similar category than to example from dissimilar category we develop a regularized kernel machine algorithm to use this category dependent similarity regularization our experiment on hundred of category show that our method can make significant improvement especially for category with no example 
i propose a notion of visual information a the complexity not of the raw image but of the image after the effect of nuisance factor such a viewpoint and illumination are discounted it is rooted in idea of j j gibson and stand in contrast to traditional information a entropy or coding length of the data regardless of it use and regardless of the nuisance factor affecting it the non invertibility of nuisance such a occlusion and quantization induces an information gap that can only be bridged by controlling the data acquisition process measuring visual information entail early vision operation tailored to the structure of the nuisance so a to be lossless with respect to visual decision and control task a opposed to data transmission and storage task implicit in traditional information theory i illustrate these idea on visual exploration whereby a shannonian explorer guided by the entropy of the data navigates unaware of the structure of the physical space surrounding it while a gibsonian explorer is guided by the topology of the environment despite measuring only image of it without performing d reconstruction the operational definition of visual information suggests desirable property that a visual representation should posse to best accomplish vision based decision and control task 
we consider the problem of estimating the depth of each pixel in a scene from a single monocular image unlike traditional approach which attempt to map from appearance feature to depth directly we first perform a semantic segmentation of the scene and use the semantic label to guide the d reconstruction this approach provides several advantage by knowing the semantic class of a pixel or region depth and geometry constraint can be easily enforced e g sky is far away and ground is horizontal in addition depth can be more readily predicted by measuring the difference in appearance with respect to a given semantic class for example a tree will have more uniform appearance in the distance than it doe close up finally the incorporation of semantic feature allows u to achieve state of the art result with a significantly simpler model than previous work 
we present a novel multi view denoising algorithm our algorithm take noisy image taken from different viewpoint a input and group similar patch in the input image using depth estimation we model intensity dependent noise in lowlight condition and use the principal component analysis and tensor analysis to remove such noise the dimensionality for both pca and tensor analysis are automatically computed in a way that is adaptive to the complexity of image structure in the patch our method is based on a probabilistic formulation that marginalizes depth map a hidden variable and therefore doe not require perfect depth estimation we validate our algorithm on both synthetic and real image with different content our algorithm compare favorably against several state of the art denoising algorithm 
in this paper we study the problem of subspace based face recognition under scenario with spatial misalignment and or image occlusion for a given subspace the embedding of a new datum and the underlying spatial misalignment parameter are simultaneously inferred by solving a constrained lscr norm optimization problem which minimizes the error between the misalignment amended image and the image reconstructed from the given subspace along with it principal complementary subspace a byproduct of this formulation is the capability to detect the underlying image occlusion extensive experiment on spatial misalignment estimation image occlusion detection and face recognition with spatial misalignment and image occlusion all validate the effectiveness of our proposed general formulation 
this paper provides a technique for measuring camera translation relatively w r t the scene from two image we demonstrate that the amount of the translation can be reliably measured for general a well a planar scene by the most frequent apical angle the angle under which the camera center are seen from the perspective of the reconstructed scene point simulated experiment show that the dominant apical angle is a linear function of the length of the true camera translation in a real experiment we demonstrate that by skipping image pair with too small motion we can reliably initialize structure from motion compute accurate camera trajectory in order to rectify image and use the ground plane constraint in recognition of pedestrian in a hand held video sequence 
in this paper we study the problem of nonnegative graph embedding originally investigated in j yang et al for reaping the benefit from both nonnegative data factorization and the specific purpose characterized by the intrinsic and penalty graph our contribution are two fold on the one hand we present a multiplicative iterative procedure for nonnegative graph embedding which significantly reduces the computational cost compared with the iterative procedure in involving the matrix inverse calculation of an m matrix on the other hand the nonnegative graph embedding framework is expressed in a more general way by encoding each datum a a tensor of arbitrary order which brings a group of byproduct e g nonnegative discriminative tensor factorization algorithm with admissible time and memory cost extensive experiment compared with the state of the art algorithm on nonnegative data factorization graph embedding and tensor representation demonstrate the algorithmic property in computation speed sparsity discriminating power and robustness to realistic image occlusion 
fusing partial estimate is a critical and common problem in many computer vision task such a part based detection and tracking it generally becomes complicated and intractable when there are a large number of multimodal partial estimate and thus it is desirable to find an effective and scalable fusion method to integrate these partial estimate this paper present a novel and effective approach to fusing multimodal partial estimate in a principled way in this new approach fusion is related to a computational geometry problem of finding the minimum volume orthotope and an effective and scalable branch and bound search algorithm is designed to obtain the global optimal solution experiment on tracking articulated object and occluded object show the effectiveness of the proposed approach 
we introduce a general formulation called non negative graph embedding for non negative data decomposition by integrating the characteristic of both intrinsic and penalty graph in the past such a decomposition wa obtained mostly in an unsupervised manner such a non negative matrix factorization nmf and it variant and hence unnecessary to be powerful at classification in this work the non negative data decomposition is studied in a unified way applicable for both unsupervised and supervised semi supervised configuration the ultimate data decomposition is separated into two part which separatively preserve the similarity measured by the intrinsic and penalty graph and together minimize the data reconstruction error an iterative procedure is derived for such a purpose and the algorithmic non negativity is guaranteed by the non negative property of the inverse of any m matrix extensive experiment compared with nmf and conventional solution for graph embedding demonstrate the algorithmic property in sparsity classification power and robustness to image occlusion 
in this paper general solution for nonlinear nonnegativecomponentanalysisfordatarepresentationandrecognition are proposed that is motivated by a combination of the nonnegative matrix factorization nmf algorithm andkerneltheory whichhasleadtoannmfalgorithmina polynomial feature space we propose a general framework where one can build a nonlinear nonnegative component analysis using kernel the so called projected gradient kernel nonnegative matrix factorization pgknmf in the proposed approach arbitrary positive kernel can be adopted while at the same time it is ensured that the limit point of the procedure is a stationary point of the optimization problem moreover we proposefixed point algorithm forthespecialcaseofradialbasisfunction rbf kernel we demonstrate the power of the proposed method in face and facial expression recognition application 
this paper examines the problem of extracting lowdimensional manifold structure given million of highdimensional face image specifically we address the computational challenge of nonlinear dimensionality reduction via isomap and laplacian eigenmaps using a graph containing about million node and million edge since most manifold learning technique rely on spectral decomposition we first analyze two approximate spectral decomposition technique for large dense matrix nystr om and column sampling providing the first direct theoretical and empirical comparison between these technique we next show extensive experiment on learning low dimensional embeddings for two large face datasets cmu pie thousand face and a web dataset million face our comparison show that the nystr om approximation is superior to the column sampling method furthermore approximate isomap tends to perform better than laplacian eigenmaps on both clustering and classification with the labeled cmu pie dataset 
the literature currently provides two way to establish point correspondence between image with moving object on one side there are energy minimization method that yield very accurate dense flow field but fail a displacement get too large on the other side there is descriptor matching that allows for large displacement but correspondence are very sparse have limited accuracy and due to missing regularity constraint there are many outlier in this paper we propose a method that can combine the advantage of both matching strategy a region hierarchy is established for both image descriptor matching on these region provides a sparse set of hypothesis for correspondence these are integrated into a variational approach and guide the local optimization to large displacement solution the variational optimization selects among the hypothesis and provides dense and subpixel accurate estimate making use of geometric constraint and all available image information 
we cast some new insight into solving the digital matting problem by treating it a a semi supervised learning task in machine learning a local learning based approach and a global learning based approach are then produced to fit better the scribble based matting and the trimap based matting respectively our approach are easy to implement because only some simple matrix operation are needed they are also extremely accurate because they can efficiently handle the nonlinear local color distribution by incorporating the kernel trick that are beyond the ability of many previous work our approach can outperform many recent matting method a shown by the theoretical analysis and comprehensive experiment the new insight may also inspire several more work 
a novel similarity measure for bag of word type large scale image retrieval is presented the similarity function is learned in an unsupervised manner requires no extra space over the standard bag of word method and is more discriminative than both l based soft assignment and hamming embedding we show experimentally that the novel similarity function achieves mean average precision that is superior to any result published in the literature on a number of standard datasets at the same time retrieval with the proposed similarity function is faster than the reference method 
we describe a method for producing a smooth stabilized video from the shaky input of a hand held light field video camera specifically a small camera array traditional stabilization technique dampen shake with d warp and thus have limited ability to stabilize a significantly shaky camera motion through a d scene other recent stabilization technique synthesize novel view a they would have been seen along a virtual smooth d camera path but are limited to static scene we show that video camera array enable much more powerful video stabilization since they allow change in viewpoint for a single time instant furthermore we point out that the straightforward approach to light field video stabilization requires computing structure from motion which can be brittle for typical consumer level video of general dynamic scene we present a more robust approach that avoids input camera path reconstruction instead we employ a spacetime optimization that directly computes a sequence of relative pose between the virtual camera and the camera array while minimizing acceleration of salient visual feature in the virtual image plane we validate our novel method by comparing it to state of the art stabilization software such a apple imovie and d steadymove pro on a number of challenging scene 
the traditional spm approach based on bag of feature bof requires nonlinear classifier to achieve good image classification performance this paper present a simple but effective coding scheme called locality constrained linear coding llc in place of the vq coding in traditional spm llc utilizes the locality constraint to project each descriptor into it local coordinate system and the projected coordinate are integrated by max pooling to generate the final representation with linear classifier the proposed approach performs remarkably better than the traditional nonlinear spm achieving state of the art performance on several benchmark compared with the sparse coding strategy the objective function used by llc ha an analytical solution in addition the paper proposes a fast approximated llc method by first performing a k nearest neighbor search and then solving a constrained least square fitting problem bearing computational complexity of o m k hence even with very large codebooks our system can still process multiple frame per second this efficiency significantly add to the practical value of llc for real application 
statistical model based segmentation of the left ventricle from cardiac image ha received considerable attention in recent year while a variety of statistical model have been shown to improve segmentation result most of them are either static model sm which neglect the temporal coherence of a cardiac sequence or generic dynamical model gdm which neglect the inter subject variability of cardiac shape and deformation in this paper we use a subject specific dynamical model ssdm that handle inter subject variability and temporal dynamic intra subject variability simultaneously it can progressively identify the specific motion pattern of a new cardiac sequence based on the segmentation observed in the past frame we formulate the integration of the ssdm into the segmentation process in a recursive bayesian framework in order to segment each frame based on the intensity information from the current frame and the prediction from the past frame we perform leave one out test on sequence to validate our approach quantitative analysis of experimental result show that the segmentation with the ssdm outperforms those with the sm and gdm by having better global and local consistency with the manual segmentation 
there are many computer vision algorithm developed for visual scene and object recognition some system focus on involved learning algorithm some leverage million of training image and some system focus on modeling relevant information feature with the goal of effective recognition however none of these system come close to human capability if we study human response on similar problem we could gain insight into which of the three factor learning algorithm amount of training data and feature is critical to human superior performance in this work we take a small step towards this goal by performing a series of human study and machine experiment we find no evidence that human pattern matching algorithm are better than standard machine learning algorithm moreover we find that human don t leverage increased amount of training data through statistical analysis on the machine experiment and supporting human study we find that the main factor impacting accuracy is the choice of feature 
this paper present geos a new algorithm for the efficient segmentation of n dimensional image and video data the segmentation problem is cast a approximate energy minimization in a conditional random field a new parallel filtering operator built upon efficient geodesic distance computation is used to propose a set of spatially smooth contrast sensitive segmentation hypothesis an economical search algorithm find the solution with minimum energy within a sensible and highly restricted subset of all possible labellings advantage include i computational efficiency with high segmentation accuracy ii the ability to estimate an approximation to the posterior over segmentation iii the ability to handle generally complex energy model comparison with max flow indicates up to time greater computational efficiency a well a greater memory efficiency geos is validated quantitatively and qualitatively by thorough comparative experiment on existing and novel ground truth data numerous result on interactive and automatic segmentation of photograph video and volumetric medical image data are presented 
this paper focus on hallucinating a facial shape from a low resolution d facial shape firstly we give a constrained conformal embedding of d shape in r w hich establishes an isomorphic mapping between curved facial surface and d planar domain with such conformal embedding two planar representation of d shape are proposed gaussian curvature image gci for a facial surface and surface displacement image sdi for a pair of facial surface the conformal planar representation reduces the data complexity from d irregular curved surface to d regular grid while preserving the necessary information for hallucination then hallucinating a low resolution facial shape is formalized a inference of sdi from gcis by modeling the relationship between gci and sdi by rbf regression the experiment on usf humanid d face database demonstrate the effectiveness of the approach our method can be easily extended to hallucinate those category specific d surface sharing with similar geometric structure 
in practice nonnegative data factorization is often performed for data dimensionality reduction prior to a classification task using a classifier which is effective in low dimensional space such a nearest neighbor classifier in this work we propose a novel formulation to learn a multi class classifier directly through a supervised nonnegative data factorization this new formulation ha the following property the nonnegative data matrix is approximated a the product of a nonnegative basis matrix and a coefficient matrix where the nonnegative base distinctively capture the common characteristic of all class apart from that specific to individual class a regularization term is imposed on nonnegative data factorization so that each datum can be predominantly reconstructed by the common basis vector and it corresponding class specific basis vector and the coefficient vector for each datum is assumed to be transformed from a mapped kernel space and the l norm of the class specific coefficient reveals the relative confidence of class which then directly lead to a multi class classifier we also present an iterative optimization technique for our formulation and analytically show it convergence property extensive experiment on face recognition head pose estimation and handwritten digit recognition task clearly demonstrate the advantage of the proposed classifier over the conventional two step approach of nonnegative data factorization followed by a classic classifier 
active contour is a popular technique for image segmentation however active contour tend to converge to the closest local minimum of it energy function and often requires a close boundary initialization we introduce a new approach that overcomes the close boundary initialization problem by reformulating the external energy term we treat the active contour a a mean curve of the probability density function p x it move to minimize the kullback leibler kl divergence between p x and the probability density function derived from the image kl divergence force p x to cover all image area and the uncovered area are heavily penalized which allows the active contour to go over the edge also we use deterministic annealing on the width of p x to implement a coarse to ne search strategy in the limit when the width of p x go to zero the kl divergence function converges to the conventional external energy term which can be seen a special case of active contour our method produce robust segmentation result from arbitrary initialization position 
obtaining ground truth motion for arbitrary real world video sequence is a challenging but important task for both algorithm evaluation and model design existing ground truth database are either synthetic such a the yosemite sequence or limited to indoor experimental setup such a the database developed by baker et al we propose a human in loop methodology to create a ground truth motion database for the video taken with ordinary camera in both indoor and outdoor scene using the fact that human being are expert at segmenting object and inspecting the match between two frame we designed an interactive computer vision system to allow a user to efficiently annotate motion our methodology is cross validated by showing that human annotated motion is repeatable consistent across annotator and close to the ground truth obtained by baker et al using our system we collected and annotated indoor and outdoor real world video to form a ground truth motion database the source code annotation tool and database is online for public evaluation and benchmarking 
in this paper we present a new approach for image labeling based on the recently introduced graph shift algorithm graph shift is an energy minimization algorithm that doe labeling by dynamically manipulating or shifting the parent child relationship in a hierarchical decomposition of the image each shift optimally reduces the energy by indirectly causing a change to the labeling graph shift is able to rapidly compute and select this optimal shift at every iteration there are no constraint on the term of the pairwise energy function the algorithm wa originally presented in the context of medical image labeling using conditional random field model in this paper we consider the algorithm in the context of both lowand highlevel natural image labeling we show that for example in both class of problem graph shift doe labeling both accurately and rapidly for low level vision we explore image restoration and for high level vision we make use of a hybrid discriminative generative model to segment and label image into semantically meaningful region e g tree building etc for both problem we obtain comparable or superior result to the state of the art computed in just a few second per image 
the layered dynamic texture ldt is a generative model which represents video a a collection of stochastic layer of different appearance and dynamic each layer is modeled a a temporal texture sampled from a different linear dynamical system with region of the video assigned to a layer using a markov randomfield model parameter are learned from training video using the em algorithm however exact inference for the e step is intractable in this paper we propose a variational approximation for the ldt that enables efficient learning of the model we also propose a temporally switching ldt t ldt which allows the layer shape to change over time along with the associated em algorithm and variational approximation the ability of the ldt to segment video into layer of coherent appearance and dynamic is also extensively evaluated on both synthetic and natural video these experiment show that the model posse an ability to group region of globally homogeneous but locally heterogeneous stochasticdynamics currently unparalleled in the literature 
this paper address the problem of characterizing a general class of camera under reasonable linear assumption concretely we use the formalism and terminology of classical projective geometry to model camera by two parameter linear family of straight line that is degenerate regulus rank family and non degenerate linear congruence rank family this model capture both the general linear camera of yu and mcmillan and the linear oblique camera of pajdla from a geometric perspective it affords a simple classification of all possible camera configuration from an analytical viewpoint it also provides a simple and unified methodology for deriving general formula for projection and inverse projection triangulation and binocular and trinocular geometry 
obscure glass is textured glass designed to separate space and obscure visibility between the space such glass is used to provide privacy while still allowing light to ow into a space and is often found in home and oces we propose and explore the challenge of seeing through obscure glass using both optical and digital technique in some case such a when the textured surface is on the side of the observer we nd that simple household substance and camera with small aperture enable a surprising level of visibility through the obscure glass in other case where optical technique are not usable we nd that we can model the action of obscure glass a convolution of spatially varying kernel and reconstruct an image of the scene on the opposite side of the obscure glass with surprising detail 
random forest rf have become commonplace in many computer vision application their popularity is mainly driven by their high computational efficiency during both training and evaluation while still being able to achieve state of the art accuracy this work extends the usage of random forest to semi supervised learning ssl problem we show that traditional decision tree are optimizing multiclass margin maximizing loss function from this intuition we develop a novel multi class margin definition for the unlabeled data and an iterative deterministic annealing style training algorithm maximizing both the multi class margin of labeled and unlabeled sample in particular this allows u to use the predicted label of the unlabeled data a additional optimization variable furthermore we propose a control mechanism based on the out of bag error which prevents the algorithm from degradation if the unlabeled data is not useful for the task our experiment demonstrate state of the art semisupervised learning performance in typical machine learning problem and constant improvement using unlabeled data for the caltech object categorization task 
although the recent advance in the sparse representation of image have achieved outstanding denosing result removing real structured noise in digital video remains a challenging problem we show the utility of reliable motion estimation to establish temporal correspondence across frame in order to achieve high quality video denoising in this paper we propose an adaptive video denosing framework that integrates robust optical flow into a nonlocal mean nlm framework with noise level estimation the spatial regularization in optical flow is the key to ensure temporal coherence in removing structured noise furthermore we introduce approximate k nearest neighbor matching to significantly reduce the complexity of classical nlm method experimental result show that our system is comparable with the state of the art in removing awgn and significantly outperforms the state of the art in removing real structured noise 
labeling image collection is a tedious task especially when multiple label have to be chosen for each image in this paper we introduce a new framework that extends state of the art model in word prediction to incorporate information from unlabeled example using manifold regularization to the best of our knowledge this is the first semisupervised multi task model used in vision problem the new model can be solved using gradient descent and is fast and efficient we show remarkable improvement for case with few labeled example for challenging multi task learning problem in vision predicting word for image and attribute for object 
we propose a novel algorithm for uncalibrated photometric stereo while most of previous method rely on various assumption on scene property we exploit constraint in lighting configuration we first derive an ambiguous reconstruction by requiring light to lie on a view centered cone this reconstruction is upgraded to euclidean by constraint derived from light of equal intensity and multiple view geometry compared to previous method our algorithm deal with more general data and achieves high accuracy another advantage of our method is that we can model weak perspective effect of lighting while previous method often assume orthographical illumination we use both synthetic and real data to evaluate our algorithm we further build a hardware prototype to demonstrate our approach 
in this paper we present a patch based regression framework for addressing the human age and head pose estimation problem firstly each image is encoded a an ensemble of orderless coordinate patch the global distribution of which is described by gaussian mixture model gmm and then each image is further expressed a a specific distribution model by maximum a posteriori adaptation from the global gmm then the patch kernel is designed for characterizing the kullback leibler divergence between the derived model for any two image and it discriminating power is further enhanced by a weak learning process called inter modality similarity synchronization finally kernel regression is employed for ultimate human age or head pose estimation these three stage are complementary to each other and jointly minimize the regression error the effectiveness of this regression framework is validated by three experiment on the yamaha aging database our solution brings a more than reduction in age estimation error compared with the best reported result on the fg net aging database our solution based on raw image feature performs even better than the stateof the art algorithm which require fine face alignment for extracting warped appearance feature and on the chil head pose database our solution significantly outperforms the best one reported in the clear evaluation 
this paper present a new approach for fitting a d morphable model to image of face using self adapting feature layer safl the algorithm integrates feature detection into an iterative analysis by synthesis framework combining the robustness of feature search with the flexibility of model fitting template for facial feature are created and updated while the fitting algorithm converges so the template adapt to the pose illumination shape and texture of the individual face unlike most existing feature based method the algorithm doe not search for the image location with maximum response which may be prone to error but form a tradeoff between feature likeness global feature configuration and image reconstruction error the benefit of the proposed method is an increased robustness of model fitting with respect to error in the initial feature point position such residual error are a problem when feature detection and model fitting are combined to form a fully automated face reconstruction or recognition system we analyze the robustness in a face recognition scenario on image from two database frgc and feret 
we study the problem of estimating the position and orientation of a calibrated camera from an image of a known scene a common problem in camera pose estimation is the existence of false correspondence between image feature and modeled d point existing technique such a ransac to handle outlier have no guarantee of optimality in contrast we work with a natural extension of the l norm to the outlier case using a simple result from classical geometry we derive necessary condition for l optimality and show how to use them in a branch and bound setting to find the optimum and to detect outlier the algorithm ha been evaluated on synthetic a well a real data showing good empirical performance in addition for case with no outlier we demonstrate shorter execution time than existing optimal algorithm 
feature based method have found increasing use in many application such a object recognition d reconstruction and mosaicing in this paper we focus on the problem of matching such feature while a histogram ofgradients type method such a sift gloh and shape context are currently popular several paper have suggested using order of pixel rather than raw intensity and shown improved result for some application the paper suggest two different technique for doing so a histogram of relative order in the patch and a histogram of lbp code while these method have shown good performance they neglect the fact that the order can be quite noisy in the presence of gaussian noise in this paper we propose change to these approach to make them robust to gaussian noise we also show how the descriptor can be matched using recently developed more advanced technique to obtain better matching performance finally we show that the two method have complimentary strength and that by combining the two descriptor one obtains much better result than either of them considered separately the result are shown on the standard d oxford and the d caltech datasets 
this paper proposes a hierarchical framework that resamples d reconstructed point to reduce computation cost on time and memory for very large scale structure from motion the goal is to maintain accuracy and stability similar for different resample rate we consider this problem in a level of detail perspective from a very large scale global and sparse bundle adjustment to a very detailed and local dense optimization the dense matching are resampled by exploring the redundancy using local invariant property while d point are resampled by exploring the redundancy using their covariance and their distribution in both d and image space detailed experiment on our resample framework are provided we also demonstrate the proposed framework on large scale example the result show that the proposed resample scheme can produce a d reconstruction with the stability similar to quasi dense method while the problem size is a neat a sparse method 
we propose a dimension reduction technique named resilient subclass discriminant analysis rsda for high dimensional classification problem the technique iteratively estimate the subclass division by embedding the fisher discriminant analysis fda with expectation maximization em in gaussian mixture model gmm the new method maintains the adaptability of sda to a wide range of data distribution by approximating the distribution of each class a a mixture of gaussians and provides superior feature selection performance to sda with modified em clustering that estimate a posteriori probability of latent variable in lower dimensional fisher s discriminant space which also improves the robustness in problem of small training datasets compared with conventional em algorithm extensive experiment and comparison result against other well known discriminant analysis da method are presented using synthetic data benchmark datasets a well a a real computational vision problem 
structured output such a multidimensional vector or graph are frequently encountered in real world pattern recognition application such a computer vision natural language processing or computational biology this motivates the learning of functional dependency between space with complex interdependent input and output a arising e g from image and their corresponding d scene representation in this spirit we propose a new structure d learning method structured output associative regression soar that model not only the input dependency but also the self dependency of output in order to provide an output re correlation mechanism that complement the more standard input based regressive prediction th e model is simple but powerful and in principle applicable in conjunction with any existing regression algorithm soar can be kernelized to deal with non linear problem and learning is efficient via primal dual formulation not unlike one used for kernel ridge regression or support vector regression we demonstrate that the method outperforms weighted nearest neighbor and regression method for the reconstruction of image of handwritten digit and for d human pose estimation from video in the humaneva benchmark 
geometric rearrangement of image includes operation such a image retargeting inpainting or object rearrangement each such operation can be characterized by a shiftmap the relative shift of every pixel in the output image from it source in an input image we describe a new representation of these operation a an optimal graph labeling where the shift map represents the selected label for each output pixel two term are used in computing the optimal shift map i a data term which indicates constraint such a the change in image size object rearrangement a possible saliency map etc ii a smoothness term minimizing the new discontinuity in the output image caused by discontinuity in the shift map this graph labeling problem can be solved using graph cut since the optimization is global and discrete it outperforms state of the art method in most case efficient hierarchical solution for graph cut are presented and operation on m image can take only a few second 
underwater natural illumination typically varies strongly temporally and spatially the reason is that wave on the water surface refract light into the water in a spatiotemporally varying manner the resulting underwater illumination field is known a underwater caustic or flicker in past study flicker ha often been considered to be an undesired effect which degrades the quality of image in contrast in this work we show that flicker can actually be useful for vision in the underwater domain specifically it solves very simply accurately and densely the stereo correspondence problem irrespective of the object s texture the temporal radiance variation due to flicker are unique to each object point thus disambiguating the correspondence with very simple calculation this process is further enhanced by compounding the spatial variability in the flicker field the method is demonstrated by underwater in situ experiment 
we propose a biologically inspired framework for visual tracking based on discriminant center surround saliency at each frame discrimination of the target from the background is posed a a binary classification problem from a pool of feature descriptor for the target and background a subset that is most informative for classification between the two is selected using the principle of maximum marginal diversity using these feature the location of the target in the next frame is identified using top down saliency completing one iteration of the tracking algorithm we also show that a simple extension of the framework to include motion feature in a bottom up saliency mode can robustly identify salient moving object and automatically initialize the tracker the connection of the proposed method to existing work on discriminant tracking are discussed experimental result comparing the proposed method to the state of the art in tracking are presented showing improved performance 
we present a self calibrating photometric stereo method from a set of image taken from a fixed viewpoint under different and unknown lighting condition our method automatically determines a radiometric response function and resolve the generalized ba relief ambiguity for estimating accurate surface normal and albedo we show that color and intensity profile which are obtained from registered pixel across image serve a effective cue for addressing these two calibration problem a a result we develop a complete auto calibration method for photometric stereo the proposed method is useful in many practical scenario where calibration are difficult experimental result validate the accuracy of the proposed method using various real world scene 
pedestrian detection is a key problem in computer vision with several application including robotics surveillance and automotive safety much of the progress of the past few year ha been driven by the availability of challenging public datasets to continue the rapid rate of innovation we introduce the caltech pedestrian dataset which is two order of magnitude larger than existing datasets the dataset contains richly annotated video recorded from a moving vehicle with challenging image of low resolution and frequently occluded people we propose improved evaluation metric demonstrating that commonly used perwindow measure are flawed and can fail to predict performance on full image we also benchmark several promising detection system providing an overview of state of theart performance and a direct unbiased comparison of existing method finally by analyzing common failure case we help identify future research direction for the field 
one of the main limitation of image search based on bag of feature is the memory usage per image only a few million image can be handled on a single machine in reasonable response time in this paper we first evaluate how the memory usage is reduced by using lossless index compression we then propose an approximate representation of bag of feature obtained by projecting the corresponding histogram onto a set of pre defined sparse projection function producing several image descriptor coupled with a proper indexing structure an image is represented by a few hundred byte a distance expectation criterion is then used to rank the image our method is at least one order of magnitude faster than standard bag of feature while providing excellent search quality 
we address the problem of incorporating user preference in automatic image enhancement unlike generic tool for automatically enhancing image we seek to develop method that can first observe user preference on a training set and then learn a model of these preference to personalize enhancement of unseen image the challenge of designing such system lie at intersection of computer vision learning and usability we use technique such a active sensor selection and distance metric learning in order to solve the problem the experimental evaluation based on user study indicates that different user do have different preference in image enhancement which suggests that personalization can further help improve the subjective quality of generic image enhancement 
in this paper we present an enhanced pictorial structure p model for precise eye localization a fundamental problem involved in many face processing task p is a computationally efficient framework for part based object modelling for face image taken under uncontrolled condition however the traditional p model is not flexible enough for handling the complicated appearance and structural variation to extend p we propose a discriminative p model for a more accurate part localization when appearance change seriously introduce a series of global constraint to improve the robustness against scale rotation and translation and adopt a heuristic prediction method to address the difficulty of eye localization with partial occlusion experimental result on the challenging lfw labeled face in the wild database show that our model can locate eye accurately and efficiently under a broad range of uncontrolled variation involving pose expression lighting camera quality occlusion etc 
face recognition algorithm need to deal with variable lighting condition near infrared nir image based face recognition technology ha been proposed to effectively overcome this difficulty however it requires that the enrolled face image be captured using nir image whereas many application require visual vi image for enrollment template to take advantage of nir face image for illumination invariant face recognition and allow the use of vi face image for enrollment we encounter a new face image pattern recognition problem that is heterogeneous face matching between nir versus vi face in this paper we present a subspace learning framework named coupled spectral regression csr to solve this challenge problem of coupling the two type of face image and matching between them csr first model the property of different type of data separately and then learns two associated projection to project heterogeneous data e g vi and nir respectively into a discriminative common subspace in which classification is finally performed compared to other existing method csr is computational efficient benefiting from the efficiency of spectral regression and ha better generalization performance experimental result on vi nir face database show that the proposed csr method significantly outperforms the existing method 
in this paper we propose a novel learning based face hallucination framework built in dct domain which can recover the high resolution face image from a single low resolution one unlike most previous learning based work our approach address the face hallucination problem from a different angle in detail the problem is formulated a inferring dct coefficient in frequency domain instead of estimating pixel intensity in spatial domain experimental result show that dc coefficient can be estimated fairly accurately by simple interpolation based method ac coefficient which contain the information of local feature of face image cannot be estimated well using interpolation we propose a method to infer ac coefficient by introducing an efficient learning based inference model moreover the proposed framework can lead to significant saving in memory and computation cost since the redundancy of the training set is reduced a lot by clustering experimental result demonstrate that our approach is very effective to produce hallucinated face image with high quality 
the paper present a fuzzy chamfer distance and it probabilistic formulation for edge based visual tracking first connection of the chamfer distance and the hausdorff distance with fuzzy objective function for clustering are shown using a reformulation theorem a fuzzy chamfer distance fcd based on fuzzy objective function and a probabilistic formulation of the fuzzy chamfer distance pfcd based on data association method are then presented for tracking which can all be regarded a reformulated fuzzy objective function and minimized with iterative algorithm result on challenging sequence demonstrate the performance of the proposed tracking method 
we propose a d registration method for multi modal image sequence of the retinal fundus and a d metric reconstruction of near planar surface from multiple view there are two major contribution in our paper for d registration our method produce high registration rate whi le accounting for large modality difference compared with the state of the art method our approach ha higher registration rate v while the computation time is much le this is achieved by extracting feature from the edge map of the contrast enhanced image and performing pairwise registration by matching the feature in an iterative manner maximizing the number of match and estimating homographies accurately the pairwise registration result is further globally optimized by an indire ct registration process for d registration part image are registered to the reference frame by transforming point vi a a reconstructed d surface the challenge is the reconstruction of a near planar surface in which the shallow depth make it a quasi degenerate case for estimating the geometry from image our contribution is the proposed pas bundle adjustment method that give optimal estimation of all camera pose with accurate camera pose the d surface can be reconstructed using the image associated with the camera with the largest baseline compared with state of the art d retinal image registration method our approach produce better result in all image set 
finding the largest consensus set is one of the key idea used by the original ransac for removing outlier in robust estimation however because of it random and non deterministic nature ransac doe not fulfill the goal of consensus set maximization exactly and optimally based on global optimization this paper present a new algorithm that solves the problem exactly we reformulate the problem a a mixed integer programming mip and solve it via a tailored branch and bound method where the bound are computed from the mip s convex under estimator by exploiting the special structure of linear robust estimation the new algorithm is also made efficient from a computational point of view 
nonnegative matrix factorization nmf approximates a given data matrix a a product of two low rank nonnegative matrix usually by minimizing the l or the kl distance between the data matrix and the matrix product this factorization wa shown to be useful for several important computer vision application we propose here a new nmf algorithm that minimizes the earth mover s distance emd error between the data and the matrix product we propose an iterative nmf algorithm emd nmf and prove it convergence the algorithm is based on linear programming we discus the numerical difficulty of the emd nmf and propose an efficient approximation naturally the matrix obtained with emd nmf are different from those obtained with l nmf we discus these difference in the context of two challenging computer vision task texture classification and face recognition and demonstrate the advantage of the proposed method 
viewpoint invariant pedestrian recognition is an important yet under addressed problem in computer vision this is likely due to the difficulty in matching two object with unknown viewpoint and pose this paper present a method of performing viewpoint invariant pedestrian recognition using an efficiently and intelligently designed object representation the ensemble of localized feature elf instead of designing a specific feature by hand to solve the problem we define a feature space using our intuition about the problem and let a machine learning algorithm find the best representation we show how both an object class specific representation and a discriminative recognition model can be learned using the adaboost algorithm this approach allows many different kind of simple feature to be combined into a single similarity function the method is evaluated using a viewpoint invariant pedestrian recognition dataset and the result are shown to be superior to all previous benchmark for both recognition and reacquisition of pedestrian 
in this paper we present a novel iris recognition method based on learned ordinal feature firstly taking full advantage of the property of iris texture a new iris representation method based on regional ordinal measure encoding is presented which provides an over complete iris feature set for learning secondly a novel similarity oriented boosting soboost algorithm is proposed to train an efficient and stable classifier with a small set of feature compared with adaboost soboost is advantageous in that it operates on similarity oriented training sample and therefore provides a better way for boosting strong classifier finally the well known cascade architecture is adopted to reorganize the learned soboost classifier into a cascade by which the searching ability of iris recognition towards large scale deployment is greatly enhanced extensive experiment on two challenging iris image database demonstrate that the proposed method achieves state ofthe art iris recognition accuracy and speed in addition soboost outperforms adaboost gentle adaboost jsadaboost etc in term of both accuracy and generalization capability across different iris database 
we present a novel method for automatically geo tagging photograph of man made environment via detection and matching of repeated pattern highly repetitive environment introduce numerous correspondence ambiguity and are problematic for traditional wide baseline matching method our method exploit the highly repetitive nature of urban environment detecting multiple perspectively distorted periodic d pattern in an image and matching them to a d database of textured facade by reasoning about the underlying canonical form of each pattern multiple d to d pattern correspondence enable robust recovery of camera orientation and location we demonstrate the success of this method in a large urban environment 
most existing structure from motion method follow a common two step scheme where relative camera motion are estimated in the first step and d structure is computed afterward in the second step this paper present a novel scheme which bypass the motion estimation step and go directly to structure computation step by introducing graph rigidity theory to sfm problem we demonstrate that such a scheme is not only theoretically possible but also technically feasible and effective we also derive a new convex relaxation technique based on semi definite programming which implement the above scheme very efficiently our new method provides other benefit a well such a that it offer a new way to looking at sfm and that it is naturally suited for handling sparse large scale sfm problem 
many object contain spatially distinct region each with a unique colour texture model mixture model ignore the spatial distribution of colour within an object and thus cannot distinguish between coherent part versus randomly distributed colour we show how to encode geometric interaction between distinct region boundary model such a region being interior exterior to each other along with preferred distance between their boundary with a single graph cut our method extract only those multi region object that satisfy such a combined model we show application in medical segmentation and scene layout estimation unlike li et al we do not need domain unwrapping nor do we have topological limit on shape 
scene categorization is a fundamental problem in computer vision however scene understanding research ha been constrained by the limited scope of currently used database which do not capture the full variety of scene category whereas standard database for object categorization contain hundred of different class of object the largest available dataset of scene category contains only class in this paper we propose the extensive scene understanding sun database that contains category and image we use well sampled category to evaluate numerous state of the art algorithm for scene recognition and establish new bound of performance we measure human scene classification performance on the sun database and compare this with computational method additionally we study a finer grained scene representation to detect scene embedded inside of larger scene 
we propose a space time markov random field mrf model to detect abnormal activity in video the node in the mrf graph correspond to a grid of local region in the videoframes andneighboringnodesin both spaceandtime are associated with link to learn normal pattern of activity at each local node we capture the distribution of it typical optical flow with a mixture of probabilistic principal component analyzer for any new optical flow pattern detected in incoming video clip we use the learned model and mrf graph to compute a maximum a posteriori estimate of the degree of normality at each local node further we show how to incrementally update the current model parameter a new video observation stream in so that the model can efficiently adapt to visual context change over a long period of time experimental result on surveillance video show that our space time mrf model robustly detects abnormal activity both in a local and global sense not only doesit accurately localize the atomic abnormalactivities in a crowded video but at the same time it capture the global level abnormality caused by irregular interaction between local activity 
diffusion tensor magnetic resonance imaging dt mri is a non invasive imaging technique allowing to estimate the molecular self diffusion tensor of water within surrounding tissue due to the low signal to noise ratio of magnetic resonance image reconstructed tensor image usually require some sort of regularization in a post processing step previous approach are either suboptimal with respect to the reconstructing or regularization step this paper present a bayesian approach for simultaneous reconstructing and regularization of dt mr image that allows to resolve the disadvantage of previous approach to this end estimation theoretical concept are generalized to tensor valued image that are considered a riemannian manifold doing so allows u to derive a maximum a posterior estimator of the tensor image that considers both the statistical characteristic of the rician noise occurring in mr image a well a the nonlinear structure of tensor valued image experiment on synthetic data a well a real dt mri data validate the advantage of considering both statistical a well a geometrical characteristic of dt mri 
camera equipped mini uavs are popular for many application including search and surveillance but video from them is commonly plagued with distracting jittery motion and disorienting rotation that make it difficult for human viewer to detect object of interest and infer spatial relationship for time critical search situation there are also inherent tradeoff between detection and search speed these problem make the use of dynamic mosaic to expand the spatiotemporal property of the video appealing however for many application it may not be necessary to maintain full mosaic of all of the video but to mosaic and retain only a number of recent temporally local frame still providing a larger field of view and effectively longer temporal view a well a natural stabilization and consistent orientation this paper present and evaluates a real time system for displaying live video to human observer in search situation by using temporally local mosaic while avoiding masking effect from dropped or noisy frame it primary contribution is an empirical study of the effectiveness of using such method for enhancing human detection of object of interest which show that temporally local mosaic increase task performance and are easier for human to use than non mosaiced method including stabilized video 
in this paper we propose an online interactive matting algorithm which we call fuzzymatte our framework is based on computing the fuzzy connectedness fc f rom each unknown pixel to the known foreground and background fc effectively capture the adjacency and similarity between image element and can be efficiently computed using the strongest connected path searching algorithm the final alpha value at each pixel can then be calculated from it fc while many previous method need to completely recompute the matte when new input are provided fuzzymatte effectively integrates these new input with the previously estimated matte by efficiently recomputing the fc value for a small subset of pixel thus the computational overhead between each iteration of the refinement is significantly reduced we demonstrate fuzzymatte on a wide range of image we show that fuzzymatte update the matte in an online interactive setting and generates high quality matte for complex image 
we propose a new family of algorithm for denoising data assumed to lie on a low dimensional manifold the algorithm are based on the blurring mean shift update which move each data point towards it neighbor but constrain the motion to be orthogonal to the manifold the resulting algorithm are nonparametric simple to implement and very effective at removing noise while preserving the curvature of the manifold and limiting shrinkage they deal well with extreme outlier and with variation of density along the manifold we apply them a preprocessing for dimensionality reduction and for nearest neighbor classification of mnist digit with consistent improvement up to over the original data 
regression analysis is a powerful tool for the study of change in a dependent variable a a function of an independent regressor variable and in particular it is applicable to the study of anatomical growth and shape change when the underlying process can be modeled by parameter in a euclidean space classical regression technique hardle applied nonparametric regression wand and jones kernel smoothing are applicable and have been studied extensively however recent work suggests that attempt to describe anatomical shape using flat euclidean space undermines our ability to represent natural biological variability fletcher et al ieee trans med imaging grenander and miller q appl math in this paper we develop a method for regression analysis of general manifold valued data specifically we extend nadaraya watson kernel regression by recasting the regression problem in term of fr chet expectation although this method is quite general our driving problem is the study anatomical shape change a a function of age from random design image data we demonstrate our method by analyzing shape change in the brain from a random design dataset of mr image of healthy adult ranging in age from to year to study the small scale change in anatomy we use the infinite dimensional manifold of diffeomorphic transformation with an associated metric we regress a representative anatomical shape a a function of age from this population 
we propose a learning based hierarchical approach of multi target tracking from a single camera by progressively associating detection response into longer and longer track fragment tracklets and finally the desired target trajectory to define tracklet affinity for association most previous work relies on heuristically selected parametric model while our approach is able to automatically select among various feature and corresponding non parametric model and combine them to maximize the discriminative power on training data by virtue of a hybridboost algorithm a hybrid loss function is used in this algorithm because the association of tracklet is formulated a a joint problem of ranking and classification the ranking part aim to rank correct tracklet association higher than other alternative the classification part is responsible to reject wrong association when no further association should be done experiment are carried out by tracking pedestrian in challenging datasets we compare our approach with state of the art algorithm to show it improvement in term of tracking accuracy 
recognition using appearance feature is confounded by phenomenon that cause image of the same object to look different or image of different object to look the same this may occur because the same object look different from different viewing direction or because two generally different object have view from which they look similar in this paper we introduce the idea of discriminative aspect a set of latent variable that encode these phenomenon change in view direction are one cause of change in discriminative aspect but others include change in texture or lighting however image are not labelled with relevant discriminative aspect parameter we describe a method to improve discrimination by inferring and then using latent discriminative aspect parameter we apply our method to two parallel problem object category recognition and human activity recognition in each case appearance feature are powerful given appropriate training data but traditionally fail badly under large change in view our method can recognize an object quite reliably in a view for which it posse no training example our method also reweights feature to discount accidental similarity in appearance we demonstrate that our method produce a significant improvement on the state of the art for both object and activity recognition 
conventional subspace learning based face recognition aim to attain low recognition error and assumes same loss from all misclassifications in many real world face recognition application however this assumption may not hold a different misclassifications could lead to different loss for example it may cause inconvenience to a gallery person who is mi recognized a an impostor and not allowed to enter the room by a face recognition based door locker but it could result in a serious loss or damage if an impostor is mi recognized a a gallery person and allowed to enter the room motivated by this concern we propose in this paper a cost sensitive subspace learning approach for face recognition our approach incorporates a cost matrix which specifies the different cost associated with misclassifications of subject into three popular subspace learning algorithm and devise the corresponding cost sensitive method namely cost sensitive principal component analysis cspca cost sensitive linear discriminant analysis cslda and cost sensitive locality preserving projection cslpp to achieve a minimum overall recognition loss by performing recognition in the low dimensional subspace derived experimental result are presented to demonstrate the efficacy of the proposed approach 
a real world object category can be viewed a a characteristic congur ation of it part that are themselves simpler smaller sub category recognition of a category can therefore be made easier by detecting it constituent subcategories and combing these detection result given a set of training image each labeled by an object category contained in it we present an approach to learning taxonomy dened by recursive sharing of subcategories by multiple image category subcategory relevance a the degree of evidence a subcategory offer for the presence of it parent likelihood that the image contains a subcategory and prior that a subcategory occurs the image are represented a point in a feature space spanned by condences in the occurrence of the subcategories the subcategory relevance are estimated a weight necessary to rescale the corresponding ax of the feature space so that the image with the same label are closer to each other than to those with different label when a new image is encountered the learned taxonomy relevance likelihood and prior are used by a linear classier to categorize the image on the challenging caltech dataset the proposed approach signicantly outperforms the best categorization reported this result is signicant in that it not only demonstrates the advantage of exploiting subcategory taxonomy for recognition but also suggests that a feature space spanned by part property instead of direct object property allows for linear separation of image class for the category the nal result is a model for each of the label category which is well represented in the image set our approach follows from the well recognized notion that object consist of part the intrinsic nature of the part and their spatial congurations dene the category model these part themselves dene their own object category thus larger category in general are hierarchical congurations of smaller and simpler category in the sequel we refer to the constituent category also a subcategories a category model capture the observed variation in the category instance these variation are due to their natural diversity a well a difference in imaging parameter e g illumination viewing direction camera characteristic and occlusion the larger the extent of an object the more diverse is the range of such effect and more complex the model therefore recognition of the smaller and simpler object part is more reliable than the recognition of the entire object this make recognition of a category from it subcategory detection an efcient strategy but requires that these detection are efciently combined 
in this work we investigate how to propagate annotated label for a given single image from the image level to their corresponding semantic region namely label to region l r by utilizing the auxiliary knowledge from internet image search with the annotated image label a query a nonparametric solution is proposed to perform l r for single image with complete label first each label of the image is used a query for online image search engine to obtain a set of semantically related and visually similar image which along with the input image are encoded a bag of hierarchical patch then an efficient two stage feature mining procedure is presented to discover those input image specific salient and descriptive feature for each label from the proposed interpolation sift isift feature pool these feature consequently constitute a patch level representation and the continuity biased sparse coding is proposed to select few patch from the online image with preference to larger patch to reconstruct a candidate region which randomly merges the spatially connected patch of the input image such candidate region are further ranked according to the reconstruction error and the top region are used to derive the label confidence vector for each patch of the input image finally a patch clustering procedure is performed a postprocessing to finalize l r for the input image extensive experiment on three public database demonstrate the encouraging performance of the proposed nonparametric l r solution 
we propose a novel approach for multi person trackingby detection in a particle filtering framework in addition to final high confidence detection our algorithm us the continuous confidence of pedestrian detector and online trained instance specific classifier a a graded observation model thus generic object category knowledge is complemented by instance specific information a main contribution of this paper is the exploration of how these unreliable information source can be used for multi person tracking the resulting algorithm robustly track a large number of dynamically moving person in complex scene with occlusion doe not rely on background modeling and operates entirely in d requiring no camera or ground plane calibration our markovian approach relies only on information from the past and is suitable for online application we evaluate the performance on a variety of datasets and show that it improves upon state of the art method 
we propose a novel formulation of stereo matching that considers each pixel a a feature vector under this view matching two or more image can be cast a matching point cloud in feature space we build a nonparametric depth smoothness model in this space that correlate the image feature and depth value this model induces a sparse graph that link pixel with similar feature thereby converting each point cloud into a connected network this network defines a neighborhood system that capture pixel grouping hierarchy without resorting to image segmentation we formulate global stereo matching over this neighborhood system and use graph cut to match pixel between two or more such network we show that our stereo formulation is able to recover surface with different order of smoothness such a those with high curvature detail and sharp discontinuity furthermore compared to other single frame stereo method our method produce more temporally stable result from video of dynamic scene even when applied to each frame independently 
this paper present a nonparametric approach to labeling of local image region that is inspired by recent development in information theoretic denoising the chief novelty of this approach rest in it ability to derive an unsupervised contextual prior over image class from unlabeled test data labeled training data is needed only to learn a local appearance model for image patch although additional supervisory information can optionally be incorporated when it is available instead of assuming a parametric prior such a a markov random field for the class label the proposed approach us the empirical bayes technique of statistical inversion to recover a contextual model directly from the test data either a a spatially varying or a a globally constant prior distribution over the class in the image result on two challenging datasets convincingly demonstrate that useful contextual information can indeed be learned from unlabeled data 
we present a novel method for learning human motion model from unsegmented video we propose a unified framework that encodes spatio temporal relationship between descriptive motion part and the appearance of individual pose sparse set of spatial and spatio temporal feature are used the method automatically learns static pose model and spatio temporal motion part neither motion cycle nor human figure need to be segmented for learning we test the model on a publicly available action dataset and demonstrate that our new method performs well on a number of classification task we also show that classification rate are improved by increasing the number of pose model in the framework 
the idea of representing image using a bag of visual word is currently popular in object category recognition since this representation is typically constructed using unsupervised clustering the resulting visual word may not capture the desired information recent work ha explored the construction of discriminative visual codebooks that explicitly consider object category information however since the codebook generation process is still disconnected from that of classifier training the set of resulting visual word while individually discriminative may not be those best suited for the classifier this paper proposes a novel optimization framework that unifies codebook generation with classifier training in our approach each image feature is encoded by a sequence of visual bit optimized for each category an image which can contain object from multiple category is represented using aggregate of visual bit for each category classifier associated with different category determine how well a given image corresponds to each category based on the performance of these classifier on the training data we augment the visual word by generating additional bit the classifier are then updated to incorporate the new representation these two phase are repeated until the desired performance is achieved experiment compare our approach to standard clustering based method and with state of the art discriminative visual codebook generation the significant improvement over previous technique clearly demonstrate the value of unifying representation and classification into a single optimization framework 
recently a novel log euclidean riemannian metric is proposed for statistic on symmetric positive definite spd matrix under this metric distance and riemannian mean take a much simpler form than the widely used affine invariant riemannian metric based on the log euclidean riemannian metric we develop a tracking framework in this paper in the framework the covariance matrix of image feature in the five mode are used to represent object appearance since a nonsingular covariance matrix is a spd matrix lying on a connected riemannian manifold the log euclidean riemannian metric is used for statistic on the covariance matrix of image feature further we present an effective online log euclidean riemannian subspace learning algorithm which model the appearance change of an object by incrementally learning a low order log euclidean eigenspace representation through adaptively updating the sample mean and eigenbasis tracking is then led by the bayesian state inference framework in which a particle filter is used for propagating sample distribution over the time theoretic analysis and experimental evaluation demonstrate the promise and effectiveness of the proposed framework 
we propose a novel tracking algorithm based on the wang landau monte carlo sampling method which efficiently deal with the abrupt motion abrupt motion could cause conventional tracking method to fail since they violate the motion smoothness constraint to address this problem we introduce the wang landau algorithm that ha been recently proposed in statistical physic and integrate this algorithm into the markov chain monte carlo based tracking method our tracking method alleviates the motion smoothness constraint utilizing both the likelihood term and the density of state term which is estimated by the wang landau algorithm the likelihood term help to improve the accuracy in tracking smooth motion while the density of state term capture abrupt motion robustly experimental result reveal that our approach efficiently sample the object s state even in a whole state space without loss of time therefore it track the object of which motion is drastically changing accurately and robustly 
recognizing object class and their d viewpoint is an important problem in computer vision based on a part based probabilistic representation we propose a new d object class model that is capable of recognizing unseen view by pose estimation and synthesis we achieve this by using a dense multiview representation of the viewing sphere parameterized by a triangular mesh of viewpoint each triangle of viewpoint can be morphed to synthesize new viewpoint by incorporating d geometrical constraint our model establishes explicit correspondence among object part across viewpoint we propose an incremental learning algorithm to train the generative model a cellphone video clip of an object is first used to initialize model learning then the model is updated by a set of unsorted training image without viewpoint label we demonstrate the robustness of our model on object detection viewpoint classification and synthesis task our model performs superiorly to and on par with state of the art algorithm on the savarese et al and pascal datasets in object detection it outperforms all previous work in viewpoint classification and offer promising result in viewpoint synthesis 
we describe a method for retrieving shot containing a particular d human pose from unconstrained movie and tv video the method involves first localizing the spatial layout of the head torso and limb in individual frame using pictorial structure and associating these through a shot by tracking a feature vector describing the pose is then constructed from the pictorial structure shot can be retrieved either by querying on a single frame with the desired pose or through a pose classifier trained from a set of pose example our main contribution is an effective system for retrieving people based on their pose and in particular we propose and investigate several pose descriptor which are person clothing background and lighting independent a a second contribution we improve the performance over existing method for localizing upper body layout on unconstrained video we compare the spatial layout pose retrieval to a baseline method where pose are retrieved using a hog descriptor performance is assessed on five episode of the tv series buffy the vampire slayer and pose retrieval is demonstrated also on three hollywood movie 
the aim of this paper is to address recognition of natural human action in diverse and realistic video setting this challenging but important subject ha mostly been ignored in the past due to several problem one of which is the lack of realistic and annotated video datasets our first contribution is to address this limitation and to investigate the use of movie script for automatic annotation of human action in video we evaluate alternative method for action retrieval from script and show benefit of a text based classifier using the retrieved action sample for visual learning we next turn to the problem of action classification in video we present a new method for video classification that build upon and extends several recent idea including local space time feature space time pyramid and multichannel non linear svms the method is shown to improve state of the art result on the standard kth action dataset by achieving accuracy given the inherent problem of noisy label in automatic annotation we particularly investigate and show high tolerance of our method to annotation error in the training set we finally apply the method to learning and classifying challenging action class in movie and show promising result 
this paper present an approach for including d prior model into a factorization framework for structure from motion the proposed method computes a closed form affine fit which mix the information from the data and the d prior on the shape structure moreover it is general in regard to different class of object treated rigid articulated and deformable the inclusion of the shape prior may aid the inference of camera motion and d structure component whenever the data is degenerate i e nearly planar motion of the projected shape afinal non linear optimization stage which includes the shape prior a a quadratic cost upgrade the affine fit to metric result on real and synthetic image sequence which present predominant degenerate motion make clear the improvement over the d reconstruction 
this paper present a new model for understanding the appearance of object that exhibit both body and surface reflection under realistic illumination specifically the model represents the appearance of surface that interact with a dominant illuminant and a non negligible ambient illuminant that may have different spectral power distribution real illumination environment usually have an ambient illuminant and the current dynamic range of consumer camera is sufficient to capture significant information in shadow the bi illuminant dichromatic reflection model explains numerous empirical finding in the literature and ha implication for commonly used chromaticity space that claim to be illumination invariant but are not in many natural situation one outcome of the model is the first d chromaticity space for an rgb image that is robust to illumination change given dominant and ambient illuminant with different spectral power distribution 
stereo matching commonly requires rectified image that are computed from calibrated camera since all underlying parametric camera model are only approximation calibration and rectification will never be perfect additionally it is very hard to keep the calibration perfectly stable in application scenario with large temperature change and vibration we show that even small calibration error of a quarter of a pixel are severely amplified on certain structure we discus a robotics and a driver assistance example where sub pixel calibration error cause severe problem we propose a filter solution based on signal theory that remove critical structure and make stereo algorithm le sensitive to calibration error our approach doe not aim to correct decalibration but rather to avoid amplification and mismatch experiment on ten stereo pair with ground truth and simulated decalibrations a well a image from robotics and driver assistance scenario demonstrate the success and limitation of our solution that can be combined with any stereo method 
large scale image search ha recently attracted considerable attention due to easy availability of huge amount of data several hashing method have been proposed to allow approximate but highly efficient search unsupervised hashing method show good performance with metric distance but in image search semantic similarity is usually given in term of labeled pair of image there exist supervised hashing method that can handle such semantic similarity but they are prone to overfitting when labeled data is small or noisy moreover these method are usually very slow to train in this work we propose a semi supervised hashing method that is formulated a minimizing empirical error on the labeled data while maximizing variance and independence of hash bit over the labeled and unlabeled data the proposed method can handle both metric a well a semantic similarity the experimental result on two large datasets up to one million sample demonstrate it superior performance over state of the art supervised and unsupervised method 
most existing video denoising algorithm assume a single statistical model of image noise e g additive gaussian white noise which often is violated in practice in this paper we present a new patch based video denoising algorithm capable of removing serious mixed noise from the video data by grouping similar patch in both spatial and temporal domain we formulate the problem of removing mixed noise a a low rank matrix completion problem which lead to a denoising scheme without strong assumption on the statistical property of noise the resulting nuclear norm related minimization problem can be efficiently solved by many recently developed method the robustness and effectiveness of our proposed denoising algorithm on removing mixed noise e g heavy gaussian noise mixed with impulsive noise is validated in the experiment and our proposed approach compare favorably against some existing video denoising algorithm 
we present a robust elastic and partial matching metric for face recognition to handle challenge such a pose facial expression and partial occlusion we enable both elastic and partial matching by computing a part based face representation in which n local image descriptor are extracted from densely sampled overlapping image patch we then define a distance metric where each descriptor in one face is matched against it spatial neighborhood in the other face and the minimal distance is recorded for implicit partial matching the list of all minimal distance are sorted in ascending order and the distance at the n th position is picked up a the final distance the parameter control how much occlusion facial expression change or pixel degradation we would allow the optimal parameter value of this new distance metric are extensively studied and identified with real life photo collection we also reveal that filtering the face image by a simple difference of gaussian brings significant robustness to lighting variation and beat the more utilized self quotient image extensive evaluation on face recognition benchmark show that our method is leading or is competitive in performance when compared to state of the art 
bottom up segmentation based only on low level cue is a notoriously difficult problem this difficulty ha lead to recent top down segmentation algorithm that are based on class specific image information despite the success of top down algorithm they often give coarse segmentation that can be significantly refined using low level cue this raise the question of how to combine both top down and bottom up cue in a principled manner in this paper we approach this problem using supervised learning given a training set of ground truth segmentation we train a fragment based segmentation algorithm which take into account both bottom up and top down cue simultaneously in contrast to most existing algorithm which train top down and bottom up module separately we formulate the problem in the framework of conditional random field crf and derive a feature induction algorithm for crf which allows u to efficiently search over thousand of candidate fragment whereas pure top down algorithm often require hundred of fragment our simultaneous learning procedure yield algorithm with a handful of fragment that are combined with low level cue to efficiently compute high quality segmentation 
human activity recognition is a challenging task especially when it background is unknown or changing and when scale or illumination differs in each video approach utilizing spatio temporal local feature have proved that they are able to cope with such difficulty but they mainly focused on classifying short video of simple periodic action in this paper we present a new activity recognition methodology that overcomes the limitation of the previous approach using local feature we introduce a novel matching spatio temporal relationship match which is designed to measure structural similarity between set of feature extracted from two video our match hierarchically considers spatio temporal relationship among feature point thereby enabling detection and localization of complex non periodic activity in contrast to previous approach to classify video our approach is designed to detect and localize all occurring activity from continuous video where multiple actor and pedestrian are present we implement and test our methodology on a newly introduced dataset containing video of multiple interacting person and individual pedestrian the result confirm that our system is able to recognize complex non periodic activity e g push and hug from set of spatio temporal feature even when multiple activity are present in the scene 
state of the art approach for detecting filament like structure in noisy image rely on filter optimized for signal of a particular shape such a an ideal edge or ridge while these approach are optimal when the image conforms to these ideal shape their performance quickly degrades on many type of real data where the image deviate from the ideal model and when noise process violate a gaussian assumption in this paper we show that by learning rotational feature we can outperform state of the art filament detection technique on many different kind of imagery more specifically we demonstrate superior performance for the detection of blood vessel in retinal scan neuron in brightfield microscopy imagery and street in satellite imagery 
multiple surface searching with only image intensity information is a difficult job in the presence of high noise and weak edge we present in this paper a novel method for globally optimal multi surface searching with a shape prior represented by convex pairwise energy a d graph theoretic framework is employed an arc weighted graph is constructed based on a shape model built from training datasets a wide spectrum of constraint is then incorporated the shape prior term penalizes the local topological change from the original shape model the globally optimal solution for multiple surface can be obtained by computing a maximum flow in low order polynomial time compared with other graph based method our approach provides more local and flexible control of the shape we also prove that our algorithm can handle the detection of multiple crossing surface with no shared voxels our method wa applied to several application problem including medical image segmentation scenic image segmentation and image resizing compared with result without using shape prior information our improvement wa quite impressive demonstrating the promise of our method 
we present a novel approach to learn distance metric for information retrieval learning distance metric from a number of query with side information i e relevance judgement ha been studied widely for example pairwise constraint based distance metric learning however the capacity of existing algorithm is limited because they usually assume that the distance between two similar object is smaller than the distance between two dissimilar object this assumption may not hold especially in the case of information retrieval when the input space is heterogeneous to address this problem explicitly we propose rank based distance metric learning our approach overcomes the drawback of existing algorithm by comparing the distance only among the relevant and irrelevant object for a given query to avoid over fitting a regularizer based on the burg matrix divergence is also introduced we apply the proposed framework to tattoo image retrieval in forensics and law enforcement application domain the goal of the application is to retrieve tattoo image from a gallery database that are visually similar to a tattoo found on a suspect or a victim the experimental result show encouraging result in comparison to the standard approach for distance metric learning 
scarcity and infeasibility of human supervision for large scale multi class classification problem necessitates ac tive learning unfortunately existing active learning method s for multi class problem are inherently binary method and do not scale up to a large number of class in this paper we introduce a probabilistic variant of thek nearest neighbor method for classification that can be seamlessly used for active learning in multi class scenario given some labeled training data our method learns an accurate metric kernel function over the input space that can be used for classification and similarity search unlike existing metric kernel learning method our scheme is highl y scalable for classification problem and provides a natural notion of uncertainty over class label further we use this measure of uncertainty to actively sample training example that maximize discriminating capability of the model experiment on benchmark datasets show that the proposed method learns appropriate distance metric that lead to state of the art performance for object categoriz ation problem furthermore our active learning method effectively sample training example resulting in signi ficant accuracy gain over random sampling for multi class problem involving a large number of class 
this paper present a novel approach for tracking human and object under severe occlusion we introduce a new paradigm for multiple hypothesis tracking observe and explain a opposed to the previous paradigm of hypothesize and test our approach efficiently enumerates multiple possibility of tracking by generating several likely explanation after concatenating a sufficient amount of observation the computational advantage of our approach over the previous paradigm under severe occlusion are presented the tracking system is implemented and tested using the i lid dataset which consists of video of human and object moving in a london subway station the experimental result show that our new approach is able to track human and object accurately and reliably even when they are completely occluded illustrating it advantage over previous approach 
we explore a location basedapproachforbehaviormodeling and abnormality detection in contrast to the conventional object based approach where an object may first be tagged identified classified and tracked we proceed directly with event characterization and behavior modeling at the pixel s level based on motion label obtained from background subtraction since event are temporally and spatially dependent this call for technique that account for statistic of spatio temporal event based on motion label we learn co occurrence statistic for normal event across space time for one or many key pixel s we estimate a co occurrence matrix that account for any two active label which co occur simultaneously within the same spatio temporal volume this co occurrence matrix is then used a a potential function in a markov random field mrf model to describe the probability of observation within the same spatio temporal volume the mrf distribution implicitly account for speed direction a well a the average size of the object passing in front of each key pixel furthermore when the spatio temporal volume is large enough the co occurrence distribution contains the average normal path followed by moving object the learned normal co occurrence distribution can be used for abnormaldetection our method hasbeen tested on various outdoor video representing various challenge 
in this paper we propose a novel approach to model shape variation it encodes sparsity exploit geometric redundancy and account for the different degree of local variation and image support in this context we consider a control point based shape representation their sparse distribution is derived based on a shape model metric learned from the training data and the ambiguity of local appearance with regard to segmentation change the resulting sparse model of the object improves reconstruction and search behavior in particular for data that exhibit a heterogeneous distribution of image information and shape complexity furthermore it go beyond conventional imagebased segmentation approach since it is able to identify reliable image structure which are then encoded within the modeland used to determinetheoptimalsegmentationmap we report promising experimental result comparing our approachwith standard modelson mri data of calf muscle anapplicationwhere traditionalimage basedmethodsfail and ct data of the left heart ventricle 
in this paper we look at improving the kd tree for a specific usage indexing a large number of siftand other type of image descriptor we have extended priority search to priority search among multiple tree by creating multiple kd tree from the same data set and simultaneously searching among these tree we have improved the kd tree s search performancesignificantly we have also exploited the structure in sift descriptor or structure in any data set to reduce the time spent in backtracking by using principal component analysis to align the principal ax of the data with the coordinate ax we have further increased the kd tree s search performance 
in this paper we address the problem of tracking an object in a video given it location in the first frame and no other information recently a class of tracking technique called tracking by detection ha been shown to give promising result at real time speed these method train a discriminative classifier in an online manner to separate the object from the background this classifier bootstrap itself by using the current tracker state to extract positive and negative example from the current frame slight inaccuracy in the tracker can therefore lead to incorrectly labeled training example which degrade the classifier and can cause further drift in this paper we show that using multiple instance learning mil instead of traditional supervised learning avoids these problem and can therefore lead to a more robust tracker with fewer parameter tweak we propose a novel online mil algorithm for object tracking that achieves superior result with real time performance we present thorough experimental result both qualitative and quantitative on a number of challenging video clip 
abstract in this paper we present an adaptive but robust object detector for static camera by introducing classifier grid instead of using a sliding window for object detection we propose to train a separate classifier for each image location obtaining a very specific object detector with a low false alarm rate for each classifier corresponding to a grid element we estimate two generative representation in parallel one describing the object s class and one describing the background these are combined in order to obtain a discriminative model to enable to adapt to changing environment these classifier are learned on line i e boosting continuously learning hour a day day a week requires a stable system in our method this is ensured by a fixed object representation while updating only the representation of the background we demonstrate the stability in a long term experiment by running the system for a whole week which show a stable performance over time in addition we compare the proposed approach to state of the art method in the field of person and car detection in both case we obtain competitive result 
this paper introduces a very compact yet discriminative video description which allows example based search in a large number of frame corresponding to thousand of hour of video our description extract one descriptor per indexed video frame by aggregating a set of local descriptor these frame descriptor are encoded using a time aware hierarchical indexing structure a modified temporal hough voting scheme is used to rank the retrieved database video and estimate segment in them that match the query if we use a dense temporal description of the video matched video segment are localized with excellent precision experimental result on the trecvid copy detection task and a set of video from youtube show that our method offer an excellent trade off between search accuracy efficiency and memory usage 
in this paper we attempt to scale up the kd tree indexing method for large scale vision application e g indexing a large number of sift feature and other type of visual descriptor to this end we propose an effective approach to generate near optimal binary space partitioning and need low time cost to access the node in the query stage first we relax the coordinate axis alignment constraint in partition axis selection used in conventional kd tree and form a partition axis with the great variance by combining a few coordinate ax in a binary manner for each node which yield better space partitioning and requires almost the same time cost to visit internal node during the query stage thanks to cheap projection operation then we introduce a simple but very effective scheme to guarantee the partition axis of each internal node is orthogonal to or parallel with those of it ancestor which lead to efficient distance computation between a query point and the cell associated with each node and yield fast priority search compared with the conventional kd tree our approach take a little more tree construction time but obtains much better nearest neighbor search performance experimental result on large scale local patch indexing and image search with tiny image show that our approach outperforms the state of the art kd tree based indexing method 
significant research ha been devoted to detecting people in image and video in this paper we describe a human detection method that augments widely used edge based feature with texture and color information providing u with a much richer descriptor set this augmentation result in an extremely high dimensional feature space more than dimension in such high dimensional space classical machine learning algorithm such a svms are nearly intractable with respect to training furthermore the number of training sample is much smaller than the dimensionality of the feature space by at least an order of magnitude finally the extraction of feature from a densely sampled grid structure lead to a high degree of multicollinearity to circumvent these data characteristic we employ partial least square pls analysis an efficient dimensionality reduction technique one which preserve significant discriminative information to project the data onto a much lower dimensional subspace dimension reduced from the original our human detection system employing pls analysis over the enriched descriptor set is shown to outperform state of the art technique on three varied datasets including the popular inria pedestrian dataset the low resolution gray scale daimlerchrysler pedestrian dataset and the ethz pedestrian dataset consisting of full length video of crowded scene 
we introduce a new class of image feature the ray feature set that consider image characteristic at distant contour point capturing information which is difficult to represent with standard feature set this property allows ray feature to efficiently and robustly recognize deformable or irregular shape such a cell in microscopic imagery experiment show ray feature clearly outperform other powerful feature including haar like feature and histogram of oriented gradient when applied to detecting irregularly shaped neuron nucleus and mitochondrion ray feature can also provide important complementary information to haar feature for other task such a face detection reducing the number of weak learner and computational cost ray feature can be efficiently precomputed to reduce cost just a precomputing integral image reduces the overall cost of haar feature while ray are slightly more expensive to precompute their computational cost is le than that of haar feature for scanning an adaboost based detector window across an image at run time 
multiple instance mi learning is a recent learning paradigm that is more flexible than standard supervised learning algorithm in the handling of label ambiguity it ha been used in a wide range of application including image classification object detection and object tracking typically mi algorithm are trained in a batch setting in which the whole training set ha to be available before training start however in application such a tracking the classifier need to be trained continuously a new frame arrive motivated by the empirical success of a batch mi algorithm called mile we propose in this paper an online mi learning algorithm that ha an efficient online update procedure and also performs joint feature selection and classification a mile besides while existing online mi algorithm lack theoretical property we prove that the proposed online algorithm ha a cumulative regret of o t where t is the number of iteration in other word the average regret go to zero asymptotically and it thus achieves the same performance a the best solution in hindsight experiment on a number of mi classification and object tracking data set demonstrate encouraging result 
generic camera odometry can be performed using two image of the same plane such a the ground plane even in the case of non central camera it is possible to recover both the angle and rotation center describing a generic planar motion on the ground plane if the center is visible in both image we present an algorithm to recover these two parameter from an initial set of correspondence and furthermore to estimate the motion flow related to any point on the ground plane in this situation the motion flow are given by a set of concentric closed curve around the rotation center by considering two subsequent ground plane motion and their related motion flow we show that it is possible to perform a rectification of the plane up to a scale factor we provide experimental result which validate our approach 
in this paper we propose an approach for action recognition based on a vocabulary forest of local motionappearance feature large number of feature with associated motion vector are extracted from action data and are represented by many vocabulary tree feature from a query sequence are matched to the tree and vote for action category and their location large number of tree make the process efficient and robust the system is capable of simultaneous categorization and localization of action using only a few frame per sequence the approach obtains excellent performance on standard action recognition sequence we perform large scale experiment on challenging real action category from olympic game we demonstrate the robustness of our method to appearance variation camera motion scale change asymmetric action background clutter and occlusion 
state of the art image classification method require an intensive learning training stage using svm boosting etc in contrast non parametric nearest neighbor nn based image classifier require no training time and have other favorable property however the large performance gap between these two family of approach rendered nnbased image classifier useless we claim that the effectiveness of non parametric nnbased image classification ha been considerably undervalued we argue that two practice commonly used in image classification method have led to the inferior performance of nn based image classifier i quantization of local image descriptor used to generate bag of word codebooks ii computation of image to image distance instead of image to class distance we propose a trivial nn based classifier nbnn naive bayes nearest neighbor which employ nndistances in the space of the local image descriptor and not in the space of image nbnn computes direct imageto class distance without descriptor quantization we further show that under the naive bayes assumption the theoretically optimal image classifier can be accurately approximated by nbnn although nbnn is extremely simple efficient and requires no learning training phase it performance rank among the top leading learning based image classifier empirical comparison are shown on several challenging database caltech caltech and graz 
historically non rigid shape recovery and articulated pose estimation have evolved a separate eld recent method for non rigid shape recovery have focused on improving the algorithmic formulation but have only considered the case of reconstruction from point to point correspondence in contrast many technique for pose estimation have followed a discriminative approach which allows for the use of more general image cue however these technique typically require large training set and suffer from the fact that standard discriminative method do not enforce constraint between output dimension in this paper we combine idea from both domain and propose a unied framework for articulated pose estimation and d surface reconstruction we address some of the issue of discriminative method by explicitly constraining their prediction furthermore our formulation allows for the combination of generative and discriminative method into a single common framework 
blind deconvolution is the recovery of a sharp version of a blurred image when the blur kernel is unknown recent algorithm have afforded dramatic progress yet many aspect of the problem remain challenging and hard to understand the goal of this paper is to analyze and evaluate recent blind deconvolution algorithm both theoretically an d experimentally we explain the previously reported failur e of the naive map approach by demonstrating that it mostly favor no blur explanation on the other hand we show that since the kernel size is often smaller than the image size a map estimation of the kernel alone can be well constrained and accurately recover the true blur the plethora of recent deconvolution technique make an experimental evaluation on ground truth data important we have collected blur data with ground truth and compared recent algorithm under equal setting additionall y our data demonstrates that the shift invariant blur assump tion made by most algorithm is often violated 
abstract parameterized appearance model pams e g eigentracking activeappearancemodels morphablemodels use principal component analysis pca to model the shape and appearance of object in image given a new image with an unknown appearance shape configuration pams can detect and track the object by optimizing the model s parameter that best match the image while pams have numerous advantage for image registration relative to alternative approach they suffer from two major limitation first pca cannot model non linear structure in the data second learning pams requires precise manually labeled training data this paper proposes parameterized kernel principal component analysis pkpca an extension of pams that us kernel pca kpca for learning a non linear appearance model invariant to rigid and or non rigid deformation we demonstrate improved performance in supervised and unsupervised image registration and present a novel application to improve the quality of manual landmark in face in addition we suggest a clean and effective matrix formulation for pkpca 
we present a hybrid camera that combine the advantage of a high resolution camera and a high speed camera our hybrid camera consists of a pair of low resolution high speed lrhs camera and a single high resolution low speed hrls camera the lrhs camera are able to capture fast motion with little motion blur they also form a stereo pair and provide a low resolution depth map the hrls camera provides a high spatial resolution but also introduces severe motion blur when capturing fast moving object we develop efficient algorithm to simultaneously motion deblur the hrls image and reconstruct a high resolution depth map our method estimate the motion flow in the lrhs pair and then warp the flow field to the hrls camera to estimate the point spread function psf we then deblur the hrls image and use the resulting image to enhance the low resolution depth map using joint bilateral filter we demonstrate the hybrid camera in depth map super resolution and motion deblurring with spatially varying kernel experiment show that our framework is robust and highly effective 
most previous work focus on how to learn discriminating appearance feature over all the face without considering the fact that each facial expression is physically composed of some relative action unit au however the definition of au is an ambiguous semantic description in facial action coding system facs so it make accurate au detection very difficult in this paper we adopt a scheme of compromise to avoid au detection and try to interpret facial expression by learning some compositional appearance feature around au area we first divided face image into local patch according to the location of au and then we extract local appearance feature from each patch a minimum error based optimization strategy is adopted to build compositional feature based on local appearance feature and this process embedded into boosting learning structure experiment on the cohn kanada database show that the proposed method ha a promising performance and the built compositional feature are basically consistent to facs 
to recognize three dimensional object it is important to model how their appearance can change due to change in viewpoint a key aspect of this involves understanding which object feature can be simultaneously visible under different viewpoint we address this problem in an imagebased framework in which we use a limited number of image of an object taken from unknown viewpoint to determine which subset of feature might be simultaneously visible in other view this lead to the problem of determining whether a set of image each containing a set of feature is consistent with a single d object we assume that each feature is visible from a disk of viewpoint on the viewing sphere in this case we show the problem is np hard in general but can be solved efficiently when all view come from a circle on the viewing sphere we also give iterative algorithm that can handle noisy data and converge to locally optimal solution in the general case our technique can also be used to recover viewpoint information from the set of feature that are visible in different image we show that these algorithm perform well both on synthetic data and image from the coil dataset 
in this paper we investigate the problem of exploiting multiple source of information for object recognition task when additional modality that are not present in the labeled training set are available for inference this scenario is common to many robotics sensing application and is in contrast with the assumption made by existing approach that require at least some labeled example for each modality to leverage the previously unseen feature we make use of the unlabeled data to learn a mapping from the existing modality to the new one this allows u to predict the missing data for the labeled example and exploit all modality using multiple kernel learning we demonstrate the effectiveness of our approach on several multi modal task including object recognition from multi resolution imagery grayscale and color image a well a image and text our approach outperforms multiple kernel learning on the original modality a well a nearest neighbor and bootstrapping scheme 
we study the problem of learning to rank image for image retrieval for a noisy set of image indexed or tagged by the same keyword we learn a ranking model from some training example and then use the learned model to rank new image unlike previous work on image retrieval which usually coarsely divide the image into relevant and irrelevant image and learn a binary classifier we learn the ranking model from image pair with preference relation in addition to the relevance of image we are further interested in what portion of the image is of interest to the user therefore we consider image represented by set of region and propose multiple instance rank learning based on the max margin framework three different scheme are designed to encode the multiple instance assumption we evaluate the performance of the multiple instance ranking algorithm on real word image collected from flickr a popular photo sharing service the experimental result show that the proposed algorithm are capable of learning effective ranking model for image retrieval 
straightforward classification using kernelized svms requires evaluating the kernel for a test vector and each of the support vector for a class of kernel we show that one can do this much more efficiently in particular we showthat one canbuild histogramintersection kernel svms iksvms with runtimecomplexityofthe classifierlogarithmic in the number of support vector a opposed tolinear for the standardapproach we further show that by precomputing auxiliary table we can construct an approximate classifier with constant runtime and space requirement independent of the number of support vector with negligible loss in classification accuracy on various task this approximation also applies to and other kernel of similar form we also introduce novel feature based on a multi level histogramsof oriented edgeenergy andpresent experiment on various detection datasets on the inria pedestrian dataset an approximate iksvm classifier based on these feature ha the current best performance with a miss rate lower at false positive per window than the linear svm detector of dalal triggs on the daimler chrysler pedestrian dataset iksvm give comparable accuracy to the best result based on quadratic svm while being faster in these experiment our approximate iksvm is up to faster than a standard implementation and requires le memory finally we show that a speedup is possible using approximate iksvm based on spatial pyramid feature on the caltech dataset with negligible loss of accuracy 
in this paper we present a surface reflectance descriptor based on the control point resulting from the interpolation of non uniform rational b spline nurbs curve to multispectral reflectance data the interpolation is based upon a knot removal scheme in the parameter domain thus we exploit the local support of nurbs so a to recover a compact descriptor robust to noise and local perturbation of the spectrum we demonstrate the utility of our nurbs based descriptor for material identification to this end we perform skin spectrum recognition making use of a support vector machine classifier we also provide result on hyperspectral imagery and elaborate on the preprocessing step for skin segmentation we compare our result with those obtained using an alternative descriptor 
we present a new direct way to register threedimensional d surface given the respective d point and surface triangulation our method is non iterative and doe not require any initial solution the idea is to compute d invariant based on local surface moment the resulting local surface descriptor are invariant with respect to euclidean or to similarity transformation by choice in the final step we use the hungarian method to find a minimum cost assignment of the computed descriptor the method is robust against different point density noise and partial overlap our experiment with real data also show that the method can serve a automatic initialization of the iterativeclosest point icp algorithm and hence extends the field of application for this standard registration method 
shape correspondence which aim at accurately identifying corresponding landmark from a given population of shape instance is a very challenging step in constructing a statistical shape model such a the point distribution model the state of the art method such a mdl and spharm are primarily focused on closed surface shape correspondence in this paper we develop a novel method aimed at identifying accurately corresponding landmark on d open surface with a closed boundary in particular we enforce explicit topology consistency on the identified landmark to ensure that they form a simple consistent triangle mesh to more accurately model the correspondence of the underlying continuous shape instance the proposed method also ensures the correspondence of the boundary of the open surface for our experiment we test the proposed method by constructing a statistical shape model of the human diaphragm from shape instance 
sliding window classifier are among the most successful and widely applied technique for object localization however training is typically done in a way that is not specific to the localization task first a binary classifier is trained using a sample of positive and negative example and this classifier is subsequently applied to multiple region within test image we propose instead to treat object localization in a principled way by posing it a a problem of predicting structured data we model the problem not a binary classification but a the prediction of the bounding box of object located in image the use of a joint kernelframework allows u to formulate the training procedure a a generalization of an svm which can be solved efficiently we further improve computational efficiency by using a branch and bound strategy for localization during both training and testing experimental evaluation on the pascal voc and tu darmstadt datasets show that the structured training procedure improves performance over binary training a well a the best previously published score 
accurate and automatic colonic polyp segmentation and measurement in computed tomography ct ha significant importance for d polyp detection classification and more generally computer aided diagnosis of colon cancer in this paper we propose a three staged probabilistic binary classification approach for automatically segmenting polyp voxels from their surrounding tissue in ct our system integrates low and mid level information for discriminative learning under local polar coordinate which align on the d colon surface around detected polyp more importantly our supervised learning system ha flexible modeling capacity which offer a principled mean of encoding semantic clinical expert annotation of colonic polyp tissue identification and segmentation the learning generality to unseen data is bounded by boosting and stacked generality extensive experimental result on polyp segmentation performance evaluation and robustness testing with disturbance using both training data and unseen data are provided to validate our presented approach the reliability of polyp segmentation and measurement ha been largely increased to ie error mm compared with other state of art work of about 
the ability to navigate through the world is an essential capability to human in a variety of situation people do not have the time the opportunity or the capability to learn the layout of the environment before visiting an area example include soldier in the field entering an unknown building firefighter responding to an emergency or a visually impaired person walking through the city in absence of external source of localization such a gps the system must rely on internal sensing to provide navigation guidance to the user in order to address real world situation the method must provide spatially extended temporally consistent navigation guidance through cluttered and dynamic environment while recent research ha largely focused on metric method based on calibrated camera the work presented in this thesis demonstrates a novel approach to navigation using uncalibrated camera during the first visit of the environment the method build a topological representation of the user s exploration path which we refer to a the place graph the method then provides navigation guidance from any place to any other in the explored environment on one hand a localization algorithm determines the location of the user in the graph on the other hand a rotation guidance algorithm provides a directional cue towards the next graph node in the user s body frame our method make little assumption about the environment except that it contains descriptive visual feature it requires no intrinsic or extrinsic camera calibration and relies instead on a method that learns the correlation between user rotation and feature correspondence across camera we validate our approach using several ground truth datasets in addition we show that our approach is capable of guiding a robot equipped with a local obstacle avoidance capability through real cluttered environment finally we validate our system with nine untrained user through several kilometer of indoor environment copy available exclusively from mit library rm cambridge ma ph fax 
we propose an approach to find and describe object within broad domain we introduce a new dataset that provides annotation for sharing model of appearance and correlation across category we use it to learn part and category detector these serve a the visual basis for an integrated model of object we describe object by the spatial arrangement of their attribute and the interaction between them using this model our system can find animal and vehicle that it ha not seen and infer attribute such a function and pose our experiment demonstrate that we can more reliably locate and describe both familiar and unfamiliar object compared to a baseline that relies purely on basic category detector 
face identification is the problem of determining whether two face image depict the same person or not this is difficult due to variation in scale pose lighting background expression hairstyle and glass in this paper we present two method for learning robust distance measure a a logistic discriminant approach which learns the metric from a set of labelled image pair ldml and b a nearest neighbour approach which computes the probability for two image to belong to the same class mknn we evaluate our approach on the labeled face in the wild data set a large and very challenging data set of face from yahoo news the evaluation protocol for this data set defines a restricted setting where a fixed set of positive and negative image pair is given a well a an unrestricted one where face are labelled by their identity we are the first to present result for the unrestricted setting and show that our method benefit from this richer training data much more so than the current state of the art method our result of and correct for the restricted and unrestricted setting respectively significantly improve over the current state of the art result of confidence score obtained for face identification can be used for many application e g clustering or recognition from a single training example we show that our learned metric also improve performance for these task 
in this paper we propose a prism based system for capturing multispectral video the system consists of a triangular prism a monochrome camera and an occlusion mask incoming light beam from the scene are sampled by the occlusion mask dispersed into their constituent spectrum by the triangular prism and then captured by the monochrome camera our system is capable of capturing video of high spectral resolution it also allows for different tradeoff between spectral and spatial resolution by adjusting the focal length of the camera we demonstrate the effectiveness of our system with several application including human skin detection physical material recognition and rgb video generation 
for many application in graphic design and human computer interaction it is essential to understand where human look in a scene where eye tracking device are not a viable option model of saliency can be used to predict fixation location most saliency approach are based on bottom up computation that doe not consider top down image semantics and often doe not match actual eye movement to address this problem we collected eye tracking data of viewer on image and use this database a training and testing example to learn a model of saliency based on low middle and high level image feature this large database of eye tracking data is publicly available with this paper 
in this paper we propose a new approach for face shape recovery from a single image a single near infrared nir image is used a the input and a mapping from the nir tensor space to d tensor space learned by using statistical learning is used for the shape recovery in the learning phase the two tensor model are constructed for nir and d image respectively and a canonical correlation analysis cca based multi variate mapping from nir to d face is learned from a given training set of nir d face pair in the reconstruction phase given an nir face image the depth map is computed directly using the learned mapping with the help of tensor model experimental result are provided to evaluate the accuracy and speed of the method the work provides a practical solution for reliable and fast shape recovery and modeling of d object 
conventional supervised method for image categorization rely on manually annotated labeled example to learn good object model which mean their generality and scalabilitydependsheavilyon the amountof humaneffort available to help train them we propose an unsupervised approach to construct discriminative model for category specified simply by their name we show that multipleinstance learning enables the recovery of robust category model from image returned by keyword based search engine by incorporatingconstraints that reflect the expected sparsity of true positive example into a large margin objective function our approach remains accurate even when the available text annotation are imperfect and ambiguous in addition we show how to iteratively improve the learned classifier by automatically refining the representation of the ambiguously labeled example we demonstrate our method with benchmark datasets and show that it performs well relative to both state of the artunsupervised approach and traditional fully supervised technique 
finding correspondence between feature point is one of the most relevant problem in the whole set of visual task in this paper we address the problem of matching a feature vector or a matrix to a given subspace given any vector base of such a subspace we observe a linear combination of it element with all entry swapped by an unknown permutation we prove that such a computationally hard integer problem is uniquely solved in a convex set resulting from relaxing the original problem also if noise is present based on this result we provide a robust estimate recurring to a linear programming based algorithm we use structure from motion and object recognition a motivating example 
in this paper we propose partition min hash pmh a novel hashing scheme for discovering partial duplicate image from a large database unlike the standard min hash algorithm that assumes a bag of word image representation our approach utilizes the fact that duplicate region among image are often localized by theoretical analysis simulation and empirical study we show that pmh outperforms standard min hash in term of precision and recall while being order of magnitude faster when combined with the start of the art geometric min hash algorithm our approach speed up hashing by time without losing precision or recall when given a fixed time budget our method achieves much higher recall than the state of the art 
we propose a novel approach to designing algorithm for object tracking based on fusing multiple observation model a the space of possible observation model is too large for exhaustive on line search this work aim to select model that are suitable for a particular tracking task at hand during an off line training stage observation model from various off the shelf tracker are evaluated from this da ta different method of fusing the observer on line are inves tigated including parallel and cascaded evaluation expe riments on test sequence show that this evaluation is useful for automatically designing and assessing algorithm for a particular tracking task result are shown for face tracking with a handheld camera and hand tracking for gesture interaction we show that for these case combining a small number of observer in a sequential cascade result in efficient algorithm that are both robust and precise 
we propose an algorithm for accurate tracking of articulated object using online update of appearance and shape the challenge here is to model foreground appearance with histogram in a way that is both efficient and accurate in this algorithm the constantly changing foreground shape is modeled a a small number of rectangular block whose position within the tracking window are adaptively determined under the general assumption of stationary foreground appearance we show that robust object tracking is possible by adaptively adjusting the location of these block implemented in matlab without substantial optimization our tracker run already at frame per second on a ghz machine experimental result have demonstrated that the algorithm is able to efficiently track articulated object undergoing large variation in appearance and shape 
palmprint verification is a relatively new but promising personal authentication technique for it high accuracy and fast matching speed two dimensional d palmprint recognition ha been well studied in the past decade and recently three dimensional d palmprint recognition technique were also proposed the d and d palmprint data can be captured simultaneously and they provide different and complementary information d palmprint contains the depth information of the palm surface while d palmprint contains plenty of texture how to efficiently extract and fuse the d and d palmprint feature to improve the recognition performance is a critical issue for practical palmprint system in this paper an efficient joint d and d palmprint matching scheme is proposed the principal line feature and palm shape feature are extracted and used to accurately align the palmprint and a couple of matching rule are defined to efficiently use the d and d feature for recognition the experiment on a d d palmprint database which contains sample show that the proposed scheme can greatly improve the performance of palmprint verification 
human motion tracking is an important problem in computer vision most prior approach have concentrated on efficient inference algorithm and prior motion model however few can explicitly account for physical plausibility of recovered motion the primary purpose of this work is to enforce physical plausibility in the tracking of a single articulated human subject towards this end we propose a fullbody d physical simulation based prior that explicitly incorporates motion control and dynamic into the bayesian filtering framework we consider the human s motion to be generated by a control loop in this control loop newtonian physic approximates the rigid body motion dynamic of the human and the environment through the application and integration of force collision generate interaction force to prevent physically impossible hypothesis this allows u to properly model human motion dynamic ground contact and environment interaction for efficient inference in the resulting high dimensional state space we introduce exemplar based control strategy to reduce the effective search space a a result we are able to recover the physically plausible kinematic and dynamic state of the body from monocular and multi view imagery we show both quantitatively and qualitatively that our approach performs favorably with respect to standard bayesian filtering method 
we present a photometric stereo method for non rigid object of unknown and spatially varying material the prior art us time multiplexed illumination but assumes constant surface normal across several frame fundamentally limiting the accuracy of the estimated normal we explicitly account for time varying surface orientation and show that for unknown lambertian material five image are sufficient to recover surface orientation in one frame our optimized system implementation exploit the physical property of typical camera and led to reduce the required number of image to just three and also facilitates frame to frame image alignment using standard optical flow method despite varying illumination we demonstrate the system s performance by computing surface orientation for several different moving deforming object 
we present a novel variant of the ransac algorithm that is much more efficient in particular when dealing with problem with low inlier ratio our algorithm assumes that there exists some grouping in the data based on which we introduce a new binomial mixture model rather than the simple binomial model a used in ransac we prove that in the new model it is more efficient to sample data from a smaller number of group and group with more tentative correspondence which lead to a new sampling procedure that us progressive number of group we demonstrate our algorithm on two classical geometric vision problem wide baseline matching and camera resectioning the experiment show that the algorithm serf a a general framework that work well with three possible grouping strategy investigated in this paper including a novel optical flow based clustering approach the result show that our algorithm is able to achieve a significant performance gain compared to the standard ransac and prosac 
a new approach called collective shape difference classifier csdc is proposed to improve the accuracy and computational efficiency of d face recognition the csdc learns the most discriminative local area from the pure shape difference map psdm and train them a weak classifier for assembling a collective strong classifier using the real boosting approach the psdm is established between two d face model aligned by a posture normalization procedure based on facial feature the model alignment is self dependent which avoids registering the probe face against every different gallery face during the recognition so that a high computational speed is obtained the experiment carried out on the frgc v and bu dfe database yield rank recognition rate better than each recognition against a gallery with face only need about second these two experimental result together with the high performance recognition on partial face demonstrate that our algorithm is not only effective but also efficient 
we present a novel action recognition method which is based on combining the effective description property of local binary pattern with the appearance invariance and adaptability of patch matching based method the resulting method is extremely efficient and thus is suitable for real time us of simultaneous recovery of human action of several length and starting point tested on all publicity available datasets in the literature known to u our system repeatedly achieves state of the art performance lastly we present a new benchmark that focus on uncut motion recognition in broadcast sport video 
this paper present a method for human action recognition based on pattern of motion previous approach to action recognition use either local feature describing small patch or large scale feature describing the entire human figure we develop a method constructing mid level motion feature which are built from low level optical flow information these feature are focused on local region of the image sequence and are created using a variant of adaboost these feature are tuned to discriminate between different class of action and are efficient to compute at run time a battery of classifier based on these mid level feature is created and used to classify input sequence state of theart result are presented on a variety of standard datasets we believe a promising direction lie in between these two type of feature building mid level feature which can be used to recognize action the focus of this paper is developing algorithm for discriminatively learning midlevel motion feature the learning framework we use is based on the shapelet feature of sabzmeydani and mori in that work midlevel shape feature were constructed from low level gradient feature using the adaboost algorithm in this work we use motion feature based on the work of efros et al in this framework with the goal of recognizing human action in video sequence the main contribution of this paper is the development of an approach for action recognition based on mid level motion feature we show that this approach give state of theart performance on a variety of standard datasets kth weizmann soccer and is computationally efficient 
the required amount of labeled training data for object detection and classification is a major drawback of current method combining labeled and unlabeled data via semisupervised learning hold the promise to ease the tedious and time consuming labeling effort this paper present a novel semi supervised learning method which combine the power of learned similarity function and classifier the approach capable of exploiting both labeled and unlabeled data is formulated in a boosting framework one classifier the learned similarity serf a a prior which is steadily improved via training a second classifier on labeled and unlabeled sample we demonstrate the approach on challenging computer vision application first we show how we can train a classifier using only a few labeled sample and many unlabeled data second we improve specialize a state of the art detector by using labeled and unlabeled data 
this article present a novel method for acquiring high quality solid model of complex d shape from multiple calibrated photograph after the purely geometric constraint associated with the silhouette found in each image have been used to construct a coarse surface approximation in the form of a visual hull photoconsistency constraint are enforced in three consecutive step the rim where the surface graz the visual hull are first identified through dynamic programming with the rim now fixed the visual hull is carved using graph cut to globally optimize the photoconsistency of the surface and recover it main feature an iterative local refinement step is finally used to recover fine surface detail the proposed approach ha been implemented and experiment with seven real data set are presented along with qualitative and quantitative comparison with several state of the art image based modeling algorithm 
in an object recognition scenario with ten of thousand of category even a small number of label per category lead to a very large number of total label required we propose a simple method of label sharing between semantically similar category we leverage the wordnet hierarchy to define semantic distance between any two category and use this semantic distance to share label our approach can be used with any classifier experimental result on a range of datasets upto million image and category in size show that despite the simplicity of the approach it lead to significant improvement in performance 
image category recognition is important to access visual information on the level of object and scene type so far intensity based descriptor have been widely used to increase illumination invariance and discriminative power color descriptor have been proposed only recently a many descriptor exist a structured overview of color invariant descriptor in the context of image category recognition is required therefore this paper study the invariance property and the distinctiveness of color descriptor in a structured way the invariance property of color descriptor are shown analytically using a taxonomy based on invariance property with respect to photometric transformation the distinctiveness of color descriptor is assessed experimentally using two benchmark from the image domain and the video domain from the theoretical and experimental result it can be derived that invariance to light intensity change and light color change affect category recognition the result reveal further that for light intensity change the usefulness of invariance is category specific 
in recent year the markov random field mrf ha become the de facto probabilistic model for low level vision application however in a maximum a posteriori map framework mrfs inherently encourage delta function marginal statistic by contrast many low level vision problem have heavy tailed marginal statistic making the mrf model unsuitable in this paper we introduce a more general marginal probability field mpf of which the mrf is a special linear case and show that convex energy mpfs can be used to encourage arbitrary marginal statistic we introduce a flexible extensible framework for effectively optimizing the resulting np hard map problem based around dual decomposition and a modified mincost flow algorithm and which achieves global optimality in some instance we use a range of application including image denoising and texture synthesis to demonstrate the benefit of this class of mpf over mrfs 
different material reflect light in different way and reflectance interacts with shape lighting and viewpoint to determine an object s image common material exhibit diverse reflectance effect and this is a significant source of difficulty for radiometric image analysis one strategy for dealing with this diversity is to build computational tool that exploit reflectance symmetry such a reciprocity an d isotropy that are exhibited by broad class of material in this paper we advocate the real projective plane a a tool for representing and exploiting these symmetry in this a pproach each point in the plane represents a surface normal that is visible from a fixed viewpoint and reflectance symmetry are analyzed in term of the geometric structure that they induce we provide an overview of these structure and explore application to both calibrated and uncalibrated photometric stereo 
abstract we introduce a novel energy minimization method to decompose a video into a set of super resolved moving layer the proposed energy corresponds to the cost of coding the sequence it consists of a data term and two term imposing regularity of the geometry and the intensity of each layer in contrast to existing motion layer method we perform graphcutoptimizationinthe dual layerspacetodetermine which layer is visible at which video position in particular we show how arising higher order term can be accounted for by a generalization of alpha expansion moreover our model accurately capture long term temporal consistency tothebestofourknowledge thisisthefirstworkwhichaims at modeling detail of the image formation process such a camera blur and downsampling in the context of motion layer decomposition the experimental result demonstrate thatenergyminimizationleadstoareconstructionofavideo in term of a superposition of multiple high resolution motion layer 
this paper proposes a novel approach to discover a set of class specific ldquocomposite featuresrdquo a the feature pool for the detection and classification of complex object using adaboost each composite feature is constructed from the combination of multiple individual feature unlike previous work that design feature manually or with certain restriction the class specific feature are selected from the space of all combination of a set of individual feature to achieve this we first establish an analogue between the problem of discriminative feature selection and generative image segmentation and then draw discriminative sample from the combinatory space with a novel algorithm called discriminative generalized swendsen wang cut these sample form the initial pool of feature where adaboost is applied to learn a strong classifier combining the most discriminative composite feature we demonstrate the efficacy of our approach by comparing with existing detection algorithm for finding people in general pose 
abstract we present a new approach to iteratively estimate both high quality depth map and alpha matte from a single image or a video sequence scene depth which is invariant to illumination change color similarity and motion ambiguity provides a natural and robust cue for foreground background segmentation a prerequisite for matting the image matte on the other hand encode rich information near boundary where either passive or active sensing method performs poorly we develop a method to combine the complementary nature of scene depth and alpha matte to mutually enhance their quality we formulate depth inference a a global optimization problem where information from passive stereo active range sensor and matte is merged the depth map is used in turn to enhance the matting in addition we extend this approach to video matting by incorporating temporal coherence which reduces flickering in the composite video we show that these technique lead to improved accuracy and robustness for both static and dynamic scene 
this paper improves recent method for large scale image search state of the art method build on the bag of feature image representation we first analyze bag of feature in the framework of approximate nearest neighbor search this show the sub optimality of such a representation for matching descriptor and lead u to derive a more precise representation based on hamming embedding he and weak geometric consistency constraint wgc he provides binary signature that refine the matching based on visual word wgc filter matching descriptor that are not consistent in term of angle and scale he and wgc are integrated within the inverted file and are efficiently exploited for all image even in the case of very large datasets experiment performed on a dataset of one million of image show a significant improvement due to the binary signature and the weak geometric consistency constraint a well a their efficiency estimation of the full geometric transformation i e a re ranking step on a short list of image is complementary to our weak geometric consistency constraint and allows to further improve the accuracy 
city environment often lack textured area contain repetitive structure strong lighting change and therefore are very difficult for standard d modeling pipeline we present a novel unified framework for creating d city model which overcomes these difficulty by exploiting image segmentation cue a well a presence of dominant scene orientation and piecewise planar structure given panoramic street view sequence we first demonstrate how to robustly estimate camera pose without a need for bundle adjustment and propose a multi view stereo method which operates directly on panorama while enforcing the piecewise planarity constraint in the sweeping stage at last w e propose a new depth fusion method which exploit the constraint of urban environment and combine advantage of volumetric and viewpoint based fusion method our technique avoids expensive voxelization of space operates directly on d reconstructed point through effective kd tre e representation and obtains a final surface by tessellationof backprojections of those point into the reference image 
background modeling play an important role in video surveillance yet in complex scene it is still a challenging problem among many difficulty problem caused by illumination variation and dynamic background are the key aspect in this work we develop an efficient background subtraction framework to tackle these problem first we propose a scale invariant local ternary pattern operator and show that it is effective for handling illumination variation especially for moving soft shadow second we propose a pattern kernel density estimation technique to effectively model the probability distribution of local pattern in the pixel process which utilizes only one single lbp like pattern instead of histogram a feature third we develop multimodal background model with the above technique and a multiscale fusion scheme for handling complex dynamic background exhaustive experimental evaluation on complex scene show that the proposed method is fast and effective achieving more than improvement in accuracy compared over existing state of the art algorithm 
probabilistic graphical model such a bayesian network have been increasingly applied to many computer vision problem accuracy of inference in such model depends on the quality of network parameter learning reliable parameter of bayesian network often requires a large amount of training data which may be hard to acquire and may contain missing value on the other hand qualitative knowledge is available in many computer vision application and incorporating such knowledge can improve the accuracy of parameter learning this paper describes a general framework based on convex optimization to incorporate constraint on parameter with training data to perform bayesian network parameter estimation for complete data a global optimum solution to maximum likelihood estimation is obtained in polynomial time while for incomplete data a modified expectation maximization method is proposed this framework is applied to real image data from a facial action unit recognition problem and produce result that are similar to those of state of the art method 
tensor based dimensionality reduction ha recently been extensively studied for computer vision application to our knowledge however there exist no rigorous error analysis on these method here we provide the first error analysis of these method and provide error bound result similar to eckart young theorem which play critical role in the development and application of singular value decomposition svd beside performance guarantee these error bound are useful for subspace size determination according to the required video image reconstruction error furthermore video surveillance retrieval d d medical image analysis and other computer vision application require particular reduction in spatio temporal space but not along data index dimension this motivates a d tensor reduction standard method such a high order svd hosvd compress data in all index dimension and thus can not perform the classification and pattern recognition task we provide algorithm and error bound analysis of the d factorization for spatio temporal data dimensionality experiment on video sequence demonstrate our approach outperforms the previous dimensionality deduction method for spatiotemporal data 
segmentation in the surveillance domain ha to deal with shadow to avoid distortion when detecting moving object most segmentation approach dealing with shadow detection are typically restricted to penumbra shadow therefore such technique cannot cope well with umbra shadow consequently umbra shadow are usually detected a part of moving object in this paper we present a novel technique based on gradient and colour model for separating chromatic moving cast shadow from detected moving object firstly both a chromatic invariant colour cone model and an invariant gradient model are built to perform automatic segmentation while detecting potential shadow in a second step region corresponding to potential shadow are grouped by considering a bluish effect and an edge partitioning lastly i temporal similarity between texture and ii spatial similarity between chrominance angle and brightness distortion are analysed for all potential shadow region in order to finally identify umbra shadow unlike other approach our method doe not make any a priori assumption about camera location surface geometry surface texture shape and type of shadow object and background experimental result show the performance and accuracy of our approach in different shadowed material and illumination condition 
we present a novel representation for modeling textured region subject to smooth variation in orientation and scale utilizing the steerable pyramid of simoncelli and freeman a a basis we decompose textured region of natural image into explicit local attribute of contrast bias scale and orientation additionally we impose smoothness on these attribute via markov random field the combinationallowsfordemonstrableimprovementsincommon scene analysis application including unsupervised segmentation reflectance and shading estimation and estimation of the radiometric response function from a single image 
we propose a novel approach to reduce spatially varying motion blur using a hybrid camera system that simultaneously capture high resolution video at a low frame rate together with low resolution video at a high frame rate our work is inspired by ben ezra and nayar who introduced the hybrid camera idea for correcting global motion blur for a single still image we broaden the scope of the problem to address spatially varying blur a well a video imagery we also reformulate the correction process to use more information available in the hybrid camera system a well a iteratively refine spatially varying motion extracted from the low resolution high speed camera we demonstrate that our approach achieves superior result over existing work and can be extended to deblurring of moving object 
this paper present a new method for computing optimal l solution for vision geometry problem particularly for those problem of fixed dimension and of large scale our strategy for solving a large l problem is to reduce it to a finite set of smallest possible subproblems by using the fact that many of the problem in question are pseudoconvex we prove that such a reduction is possible to actually solve these small subproblems efficiently we propose a direct approach which make no use of any convex optimizer e g socp or lp but is based on a simple local newton method we give both theoretic justification and experimental validation to the new method potentially our new method can be made extremely fast 
we propose an algorithm for large displacement optical flow estimation which doe not require the commonly used coarse to fine warping strategy it is based on a quadratic relaxation of the optical flow functional which decouples data term and regularizer in such a way that the non linearized variational problem can be solved by an alternation of two globally optimal step one imposing optimal data consistency the other imposing discontinuitypreserving regularity of the flow field experimental result confirm that the proposed algorithmic implementation outperforms the traditional warping strategy in particular for the case of large displacement of small scale structure 
visual tracking usually involves an optimization process for estimating the motion of an object from measured image in a video sequence in this paper a new evolutionary approach pso particle swarm optimization is adopted for visual tracking since the tracking process is a dynamic optimization problem which is simultaneously influenced by the object state and the time we propose a sequential particle swarm optimization framework by incorporating the temporal continuity information into the traditional pso algorithm in addition the parameter in pso are changed adaptively according to the fitness value of particle and the predicted motion of the tracked object leading to a favourable performance in tracking application furthermore we show theoretically that in a bayesian inference view the sequential pso framework is in essence a multilayer importance sampling based particle filter experimental result demonstrate that compared with the state of the art particle filter and it variation the unscented particle filter the proposed tracking algorithm is more robust and effective especially when the object ha an arbitrary motion or undergoes large appearance change 
this paper present a method to quantitatively evaluate information contribution of individual bottom up and top down computing process in object recognition our objective is to start a discovery on how to schedule bottom up and top down process we identify two bottom up process and one top down process in hierarchical model termed and channel respectively we formulate the three channel under an unified bayesian framework we use a blocking control strategy to isolate the three channel to separately train them and individually measure their information contribution in typical recognition task based on the evaluated result we integrate the three channel to detect object with performance improvement obtained our experiment are performed in both low middle level task such a detecting edge bar and junction and high level task such a detecting human face and car together with a group of human study designed to compare computer and human perception 
abstract spectral clustering and eigenvector based method have become increasingly popular in segmentation and recognition although the choice of the pairwise similarity metric or affinity greatly influence the quality of the result this choice is typically specified outside the learning framework in this paper we present an algorithm to learn class specific similarity function mapping our problem in a conditional random field crf framework enables u to pose the task of learning affinity a parameter learning in undirected graphical model there are two significant advance over previous work first we learn the affinity between a pair of data point a a function of a pairwise feature and in contrast with previous approach the class to which these two data point were mapped allowing u to work with a richer class of affinity second our formulation provides a principled probabilistic interpretation for learning all of the parameter that define these affinity using ground truth segmentation and labellings for training we learn the parameter with the greatest discriminative power in an mle sense on the training data we demonstrate the power of this learning algorithm in the setting of joint segmentation and recognition of object class specifically even with very simple appearance feature the proposed method achieves state of the art performance on standard datasets i content 
dictionary generation is a core technique of the bag of visual word bov model when applied to image categorization most of previous approach generate dictionary by unsupervised clustering technique e g k mean however the feature obtained by such kind of dictionary may not be optimal for image classification in this paper we propose a probabilistic model for supervised dictionary learning sdlm which seamlessly combine an unsupervised model a gaussian mixture model and a supervised model a logistic regression model in a probabilistic framework in the model image category information directly affect the generation of a dictionary a dictionary obtained by this approach is a trade off between minimization of distortion of cluster and maximization of discriminative power of image wise representation i e histogram representation of image we further extend the model to incorporate spatial information during the dictionary learning process in a spatial pyramid matching like manner we extensively evaluated the two model on various benchmark dataset and obtained promising result 
automatic defect tolerant registration of transmission electron microscopy tem image pose an important and challenging problem for biomedical image analysis e g in computational neuroanatomy in this paper we demonstrate a fully automatic stitching and distortion correction method for tem image and propose a probabilistic approach for image registration the technique identifies image defect due to sample preparation and image acquisition by outlier detection a polynomial kernel expansion is used to estimate a non linear image transformation based on intensity and spatial feature corresponding point in the image are not determined beforehand but they are estimated via an em algorithm during the registration process which is preferable in the case of noisy tem image our registration model is successfully applied to two large image stack of serial section tem image acquired from brain tissue sample in a computational neuroanatomy project and show significant improvement over existing image registration method on these large datasets 
multiple camera system mc have been widely used in many vision application and attracted much attention recently there are two principle type of mc one is the rigid multiple camera system rmcs the other is the articulated camera system ac in a rmcs the relative pose relative d position and orientation between the camera are invariant while in an ac the camera are articulated through movable joint the relative pose between them may change therefore through calibration of an ac we want to find not only the relative pose between the camera but also the position of the joint in the ac although calibration method for rmcs have been extensively developed during the past decade the study of ac calibration are still rare in this paper two ac calibration method are proposed the first one us the feature correspondence between the camera in the ac the second one requires only the ego motion information of the camera and can be used for the calibration of the non overlapping view ac in both method the ac is assumed to have performed general transformation in a static environment the efficiency and robustness of the proposed method are tested by simulation and real experiment in the real experiment the intrinsic and extrinsic parameter of the ac are calibrated using the same image sequence no extra data capturing step is required the corresponding trajectory is recovered and illustrated using the calibration result of the ac to our knowledge we are the first to study the calibration of ac 
context modeling for vision recognition and automatic image annotation aia ha attracted increasing attention in recent year for various contextual information and resource semantic context ha been exploited in aia and brings promising result however previous work either casted the problem into structural classification or adopted multi layer modeling which suffer from the problem of scalability or model efficiency in this paper we propose a novel discriminative conditional random field crf model for semantic context modeling in aia which is built over semantic concept and treat an image a a whole observation without segmentation our model capture the interaction between semantic concept from both semantic level and visual level in an integrated manner specifically we employ graph structure to model contextual relationship between semantic concept the potential function are designed based on linear discriminative model which enables u to propose a novel decoupled hinge loss function for maximal margin parameter estimation we train the model by solving a set of independent quadratic programming problem with our derived contextual kernel the experiment are conducted on commonly used benchmark corel and trecvid data set for evaluation the experimental result show that compared with the state of the art method our method achieves significant improvement on annotation performance 
in many retrieval object recognition and wide baseline stereo method correspondence of interest point distinguished region are commonly established by matching compact descriptor such a sifts we show that a subsequent cosegmentation process coupled with a quasi optimal sequential decision process lead to a correspondence verification procedure that ha high precision is highly discriminative ha good recall and is fast the sequential decision on the correctness of a correspondence is based on simple statistic of a modified dense stereo matching algorithm the statistic are projected on a prominent discriminative direction by svm wald s sequential probability ratio test is performed on the svm projection computed on progressively larger cosegmented region we show experimentally that the proposed sequential correspondence verification scv algorithm significantly outperforms the standard correspondence selection method based on sift distance ratio on challenging matching problem 
this paperpresentsa newmethodto enforceinverse consistency in nonrigid image registration and matching conventional approach assume diffeomorphic transformation implicitly or explicitly however the inherent smoothnessconstraintdiscouragesdiscontinuityconsideration we propose a post processing algorithm that integrates the input forward and backward field which are output by existing registration matching algorithm to produce more robust result given such a pair of input field our algorithm alternately refines the field by tensor belief propagation and enforces inverse consistency in stochastic sense by generalized total least square fitting to show the efficacyof ourstochastic inverse consistencyapproach we first present result on very noisy field we then demonstrate improvement on existing stereo matching where occlusion is naturally handled by localizing violation of inverse consistency finally we propose a novel application on image stitching where stochastic inverse consistency is employed in structure deformation in order to seamlessly align overlapping image with severe misalignment in structure and intensity 
many computer vision problem involving feature correspondence among image can be formulated a an assignment problem with a quadratic cost function such problem are computationally infeasible in general but recent advance in discrete optimization such a tree reweighted belief propagation trw often provide high quality solution in this paper we improve upon these algorithm in two way first we introduce covering tree a variant of trw which provide the same bound on the map energy a trw with far fewer variational parameter optimization of these parameter can be carried out efficiently using either fixed point iteration a in trw or sub gradient based technique second we introduce a new technique that utilizes bipartite matching applied to the min marginals produced with covering tree in order to compute a tighter lower bound for the quadratic assignment problem we apply this machinery to the problem of finding correspondence with pairwise energy function and demonstrate the resulting hybrid method outperforms trw alone and a recent related subproblem decomposition algorithm on benchmark image correspondence problem 
we present a method for the detection of instance of an object class such a car or pedestrian in natural image similarly to some previous work this is accomplished via generalized hough transform where the detection of individual object part cast probabilistic vote for possible location of the centroid of the whole object the detection hypothesis then correspond to the maximum of the hough image that accumulates the vote from all part however whereas the previous method detect object part using generative codebooks of part appearance we take a more discriminative approach to object part detection towards this end we train a class specific hough forest which is a random forest that directly map the image patch appearance to the probabilistic vote about the possible location of the object centroid we demonstrate that hough forest improve the result of the hough transform object detection significantly and achieve state of the art performance for several class and datasets 
image similarity search is a fundamental problem in computer vision efficient similarity search across large image database depends critically on the availability of compact image representation and good data structure for indexing them numerous approach to the problem of generating and indexing image code have been presented in the literature but existing scheme generally lack explicit estimate of the number of bit needed to effectively index a given large image database we present a very simple algorithm for generating compact binary representation of imagery data based on random projection our analysis give the first explicit bound on the number of bit needed to effectively solve the indexing problem when applied to real image search task these theoretical improvement translate into practical performance gain experimental result show that the new method while using significantly le memory is several time faster than existing alternative 
similarity metric that are learned from labeled training data can be advantageous in term of performance and or efficiency these learned metric can then be used in conjunction with a nearest neighbor classifier or can be plugged in a kernel to an svm for the task of categorization two scenario have thus far been explored the first is to train a single monolithic similarity metric that is then used for all example the other is to train a metric for each category in a v all manner while the former approach seems to be at a disadvantage in term of performance the latter is not practical for large number of category in this paper we explore the space in between these two extreme we present an algorithm that learns a few similarity metric while simultaneously grouping category together and assigning one of these metric to each group we present promising result and show how the learned metric generalize to novel category 
we investigate the problem of pedestrian detection in still image sliding window classifier notably using the histogram of gradient hog feature proposed by dalal and triggs are the state of the art for this task and we base our method on this approach we propose a novel feature extraction scheme which computes implicit soft segmentation of image region into foreground background the method yield stronger object background edge than grayscale gradient alone suppresses textural and shading variation and capture local coherence of object appearance the main contribution of our work are i incorporation of segmentation cue into object detection ii integration with classifier learning cf a post processing filter iii high computational efficiency we report result on the inria person detection dataset achieving state of the art result considerably exceeding those of the original hog detector preliminary result for generic object detection on the pascal voc dataset also show substantial improvement in accuracy 
we address the problem of tracking point in dense vector field such vector field may come from computational fluid dynamic simulation environmental monitoring sensor or dense point tracking of video data to track point in vector field we capture the distribution of higher order property e g property derived from the gradient of the velocity vector field in a novel local descriptor called a vector spin image our distribution based approach ha a number of advantage over method that use topology analysis to track point in vector field the local distribution are robust to noise adaptable to change in the feature and can be used to extrapolate the location of feature after they have disappeared we describe the vector spin image data structure the higher order property we record to track vector field point and show result of tracking point in the simulated flow through a diesel engine cylinder 
systematic content screening of cell phenotype in microscopic image ha been shown promising in gene function understanding and drug design however manual annotation of cell and image in genome wide study is cost prohibitive in this paper we propose a highly efficient active annotation framework in which a small amount of expert input is leveraged to rapidly and effectively infer the label over the remaining unlabeled data we formulate this a a graph based transductive learning problem and develop a novel method for label propagation specifically a label regularizer method is proposed to handle the important label imbalance issue typically seen in the cellular image screening application we also design a new scheme which break the graph into linear superposition of contribution from individual labeled sample we take advantage of such a superposable representation to achieve fast annotation in an interactive setting extensive evaluation over toy data and realistic cellular image confirm the superiority of the proposed method over existing alternative 
much of recent action recognition research is based on space time interest point extracted from video using a bag of word bow representation it mainly relies on the discriminative power of individual local space time descriptor whilst ignoring potentially valuable information about the global spatio temporal distribution of interest point in this paper we propose a novel action recognition approach which differs significantly from previous interest point based approach in that only the global spatiotemporal distribution of the interest point are exploited this is achieved through extracting holistic feature from cloud of interest point accumulated over multiple temporal scale followed by automatic feature selection our approach avoids the non trivial problem of selecting the optimal space time descriptor clustering algorithm for constructing a codebook and selecting codebook size faced by previous interest point based method our model is able to capture smooth motion robust to view change and occlusion at a low computation cost experiment using the kth and weizmann datasets demonstrate that our approach outperforms most existing method 
in this paper we present a novel approach for automatically learning a compact and yet discriminative appearance based human action model a video sequence is represented by a bag of spatiotemporal feature called video word by quantizing the extracted d interest point cuboid from the video our proposed approach is able to automatically discover the optimal number of videoword cluster by utilizing maximization of mutual information mmi unlike the k mean algorithm which is typically used to cluster spatiotemporal cuboid into video word based on their appearance similarity mmi clustering further group the video word which are highly correlated to some group of action to capture the structural information of the learnt optimal video word cluster we explore the correlation of the compact video word cluster we use the modified correlgoram which is not only translation and rotation invariant but also somewhat scale invariant we extensively test our proposed approach on two publicly available challenging datasets the kth dataset and ixmas multiview dataset to the best of our knowledge we are the first to try the bag of video word related approach on the multiview dataset we have obtained very impressive result on both datasets 
the objective of this paper is to estimate d human pose a a spatial configuration of body part in tv and movie video shot such video material is uncontrolled and extremely challenging we propose an approach that progressively reduces the search space for body part to greatly improve the chance that pose estimation will succeed this involves two contribution i a generic detector using a weak model of pose to substantially reduce the full pose search space and ii employing grabcut initialized on detected regio n proposed by the weak model to further prune the search space moreover we also propose iii an integrated spatio temporal model covering multiple frame to refine pose estimate from individual frame with inference using belie f propagation the method is fully automatic and self initializing and explains the spatio temporal volume covered by a person moving in a shot by soft labeling every pixel a belonging to a particular body part or to the background we demonstrate upper body pose estimation by an extensive evaluation over frame from four episode of the tv series buffy the vampire slayer and present an application to fullbody action recognition on the weizmann dataset 
we address the problem of deformable shape and motion recovery from point correspondence in multiple perspective image we use the low rank shape model i e the d shape is represented a a linear combination of unknown shape base we propose a new way of looking at the low rank shape model instead of considering it a a whole we assume a coarse to fine ordering of the deformation mode which can be seen a a model prior this ha several advantage first the high level of ambiguity of the original low rank shape model is drastically reduced since the shape base can not anymore be arbitrarily re combined second this allows u to propose a coarse to fine reconstruction algorithm which start by computing the mean shape and iteratively add deformation mode it directly give the sought after metric model thereby avoiding the difficult upgrading step required by most of the other method third this make it possible to automatically select the number of deformation mode a the reconstruction algorithm proceeds we propose to incorporate two other prior accounting for temporal and spatial smoothness which are shown to improve the quality of the recovered model parameter the proposed model and reconstruction algorithm are successfully demonstrated on several video and are shown to outperform the previously proposed algorithm 
automatic facial action unit au detection from video is a long standing problem in computer vision two main approacheshave been pursued static modeling typically posed a a discriminative classification problem in which each video frame is evaluated independently temporal modeling frame are segmented into sequence and typically modeled with a variant of dynamic bayesian network we propose a segment based approach kseg svm that incorporates benefit of both approach and avoids their limitation kseg svm is a temporal extension of the spatial bag of word kseg svm is trained within a structured output svm framework that formulates au detection a a problem of detecting temporal event in a time series of visual feature each segment is modeled by a variant of the bow representation with soft assignment of the word based on similarity our framework ha several benefit for au detection both dependency between feature and the length of action unit are modeled all possible segment of the video may be used for training and no assumption are required about the underlying structure of the action unit event e g i i d our algorithm find the best k or fewer segment that maximize the svm score experimental result suggest that the proposedmethod outperforms state of the art static method for au detection 
this paper is focused on the co segmentation problem where the objective is to segment a similar object from a pair of image the background in the two image may be arbitrary therefore simultaneous segmentation of both image must be performed with a requirement that the appearance of the two set of foreground pixel in the respective image are consistent existing approach cast this problem a a markov random field mrf based segmentation of the image pair with a regularized difference of the two histogram assuming a gaussian prior on the foreground appearance or by calculating the sum of squared difference both are interesting formulation but lead to difficult optimization problem due to the presence of the second histogram difference term the model proposed here bypass measurement of the histogram difference in a direct fashion we show that this enables obtaining efficient solution to the underlying optimization model our new algorithm is similar to the existing method in spirit but differs substantially in that it can be solved to optimality in polynomial time using a maximum flow procedure on an appropriately constructed graph we discus our idea and present promising experimental result 
in this work we introduce a novel approach to object categorization that incorporates two type of context cooccurrence and relative location with local appearancebased feature our approach named cola for cooccurrence location and appearance us a conditional random field crf to maximize object label agreement according to both semantic and spatial relevance we model relative location between object using simple pairwise feature by vector quantizing this feature space we learn a small set of prototypical spatial relationship directly from the data we evaluate our result on two challenging datasets pascal and msrc the result show that combining co occurrence and spatial context improves accuracy in a many a half of the category compared to using co occurrence alone 
model updating is a critical problem in tracking inaccurate extraction of the foreground and background information in model adaptation would cause the model to drift and degrade the tracking performance the most direct but yet difficult solution to the drift problem is to obtain accurate boundary of the target we approach such a solution by proposing a novel closed loop model adaptation framework based on the combination of matting and tracking in our framework the scribble for matting are all automatically generated which make matting applicable in a tracking system meanwhile accurate boundary of the target can be obtained from matting result even when the target ha large deformation an effective model is further constructed and successfully updated based on such accurate boundary extensive experiment show that our closed loop adaptation scheme largely avoids model drift and significantly outperforms other discriminative tracking model a well a video matting approach 
in this paper we present a novel d surface and image reconstruction method based on the off axis aperture camera the key idea is to change the size or the d location of the aperture of the camera lens so a to extract selected portion of the light field of the scene we show that this result in an imaging device that blend defocus and stereo information and present an image formation model that simultaneously capture both phenomenon a this model involves a non trivial deformation of the scene space we also introduce the concept of scene space rectification and how this help the reconstruction problem finally we formulate our shape and image reconstruction problem a an energy minimization and use a gradient flow algorithm to find the solution result on both real and synthetic data are shown 
we present a novel content based video retrieval cbvr system driven by free hand sketch query depicting both object and their movement via dynamic cue streak line and arrow our main contribution is a probabilistic model of video clip based on linear dynamical system leading to an algorithm for matching description of sketched object to video we demonstrate our model fitting to clip under static and moving camera condition exhibiting linear and oscillatory motion we evaluate retrieval on two real video data set and on a video data set exhibiting controlled variation in shape color motion and clutter 
a fast d model reconstruction methodology is desirable in many application such a urban planning training and simulation in this paper we develop an automated algorithm for texture mapping oblique aerial image onto a d model generated from airborne light detection and ranging lidar data our proposed system consists of two step in the first step we combine vanishing point and global positioning system aided inertial system reading to roughly estimate the extrinsic parameter of a calibrated camera in the second step we refine the coarse estimate of the first step by applying a series of processing step specifically we extract d corner corresponding to orthogonal d structural corner a feature from both image and the untextured d lidar model the correspondence between an image and the d model is then performed using hough transform and generalized m estimator sample consensus the resulting d corner match are used in lowe s algorithm to refine camera parameter obtained earlier our system achieves correct pose recovery rate for image over the downtown berkeley area and overall accuracy rate for image over the residential downtown and campus portion of the city of berkeley 
we present a closed form solution to the nonrigid shape andmotion nrsm problem from point correspondence in multipleperspective uncalibrated view under the assumption that thenonrigid object deforms a a linear combination of krigidshapes we show that the nrsm problem can be viewed a areconstruction problem from multiple projection from k to therefore one can linearly solve for the projection matrix by factorizing amultifocal tensor however this projective reconstruction in k doe not satisfy the constraint ofthe nrsm problem because it is computed only up to a projectivetransformation in k our keycontribution is to show that by exploiting algebraic dependenciesamong the entry of the projection matrix one can upgrade theprojective reconstruction to determine the affine configuration ofthe point in and the motion of the camerarelative to their centroid moreover if k theneither by using calibrated camera or by assuming a camera withfixed internal parameter it is possible to compute the euclideanstructure by a closed form method 
a part of an architectural modeling project this paper investigates the problem of understanding and manipulating image of building our primary motivation is to automatically detect and seamlessly remove unwanted foreground element from urban scene without explicit handling these object will appear pasted a artifact on the model recovering the building facade in a video sequence is relatively simple because parallax induces foreground background depth layer but here we consider static image only we develop a series of method that enable foreground removal from image of building or brick wall the key insight is to use a prioriknowledge about grid pattern on building facade that can be modeled a near regular texture nrt we describe a markov random field mrf model for such texture and introduce a markov chain monte carlo mcmc optimization procedure for discovering them this simple spatial rule is then used a a starting point for inference of missing window facade segmentation outlier identification and foreground removal 
active appearance model aam based face tracking ha advantage of accurate alignment high efficiency and effectiveness for handling face deformation however aam suffers from the generalization problem and ha difficulty in image with cluttered background in this paper we introduce two novel constraint into aam fitting to address the above problem we first introduce a temporal matching constraint in aam fitting in the proposed fitting scheme the temporal matching enforces an inter frame local appearance constraint between frame the resulting model take advantage of temporal matching s good generalizability but doe not suffer from the mismatched point to make aam more stable for cluttered background we introduce a color based face segmentation a a soft constraint both constraint effectively improve the aam tracker s performance a demonstrated with experiment on various challenging real world video 
we propose a novel parametric deformable model controlled by shape and visual appearance prior learned from a training subset of co aligned image of goal object the shape prior is derived from a linear combination of vector of distance between the training boundary and their common centroid the appearance prior considers gray level within each training boundary a a sample of a markov gibbs random field with pairwise interaction spatially homogeneous interaction geometry and gibbs potential are analytically estimated from the training data to accurately separate a goal object from an arbitrary background empirical marginal gray level distribution inside and outside of the boundary are modeled with adaptive linear combination of discrete gaussians lcdg the evolution of the parametric deformable model is based on solving an eikonal partial differential equation with a new speed function which combine the prior shape prior appearance and current appearance model due to the analytical shape and appearance prior and a simple expectation maximization procedure for getting the object and background lcdg our segmentation is considerably faster than most of the known geometric and parametric model experiment with various goal image confirm the robustness accuracy and speed of our approach 
this project explores the idea of facial expression for automated feedback in teaching we show how automatic realtime facial expression recognition can be effectively used to estimate the difficulty level a perceived by an individual student of a delivered lecture we also show that facial expression is predictive of an individual student s preferred rate of curriculum presentation at each moment in time on a video lecture viewing task training on le than two minute of recorded facial expression data and testing on a separate validation set our system predicted the subject self reported difficulty score with mean accuracy of pearson r and their preferred viewing speed with mean accuracy of our technique are fully automatic and have potential application for both intelligent tutoring system it and standard classroom environment 
automated cell tracking using in vivo imagery is difficult in general due to the noise inherent in the imaging process occlusion varied cell appearance over time motion of other tissue distractors and cell traveling in and out of the image plane for certain type of cell these problem are exacerbated due to erratic motion pattern in this paper we introduce the radial flow transform which provides motion estimate for object of interest in a scene without explicitly tracking each object the transform is robust to misdetected object temporally disjoint motion event and can represent multiple direction of flow at a single location we provide operation to convert to and from a vector field representation this allows for intuitive reasoning about the motion pattern in a scene we demonstrate result on synthetic data and in vivo microscopy video of a mouse liver 
this paper present a new method to increase the quality of d video a new medium developed to represent d object in motion this representation is obtained from multi view reconstruction technique that require image recorded simultaneously by several video camera all camera are calibrated and placed around a dedicated studio to fully surround the model the limited quality and quantity of camera may produce inaccurate d model reconstruction with low quality texture to overcome this issue first we propose super resolution sr technique for d video sr on multi view image and sr on single view video frame second we propose to combine both super resolution and dynamic d shape reconstruction problem into a unique markov random field mrf energy formulation the mrf minimization is performed using graph cut thus we jointly compute the optimal solution for super resolved texture and d shape model reconstruction moreover we propose a coarse to fine strategy to iteratively produce d video with increasing quality our experiment show the accuracy and robustness of the proposed technique on challenging d video sequence 
common visual codebook generation method used in a bag of visual word model e g k mean or gaussian mixture model use the euclidean distance to cluster feature into visual code word however most popular visual descriptor are histogram of image measurement it ha been shown that the histogram intersection kernel hik is more effective than the euclidean distance in supervised learning task with histogram feature in this paper we demonstrate that hik can also be used in an unsupervised manner to significantly improve the generation of visual codebooks we propose a histogram kernel k mean algorithm which is easy to implement and run almost a fast a k mean the hik codebook ha consistently higher recognition accuracy over k mean codebooks by in addition we propose a one class svm formulation to create more effective visual code word which can achieve even higher accuracy the proposed method ha established new state of the art performance number for popular benchmark datasets on object and scene recognition in addition we show that the standard k median clustering method can be used for visual codebook generation and can act a a compromise between hik and k mean approach 
in this work we present a technique for robust estimation which by explicitly incorporating the inherent uncertainty of the estimation procedure result in a more efficient robust estimation algorithm in addition we build on recent work in randomized model verification and use this to characterize the non randomness of a solution the combination of these two strategy result in a robust estimation procedure that provides a significant speed up over existing ransac technique while requiring no prior information to guide the sampling process in particular our algorithm requires on average time fewer sample than standard ransac which is in close agreement with theoretical prediction the efficiency of the algorithm is demonstrated on a selection of geometric estimation problem 
recently dpca and it variant have attracted much attention in face recognition area in this paper some effort are made to discover the underlying fundament of these method and a novel framework called unified principal component analysis upca is proposed first we introduce a novel concept named generalized covariance matrix gcm which is naturally derived from the traditional covariance matrix cm each element of gcm is a generalized covariance of two random vector rather than two scalar variable in cm based on gcm the upca framework is proposed from which the traditional pca and it d counterpart can be deduced a special case furthermore under the upca framework we not only revisit the existing d pca method and their limitation but also propose two new method the grid sampling method gridpca and the intra group correlation reduction method extensive experimental result on the feret face database support the theoretical analysis and validate the feasibility of the proposed method 
we present an approach for unsupervised segmentation of natural and textural image based on active contour differential geometry and information theoretical concept more precisely we propose a new texture descriptor which intrinsically defines the geometry of textural region using the shape operator borrowed from differential geometry then we use the popular kullback leibler distance to define an active contour model which distinguishes the background and textural object of interest represented by the probability density function of our new texture descriptor weprovetheexistenceofa solutionto theproposedsegmentation model finally a fast and easy to implement texture segmentation algorithm is introduced to extract meaningful object we present promising synthetic and real world result and compare our algorithm to other state of the art technique 
this paper present a technique for estimating the three dimensional velocity vector field that describes the motion of each visible scene point scene flow the technique presented us two consecutive image pair from a stereo sequence the main contribution is to decouple the position and velocity estimation step and to estimate dense velocity using a variational approach we enforce the scene flow to yield consistent displacement vector in the left and right image the decoupling strategy ha two main advantage firstly we are independent in choosing a disparity estimation technique which can yield either sparse or dense correspondence and secondly we can achieve frame rate of fps on standard consumer hardware the approach provides dense velocity estimate with accurate result at distance up to meter 
current work in object categorization discriminates among object that typically posse gross difference which are readily apparent however many application require making much finer distinction we address an insect categorization problem that is so challenging that eve n trained human expert cannot readily categorize the insect s based on their image the state of the art that us visual dictionary when applied to this problem yield mediocr e result error three possible explanation for thi s are a the dictionary are unsupervised b the dictionary lose the detailed information contained in each keypoint and c these method rely on hand engineered decision about dictionary size this paper present a novel dictionary free methodology a random forest of tree is first trained to predict the class of an image based on individual keypoint descriptor a unique aspect of these tree is that they do not makedecisions but instead merely record evidence i e the number of descriptor from training example of each category that reached each leaf of the tree we provide a mathematical model showing that voting evidence is better than voting decision to categorize a new image descriptor for all detected keypoints are dropped through the tree and the evidence at each leaf is summed to obtain an overall evidence vector this is then sent to a second level classifier to make the categorization decisio n we achieve excellent performance error on the class stonefly data set also our method achieves an average auc of on the pascal voc which place it fifth out of method reported in the literature and demonstrates that the method also work well for generic object categorization 
multiple instance learning mil is a new paradigm of supervised learning that deal with the classification of bag each bag is presented a a collection of instance from which feature are extracted in mil we have usually confronted with a large instance space for even moderately sized data set since each bag may contain many instance hence it is important to design efficient instance pruning and selection technique to speed up the learning process without compromising on the performance in this paper we address the issue of instance selection in multiple instance learning and propose the is mil an instance selection framework for mil to tackle large scale mil problem is mil is based on an alternative optimisation framework by iteratively repeating the step of instance selection updating and classifier learning which is guaranteed to converge experimental result demonstrate the utility and efficiency of the proposed approach compared to the alternative 
learning to cope with domain change ha been known a a challenging problem in many real world application this paper proposes a novel and efficient approach named domain adaptive semantic diffusion dasd to exploit semantic context while considering the domain shift of context for large scale video concept annotation starting with a large set of concept detector the proposed dasd refines the initial annotation result using graph diffusion technique which preserve the consistency and smoothness of the annotation over a semantic graph different from the existing graph learning method which capture relation among data sample the semantic graph treat concept a node and the concept affinity a the weight of edge particularly the dasd approach is capable of simultaneously improving the annotation result and adapting the concept affinity to new test data the adaptation provides a mean to handle domain change between training and test data which occurs very often in video annotation task we conduct extensive experiment to improve annotation result of concept over hour of video from trecvid data set result show consistent and significant performance gain over various baseline in addition the proposed approach is very efficient completing dasd over concept within just millisecond for each video shot on a regular pc 
this paper present a complete analytical characterization of a large class of central and non central imaging device dubbed linear camera by ponce pajdla ha shown that a subset of these the oblique camera can be modelled by a certain type of linear map we give here a full tabulation of all admissible map that induce camera in the general sense of grossberg and nayar and show that these camera are exactly the linear one combining these two model with a new notion of intrinsic parameter and normalized coordinate for linear camera allows u to give simple analytical formula for direct and inverse projection we also show that the epipolar geometry of any two linear camera can be characterized by a fundamental matrix whose size is at most when the camera are uncalibrated or by an essential matrix of size at most when their internal parameter are known similar result hold for trinocular constraint 
shape database search is ubiquitous in the world of biometric system cad system etc shape data in these domain is experiencing an explosive growth and usually requires search of whole shape database to retrieve the best match with accuracy and efficiency for a variety of task in this paper we present a novel divergence measure between any two given point in formula see text or two distribution function this divergence measure the orthogonal distance between the tangent to the convex function used in the definition of the divergence at one of it input argument and it second argument this is in contrast to the ordinate distance taken in the usual definition of the bregman class of divergence we use this orthogonal distance to redefine the bregman class of divergence and develop a new theory for estimating the center of a set of vector a well a probability distribution function the new class of divergence are dubbed the total bregman divergence tbd we present the l norm based tbd center that is dubbed the t center which is then used a a cluster center of a class of shape the t center is weighted mean and this weight is small for noise and outlier we present a shape retrieval scheme using tbd and the t center for representing the class of shape from the mpeg database and compare the result with other state of the art method in literature 
we are interested in identifying the material category e g glass metal fabric plastic or wood from a single image of a surface unlike other visual recognition task in computer vision it is difficult to find good reliable feature that can tell material category apart our strategy is to use a rich set of low and mid level feature that capture various aspect of material appearance we propose an augmented latent dirichlet allocation alda model to combine these feature under a bayesian generative framework and learn an optimal combination of feature experimental result show that our system performs material recognition reasonably well on a challenging material database outperforming state of the art material texture recognition system 
recognizing human action in non instrumented video is a challenging task not only because of the variability produced by general scene factor like illumination background occlusion or intra class variability but also because of subtle behavioral pattern among interacting people or between people and object in image to improve recognition a system may need to use not only low level spatio temporal video correlation but also relational descriptor between people and object in the scene in this paper we present contextual scene descriptor and bayesian multiple kernel learning method for recognizing human action in complex non instrumented video our contribution is threefold we introduce bag of detector scene descriptor that encode presence absence and structural relation between object part we derive a novel bayesian classification method based on gaussian process with multiple kernel covariance function mkgpc in order to automatically select and weight multiple feature both low level and high level out of a large collection in a principled way and perform large scale evaluation using a variety of feature on the kth and a recently introduced challenging hollywood movie dataset on the kth dataset we obtain accuracy the best result reported to date on the hollywood dataset we obtain promising result in several action class using fewer descriptor and about improvement in a previous benchmark test 
markov random field is now ubiquitous in many formulation of various vision problem recently optimization of higher order potential became practical using higherorder graph cut the combination of i the fusion move algorithm ii the reduction of higher order binary energy minimization to first order and iii the qpbo algorithm in the fusion move it is crucial for the success and efficiency of the optimization to provide proposal that fit the energy being optimized for higher order energy it is even more so because they have richer class of null potential in this paper we focus on the efficiency of the higher order graph cut and present a simple technique for generating proposal labelings that make the algorithm much more efficient which we empirically show using example in stereo and image denoising 
functional object recognition in video is an emerging problem for visual surveillance and video understanding problem by functional object we mean object with specific purpose such a postman and delivery truck which are defined more by their action and behavior than by appearance in this work we present an approach for content based learning and recognition of the function of moving object given video derived track in particular we show that semantic behavior of mover can be captured in location independent manner by attributing them with feature which encode their relation and action w r t scene context by scene context we mean local scene region with different functionality such a doorway and parking spot which moving object often interact with based on these representation functional model are learned from example and novel instance are identified from unseen data afterwards furthermore recognition in the presence of track fragmentation due to imperfect tracking is addressed by a boosting based track linking classifier our experimental result highlight both promising and practical aspect of our approach 
relation between deterministic e g variational or pde based method and bayesian inference have been known for a long time however a classification of deterministic approach into those method which can be handled within a bayesian framework and those with no such statistical counterpart is still missing in literature after providing such taxonomy we present a bayesian framework for embedding the former one into a statistical context allowing to equip them with advantage of probabilistic estimation theory a stochastic point of view allows u to learn influence function and derivative filter adapt diffusion and regularization approach to change in the image characteristic e g varying noise level and to estimate error bound on the solution for the latter one we present alternative learning scheme also allowing their parameter to be related to the image statistic such that hand tuning becomes dispensable we demonstrate that a statistical point of view on diffusion and regularization scheme lead to image denoising performance comparable with state of the art markov random field approach while being computationally much more effective 
we present a privacy preserving system for estimating thesize of inhomogeneouscrowds composed of pedestrian that travel in different direction without using explicit object segmentation or tracking first the crowd is segmented into component of homogeneous motion using the mixture of dynamic texture motion model second a set of simple holistic feature is extracted from each segmented region and the correspondence between feature and the number of people per segment is learned with gaussian process regression we validate both the crowd segmentation algorithm and the crowd counting system on a large pedestrian dataset frame of video containing total pedestrian instance finally we present result of the system running on a full hour of video 
in this paper we present a novel probabilistic framework for automatic follicle quantification in d ultrasound data the proposed framework robustly estimate size and location of each individual ovarian follicle by fusing the information from both global and local context follicle candidate at detected location are then segmented by a novel databaseguided segmentation method to efficiently search hypothesis in a high dimensional space for multiple object detection a clustered marginal space learning approach is introduced extensive evaluation conducted on volume containing follicle showed that our method is able to detect and segment ovarian follicle with high robustness and accuracy it is also much faster than the current ultrasound manual workflow the proposed method is ableto streamline the clinical workflow and improve the accuracy of existing follicular measurement 
most state of the art nonrigid shape recovery method usually use explicit deformable mesh model to regularize surface deformation and constrain the search space these triangulated mesh model heavily relying on the quadratic regularization term are difficult to accurately capture large deformation such a severe bending in this paper we propose a novel gaussian process regression approach to the nonrigid shape recovery problem which doe not require to involve a predefined triangulated mesh model by taking advantage of our novel gaussian process regression formulation together with a robust coarse to fine optimization scheme the proposed method is fully automatic and is able to handle large deformation and outlier we conducted a set of extensive experiment for performance evaluation in various environment encouraging experimental result show that our proposed approach is both effective and robust to nonrigid shape recovery with large deformation 
many different automatic color correction approach have been proposed by different research community in the past decade however these approach are seldom compared so their relative performance and applicability are unclear for multi view image and video stitching application an ideal color correction approach should be effective at transferring the color palette of the source image to the target image and meanwhile be able to extend the transferred color from the overlapped area to the full target image without creating visual artifact in this paper we evaluate the performance of color correction approach for automatic multi view image and video stitching we consider nine color correction algorithm from the literature applied to synthetic image pair and real mosaic image pair selected from different application experimental result show that both parametric and non parametric approach have member that are effective at transferring color while parametric approach are generally better than non parametric approach in extendability 
in this paper we propose an approach to the problem of simultaneous shape and refractive index recovery from multispectral polarisation imagery captured from a single viewpoint the focus of this paper is on dielectric surface which diffusely polarise light transmitted from the dielectric body into the air the diffuse polarisation of the reflection process is modelled using a transmitted radiance sinusoid curve and the fresnel transmission theory we provide a method of estimating the azimuth angle of surface normal from the spectral variation of the phase of polarisation moreover to render the problem of simultaneous estimation of surface orientation and index of refraction well posed we enforce a generative model on the material dispersion equation for the index of refraction this generative model together with the fresnel transmission ratio permit the recovery of the index of refraction and the zenith angle simultaneously we show result on shape recovery and rendering for real world and synthetic imagery 
we consider the task of dimensionality reduction for regression drr whose goal is to find a low dimensional representation of input covariates while preserving the statistical correlation with output target ddr is particularly suited for visualization of high dimensional data a well a the efficient regressor design with a reduced input dimension in this paper we propose a novel nonlinear method for drr that exploit the kernel gram matrix of input and output while most existing ddr technique rely on the inverse regression our approach remove the need for explicit slicing of the output space using covariance operator in rkhs this unique property make drr applicable to problem domain with high dimensional output data with potentially significant amount of noise although recent kernel dimensionality reduction algorithm make use of rkhs covariance operator to quantify conditional dependency between the input and the target via the dimension reduced input they are either limited to a transduction setting or linear input subspace and restricted to non closed form solution in contrast our approach provides a closed form solution to the nonlinear basis function on which any new input point can be easily projected we demonstrate the benefit of the proposed method in a comprehensive set of evaluation on several important regression problem that arise in computer vision 
we seek to recognize the place depicted in a query image using a database of street side image annotated with geolocation information this is a challenging task due to change in scale viewpoint and lighting between the query and the image in the database one of the key problem in place recognition is the presence of object such a tree or road marking which frequently occur in the database and hence cause significant confusion between different place a the main contribution we show how to avoid feature leading to confusion of particular place by using geotags attached to database image a a form of supervision we develop a method for automatic detection of image specific and spatially localized group of confusing feature and demonstrate that suppressing them significantly improves place recognition performance while reducing the database size we show the method combine well with the state of the art bag of feature model including query expansion and demonstrate place recognition that generalizes over wide range of viewpoint and lighting condition result are shown on a geotagged database of over k image of paris downloaded from google street view 
abstract stereo correspondence research often involves the comparison of technique to determine which are better under different circumstance the method of comparison employed often take the form of applying the technique to a few stereo image pair with the technique with the lowest error rate declared superior however the majority of these comparison do not contain any discussion of statistical significance making the declared superiority of a technique statistically unreliable in this paper we present a new evaluation method called cluster ranking that yield a statistically significant comparison of the stereo technique being compared cluster ranking leverage statistical inference technique tofirst rank the performance of stereo technique on a single stereo image pair and then combine the ranking from multiple stereo pair into an over all ranking in both of these ranking only stereo technique that are statistically different are given different rank we demonstrate our framework with a comparison of constructable match cost measure those that can be assembled from a base set of component on a data set consisting of synthetic stereo pair with varying amount of noise and scene from the and middlebury data set our analysis reveals match cost measure and measure component that are statistically superior to all other measure depending on amount of noise illumination or exposure time 
range sensor for assisted backup and parking have potential for saving human life and for facilitating parking in challenging situation however important feature such a curb and ramp are difficult to detect using ultrasonic or microwave sensor tof imaging range sensor may be used successfully for this purpose in this paper we present a study concerning the use of the canesta tof camera for recognition of curb and ramp our approach is based on the detection of individual planar patch using cc ransac a modified version of the classic ransac robust regression algorithm whereas ransac us the whole set of inliers to evaluate the fitness of a candidate plane cc ransac only considers the largest connected component of inliers we provide experimental evidence that cc ransac provides a more accurate estimation of the dominant plane than ransac with a smaller number of iteration 
current us of tagged image typically exploit only the most explicit information the link between the noun named and the object present somewhere in the image we propose to leverage unspoken cue that rest within an ordered list of image tag so a to improve object localization we define three novel implicit feature from an image s tag the relative prominence of each object a signified by it order of mention the scale constraint implied by unnamed object and the loose spatial link hinted by the proximity of name on the list by learning a conditional density over the localization parameter position and scale given these cue we show how to improve both accuracy and efficiency when detecting the tagged object we validate our approach with object category from the pascal voc and labelme datasets and demonstrate it effectiveness relative to both traditional sliding window a well a a visual context baseline 
many traditional method for shape classification involve establishing point correspondence between shape to produce matching score which are in turn used a similarity measure for classification learning technique have been applied only in the second stage of this process after the matching score have been obtained in this paper instead of simply taking for granted the score obtained by matching and then learning a classifier we learn the matching score themselves so a to produce shape similarity score that minimize the classification loss the solution is based on a max margin formulation in the structured prediction setting experiment in shape database reveal that such an integrated learning algorithm substantially improves on existing method 
this paper present an algorithm for automatically detecting and segmenting a moving object from a monocular video detecting and segmenting a moving object from a video with limited object motion is challenging since existing automatic algorithm rely on motion to detect the moving object they cannot work well when the object motion is sparse and insufficient in this paper we present an unsupervised algorithm to learn object color and locality cue from the sparse motion information we first detect key frame with reliable motion cue and then estimate moving sub object based on these motion cue using a markov random field mrf framework from these sub object we learn an appearance model a a color gaussian mixture model to avoid the false classification of background pixel with similar color to the moving object the location of these sub object are propagated to neighboring frame a locality cue finally robust moving object segmentation is achieved by combining these learned color and locality cue with motion cue in a mrf framework experiment on video with a variety of object and camera motion demonstrate the effectiveness of this algorithm 
practically all existing approach to structure and motion computation use only positive image correspondence to verify the camera pose hypothesis incorrect epipolar geometry are solely detected by identifying outlier among the found correspondence ambigous pattern in the image are often incorrectly handled by these standard method in this work we propose two approach to overcome such problem first we apply non monotone reasoning on view triplet using a bayesian formulation in contrast to two view epipolar geometry image triplet allow the prediction of feature in the third image absence of these feature i e missing correspondence enables additional inference about the view triplet furthermore we integrate these view triplet handling into an incremental procedure for structure and motion computation thus our approach is able to refine the maintained d structure when additional image data is provided 
in this report we consider whether statistical regularity in natural image might be exploited to provide an improved selection criterion for interest point one approach that ha been particularly influential in this domain is the harris corner detector the impetus for the selection criterion for harris corner proposed in early work and which remains in use to this day is based on an intuitive mathematical definition constrained by the need for computational parsimony in this report we revisit this selection criterion free of the computational constraint that existed year ago and also importantly taking advantage of the regularity observed in natural image statistic based on the motivating factor of stability and richness of structure a selection threshold for harris corner is proposed that is optimal with respect to the structure observed in natural image following the protocol proposed by mikolajczyk et al we demonstrate that the proposed approach produce interest point that are more stable across various image deformation and are more distinctive resulting in improved matching score finally the proposal may be shown to generalize to provide an improved selection criterion for other type of interest point a a whole the report affords an improved selection criterion for harris corner which might foreseeably benefit any system that employ harris corner a a constituent component and additionally present a general strategy for the selection of interest point based on any measure of local image structure 
we present a novel approach for detecting global behaviour anomaly in multiple disjoint camera by learning time delayed dependency between activity cross camera view specifically we propose to model multi camera activity using a time delayed probabilistic graphical model td pgm with different node representing activity in different semantically decomposed region from different camera view and the directed link between node encoding causal relationship between the activity a novel two stage structure learning algorithm is formulated to learn globally optimised time delayed dependency a new cumulative abnormality score is also introduced to replace the conventional log likelihood score for gaining significantly more robust and reliable real time anomaly detection the effectiveness of the proposed approach is validated using a camera network installed at a busy underground station 
a common design of an object recognition system ha two step a detection step followed by a foreground within class classification step for example consider face detection by a boosted cascade of detector followed by face id recognition via one v all ovum classifier another example is human detection followed by pose recognition although the detection step can be quite fast the foreground within class classification process can be slow and becomes a bottleneck in this work we formulate a filter and refine scheme where the binary output of the weak classifier in a boosted detector are used to identify a small number of candidate foreground state hypothesis quickly via hamming distance or weighted hamming distance the approach is evaluated in three application face recognition on the frgc v data set hand shape detection and parameter estimation on a hand data set and vehicle detection and view angle estimation on a multi view vehicle data set on all data set our approach ha comparable accuracy and is at least five time faster than the brute force approach 
we present a novel structure learning method max margin and or graph mm aog for parsing the human body into part and recovering their pose our method represents the human body and it part by an and or graph which is a multi level mixture of markov random field mrfs max margin learning which is a generalization of the training algorithm for support vector machine svms is used to learn the parameter of the and or graph model discriminatively there are four advantage from this combination of and or graph and max margin learning firstly the and or graph allows u to handle enormous articulated pose with a compact graphical model secondly max margin learning ha more discriminative power than the traditional maximum likelihood approach thirdly the parameter of the and or graph model are optimized globally in particular the weight of the appearance model for individual node and the relative importance of spatial relationship between node are learnt simultaneously finally the kernel trick can be used to handle high dimensional feature and to enable complex similarity measure of shape we perform comparison experiment on the base ball datasets showing significant improvement over state of the art method 
markov random field with higher order potential have emerged a a powerful model for several problem in computer vision in order to facilitate their use we propose a new representation for higher order potential a upper and lower envelope of linear function our representation concisely model several commonly used higher order potential thereby providing a unified framework for minimizing the corresponding gibbs energy function we exploit this framework by converting lower envelope potential to standard pairwise function with the addition of a small number of auxiliary variable this allows u to minimize energy function with lower envelope potential using conventional algorithm such a bp trw and expansion furthermore weshowhow the minimization of energyfunctions with upper envelope potential lead to a difficult minmax problem we address this difficulty by proposing a new message passing algorithm that solves a linear programming relaxation of the problem although this is primarily a theoretical paper we demonstrate the efficacy of our approach on the binary fg bg segmentation problem 
pairwise constraint specify whether or not two sample should be in one cluster although it ha been successful to incorporate them into traditional clustering method such a k mean little progress ha been made in combining them with spectral clustering the major challenge in designing an effective constrained spectral clustering is a sensible combination of the scarce pairwise constraint with the original affinity matrix we propose to combine the two source of affinity by propagating the pairwise constraint information over the original affinity matrix our method ha a gaussian process interpretation and result in a closed form expression for the new affinity matrix experiment show it outperforms state of the art constrained clustering method in getting good clustering with fewer constraint and yield good image segmentation with user specified pairwise constraint 
the biometric identification approach using iris image are receiving increasing attention in the literature several method for the automated iris identification have been presented in the literature and those based on the phase encoding of texture information are suggested to be the most promising however there ha not been any attempt to combine these phase preserving approach to achieve further improvement in the performance this paper present a comparative study of the performance from the iris identification using log gabor haar wavelet dct and fft based feature our experimental result suggest that the performance from the haar wavelet and log gabor filter based phase encoding is the most promising among all the four approach considered in this work therefore the combination of these two matcher is most promising both in term of performance and the computational complexity our experimental result from the all user casia v and user iitd v database illustrate significant improvement in the performance that is not possible with either of these approach individually 
we propose a novel step toward the unsupervised segmentation of whole object by combining hint of partial scene segmentation offered by multiple soft binary matte these matte are implied by a set of hypothesized object boundary fragment in the scene rather than trying to find or define a single best segmentation we generate multiple segmentation of an image this reflects contemporary method for unsupervised object discovery from group of image and it allows u to define intuitive evaluation metric for our set of segmentation based on the accurate and parsimonious delineation of scene object our proposed approach build on recent advance in spectral clustering image matting and boundary detection it is demonstrated qualitatively and quantitatively on a dataset of scene andis suitable for current work in unsupervised object discovery without top down knowledge 
the simultaneous segmentation of multiple object is an important problem in many imaging and computer vision application various extension of level set segmentation technique to multiple object have been proposed however no one method maintains object relationship preserve topology is computationally efficient and provides an object dependent internal and external force capability in this paper a framework for segmenting multiple object that permit different force to be applied to different boundary while maintaining object topology and relationship is presented because of this framework the segmentation of multiple object each with multiple compartment is supported and no overlap or vacuum are generated the computational complexity of this approach is independent of the number of object to segment thereby permitting the simultaneous segmentation of a large number of component the property of this approach and comparison to existing method are shown using a variety of image both synthetic and real 
the analysis of pattern of movement is a crucial task for several surveillance application for instance to classify normal or abnormal people trajectory on the basis of their occurrence this paper proposes to model the shape of a single trajectory a a sequence of angle described using a mixture of von mi movm distribution a complete em expectation maximization algorithm is derived for movm parameter estimation and an on line version proposed to meet real time requirement maximum a posteriori is used to encode the trajectory a a sequence of symbol corresponding to the movm component iterative k medoids clustering group trajectory in a variable number of similarity class the similarity is computed aligning with dynamic programming two sequence and considering a symbol to symbol distance the bhattacharyya distance between von mi distribution extensive experiment have been performed on both synthetic and real data the people trajectory projected on the ground plane is a very compact representation of pattern of movement normally characterized by a sequence of d data x y coordinate in this paper we propose a d representation of trajectory based on a sequence of angle and a new statistical representation of the pattern by mean of a mixture of von mi movm distribution the description by mean of a sequence of angle exhibit several advantage first it is a more compact representation second it is invariant to spatial translation of the starting point of the trajectory third by using absolute angle and eliminating spatial reference the shape similarity can be measured locally independently by spatial shift of part of the trajectory moreover supposing a constant sample rate of point in the trajectory the sequence of angle also considers speed since when a person move fast along a given direction he will generate le point i e le angle wrt the case when he move slowly 
in this work we extend a common framework for seeded image segmentation that includes the graph cut random walker and shortest path optimization algorithm viewing an image a a weighted graph these algorithm can be expressed by mean of a common energy function with differing choice of a parameter q acting a an exponent on the difference between neighboring node introducing a new parameter p that fix a power for the edge weight allows u to also include the optimal spanning forest algorithm for watershed in this same framework we then propose a new family of segmentation algorithm that fix p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm which we term power watershed placing the watershed algorithm in this energy minimization framework also open new possibility for using unary term in traditional watershed segmentation and using watershed to optimize more general model of use in application beyond image segmentation 
because of the large variation across different environment a generic classifier trained on extensive data set may perform sub optimally in a particular test environment in this paper we present a general framework for classifier adaptation which improves an existing generic classifier in the new test environment viewing classifier learning a a cost minimization problem we perform classifier adaptation by combining the cost function on the old data set with the cost function on the data set collected from the new environment the former term is further approximated with it second order taylor expansion to reduce the amount of information that need to be saved for adaptation unlike traditional approach that are often designed for a specific application or classifier our scheme is applicable to various type of classifier and user label we demonstrate this property on two popular classifier logistic regression and boosting while using two type of user label direct label and similarity label extensive experiment conducted for the task of person detection in conference room environment show that significant performance improvement can be achieved with our proposed method 
abstract we present a discriminative hough transform based object detectorwhere each local part cast a weighted vote for the possible location of the object center we show that the weight can be learned in a max margin framework which directly optimizes the classification performance the discriminative training take into account both the codebook appearance and the spatial distribution of it position with respect to the object center to derive it importance on various datasets we show that the discriminative training improves the hough detector combined with a verification step using a svm based classifier our approach achieves a detection rate of at false positive per image on the ethz shape dataset a significant improvement over the state of the art while running the verification step on at least an order of magnitude fewer window than in a sliding window approach 
recently we proposed marginal space learning msl a a generic approach for automatic detection of d anatomical structure in many medical imaging modality to accurately localize a d object we need to estimate nine parameter three for position three for orientation and three for anisotropic scaling instead of uniformly searching the original nine dimensional parameter space only low dimensional marginal space are uniformly searched in msl which significantly improves the speed in many real application a strong correlation may exist among parameter in the same marginal space for example a large object may have large scaling value along all direction in this paper we propose constrained msl to exploit this correlation for further speed up a another major contribution we propose to use quaternion for d orientation representation and distance measurement to overcome the inherent drawback of euler angle in the original msl the proposed method ha been tested on three d anatomical structure detection problem in medical image including liver detection in computed tomography ct volume and left ventricle detection in both ct and ultrasound volume experiment on the largest datasets ever reported show that constrained msl can improve the detection speed up to time while achieving comparable or better detection accuracy it take le than half a second to detect a d anatomical structure in a volume 
computational depth estimation is a central task in computer vision and graphic a large variety of strategy have been introduced in the past relying on viewpoint variation defocus change and general aperture code however the tradeoff between such design are not well understood depth estimation from computational camera measurement is a highly non linear process and therefore most research attempt to evaluate depth estimation strategy rely on numerical simulation previous attempt to design computational camera with good depth discrimination optimized highly non linear and nonconvex score and hence it is not clear if the constructed design are optimal in this paper we address the problem of depth discrimination from j image captured using j arbitrary code placed within one fixed lens aperture we analyze the desired property of discriminative code under a geometric optic model and propose an upper bound on the best possible discrimination we show that under a multiplicative noise model the half ring code discovered by zhou et al are near optimal when a large number of image are allowed a multiaperture camera dividing the aperture into multiple annular ring provides near optimal discrimination in contrast the plenoptic camera of which divide the aperture into compact support circle can achieve at most of the optimal discrimination bound 
airborne lidar technology draw increasing interest in large scale d urban modeling in recent year d lidar data typically ha no texture information to generate photo realistic d model oblique aerial image are needed for texture mapping in which the key step is to obtain accurate registration between aerial image and untextured d lidar data we present a robust automatic registration approach a novel feature called c is proposed which is composed of connected line segment putative line segment correspondence are obtained by matching c feature detected from both aerial image and d lidar data outlier are removed with a two level ransac algorithm that integrates local and global processing to improve robustness and efficiency the approach ha been tested on aerial image that cover a variety of urban environment in oakland and atlanta area it correct pose recovery rate is over 
deblurring image of moving object captured from a traditional camera is an ill posed problem due to the loss of high spatial frequency in the captured image technique have attempted to engineer the motion point spread function psf by either making it invertible using coded exposure or invariant to motion by moving the camera in a specific fashion we address the problem of optimal single image capture strategy for best deblurring performance we formulate the problem of optimal capture a maximizing the signal to noise ratio snr of the deconvolved image given a scene light level a the exposure time increase the sensor integrates more light thereby increasing the snr of the captured signal however for moving object larger exposure time also result in more blur and hence more deconvolution noise we compare the following three single image capture strategy a traditional camera b coded exposure camera and c motion invariant photography a well a the best exposure time for capture by analyzing the rate of increase of deconvolution noise with exposure time we analyze which strategy is optimal for known unknown motion direction and speed and investigate how the performance degrades for other case we present real experimental result by simulating the above capture strategy using a high speed video camera 
the mean shift procedure is a well established clustering technique that is widely used in imaging application such a image and video segmentation denoising object tracking texture classification and others however the mean shift procedure ha relatively high time complexity which is superlinear in the number of data point in this paper we present a novel fast mean shift procedure which is based on the random sampling of the kernel density estimate kde we show theoretically that the resulting reduced kde is close to the complete data kde to within a given accuracy moreover we prove that the time complexity of the proposed fast mean shift procedure based on the reduced kde is considerably lower than that of the original mean shift the typical gain is of several order for big data set experiment show that image and video segmentation result of the proposed fast mean shift method are similar to those based on the standard mean shift procedure we also present a new application of the fast mean shift method to the efficient construction of graph hierarchy for image the resulting structure is potentially useful for solving computer vision problem which can be posed a graph problem including stereo semi automatic segmentation and optical flow 
in this paper we describe a new markov random field mrf model for natural image in multiscale oriented representation the mrf in this model is specified with the singleton conditional density the density of one subband coefficient given it markovian neighbor while the clique potential and joint density of this model are implicitly defined the singleton conditional density are chosen to have maximum entropy and consistent with observed statistical property of natural image we then describe parameter learning for this model and a sparse prior to choose optimal model structure using this model a image prior we develop an iterative image denoising method and a solution to restoring image with missing block of subband coefficient 
this paper focus on multimodal gender recognition to achieve a robust and discriminative performance for gender recognition visual observation from both face and corresponding fingerprint are fused to serve for the task the bag of word model is employed to structure the image representation we propose a novel supervised method to construct the visual word by which the redundant feature dimension are discarded and the important dimension for gender classification are highlighted the dimension rearrangement is achieved by aligning the feature dimension to a common normal vector of the hyperplane between category the latent dirichlet allocation lda model is extended to incorporate discriminative clue for supervised classification we build the novel discriminative lda d lda model by maximizing the inter class margin which can significantly enhance the discriminative power of the whole model experiment on a large face and fingerprint database demonstrate the effectiveness of the proposed new feature and model complementary advantage benefited from face fingerprint fusion to a robust gender recognition framework also get validated 
texture information in image is coupled with geometric macrostructures and piecewise smooth intensity variation decomposing an image f into a geometric structure component u and a texture component v is an inverse estimation problem essential for understanding and analyzing image dependingontheircontent inthispaper wepresentanovel combined approach for simultaneous texture from structure separation and multiband texture modeling first we formulate a new variational decomposition scheme involving an explicit texture reconstruction constraint prior formed by the response of selected frequency tuned linear filter this form a u kv image model of k component subsequent texture modeling is applied to the estimated v component and it consistency is compared to using the complete initial image f the decomposition step functioning a an advanced texture front end improves clustering and classification performance for various multiband feature the proposed method can be generalized to other texture model or application 
spatial pyramid matching spm is a simple yet effective approach to compute similarity between image similarity kernel at different region and scale are usually fused by some heuristic weight in this paper we develop a novel and fast approach to improve spm by finding the optimal kernel fusing weight from multiple scale location a well a codebooks one unique contribution of our approach is the novel formulation of kernel matrix learning problem leading to an efficient quadratic programming solution with much lower complexity than those associated with existing solution e g semidefinite programming we demonstrate performance gain of the proposed method by evaluation over well known public data set such a natural scene and trecvid 
in this paper we study some problem related to human age estimation using a large database first we study the influence of gender on age estimation based on face representation that combine biologically inspired feature with manifold learning technique second we study age estimation using smaller gender and age group rather than on all age significant error reduction are observed in both case based on these result we designed three framework for automatic age estimation that exhibit high performance unlike previous method that require manual separation of male and female prior to age estimation our work is the first to estimate age automatically on a large database furthermore a data fusion approach is proposed using one of the framework which give an age estimation error more than smaller than previous method 
in this paper we presenta l regularizedprojectionpursuit algorithm for additive model learning two new algorithm are developed for regression and classification respectively sparse projection pursuit regression and sparse jensen shannon boosting the introduced l regularized projection pursuit encourages sparse solution thus our new algorithm are robust to overfitting and present better generalization ability especially in setting with many irrelevant input feature and noisy data to make the optimization with l regularization more efficient we develop an informative feature first sequential optimization algorithm extensive experiment demonstrate the effectiveness of our proposed approach 
in this paper we propose a novel method of computing the optical flow using the fourier mellin transform fmt each image in a sequence is divided into a regular grid of patch and the optical flow is estimated by calculating the phase correlation of each pair of co sited patch using the fmt by applying the fmt in calculating the phase correlation we are able to estimate not only the pure translation a limited in the case of the basic phase correlation technique but also the scale and rotation motion of image patch i e full similarity transforms moreover the motion parameter of each patch can be estimated to subpixel accuracy based on a recently proposed algorithm that us a d esinc function in fitting the data from the phase correlation output we also improve the estimation of the optical flow by presenting a method of smoothing the field by using a vector weighted average filter finally experimental result using publicly available data set are presented demonstrating the accuracy and improvement of our method over previous optical flow method 
automatic non rigid registration of d time varying data is fundamental in many vision and graphic application such a facial expression analysis synthesis and recognition despite many research advance in recent year it still remains to be technically challenging especially for d dynamic densely sampled facial data with a large number of degree of freedom necessarily used to represent rich and subtle facial expression in this paper we present a new method for automatic non rigid registration of d dynamic facial data using least square conformal map and based on this registration method we also develop a new framework of facial expression synthesis and transfer nowadays more and more d dynamic densely sampled data become prevalent with the advancement of novel d scanning technique to analyze and utilize such huge d data an efficient non rigid registration algorithm is needed to establish one to one inter frame correspondence towards this goal a non rigid registration algorithm of d dynamic facial data is developed by using least square conformal map with additional feature correspondence detected by employing active appearance model aam the proposed method with additional interior feature constraint guarantee that the non rigid data will be accurately registered the least square conformal map between two d surface are globally optimized with the least angle distortion and the resulting d map are stable and one to one furthermore by using this non rigid registration method we develop a new system of facial expression synthesis and transfer finally we perform a series of experiment to evaluate our non rigid registration method and demonstrate it efficacy and efficiency in the application of facial expression synthesis and transfer 
we introduce a new descriptor for image which allows the construction of efficient and compact classifier with good accuracy on object category recognition the descriptor is the output of a large number of weakly trained object category classifier on the image the trained category are selected from an ontology of visual concept but the intention is not to encode an explicit decomposition of the scene rather we accept that existing object category classifier often encode not the category per se but ancillary image characteristic and that these ancillary characteristic can combine to represent visual class unrelated to the constituent category semantic meaning the advantage of this descriptor is that it allows object category query to be made against image database using efficient classifier efficient at test time such a linear support vector machine and allows these query to be for novel category even when the representation is reduced to byte per image classification accuracy on object category recognition is comparable with the state of the art versus but at order of magnitude lower computational cost 
we propose a polynomial time algorithm for segmentation and open boundary estimation which take into account a series of user specified attraction point in contrast to existing algorithm which impose that the segmenting boundary pass through these point our algorithm allows an imprecision in the user input an energy minimization approach imposes that the segmenting boundary optimally pass along high contrast edge in such a way that at least one point along the computed boundary is a close a possible to any given attraction point in this sense the user input can be seen a a soft constraint we prove that the resulting optimization problem is np hard we prove that in the case that the user attraction point are ordered then optimal solution can be computed in polynomial time using a shortest path formulation in an appropriately constructed four dimensional graph spanned by the image pixel a set of tangent angle and the user attraction point experimental result on a variety of image demonstrate that good quality segmentation can be obtained with a few imprecise user click 
a computer vision research considers more object category and greater variation within object category it is clear that larger and more exhaustive datasets are necessary however the process of collecting such datasets is laborious and monotonous we consider the setting in which many image have been automatically collected for a visual category typically by automatic internet search and we must separate relevant image from noise we present a discriminative learning process which employ active online learning to quickly classify many image with minimal user input the principle advantage of this work over previous endeavor is it scalability we demonstrate precision which is often superior to the state of the art with scalability which exceeds previous work 
for object category recognition to scale beyond a small number of class it is important that algorithm be able to learn from a small amount of labeled data per additional class one shot recognition aim to apply the knowledge gained from a set of category with plentiful data to category for which only a single exemplar is available for each a with earlier effort motivated by transfer learning we seek an internal representation for the domain that generalizes across class however in contrast to existing work we formulate the problem in a fundamentally new manner by optimizing the internal representation for the one shot task using the notion of micro set a micro set is a sample of data that contains only a single instance of each category sampled from the pool of available data which serf a a mechanism to force the learned representation to explicitly address the variability and noise inherent in the one shot recognition task we optimize our learned domain feature so that they minimize an expected loss over micro set drawn from the training set and show that these feature generalize effectively to previously unseen category we detail a discriminative approach for optimizing one shot recognition using micro set and present experiment on the animal with attribute and caltech datasets that demonstrate the benefit of our formulation 
shape registration is often involved in computing statistical difference between group of shape which is a key aspect of morphometric study the result of shape difference are found to be sensitive to registration i e different registration method lead to varied result this raise the question of how to improve the reliability of registration procedure this paper proposes a perturbation scheme which perturbs registration by feeding them with different resampled shape group and then aggregate the resulting shape difference experiment are conducted using three typical registration algorithm on both synthetic and biomedical shape where more reliable inter group shape difference are found under the proposed scheme 
we propose a convergent iterative regularization procedure based on the square of a dual norm for image restoration with general quadratic or non quadratic convex fidelity term convergent iterative regularization method have been employed for image deblurring or denoising in the presence of gaussian noise which use l and l fidelity term iusem resmerita proposed a proximal point method using inexact bregman distance for minimizing a general convex function defined on a general non reflexive banach space which is the dual of a separable banach space based on this we investigate several approach for image restoration denoising deblurring with different type of noise we test the behavior of proposed algorithm on synthetic and real image we compare the result with other state of the art iterative procedure a well a the corresponding existing one step gradient descent implementation the numerical experiment indicate that the iterative procedure yield high quality reconstruction and superior result to those obtained by one step gradient descent and similar with other iterative method 
scalable image retrieval system usually involve hierarchical quantization of local image descriptor which produce a visual vocabulary for inverted indexing of image although hierarchical quantization ha the merit of retrieval efficiency the resulting visual vocabulary representation usually face two crucial problem hierarchical quantization error and bias in the generation of visual word the model cannot adapt to database variance in this paper we describe an unsupervised optimization strategy in generating the hierarchy structure of visual vocabulary which produce a more effective and adaptive retrieval model for large scale search we adopt a novel density based metric learning dml algorithm which corrects word quantization bias without supervision in hierarchy optimization based on which we present a hierarchical rejection chain for efficient online search based on the vocabulary hierarchy we also discovered that by hierarchy optimization efficient and effective transfer of a retrieval model across different database is feasible we deployed a large scale image retrieval system using a vocabulary tree model to validate our advance experiment on ukbench and street side urban scene database demonstrated the effectiveness of our hierarchy optimization approach in comparison with state of the art method 
image retargeting algorithm often create visually disturbing distortion we introduce the property of scene consistency which is held by image which contain no object distortion and have the correct object depth ordering we present two new image retargeting algorithm that preserve scene consistency these algorithm make use of a user provided relative depth map which can be created easily using a simple grabcut style interface our algorithm generalize seam carving we decompose the image retargeting procedure into a removing image content with minimal distortion and b re arrangement of known object within the scene to maximize their visibility our algorithm optimize objective a and b jointly however they differ considerably in how they achieve this we discus this in detail and present example illustrating the rationale of preserving scene consistency in retargeting 
convex and continuous energy formulation for low level vision problem enable efficient search procedure for the corresponding globally optimal solution in this work we extend the well established continuous isotropic capacity based maximal flow framework to the anisotropic setting by using powerful result from convex analysis a very simple and efficient minimization procedure is derived further we show that many important property carry over to the new anisotropic framework e g globally optimal binary result can be achieved simply by thresholding the continuous solution in addition we unify the anisotropic continuous maximal flow approach with a recently proposed convex and continuous formulation for markov random field thereby allowing more general smoothness prior to be incorporated dense stereo result are included to illustrate the capability of the proposed approach 
image alignment in the presence of non rigid distortion is a challenging task typically this involves estimating the parameter of a dense deformation field that warp a distorted image back to it undistorted template generative approach based on parameter optimization such a lucas kanade can get trapped within local minimum on the other hand discriminative approach like nearest neighbor require a large number of training sample that grows exponentially with the desired accuracy in this work we develop a novel data driven iterative algorithm that combine the best of both generative and discriminative approach for this we introduce the notion of a pull back operation that enables u to predict the parameter of the test image using training sample that are not in it neighborhood not close in parameter space we prove that our algorithm converges to the global optimum using a significantly lower number of training sample that grows only logarithmically with the desired accuracy we analyze the behavior of our algorithm extensively using synthetic data and demonstrate successful result on experiment with complex deformation due to water and clothing 
depth map merging is one typical technique category for multi view stereo mv reconstruction to guarantee accuracy existing algorithm usually require either sub pixel level stereo matching precision or continuous depth map estimation the merging of inaccurate depth map remains a challenging problem this paper introduces a bundle optimization method for robust and accurate depth map merging in the method depth map are generated using daisy feature followed by two stage of bundle optimization the first stage optimizes the track of connected stereo match to generate initial d point the second stage optimizes the position and normal of d point high quality point cloud is then meshed a geometric model the proposed method can be easily parallelizable on multi core processor middlebury evaluation show that it is one of the most efficient method among non gpu algorithm yet still keep very high accuracy we also demonstrate the effectiveness of the proposed algorithm on various real world high resolution self calibrated data set including object with complex detail object with large area of highlight and object with non lambertian surface 
this paper present bayesian edge inference bei a single frame super resolution method explicitly grounded in bayesian inference that address issue common to existing method though the best give excellent result at modest magnification factor they suffer from gradient stepping and boundary coherence problem by factor of x central to bei is a causal framework that allows image capture and recapture to be modeled differently a principled way of undoing downsampling blur and a technique for incorporating markov random field potential arbitrarily into bayesian network besides addressing gradient and boundary issue bei is shown to be competitive with existing method on published correctness measure the model and framework are shown to generalize to other reconstruction task by demonstrating bei s effectiveness at ccd demosaicing and inpainting with only trivial change 
while global method for matching shape to image have recently been proposed so far research ha focused on small deformation of a fixed template in this paper we present the first global method able to pixel accurately match non rigidly deformable shape across image at amenable run time by finding cycle of optimal ratio in a four dimensional graph spanned by the image the prior shape and a set of rotation angle we simultaneously compute a segmentation of the image plane a matching of point on the template to point on the segmenting boundary and a decomposition of the template into a set of deformable part in particular the interpretation of the shape template a a collection of an a priori unknown number of deformable part an important aspect of higher level shape representation emerges a a byproduct of our matching algorithm on real world data of running people and walking animal we demonstrate that the proposed method can match strongly deformed shape even in case where simple shape measure and optic flow method fail 
abstract parameterized appearance model pams e g eigentracking active appearance model morphable model are commonly used to model the appearance and shape variation of object in image while pams have numerous advantage relative to alternate approach they have at least two drawback first they are especially prone to local minimum in the fitting process second often few if any of the local minimum of the cost function correspond to acceptable solution to solve these problem this paper proposes a method to learn a cost function by explicitly optimizing that the local minimum occur at and only at the place corresponding to the correct fitting parameter to the best of our knowledge this is the first paper to address the problem of learning a cost function to explicitly model local property of the error surface to fit pams synthetic and real example show improvement in alignment performance in comparison with traditional approach 
this paper present an integrated framework for mobile street level tracking of multiple person in contrast to classic tracking by detection approach our framework employ an efficient level set tracker in order to follow individual pedestrian over time this low level tracker is initialized and periodically updated by a pedestrian detector and is kept robust through a series of consistency check in order to cope with drift and to bridge occlusion the resulting tracklet output are fed to a high level multi hypothesis tracker which performs longer term data association this design ha the advantage of simplifying short term data association resulting in higher quality track that can be maintained even in situation where the pedestrian detector doe no longer yield good detection in addition it requires the pedestrian detector to be active only part of the time resulting in computational saving we quantitatively evaluate our approach on several challenging sequence and show that it achieves state of the art performance 
robustness to illumination variation is a key requirement for the problem of change detection which in turn is a fundamental building block for many visual surveillance application the use of ordinalmeasures is a powerful way of filtering out illumination dependency in representing appearance andseveral such measureshavebeen proposedin thepast forchangedetection bydesign these measuresare invariant to unknown monotonic transformation that may be caused due to global illumination change or automatic camera gain however previous work ha left theoretical and practical gap that limit their full potential from being realized for instance random noise ha not been given a principledtreatment in this paper we formulatethe change detection problem in term of order consistency and show that in the presence of noise with known statistical property significance test for order consistency yield much better result than the state of the art since ordinal measure require a reordering of patch they are usually expensive in practice o n log n at best we improve upon this by connecting the problem to monotonic regression and applying a fast algorithm from the corresponding literature we also show that good trade offs between speed and accuracy can be made by quantization to achieve accurate and very fast matching algorithm in practice we demonstrate superior performance on statistical simulation a well a real image sequence 
this paper present a method for recognizing human action based on pose primitive in learning mode the parameter representing pose and activity are estimated from video in run mode the method can be used both for video or still image for recognizing pose primitive we extend a histogram of oriented gradient hog based descriptor to better cope with articulated pose and cluttered background action class are represented by histogram of pose primitive for sequence we incorporate the local temporal context by mean of n gram expression action recognition is based on a simple histogram comparison unlike the mainstream video surveillance approach the proposed method doe not rely on background subtraction or dynamic feature and thus allows for action recognition in still image 
with increasing technical advance computer graphic are becoming more photorealistic therefore it is importa nt to develop method for distinguishing between actual photograph from digital camera and computer generated image we describe a novel approach to this problem rather than focusing on the statistical difference between the im age texture we recognize that image from digital camera contain trace of resampling a a result of using a color filter array with demosaicing algorithm we recognize that estimation of the actual demosaicing parameter is not necessary rather detection of the presence of demosaicing is the key the in camera processing rather than the image content distinguishes the digital camera photograph fro m computer graphic our result show high reliability on a standard test set of jpeg compressed image from consumer digital camera further we show the application of these idea for accurately localizing forged region withi n digital camera image 
this paper present a simple yet effective method of building a codebook for pair of spatially close sift descriptor integrating such codebook into the popular bag of word model encodes local spatial information which otherwise cannot be represented with just individual sift descriptor many previous pairing technique first quantize the descriptor to learn a set of visual word before they are actually paired our approach contrast with theirs in that each pair of spatially close descriptor is represented a a data point in a joint feature space first and then clustering is applied to build a codebook called local pairwise codebook lpc it is advantageous over the previous approach in that feature selection over quadratic number of possible pair of visual word is not required and feature aggregation is implicitly performed to achieve a compact codebook this is all done in an unsupervised manner experimental result on challenging datasets namely scene indoors caltech caltech and msrcv demonstrate that lpc outperforms the baseline and performs competitively against the state of the art technique in scene and object categorization task where a large number of category need to be recognized 
this paper proposes a general framework called markov stationary feature msf to extend histogram based feature the msf characterizes the spatial co occurrence of histogram pattern by markov chain model and finally yield a compact feature representation through markov stationary analysis therefore the msf go one step beyond histogram since it now involves spatial structure information of both within histogram bin and between histogram bin moreover it still keep simplicity compactness efficiency and robustness we demonstrate how the msf is used to extend histogram based feature like color histogram edge histogram local binary pattern histogram and histogram of oriented gradient we evaluate the msf extended histogram feature on the task of trecvid video concept detection result show that the proposed msf extension can achieve significant performance improvement over corresponding histogram feature 
in many social setting image of group of people are captured the structure of this group provides meaningful context for reasoning about individual in the group and about the structure of the scene a a whole for example men are more likely to stand on the edge of an image than woman instead of treating each face independently from all others we introduce contextual feature that encapsulate the group structure locally for each person in the group and globally the overall structure of the group this social context allows u to accomplish a variety of task such a such a demographic recognition calculatin g scene and camera parameter and even event recognition we perform human study to show this context aid recognition of demographic information in image of stranger 
can we discover common object shape within unlabeled multi category collection of image while often a critical cue at the category level contour match can be difficult to isolate reliably from edge clutter even within labeled image from a known class let alone unlabeled example we propose a shape discovery method in which local appearance patch match serve to anchor the surrounding edge fragment yielding a more reliable affinity function for image that account for both shape and appearance spectral clustering from the initial affinity provides candidate object cluster then we compute the within cluster match pattern to discern foreground edge from clutter attributing higher weight to edge more likely to belong to a common object in addition to discovering the object contour in each image we show how to summarize what is found with prototypical shape our result on benchmark datasets demonstrate the approach can successfully discover shape from unlabeled image 
given a multi exposure sequence of a scene our aim is to recover the absolute irradiance falling onto a linear camera sensor the established approach is to perform a weighted average of the scaled input exposure however there is no clear consensus on the appropriate weighting to use we propose a weighting function that produce statistically optimal estimate under the assumption of compoundgaussian noise our weighting is based on a calibrated camera model that account for all noise source this model also allows u to simultaneously estimate the irradiance and it uncertainty we evaluate our method on simulated and real world photograph and show that we consistently improve the signal to noise ratio over previous approach finally we show the effectiveness of our model for optimal exposure sequence selection and hdr image denoising 
a key ingredient in the design of visual object classification system is the identification of relevant class specific aspect while being robust to intra class variation while this is a necessity in order to generalize beyond a given set of training image it is also a very difficult problem due to the high variability of visual appearance within each class in the last year substantial performance gain on challenging benchmark datasets have been reported in the literature this progress can be attributed to two development the design of highly discriminative and robust image feature and the combination of multiple complementary feature based on different aspect such a shape color or texture in this paper we study several model that aim at learning the correct weighting of different feature from training data these include multiple kernel learning a well a simple baseline method furthermore we derive ensemble method inspired by boosting which are easily extendable to several multiclass setting all method are thoroughly evaluated on object classification datasets using a multitude of feature descriptor the key result are that even very simple baseline method that are order of magnitude faster than learning technique are highly competitive with multiple kernel learning furthermore the boosting type method are found to produce consistently better result in all experiment we provide insight of when combination method can be expected to work and how the benefit of complementary feature can be exploited most efficiently 
in this paper we considerably improve on a state of theart alpha matting approach by incorporating a new prior which is based on the image formation process in particular we model the prior probability of an alpha matte a the convolution of a high resolution binary segmentation with the spatially varying point spread function psf of the camera our main contribution is a new and efficient deconvolution approach that recovers the prior model given an approximate alpha matte by assuming that the psf is a kernel with a single peak we are able to recover the binary segmentation with an mrf based approach which exploit flux and a new way of enforcing connectivity the spatially varying psf is obtained via a partitioning of the image into region of similar defocus incorporating our new prior model into a state of the art matting technique produce result that outperform all competitor which we confirm using a publicly available benchmark 
in this paper we propose a method for extracting image feature which utilizes nd order statistic i e spatial and orientational auto correlation of local gradient it enables u to extract richer information from image and to obtain more discriminative power than standard histogram based method the image gradient are sparsely described in term of magnitude and orientation in addition normal vector on the image surface are derived from the gradient and these could also be utilized instead of the gradient from a geometrical viewpoint the method extract information about not only the gradient but also the curvature of the image surface experimental result for pedestrian detection and image patch matching demonstrate the effectiveness of the proposed method compared with other method such a hog and sift 
d active appearance model aam and d morphable model dmm are widely used technique aam provide a fast fitting process but may represent unwanted d transformation unless strictly constrained not to do so the reverse is true for dmm the two approach also require of a pre alignment of their d or d shape before the modeling can be carried out which may lead to error furthermore current model are insufficient to represent nonlinear shape and texture variation in this paper we derive a new approach that can model nonlinear change in example without the need of a pre alignment step in addition we show how the proposed approach carry the above mentioned advantage of aam and dmm to achieve this goal we take advantage of the inherent property of complex spherical distribution which provide invariance to translation scale and rotation to reduce the complexity of parameter estimation we take advantage of a recent result that show how to estimate spherical distribution using their euclidean counterpart e g the gaussians this lead to the definition of rotation invariant kernel rik for modeling nonlinear shape change we show the superiority of our algorithm to aam in several face datasets we also show how the derived algorithm can be used to model complex d facial expression change observed in american sign language asl 
we present a wide baseline image matching approach based on line segment line segment are clustered into local group according to spatial proximity each group is treated a a feature called a line signature similar to local feature line signature are robust to occlusion image clutter and viewpoint change the descriptor and similarity measure of line signature are presented under our framework the feature matching is not only robust against affine distortion but also a considerable range of d viewpoint change for non planar surface when compared to matching approach based on existing local feature our method show improved result with low texture scene moreover extensive experiment validate that our method ha advantage in matching structured non planar scene under large viewpoint change and illumination variation 
in this paper we present a robust face alignment system that is capable of dealing with exaggerating expression large occlusion and a wide variety of image noise the robustness come from our shape regularization model which incorporates constrained nonlinear shape prior geometric transformation and likelihood of multiple candidate landmark in a three layered generative model the inference algorithm iteratively examines the best candidate position and update face shape and pose this model can effectively recover sufficient shape detail from very noisy observation we demonstrate the performance of this approach on two public domain database and a large collection of real world face photograph 
image parsing remains difficult due to the need to combine local and contextual information when labeling a scene we approach this problem by using the epitome a a prior over label configuration several property make it suited to this task first it allows a condensed patch based representation second efficient e m based learning and inference algorithm can be used third non stationarity is easily incorporated we consider three existing prior and show how each can be extended using the epitome the simplest prior assumes patch of label are drawn independently from either a mixture model or an epitome next we investigate a conditional epitome model which substitute an epitome for a conditional mixture model finally we develop an epitome tree model which combine the epitome with a tree structured belief network prior each model is combined with a per pixel classifier to perform segmentation in each case the epitomized form of the prior provides superior segmentation performance with the epitome tree performing best overall we also apply the same model to denoising binary image with similar result 
local bundle adjustment lba ha recently been introduced to estimate the geometry of image sequence taken by a calibrated camera it advantage over standard global bundle adjustment is a great reduction of computational complexity which allows real time performance with a similar accuracy however no confidence measure on the lba result such a uncertainty or covariance ha yet been introduced this paper introduces statistical model and e stimation method for uncertainty with two desirable property uncertainty propagation along the sequence and real time calculation we also explain why this problem is more complicated than it may appear at first glance and we provide result on video sequence 
two tone mooney image seem to arouse vivid d percept of face both familiar and unfamiliar despite their seemingly poor content recent psychological and fmri study suggest that this percept is guided primarily by topdown procedure in which recognition precedes reconstruction in this paper we investigate this hypothesis from a mathematical standpoint we show that indeed under standard shape from shading assumption a mooney image can give rise to multiple different d reconstruction even if reconstruction is restricted to the mooney transition curve the boundary curve between black and white alone we then use top down reconstruction method to recover the shape of novel face from single mooney image exploiting prior knowledge of the structure of at least one face of a different individual we apply these method to thresholded image of real face and compare the reconstruction quality relative to reconstruction from gray level image 
in this paper we propose a new method that infers accurate depth map and color consistent image between radiometrically varying stereo image simultaneously in general stereo matching and performing color consistency between stereo image are a chicken and egg problem color consistency enhances the performance of stereo matching while accurate correspondence from stereo disparity improve color consistency between stereo image we devise a new iterative framework in which these two process can boost each other for robust stereo matching we utilize the mutual information based method combined with the sift descriptor from which we can estimate the joint pdf in log chromaticity color space from this joint pdf we can estimate a linear relationship between the corresponding pixel in stereo image using this linear relationship and the estimated depth map we devise a stereo color histogram equalization method to make color consistent stereo image which conversely boost the disparity map estimation experimental result show that our method produce both accurate depth map and color consistent stereo image even for stereo image with severe radiometric difference 
appearance feature are good at discriminating activity in a fixed view but behave poorly when aspect is changed we describe a method to build feature that are highly stable under change of aspect it is not necessary to have multiple view to extract our feature our feature make it possible to learn a discriminative model of activity in one view and spot that activity in another view for which one might pose no labeled example at all our construction us labeled example to build activity model and unlabeled but corresponding example to build an implicit model of how appearance change with aspect we demonstrate our method with challenging sequence of real human motion where discriminative method built on appearance alone fail badly 
we study the task of detecting the occurrence of object in large image collection or in video a problem that combine aspect of content based image retrieval and object localization while most previous approach are either limited to special kind of query or do not scale to large image set we propose a new method efficient subimage retrieval esr which is at the same time very flexible and very efficient relying on a two layered branch and bound setup esr performs object based image retrieval in set of or more image within second an extensive evaluation on several datasets show that esr is not only very fast but it also achieves detection accuracy that are on par with or superior to previously published method for object based image retrieval 
we propose a global optimisation approach to multi target tracking the method extends recent work which cast tracking a an integer linear program by discretising the space of target location our main contribution is to show how dynamic model can be integrated in such an approach the dynamic model which encodes prior expectation about object motion ha been an important component of tracking system for a long time but ha recently been dropped to achieve globally optimisable objective function we re introduce it by formulating the optimisation problem such that deviation from the prior can be measured independently for each variable furthermore we propose to sample the location space on a hexagonal lattice to achieve smoother more accurate trajectory in spite of the discrete setting finally we argue that non maximum suppression in the measured evidence should be performed during tracking when the temporal context and the motion prior are available rather than a a preprocessing step on a per frame basis experiment on five different recent benchmark sequence demonstrate the validity of our approach 
over the past decade multiple instance learning mil ha been successfully utilized to model the localized content based image retrieval cbir problem in which a bag corresponds to an image and an instance corresponds to a region in the image however existing feature representation scheme are not effective enough to describe the bag in mil which hinders the adaptation of sophisticated single instance learning sil method for mil problem in this paper we first propose an evidence region or evidence instance identification method to identify the evidence region supporting the label of the image i e bag then based on the identified evidence region a very effective feature representation scheme which is also very computationally efficient and robust to labeling noise is proposed to describe the bag a a result the mil problem is converted into a standard sil problem and a support vector machine svm can be easily adapted for localized cbir experimental result on two challenging data set show that our method called ec svm can outperform the state of the art method in term of accuracy robustness and efficiency 
we introduce spatial pact principal component analysis of census transform histogram a new representation for recognizing instance and category of place or scene both place instance recognition i am in room and category recognition i am in an office have been widely researched feature that have different discriminative power invariance tradeoff have been used separately for the two task pact capture local structure of an image through the census transform ct while largescale structure are captured by the strong correlation between neighboring ct value and the histogram the pca operation ignores noise in the histogram distribution computes important primitive shape and result in a compact representation spatial pact a spatial pyramid of pact further incorporates global structure in the image our experiment demonstrate that spatial pact outperforms the current state of the art in several place and scene recognition and shape matching datasets besides spatial pact is easy to implement it ha nearly no parameter to tune and evaluates extremely fast 
this paper revisits the classical problem of detecting interest point popularly known a corner in d image by proposing a technique based on fitting algebraic shape model to contour in the edge image our method for corner detection is targeted for use on structural image i e image that contain man made structure for which corner detection algorithm are known to perform well further our detector seek to find image region that contain two distinct linear contour that intersect we define the intersection point a the corner and in contrast to previous approach such a the harris detector we consider the spatial coherence of the edge point i e the fact that the edge point must lie close to one of the two intersecting line an important aspect to stable corner detection comparison between result for the proposed method and that for several popular feature detector are provided using input image exhibiting a number of standard image variation including blurring affine transformation scaling rotation and illumination variation a modified version of the repeatability rate is proposed for evaluating the stability of the detector under these variation which requires a to mapping between matched feature using this performance metric our method is found to perform well in contrast to several current method for corner detection discussion is provided that motivates our method of evaluation and provides an explanation for the observed performance of our algorithm in contrast to other algorithm our approach is distinct from other contour based method since we need only compute the edge image from which we explicitly solve for the unknown linear contour and their intersection that provide image corner location estimate the key benefit to this approach are performance in space and time since no image pyramid space and no edge linking time is required and compactness the estimated model includes the corner location and direction of the incoming contour in space i e a complete model of the local corner geometry 
in the last decade several cost aggregation method aimed at improving the robustness of stereo correspondence within local and global algorithm have been proposed given the recent development and the lack of an appropriate comparison in this paper we survey classify and compare experimentally on a standard data set the main cost aggregationapproachesproposed in literature the experimental evaluation address both accuracy and computational requirement so a to outline the best performing method under these two criterion 
many interactive image segmentation approach use an objective function which includes appearance model a an unknown variable since the resulting optimization problem is np hard the segmentation and appearance are typically optimized separately in an em style fashion one contribution of this paper is to express the objective function purely in term of the unknown segmentation using higher order clique this formulation reveals an interesting bias of the model towards balanced segmentation furthermore it enables u to develop a new dual decomposition optimization procedure which provides additionally a lower bound hence we are able to improve on existing optimizers and verify that for a considerable number of real world example we even achieve global optimality this is important since we are able for the first time to analyze the deficiency of the model another contribution is to establish a property of a particular dual decomposition approach which involves convex function depending on foreground area a a consequence we show that the optimal decomposition for our problem can be computed efficiently via a parametric maxflow algorithm 
current approach to pose estimation and tracking can be classified into two category generative and discriminative while generative approach can accurately determine human pose from image observation they are computationally expensive due to search in the high dimensional human pose space on the other hand discriminative approach do not generalize well but are computationally efficient we present a hybrid model that combine the strength of the two in an integrated learning and inference framework we extend the gaussian process latent variable model gplvm to include an embedding from observation space the space of image feature to the latent space gplvm is a generative model but the inclusion of this mapping provides a discriminative component making the model observation driven observation driven gplvm od gplvm not only provides a faster inference approach but also more accurate estimate compared to gplvm in case where dynamic are not sufficient for the initialization of search in the latent space we also extend od gplvm to learn and estimate pose from parameterized action gesture parameterized gesture are action which exhibit large systematic variation in joint angle space for different instance due to difference in contextual variable for example the joint angle in a forehand tennis shot are function of the height of the ball figure we learn these systematic variation a a function of the contextual variable we then present an approach to use information from scene object to provide context for human pose estimation for such parameterized action 
in this paper a novel feature named adaptive contour feature acf is proposed for human detection and segmentation this feature consists of a chain of a number of granule in oriented granular space ogs that is learnt via the adaboost algorithm three operation are defined on the ogs to mine object contour feature and feature cooccurrences automatically a heuristic learning algorithm is proposed to generate an acf that at the same time define a weak classifier for human detection or segmentation experiment on two open datasets show that the acf outperform several well known existing feature due to it stronger discriminative power rooted in the nature of it flexibility and adaptability to describe an object contour element 
latent variable model lvm like the shared gplvm and the spectral latent variable model help mitigate overfitting when learning discriminative method from small or moderately sized training set nevertheless existing method suffer from several problem complexity the lack of explicit mapping to and from the latent space an inability to cope with multi modality and the lack of a well defined density over the latent space we propose a lvm called the shared kernel information embedding skie it defines a coherent density over a latent space and multiple input output space e g image feature and pose and it is easy to condition on a latent state or on combination of the input output state learning is quadratic and it work well on small datasets with datasets too large to learn a coherent global model one can use skie to learn local online model skie permit missing data during inference and partially labelled data during learning we use skie for human pose inference 
the goal of this work is to find all people in archive film challenge include low image quality motion blur partial occlusion non standard pose and crowded scene we base our approach on face detection and take a tracking temporal approach to detection our tracker operates in two mode following face detection whenever possible switching to low level tracking if face detection fails with temporal correspondence established by tracking we formulate detection a an inference problem in onedimensional chain track we use a conditional random field model to integrate information across frame and to re score tentative detection in track quantitative evaluation on full length film show that the crf based temporal detector greatly improves face detection increasing precision for about suppressing isolated false positive and at the same time boosting recall for over recovering difficult case where face detector fail 
a generic imaging model refers to a non parametric camera model where every camera is treated a a set of unconstrained projection ray calibration would simply be a method to map the projection ray to image pixel such a mapping can be computed using plane based calibration grid however existing algorithm for generic calibration use more point correspondence than the theoretical minimum it ha been well established that non minimal solution for calibration and structure from motion algorithm are generally noise prone compared to minimal solution in this work we derive minimal solution for generic calibration algorithm our algorithm for generally central camera use point correspondence in three calibration grid to compute the motion between the grid using simulation we show that our minimal solution are more robust to noise compared to non minimal solution we also show very accurate distortion correction result on fisheye image 
abstract in this paper we present a non rigid quasi dense matching method and it application to object recognition and segmentation the matching method is based on the match propagation algorithm which is here extended by using local image gradient for adapting the propagation to smooth non rigid deformation of the imaged surface the adaptation is based entirely on the local property of the image and the method can be hence used in non rigid image registration where global geometric constraint are not available our approach for object recognition and segmentation is directly built on the quasi dense matching the quasi dense pixel match between the model and test image are grouped into geometrically consistent group using a method which utilizes the local afne transformation estimate obtained during the propagation the number and quality of geometrically consistent match is used a a recognition criterion and the location of the matching pixel directly provides the segmentation the experiment demonstrate that our approach is able to deal with extensive background clutter partial occlusion large scale and viewpoint change and notable geometric deformation 
second order prior on the smoothness of d surface are a better model of typical scene than first order prior however stereo reconstruction using global inference algorithm such a graph cut ha not been able to incorporate second order prior because the triple clique needed to express them yield intractable nonsubmodular optimization problem this paper show that inference with triple clique can be effectively performed our optimization strategy is a development of recent extension to alpha expansion based on the qpbo algorithm the strategy is to repeatedly merge proposal depth map using a novel extension of qpbo proposal depth map can come from any source for example frontoparallel plane a in alpha expansion or indeed any existing stereo algorithm with arbitrary parameter setting 
stereo matching and volumetric reconstruction are the most explored d scene recovery technique in computer vision many existing approach assume perspective input image and use the epipolar constraint to reduce the search space and improve the accuracy in this paper we present a novel framework that us multi perspective camera for stereo matching and volumetric reconstruction our approach first decomposes a multi perspective camera into piecewise primitive general linear camera or glcs a pair of glcs in general do not satisfy the epipolar constraint however they still form a nearly stereo pair we develop a new graph cut based algorithm to account for the slight vertical parallax using the glc ray geometry we show that the recovered pseudo disparity map conveys important depth cue analogous to perspective stereo matching to more accurately reconstruct a d scene we develop a new multi perspective volumetric reconstruction method we discretize the scene into voxels and apply the glc back projection to map the voxel onto each input multi perspective camera finally we apply the graph cut algorithm to optimize the d embedded voxel graph we demonstrate our algorithm on both synthetic and real multi perspective camera experimental result show that our method are robust and reliable 
image analysis method play an important role in helping detect brain change in and diagnosis of alzheimer s disease ad in this paper we propose an automatic unsupervised classification approach to distinguish brain magnetic resonance mr image of ad patient from those of elderly normal control the symmetric log domain diffeomorphic demon algorithm with the property of symmetry and invertibility is used to compute the pair wise registration whose deformation field is then used to calculate the riemannian distance between them the spectral embedding algorithm is performed based on the riemannian distance matrix to project image onto a low dimensional space where each image is represented a a point and it neighboring point correspond to image of high anatomical similarity finally the quick shift clustering method is employed in the embedded space to partition the dataset into subgroup the experiment using the proposed method show very good performance for clustering image into ad and normal aging using the clinical dementia rating cdr scale a a comparison 
geometric verification with ransac ha become a crucial step for many local feature based matching application therefore the detail of it implementation are directly relevant for an application s run time and the quality of the estimated result in this paper we propose a ransac extension that is several order of magnitude faster than standard ransac and a fast a and more robust to degenerate configuration than prosac the currently fastest ransac extension from the literature in addition our proposed method is simple to implement and doe not require parameter tuning it main component is a spatial consistency check that result in a reduced correspondence set with a significantly increased inlier ratio leading to faster convergence of the remaining estimation step in addition we experimentally demonstrate that ransac can operate entirely on the reduced set not only for sampling but also for it consensus step leading to additional speed ups the resulting approach is widely applicable and can be readily combined with other extension from the literature we quantitatively evaluate our approach s robustness on a variety of challenging datasets and compare it performance to the state of the art 
histogram represent a popular mean for feature representation this paper is concerned with the problem of exhaustive histogram based image search several standard histogram construction method are explored including the conventional approach huang s method and the state of the art integral histogram in addition we present a novel multiscale histogram based search algorithm termed the distributive histogram that can be evaluated exhaustively in a fast and memory efficient manner an extensive systematic empirical evaluation is presented that explores the computational and storage consequence of altering the search image and histogram bin size experiment reveal up to an eight fold decrease in computation time and hundredsto thousandsfold decrease of memory use of the proposed distributive histogram in comparison to the integral histogram finally we conclude with a discussion on the relative merit between the various approach considered in the paper 
with this paper we offer a game theoretic perspective for the all pervasive matching problem in computer vision specifically we formulate the matching problem a a population non cooperative game where the potential association between the item to be matched correspond to pure strategy while payoff reflect the degree of compatibility between competing hypothesis within this formulation the solution of the matching problem correspond to evolutionary stable state es s a robust population based generalization of the notion of a nash equilibrium in order to find es s of our matching game we propose using a novel fast evolutionary game dynamic motivated by darwinian selection process which let the pure strategy play against each other until an equilibrium is reached a distinguishing feature of the proposed framework is that it allows one to naturally deal with general many to many matching problem even in the presence of asymmetric compatibility the potential of the proposed approach is demonstrated via two set of image matching experiment both of which show that our result outperform those obtained using well known domain specific algorithm 
the success of kernel method including support vector network svms strongly depends on the design of appropriate kernel while initially kernel were designed in order to handle fixed length data their extension to unordered variable length data became more than necessary for real pattern recognition problem such a object recognition and bioinformatics we focus in this paper on object recognition using a new type of kernel referred to a context dependent object seen a constellation of local feature interest point region etc are matched by minimizing an energy function mixing a fidelity term which measure the quality of feature matching a neighborhood criterion which capture the object geometry and a regularization term we will show that the fixed point of this energy is a context dependent kernel cdk which also satisfies the mercer condition experiment conducted on object recognition show that when plugging our kernel in svms we clearly outperform svms with context free kernel noyaux contexte pour l appariement et la reconnaissance d objets 
this paper address the limitation of current multilinear technique multilinear pca multilinear ica when applied to face recognition for handling face in unseen illumination and viewpoint we propose a new recognition method exploiting the interaction of all the subspace resulting from multilineardecomposition for both multilinear pca and ica to produce a new basis called multilineareigenmodes this basis offer the flexibility to handle face image at unseen illumination or viewpoint experiment on benchmarked datasets yield superior performance in term of both accuracy and computational cost 
most method for object class segmentation are formulated a a labelling problem over a single choice of quantisation of an image space pixel segment or group of segment it is well known that each quantisation ha it fair share of pro and con and the existence of a common optimal quantisation level suitable for all object category is highly unlikely motivated by this observation we propose a hierarchical random field model that allows integration of feature computed at different level of the quantisation hierarchy map inference in this model can be performed efficiently using powerful graph cut based move making algorithm our framework generalises much of the previous work based on pixel or segment we evaluate it efficiency on some of the most challenging data set for object class segmentation and show it obtains state of the art result 
we address an unsupervised object detection and segmentation problem that go beyond the conventional assumption of one to one object correspondence or model test setting between image our method can detect and segment identical object directly from a single image or a handful of image without any supervision to detect and segment all the object level correspondence from the given image a novel multi layer match growing method is proposed that start from initial local feature match and explores the image by intra layer expansion and inter layer merge it estimate geometric relation between object entity and establishes object correspondence network that connect matching object experiment demonstrate robust performance of our method on challenging datasets 
human action recognition is a challenging problem due to the large change of human appearance in the case of partial occlusion non rigid deformation and high irregularity it is difficult to collect a large set of training sample with the hope of covering all possible variation of an action in this paper we propose an online recognition method namely incremental discriminant analysis of canonical correlation idcc whose discriminative model is incrementally updated to capture the change of human appearance and thereby facilitates the recognition task in changing environment a the training set are acquired sequentially instead of being given completely in advance our method is able to compute a new discriminant matrix by updating the existing one using the eigenspace merging algorithm experimental result on both weizmann and kth action data set show that our method performs better than state of the art method on both accuracy and efficiency moreover the robustness of our method is demonstrated on the irregular action recognition 
many vision problem have been formulated a energy minimization problem and there have been significant advance in energy minimization algorithm the most widely used energy minimization algorithm include graph cut belief propagation and tree reweighted message passing although they have obtained good result they are still unsatisfactory when it come to more difficult mrf problem such a non submodular energy function highly connected mrfs and high order clique potential there have also been other approach known a stochastic sampling based algorithm which include simulated annealing markov chain monte carlo and populationbased markov chain monte carlo they are applicable to any general energy model but they are usually slower than deterministic method in this paper we propose new algorithm which elegantly combine stochastic and deterministic method sampling based method are boosted by deterministic method so that they can rapidly move to lower energy state and easily jump over energy barrier in different point of view the sampling based method prevents deterministic method from getting stuck at local minimum consequently a combination of both approach substantially increase the quality of the solution we present a thorough analysis of the proposed method in synthetic mrf problem by controlling the hardness of the problem we also demonstrate experimental result for the photomontage problem which is the most difficult one among the standard mrf benchmark problem 
we explore the use of cloud a a form of structured lighting to capture the d structure of outdoor scene observed over time from a static camera we derive two cue that relate d distance to change in pixel intensity due to cloud shadow the first cue is primarily spatial work with low frame rate time lapse and support estimating focal length and scene structure up to a scale ambiguity the second cue depends on cloud motion and ha a more complex but still linear ambiguity we describe a method that us the spatial cue to estimate a depth map and a method that combine both cue result on time lapse of several outdoor scene show that these cue enable estimating scene geometry and camera focal length 
detection and tracking of moving vehicle in airborne video is a challenging problem many approach have been proposed to improve motion segmentation on frame by frame and pixel by pixel base however little attention ha been paid to analyze the long term motion pattern which is a distinctive property for moving vehicle in airborne video in this paper we provide a straightforward geometric interpretation of a general motion pattern in d space x y vx vy we propose to use the tensor voting computational framework to detect and segment such motion pattern in d space specifically in airborne video we analyze the essential difference in motion pattern caused by parallax and independent moving object which lead to a practical method for segmenting motion pattern flow created by moving vehicle in stabilized airborne video the flow are used in turn to facilitate detection and tracking of each individual object in the flow conceptually this approach is similar to track before detect technique which involves temporal information in the process a early a possible a shown in the experiment many difficult case in airborne video such a parallax noisy background modeling and long term occlusion can be addressed by our approach 
all surface can be classified by the conformal equivalence relation conformal invariant which are shape index that can be defined intrinsically on a surface may be used to identify which surface are conformally equivalent and they can also be used to measure surface deformation here we propose to compute a conformal invariant or shape index that is associated with the perimeter of the inner concentric circle in the hyperbolic parameter plane with the surface ricci flow method we can conformally map a multiply connected domain to a multi hole disk and this conformal map can preserve the value of the conformal invariant our algorithm provides a stable method to map the value of this shape index in the d hyperbolic space parameter domain we also applied this new shape index for analyzing abnormality in brain morphology in alzheimer s disease ad and williams syndrome w after cutting along various landmark curve on surface model of the cerebral cortex or hippocampus we obtainedmultiple connected domain we conformally projected the surface to hyperbolic plane with surface ricci flow method accurately computed the proposed conformal invariant for each selected landmark curve and assembled these into a feature vector we also detected group difference in brain structure based on multivariate analysis of the surface deformation tensor induced by these ricci flow mapping experimental result with d mri data from subject demonstrate that our method powerfully detects brain surface abnormality when combined with a constrained harmonic map based surface registration method 
detecting image pair with a common field of view is an important prerequisite for many computer vision task typically common local feature are used a a criterion for identifying such image pair this approach however requires a reliable method for matching feature which is generally a very di cult problem especially in situation with a wide baseline or ambiguity in the scene we propose two new approach for the common field of view problem the first one is still based on feature matching instead of requiring a very low false positive rate for the feature matching however geometric constraint are used to ass match which may contain many false positive the second approach completely avoids hard matching of feature by evaluating the entropy of correspondence probability we perform quantitative experiment on three di erent hand labeled scene with varying di culty in moderately di cult situation with a medium baseline and few ambiguity in the scene our proposed method give similarly good result to the classical matching based method on the most challenging scene having a wide baseline and many ambiguity the performance of the classical method deteriorates while ours are much le a ected and still produce good result hence our method show the best overall performance in a combined evaluation 
we consider the group motion segmentation problem and provide a solution for it the group motion segmentation problem aim at analyzing motion trajectory of multiple object in video and finding among them the one involved in a group motion pattern this problem is motivated by and serf a the basis for the multi object activity recognition problem which is currently an active research topic in event analysis and activity recognition specifically we learn a spatio temporal driving force model to characterize a group motion pattern and design an approach for segmenting the group motion we illustrate the approach using video of american football play where we identify the offensive player who follow an offensive motion pattern from motion of all player in the field experiment using gatech football play dataset validate the effectiveness of the segmentation algorithm 
this paper proposes a metric learning based approach for human activity recognition with two main objective reject unfamiliar activity and learn with few example we show that our approach outperforms all state of the art method on numerous standard datasets for traditional action classification problem furthermore we demonstrate that our method not only can accurately label activity but also can reject unseen activity and can learn from few example with high accuracy we finally show that our approach work well on noisy youtube video 
shape representation and retrieval of stored shape model are becoming increasingly more prominent in field such a medical imaging molecular biology and remote sensing we present a novel framework that directly address the necessity for a rich and compressible shape representation while simultaneously providing an accurate method to index stored shape the core idea is to represent point set shape a the square root of probability density expanded in a wavelet basis we then use this representation to develop a natural similarity metric that respect the geometry of these probability distribution i e under the wavelet expansion density are point on a unit hypersphere and the distance between density is given by the separating arc length the process us a linear assignment solver for non rigid alignment between density prior to matching this ha the connotation of sliding wavelet coefficient akin to the sliding block puzzle l ne rouge we illustrate the utility of this framework by matching shape from the mpeg data set and provide comparison to other similarity measure such a euclidean distance shape distribution 
concept based multimedia search ha become more and more popular in multimedia information retrieval mir however which semantic concept should be used for data collection and model construction is still an open question currently there is very little research found on automatically choosing multimedia concept with small semantic gap in this paper we propose a novel framework to develop a lexicon of high level concept with small semantic gap lcss from a large scale web image dataset by defining a confidence map and content context similarity matrix image with small semantic gap are selected and clustered the final concept lexicon is mined from the surrounding description title category and comment of these image this lexicon offer a set of high level concept with small semantic gap which is very helpful for people to focus for data collection annotation and modeling it also show a promising application potential for image annotation refinement and rejection the experimental result demonstrate the validity of the developed concept lexicon 
in structure from motion with a single camera it is well known that the scene can be only recovered up to a scale in order to compute the absolute scale one need to know the baseline of the camera motion or the dimension of at least one element in the scene in this paper we show that there exists a class of structure from motion problem where it is possible to compute the absolute scale completely automatically without using this knowledge that is when the camera is mounted on wheeled vehicle e g car bike or mobile robot the construction of these vehicle put interesting constraint on the camera motion which are known a nonholonomic constraint the interesting case is when the camera ha an offset to the vehicle s center of motion we show that by just knowing this offset the absolute scale can be computed with a good accuracy when the vehicle turn we give a mathematical derivation and provide experimental result on both simulated and real data over a large image dataset collected during a km path to our knowledge this is the first time nonholonomic constraint of wheeled vehicle are used to estimate the absolute scale we believe that the proposed method can be useful in those research area involving visual odometry and mapping with vehicle mounted camera 
in this paper we present a kernel based approach to the clustering of diffusion tensor and fiber tract we propose to use a mercer kernel over the tensor space where both spatial and diffusion information are taken into account this kernel highlight implicitly the connectivity along fiber tract tensor segmentation is performed using kernel pca compounded with a landmark isomap embedding and k mean clustering based on a soft fiber representation we extend the tensor kernel to deal with fiber tract using the multi instance kernel that reflects not only interaction between point along fiber tract but also the interaction between diffusion tensor this unsupervised method is further extended by way of an atlas based registration of diffusion free image followed by a classification of fiber based on nonlinear kernel support vector machine svms promising experimental result of tensor and fiber classification of the human skeletal muscle over a significant set of healthy and diseased subject demonstrate the potential of our approach 
in this paper we introduce a novel approach to single view reconstruction using shape grammar our approach consists in modeling architectural style using a set of basic shape and a set of parametric rule corresponding to increasing level of detail this approach is able to model elaborate and varying architectural style using a tree representation of variable depth and complexity towards reconstruction the parameter of the rule are optimized using image based and architectural cost this is done through an efficient mrf formulation based on the shape grammar itself the resulting framework can produce precise d model from single view can deal with lack of texture and the presence of occlusion and specular reflection while maintaining the ability to cope with very complex architectural style promising result demonstr ate the potential of our approach 
this paper proposes a novel approach to nonrigid markerless motion capture from synchronized video stream acquired by calibrated camera the instantaneous geometry of the observed scene is represented by a polyhedral mesh with fixed topology the initial mesh is constructedin thefirst frameusingthe publiclyavailablepmvs software for multi view stereo it deformation is captured by tracking it vertex over time using two optimization process at each frame a local one using a rigid motion model in the neighborhoodof each vertex and a global one using a regularized nonrigid model for the whole mesh qualitative and quantitative experiment using seven real datasets show that our algorithm effectively handle complex nonrigid motion and severe occlusion 
we introduce an equi affine invariant diffusion geometry by which surface that go through squeeze and shear transformation can still be properly analyzed the definition of an affine invariant metric enables u to construct an invariant laplacian from which local and global geometric structure are extracted application of the proposed framework demonstrate it power in generalizing and enriching the existing set of tool for shape analysis 
most research on image decomposition e g image segmentation and image parsing ha predominantly focused on the low level visual clue within single image and neglected the contextual information across different image in this paper we present a new perspective to image decomposition piloted by the multi label associated with individual image observing that the context information i e local label representation of the same label are similar while those from different label are dissimilar exists across different image we propose to perform image decomposition in a collective way and then the image decomposition problem is formulated a an optimization which maximizes inter label difference and at the same time minimizes intra label difference of the target label representation such contextual image decomposition ha a wide variety of application among which the two exemplary one are multi label image annotation in which the sparse coding of a query image over the base consisting of all learned label representation naturally produce the multi label annotation and label ranking in which the annotated label are re ordered according to the sparse coding coefficient on those learned label representation it is worth noting that these two application can be performed simultaneously via the label propagation process in sparse coding 
we propose a novel approach to increase the robustness of object detection algorithm in surveillance scenario the cascaded confidence filter successively incorporates constraint on the size of the object on the preponderance of the background and on the smoothness of trajectory in fact the continuous detection confidence score are analyzed locally to adapt the generic detector to the specific scene the approach doe not learn specific object model reason about complete trajectory or scene structure nor use multiple camera therefore it can serve a preprocessing step to robustify many tracking by detection algorithm our real world experiment show significant improvement especially in the case of partial occlusion changing background and similar distractors 
this paper address the problem of automatic temporal annotation of realistic human action in video using minimal manual supervision to this end we consider two associated problem a weakly supervised learning of action model from readily available annotation and b temporal localization of human action in test video to avoid the prohibitive cost of manual annotation for training we use movie script a a mean of weak supervision script however provide only implicit noisy and imprecise information about the type and location of action in video we address this problem with a kernel based discriminative clustering algorithm that locates action in the weakly labeled training data using the obtained action sample we train temporal action detector and apply them to locate action in the raw video data our experiment demonstrate that the proposed method for weakly supervised learning of action model lead to significant improvement in action detection we present detection result for three action class in four feature length movie with challenging and realistic video data 
face verification ha many potential application including filtering and ranking image video search result on celebrity since these image video are taken under uncontrolled environment the problem is very challenging due to dramatic lighting and pose variation low resolution compression artifact etc in addition the available number of training image for each celebrity may be limited hence learning individual classifier for each person may cause overfitting in this paper we propose two idea to meet the above challenge first we propose to use individual bin instead of whole histogram of local binary pattern lbp a feature for learning which yield significant performance improvement and computation reduction in our experiment second we present a novel multi task learning mtl framework called boosted mtl for face verification with limited training data it jointly learns classifier for multiple people by sharing a few boosting classifier in order to avoid overfitting the effectiveness of boosted mtl and lbp bin feature is verified with a large number of celebrity image video from the web 
restoration of a degraded image from motion blurring is highly dependent on the estimation of the blurring kernel most of the existing motion deblurring technique model the blurring kernel with a shift invariant box filter which hold true only if the motion among image is of uniform velocity in this paper we present a spectral analysis of image gradient which lead to a better configuration for identifying the blurring kernel of more general motion type uniform velocity motion accelerated motion and vibration furthermore we introduce a hybrid fourier radon transform to estimate the parameter of the blurring kernel with improved robustness to noise over available technique the experiment on both simulated image and real image show that our algorithm is capable of accurately identifying the blurring kernel for a wider range of motion type 
matching articulated shape represented by voxel set reduces to maximal sub graph isomorphism when each set is described by a weighted graph spectral graph theory can be used to map these graph onto lower dimensional space and match shape by aligning their embeddings in virtue of their invariance to change of pose classical graph isomorphism scheme relying on the ordering of the eigenvalue to align the eigenspaces fail when handling large data set or noisy data we derive a new formulation that find the best alignment between two congruent k dimensional set of point by selecting the best subset of eigenfunctions of the laplacian matrix the selection is done by matching eigenfunction signature built with histogram and the retained set provides a smart initialization for the alignment problem with a considerable impact on the overall performance dense shape matching casted into graph matching reduces then to point registration of embeddings under orthogonal transformation the registration is solved using the framework of unsupervised clustering and the em algorithm maximal subset matching of non identical shape is handled by defining an appropriate outlier class experimental result on challenging example show how the algorithm naturally treat change of topology shape variation and different sampling density 
poor visibility condition due to murky water bad weather dust and smoke severely impede the performance of vision system passive method have been used to restore scene contrast under moderate visibility by digital postprocessing however these method are ineffective when the quality of acquired image is poor to begin with in this work we design active lighting and sensing system for controlling light transport before image formation and hence obtain higher quality data first we present a technique of polarized light striping based on combining polarization imaging and structured light striping we show that this technique out performs different existing illumination and sensing methodology second we present a numerical approach for computing the optimal relative sensor source position which result in the best quality image our analysis account for the limit imposed by sensor noise 
we consider two scenario of naming people in database of news photo with caption i finding face of a single person and ii assigning name to all face we combine an initial text based step that restricts the name assigned to a face to the set of name appearing in the caption with a second step that analyzes visual feature of face by searching for group of highly similar face that can be associated with a name the result of purely text based search can be greatly ameliorated we improve a recent graph based approach in which node correspond to face and edge connect highly similar face we introduce constraint when optimizing the objective function and propose improvement in the low level method used to construct the graph furthermore we generalize the graph based approach to face naming in the full data set in this multi person naming case the optimization quickly becomes computationally demanding and we present an important speed up using graph flow to compute the optimal name assignment in document generative model have previously been proposed to solve the multi person naming task we compare the generative and graph based method in both scenario and find significantly better performance using the graph based method in both case 
in this paper we present a framework for estimating what portion of video are most discriminative for the task of action recognition we explore the impact of the temporal cropping of training video on the overall accuracy of an action recognition system and we formalize what make a set of croppings optimal in addition we present an algorithm to determine the best set of croppings for a dataset and experimentally show that our approach increase the accuracy of various state of the art action recognition technique 
we present an algorithm for detecting human action based upon a single given video example of such action the proposed method is unsupervised doe not require learning segmentation or motion estimation the novel feature employed in our method are based on space time locally adaptive regression kernel our method is based on the dense computation of so called space time local regression kernel i e local descriptor from a query video which measure the likeness of a voxel to it spatio temporal surroundings salient feature are then extracted from these descriptor using principal component analysis pca these are efficiently compared against analogous feature from the target video using a matrix generalization of the cosine similarity measure the algorithm yield a scalar resemblance volume each voxel indicating the like lihood of similarity between the query video and all cube in the target video by employing non parametric significance test and non maximum suppression we accurately detect the presence and location of action similar to the given query video high performance is demonstrated on a challenging set of action data indicating successful detection of multiple complex action even in the presence of fast motion 
we present a feature matching algorithm that leverage bottom up segmentation unlike conventional image to image or region to region matching algorithm our method find corresponding point in an asymmetric manner matching feature within each region of a segmented image to a second unsegmented image we develop a dynamic programming solution to efficiently identify corresponding point for each region so a to maximize both geometric consistency and appearance similarity the final matching score between two image is determined by the union of corresponding point obtained from each region to image match our encoding for the geometric constraint make the algorithm flexible when matching object exhibiting non rigid deformation or intra class appearance variation we demonstrate our image matching approach applied to object category recognition and show on the caltech and datasets that it outperforms existing image matching measure by in nearest neighbor recognition test 
automatic categorization of video in a web scale unconstrained collection such a youtube is a challenging task a key issue is how to build an effective training set in the presence of missing sparse or noisy label we propose to achieve this by first manually creating a small labeled set and then extending it using additional source such a related video searched video and text based webpage the data from such disparate source ha different property and labeling quality and thus fusing them in a coherent fashion is another practical challenge we propose a fusion framework in which each data source is first combined with the manually labeled set independently then using the hierarchical taxonomy of the category a conditional random field crf based fusion strategy is designed based on the final fused classifier category label are predicted for the new video extensive experiment on about k video from most frequent category in youtube show the effectiveness of the proposed method for categorizing large scale wild web video 
this paper proposes a method to recover the embedding of the possible shape assumed by a deforming nonrigid object by comparing triplet of frame from an orthographic video sequence we assume that we are given feature tracked with no occlusion and no outlier but possible noise an orthographic camera and that any d shape of a deforming object is a linear combination of several canonical shape by exploiting any repetition in the object motion and defining an ordering between triplet of frame in a generalized non metric multi dimensional scaling framework our approach recovers the shape coefficient of the linear combination independently from other structure and motion parameter from this point a good estimate of the remaining unknown is obtained for a final optimization to perform full non rigid structure from motion result are presented on synthetic and real image sequence and our method is found to perform better than current state of the art 
the explosive growth of the vision data motivates the recent study on efficient data indexing method such a locality sensitive hashing lsh most existing approach perform hashing in an unsupervised way in this paper we move one step forward and propose a supervised hashing method i e the label regularized max margin partition lamp algorithm the proposed method generates hash function in weakly supervised setting where a small portion of sample pair are manually labeled to be similar or dissimilar we formulate the task a a constrained convex concave procedure cccp which can be relaxed into a series of convex sub problem solvable with efficient quadratic program qp the proposed hashing method posse other characteristic including most existing lsh approach rely on linear feature representation unfortunately kernel trick are often more natural to gauge the similarity between visual object in vision research which corresponds to probably infinite dimensional hilbert space the proposed lamp ha a natural support for kernel based feature representation traditional hashing method assume uniform data distribution typically the collision probability of two sample in hash bucket is only determined by pairwise similarity unrelated to contextual data distribution in contrast we provide such a collision bound which is beyond pairwise data interaction based on markov random field theory extensive empirical evaluation are conducted on five widely used benchmark it take only several second to generate a new hashing function and the adopted random supporting vector scheme enables the lamp algorithm scalable to large scale problem experimental result well validate the superiority of the lamp algorithm over the state of the art kernel based hashing method 
we present a novel multi view stereo method designed for image based rendering that generates piecewise planar depth map from an unordered collection of photograph first a discrete set of d plane candidate are computed based on a sparse point cloud of the scene recovered by structure from motion and sparse d line segment reconstructed from multiple view next evidence is accumulated for each plane using d point and line incidence and photo consistency cue finally a piecewise planar depth map is recovered for each image by solving a multi label markov random field mrf optimization problem using graph cut our novel energy minimization formulation exploit high level scene information it incorporates geometric constraint derived from vanishing direction enforces free space violation constraint based on ray visibility of d point and d line and imposes smoothness prior specific to plane that intersect we demonstrate the effectiveness of our approach on a wide variety of outdoor and indoor datasets the view interpolation result are perceptually pleasing a straight line are preserved and hole are minimized even for challenging scene with non lambertian and textureless surface 
object detection in cluttered natural scene ha a high complexity since many local observation compete for object hypothesis voting method provide an efficient solution to this problem when hough voting is extended to location and scale vote naturally become line through scale space due to the local scale location ambiguity in contrast to this current voting method stick to the location only setting and cast point vote which require local estimate of scale rather than searching for object hypothesis in the hough accumulator we propose a weighted pairwise clustering of voting line to obtain globally consistent hypothesis directly in essence we propose a hierarchical approach that is based on a sparse representation of object boundary shape clustering of voting line cvl condenses the information from these edge point in few globally consistent candidate hypothesis a final verification stage concludes by refining the candidate experiment on the ethz shape dataset show that clustering voting line significantly improves state of the art hough voting technique 
in this paper we propose a framework for gradient descent image alignment in the fourier domain specifically we propose an extension to the classical lucas kanade lk algorithm where we represent the source and template image s intensity pixel in the complex d fourier domain rather than in the d spatial domain we refer to this approach a the fourier lk flk algorithm the flk formulation is especially advantageous over traditional lk when it come to pre processing the source and template image with a bank of filter e g gabor filter a i it can handle substantial illumination variation ii the inef ficient pre processing filter bank step can be subsumed within the flk algorithm a a sparse diagonal weighting matrix iii unlike traditional lk the computational cost is invar iant to the number of filter and a a result far more efficient iv this approach can be extended to the inverse compositional form of the lk algorithm where nearly all step including fourier transform and filter bank pre processing can be pre computed leading to an extremely efficient and robust approach to gradient descent image matching we demonstrate robust image matching performance on a variety of object in the presence of substantial illuminatio n difference with exactly the same computational overhead a that of traditional inverse compositional lk during fitting 
the objective of this paper is to parse object trajectory in surveillance video against occlusion interruption and background clutter we present a spatio temporal graph st graph representation and a cluster sampling algorithm via deferred inference an object trajectory in the st graph is represented by a bundle of motion primitive each of which consists of a small number of matched feature interesting patch generated by adaptive feature pursuit and a tracking process each motion primitive is a graph vertex and ha six bond connecting to neighboring vertex based on the st graph we jointly solve three task spatial segmentation temporal correspondence and object recognition by flipping the label of the motion primitive we also adapt the scene geometric and statistical information a strong prior then the inference computation is formulated in a markov chain and solved by an efficient cluster sampling we apply the proposed approach to various challenging video from a number of public datasets and show it outperform other state of the art method 
automatic coronary artery centerline extraction from d ct angiography cta ha significant clinical importance for diagnosis of atherosclerotic heart disease the focus of past literature is dominated by segmenting the complete coronary artery system a tree by computer though the labeling of different vessel branch defined by their medical semantics is much needed clinically this task ha been performed manually in this paper we propose a hierarchical machine learning approach to tackle the problem of tubular structure parsing in medical imaging it ha a progressive three tiered classification process at volumetric voxel level vessel segment level and inter segment level generative model are employed to project from low level ambiguous data to class conditional probability and discriminative classifier are trained on the upper level structural pattern of probability to label and parse the vessel segment our method is validated by experiment of detecting and segmenting clinically defined coronary artery from the initial noisy vessel segment network generated by low level heuristic based tracing algorithm the proposed framework is also generically applicable to other tubular structure parsing task 
the aim of color constancy is to remove the effect of the color of the light source a color constancy is inherently an ill posed problem most of the existing color constancy algorithm are based on specific imaging assumption such a the grey world and white patch assumption in this paper d geometry model are used to determine which color constancy method to use for the different geometrical region found in image to this end image are first classified into stage rough d geometry model according to the stage model image are divided into different region using hard and soft segmentation after that the best color constancy algorithm is selected for each geometry segment a a result light source estimation is tuned to the global scene geometry our algorithm open the possibility to estimate the remote scene illumination color by distinguishing nearby light source from distant illuminant experiment on large scale image datasets show that the proposed algorithm outperforms state of the art single color constancy algorithm with an improvement of almost of median angular error when using an ideal classifier i e all of the test image are correctly classified into stage the performance of the proposed method achieves an improvement of of median angular error compared to the best performing single color constancy algorithm 
we propose a person dependent manifold based approach for modeling and tracking rigid and nonrigid d facial deformation from a monocular video sequence the rigid and nonrigid motion are analyzed simultaneously in d by automatically fitting and tracking a set of landmark we do not represent all nonrigid facial deformation a a simple complex manifold but instead decompose them on a basis of eight d manifold each d manifold is learned offline from sequence of labeled expression such a smile surprise etc any expression is then a linear combination of value along these ax with coefficient representing the level of activation we experimentally verify that expression can indeed be represented this way and that individual manifold are indeed d the manifold dimensionality estimation manifold learning and manifold traversal operation are all implemented in the n d tensor voting framework using simple local operation this framework give an estimate of the tangent and normal space at every sample and provides excellent robustness to noise and outlier the output of our system besides the tracked landmark in d is a labeled annotation of the expression we demonstrate result on a number of challenging sequence 
this paper study automatic segmentation of multiple motion from tracked feature point through spectral embedding and clustering of linear subspace we show that the dimension of the ambient space is crucial for separability and that low dimension chosen in prior work are not optimal we suggest lower and upper bound together with a data driven procedure for choosing the optimal ambient dimension application of our approach to the hopkins video benchmark database uniformly outperforms a range of state of the art method both in term of segmentation accuracy and computational speed 
rigid registration of intraoperative ultrasound u and ct is an important technique to provide real time guidance for preoperative image and model due to the speckle noise and artefact in u image accurate registration of ct and u is still a challenging problem we propose an adaptive region intensity based ct and u registration method the registration is initialized by matching the distinctive region of ct and u image then the registration is a multistage process in which the region in u used will be adaptively updated at each stage the registration problem is considered a a global similarity energy optimization and high local statistical dependency region selection process performance of our method and other intensity based method are evaluated with simulated and real datasets experiment result show the improvement of our registration method in robustness and accuracy 
motion blur confound many computer vision problem the fluttered shutter f camera tackle the motion deblurring problem by emulating invertible broadband blur kernel however existing f method assume known constant velocity motion e g via user specification in this paper we extend the f technique to general d motion and develop an automatic motion from blur framework by analyzing the image statistic under the f we first introduce a fluttered shutter point spread function f psf to uniformly model the blur kernel under general motion we show that many commonly used motion have closed form f psf to recover the f psf from the blurred image we present a new method by analyzing image power spectrum statistic we show that the modulation transfer function of the d f psf is statistically correlated to the blurred image power spectrum along the motion direction we then recover the f psf by finding the motion parameter that maximize the correlation we demonstrate our technique on a variety of motion including constant velocity constant acceleration and harmonic rotation experimental result show that our method can automatically and accurately recover the motion from the blur captured under the fluttered shutter 
we present a model based system for tracking rotating fluid and apply it to a laboratory study of atmospheric circulation tracking is accomplished by filtering uncertain and high dimensionalstates of a nonlineargeneral circulation model with optical measurement of the physical fluid s velocity realtime performance is achieved by using a nonuniform discretization of the model s spatial resolution and by using time snapshot of model state to construct spatially localized reduced rank square root representation of forecast uncertainty realtime performance economical and repeatable experimentation and a direct connection to planetary flow implies that the proposed physical numerical coupling can be useful for addressing many perceptual geophysical fluid dynamic problem to the best of our knowledge such a system ha not hitherto been reported 
we present a method for decomposing an image into it intrinsic reflectance and shading component different from previous work our method examines texture information to obtain constraint on reflectance among pixel that may be distant from one another in the image we observe that distinct point with the same intensity normalized texture configuration generally have the same reflectance value the separation of shading and reflectance component should thus be performed in a manner that guarantee these non local constraint we formulate intrinsic image decomposition by adding these non local texture constraint to the local derivative analysis employed in conventional technique our result show a significant improvement in performance with better recovery of global reflectance and shading structure than by previous method 
we propose a new method for sampling camera response function temporally mixing two uncalibrated irradiances within a single camera exposure calibration method rely on some known relationship between irradiance at the camera image plane and measured pixel intensity prior approach use a color checker chart with known reflectance registered image with different exposure ratio or even the irradiance distribution along edge in image we show that temporally blending irradiances allows u to densely sample the camera response function with known relative irradiances our first method computes the camera response curve using temporal mixture of two pixel intensity on an uncalibrated computer display the second approach make use of temporal irradiance mixture caused by motion blur both method require only one input image although more image can be used for improved robustness to noise or to cover more of the response curve we show that our method compute accurate response function for a variety of camera 
in this paper we investigate shape and motion retrieval in the context of multi camera system we propose a new lowlevel analysis based on latent silhouette cue particularly suited for low texture and outdoor datasets our analysis doe not rely on explicit surface representation instead using an em framework to simultaneously update a set of volumetric voxel occupancy probability and retrieve a best estimate of the dense d motion field from the last consecutively observed multi view frame set a the framework us only latent probabilistic silhouette information the method yield a promising d scene analysis method robust to many source of noise and arbitrary scene object it can be used a input for higher level shape modeling and structural inference task we validate the approach and demonstrate it practical use for shape and motion analysis experimentally 
estimating the color of a scene illuminant often play a central role in computational color constancy while this problem ha received signicant attention the method that exist do not maximally leverage spatial dependency between pixel indeed most method treat the observed color or it spatial derivative at each pixel independently of it neighbor we propose an alternative approach to illuminant estimation one that employ an explicit statistical model to capture the spatial dependency between pixel induced by the surface they observe the parameter of this model are estimated from a training set of natural image captured under canonical illumination and for a new image an appropriate transform is found such that the corrected image best t our model 
this paper proposes a new object representation called connected segmentation tree cst which capture canonical characteristic of the object in term of the photometric geometric and spatial adjacency and containment property of it constituent image region cst is obtained by augmenting the object s segmentation tree st with inter region neighbor link in addition to their recu rsive embedding structure already present in st this make cst a hierarchy of region adjacency graph a region s neighbor are computed using an extension to region of the voronoi diagram for point pattern unsupervised learning of the cst model of a category is formulated a matching the cst graph representation of unlabeled training image and fusing their maximally matching subgraphs a new learning algorithm is proposed that optimizes the model structure by simultaneously searching for both the most salient node region and the most salient edge containment and neighbor relationship of region acros s the image graph matching of the category model to the cst of a new image result in simultaneous detection segmentation and recognition of all occurrence of the category and a semantic explanation of these result 
clustering performance can often be greatly improved by leveraging side information in this paper we consider constrained clustering with pairwise constraint which specify some pair of object from the same cluster or not the main idea is to design a kernel to respect both the proximity structure of the data and the given pairwise constraint we propose a spectral kernel learning framework and formulate it a a convex quadratic program which can be optimally solved efficiently our framework enjoys several desirable feature it is applicable to multi class problem it can handle both must link and cannot link constraint it can propagate pairwise constraint effectively it is scalable to large scale problem and it can handle weighted pairwise constraint extensive experiment have demonstrated the superiority of the proposed approach 
this paper proposes a novel method called microdeformation analysis to analyze and describe local image structure this method is a general analytic tool and can be applied to any high dimensional scalar or vector function we derive the tensor matrix from this method a the descriptor to represent the information within local image patch our experimental result suggest that we can design low dimensional local tensor descriptor with performance comparable to the popular sift descriptor which is the state of the artfeature descriptor used for object recognition and categorization 
computer system are increasingly being used for sport training existing sport training system either require expensive d motion capture system or do not provide intelligent analysis of user s sport motion this paper present a framework for affordable and intelligent sport training system for general user that require only single camera to record the user s motion sport motion analysis is formulated a a d d spatiotemporal motion registration problem a novel algorithm is developed to perform spatiotemporal registration of the expert s d reference motion and a performer s d input video thereby computing the deviation of the performer s motion from the expert s motion the algorithm can effectively handle ambiguous situation in a single video such a depth ambiguity of body part and partial occlusion test result show that despite using only single video the algorithm can compute d posture error that reflect the performer s actual motion error 
abstract interactive segmentation is often performed on image that have been stored on disk e g a medical image server for some time prior to user interaction we propose to use this time to perform an offline precomputation of the segmentation prior to user interaction that significantly decrease the amount of user time necessary to produce a segmentation knowing how to effectively precompute the segmentation prior to user interaction is difficult since a user may choose to guide the segmentation algorithm to segment any object or multiple object in the image consequently precomputation performed prior to user interaction must be performed without any knowledge of the user interaction specifically we show that one may precompute several eigenvectors of the weighted laplacian matrix of a graph and use this information to produce a linear time approximation of the random walker segmentation algorithm even without knowing where the foreground background seed will be placed finally we also show that this procedure may be interpreted a a seeded interactive normalized cut algorithm 
the observation model in tracking algorithm are critical to both tracking performance and applicable scenario but are often simplified to focus on fixed level of certain target property such a appearance and structure in this paper we propose a unified tracking paradigm in which target are represented by markov random field of interest region and introduce a new way to adapt observation model by automatically tuning the feature granularity and model elasticity i e the abstraction level of feature and the modelpsilas degree of flexibility to tolerate deformation specifically we employ a multi scale scheme to extract feature from interest region and adjust the parameter of the potential function of the mrf model to maximize the likelihood of tracking result experiment demonstrate the method can estimate translation scaling and rotation and deal with deformation partial occlusion and camouflage object within this unified framework 
object detection remains an important but challenging task in computer vision we present a method that combine high accuracy with high efficiency we adopt simplified form of apcf feature which we term joint ranking of granule jrog feature the feature consists of discrete value by uniting binary ranking result of pair wise granule in the image we propose a novel collaborative learning method for jrog feature which consists of a simulated annealing sa module and an incremental feature selection module the two complementary module collaborate to efficiently search the formidably large jrog feature space for discriminative feature which are fed into a boosted cascade for object detection to cope with occlusion in crowded environment we employ the strategy of part based detection a in but propose a new dynamic search method to improve the bayesian combination of the part detection result experiment on several challenging data set show that our approach achieves not only considerable improvement in detection accuracy but also major improvement in computational efficiency on a xeon ghz computer with only a single thread it can process a million scanning window per second sufficing for many practical real time detection task 
we present a new method for classification with structured latent variable our model is formulated using the max margin formalism in the discriminative learning literature we propose an efficient learning algorithm based on the cutting plane method and decomposed dual optimization we apply our model to the problem of recognizing human action from video sequence where we model a human action a a global root template and a constellation of several part we show that our model outperforms another similar method that us hidden conditional random field and is comparable to other state of the art approach more importantly our proposed work is quite general and can potentially be applied in a wide variety of vision problem that involve various complex interdependent latent structure 
linear discriminant analysis lda might be the most widely used linear feature extraction method in pattern recognition based on the analysis on the several limitation of traditional lda this paper make an effort to propose a new computational paradigm named optimal discriminatory projection pursuit odpp which is totally different from the traditional lda and it variant only two simple step are involved in the proposed odpp one is the construction of candidate projection set the other is the optimal discriminatory projection pursuit for the former step candidate projection are generated a the difference vector between nearest between class boundary sample with redundancy well controlled while the latter is efficiently achieved by classifiability based adaboost learning from the large candidate projection set we show that the new projection pursuit paradigm not only doe not suffer from the limitation of the traditional lda but also inherits good generalizability from the boundary attribute of candidate projection extensive experimental comparison with lda and it variant on synthetic and real data set show that the proposed method consistently ha better performance 
we present a new algorithm for a robust family of earth mover s distance emds with thresholded ground distance the algorithm transforms the flow network of the emd so that the number of edge is reduced by an order of magnitude a a result we compute the emd by an order of magnitude faster than the original algorithm which make it possible to compute the emd on large histogram and database in addition we show that emds with thresholded ground distance have many desirable property first they correspond to the way human perceive distance second they are robust to outlier noise and quantization effect third they are metric finally experime ntal result on image retrieval show that thresholding the groun d distance of the emd improves both accuracy and speed 
we discus the cause of a severe optical flow estimation problem that fine motion structure cannot always be correctly reconstructed in the commonly employed multiscale variational framework our major finding is that significant and abrupt displacement transition wreck smallscale motion structure in the coarse to fine refinement a novel optical flow estimation method is proposed in this paper to address this issue which reduces the reliance of the flow estimate on their initial value propagated from the coarser level and enables recovering many motion detail in each scale the contribution of this paper also includes adaption of the objective function and development of a new optimization procedure the effectiveness of our method is borne out by experiment for both largeand small displacement optical flow estimation 
learning visual classifier for object recognition from weakly labeled data requires determining correspondence between image region and semantic object class most approach use co occurrence of noun and image feature over large datasets to determine the correspondence but many correspondence ambiguity remain we further constrain the correspondence problem by exploiting additional language construct to improve the learning process from weakly labeled data we consider both preposition and comparative adjective which are used to express relationship between object if the model of such relationship can be determined they help resolve correspondence ambiguity however learning model of these relationship requires solving the correspondence problem we simultaneously learn the visual feature defining noun and the differential visual feature defining such binary relationship using an em based approach 
spatial intensity variation caused by illumination change have been a challenge for image segmentation and many other computer vision task this paper present a novel method for image segmentation with simultaneous estimation of illumination and reflectance image the proposed method is based on the composition of an observed scene image with an illumination component and a reflectance component known a intrinsic image we define an energy functional in term of an illumination image the membership function of the region and the corresponding reflectance constant of the region in the scene this energy is convex in each of it variable by minimizing the energy image segmentation result is obtained in the form of the membership function of the region the illumination and reflectance component of the observed image are estimated simultaneously a the result of energy minimization with illumination taken into account the proposed method is able to segment image with non uniform intensity caused by spatial variation in illumination comparison with the state of the art piecewise smooth model demonstrate the superior performance of our method 
using only shadow trajectory of stationary object in a scene we demonstrate that using a set of six or more photograph are sufficient to accurately calibrate the camera moreover we present a novel application where using only three point from the shadow trajectory of the object one can accurately determine the geo location of the camera up to a longitude ambiguity and also the date of image acquisition without using any gps or other special instrument we refer to this a geo temporal localization we consider possible case where ambiguity can be removed if additional information is available our method doe not require any knowledge of the date or the time when the picture are taken and geo temporal information is recovered directly from the image we demonstrate the accuracy of our technique for both step of calibration and geo temporal localization using synthetic and real data 
this paper examines the problem of moving object detection more precisely it address the difficult scenario where background scene texture in the video might change over time in this paper we formulate the problem mathematically a minimizing a constrained risk functional motivated from the large margin principle it is a generalization of the one class support vector machine svms to accommodate spatial interaction which is further incorporated into an online learning framework to track temporal change a a result it yield a closed form update formula a central component of the proposed algorithm to enable prompt adaptation to spatio temporal change we also analyze the mistake bound and discus issue such a dealing with non stationary distribution making use of kernel and efficient inference by a variant of dynamic programming by exploiting the inherently concurrent structure the proposed approach is designed to work with the highly parallel graphic processor gpus to facilitate realtime analysis our empirical study demonstrates that the proposed approach work in realtime over frame per second and at the same time performs competitively against state of the art offline and quasi realtime method 
pattern matching is a widely used procedure in signal processing computer vision image and video processing recently method using walsh hadamard transform wht and gray code kernel gck are successfully applied for fast transform domain pattern matching this paper introduces strip sum on the image the sum of pixel in a rectangle can be computed by one addition using the strip sum then we propose to use the orthogonal haar transform oht for pattern matching applied for pattern matching the algorithm using strip sum requires o log u addition per pixel to project input data of size n n onto u d oht basis while existing fast algorithm require o u addition per pixel to project the same data onto u d wht or gck basis experimental result show the efficiency of pattern matching using oht 
we propose an unsupervised method for evaluating image segmentation common method are typically based on evaluating smoothness within segment and contrast between them and the measure they provide is not explicitly related to segmentation error the proposed approach differs from thesemethodson several importantpointsand ha several advantage over them first it provides a meaningful quantitative assessment of segmentation quality in precision recall term which were applicable so far only for supervised evaluation second it build on a new image model which characterizes the segmentsas a mixture of basic featuredistributions the precision recall estimate are then obtained by a nonnegative matrix factorization nmf process a third important advantage is that the estimate which are based on intrinsic property of the specific image being evaluated and not on a comparison to typical image learning are relatively robust to context factor such a image quality or the presence of texture experimental result demonstrate the accuracy of the precision recall estimate in comparison to ground truth based on human judgment moreover it is shown that tuning a segmentation algorithm using the unsupervised measure improves the algorithm s quality a measured by a supervised method 
in this paper we propose a novel temporal template called chrono gait image cgi to describe the spatio temporal walking pattern for human identification by gait the cgi temporal template encodes the temporal information among gait frame via color mapping to improve the recognition performance our method start with the extraction of the contour in each gait image followed by utilizing a color mapping function to encode each of gait contour image in the same gait sequence and compositing them to a single cgi we also obtain the cgi based real template by generating cgi for each period of one gait sequence and utilize contour distortion to generate the cgi based synthetic template in addition to independent recognition using either of individual template we combine the real and synthetic temporal template for refining the performance of human recognition extensive experiment on the usf humanid database indicate that compared with the recently published gait recognition approach our cgi based approach attains better performance in gait recognition with considerable robustness to gait period detection 
it ha been of great interest to find sparse and or nonnegative representation in computer vision literature in this paper we propose a novel method to such a purpose and refer to it a nonnegative curd and whey nncw the nncw procedure consists of two stage in the first stage we consider a set of sparse and nonnegative representation of a test image each of which is a linear combination of the image within a certain class by solving a set of regression type nonnegative matrix factorization problem in the second stage we incorporate these representation into a new sparse and nonnegative representation by using the group nonnegative garrote this procedure is particularly appropriate for discriminant analysis owing to it supervised and nonnegativity nature in sparsity pursuing experiment on several benchmark face database and caltech image dataset demonstrate the efficiency and effectiveness of our nonnegative curd and whey method 
abstract this paper deal with the problem of tracking multiple target in a distributed network of self configuring pan tiltzoom camera we focus on application where event unfold over a large geographic area and need to be analyzed by multiple overlapping and non overlapping active camera without a central unit accumulating and analyzing all the data the overall goal is to keep track of all target in the region of deployment of the camera while selectively focusing at a high resolution on some particular target feature to acquire all the target at the desired resolution while keeping the entire scene in view we use cooperative network control idea based on multi player learning in game for tracking the target a they move through the area covered by the camera we propose a special application of the distributed estimation algorithm known a kalman consensus filter through which each camera come to a consensus with it neighboring camera about the actual state of the target this lead to a camera network topology that change with time combining these idea with single view analysis we have a completely distributed approach for multi target tracking and camera network self configuration we show performance analysis result with real life experiment on a network of camera 
automatic age estimation from facial image ha aroused research interest in recent year due to it promising potential for some computer vision application among the method proposed to date personalized age estimation method generally outperform global age estimation method by learning a separate age estimator for each person in the training data set however since typical age database only contain very limited training data for each person training a separate age estimator using only training data for that person run a high risk of overfitting the data and hence the prediction performance is limited in this paper we propose a novel approach to age estimation by formulating the problem a a multi task learning problem based on a variant of the gaussian process gp called warped gaussian process wgp we propose a multi task extension called multi task warped gaussian process mtwgp age estimation is formulated a a multi task regression problem in which each learning task refers to estimation of the age function for each person while mtwgp model common feature shared by different task person it also allows task specific person specific feature to be learned automatically moreover unlike previous age estimation method which need to specify the form of the regression function or determine many parameter in the function using inefficient method such a cross validation the form of the regression function in mtwgp is implicitly defined by the kernel function and all it model parameter can be learned from data automatically we have conducted experiment on two publicly available age database fg net and morph the experimental result are very promising in showing that mtwgp compare favorably with state of the art age estimation method 
in this paper an analysis of locally linear embedding lle in the context of clustering is developed a lle conserve the local affine coordinate of point shape protrusion a high curvature region of the surface are preserved also lle s covariance constraint act a a force stretching those protrusion and making them wider separated and lower dimensional a novel scheme for unsupervised body part segmentation along time sequence is thus proposed in which d shape are clustered after embedding cluster are propagated in time and merged or split in an unsupervised fashion to accommodate change of the body topology comparison on synthetic and real data with ground truth are run with direct segmentation in d by em clustering and isomap based clustering robustness and the effect of topology transition are discussed 
this paper proposes a novel method to apply the standard graph cut technique to segmenting multimodal tensor valued image the riemannian nature of the tensor space is explicitly taken into account by first mapping the data to a euclidean space where non parametric kernel density estimate of the regional distribution may be calculated from user initialized region these distribution are then used a regional prior in calculating graph edge weight hence this approach utilizes the true variation of the tensor data by respecting it riemannian structure in calculating distance when forming probability distribution further the non parametric model generalizes to arbitrary tensor distribution unlike the gaussian assumption made in previous work casting the segmentation problem in a graph cut framework yield a segmentation robust with respect to initialization on the data tested 
this paper address the problem of exactly inferring the maximum a posteriori solution of discrete multi label mrf so rcrfs with higher order clique we present a framework to transform special class of multi label higherorder functionsto submodularsecond order boolean function referred to a f s which can be minimized exactly using graph cut and we characterize those class the basic idea is to use two or more boolean variable to encode the state of a single multi label variable there are many way in which this can be done and much interesting research lie in finding way which are optimal or minimal in some sense we study the space of possible encoding and find the one that can transform the most general class of function to f s our main contribution are two fold first we extend the subclass of submodular energy function that can be minimized exactly using graph cut second we show how higher order potential can be used to improve single view d reconstruction result we believe that our work on exact minimization of higher order energy function will lead to similar improvement in solution of other labelling problem 
we propose a novel global pose estimation method to detect body part of articulated object in image based on non tree graph model there are two kind of edge defined in the body part relation graph strong tree edge corresponding to the body plan that can enforce any type of constraint and weak non tree edge that express exclusion constraint arising from inter part occlusion and symmetry condition we express optimal part localization a a multiple shortest path problem in a set of correlated trellis constructed from the graph model strong model edge generate the trellis while weak model edge prohibit implausible pose by generating exclusion constraint among trellis node and edge the optimization may be expressed a an integer linear program and solved using a novel twostage relaxation scheme experiment show that the proposed method ha a high chance of obtaining the globally optimal pose at low computational cost 
in this paper we present a deformable action template dat model that is learnable from cluttered real world video with weak supervision in our generative model an action template is a sequence of image template each of which consists of a set of shape and motion primitive gabor wavelet and optical flow patch at selected orientation and location these primitive are allowed to slightly perturb their location and orientation to account for spatial deformation we use a shared pursuit algorithm to automatically discover a best set of primitive and weight by maximizing the likelihood over one or more aligned training example since it is extremely hard to accurately label human action from real world video we use a threestep semi supervised learning procedure for each human action class a template is initialized from a labeled one bounding box per frame training video the template is used to detect action from other training video of the same class by a dynamic space time warping algorithm which search a best match between the template and target video in d space x y scale ttemplate and ttarget using dynamic programming the template is updated by the shared pursuit algorithm over all aligned video the nd and rd step iterate several time to arrive at an optimal action template we tested our algorithm on a cluttered action dataset the cmu dataset and achieved favorable performance than our classification performance on the kth dataset is also comparable to state of the art 
there are many application such a image based rendering where multiple view of a scene are considered simultaneously for improved analysis through employing strong correlation among the set of pixel corresponding to the same physical scene point while being a useful tool for modeling pixel interaction markov random field mrf model encounter challenge in such case since they assume strong independence of the observed data for tractability rendering it difficult to take advantage of having multiple correlated view in this paper we propose joint conditional random field crf for multiple view in the context of virtual view synthesis in image based rendering the model is enabled by the adoption of steerable spatial filter for capturing not only the pixel dependence in a single image but also their correlation among multiple view furthermore a novel on line learning scheme is proposed for the crf model which learns the crf parameter from the same input data for synthesizing virtual view this effectively make the model adaptive to the input and thus optimal result can be expected experiment are designed to validate the proposed approach and it effectiveness 
abstract a novel particle filter the memory based particle filter m pf is proposed that can visually track moving object that have complex dynamic we aim to realize robustness against abrupt object movement and quick recovery from tracking failure caused by factor such a occlusion to that end we eliminate the markov assumption from the previous particle filtering framework and predict the prior distribution of the target state from the long term dynamic more concretely m pf store the past history of the estimated target state and employ a random sampling from the history to generate prior distribution it represents a novel pf formulation our method can handle nonlinear time variant and non markov dynamic which is not possible within existing pf framework accurate prior prediction based on proper dynamic model is especially effective for recovering lost track because it can provide possible target state which can drastically change since the track wa lost we target the face pose of seated human in this paper quantitative evaluation with magnetic sensor confirm improved accuracy in face pose estimation and successful recovery from tracking loss the proposed m pf suggests a new paradigm for modeling system with complex dynamic and so offer a various visual tracking application 
in this paper we introduce a novel iterative motion tracking framework that combine d tracking technique with motion retrieval for stabilizing markerless human motion capturing the basic idea is to start human tracking without prior knowledge about the performed action the resulting d motion sequence which may be corrupted due to tracking error are locally classified according to available motion category depending on the classification result a retrieval system supply suitable motion prior which are then used to regularize and stabilize the tracking in the next iteration step experiment with the humaneva ii benchmark show that tracking and classification are remarkably improved after few iteration 
we propose an efficient method built on the popular bag of feature approach that obtains robust multiclass pixellevel object segmentation of an image in le than m with result comparable or better than most state of the art method we introduce the integral linear classifier ilc that can readily obtain the classification score for any image sub window with only addition and product by fusing the accumulation and classification step in a single operation in order to design a method a efficient a possible our building block are carefully selected from the quickest in the state of the art more precisely we evaluate the performance of three popular local descriptor that can be very efficiently computed using integral image and two fast quantization method the hierarchical k mean and the extremely randomized forest finally we explore the utility of adding spatial bin to the bag of feature histogram and that of cascade classifier to improve the obtained segmentation our method is compared to the state of the art in the difficult graz and pascal segmentation challenge datasets 
multi label learning is useful in visual object recognition when several object are present in an image conventional approach implement multi label learning a a set of binary classification problem but they suffer from imbalanced data distribution when the number of class is large in this paper we address multi label learning with many class via a ranking approach termed multi label ranking given a test image the proposed scheme aim to order all the object class such that the relevant class are ranked higher than the irrelevant one we present an efficient algorithm for multi label ranking based on the idea of block coordinate descent the proposed algorithm is applied to visual object recognition empirical result on the pascal voc and data set show promising result in comparison to the state of the art algorithm for multi label learning 
recently a simple yet powerful branch and bound method called efficient subwindow search es wa developed to speed up sliding window search in object detection a major drawback of es is that it computational complexity varies widely from o n to o n for n n matrix our experimental experience show that the es s performance is highly related to the optimal confidence level which indicate the probability of the object s presence in particular when the object is not in the image the optimal subwindow score low and es may take a large amount of iteration to converge to the optimal solution and so perform very slow addressing this problem we present two significantly faster method based on the linear time kadane s algorithm for d maximum subarray search the first algorithm is a novel computationally superior branch and bound method where the worst case complexity is reduced to o n experiment on the pascal voc data set demonstrate that this method is significantly and consistently faster approximately time faster on average than the original es our second algorithm is an approximate algorithm based on alternating search whose computational complexity is typically o n experiment show that on average it is time faster again than our first algorithm or time faster than es it is thus well suited for real time object detection 
we propose an approach to overcome the two main challenge of d multiview object detection and localization the variation of object feature due to change in the viewpoint and the variation in the size and aspect ratio of the object our approach proceeds in three step given an initial bounding box of fixed size we first refine it aspect ratio and size we can then predict the viewing angle under the hypothesis that the bounding box actually contains an object instance finally a classifier tuned to this particular viewpoint check the existence of an instance a a result we can find the object instance and estimate their pose without having to search over all window size and potential orientation we train and evaluate our method on a new object database specifically tailored for this task containing realworld object imaged over a wide range of smoothly varying viewpoint and significant lighting change we show that the successive estimation of the bounding box and the viewpoint lead to better localization result 
higher order spatial feature such a doublet or triplet have been used to incorporate spatial information into the bag of local feature model due to computational limit researcher have only been using feature up to the rd order i e triplet since the number of feature increase exponentially with the order we propose an algorithm for identifying high order spatial feature efficiently the algorithm directly evaluates the inner product of the feature vector from two image to be compared identifying all high order feature automatically the algorithm hence serf a a kernel for any kernel based learning algorithm the algorithm is based on the idea that if a high order spatial feature co occurs in both image the occurrence of the feature in one image would be a translation from the occurrence of the same feature in the other image this enables u to compute the kernel in time that is linear to the number of local feature in an image same a the bag of local feature approach regardless of the order therefore our algorithm doe not limit the upper bound of the order a in previous work the experiment result on the object categorization task show that high order feature can be calculated efficiently and provide significant improvement in object categorization performance 
feature selection play a fundamental role in many pattern recognition problem however most effort have been focused on the supervised scenario while unsupervised fea ture selection remains a a rarely touched research topic in this paper we propose manifold based maximum margin feature selection m f to select the most discriminative feature for clustering m f target to find those feature that would result in the maximal separation of different cluster and incorporates manifold information by enforcing smoothness constraint on the clustering functio n specifically we define scale factor for each feature to measure it relevance to clustering and irrelevant feature a re identified by assigning zero weight feature selection is then achieved by the sparsity constraint on scale factor computationally m f is formulated a an integer programming problem and we propose a cutting plane algorithm to efficiently solve it experimental result on both toy and real world data set demonstrate it effectiveness 
we present a region based active contour detection algorithm for object that exhibit relatively homogeneous photometric characteristic e g smooth color or gray level embedded in complex background clutter current method either frame this problem in bayesian classification term where precious modeling resource are expended representing the complex background away from decision boundary or use heuristic to limit the search to local region around the object of interest we propose an adaptive lookout region whose size depends on the statistic of the data that are estimated along with the boundary during the detection process the result is a curious snake that explores the outside of the decision boundary only locally to the extent necessary to achieve a good tradeoff between missed detection and narrowest lookout region drawing inspiration from the literature of minimum latency set point change detection and robust statistic this development make fully automatic detection in complex background a realistic possibility for active contour allowing u to exploit their powerful geometric modeling capability compared with other approach used for segmentation of cluttered scene to this end we introduce an automatic initialization method tailored to our model that overcomes one of the primary obstacle in using active contour for fully automatic object detection 
d object design ha many application including flexible d sketch input in cad computer game webpage content design image based object modeling and dobject retrieval most current d object design tool work on a d drawing plane such a computer screen or tablet which is often inflexible with one dimension lost on the other hand virtual reality based method have the drawback that there are awkward device worn by the user and the virtual environment system are expensive in this paper we propose a novel vision based approach to d object design our system consists of a pc a camera and a mirror we use the camera and mirror to track a wand so that the user can design d object by sketching in d free space directly without having to wear any cumbersome device a number of new technique are developed for working in thissystem including input of object wireframes gesture for editing and drawing object and optimization based planarand curved surface generation our system provides designer a new user interface for designing d object conveniently 
typical content based image retrieval cbir solution with regular euclidean metric usually cannot achieve satisfactory performance due to the semantic gap challenge hence relevancefeedbackhas beenadoptedas a promising approach to improve the search performance in this paper we propose a novel idea of learning with historical relevance feedback log data and adopt a new paradigm called collaborative image retrieval cir to effectively explore the log data we propose a novel semi supervised distance metric learning technique called laplacian regularized metric learning lrml for learning robust distance metric for cir different from previous method the proposed lrml method integrates both log data and unlabeled data information through an effective graph regularization framework we show that reliable metric can be learned from real log data even they may be noisy and limited at the beginning stage of a cir system we conducted extensive evaluation to compare the proposed method with a large number of competing method including standard metric unsupervised metric and supervised metric with side information 
in this paper we propose a novel robust retrieval and classification system for video and motion event based on null space representation in order to analyze the robustness of the system the perturbed null operator have been derived with the first order perturbation theory subsequently the sensitivity of the null operator is discussed in term of the error ratio and the snr respectively meanwhile the normwise bound and componentwise bound based on classical matrix perturbation theory are presented and discussed given the perturbation uniform sampling are proposed for the convergence of the snr and poisson sampling are proposed for the convergence of the error ratio in the mean sense by choosing the rate parameter the same order a the number of sample the simulation result are provided to demonstrate the effectiveness and robustness of our system in motion event indexing retrieval and classification that is invariant to affine transformation due to camera motion 
in this paper we introduce a novel method to detect and localize abnormal behavior in crowd video using social force model for this purpose a grid of particle is placed over the image and it is advected with the space time average of optical flow by treating the moving particle a individual their interaction force are estimated using social force model the interaction force is then mapped into the image plane to obtain force flow for every pixel in every frame randomly selected spatio temporal volume of force flow are used to model the normal behavior of the crowd we classify frame a normal and abnormal by using a bag of word approach the region of anomaly in the abnormal frame are localized using interaction force the experiment are conducted on a publicly available dataset from university of minnesota for escape panic scenario and a challenging dataset of crowd video taken from the web the experiment show that the proposed method capture the dynamic of the crowd behavior successfully in addition we have shown that the social force approach outperforms similar approach based on pure optical flow 
deformable model fitting ha been actively pursued in the computer vision community for over a decade a a result numerous approach have been proposed with varying degree of success a class of approach that ha shown substantial promise is one that make independent prediction regarding location of the model s landmark which are combined by enforcing a prior over their joint motion a common theme in innovation to this approach is the replacement of the distribution of probable landmark location obtained from each local detector with simpler parametric form this simplification substitute the true objective with a smoothed version of itself reducing sensitivity to local minimum and outlying detection in this work a principled optimization strategy is proposed where a nonparametric representation of the landmark distribution is maximized within a hierarchy of smoothed estimate the resultingupdateequationsare reminiscent of mean shiftbut with a subspace constraint placed on the shape s variability this approach is shown to outperform other existing method on the task of generic face fitting 
in the last decade graph cut optimization ha been popular for a variety of pixel labeling problem typically graph cut method are used to incorporate a smoothness prior on a labeling recently several method incorporated ordering constraint on label for the application of object segmentation an example of an ordering constraint is prohibiting a pixel with a car wheel label to be above a pixel with a car roof label we observe that the commonly used graph cut based expansion is more likely to get stuck in a local minimum when ordering constraint are used for certain model with ordering constraint we develop new graph cut move which we call order preserving move order preserving move act on all label unlike expansion although the global minimum is still not guaranteed optimization with order preserving move performs significantly better than expansion we evaluate orderpreserving move for the geometric class scene labeling introduced by hoiem et al where the goal is to assign each pixel a label such a sky ground etc so ordering constraint arise naturally in addition we use orderpreserving move for certain simple shape prior in graphcut segmentation which is a novel contribution in itself 
we present two novel method for face verification our first method attribute classifier us binary classifier trained to recognize the presence or absence of describable aspect of visual appearance e g gender race and age our second method simile classifier remove the manual labeling required for attribute classification and instead learns the similarity of face or region of face to specific reference people neither method requires costly often brittle alignment between image pair yet both method produce compact visual description and work on real world image furthermore both the attribute and simile classifier improve on the current state of the art for the lfw data set reducing the error rate compared to the current best by and respectively and when combined for further testing across pose illumination and expression we introduce a new data set termed pubfig of real world image of public figure celebrity and politician acquired from the internet this data set is both larger image and deeper image per individual than existing data set of it kind finally we present an evaluation of human performance figure attribute classifier an attribute classifier can be trained to recognize the presence or absence of a describable aspect of visual appearance the response for several such attribute classifier are shown for a pair of image of halle berry note that the flash and shiny skin attribute produce very different response while the response for the remaining attribute are in strong agreement despite the change in pose illumination expression and image quality we use these attribute for face verification achieving a drop in error rate on the lfw benchmark compared to the existing state of the art 
non frontal view facial expression recognition is important in many scenario where the frontal view face image may not be available however few work on this issue ha been done in the past several year because of it technical challenge and the lack of appropriate database recently a d facial expression database bu dfe database is collected by yin et al and ha attracted some researcher to study this issue based on the bu dfe database in this paper we propose a novel approach to expression recognition from non frontal view facial image the novelty of the proposed method lie in recognizing the multi view expression under the unified bayes theoretical framework where the recognition problem can be formulated a an optimization problem of minimizing an upper bound of bayes error we also propose a close form solution method based on the power iteration approach and rank one update rou technique to find the optimal solution of the proposed method extensive experiment on bu dfe database with subject and yaw rotation view angle demonstrate the effectiveness of our method 
we present a semi automatic system that convert conventional video shot to stereoscopic video pair the system requires just a few user scribble in a sparse set of frame the system combine a diffusion scheme which take into account the local saliency and the local motion at each video location coupled with a classification scheme that assigns depth to image patch the system tolerates both scene motion and camera motion in typical shot containing hundred of frame even in the face of significant motion it is enough to mark scribble on the first and last frame of the shot once marked plausible stereo result are obtained in a matter of second leading to a scalable video conversion system finally we validate our result with ground truth stereo video 
with the recent effort made by computer vision researcher more and more type of feature have been designed to describe various aspect of visual characteristic modeling such heterogeneous feature ha become an increasingly critical issue in this paper we propose a machinery called the heterogeneous feature machine hfm to effectively solve visual recognition task in need of multiple type of feature our hfm build a kernel logistic regression model based on similarity that combine different feature and distance metric different from existing approach that use a linear weighting scheme to combine different feature hfm doe not require the weight to remain the same across different sample and therefore can effectively handle feature of different type with different metric to prevent the model from overfitting we employ the so called group lasso constraint to reduce model complexity in addition we propose a fast algorithm based on co ordinate gradient descent to efficiently train a hfm the power of the proposed scheme is demonstrated across a wide variety of visual recognition task including scene event and action recognition 
we propose a new algorithm for learning kernel for variant of the normalized cut ncuts objective i e given a set of training example with known partition how should a basis set of similarity function be combined to induce ncuts favorable distribution such a procedure facilitates design of good affinity matrix it also help ass the importance of different feature type for discrimination rather than formulating the learning problem in term of the spectral relaxation the alternative we pursue here is to work in the original discrete setting i e the relaxation occurs much later we show that this strategy is useful while the initial specification seems rather difficult to optimize efficiently a set of manipulation reveal a related model which permit a nice sdp relaxation a salient feature of our model is that the eventual problem size is only a function of the number of input kernel and not the training set size this relaxation also allows strong optimality guarantee if certain condition are satisfied we show that the sub kernel weight obtained provide a complementary approach for mkl based method our experiment on caltech and adni a brain imaging dataset show that the quality of solution is competitive with the state of the art 
we consider the problem of motion detection by background subtraction an accurate estimation of the background is only possible if we locate the moving object meanwhile a correct motion detection is achieved if we have a good available background model this work proposes a new direction in the way such problem are considered the main idea is to formulate this class of problem a a joint decision estimation unique step the goal is to exploit the way two process interact even if they are of a dissimilar nature symbolic continuous by mean of a recently introduced framework called mixed state markov random field in this paper we will describe the theory behind such a novel statistical framework that subsequently will allows u to formulate the specific joint problem of motion detection and background reconstruction experiment on real sequence and comparison with existing method will give a significant support to our approach further implication for video sequence inpainting will be also discussed 
this paper present a d approach to multi view object class detection most existing approach recognize object class for a particular viewpoint or combine classifier for a few discrete view we propose instead to build d representation of object class which allow to handle viewpoint change and intra class variability our approach extractsa set of pose andclass discriminantfeaturesfrom synthetic d object model using a filtering procedure evaluates their suitability for matching to real image data and represents them by their appearance and d position we term these representation d feature map for recognizing an object class in an image we match the synthetic descriptor to the real one in a d voting scheme geometric coherence is reinforced by mean of a robust pose estimation which yield a d bounding box in addition to the d localization the precisionof the d poseestimation is evaluated on a set of image of a calibrated scene the d localization is evaluated on the pascal dataset for motorbike and car showing that it performance can compete with state of the art d object detector 
the potential success of discriminative learning approach to d reconstruction relies on the ability to efficiently train predictive algorithm using sufficiently many example that are representative of the typical configuration encountered in the application domain recent research indicates that sparse conditional bayesian mixture of expert cmoe model e g bme sminchisescu et al are adequate modeling tool that not only provide contextual d prediction for problem like human pose reconstruction but can also represent multiple interpretation that result from depth ambiguity or occlusion however training conditional predictor requires sophisticated double loop algorithm that scale unfavorably with the input dimension and the training set size thus limiting their usage to example of le so far in this paper we present large scale algorithm referred to a fbme that combine forward feature selection and bound optimization in order to train probabilistic bme model with one order of magnitude more data example and up and more than one order of magnitude faster we present several large scale experiment including monocular evaluation on the humaneva dataset sigal and black demonstrating how the proposed method overcome the scaling limitation of existing one 
abstract sparse signal model have been the focus of much recent research leading to or improving upon state of the art result in signal image and video restoration this articleextends this line of research into a novel framework for local image discrimination task proposing an energy formulation with both sparse reconstruction and class discrimination component jointly optimized during dictionary learning this approach improves over the state of the art in texture segmentation experiment using the brodatz database and it pave the way for a novel scene analysis and recognition framework based on simultaneously learning discriminative and reconstructive dictionary preliminary result in this direction using example from the pascal voc and graz datasets are presented a well 
we propose a method to generate a highly accurate d face model from a set of wide baseline image in a weakly calibrated setup our approach is purely data driven and produce faithful d model without any pre defined model unlike other statistical model based approach our result do not rely upon a critical initialization step nor parameter for optimization step we process image including profile view infer the accurate pose of camera in all view and then infer a dense d face model the quality of d face model depends on the accuracy of estimated head camera motion first we propose to use an iterative bundle adjustment approach to remove outlier in corresponding point contour in the profile view are matched to provide reliable correspondence that link two opposite side of view together for dense reconstruction we propose to use a face specific cylindrical representation which allows u to solve a global optimization problem for n view dense aggregation profile contour are used once again to provide constraint in the optimization step experimental result using synthetic and real image show that our method provides accurate and stable reconstruction result on wide baseline image we compare our method with state of the art method and show that it provides significantly better result in term of both accuracy and efficiency 
the classical optical flow assumes that a feature point maintains constant brightness across the frame for fluid type motion such a smoke or cloud the constant brightness assumption doe not hold and accurately estimating the motion flow from their image is difficult in this paper we introduce a simple but effective navier stokes n potential flow model for recovering fluid type motion our method treat the image a a wavefront surface and model the d potential flow beneath the surface the gradient of the velocity potential describes the motion flow at every voxel we first derive a general brightness constraint that explicitly model wavefront brightness variation in term of the velocity potential we then use a series of partial differential equation to separately model the dynamic of the potential flow to solve for the potential flow we use the dirichlet neumann operator dno to simplify the d volumetric velocity potential to d surface velocity potential we approximate the dno via taylor expansion and develop a fourier domain method to efficiently estimate the taylor coefficient finally we show how to use the dno to recover the velocity potential from image a well a to propagate the wavefront image over time experimental result on both synthetic and real image show that our technique is robust and reliable 
color constancy is the ability to measure image feature independent of the color of the scene illuminant and is an important topic in color and computer vision a many color constancy algorithm exist different distance measure are used to compute their accuracy in general these distance measure are based on mathematical principle such a the angular error and euclidean distance however it is unknown to what extent these distance measure correlate to human vision therefore in this paper a taxonomy of different distance measure for color constancy algorithm is presented the main goal is to analyze the correlation between the observed quality of the output image and the different distance measure for illuminant estimate the output image are the resulting color corrected image using the illuminant estimate of the color constancy algorithm and the quality of these image is determined by human observer distance measure are analyzed how they mimic difference in color naturalness of image a obtained by human based on the theoretical and experimental result on spectral and real world data set it can be concluded that the perceptual euclidean distance ped with weight coefficient wr wg wb find it root in human vision and correlate significantly higher than all other distance measure including the angular error and euclidean distance 
we present a new gaussian process inference algorithm called online sparse matrix gaussian process osmgp and demonstrate it merit with a few vision application the osmgp is based on the observation that for kernel with local support the gram matrix is typically sparse maintaining and updating the sparse cholesky factor of the gram matrix can be done efficiently using given rotation this lead to an exact online algorithm whose update time scale linearly with the size of the gram matrix further if approximate update are permissible the cholesky factor can be maintained at a constant size using hyperbolic rotation to remove certain row and column corresponding to discarded training example we demonstrate that using these matrix downdates online hyperparameter estimation can be included without affecting the linear runtime complexity of the algorithm the osmgp algorithm is applied to head pose estimation and visual tracking problem experimental result demonstrate that the proposed method is accurate efficient and generalizes well using online learning 
we present a novel image representation that characterizes a color image by an intensity image and a small number of color pixel our idea is based on solving an inverse problem of colorization given a color image we seek to obtain an intensity image and a small subset of color pixel which are called landmark pixel so that the input color image can be recovered faithfully using the intensity image and the color cue provided by the selected landmark pixel we develop an algorithm to derive the landmark based sparse color representation from color image and use the representation in the application of color transfer and color correction the computational cost for these application is low owing to the sparsity of the proposed representation the landmark based representation is also preferable to statistic based representation e g color histogram and gaussian mixture model when we need to reconstruct the color image from a given representation 
we propose an algorithm to improve the quality of depth map used for multi view stereo mv many existing mv technique make use of a two stage approach which estimate depth map from neighbouring image and then merges them to extract a final surface often the depth map used for the merging stage will contain outlier due to error in the matching process traditional system exploit redundancy in the image sequence the surface is seen in many view in order to make the final surface estimate robust to these outlier in the case of sparse data set there is often insufficient redundancy and thus performance degrades a the number of image decrease in order to improve performance in these circumstance it is necessary to remove the outlier from the depth map we identify the two main source of outlier in a top performing algorithm spurious match due to repeated texture and matching failure due to occlusion distortion and lack of texture we propose two contribution to tackle these failure mode firstly we store multiple depth hypothesis and use a spatial consistency constraint to extract the true depth secondly we allow the algorithm to return an unknownstate when the a true depth estimate cannot be found by combining these in a discrete label mrf optimisation we are able to obtain high accuracy depth map with low number of outlier we evaluate our algorithm in a multi view stereo framework and find it to confer state of the art performance with the leading technique in particular on the standard evaluation sparse data set 
this paper present an approach for modeling landmark site such a the statue of liberty based on large scale contaminated image collection gathered from the internet our system combine d appearance and d geometric constraint to efficiently extract scene summary build d model and recognize instance of the landmark in new test image we start by clustering image using low dimensional global gist descriptor next we perform geometric verification to retain only the cluster whose image share a common d structure each valid cluster is then represented by a single iconic view and geometric relationship between iconic view are captured by an iconic scene graph in addition to serving a a compact scene summary this graph is used to guide structure from motion to efficiently produce d model of the different aspect of the landmark the set of iconic image is also used for recognition i e determining whether new test image contain the landmark result on three data set consisting of ten of thousand of image demonstrate the potential of the proposed approach 
segmenting arbitrary union of linear subspace is an important tool for computer vision task such a motion and image segmentation sfm or object recognition we segment subspace by searching for the orthogonal complement of the subspace supported by the majority of the observation i e the maximum consensus subspace it is formulated a a grassmannian optimization problem a smooth constrained but nonconvex program is immersed into the grassmann manifold resulting in a low dimensional and unconstrained program solved with an efcient optimization algorithm nonconvexity implies that global optimality depends on the initialization however by nding the maximum consensus subspace outlier rejection becomes an inherent property of the method besides robustness it doe not rely on prior global detection procedure e g rank of data matrix which is the case of most current work we test our algorithm in both synthetic and real data where no outlier wa ever classied a inlier 
in image categorization the goal is to decide if an image belongs to a certain category or not a binary classifier can be learned from manually labeled image while using more labeled example improves performance obtaining the image label is a time consuming process we are interested in how other source of information can aid the learning process given a fixed amount of labeled image in particular we consider a scenario where keywords are associated with the training image e g a found on photo sharing website the goal is to learn a classifier for image alone but we will use the keywords associated with labeled and unlabeled image to improve the classifier using semi supervised learning we first learn a strong multiple kernel learning mkl classifier using both the image content and keywords and use it to score unlabeled image we then learn classifier on visual feature only either support vector machine svm or leastsquares regression lsr from the mkl output value on both the labeled and unlabeled image in our experiment on class from the pascal voc set and from the mir flickr set we demonstrate the benefit of our semi supervised approach over only using the labeled image we also present result for a scenario where we do not use any manual labeling but directly learn classifier from the image tag the semi supervised approach also improves classification accuracy in this case 
we present an efficient algorithm for fitting a morphable model to an image sequence it is built on a projective geometry formulation of perspective projection which result in a linear mapping from d shape to the projective plane and a factorisation of this mapping into matrix that can be partially computed off line this algorithm can cope with full degree object rotation and linear deformation we validate our approach using synthetically generated and real sequence compared to a plain lucas kanade implementation we achieve a six fold increase in performance for a rigid object and two fold for a non rigid face 
the use of d ultrasound data ha several advantage over d ultrasound for fetal biometric measurement such a considerable decrease in the examination time possibility of post exam data processing by expert and the ability to produce d view of the fetal anatomy in orientation that cannot be seen in common d ultrasound exam however the search for standardized plane and the precise localization of fetal anatomy in ultrasound volume are hard and time consuming process even for expert physician and sonographers the relative low resolution in ultrasound volume small size of fetus anatomy and intervolume position orientation and size variability make this localization problem even more challenging in order to make the plane search and fetal anatomy localization problem completely automatic we introduce a novel principled probabilistic model that combine discriminative and generative classifier with contextual information and sequential sampling we implement a system based on this model where the user query consist of semantic keywords that represent anatomical structure of interest after queried the system automatically display standardized plane and produce biometric measurement of the fetal anatomy experimental result on a held out test set show that the automatic measurement are within the inter user variability of expert user it resolve for position orientation and size of three different anatomy in le than second in a dual core computer running at ghz 
surface registration is a fundamental step in the reconstruction of three dimensional object this is typically a two step process where an initial coarse motion estimation is followed by a refinement most coarse registration algorithm exploit some local point descriptor that is intrinsic to the shape and doe not depend on the relative position of the surface by contrast refinement technique iteratively minimize a distance function measured between pair of selected neighboring point and are thus strongly dependent on initial alignment in this paper we propose a novel technique that allows to obtain a fine surface registration in a single step without the need of an initial motion estimation the main idea of our approach is to cast the selection of correspondence between point on the surface in a game theoretic framework where a natural selection process allows mating point that satisfy a mutual rigidity constraint to thrive eliminating all the other correspondence this process yield a very robust inlier selection scheme that doe not depend on any particular technique for selecting the initial strategy a it relies only on the global geometric compatibility between correspondence the practical effectiveness of the proposed approach is confirmed by an extensive set of experiment and comparison with state of the art technique 
most previous facial expression analysis work only focused on expression recognition in this paper we propose a novel framework of facial expression analysis based on the ranking model different from previous work it not only can do facial expression recognition but also can estimate the intensity of facial expression which is very important to further understand human emotion although it is hard to label expression intensity quantitatively the ordinal relationship in temporal domain is actually a good relative measurement based on this observation we convert the problem of intensity estimation to a ranking problem which is modeled by the rankboost the output ranking score can be directly used for intensity estimation and we also extend the ranking function for expression recognition to further improve the performance we propose to introduce l based regularization into the rankboost experiment on the cohn kanade database show that the proposed method ha a promising performance compared to the state of the art 
this paper introduces an algorithm for detecting walking motion using point trajectory in video sequence given a number of point trajectory we identify those which are spatio temporally correlated a arising from foot in walking motion unlike existing technique we do not assume clean point track but instead propose probabilistic trajectory a new feature to classify these are extracted from directed acyclic graph whose edge represent temporal point correspondence and are weighted with their matching probability in term of appearance and location this representation tolerates the inherent trajectory amb iguity for example due to occlusion we then learn the correlation between the movement of two foot using a random forest classifier the effectiveness of the algorithm is demonstrated in experiment on image sequence captured with a static camera 
human identity recognition is an important yet under addressed problem previous method were strictly limited to high quality photograph where the principal technique heavily rely on body detail such a face detection in this paper we propose an algorithm to address the novel problem of human identity recognition over a set of unordered low quality aerial image assuming a user wa able to manually locate a target in some image of the set we find the target in each other query image by implementing a weighted voter candidate formulation in the framework every manually located target is a voter and the set of human in a query image are candidate in order to locate the target we detect and align blob of voter and candidate consequently we use pagerank to extract distinguishing region and then match multiple region of a voter to multiple region of a candidate using earth mover distance emd this generates a robust similarity measure between every voter candidate pair finally we identify the candidate with the highest weighted vote a the target we tested our technique over several aerial image set that we collected along with publicly available set and have obtained promising result 
support vector machine svm are one of the most useful technique in classification problem one clear example is face recognition however svm cannot be applied when the feature vector defining our sample have missing entry this is clearly the case in face recognition when occlusion are present in the training and or testing set when k feature are missing in a sample vector of class these define an affine subspace of k dimension the goal of the svm is to maximize the margin between the vector of class and class on those dimension with no missing element and at the same time maximize the margin between the vector in class and the affine subspace of class this second term of the svm criterion will minimize the overlap between the classification hyperplane and the subspace of solution in class because we do not know which value in this subspace a test vector can take the hyperplane minimizing this overlap is obviously the one parallel to the missing dimension however this condition is too restrictive because it solution will generally contradict that obtained when maximizing the margin of the visible data to resolve this problem we define a criterion which minimizes the probability of overlap the resulting optimization problem can be solved efficiently and we show how the global minimum of the error term is guaranteed under mild condition we provide extensive experimental result demonstrating the superiority of the proposed approach over the state of the art 
in this paper we address the problem of classifying image set each of which contains image belonging to the same class but covering large variation in for instance viewpoint and illumination we innovatively formulate the problem a the computation of manifold manifold distance mmd i e calculating the distance between nonlinear manifold each representing one image set to compute mmd we also propose a novel manifold learning approach which express a manifold by a collection of local linear model each depicted by a subspace mmd is then converted to integrating the distance between pair of subspace respectively from one of the involved manifold the proposed mmd method is evaluated on the task of face recognition based on image set fri in fri each known subject is enrolled with a set of facial image and modeled a a gallery manifold while a testing subject is modeled a a probe manifold which is then matched against all the gallery manifold by mmd identification is achieved by seeking the minimum mmd experimental result on two public face database honda ucsd and cmu mobo demonstrate that the proposed mmd method outperforms the competing method 
w e analyze the modulation of a light field via nonrefracting attenuator in the most general case any desired modulation can be achieved with attenuator having four degree of freedom in ray space we motivate the discussion with a universal d ray modulator ray filter whichcanattenuatetheintensityofeachrayindependently wedescribeoperationofsuchafantasyray filterinthecontext of altering the d lightfield incident on a d camera sensor ray filter are difficult to realize in practice but we can achievereversibleencodingforlightfieldcaptureusingpatterned attenuating mask two mask based design are analyzed in this framework the first design closely mimic the angle dependent ray sorting possible with the rayfilter theseconddesign exploitsfrequency domain modulation to achieve a more efficient encoding we extend these design for optimal sampling of lightfield by matching the modulation function to the specific shape of the band limit frequency transform of light field we also show how a hand held version of an attenuator based light field camera can be built using a medium format digital camera and an inexpensive mask 
semi supervised learning ssl relies on partial supervision information for prediction where only a small set of sample are associated with label performance of ssl is significantly degraded if the given label are not reliable such problem arise in realistic application such a web image search using noisy textual tag this paper proposes a novel and efficient graph based ssl method with the unique capacity of pruning contradictory label and inferring new label through a bidirectional and alternating optimization process the objective is to automatically identify the most suitable sample for manipulation labeling or unlabeling and meanwhile estimate a smooth classification function over a weighted graph different from other graph based ssl approach the proposed method employ a bivariate objective function and iteratively modifies label variable on both labeled and unlabeled sample starting from such a ssl setting we present a relearning framework to improve the performance of base learner particularly for the application of web image search besides the toy demonstration on artificial data we evaluated the proposed method on flickr image search with unreliable textual label experimental result confirm the significant improvement of the method over the baseline text based search engine and the state of the art ssl method 
in this paper we investigate the challenging problem of recovering the depth layer in a scene from a single defocused observation the problem is definitely solvable if there are multiple observation in this paper we show that one can perceive the depth in the scene even from a single observation we use the inhomogeneous reverse heat equation to obtain an estimate of the blur thereby preserving the depth information characterized by the defocus however the reverse heat equation due to it parabolic nature is divergent we stabilize the reverse heat equation by considering the gradient degeneration a an effective stopping criterion the amount of inverse diffusion is actually a measure of relative depth because of ill posedness we propose a graph cut based method for inferring the depth in the scene using the amount of diffusion a a data likelihood and a smoothness condition on the depth in the scene the method is verified experimentally on a varied set of test case 
bottom up segmentation tends to rely on local feature yet many natural and man made object contain repeating element such structural and more spread out feature are important cue for segmentation but are more difficult to exploit the difficulty also come from the fact that repetition need not be perfect and will actually rather be partial approximate or both in most case this paper present a multi label image segmentation algorithm that process a single input image and efficiently discovers and exploit repeating element without any prior knowledge about their shape color or structure the algorithm spell out the interplay between segmentation and repetition detection the key of our approach is a novel point wise concept of repetition this is defined by point wise mutual information and locally compare certain neighborhood to accumulate evidence this point wise repetition measure naturally handle imperfect repetition and the part with inconsistent appearance are recognized and assigned with low score an energy functional is proposed to include the point wise repetition into the image segmentation process which take the form of a graph cut minimization real scene image demonstrate the ability of our algorithm to handle partial and approximate repetition 
a number of d shape reconstruction algorithm in particular d image segmentation method produce their result in the form of binary volume where a binary value indicates whether a voxel is associated with the interior or the exterior for visualization purpose it is often desirable to convert a binary volume into a surface representation straightforward extraction of the median isosurfaces for binary volume using the marching cube algorithm however produce jaggy visually unrealistic mesh therefore similarly to some previous work we suggest to precede the isosurface extraction by replacing the original binary volume with a new continuous valued embedding function so that the zero isosurface of the embedding function is smooth but at the same time consistent with the original binary volume in contrast to previous work computing such an embedding function in our case permit imposing a higher order smoothness on the embedding function and involves solving a convex optimization problem we demonstrate that the resulting separating surface are smoother and of better visual quality than minimal area separating surface extracted by previous approach to the problem we plan to make the code of our algorithm publicly available for researcher working on d image segmentation a well a other d shape reconstruction application 
time varying spatial pattern are common but few computational tool exist for discovering and tracking multiple sometimes overlapping spatial structure of target we propose a multi target tracking framework that take advantage of spatial pattern inside the target even though the number the form and the regularity of such pattern vary with time ransac based model fitting algorithm are developed to automatically recognize or dismiss il legitimate pattern pattern are represented using a mixture of markov random field mrf with constraint local and global and preference encoded into pairwise potential function to handle pattern variation continuously we introduce a posterior probability for each spatial pattern modeled a a bernoulli distribution tracking is achieved by inferring the optimal state configuration of the target using belief propagation on a mixture of mrfs we have evaluated our formulation on real video data with multiple target containing time varying lattice pattern and or reflection symmetry pattern experimental result of our proposed algorithm show superior tracking performance over existing method 
we propose a novel system for associating multi target track across multiple non overlapping camera by an on line learned discriminative appearance affinity model collecting reliable training sample is a major challenge in on line learning since supervised correspondence is not available at runtime to alleviate the inevitable ambiguity in these sample multiple instance learning mil is applied to learn an appearance affinity model which effectively combine three complementary image descriptor and their corresponding similarity measurement based on the spatial temporal information and the proposed appearance affinity model we present an improved inter camera track association framework to solve the target handover problem across camera our evaluation indicate that our method have higher discrimination between different target than previous method 
in this work we aim to capitalize on the availability of internet image search engine to automatically create image training set from user provided query this problem is particularly difficult due to the low precision of image search result unlike many existing dataset gathering approach we do not assume a category model based on a small subset of the noisy data or an ad hoc validation set instead we use a nonparametric measure of strangeness in the space of holistic image representation and perform an iterative feature elimination algorithm to remove the most strange example from the category this is the equivalent of keeping only feature that are found to be consistent with others in the class we show that applying our method to image search data before training improves average recognition performance and demonstrate that we obtain comparative precision and recall result to the current state of the art all the while maintaining a significantly simpler approach in the process we also extend the strangeness based feature elimination algorithm to automatically select good threshold value and perform filtering of a single class when the background is given 
we propose a simple but powerful multi view semantic segmentation framework for image captured by a camera mounted on a car driving along street in our approach a pair wise markov random field mrf is laid out across multiple view both d and d feature are extracted at a super pixel level to train classifier for the unary data term of mrf for smoothness term our approach make use of color difference in the same image to identify accurate segmentation boundary and dense pixel to pixel correspondence to enforce consistency across different view to speed up training and to improve the recognition quality our approach adaptively selects the most similar training data for each scene from the label pool furthermore we also propose a powerful approach within the same framework to enable large scale labeling in both the d space and d image we demonstrate our approach on more than image from google map street view 
markov random field mrf crf model are popular in computer vision however in order to be computationally tractable they are limited to incorporate only local interaction and cannot model global property such a connectedness which is a potentially useful high level prior for object segmentation in this work we overcome this limitation by deriving a potential function that enforces the output labeling to be connected and that can naturally be used in the framework of recent map mrf lp relaxation using technique from polyhedral combinatorics we show that a provably tight approximation to the map solution of the resulting mrf can still be found efficiently by solving a sequence of max flow problem the efficiency of the inference procedure also allows u to learn the parameter of a mrf with global connectivity potential by mean of a cutting plane algorithm we experimentally evaluate our algorithm on both synthetic data and on the challenging segmentation task of the pascal voc data set we show that in both case the addition of a connectedness prior significantly reduces the segmentation error 
in this paper we propose a framework that fuse multiple feature for improved action recognition in video the fusion of multiple feature is important for recognizing action a often a single feature based representation is not enough to capture the imaging variation view point illumination etc and attribute of individual size age gender etc hence we use two type of feature i a quantized vocabulary of local spatio temporal st volume or cuboid and ii a quantized vocabulary of spin image which aim to capture the shape deformation of the actor by considering action a d object x y t to optimally combine these feature we treat different feature a node in a graph where weighted edge between the node represent the strength of the relationship between entity the graph is then embedded into a k dimensional space subject to the criterion that similar node have euclidian coordinate which are closer to each other this is achieved by converting this constraint into a minimization problem whose solution is the eigenvectors of the graph laplacian matrix this procedure is known a fiedler embedding the performance of the proposed framework is tested on publicly available data set the result demonstrate that fusion of multiple feature help in achieving improved performance and allows retrieval of meaningful feature and video from the embedding space 
in this paper we wish to build a high quality database of image depicting scene along with their real world threedimensional d coordinate such a database is useful for a variety of application including training system for object detection and validation of d output we build such a database from image that have been annotated with only the identity of object and their spatial extent in image important for this task is the recovery of geometric information that is implicit in the object label such a qualtitative relationship between object attachment support occlusion and quantitative one inferring camera parameter we describe a model that integrates cue extracted from the object label to infer the implicit geometric information we show that we are able to obtain high quality d information by evaluating the proposed approach on a database obtained with a laser range scanner finally given the database of d scene we show how it can find better scene match for an unlabeled image by expanding the database through viewpoint interpolation to unseen view 
maintaining the stability of track on multiple target in video over extended time period remains a challenging problem a few method which have recently shown encouraging result in this direction rely on learning context model or the availability of training data however this may not be feasible in many application scenario moreover tracking method should be able to work across different scenario e g multiple resolution of the video making such context model hard to obtain in this paper we consider the problem of long term tracking in video in application domain where context information is not available a priori nor can it be learned online we build our solution on the hypothesis that most existing tracker can obtain reasonable short term track tracklets by analyzing the statistical property of these tracklets we develop association between them so a to come up with longer track this is achieved through a stochastic graph evolution step that considers the statistical property of individual tracklets a well a the statistic of the target along each proposed long term track on multiple real life video sequence spanning low and high resolution data we show the ability to accurately track over extended time period result are shown on many minute of continuous video 
in this paper we present a novel single image vignetting method based on the symmetric distribution of the radial gradient rg the radial gradient is the image gradient along the radial direction with respect to the image center we show that the rg distribution for natural image without vignetting is generally symmetric however this distribution is skewed by vignetting we develop two variant of this technique both of which remove vignetting by minimizing asymmetry of the rg distribution compared with prior approach to single image vignetting correction our method doe not require segmentation and the result are generally better experiment show our technique work for a wide range of image and it achieves a speed up of time compared with a state of the art method 
most of the recent work on image based object recognition and d reconstruction ha focused on improving the underlying algorithm in this paper we present a method to automatically improve the quality of the reference database which a we will show also affect recognition and reconstruction performance significantly starting out from a reference database of clustered image we expand small cluster this is done by exploiting cross medium information which allows for crawling of additional image for large cluster redundant information is removed by scene analysis we show how these technique make object recognition and d reconstruction both more efficient and more precise we observed up to improvement for the recognition task furthermore the method are completely data driven and fully automatic 
several object categorization algorithm use kernel method over multiple cue a they offer a principled approach to combine multiple cue and to obtain state of theart performance a general drawback of these strategy is the high computational cost during training that prevents their application to large scale problem they also do not provide theoretical guarantee on their convergence rate here we present a multiclass multi kernel learning mkl algorithm that obtains state of the art performance in a considerably lower training time we generalize the standardmklformulationtointroducea parameterthatallowsusto decidethelevelofsparsityof thesolution thanks to this new setting we can directly solve the problem in the primal formulation we prove theoretically and experimentally that our algorithm ha a faster convergence rate a the number of kernel grow the training complexity is linear in the number of training example very few iteration are enough to reach good solution experiment on three standard benchmark database support our claim 
this work deal with modeling and markerless tracking of athlete interacting with sport gear in contrast to classical markerless tracking the interaction with sport gear come along with joint movement restriction due to additional constraint while human can generally use all their joint interaction with the equipment imposes a coupling between certain joint a cyclist who performs a cycling pattern is one example the foot are supposed to stay on the pedal which are again restricted to move along a circular trajectory in d space in this paper we present a markerless motion capture system that take the lowerdimensional pose manifold into account by modeling the motion restriction via soft constraint during pose optimization experiment with two different model a cyclist and a snowboarder demonstrate the applicability of the method moreover we present motion capture result for challenging outdoor scene including shadow and strong illumination change 
many object have smooth surface of a fairly uniform color thereby exhibiting shading pattern that reveal information about it shape an important clue to the nature of the object this paper explores extracting this information from image by creating shape detector based on shading recent work ha derived low dimensional model of shading that can handle realistic unknown lighting condition and surface reflectance property we extend this theory by also incorporating variation in the surface shape in doing so it enables the creation of very general model for the d appearance of object not only coping with variation in illumination and brdf but also in shape alteration such a small scale and pose change using this framework we propose a scheme to build shading model that can be used for shape detection in a bottom up fashion without any a priori knowledge about the scene from the developed theory we construct detector for two basic shape primitive sphere and cylinder their performance is evaluated by extensive synthetic experiment a well a experiment on real image 
in this paper the problem of estimating automatically the symmetry plane of bilateral object having perfect or imperfect mirror symmetry in point cloud is reexamined classical method mostly based on the icp algorithm are shown to be limited and complicated by an inappropriate parameterization of the problem first we show how an adequate parameterization used in an icp like scheme can lead to a simpler more accurate and faster algorithm then using this parameterization we reinterpret the problem in a probabilistic framework and use the maximum likelihood principle to define the optimal symmetry plane this problem can be solved efficiently using an em algorithm the resulting iterative scheme can be seen a an icp like algorithm with multiple match between the two side of the object this new algorithm implemented using a multiscale multiresolution approach is evaluated in term of accuracy robustness and speed on ground truth data and some result on real data are presented 
local expertshave beenusedto great effect forfittingdeformable model to image typically the best location in an image for the deformable model s landmark are found through a locally exhaustive search using these expert in order to achieve efficient fitting these expert should afford an efficient evaluation which often lead to form with restricted discriminative capacity in this work a framework is proposed in which multiple simple expert can be utilized to increase the capacity of the detection overall in particular the use of a mixture of linear classifier is proposed the computational complexity of which scale linearly with the number of mixture component the fitting objective is maximized using the expectation maximization em algorithm where approximation to the true objective are made in order to facilitate efficient and numerically stable fitting the efficacy of the proposed approach is evaluated on the task of generic face fitting where performance improvement is observed over two existing method 
magnetic resonance imaging mri is currently the gold standard for left ventricle lv quantification detection of the lv in an mri image is a prerequisite for functional measurement however due to the large variation in the orientation size shape and image intensity of the lv automatic lv detection is challenging in this paper we propose to use marginal space learning msl to exploit the recent advance in learning discriminative classifier unlike full space learning fsl where a monolithic classifier is trained directly in the five dimensional object pose space two for position one for rotation and two for anisotropic scaling we train three detector namely the position detector the position orientation detector and the position orientation scale detector a a contribution of this paper we perform thorough comparison between msl and fsl experiment show msl significantly outperforms fsl on both the training and test set additionally we also detect several lv landmark such a the lv apex and two annulus point if we combine the detected candidate from both the whole object detector and landmark detector we can further improve the system robustness even when one detector fails a novel ranking based strategy is proposed to combine the detected candidate from all detector experiment show our ranking based aggregation approach can significantly reduce the detection outlier 
we present a method to fully automatically fit video in format on screen and vice versa it can be applied to arbitrary aspect ratio and can be used to make video suitable for mobile viewing device with small and possibly uncommonly sized display the cropping sequence is optimised over time to create smooth transition and thus lead to an excellent viewing experience current television have simple and often disturbing method which either show the centre region of the image distort the image or pad it with black border the technique presented here can fully automatically find the right viewing area for each image in a video sequence it work in real time with only very little time shift we employ different low level feature and a loglinear model to learn how to find the right area the method is able to automatically decide whether padding with black border is necessary or whether all relevant image area fit on screen by cropping the image evaluation is done on ten video from five different type of content and the baseline method are clearly outperformed 
we describe a novel and robust feature descriptor called ordinal spatial intensity distribution osid which is invariant to any monotonically increasing brightness change many traditional feature are invariant to intensity shift or affine brightness change but cannot handle more complex nonlinear brightness change which often occur due to the nonlinear camera response variation in capture device parameter temporal change in the illumination and viewpoint dependent illumination and shadowing a configuration of spatial patch sub division is defined and the descriptor is obtained by computing a d histogram in the intensity ordering and spatial sub division space extensive experiment show that the proposed descriptor significantly outperforms many state of the art descriptor such a sift gloh and pca sift under complex brightness change moreover the experiment demonstrate the proposed descriptor s superior performance even in the presence of image blur viewpoint change and jpeg compression the proposed descriptor ha far reaching implication for many application in computer vision including motion estimation object tracking recognition image classification retrieval d reconstruction and stereo 
we present a new unsupervised method to learn unified probabilistic object model pom which can be applied to classification segmentation and recognition we formulate this a a structure learning task and our strategy is to learn and combine basic pom s that make use of complementary image cue each pom ha algorithm for inference and parameter learning but i the structure of each pom is unknown and ii the inference and parameter learning algorithm for a pom may be impractical without additional information we address these problem by a novel structure induction procedure which us knowledge propagation to enable pom s to provide information to other pom s and teach them which greatly reduced the amount of supervision required for training in particular we learn a pom ip defined on interest point using weak supervision and use this to train a pommask definedon regionalfeatures which yield a combined pom which performs segmentation localization this combined model can be used to train pom edgelets defined on edgelets which give a full pom with improved performance on classification we give detailed experimental analysis on large datasets which show that the full pom is invariant to scale and rotation of the object for learning and inference and performs inference rapidly in addition we show that we can apply pom s to learn object class i e when there are several object and the identity of the object in each image is unknown we emphasize that these model can match between different object from the same category and hence enable object recognition 
when rotating a pinhole camera image are related by the infinite homography krk which is algebraically a conjugate rotation although being a very common image transformation e g important for self calibration or panoramic image mosaicing it is not completely understood yet we show that a conjugate rotation ha degree of freedom a opposed to for a general homography and give a minimal parameterization to estimate the conjugate rotation author traditionally made use of point correspondence which can be seen a local zero order taylor approximation to the image transformation recently however affine feature correspondence have become increasingly popular we observe that each such affine correspondence now provides a local first order taylor approximation which ha not been exploited in the context of geometry estimation before using those two novel concept above we finally show that it is possible to estimate a conjugate rotation from a single affine feature correspondence under the assumption of square pixel and zero skew a a byproduct the proposed algorithm directly yield rotation focal length and principal point 
much research effort on automatic image annotation aia ha been focused on generative model due to it well formed theory and competitive performance a compared with many well designed and sophisticated method however when considering semantic context for annotation the model suffers from the weak learning ability this is mainly due to the lack of parameter setting and appropriate learning strategy for characterizing the semantic context in the traditional generative model in this paper we present a new approach based on multiple markov random field mrf for semantic context modeling and learning differing from previous mrf related aia approach we explore the optimal parameter estimation and model inference systematically to leverage the learning power of traditional generative model specifically we propose new potential function for site modeling based on generative model and build local graph for each annotation keyword the parameter estimation and model inference is performed in local optimal sense we conduct experiment on commonly used benchmark on corel image we achieved and in recall and precision respectively on keywords this is a very significant improvement over the best reported result of the current state of the art approach 
d acquisition technique to measure dynamic scene and deformable object with little texture are extensively researched for application like the motion capturing of human facial expression to allow such measurement several technique using structured light have been proposed these technique can be largely categorized into two type the first involves technique to temporally encode positional information of a projector s pixel using multiple projected pattern and the second involves technique to spatially encode positional information into area or color space although the former allows dense reconstruction with a sufficient number of pattern it ha difficulty in scanning object in rapid motion the latter technique us only a single pattern so this problem can be resolved however it often us complex pattern or color intensity which are weak to noise shape distortion or texture thus it remains an open problem to achieve dense and stable d acquisition in real case in this paper we propose a technique to achieve dense shape reconstruction that requires only a single frame image of a grid pattern the proposed technique also ha the advantage of being robust in term of image processing 
this paper discus the question can we improve the recognition of object by using their spatial context we start from bag of word model and use the pascal dataset we use the rough object bounding box that come with this dataset to investigate the fundamental gain context can bring our main contribution are i the result of zhang et al in cvpr that context is superfluous derived from the pascal data set of class doe not generalize to this dataset for our larger and more realistic dataset context is important indeed ii using the rough bounding box to limit or extend the scope of an object during both training and testing we find that the spatial extent of an object is determined by it category a well defined rigid object have the object itself a the preferred spatial extent b non rigid object have an unbounded spatial extent all spatial extent produce equally good result c object primarily categorised based on their function have the whole image a their spatial extent finally iii using the rough bounding box to treat object and context separately we find that the upper bound of improvement is absolute in term of mean average precision and this bound is likely to be higher if the localisation is done using segmentation it is concluded that object localisation if done sufficiently precise help considerably in the recognition of object for the pascal dataset 
detection of visually salient image region is useful for application like object segmentation adaptive compression and object recognition in this paper we introduce a method for salient region detection that output full resolution saliency map with well defined boundary of salient object these boundary are preserved by retaining substantially more frequency content from the original image than other existing technique our method exploit feature of color and luminance is simple to implement and is computationally efficient we compare our algorithm to five state of the art salient region detection method with a frequency domain analysis ground truth and a salient object segmentation application our method outperforms the five algorithm both on the ground truth evaluation and on the segmentation task by achieving both higher precision and better recall 
segmentation ha gained in popularity in stereo matching however it is not trivial to incorporate it in optical flow estimation due to the possible non rigid motion problem in this paper we describe a new optical flow scheme containing three phase first we partition the input image and integrate the segmentation information into a variational model where each of the segment is constrained by an affine motion then the error brought in by segmentation are measured and stored in a confidence map the final flow estimation is achieved through a global optimization phase that minimizes an energy function incorporating the confidence map extensive experiment show that the proposed method not only produce quantitatively accurate optical flow estimate but also preserve sharp motion boundary which make the optical flow result usable in a number of computer vision application such a image video segmentation and editing 
sparse representation ha found application in numerous domain and recent development have been focused on the convex relaxation of the lo norm minimization for sparse coding i e the norm minimization nevertheless the time and space complexity of these algorithm remain significantly high for large scale problem a signal in most problem can be modeled by a small set of prototype we propose an algorithm that exploit this property and show that the norm minimization problem can be reduced to a much smaller problem thereby gaining significant speed ups with much le memory requirement experimental result demonstrate that our algorithm is able to achieve double digit gain in speed with much le memory requirement than the state of the art algorithm 
classification of image in many category datasets ha rapidly improved in recent year however system that perform well on particular datasets typically have one or more limitation such a a failure to generalize across visual task e g requiring a face detector or extensive retuning of parameter insufficient translation invariance inability to cope with partial view and occlusion or significant performance degradation a the number of class is increased here we attempt to overcome these challenge using a model that combine sequential visual attention using fixation with sparse coding the model s biologically inspired filter are acquired using unsupervised learning applied to natural image patch using only a single feature type our approach achieves accuracy on caltech and on the flower dataset when trained on instance per class and it achieves accuracy on the ar face database with training instance per person the same feature and parameter are used across these datasets to illustrate it robust performance 
in this paper we present a combined approach for object localization and classification our contribution is twofold a a contextual combination of localization and classification which show that classification can improve detection and vice versa b an efficient two stage sliding window object localization method that combine the efficiency of a linear classifier with the robustness of a sophisticated non linear one experimental result evaluate the parameter of our two stage sliding window approach and show that our combined object localization and classification method outperform the state of the art on the pascal voc and datasets 
in this paper we present a hierarchical learning based approach for automatic and accurate liver segmentation from d ct volume we target ct volume that come from largely diverse source e g diseased in six different organ and are generated by different scanning protocol e g contrast and non contrast various resolution and position three key ingredient are combined to solve the segmentation problem first a hierarchical framework is used to efficiently and effectively monitor the accuracy propagation in a coarse to fine fashion second two new learning technique marginal space learning and steerable feature are applied for robust boundary inference this enables handling of highly heterogeneous texture pattern third a novel shape space initialization is proposed to improve traditional method that are limited to similarity transformation the proposed approach is tested on a challenging dataset containing volume our approach not only produce excellent segmentation accuracy but also run about fifty time faster than state of the art solution 
compressed sensing an emerging multidisciplinary field involving mathematics probability optimization and signal processing focus on reconstructing an unknown signal from a very limited number of sample because information such a boundary of organ is very sparse in most mr image compressed sensing make it possible to reconstruct the same mr image from a very limited set of measurement significantly reducing the mri scan duration in order to do that however one ha to solve the difficult problem of minimizing nonsmooth function on large data set to handle this we propose an efficient algorithm that jointly minimizes the lscr norm total variation and a least square measure one of the most powerful model for compressive mr imaging our algorithm is based upon an iterative operator splitting framework the calculation are accelerated by continuation and take advantage of fast wavelet and fourier transforms enabling our code to process mr image from actual real life application we show that faithful mr image can be reconstructed from a subset that represents a mere percent of the complete set of measurement 
this paper investigates ordinal image description for invariant feature correspondence ordinal description is a meta technique which considers image measurement in term of their rank in a sorted array instead of the measurement value themselves rank ordering normalizes descriptor in a manner invariant under monotonic deformation of the underlying image measurement and therefore serf a a simple non parametric substitute for ad hoc scaling and thresholding technique currently used ordinal description is particularly well suited for invariant feature a the high dimensionality of state of the art descriptor permit a large number of unique rank ordering and the computationallycomplex step of sorting is only required once after geometrical normalization correspondence trial based on a benchmark data set show that in general rank ordered sift sift rank descriptor outperform otherstate of the artdescriptorsin term of precisionrecall including standard sift and gloh 
we present a dense d correspondence finding method that enables spatio temporally coherent reconstruction of surface animation from multi view video data given a input a sequence of shape from silhouette volume of a moving subject that were reconstructed for each time frame individually our method establishes dense surface correspondence between subsequent shape independently of surface discretization this is achieved in two step first we obtain sparse correspondence from robust optical feature between adjacent frame second we generate dense correspondence which serve a map between respective surface by applying this procedure subsequently to all pair of time step we can trivially align one shape with all others thus the original input can be reconstructed a a sequence of mesh with constant connectivity and small tangential distortion we exemplify the performance and accuracy of our method using several synthetic and captured real world sequence 
we present a fast and robust system for estimating structure and motion using a stereo pair with straight line a feature our first set of contribution are efficient algorithm to perform this estimation using a few two or three line which are well suited for use in a hypothesize and test framework our second contribution is the design of an efficient structure from motion system that performs robustly in complex indoor environment by using infinite line rather than line segment our approach avoids the issue arising due to uncertain determination of end point our cost function stem from a rank condition on plane backprojected from corresponding image line we propose a framework that imposes orthonormality constraint on the rigid body motion and can perform estimation using only two or three line through efficient solution of an overdetermined system of polynomial this is in contrast to simple approach which first reconstruct d line and then align them but perform poorly in real world scene with narrow baseline stereo experiment using synthetic a well a real data demonstrate the speed accuracy and reliability of our system 
feature misalignment in object detection refers to the phenomenon that feature which r e up in some positive detection window do not r e up in other positive detection window most often it is caused by pose variation and local part deformation previous work either totally ignores this issue or naively performs a local exhaustive search to better position each feature we propose a learning framework to mitigate this problem where a boosting algorithm is performed to seed the position of the object part and a multiple instance boosting algorithm further pursues an aggregated feature for this part namely multiple instance feature unlike most previous boosting based object detector where each feature value produce a single classic ation result the value of the proposed multiple instance feature is the noisy or integration of a bag of classic ation result our approach is applied to the task of human detection and is tested on two popular benchmark the proposed approach brings signic ant improvement in performance i e smaller number of feature used in the cascade and better detection accuracy 
visual attention is an important issue in image and video analysis and keep being an open problem in the computer vision field motivated by the famous helmholtz principle a new approach of visual attention analysis is proposed in this paper based on the low level feature statistic of natural image and the bayesian framework firstly two prior i e surrounding feature prior sfp and single feature probability distribution sfpd are learned and integrated by a bayesian framework to compute the chance of happening coh of each pixel in an image then another prior i e center bias prior cbp is learned and applied to the coh to compute the saliency map of the image the experimental result demonstrate that the proposed approach is both effective and efficient by providing more accurate and quick visual attention location we make three major contribution in this paper a set of simple but powerful prior sfp sfpd and cbp are presented in an intuitive way a computational model of coh based on bayesian framework is given to integrate sfp and sfpd together a computationally plausible way to obtain the saliency map of natural image based on coh and cbp 
subspace segmentation is the task of segmenting data lying on multiple linear subspace it application in computer vision include motion segmentation in video structure from motion and image clustering in this work we describe a novel approach for subspace segmentation that us probabilistic inference via a message passing algorithm we cast the subspace segmentation problem a that of choosing the best subset of linear subspace from a set of candidate subspace constructed from the data under this formulation subspace segmentation reduces tofacility location a well studied operational research problem approximate solution to this np hard optimization problem can be found by performing maximum a posteriori map inference in a probabilistic graphical model we describe the graphical model and a message passing inference algorithm 
we introduce the patch transform where an image is broken into non overlapping patch and modification or constraint are applied in the patch domain a modified image is then reconstructed from the patch subject to those constraint when no constraint are given the reconstruction problem reduces to solving a jigsaw puzzle constraint the user may specify include the spatial location of patch the size of the output image or the pool of patch from which an image is reconstructed we define term in a markov network to specify a good image reconstructionfrom patch neighboringpatchesmustfit to form a plausibleimage and eachpatchshouldbe usedonly once we find an approximate solution to the markov network using loopy belief propagation introducing an approximation to handle the combinatorially difficult patch exclusion constraint the resulting image reconstruction show the original image modified to respect the user s change we apply the patchtransform to various image editing task and show that the algorithm performs well on real world image 
a novel parametric deformable model of a goal object controlled by shape and appearance prior learned from co aligned training image is introduced the shape prior is built in a linear space of vector of distance to the training boundary from their common centroid the appearance prior is modeled with a spatially homogeneous nd order markov gibbs random field mgrf of gray level within each training boundary geometric structure of the mgrf and gibbs potential are analytically estimated from the training data to accurately separate goal object from arbitrary background the deformable model is evolved by solving an eikonal partial differential equation with a speed function combining the shape and appearance prior and the current appearance model the latter represents empirical gray level marginals inside and outside an evolving boundary with adaptive linear combination of discrete gaussians lcdg the analytical shape and appearance prior and a simple expectation maximization procedure for getting the object and background lcdgs make our segmentation considerably faster than most of the known counterpart experiment with various image confirm robustness accuracy and speed of our approach 
we propose a novel approach for activity analysis in multiple synchronized but uncalibrated static camera view we assume that the topology of camera view is unknown and quite arbitrary the field of view covered by these camera may have no overlap or any amount of overlap and object may move on different ground plane using low level cue object are tracked in each of the camera view independently and the position and velocity of object along trajectory are computed a feature under a generative model our approach jointly learns the distribution of an activity in the feature space of different camera view it accomplishes two task grouping trajectory in different camera view belonging to the same activity into one cluster modeling path commonly taken by object across camera view to our knowledge no prior result of co clustering trajectory in multiple camera view ha been published advantage of this approach are that it doe not require first solving the challenging correspondence problem and the learning is unsupervised our approach is evaluated on two very large data set with and trajectory 
widespread use of surveillance camera in office and other business establishment pose a significant threat to the privacy of the employee and visitor the challenge of introducingprivacy and security in such a practical surveillance system ha been stifled by the enormous computational and communication overhead required by the solution in this paper we propose an efficient framework to carry out privacy preserving surveillance we split each frame into a set of random image each image by itself doe not conveyany meaningful information about the original frame while collectively they retain all the information our solution is derived from a secret sharing scheme basedonthe chinese remaindertheorem suitablyadapted to image data our method enables distributed secure processing and storage while retaining the ability to reconstruct the original data in case of a legal requirement the system installed in an office like environment can effectively detect and track people or solve similar surveillance task our proposed paradigm is highly efficient compared to secure multiparty computation making privacy preserving surveillance practical 
high level generative model provide elegant description of video and are commonly used a the inference framework in many unsupervised motion segmentation scheme however approximate inference in these model often require ad hoc initialization to avoid local minimum issue low level cue obtained independently from the highlevel model can constrain the search space and reduce the chance of inference algorithm falling into a local minimum this paper introduces a novel principled fusion framework where local hierarchical superpixels segmentation of image are used to capture local motion the low level cue such a local motion on their own not adequate to obtain full motion segmentation a occlusion need to be handled globally we fuse the low level motion cue with the highlevel model in a principled manner to surmount the shortcoming of using only the high level model or low level cue to perform motion segmentation the fused model contains both continuous and discrete variable which form a number of markov random field variational approximation or belief propagation algorithm cannot be applied due to the complex interaction between the variable hence approximate inference is performed using expectation propagation ep algorithm the scheme is demonstrated by performing motion segmentation in two video sequence 
active learning ha been shown a a key technique for improving content based image retrieval cbir performance among various method support vector machine svm active learning is popular for it application to relevance feedback in cbir however the regular svm active learning ha two main drawback when used for relevance feedback first svm often suffers from learning with a small number of labeled example which is the case in relevance feedback second svm active learning usually doe not take into account the redundancy among example and therefore could select multiple example in relevance feedback that are similar or even identical to each other in this paper we propose a novel scheme that exploit both semi supervised kernel learning and batch mode active learning for relevance feedback in cbir in particular a kernel function is first learned from a mixture of labeled and unlabeled example the kernel will then be used to effectively identify the informative and diverse example for active learning via a min max framework an empirical study with relevance feedback of cbir showed that the proposed scheme is significantly more effective than other state of the art approach 
we propose a new template based approach for view invariant recognition of body pose based on geometric constraint derived from the motion of body point triplet in addition to spatial information our template encode temporal information of body pose transition unlike existing method that study a body pose a a whole we decompose it into a number of body point triplet and compare their motion to our template using the fact that the homography induced by the motion of a triplet of body point in two identical body pose transition reduces to the special case of a homology we exploit the equality of two of it eigenvalue to impose constraint on the similarity of the pose transition between two subject observed by different perspective camera and from different viewpoint extensive experimental result show that our method can accurately identify human pose from video sequence when they are observed from totally different viewpoint with different camera parameter 
we observe that everyday image contain dozen of object and that human in describing these image give different priority to these object we argue that a goal of visual recognition is therefore not only to detect and classify object but also to associate with each a level of priority which we call importance we propose a definition of importance and show how this may be estimated reliably from data harvested from human observer we conclude by showing that a first order estimate of importance may be computed from a number of simple image region measurement and doe not require access to image meaning 
treating visual object tracking a foreground and background classification problem ha attracted much attention in the past decade most method adopt mean shift or brute force search to perform object tracking on the generated probability map which is obtained from the classification result however performing probabilistic object tracking on the probability map is almost unexplored this paper proposes a novel observation model which is suitable to perform this task the observation model considers both region and boundary cue on the probability map and can be computed very efficiently by using the integral image data structure extensive experiment are carried out on several challenging image sequence which include abrupt motion change background clutter partial occlusion and significant appearance change quantitative experiment are further performed with several related tracker on a public benchmark dataset the experimental result demonstrate the effectiveness of the proposed approach 
image matting is of great importance in both computer vision and graphic application most existing state of the art technique rely on large sparse matrix such a the matting laplacian however solving these linear system is often time consuming which is unfavored for the user interaction in this paper we propose a fast method for high quality matting we first derive an efficient algorithm to solve a large kernel matting laplacian a large kernel propagates information more quickly and may improve the matte quality to further reduce running time we also use adaptive kernel size by a kd tree trimap segmentation technique a variety of experiment show that our algorithm provides high quality result and is to time faster than previous method 
accurately identifying corresponded landmark from a population of shape instance is the major challenge in constructing statistical shape model in general shapecorrespondence method can be grouped into one of two category global method and pair wise method in this paper we develop a new method that attempt to address the limitation of both the global and pair wise method in particular we reorganize the input population into a tree structure that incorporates global information about the population of shape instance where each node in the tree represents a shape instance and each edge connects two very similar shape instance using this organized tree neighboring shape instance can be corresponded efficiently and accurately by a pair wise method in the experiment we evaluate the proposed method and compare it performance to five available shape correspondence method and show the proposed method achieves the accuracy of a global method with speed of a pair wise method 
this paper describes how phase sensitive rotation invariant for three dimensional data may be obtained a bispectrum is formulated for rotation and it property are derived for spherical harmonic coefficient a well a for moment the bispectral invariant offer improved discrimination over previously published magnitude only invariant they are able to distinguish rotation from reflection a well a rotation of an entire shape from component wise rotation of element of the shape a experiment show they provide robust performance for both surface and voxel data 
many computer vision problem rely on computing histogram based objective function with a sliding window a main limiting factor is the high computational cost existing computational method have a complexity linear in the histogram dimension in this paper we propose an efficient method that ha a constant complexity in the histogram dimension and therefore scale well with high dimensional histogram this is achieved by harnessing the spatial coherence of natural image and computing the objective function in an incremental manner we demonstrate the significant performance enhancement by our method through important vision task including object detection object tracking and image saliency analysis compared with stateof the art technique our method typically achieves from ten to hundred of time speedup for those task 
we develop a novel method for extracting graph characteristic from edge weighted graph based on an extension of the ihara zeta function from unweighted to edge weighted graph this is effected by generalizing the determinant form of the ihara zeta function we use the set of the reciprocal polynomial coefficient of the resulting ihara zeta function i e the ihara coefficient to construct our characterization we also present a spectral analysis of the edge weighted graph ihara coefficient and indicate their advantage over graph spectral method experimental result reveal that the ihara coefficient are effective for the purpose of clustering edge weighted graph 
face recognition degrades when face are of very low resolution since many detail about the difference between one person and another can only be captured in image of sufficient resolution in this work we propose a new procedure for recognition of low resolution face when there is a high resolution training set available most previous super resolution approach are aimed at reconstruction with recognition only a an after thought in contrast in the proposed method face feature a they would be extracted for a face recognition algorithm e g eigenfaces fisherfaces etc are included in a super resolution method a prior information this approach simultaneously provides measure of fit of the super resolution result from both reconstruction and recognition perspective this is different from the conventional paradigm of matching in a low resolution domain or alternatively applying a superresolution algorithm to a low resolution face and then classifying the super resolution result we show for example that recognition of face of a low a pixel size is considerably improved compared to matching using a superresolution reconstruction followed by classification and to matching with a low resolution training set 
we address the problem of parameter estimation in presence of both uncertainty and outlier noise this is a common occurrence in computer vision feature localization is performed with an inherent uncertainty which can be described a gaussian with unknown variance feature matching in multiple image produce incorrect data point ransac is the preferred method to reject outlier if the variance of the uncertainty noise is known but fails otherwise by producing either a tight fit to an incorrect solution or by computing a solution which includes outlier we thus propose a new estimator which enforces stability of the solution with respect to the uncertainty bound we show that the variance of the estimated parameter vop exhibit range of stability with respect to this bound within this range of stability we can accurately segment the inliers and estimate the parameter the variance of the gaussian noise we show how to compute this stable range using ransac and a search we validate our result by extensive test and comparison with state of the art estimator on both synthetic and real data set these include line fitting homography estimation and fundamental matrix estimation the proposed method outperforms all others 
we propose a joint representation and classification framework that achieves the dual goal of finding the most discriminative sparse overcomplete encoding and optimal classifier parameter formulating an optimization problem that combine the objective function of the classification with the representation error of both labeled and unlabeled data constrained by sparsity we propose an algorithm that alternate between solving for subset of parameter whilst preserving the sparsity the method is then evaluated over two important classification problem in computer vision object categorization of natural image using the caltech database and face recognition using the extended yale b face database the result show that the proposed method is competitive against other recently proposed sparse overcomplete counterpart and considerably outperforms many recently proposed face recognition technique when the number training sample is small 
it is a challenging vision problem to discover non rigid shape deformation for an image ensemble belonging to a single object class in an automatic or semi supervised fashion the conventional semi supervised approach us a congealing like process to propagate manual landmark label from a few image to a large ensemble although effective on an inter person database with a large population there is potential for increased labeling accuracy with the goal of providing highly accurate label in this paper we present a parametric curve representation for each of the seven major facial contour the appearance information along the curve named curve descriptor is extracted and used for congealing furthermore we demonstrate that advanced feature such a histogram of oriented gradient hog can be utilized in the proposed congealing framework which operates in a dual curve congealing manner for the case of a closed contour with extensive experiment on a image ensemble that exhibit moderate variation in facial pose and shape we show that substantial progress ha been achieved in the labeling accuracy compared to the previous state of the art approach 
many object detection system rely on linear classifier embedded in a sliding window scheme such exhaustive search involves massive computation efficient subwindow search es avoids this by mean of branch and bound however es make an unfavourable memory tradeoff memory usage scale with both image size and overall object model size this risk becoming prohibitive in a multiclass 
the goal of image categorization is to classify a collection of unlabeled image into a set of predefined class to support semantic level image retrieval the distance measure used in most existing approach either ignored the spatial structure or used them in a separate step a a result these distance measure achieved only limited succes s to address these difficulty in this paper we propose a new distance measure that integrates joint appearance spatia l image feature such a distance measure is computed a an upper bound of an information theoretic discrimination and can be computed efficiently in a recursive formulation that scale well to image size in addition the upper bound approximation can be further tightened via adaption learning from a universal reference model extensive experiment on two widely used data set show that the proposed approach significantly outperforms the state of the art a pproaches 
given a single outdoor image we present a method for estimating the likely illumination condition of the scene in particular we compute the probability distribution over the sun position and visibility the method relies on a combination of weak cue that can be extracted from different portion of the image the sky the vertical surface and the ground while no single cue can reliably estimate illumination by itself each one can reinforce the others to yield a more robust estimate this is combined with a data driven prior computed over a dataset of million internet photo we present quantitative result on a webcam dataset with annotated sun position a well a qualitative result on consumer grade photograph downloaded from internet based on the estimated illumination we show how to realistically insert synthetic d object into the scene 
we propose a geometric method for visual tracking in which the d affine motion of a given object template is estimated in a video sequence by mean of coordinateinvariant particle filtering on the d affine group aff tracking performance is further enhanced through a geometrically defined optimal importance function obtained explicitly via taylor expansion of a principal component analysis based measurement function on aff the efficiency of our approach to tracking is demonstrated via comparative experiment 
this paper present a new stereo matching algorithm based on inter regional cooperative optimization the proposed algorithm us region a matching primitive and defines the corresponding region energy functional for matching by utilizing the color statistic of region and the constraint on smoothness and occlusion between adjacent region in order to obtain a more reasonable disparity map a cooperative optimization procedure ha been employed to minimize the matching cost of all region by introducing the cooperative and competitive mechanism between region firstly a color based segmentation method is used to segment the reference image into region with homogeneous color secondly a local window based matching method is used to determine the initial disparity estimate of each image pixel and then a voting based plane fitting technique is applied to obtain the parameter of disparity plane corresponding to each image region finally the disparity plane parameter of all region are iteratively optimized by an inter regional cooperative optimization procedure until a reasonable disparity map is obtained the experimental result on middlebury test set and real stereo image indicate that the performance of our method is competitive with the best stereo matching algorithm and the disparity map recovered are close to the ground truth data 
we present a latent hierarchical structural learning method for object detection an object is represented by a mixture of hierarchical tree model where the node represent object part the node can move spatially to allow both local and global shape deformation the model can be trained discriminatively using latent structural svm learning where the latent variable are the node position and the mixture component but current learning method are slow due to the large number of parameter and latent variable and have been restricted to hierarchy with two layer in this paper we describe an incremental concave convex procedure icccp which allows u to learn both two and three layer model efficiently we show that icccp lead to a simple training algorithm which avoids complex multi stage layer wise training careful part selection and achieves good performance without requiring elaborate initialization we perform object detection using our learnt model and obtain performance comparable with state of the art method when evaluated on challenging public pascal datasets we demonstrate the advantage of three layer hierarchy outperforming felzenszwalb et al s two layer model on all class 
we present an extensive evaluation of confidence metric for stereo matching that compare the most widely used metric a well a four novel technique proposed here we begin by categorizing the method according to which aspect of stereo computation they take into account and then ass their strength and weakness the evaluation is conducted on indoor and outdoor datasets with ground truth and measure the capability of each confidence metric to rank depth estimate according to their likelihood for being correct to detect occluded pixel and to generate low error depth map by selecting among multiple hypothesis for each pixel we believe that such an evaluation is missing from the rapidly maturing stereo literature and that our finding will be helpful to researcher in binocular and multi view stereo 
many semi supervised learning algorithm only deal with binary classification their extension to the multi class problem is usually obtained by repeatedly solving a set of binary problem additionally many of these method do not scale very well with respect to a large number of unlabeled sample which limit their application to large scale problem with many class and unlabeled sample in this paper we directly address the multi class semi supervised learning problem by an efficient boosting method in particular we introduce a new multi class margin maximizing loss function for the unlabeled data and use the generalized expectation regularization for incorporating cluster prior into the model our approach enables efficient usage of very large data set the performance and efficiency of our method is demonstrated on both standard machine learning data set a well a on challenging object categorization task 
we consider the least square l triangulation problem and structure and motion with known rotatation or known plane although optimal algorithm have been given for these algorithm under an l infinity cost function finding optimal least square l solution to these problem is difficult since the cost function are not convex and in the worst case can have multiple minimum iterative method can usually be used to find a good solution but this may be a local minimum this paper provides a method for verifying whether a local minimum solution is globally optimal by providing a simple and rapid test involving the hessian of the cost function in test of a data set involving independent triangulation problem it is shown that the test verifies the global optimality of an iterative solution in over of the case 
we present method for training high quality object detector very quickly the core contribution is a pair of fast training algorithm for piece wise linear classifier which can approximate arbitrary additive model the classifier are trained in a max margin framework and significantly outperform linear classifier on a variety of vision datasets we report experimental result quantifying training time and accuracy on image classification task and pedestrian detection including detection result better than the best previous on the inria dataset with faster training 
to correctly estimate the camera motion parameter and reconstruct the structure of the surrounding tissue from endoscopic image sequence we need not only to deal with outlier e g mismatch which may involve more than of the data but also to accurately distinguish inliers correct match from outlier in this paper we propose a new robust estimator adaptive scale kernel consensus askc which can tolerate more than percent outlier while automatically estimating the scale of inliers with askc we develop a reliable feature tracking algorithm this in turn allows u to develop a complete system for estimating endoscopic camera motion and reconstructing anatomical structure from endoscopic image sequence preliminary experiment on endoscopic sinus imagery have achieved promising result 
seeded image segmentation is a popular type of supervised image segmentation in computer vision and image processing previous method of seeded image segmentation treat the image a a weighted graph and minimize an energy function on the graph to produce a segmentation in this paper we propose to conduct the seeded image segmentation according to the result of a heat diffusion process in which the seeded pixel are considered to be the heat source and the heat diffuses on the image starting from the source after the diffusion reach a stable state the image is segmented based on the pixel temperature it is also shown that our proposed framework includes the randomwalk algorithm for image segmentation a a special case which diffuses only along the two coordinate ax to better control diffusion we propose to incorporate the attribute such a the geometric structure of the image into the diffusion process yielding an anisotropic diffusion method for image segmentation the experiment show that the proposed anisotropic diffusion method usually produce better segmentation result in particular when the method is tested using the groundtruth dataset of microsoft research cambridge msrc an error rate of can be achieved which is lower than the reported error rate of other state of the art algorithm 
this work present a discriminative training method for particle filter in the context of multi object tracking we are motivated by the difficulty of hand tuning the many model parameter for such application and also by result in many application domain indicating that discriminative training is often superior to generative training method our learning approach is tightly integrated into the actual inference process of the filter and attempt to directly optimize the filter parameter in response to observed error we present experimental result in the challenging domain of american football where our filter is trained to track all player throughout football play the training method is shown to significantly improve performance of the tracker and to significantly outperform two recent particle based multi object tracking method 
we use spectral analysis to facilitate gaussian process gp classification our solution provides two improvement scaling of the data to achieve a more isotropic nature a well a a method to choose the kernel to match certain data characteristic given the dataset from the fourier transform of the training data we compare the frequency domain feature of each dimension to estimate a rescaling towards making the data isotropic also the spectrum of the training data is compared with several candidate kernel spectrum from this comparison the best matching kernel is chosen in these way the training data match better the gp classification kernel function and hence the underlying assumed correlation characteristic resulting in a better gp classification result test result on both non image and image data show the efficiency and effectiveness of our approach 
time of flight range sensor have error characteristic which are complementary to passive stereo they provide real time depth estimate in condition where passive stereo doe not work well such a on white wall in contrast these sensor are noisy and often perform poorly on the textured scene for which stereo excels we introduce a method for combining the result from both method that performs better than either alone a depth probability distribution function from each method is calculated and then merged in addition stereo method have long used global method such a belief propagation and graph cut to improve result and we apply these method to this sensor since time of flight device have primarily been used a individual sensor they are typically poorly calibrated we introduce a method that substantially improves upon the manufacturer s calibration we show that these technique lead to improved accuracy and robustness 
abstract study support the need for high resolution imagery to identify person in surveillance video however the use of telephoto lens sacrifice a wider field of view and thereby increase the uncertainty of other possibly more interesting event in the scene using zoom lens offer the possibility of enjoying the benefit of both wide field of view and high resolution but not simultaneously we approach this problem of balancing these finite imaging resource or of exploration v exploitation using an informationtheoretic approach we argue that the camera parameter pan tilt and zoom should be set to maximise information gain or equivalently minimising conditional entropy of the scene model comprised of multiple target and a yet unobserved one the information content of the former is supplied directly by the uncertainty computed using a kalman filter tracker while the latter is modelled using a background poisson process whose parameter are learned from extended scene observation together these yield an entropy for the scene we support our argument with quantitative and qualitative analysis in simulated and real world environment demonstrating that this approach yield sensible exploration behaviour in which the camera alternate between obtaining close up view of the target while paying attention to the background especially to area of known high activity 
recovering the three dimensional d object shape remains an unresolved area of research on the cross section of computer vision photogrammetry and bioinformatics although various technique have been developed the computational complexity and the constraint introduced to overcome the problem have limited their applicability in the real world scenario in this paper we propose a method that is based on the projective geometry between the object space and the silhouette image taken from multiple view point the approach eliminates the problem related to dense feature point matching and camera calibration that are generally adopted by many state of the art shape reconstruction method the object shape is reconstructed by establishing a set of hypothetical plane slicing the object volume and estimating the projective geometric relation between the image of these plane the experimental result show that the d object shape can be recovered by applying minimal constraint 
in recent year d deformable surface reconstruction from single image ha attracted renewed interest it ha been shown that preventing the surface from either shrinking or stretching is an effective way to resolve the ambiguity inherent to this problem however while the geodesic distance on the surface may not change the euclidean one decrease when fold appear therefore when applied to discrete surface representation such constant distance constraint are only effective for smoothly deforming surface and become inaccurate for more e xible one that can exhibit sharp fold in such case surface point must be allowed to come closer to each other in this paper we show that replacing the equality constraint of earlier approach by inequality constraint that let the mesh representation of the surface shrink but not expand yield not only a more faithful representation but also a convex formulation of the reconstruction problem a a result we can accurately reconstruct surface undergoing complex deformation that include sharp fold from individual image 
in this paper we present a new framework for non rigid structure from motion nrsfm that simultaneously address three significant challenge severe occlusion perspective camera projection and large non linear deformation we introduce a concept called a model graph which greatly reduces the computational cost of discovering group of input image that depict consistent d shape a d model is constructed for each input image by traversing the model graph along multiple evolutionary path a compressive shape representation is constructed which consolidates the multiple d model for each image reconstructed during model evolution and reduces the number of model needed to represent the input image set assuming feature correspondence are known we demonstrate our algorithm on both real and synthetic data set that exemplify all three aforementioned challenge 
example based super resolution recovers missing high frequency in a magnified image by learning the correspondence between co occurrence example at two different resolution level a high resolution example usually contain more detail and are of higher dimensionality in comparison with low resolution one the mapping from low resolution to high resolution is an ill posed problem rather than imposing more complicated mapping constraint we propose to improve the mapping accuracy by enhancing low resolution example in term of mapped feature e g derivative and primitive a feature enhancement method is presented through a combination of interpolation with prefiltering and non blind sparse prior deblurring by enhancing low resolution example unique feature information carried by high resolution example is decreased this regularization reduces the intrinsic dimensionality disparity between two different resolution example and thus improves the feature mapping accuracy experiment demonstrate our super resolution scheme with feature enhancement produce high quality result both perceptually and quantitatively 
human aided computing proposes using information measured directly from the human brain in order to perform useful task in this paper we extend this idea by fusing computer vision based processing and processing done by the human brain in order to build more effective object categorization system specifically we use an electroencephalograph eeg device to measure the subconscious cognitive processing that occurs in the brain a user see image even when they are not trying to explicitly classify them we present a novel framework that combine a discriminative visual category recognition system based on the pyramid match kernel pmk with information derived from eeg measurement a user view image we propose a fast convex kernel alignment algorithm to effectively combine the two source of information our approach is validated with experiment using real world data where we show significant gain in classification accuracy we analyze the property of this information fusion method by examining the relative contribution of the two modality the error arising from each source and the stability of the combination in repeated experiment 
we present spatio temporal feature descriptor that can be inferred from video and used a building block in action recognition system they capture the evolution of elementary action element under a set of assumption on the image formation model and are designed to be insensitive to nuisance variability absolute position contrast while retaining discriminative statistic due to the fine scale motion and the local shape in compact region of the image despite their simplicity these descriptor used in conjunction with basic classifier attain state of the art performance in the recognition of action in benchmark datasets 
in this paper we present a novel algorithm for partial intrinsic symmetry detection in d geometry unlike previous work our algorithm is based on a conceptually simple and straightforward probabilistic formulation of partial shape matching based on a markov random field model we obtain a probability distribution over all possible intrinsic match of a shape to itself which reveals the symmetry structure of the object rather than examining this exponentially sized distribution directly which is infeasible we approximate marginals of this distribution using sumproduct loopy belief propagation and show how the symmetry information can subsequently be extracted from this condensed representation using a parallel implementation on graphic hardware we are able to extract symmetry of deformable shape in general pose efficiently we apply our algorithm on several standard d model demonstrating that a concise probabilistic model yield a practical and general symmetry detection algorithm 
coronary heart disease can be diagnosed by assessing the regional motion of the heart wall in ultrasound image of the left ventricle even for expert ultrasound image are difficult to interpret leading to high intra observer variability previous work indicates that in order to approach this problem the interaction between the different heartregions and their overall influence on the clinical condition of the heart need to be considered to do this we propose a method for jointly learning the structure and parameter of conditional random field formulating these task a a convex optimization problem we consider block l regularization for each set of feature associated with an edge and formalize an efficient projection method to find the globally optimal penalized maximum likelihood solution we perform extensive numerical experiment comparing the presented method with related method that approach the structure learning problem differently we veri fy the robustness of our method on echocardiogram collected in routine clinical practice at one hospital 
human activity analysis is an important problem in computer vision with application in surveillance and summarization and indexing of consumer content complex human activity are characterized by non linear dynamic that make learning inference and recognition hard in this paper we consider the problem of modeling and recognizing complex activity which exhibit time varying dynamic to this end we describe activity a output of linear dynamic system lds whose parameter vary with time or a time varying linear dynamic system tv lds we discus parameter estimation method for this class of model by assuming that the parameter are locally time invariant then we represent the space of lds model a a grassmann manifold then the tv lds model is defined a a trajectory on the grassmann manifold we show how trajectory on the grassmannian can be characterized using appropriate distance metric and statistical method that reflect the underlying geometry of the manifold this result in more expressive and powerful model for complex human activity we demonstrate the strength of the framework for activity based summarization of long video and recognition of complex human action on two datasets 
in this paper we present novel technique that improve the computational and memory efficiency of algorithm for solving multi label energy function arising from discrete mrf so rcrfs these method are motivated by the observation that the performance of minimization algorithm depends on a the initialization used for the primal and dual variable and b the number of primal variable involved in the energy function our first method dynamic expansion work by recycling result from previous problem instance the second method simplifies the energy function by reducing the number of unknown variable and can also be used to generate a good initialization for the dynamic expansion algorithm by reusing dual variable we test the performance of our method on energy function encountered in the problem of stereo matching and colourandobjectbasedsegmentation experimentalresults show that our method achieve a substantial improvement in the performance of expansion a well a other popular algorithm such a sequential tree reweighted message passing and max productbelief propagation in most case we achieve a time speed up in the computation time our modified expansion algorithm provides similar performance to fast pd however it is much simpler and can be made order of magnitude faster by using the initialization scheme proposed in the paper introduction many problem in computer vision such a image segmentation stereo matching image restoration and panoramicstitching involveinferringthe maximuma posteriori map solution of a probability distribution defined by a discrete mrf or crf the map solution can be found by minimizing an energy or cost function in the last few year driven by it applicability energy minimization ha become a very active area of research although minimizing a general mrf energy function is an np hard problem there exist a number of powerful algorithm which compute the exact solution for a particular family of energy function in polynomial time for instance maxproduct min sum belief propagation exactly minimizes energy function defined over graph with no loop 
this paper show that the performance of a binary classifier can be significantly improved by the processing of structured unlabeled data i e data are structured if knowing the label of one example restricts the labeling of the others we propose a novel paradigm for training a binary classifier from labeled and unlabeled example that we call p n learning the learning process is guided by positive p and negative n constraint which restrict the labeling of the unlabeled set p n learning evaluates the classifier on the unlabeled data identifies example that have been classified in contradiction with structural constraint and augments the training set with the corrected sample in an iterative process we propose a theory that formulates the condition under which p n learning guarantee improvement of the initial classifier and validate it on synthetic and real data p n learning is applied to the problem of on line learning of object detector during tracking we show that an accurate object detector can be learned from a single example and an unlabeled video sequence where the object may occur the algorithm is compared with related approach and state of the art is achieved on a variety of object face pedestrian car motorbike and animal 
we present a new method for detecting interest point using histogram information unlike existing interest point detector which measure pixel wise difference in image intensity our detector incorporate histogram based representation and thus can find image region that present a distinct distribution in the neighborhood the proposed detector are able to capture large scale structure and distinctive textured pattern and exhibit strong invariance to rotation illumination variation and blur the experimental result show that the proposed histogram based interest point detector perform particularly well for the task of matching textured scene under blur and illumination change in term of repeatability and distinctiveness an extension of our method to space time interest point detection for action classification is also presented 
multiple view d video reconstruction of actor performance capture a level of detail for body and clothing movement which is time consuming to produce using existing animation tool in this paper we present a framework for concatenative synthesis from multiple d video sequence according to user constraint on movement position and timing multiple d video sequence of an actor performing different movement are automatically constructed into a surface motion graph which represents the possible transition with similar shape and motion between sequence without unnatural movement artefact shape similarity over an adaptive temporal window is used to identify transition between d video sequence novel d video sequence are synthesized by finding the optimal path in the surface motion graph between user specified key frame for control of movement location and timing the optimal path which satisfies the user constraint whilst minimizing the total transition cost between d video sequence is found using integer linear programming result demonstrate that this framework allows flexible production of novel d video sequence which preserve the detailed dynamic of the captured movement for actress with loose clothing and long hair without visible artefact 
simultaneous registration and segmentation sr provides a powerful framework for tracking an object of interest in an image sequence the state of the art srsbased tracking method assume that the illumination is maintained constant across consecutive frame however this assumption doe not hold in many natural image sequence due to dynamic light source and shadow we propose a generalized model for sr based tracking in this paper to account for non uniform additive illumination change more specifically we introduce two new term in the sr energy functional which address the above mentioned problem the first term couple the shape based cue and intensity based cue to establish a correspondence between them the second term compensates for the illumination change which is complementary to the first term we demonstrate that the proposed sr energy functional yield superior performance over the state of the art sr based method for various indoor and outdoor image sequence 
this paper deal with estimation of dense optical flow and ego motion in a generalized imaging system by exploiting probabilistic linear subspace constraint on the flow we deal with the extended motion of the imaging system through an environment that we assume to have some degree of statistical regularity for example in autonomous ground vehicle the structure of the environment around the vehicle is far from arbitrary and the depth at each pixel is often approximately constant the subspace constraint hold not only for perspective camera but in fact for a very general class of imaging system including catadioptric and multiple view system using minimal assumption about the imaging system we learn a probabilistic subspace constraint that capture the statistical regularity of the scene geometry relative to an imaging system we propose an extension to probabilistic pca tipping and bishop a a way to robustly learn this subspace from recorded imagery and demonstrate it use in conjunction with a sparse optical flow algorithm to deal with the sparseness of the input flow we use a generative model to estimate the subspace using only the observed flow measurement additionally to identify and cope with image region that violate subspace constraint such a moving object object that violate the depth regularity or gross flow estimation error we employ a per pixel gaussian mixture outlier process we demonstrate result of finding the optical flow subspace and employing them to estimate dense flow and to recover camera motion for a variety of imaging system in several different environment 
we present an automatic method that establishes d correspondence between isometric shape our goal is to find an optimal correspondence between two given nearly isometric shape that minimizes the amount of deviation from isometry we cast the problem a a complete surface correspondence problem our method first divide the given shape to be matched into surface patch of equal area and then seek for a mapping between the patch center which we refer to a base vertex hence the correspondence is established in a fast and robust manner at a relatively coarse level a imposed by the patch radius we optimize the isometry cost in two step in the first step the base vertex are transformed into spectral domain based on geodesic affinity where the isometry error are minimized in polynomial time by complete bipartite graph matching the resulting correspondence serf a a good initialization for the second step of optimization in which we explicitly minimize the isometry cost via an iterative greedy algorithm in the original d euclidean space we demonstrate the performance of our method on various isometric or nearly isometric pair of shape for some of which the ground truth correspondence is available 
detection tracking segmentation and pose estimation of people in monocular image are widely studied two dimensional model of the human body are extensively used however they are typically fairly crude representing the body either a a rough outline or in term of articulated geometric primitive we describe a new d model of the human body contour that combine an underlying naked body with a low dimensional clothing model the naked body is represented a a contour person that can take on a wide variety of pose and body shape clothing is represented a a deformation from the underlying body contour this deformation is learned from training example using principal component analysis to produce eigen clothing we find that the statistic of clothing deformation are skewed and we model the a priori probability of these deformation using a beta distribution the resulting generative model capture realistic human form in monocular image and is used to infer d body shape and pose under clothing we also use the coefficient of the eigen clothing to recognize different category of clothing on dressed people the method is evaluated quantitatively on synthetic and real image and achieves better accuracy than previous method for estimating body shape under clothing 
this paper deal with a new problem in face recognition research in which the enrollment and query face sample are captured under different lighting condition in our case the enrollment sample are visual light vi image whereas the query sample are taken under near infrared nir condition it is very difficult to directly match the face sample captured under these two lighting condition due to their different visual appearance in this paper we propose a novel method for synthesizing vi image from nir image based on learning the mapping between image of different spectrum i e nir and vi in our approach we reduce the inter spectral difference significantly thus allowing effective matching between face taken under different imaging condition face recognition experiment clearly show the efficacy of the proposed approach 
we present a shape based algorithm for detecting and recognizing non rigid object from natural image the existing literature in this domain often cannot model the object very well in this paper we use the skeleton medial axis information to capture the main structure of an object which ha the particular advantage in modeling articulation and non rigid deformation given a set of training sample a tree union structure is learned on the extracted skeleton to model the variation in configuration each branch on the skeleton is associated with a few part based template modeling the object boundary information we then apply sum and max algorithm to perform rapid object detection by matching the skeleton based active template to the edge map extracted from a test image the algorithm report the detection result by a composition of the local maximum response compared with the alternative on this topic our algorithm requires le training sample it is simple yet efficient and effective we show encouraging result on two widely used benchmark image set the weizmann horse dataset and the ethz dataset 
we introduce a new problem of automatic photo composition and present an effective technique for finding good view within a panoramic scene instead of applying heuristic rule of photo composition we propose to imitate good composition presented in the artwork of professional photographer our approach try to model the composition style of professional photograph by analyzing the structural feature and the layout of visual saliency the task of finding good photo composition through a viewfinder is formulated a a search problem and we present a stochastic search algorithm to look for good viewing configuration and to choose suitable reference image from the collection of masterpiece photograph given any initial location in the panoramic scene our algorithm is able to suggest a better view that would often yield professional like photo composition 
nearest neighbour classifier and related kernel method often perform poorly in high dimensional problem because it is infeasible to include enough training sample to cover the class region densely in such case test sample often fall into gap between training sample where the nearest neighbour are too distant to be good indicator of class membership one solution is to project the data onto a discriminative lower dimensional subspace we propose a gap resistant nonparametric method for finding such subspace first the gap are filled by building a convex model of the region spanned by each class we test the affine and convex hull and the bounding disk of the class training sample then a set of highly discriminative direction is found by building and decomposing a scatter matrix of weighted displacement vector from training example to nearby rival class region the weight are chosen to focus attention on narrow margin case while still allowing more diversity and hence more discriminability than the d linear support vector machine svm projection experimental result on several face and object recognition datasets show that the method find effective projection allowing simple classifier such a nearest neighbour to work well in the low dimensional reduced space 
in this paper we propose a new image representation to capture both the appearance and spatial information for image classification application first we model the feature vector from the whole corpus from each image and at each individual patch in a bayesian hierarchical framework using mixture of gaussians after such a hierarchical gaussianization each image is represented by a gaussian mixture model gmm for it appearance and several gaussian map for it spatial layout then we extract the appearance information from the gmm parameter and the spatial information from global and local statistic over gaussian map finally we employ a supervised dimension reduction technique called dap discriminant attribute projection to remove noise direction and to further enhance the discriminating power of our representation we justify that the traditional histogram representation and the spatial pyramid matching are special case of our hierarchical gaussianization we compare our new representation with other approach in scene classification object recognition and face recognition and our performance rank among the top in all three task 
central to many problem in scene understanding based on using a network of ten hundred or even thousand of randomly distributed camera with on board processing and wireless communication capability is the efficient reconstruction of the d geometry structure in the scene what is meant by efficient reconstruction in this paper we investigate this from different aspect in the context of visual sensor network and offer a distributed reconstruction algorithm roughly meeting the following goal close to achievable d reconstruction accuracy and robustness minimization of the processing time by adaptive computing job distribution among all the camera in the network and asynchronous parallel processing communication optimization and minimization of the battery stored energy by reducing and localizing the communication between camera a volumetric representation of the scene is reconstructed with a shape from apparent contour algorithm which is suitable for distributed processing because it is essentially a local operation in term of the involved camera and apparent contour are robust to ourdoor illumination condition each camera process it own image and performs the computation for a small subset of voxels and update the voxels through collaborating with it neighbor camera by exploring the structure of the reconstruction algorithm we design the minimum spanning tree mst message passing protocol in order to minimize the communication of interest is that the resulting system is an example of swarm behavior d reconstruction is illustrated using two real image set running on a single computer the iterative computation used in the single processor experiment are exactly the same a are those used in the network computation distributed concept and algorithm for network control and communication performance are theoretical design and estimate 
many solution to computer vision and image processing problem involve the minimization of multi label energy function with up to k variable in each term in the minimization process swap and expansion are two commonly used move this paper re derives the optimal swap and expansion move for k in a short manner by using the original pseudo boolean quadratic function minimization method a a black box it is then revealed that the found minimum w r t expansion move are in fact also minimum w r t swap move this process is repeated for k the minimum related result is extended to all function under the condition that they are reduced into submodular one which make it applicable to all expansion algorithm these may explain the prevalent impression that expansion algorithm are more effective than swap algorithm to make the search space larger exwap a generalization of the expansion and the swap move is introduced efficient algorithm for minimizing w r t it for k including a truncation procedure k and the pn potts model are provided the move is capable of reaching lower energy than those reached by the expansion algorithm a demonstrated for several benchmark problem 
this paper study a framework for matching an unknown number of corresponding structure in two image shape motivated by detecting object in cluttered background and learning part from articulated motion due to the large distortion between shape and ambiguity caused by symmetric or cluttered structure many inference algorithm often get stuck in local minimum and converge slowly we propose a composite cluster sampling algorithm with a candidacy graph representation where each vertex candidate is a possible match for a pair of source and target primitive local structure or small curve and the layered matching is then formulated a a multiple coloring problem each two vertex can be linked by either a competitive edge or a collaborative edge these edge indicate the connected vertex should shouldn t be assigned the same color with this representation the stochastic sampling contains two step i sampling the competitive and collaborative edge to form a composite cluster in which a few mutual conflicting connected component are in different color ii sampling the new color to this cluster remaining consistency with markov chain monte carlo mcmc mechanism the algorithm is applied to many application on many public datasets and outperform the state of the art approach 
we discus a few new motion deblurring problem that are significant to kernel estimation and non blind deconvolution we found that strong edge do not always profit kernel estimation but instead under certain circumstance degrade it this finding lead to a new metric to measure the usefulness of image edge in motion deblurring and a gradient selection process to mitigate their possible adverse effect we also propose an efficient and high quality kernel estimation method based on using the spatial prior and the iterative support detection isd kernel refinement which avoids hard threshold of the kernel element to enforce sparsity we employ the tv l deconvolution model solved with a new variable substitution scheme to robustly suppress noise 
taking multiple exposure is a well established approach both for capturing high dynamic range hdr scene and for noise reduction but what is the optimal set of photo to capture the typical approach to hdr capture us a set of photo with geometrically spaced exposure time at a fixed iso setting typically iso or by contrast we show that the capture sequence with optimal worst case performance in general us much higher and variable iso setting and spends longer capturing the dark part of the scene based on a detailed model of noise we show that optimal capture can be formulated a a mixed integer programming problem compared to typical hdr capture our method let u achieve higher worst case snr in the same capture time for some camera up to db improvement in the darkest region or much faster capture for the same minimum acceptable level of snr our experiment demonstrate this advantage for both real and synthetic scene 
in this paper we propose a novel dynamic discrete framework to address image morphing with application to optical flow estimation we reformulate the problem using a number of discrete displacement and therefore the estimation of the morphing parameter becomes a tractable matching criterion independent combinatorial problem which is solved through the fastpd algorithm in order to overcome the main limitation of discrete approach low dimensionality of the label space is unable to capture the continuous nature of the expected solution we introduce a dynamic behavior in the model where the plausible discrete deformation displacement are varying in space across the domain and time different state of the process successive morphing state according to the local uncertainty of the obtained solution 
a novel method for crowd flow modeling and anomaly detection is proposed for both coherent and incoherent scene the novelty is revealed in three aspect first it is a unique utilization of particle trajectory for modeling crowded scene in which we propose new and efficient representative trajectory for modeling arbitrarily complicated crowd flow second chaotic dynamic are introduced into the crowd context to characterize complicated crowd motion by regulating a set of chaotic invariant feature which are reliably computed and used for detecting anomaly third a probabilistic framework for anomaly detection and localization is formulated the overall work flow begin with particle advection based on optical flow then particle trajectory are clustered to obtain representative trajectory for a crowd flow next the chaotic dynamic of all representative trajectory are extracted and quantified using chaotic invariant known a maximal lyapunov exponent and correlation dimension probabilistic model is learned from these chaotic feature set and finally a maximum likelihood estimation criterion is adopted to identify a query video of a scene a normal or abnormal furthermore an effective anomaly localization algorithm is designed to locate the position and size of an anomaly experiment are conducted on known crowd data set and result show that our method achieves higher accuracy in anomaly detection and can effectively localize anomaly 
the accurate localization of facial feature play a fundamental role in any face recognition pipeline constraine d local model clm provide an effective approach to localization by coupling ensemble of local patch detector for non rigid object alignment a recent improvement ha been made by using generic convex quadratic fitting cqf which elegantly address the clm warp update by enforcing convexity of the patch response surface in this paper cqf is generalized to a bayesian inference problem in which it appears a a particular maximum likelihood solution the bayesian viewpoint hold many advantage for example the task of feature localization can explicitly bu ild on previous face detection stage and multiple set of patc h response can be seamlessly incorporated a second contribution of the paper is an analytic solution to finding convex approximation to patch response surface which remove cqf s reliance on a numeric optimizer improvement in feature localization performance are illustrated on the la beled face in the wild and bioid data set 
the availability of quantitative online benchmark for low level vision task such a stereo and optical flow ha led to significant progress in the respective field this paper introduces such a benchmark for image matting there are three key factor for a successful benchmarking system a a challenging high quality ground truth test set b an online evaluation repository that is dynamically updated with new result c perceptually motivated error function our new benchmark strives to meet all three criterion we evaluated several matting method with our benchmark and show that their performance varies depending on the error function also our challenging test set reveals problem of existing algorithm not reflected in previously reported result we hope that our effort will lead to considerable progress in the field of image matting and welcome the reader to visit our benchmark at www alphamatting com 
markov random field mrf model are a powerful tool in machine vision application however learning the model parameter is still a challenging problem and a burdensome task the main contribution of this paper is to propose a locally adaptive learning framework the proposed learning framework is simple and effective learning framework for translation variant mrf model the key idea is to use neighboring patch a a locally adaptive training set we use multivariate gaussian mrf model for local image prior model although the gaussian mrf model are too simple for whole natural image prior the locally adaptive framework enables to express the prior distribution of the every observed image these locally adaptive learning framework and the multivariate gaussian translation variant mrf model simplify the learning procedure this paper also includes other two contribution a novel iteration framework by updating the prior information and a simple and intuitive derivation of the well known bilateral filter experimental result of denoising application demonstrate that the denoising based on the proposed locally adaptive learning framework outperforms existing high performance denoising algorithm 
in this work we propose a convex relaxation approach for computing minimal partition our approach is based on rewriting the minimal partition problem also known a potts model in term of a primal dual total variation functional we show that the potts prior can be incorporated by mean of convex constraint on the dual variable for minimization we propose an efficient primal dual projected gradient algorithm which also allows a fast implementation on parallel hardware although our approach doe not guarantee to find global minimizers of the potts model we can give a tight bound on the energy between the computed solution and the true minimizer furthermore we show that our relaxation approach dominates recently proposed relaxation a a consequence our approach allows to compute solution closer to the true minimizer for many practical problem we even find the global minimizer we demonstrate the excellent performance of our approach on several multi label image segmentation and stereo problem 
this purely theoretical work investigates the problem of artificial singularity in camera self calibration selfcalibration allows one to upgrade a projective reconstruction to metric and ha a concise and well understood formulation based on the dual absolute quadric daq a rank quadric envelope satisfying nonlinear spectral constraint it must be positive of rank the practical scenario we consider is the one of square pixel known principal point and varying unknown focal length for which generic critical motion sequence cm have been thoroughly derived the standard linear self calibration algorithm us the daq paradigm but ignores the spectral constraint it thus ha artificial cm which have barely been studied so far we propose an algebraic model of singularity based on the confocal quadric theory it allows to easily derive all type of cm we first review the already known generic cm for which any self calibration algorithm fails we then describe all cm for the standard linear selfcalibration algorithm among those are artificial cm caused by the above spectral constraint being neglected we then show how to detect cm if this is the case it is actually possible to uniquely identify the correct selfcalibration solution based on a notion of signature of quadric the main conclusion of this paper is that a posteriori enforcing the spectral constraint in linear self calibration is discriminant enough to resolve all artificial cm 
we present a novel building segmentation system for densely built area containing thousand of building per square kilometer we employ solely sparse lidar light laser detection ranging d data captured from an aerial platform with resolution le than one point per square meter the goal of our work is to create segmented and delineated building a well a structure on top of building without requiring scanning for the side of building building segmentation is a critical component in many application such a d visualization robot navigation and cartography lidar ha emerged in recent year a a more robust alternative to d imagery because it acquires d structure directly without the shortcoming of stereo in untextured region and at depth discontinuity our main technical contribution in this paper are i a ground segmentation algorithm which can handle both rural region and heavily urbanized area where the ground is or le of the data ii a building segmentation technique which is robust to building in close proximity to each other sparse measurement and nearby structured vegetation clutter and iii an algorithm for estimating the orientation of a boundary contour of a building based on minimizing the number of vertex in a rectilinear approximation to the building outline which can cope with significant quantization noise in the outline measurement we have applied the proposed building segmentation system to several urban region with area of hundred of square kilometer each obtaining average segmentation speed of le than three minute per km on a standard pentium processor extensive qualitative result obtained by overlaying the d segmented region onto d imagery indicate accurate performance of our system 
face alignment seek to deform a face model to match it with the feature of the image of a face by optimizing an appropriate cost function we propose a new face model that is aligned by maximizing a score function which we learn from training data and that we impose to be concave we show that this problem can be reduced to learning a classifier that is able to say whether or not by switching from one alignment to a new one the model is approaching the correct fitting this relates to the ranking problem where a number of instance need to be ordered for training the model we propose to extend gentleboost to rank learning extensive experimentation show the superiority of this approach to other learning paradigm and demonstrates that this model exceeds the alignment performance of the state of the art 
we introduce a new class of probabilistic latent variable model called the implicit mixture of conditional restricted boltzmann machine imcrbm for use in human pose tracking key property of the imcrbm are a follows learning is linear in the number of training exemplar so it can be learned from large datasets it learns coherent model of multiple activity it automatically discovers atomic movemes and it can infer transition between activity even when such transition are not present in the training set we describe the model and how it is learned and we demonstrate it use in the context of bayesian filtering for multi view and monocular pose tracking the model handle difficult scenario including multiple activity and transition among activity we report state of the art result on the humaneva dataset 
due to the capacity of pan tilt zoom ptz camera to simultaneously cover a panoramic area and maintain high resolution imagery research in automated surveillance system with multiple ptz camera have become increasingly important most existing algorithm require the prior knowledge of intrinsic parameter of the ptz camera to infer the relative positioning and orientation among multiple ptz camera to overcome this limitation we propose a novel mapping algorithm that derives the relative positioning and orientation between two ptz camera based on a unified polynomial model this reduces the dependence on the knowledge of intrinsic parameter of ptz camera and relative position experimental result demonstrate that our proposed algorithm present substantially reduced computational complexity and improved flexibility at the cost of slightly decreased pixel accuracy a compared with the work of chen and wang this slightly decreased pixel accuracy can be compensated by consistent labeling approach without added cost for the application of automated surveillance system along with changing configuration and a larger number of ptz camera 
we present a novel framework for recognizing repetitive sequential event performed by human actor with strong temporal dependency and potential parallel overlap our solution incorporates sub event or primitive detector and a spatiotemporal model for sequential event change we develop an effective and efficient method to integrate primitive into a set of sequential event where strong temporal constraint are imposed on the ordering of the primitive in particular the combination process is approached a an optimization problem a specialized viterbi algorithm is designed to learn and infer the target sequential event and handle the event overlap simultaneously to demonstrate the effectiveness of the proposed framework we report detailed quantitative analysis on a large set of cashier checkout activity in a retail store 
kernel method provide an efficient mechanism to derive nonlinear algorithm in classification problem a well a in feature extraction kernel based approach map the originally nonlinearly separable data into a space of intrinsically much higher dimensionality where the data is linearly separable and can be readily classified with existing and efficient linear method for a given kernel function the main challenge is to determine the parameter of the kernel which map the original nonlinear problem to a linear one this paper derives a bayes optimal criterion for the selection of the kernel parameter in discriminant analysis our criterion selects the kernel parameter that maximize the bayes classification accuracy in the kernel space we also show how we can use the same criterion to do subclass selection in the kernel space for problem with multimodal class distribution extensive experimental evaluation demonstrates the superiority of the proposed criterion over the state of the art 
in this paper we present a novel approach using a d x y z t action feature model d afm for recognizing action from arbitrary view the d afm elegantly encodes shape and motion of actor observed from multiple view the modeling process start with reconstructing d visual hull of actor at each time instant spatiotemporal action feature are then computed in each view by analyzing the differential geometric property of spatio temporal volume d stvs generated by concatenating the actor s silhouette over the course of the action x y t these feature are mapped to the sequence of d visual hull over time d to build the initial d afm to generalize the model for action category recognition the afms are further learned over a number of supplemental video with unknown camera parameter action are recognized based on the score of matching action feature from the input video to the model point of d afms by exploiting pairwise interaction of feature promising recognition result have been demonstrated on the multi view ixmas dataset using both single and multi view input video 
d ultrasound imaging ha been increasingly used in clinic for fetal examination however manually searching for the optimal view of the fetal face in d ultrasound volume is cumbersome and time consuming even for expert physician and sonographers in this paper we propose a learning based approach which combine both d and d information for automatic and fast fetal face detection from d ultrasound volume our approach applies a new technique constrained marginal space learning for d face mesh detection and combine a boosting based d profile detection to refine d face pose to enhance the rendering of the fetal face an automatic carving algorithm is proposed to remove all obstruction in front of the face based on the detected face mesh experiment are performed on a challenging d ultrasound data set containing fetal volume the result show that our system not only achieves excellent detection accuracy but also run very fast it can detect the fetal face from the d data in second on a dual core ghz computer 
this paper present a calibration and rectification method for single camera range estimation using a single complex image with a transparent plate or a doublesided half mirror plate which are collectively called a reflection stereo the range to an object is obtainable by finding the correspondence on a constraint line in the complex image which consists of a surface and a rear surface reflected image in the transparent plate or also includes a transmitted and internal reflected image through a double sided half mirror plate the range estimation requires extrinsic parameter of the reflection stereo that include the shape and position of the plate and it refraction index the proposed method assumes that the plate is non parallel but planar for a local region around the point of interest in the complex image the method estimate the extrinsic parameter from a set of displacement in the complex image experiment using real image demonstrate the effectiveness of the proposed calibration and rectification method along with fine range estimation result 
the ranking model of existing image video search engine are generally based on associated text while the visual content is actually neglected imperfect search result frequently appear due to the mismatch between the textual feature and the actual visual content visual reranking in which visual information is applied to refine text based search result ha been proven to be effective however the improvement brought by visual reranking is limited and the main reason is that the error in the text based result will propagate to the refinement stage in this paper we propose a content aware ranking model based on learning to rank framework in which textual and visual information are simultaneously leveraged in the ranking learning process we formulate the content aware ranking based on large margin structured output learning by modeling the visual information into a regularization term the direct optimization of the learning problem is nearly infeasible since the number of constraint is huge the efficient cutting plane algorithm is adopted to learn the model by iteratively adding the most violated constraint extensive experimental result on a large scale dataset collected from a commercial web image search engine a well a the trecvid video search dataset demonstrate that the proposed ranking model significantly outperforms the state of the art ranking and reranking method 
we study the problem of generating plausible interpretation of a scene from a collection of line segment automatically extracted from a single indoor image we show that we can recognize the three dimensional structure of the interior of a building even in the presence of occluding object several physically valid structure hypothesis are proposed by geometric reasoning and verified to find the best fitting model to line segment which is then converted to a full d model our experiment demonstrate that our structure recovery from line segment is comparable with method using full image appearance our approach show how a set of rule describing geometric constraint between group of segment can be used to prune scene interpretation hypothesis and to generate the most plausible interpretation 
accurate denition of similarity measure is a key component in image registration most commonly used intensitybased similarity measure rely on the assumption of independence and stationarity of the intensity from pixel to pixel such measure cannot capture the complex interaction among the pixel intensity and often result in le satisfactory registration performance especially in the presence of nonstationary intensity distortion we propose a novel similarity measure that account for intensity nonstationarities and complex spatially varying intensity distortion we derive the similarity measure by analytically solving for the intensity correction eld and it adaptive regularization the nal measure can be interpreted a one that favor a registration with minimum compression complexity of the residual image between the two registered image this measure produce accurate registration result on both articial and real world problem that we have tested whereas many other state of the art similarity measure have failed to do so 
in this paper we present an appearance based method for person re identification it consists in the extraction of feature that model three complementary aspect of the human appearance the overall chromatic content the spatial arrangement of color into stable region and the presence of recurrent local motif with high entropy all this information is derived from different body part and weighted opportunelyby exploiting symmetry and asymmetry perceptual principle in this way robustness against very low resolution occlusion and pose viewpoint and illumination change is achieved the approach applies to situation where the number of candidate varies continuously considering single image or bunch of frame for each individual it hasbeen tested on several publicbenchmarkdatasets viper ilids ethz gaining new state of the art performance 
we propose a framework that can conveniently capture heterogeneous relationship among multiple random variable the framework is formulated based on a hybrid probabilistic graphical model it allows using both directed link and undirected link to capture various type of relationship based on this framework we develop a multiscale hybrid model for image segmentation the multiscale model systematically capture the spatial relationship and causal relationship among such image entity a region edge and vertex at different scale we further show how to parameterize such a hybrid model and how to factorize it joint probability distribution according to the global markov property based on this factorization we exploit the factor graph theory to perform joint probabilistic inference and solve for the image segmentation problem 
in image restoration task a heavy tailed gradient distribution of natural image ha been extensively exploited a an image prior most image restoration algorithm impose a sparse gradient prior on the whole image reconstructing an image with piecewise smooth characteristic while the sparse gradient prior remove ringing and noise artifact it also tends to remove mid frequency texture degrading the visual quality we can attribute such degradation to imposing an incorrect image prior the gradient profile in fractal like texture such a tree is close to a gaussian distribution and small gradient from such region are severely penalized by the sparse gradient prior to address this issue we introduce an image restoration algorithm that adapts the image prior to the underlying texture we adapt the prior to both low level local structure a well a mid level textural characteristic improvement in visual quality is demonstrated on deconvolution and denoising task 
this paper present a novel local image descriptor that is robust to general image deformation a limitation with traditional image descriptor is that they use a single support region for each interest point for general image deformation the amount of deformation for each location varies and is unpredictable such that it is difficult to choose the best scale of the support region to overcome this difficulty we propose to use multiple support region of different size surrounding an interest point a feature vector is computed for each support region and the concatenation of these feature vector form the descriptor for this interest point furthermore we propose a new similarity measure model local to global similarity lgs model for point matching that take advantage of the multi size support region each support region act a a dasiaweakpsila classifier and the weight of these classifier are learned in an unsupervised manner the proposed approach is evaluated on a number of image with real and synthetic deformation the experiment result show that our method outperforms existing technique under different deformation 
abstract we examine the problem of segmenting tracked feature point trajectory of multiple moving object in an image sequence using the affine camera model this motion segmentation problem can be cast a the problem of segmenting sample drawn from a union of linear subspace due to limitation of the tracker occlusion and the presence of nonrigid object in the scene the obtained motion trajectory may contain grossly mistracked feature missing entry or not correspond to any valid motion model in this paper we develop a robust subspace separation scheme that can deal with all of these practical issue in a unified framework our method draw strong connection between lossy compression rank minimization and sparse representation we test our method extensively and compare their performance to several extant method with experiment on the hopkins database our result are on par with stateof the art result and in many case exceed them all matlab code and segmentation result are publicly available for peer evaluation at http perception csl uiuc edu coding motion 
a large variety of image feature ha been invented for detection of object of a known class we propose a frameworkto optimizethediscrimination efficiencytradeoffin integrating multiple heterogeneous feature for object detection cascade structured detector are learned by boosting local feature based weak classifier each weak classifier corresponds to a local image region from which several different type of feature are extracted the weak classifier make prediction by examining the feature one by one this classifier go to the next feature only when the prediction from the already examined feature is not confident enough the order in which the feature are evaluated is determined based on their computational cost normalized classification power we apply our approach to two object class pedestrian and car the experimental result show that our approach outperforms the state of theart method 
we propose a novel meshless deformable model for in vivo cardiac left ventricle lv d motion estimation a a relatively new technology tagged mri tmri provides a direct and noninvasive way to reveal local deformation of the myocardium which creates a large amount of heart motion data which requiring quantitative analysis in our study we sample the heart motion sparsely at intersection of three set of orthogonal tagging plane and then use a new meshless deformable model to recover the dense d motion of the myocardium temporally during the cardiac cycle we compute external force at tag intersection based on tracked local motion and redistribute the force to meshless particle throughout the myocardium internal constraint force at particle are derived from local strain energy using a moving least square ml method the dense d motion field is then computed and updated using the lagrange equation the new model avoids the singularity problem of mesh based model and is capable of tracking large deformation with high efficiency and accuracy in particular the model performs well even when the control point tag intersection are relatively sparse we tested the performance of the meshless model on a numerical phantom a well a in vivo heart data of healthy subject and patient the experimental result show that the meshless deformable model can fully recover the myocardium motion in d 
this paper present a joint probabilistic relation graph approach to simultaneously detect and track a large number of vehicle in low frame rate aerial video due to low frame rate low spatial resolution and sheer number of moving object detection and tracking in wide area video pose unique challenge in this paper we explore vehicle behavior model from road structure and generate a set of constraint to regulate both object based vertex matching and pairwise edge matching scheme the proposed relation graph approach then unifies these two matching scheme into a single cost minimization framework to produce a quadratic optimized association result the experiment on hour of real video demonstrate the graph matching framework with vehicle behavior model effectively improves tracking performance in large scale dense traffic scenario 
our goal is to fit the multiple instance or structure of a generic model existing in data here we propose a novel model selection scheme to estimate the number of genuine structure present in contrast to conventional model selection approach our method is driven by kernel based learning the input data is first clustered based on their potential to have emerged from the same structure however the number of cluster is deliberately overestimated to obtain a set of initial model fit onto the data we then resolve the oversegmentation via a series of kernel optimisation conducted through multiple kernel learning and the concept of kernel target alignment is used a a model selection criterion experiment on synthetic and real data show that our method outperforms previous model selection scheme we also focus on the application of multi body motion segmentation in particular we demonstrate success on estimating the number of motion on sequence with more than unique motion 
this paper introduces a class of correlation filter called average of synthetic exact filter asef for asef the correlation output is completely specified for each training image this is in marked contrast to prior method such a synthetic discriminant function sdfs which only specify a single output value per training image advantage of asef training include insenitivity to over fitting greater flexibility with regard to training image and more robust behavior in the presence of structured background the theory and design of asef filter is presented using eye localization on the feret database a an example task asef is compared to other popular correlation filter including sdf mace otf and umace and with other eye localization method including gabor jet and the opencv cascade classifier asef is shown to outperform all these method locating the eye to within the radius of the iris approximately of the time 
we extend photometric stereo to make it work with internet image which are typically associated with different viewpoint and significant noise for popular tourism site thousand of image can be obtained from internet search engine with these image our method computes the global illumination for each image and the surface orientation at some scene point the illumination information can then be used to estimate the weather condition such a sunny or cloudy for each image since there is a strong correlation between weather and scene illumination we demonstrate our method on several challenging example 
active contour formulation predominate current minimization of the mumford shah functional msf for image segmentation and filtering unfortunately these formulation necessitate optimization of the contour by evolving via gradient descent which is known for it sensitivity to initialization and the tendency to produce undesirable local minimum in order to reduce these problem we reformulate the corresponding msf on an arbitrary graph and apply combinatorial optimization to produce a fast low energy solution the solution provided by this graph formulation is compared with the solution computed via traditional narrow band level set method this comparison demonstrates that our graph formulation and optimization produce lower energy solution than gradient descent based contour evolution method in significantly le time finally by avoiding evolution of the contour via gradient descent we demonstrate that our optimization of the msf is capable of evolving the contour with non local movement 
the dynamic texture dt is a probabilistic generative model defined over space and time that represents a video a the output of a linear dynamical system lds the dt model ha been applied to a wide variety of computer vision problem such a motion segmentation motion classification and video registration in this paper we derive a new algorithm for clustering dt model that is based on the hierarchical em algorithm the proposed clustering algorithm is capable of both clustering dts and learning novel dt cluster center that are representative of the cluster member in a manner that is consistent with the underlying generative probabilistic model of the dt we then demonstrate the efficacy of the clustering algorithm on several application in motion analysis including hierarchical motion clustering semantic motion annotation and bag ofsystems codebook generation 
multiplexing is a common technique for encoding high dimensional image data into a single two dimensional image example of spatial multiplexing include bayer pattern to capture color channel and integral image to encode light field in the fourier domain optical heterodyning ha been used to acquire light field in this paper we develop a general theory of multiplexing the dimension of the plenoptic function onto an image sensor our theory enables a principled comparison of plenoptic multiplexing scheme including noise analysis a well a the development of a generic reconstruction algorithm the framework also aide in the identification and optimization of novel multiplexed imaging application 
we present a bayesian framework for action recognition through ballistic dynamic psycho kinesiological study indicate that ballistic movement form the natural unit for human movement planning the framework lead to an efficient and robust algorithm for temporally segmenting video into atomic movement individual movement are annotated with person centric morphological label called ballistic verb this is tested on a dataset of interactive movement achieving high recognition rate the approach is also applied on a gesture recognition task improving a previously reported recognition rate from to consideration of ballistic dynamic enhances the performance of the popular motion history image feature we also illustrate the approach s general utility on real world video experiment indicate that the method is robust to view style and appearance variation 
we present a new energy model for optical flow estimation on discrete mrf framework the proposed model yield discrete analog to the prevailing model with diffusion tensor based regularizer which ha been optimized by variational approach inspired from the fact that the regularization process work a a convolution kernel filtering we formulate the difference between original flow and filtered flow a a smoothness prior then the discrete framework enables u to employ a robust penalizer le concerning convexity and differentiability of the energy function in addition we provide a new kernel design based on the bilateral filter adaptively controlling intensity variance according to the local statistic the proposed kernel simultaneously address over segmentation and over smoothing problem which is hard to achieve by tuning parameter involving a complex graph structure with large label set this work also present a strategy to efficiently reduce memory requirement and computational time to a tolerable state experimental result show the proposed method yield plausible result on the various data set including large displacement and textured region 
the integral image is typically used for fast integrating a function over a rectangular region in an image we propose a method that extends the integral image to do fast integration over the interior of any polygon that is not necessarily rectilinear the integration time of the method is fast independent of the image resolution and only linear to the polygon s number of vertex we apply the method to viola and jones object detection framework in which we propose to improve classical haar like feature with polygonal haar like feature we show that the extended feature set improves object detection s performance the experiment are conducted in three domain frontal face detection fixed pose hand detection and rock detection for mar surface terrain assessment 
object localization and recognition are important problem in computer vision however in many application exhaustive search over all object model and image location is computationally prohibitive while several method have been proposed to make either recognition or localization more efficient few have dealt with both task simultaneously this paper proposes an efficient method for concurrent object localization and recognition based on a datadependent multi class branch and bound formalism existing bag of feature recognition technique which can be expressed a weighted combination of feature count can be readily adapted to our method we present experimental result that demonstrate the merit of our algorithm in term of recognition accuracy localization accuracy and speed compared to baseline approach including exhaustive search implicit shape model ism method and efficient subwindow search es moreover we develop two extension to consider non rectangular bounding region composite box and polygon and demonstrate their ability to achieve higher recognition score compared to traditional rectangular bounding box 
statistical learning technique have been used to dramatically speed up keypoint matching by training a classifier to recognize a specific set of keypoints however the training itself is usually relatively slow and performed offline although method have recently been proposed to train the classifier online they can only learn a very limited number of new keypoints this represents a handicap for real time application such a simultaneous localization and mapping slam which require incremental addition of arbitrary number of keypoints a they become visible in this paper we overcome this limitation and propose a descriptor that can be learned online fast enough to handle virtually unlimited number of keypoints it relies on the fact that if we train a randomized tree classifier to recognize a number of keypoints extracted from an image database all other keypoints can be characterized in term of their response to these classification tree this signature is fast to compute and ha a discriminative power that is comparable to that of the much slower sift descriptor 
we present a system for fast model based segmentation and d pose estimation of specular object using appearance based specular feature we use observed a specular reflection and b specular flow a cue which are matched against similar cue generated from a cad model of the object in various pose we avoid estimating d geometry or depth which is difficult and unreliable for specular scene in the first method the environment map of the scene is utilized to generate a database containing synthesized specular reflection of the object for densely sampled d pose this database is compared with captured image of the scene at run time to locate and estimate the d pose of the object in the second method specular flow are generated for dense d pose a illumination invariant feature and are matched to the specular flow of the scene we incorporate several practical heuristic such a use of saturated highlight pixel for fast matching and normal selection to minimize the effect of inter reflection and cluttered background despite it simplicity our approach is effective in scene with multiple specular object partial occlusion inter reflection cluttered background and change in ambient illumination experimental result demonstrate the effectiveness of our method for various synthetic and real object 
we propose a new method for video retargeting which can generate spatial temporal consistent video the new measure called spatial temporal naturality preserve the motion in the source video without any motion analysis in contrast to other method that need motion estimation this advantage prevents the retargeted video from degenerating due to the propagation of the error in motion analysis it allows the proposed method to be applied on challenging video with complex camera and object motion to improve the efficiency of the retargeting process we retarget video using a d shift map in low resolution and refine it using an incremental d shift map in higher resolution this new hierarchical framework denoted a hybrid shift map can produce satisfactory retargeting result while significantly improving the computational efficiency 
visual tracking is one of the central problem in computer vision a crucial problem of tracking is how to represent the object traditional appearance based tracker are using increasingly more complex feature in order to be robust however complex representation typically will not only require more computation for feature extraction but also make the state inference complicated in this paper we show that with a careful feature selection scheme extremely simple yet discriminative feature can be used for robust object tracking the central component of the proposed method is a succinct and discriminative representation of image template using discriminative non orthogonal binary subspace spanned by haar like feature these haar like base are selected from the over complete dictionary using a variation of the oomp optimized orthogonal matching pursuit such a representation inherits the merit of original nb in that it can be used to efficiently describe the object it also incorporates the discriminative information to distinguish the foreground and background we apply the discriminative nb to object tracking through ssd based template matching an update scheme of the discriminative nb is devised in order to accommodate object appearance change we validate the effectiveness of our method through extensive experiment on challenging video and demonstrate it capability to track object in clutter and moving background 
background estimation i e automatic recovery of the background image from a sequence of image containing moving foreground object is an important module in many application e g surveillance and video segmentation in this paper we present a simple yet effective and robust approach for background estimation based on loopy belief propagation robustness of the proposed approach mean i minimal assumption on the input frame and ii no need to tune parameter basically the background can be recovered even when the occluding foreground object stay still for a long time furthermore no motion information need to be known or estimated for the foreground object which implies that background can be recovered from a set of frame which are not consecutive temporally analysis and experiment are provided to compare the proposed approach to related method experimental result on typical surveillance video demonstrate the effectiveness of our approach 
we propose to shift the goal of recognition from naming to describing doing so allows u not only to name familiar object but also to report unusual aspect of a familiar object spotty dog not just dog to say something about unfamiliar object hairy and four legged not just unknown and to learn how to recognize new object with few or no visual example rather than focusing on identity assignment we make inferring attribute the core problem of recognition these attribute can be semantic spotty or discriminative dog have it but sheep do not learning attribute present a major new challenge generalization across object category not just across instance within a category in this paper we also introduce a novel feature selection method for learning attribute that generalize well across category we support our claim by thorough evaluation that provides insight into the limitation of the standard recognition paradigm of naming and demonstrates the new ability provided by our attributebased framework 
food recognition is difficult because food item are de formable object that exhibit significant variation in appearance we believe the key to recognizing food is to exploit the spatial relationship between different ingredient such a meat and bread in a sandwich we propose a new representation for food item that calculates pairwise statistic between local feature computed over a soft pixel level segmentation of the image into eight ingredient type we accumulate these statistic in a multi dimensional histogram which is then used a a feature vector for a discriminative classifier our experiment show that the proposed representation is significantly more accurate at identifying food than existing method 
the spatial distribution of fingerprint minutia is a core problem in the fingerprint individuality study the cornerstone of the fingerprint authentication technology previously the assumption in most research that minutia distribution is random ha been proved to be inaccurate and may lead to significant overestimate of fingerprint uniqueness in this paper we propose a stochastic model for describing and simulating fingerprint minutia pattern through coupling a pair potential markov point process with a thinned process this model successfully depicts the complex statistical behavior of fingerprint minutia parameter of this model can be determined by nonlinear minimization furthermore experiment result show that the statistical property of our proposed model dovetail nicely with real minutia data in term of the false fingerprint correspondence probability such evidence indicate that the proposed model is a more accurate foundation for minutia based fingerprint individuality study a well a the artificial fingerprint synthesis when compared to the model of random distribution 
we describe a single shot method to differentiate unscattered and scattered component of light transmission through a heterogeneous translucent material directly transmitted component travel in a straight line from the light source while scattered component originate from multiple scattering center in the volume computer vision method deal with participating medium via d contrast enhancing software technique on the other hand optic technique treat scattering a noise and use elaborate method to reduce the scattering or it impact on the direct unscattered component we observe the scattered component on it own provides useful information because the angular variation is low frequency we propose a method to strategically capture angularly varying scattered light and compute the unscattered direct component we capture the scattering from a single light source via a lenslet array placed close to the image plane a an application we demonstrate enhanced tomographic reconstruction of scattering object using estimated direct transmission image 
we introduce a novel local image descriptor designed for dense wide baseline matching purpose we feed our descriptor to a graph cut based dense depth map estimation algorithm and this yield better wide baseline performance than the commonly used correlation window for which the size is hard to tune a a result unlike competing technique that require many high resolution image to produce good reconstruction our descriptor can compute them from pair of low quality image such a the one captured by video stream ourdescriptoris inspiredfrom earlieronessuchassift and gloh but can be computed much faster for our purpose unlike surf which can also be computed efficiently at every pixel it doe not introduce artifact that degrade the matching performance our approach wa tested with ground truth laser scanned depth map a well a on a wide variety of image pair of different resolution and we show that good reconstruction are achieved even with only two low quality image 
in this paper we present a novel approach to contentsbased image retrieval the method hinge in the use of quasi random sampling to retrieve those image in a database which are related to a query image provided by the user departing from random sampling theory we make use of the em algorithm so a to organize the image in the database into compact cluster that can then be used for stratified random sampling for the purpose of retrieval we use the similarity between the query and the clustered image to govern the sampling process within cluster in this way the sampling can be viewed a a stratified sampling one which is random at the cluster level and take into account the intra cluster structure of the dataset this approach lead to a measure of statistical confidence that relates to the theoretical hard limit of the retrieval performance we show result on the oxford flower dataset 
in this paper we propose a simple but effective image prior dark channel prior to remove haze from a single input image the dark channel prior is a kind of statistic of the haze free outdoor image it is based on a key observation most local patch in haze free outdoor image contain some pixel which have very low intensity in at least one color channel using this prior with the haze imaging model we can directly estimate the thickness of the haze and recover a high quality haze free image result on a variety of outdoor haze image demonstrate the power of the proposed prior moreover a high quality depth map can also be obtained a a by product of haze removal 
integral image are commonly used in computer vision and computer graphic application evaluation of box filter via integral image can be performed in constant time regardless of the filter size although heckbert extended the integral image approach for more complex filter it usage ha been very limited in practice in this paper we present an extension to integral image that allows for application of a wide class of non uniform filter our approach is superior to heckberts in term of precision requirement and suitability for parallelization we explain the theoretical basis of the approach and instantiate two concrete example filtering with bilinear interpolation and filtering with approximated gaussian weighting our experiment show the significant speedup we achieve and the higher accuracy of our approach compared to heckbert s 
we consider the problem of reconstructing a smooth surface under constraint that have discrete ambiguity these problem arise in area such a shape from texture shape from shading photometric stereo and shape from defocus while the problem is computationally hard heuristic based on semidefinite programming may reveal the shape of the surface 
we show that histogram of keypoint descriptor distance can make useful feature for visual recognition descriptor distance are often exhaustively computed between set of keypoints but besides finding the k smallest distance the structure of the distribution of these distance ha been largely overlooked we highlight the potential of such information in the task of particular scene recognition discriminative scene signature in the form of histogram of keypoint descriptor distance are constructed in a supervised manner the distance are computed between properly selected reference keypoints and the keypoints detected in the input image the signature is low dimensional computationally cheap to obtain and can distinguish a large number of scene we introduce a scheme based on multiclass adaboost to select the appropriate reference keypoints the resulting system is capable of handling a large number of scene class at a fraction of the time required for exhaustively matching set of keypoints this support support a coarse to fine search strategy for approach reliant on keypoint matching we test the idea on datasets for particular scene recognition and report the obtained result 
cross domain learning method have shown promising result by leveraging labeled pattern from auxiliary domain to learn a robust classifier for target domain which ha a limited number of labeled sample to cope with the tremendous change of feature distribution between different domain in video concept detection we propose a new cross domain kernel learning method our method referred to a domain transfer svm dtsvm simultaneously learns a kernel function and a robust svm classifier by minimizing both the structural risk functional of svm and the distribution mismatch of labeled and unlabeled sample between the auxiliary and target domain comprehensive experiment on the challenging trecvid corpus demonstrate that dtsvm outperforms existing cross domain learning and multiple kernel learning method 
global shape information is an effective top down complement to bottom up figure ground segmentation a well a a useful constraint to avoid drift during adaptive tracking we propose a novel method to embed global shape information into local graph link in a conditional random field crf framework given object shape from several key frame we automatically collect a shape dataset on the fly and perform statistical analysis to build a collection of deformable shape template representing global object shape in new frame simulated annealing and local voting align the deformable template with the image to yield a global shape probability map the global shape probability is combined with a region based probability of object boundary map and the pixel level intensity gradient to determine each link cost in the graph the crf energy is minimized by min cut followed by random walk on the uncertain boundary region to get a soft segmentation result experiment on both medical and natural image with deformable object shape are demonstrated 
in this paper we propose a novel approach for learning generic visual vocabulary we use diffusion map to automatically learn a semantic visual vocabulary from abundant quantized midlevel feature each midlevel feature is represented by the vector of pointwise mutual information pmi in this midlevel feature space we believe the feature produced by similar source must lie on a certain manifold to capture the intrinsic geometric relation between feature we measure their dissimilarity using diffusion distance the underlying idea is to embed the midlevel feature into a semantic lower dimensional space our goal is to construct a compact yet discriminative semantic visual vocabulary although the conventional approach using k mean is good for vocabulary construction it performance is sensitive to the size of the visual vocabulary in addition the learnt visual word are not semantically meaningful since the clustering criterion is based on appearance similarity only our proposed approach can effectively overcome these problem by capturing the semantic and geometric relation of the feature space using diffusion map unlike some of the supervised vocabulary construction approach and the unsupervised method such a plsa and lda diffusion map can capture the local intrinsic geometric relation between the midlevel feature point on the manifold we have tested our approach on the kth action dataset our own youtube action dataset and the fifteen scene dataset and have obtained very promising result 
landmark labeling of training image is essential for many learning task in computer vision such a object detection tracking and alignment image labeling is typically conducted manually which is both labor intensive and error prone to improve this process this paper proposes a new approach to estimate a set of landmark for a large image ensemble with only a small number of manually labeled image from the ensemble our approach named semi supervised least square congealing aim to minimize an objective function defined on both labeled and unlabeled image a shape model is learnt on line to constrain the landmark configuration we also employ a partitioning strategy to allow coarse to fine landmark estimation extensive experiment on facial image show that our approach can reliably and accurately label landmark for a large image ensemble starting from a small number of manually labeled image under various challenging scenario 
abstract the mean shift algorithm which is a nonparametric density estimator for detecting the mode of a distribution on a euclidean space wa recently extended to operate on analytic manifold the extension is extrinsic in the sense that the inherent optimization is performed on the tangent space of these manifold this approach specifically requires the use of the exponential map at each iteration this paper present an alternative mean shift formulation which performs the iterative optimization on the manifold of interest and intrinsically locates the mode via consecutive evaluation of a mapping in particular these evaluation constitute a modified gradient ascent scheme that avoids the computation of the exponential map for stiefel and grassmann manifold the performance of our algorithm is evaluated by conducting extensive comparative study on synthetic data a well a experiment on object categorization and segmentation of multiple motion 
this paper present a global minimization framework for estimating analytical brdf model parameter using the technique of convex programming and branch and bound traditional local minimization suffers from local minimum and requires a large number of initial condition and supervision for successful result especially when a model is highly complex and nonlinear we consider the cook torrance model a parametric model with the gaussian like beckmann distribution for specular reflectance instead of optimizing the multiple parameter simultaneously we search over all possible surface roughness value based on a branch and bound algorithm and reduce the estimation problem to convex minimization with known fixed surface roughness our algorithm guarantee globally optimal solution experiment have been carried out for isotropic surface to validate the method using the extensive high precision measurement from the merl brdf database 
reseachers have verified that clothing provides information about the identity of the individual to extract featur e from the clothing the clothing region first must be localize d or segmented in the image at the same time given multiple image of the same person wearing the same clothing we expect to improve the effectiveness of clothing segmentation therefore the identity recognition and clothing s egmentation problem are inter twined a good solution for one aide in the solution for the other we build on this idea by analyzing the mutual information between pixel location near the face and the identity of the person to learn a global clothing mask we segment the clothing region in each image using graph cut based on a clothing model learned from one or multiple image believed to be the same person wearing the same clothing we use facial feature and clothing feature to recognize indi viduals in other image the result show that clothing segmentation provides a significant improvement in recognitio n accuracy for large image collection and useful clothing mask are simultaneously produced a further significant contribution is that we introduce a publicly available consumer image collection where each individual is identified we hope this dataset allows the vision community to more easily compare result for task related to recognizing people in consumer image collection 
image segmentation is a fundamental task in computer vision and there are numerous algorithm that have been successfully applied in various domain there are still plenty of challenge to be met with in this paper we consider one such challenge that of achieving segmentation while preserving complicated and detailed feature present in the image be it a gray level or a textured image we present a novel approach that doe not make use of any prior information about the object in the image being segmented segmentation is achieved using local orientation information which is obtained via the application of a steerable gabor filter bank in a statistical framework this information is used to construct a spatially varying kernel called the rigaut kernel which is then convolved with the signed distance function of an evolving contour placed in the image to achieve segmentation we present numerous experimental result on real image including a quantitative evaluation superior performance of our technique is depicted via comparison to the state of the art algorithm in literature 
image taken from different view of a planar object are related by planar homography recovering the parameter of such transformation is a fundamental problem in computer vision with various application this paper proposes a novel method to estimate the parameter of a homography that aligns two binary image it is obtained by solving a system of nonlinear equation generated by integrating linearly independent function over the domain determined by the shape the advantage of the proposed solution is that it is easy to implement le sensitive to the strength of the deformation work without established correspondence and robust against segmentation error the method ha been tested on synthetic a well a on real image and it efficiency ha been demonstrated in the context of two different application alignment of hip prosthesis x ray image and matching of traffic sign 
we propose a novel framework for constrained spectral clustering with pairwise constraint which specify whether two object belong to the same cluster or not unlike previous method that modify the similarity matrix with pairwise constraint we adapt the spectral embedding towards an ideal embedding a consistent with the pairwise constraint a possible our formulation lead to a small semidefinite program whose complexity is independent of the number of object in the data set and the number of pairwise constraint making it scalable to large scale problem the proposed approach is applicable directly to multi class problem handle both must link and cannot link constraint and can effectively propagate pairwise constraint extensive experiment on real image data and uci data have demonstrated the efficacy of our algorithm 
we consider the problem of data association in a multiperson tracking context in semi crowded environment people are still discernible a individually moving entity that undergo many interaction with other people in their direct surrounding finding the correct association is therefore difficult but higher order social factor such a group membership are expected to ease the problem however estimating group membership is a chicken and egg problem knowing pedestrian trajectory it is rather easy to find out possible grouping in the data but in crowded scene it is often difficult to estimate closely interacting trajectory without further knowledge about group to this end we propose a third order graphical model that is able to jointly estimate correct trajectory and group membership over a short time window a set of experiment on challenging data underline the importance of joint reasoning for data association in crowded scenario 
we describe an algorithm for similar image search which is designed to be efficient for extremely large collection of image for each query a small response set is selected by a fast prefilter after which a more accurate ranker may be applied to each image in the response set we consider a class of prefilters comprising disjunction of conjunction or of ands of boolean feature and filter can be implemented efficiently using skipped inverted file a key component of web scale text search engine these structure permit search in time proportional to the response set size the prefilters are learned from training example and refined at query time to produce an approximately bounded response set we cast prefiltering a an optimization problem for each test query select the or of and filter which maximizes training set recall for an adjustable bound on response set size this may be efficiently implemented by selecting from a large pool of candidate conjunction of boolean feature using a linear program relaxation test on object class recognition show that this relatively simple filter is nevertheless powerful enough to capture some semantic information 
we propose a novel method for unsupervised class segmentation on a set of image it alternate between segmenting object instance and learning a class model the method is based on a segmentation energy defined over all image at the same time which can be optimized efficiently by technique used before in interactive segmentation over iteration our method progressively learns a class model by integrating observation over all image in addition to appearance this model capture the location and shape of the class with respect to an automatically determined coordinate frame common across image this frame allows u to build stronger shape and location model similar to those used in object class detection our method is inspired by interactive segmentation method but it is fully automatic and learns model characteristic for the object class rather than specific to one particular object image we experimentally demonstrate on the caltech caltech and weizmann horse datasets that our method a transfer class knowledge across image and this improves result compared to segmenting every image independently b outperforms grabcut for the task of unsupervised segmentation c offer competitive performance compared to the state of the art in unsupervised segmentation and in particular it outperforms the topic model 
system theoretic approach to action recognition model the dynamic of a scene with linear dynamical system ldss and perform classification using metric on the space of ldss e g binet cauchy kernel however such approach are only applicable to time series data living in a euclidean space e g joint trajectory extracted from motion capture data or feature point trajectory extracted from video much of the success of recent object recognition technique relies on the use of more complex feature descriptor such a sift descriptor or hog descriptor which are essentially histogram since histogram live in a non euclidean space we can no longer model their temporal evolution with ldss nor can we classify them using a metric for ldss in this paper we propose to represent each frame of a video using a histogram of oriented optical flow hoof and to recognize human action by classifying hoof time series for this purpose we propose a generalization of the binet cauchy kernel to nonlinear dynamical system nlds whose output life in a non euclidean space e g the space of histogram this can be achieved by using kernel defined on the original non euclidean space leading to a well defined metric for nldss we use these kernel for the classification of action in video sequence using hoof a the output of the nlds we evaluate our approach to recognition of human action in several scenario and achieve encouraging result 
non rigid surface registration particularly registration of human face find a wide variety of application in computer vision and graphic we present a new automatic surface registration method which utilizes both attraction force originating from geometrical and textural similarity and stress due to non linear elasticity of the surface reference and target surface are first mapped onto their feature image plane then these image are registered by subjecting them to local deformation and finally d correspondence are established surface are assumed to be elastic sheet and are represented by triangular mesh the internal elastic force act a a regularizer in this ill posed problem furthermore the non linear elasticity model allows u to handle large deformation which can be essential for instance for facial expression the method ha been tested successfully on d scanned human face with and without expression the algorithm run quite efficiently using a multiresolution approach 
we generalize reflection symmetry detection to a curved glide reflection symmetry detection problem we propose a unifying local feature based approach for curved glidereflection symmetry detection from real unsegmented image where the classic reflection symmetry becomes one of four special case our method detects and group statistically dominant local reflection ax in a d parameter space a curved glide reflection symmetry axis is estimated by a set of contiguous local straight reflection ax experimental result of the proposed algorithm on real world image demonstrate promising performance 
linear and multi linear model of object shape appearance pca dmm aam asm multilinear tensor have been very popular in computer vision in this paper we analyze the validity of these model from the fundamental physical law of object motion and image formation we rigorously prove that the image appearance space can be closely approximated to be locally multilinear with the illumination subspace being bilinearly combined with the direct sum of the motion deformation and texture subspace this result allows u to understand theoretically many of the success and limitation of the linear and multi linear approach existing in the computer vision literature and also identifies some of the condition under which they are valid it provides an analytical representation of the image space in term of different physical factor that affect the image formation process experimental analysis of the accuracy of the theoretical model is performed a well a tracking on real data using the analytically derived basis function of this space 
recognition of sign in sentence requires a training set constructed out of sign found in continuous sentence currently this is done manually which is a tedious process in this work we consider a framework where the modeler just provides multiple video sequence of sign language sentence constructed to contain the vocabulary of interest we learn the model of the recurring sign automatically specifically we automatically extract the part of the sign that are present in most occurrence of the sign in context these part of the sign that is stable with respect to adjacent sign are referred to a signemes each video is first transformed into a multidimensional time series representation capturing the motion and shape aspect of the sign we then extract signemes from multiple sentence concurrently using iterated conditional mode icm we show result by learning multiple instance of different sign from a set of sign language sentence we classify the extracted signemes a correct partially correct or incorrect depending on whether both the start and end location are correct only one of them is correct or both are incorrect respectively out of the extracted video signemes were correct were partially correct and were incorrect to demonstrate the generality of the unsupervised modeling idea we also show the ability to automatically extract common spoken word in audio we consider the english gloss spoken corresponding to the sign language sentence and extract the audio counterpart of the sign of the such instance we recovered correct partially correct and incorrect representation of the word 
a general framework simultaneously addressing pose estimation d segmentation object recognition and d reconstruction from a single image is introduced in this paper the proposed approach partition d space into voxels and estimate the voxel state that maximize a likelihood integrating two component the object fidelity that is the probability that an object occupies the given voxels here encoded a a d shape prior learned from d sample of object in a class and the image fidelity meaning the probability that the given voxels would produce the input image when properly projected to the image plane we derive a loop le graphical model for this likelihood and propose a computationally efficient optimization algorithm that is guaranteed to produce the global likelihood maximum furthermore we derive a multi resolution implementation of this algorithm that permit to trade reconstruction and estimation accuracy for computation the presentation of the proposed framework is complemented with experiment on real data demonstrating the accuracy of the proposed approach 
in this paper we present an approach we refer to a least square congealing which provides a solution to the problem of aligning an ensemble of image in an unsupervised manner our approach circumvents many of the limitation existing in the canonical congealing algorithm specifically we present an algorithm that i is able to simultaneously rather than sequentially estimate warp parameter update ii exhibit fast convergence and iii requires no pre defined step size we present alignment result which show an improvement in performance for the removal of unwanted spatial variation when compared with the related work of learned miller on two datasets the mnist hand written digit database and the multipie face database 
we study the problem of object classification when training and test class are disjoint i e no training example of the target class are available this setup ha hardly been studied in computer vision research but it is the rule rather than the exception because the world contains ten of thousand of different object class and for only a very few of them image collection have been formed and annotated with suitable class label in this paper we tackle the problem by introducing attribute based classification it performs object detection based on a human specified high level description of the target object instead of training image the description consists of arbitrary semantic attribute like shape color or even geographic information because such property transcend the specific learning task at hand they can be pre learned e g from image datasets unrelated to the current task afterwards new class can be detected based on their attribute representation without the need for a new training phase in order to evaluate our method and to facilitate research in this area we have assembled a new largescale dataset animal with attribute of over animal image that match the class in osherson s classic table of how strongly human associate semantic attribute with animal class our experiment show that by using an attribute layer it is indeed possible to build a learning object detection system that doe not require any training image of the target class 
in this paper we present a novel method the first to date to our knowledge which is capable of directly and automatically producing a concise and idealized d representation from unstructured point data of complex cluttered real world scene with a high level of noise and a significant proportion of outlier such a those obtained from passive stereo our algorithm can digest million of input point into an optimized lightweight watertight polygonal mesh free of self intersection that preserve the structural component of the scene at a user defined scale and completes missing scene part in a plausible manner to achieve this our algorithm incorporates prior on urban and architectural scene notably the prevalence of vertical structure and orthogonal intersection a major contribution of our work is an adaptive decomposition of d space induced by planar primitive namely a polyhedral cell complex we experimentally validate our approach on several challenging noisy point cloud of urban and architectural scene 
this paper introduces a method to correct over exposure in an existing photograph by recovering the color and lightness separately first the dynamic range of well exposed region is slightly compressed to make room for the recovered lightness of the over exposed region then the lightness is recovered based on an over exposure likelihood the color of each pixel is corrected via neighborhood propagation and also based on the confidence of the original color previous method make use of ratio between different color channel to recover the over exposed one and thus can not handle region where all three channel are over exposed in contrast our method doe not have this limitation our method is fully automatic and requires only one single input photo we also provide user with the flexibility to control the amount of over exposure correction experiment result demonstrate the effectiveness of the proposed method in correcting over exposure 
in this paper we pursue the task of aligning an ensemble of image in an unsupervised manner this task ha been commonly referred to a congealing in literature a form of congealing using a least square criterion ha been recently demonstrated to have desirable property over conventional congealing least square congealing can be viewed a an extension of the lucas kanade lk image alignment algorithm it is well understood that the alignment performance for the lk algorithm when aligning a single image with another is theoretically and empirical ly equivalent for additive and compositional warp in this pa per we i demonstrate that this equivalence doesnot hold for the extended case of congealing ii characterize the inherent drawback associated with least square congeal ing when dealing with large number of image and iii propose a novel method for circumventing these limitation through the application of an inverse compositional strat egy that maintains the attractive property of the origina l method while being able to handle very large number of image 
we propose a technique for cheap and efficient acquisition of mesostructure normal map from specularities which only requires a simple lcd monitor and a digital camera coded illumination enables u to capture subtle surface detail with only a handful of image in addition our method can deal with heterogeneous surface and high albedo material we are able to recover highly detailed mesostructures which wa previously only possible with an expensive hardware setup 
in this paper we present a method for learning classspecific feature for recognition recently a greedy layerwise procedure wa proposed to initialize weight of deep belief network by viewing each layer a a separate restricted boltzmann machine rbm we develop the convolutional rbm c rbm a variant of the rbm model in which weight are shared to respect the spatial structure of image this framework learns a set of feature that can generate the image of a specific object class our feature extraction model is a four layer hierarchy of alternating filtering and maximum subsampling we learn feature parameter of the first and third layer viewing them a separate c rbms the output of our feature extraction hierarchy are then fed a input to a discriminative classifier it is experimentally demonstrated that the extracted feature are effective for object detection using them to obtain performance comparable to the state of the art on handwritten digit recognition and pedestrian detection 
in this paper we develop a geometric framework for linear or nonlinear discriminant subspace learning and classification in our framework the structure of class are conceptualized a a semi riemannian manifold which is considered a a submanifold embedded in an ambient semiriemannian space the class structure of original sample can be characterized and deformed by local metric of the semi riemannian space semi riemannian metric are uniquely determined by the smoothing of discrete function and the nullity of the semi riemannian space based on the geometrization of class structure optimizing class structure in the feature space is equivalent to maximizing the quadratic quantity of metric tensor in the semiriemannian space thus supervised discriminant subspace learning reduces to unsupervised semi riemannian manifold learning based on the proposed framework a novel algorithm dubbed a semi riemannian discriminant analysis srda is presented for subspace based classification the performance of srda is tested on face recognition singular case and handwritten capital letter classification nonsingular case against existing algorithm the experimental result show that srda work well on recognition and classification implying that semi riemannian geometry is a promising new tool for pattern recognition and machine learning 
most modern computer vision system for high level task such a image classification object recognition and segmentation are based on learning algorithm that are able to separate discriminative information from noise in practice however the typical system consists of a long pipeline of pre processing step such a extraction of different kind of feature various kind of normalization feature selection and quantization into aggregated representation such a histogram along this pipeline there are many parameter to set and choice to make and their effect on the overall system performance is a priori unclear in this work we shorten the pipeline in a principled way we move pre processing step into the learning system by mean of kernel parameter letting the learning algorithm decide upon suitable parameter value learning to optimize the pre processing choice becomes learning the kernel parameter we realize this paradigm by extending the recent multiple kernel learning formulation from the finite case of having a fixed number of kernel which can be combined to the general infinite case where each possible parameter setting induces an associated kernel we evaluate the new paradigm extensively on image classification and object classification task we show that it is possible to learn optimal discriminative codebooks and optimal spatial pyramid scheme consistently outperforming all previous state of the art approach 
this paper present an empirical evaluation of the role of context in a contemporary challenging object detection task the pascal voc previous experiment with context have mostly been done on home grown datasets often with non standard baseline making it difficult to isolate the contribution of contextual information in this work we present our analysis on a standard dataset using topperforming local appearance detector a baseline we evaluate several different source of context and way to utilize it while we employ many contextual cue that have been used before we also propose a few novel one including the use of geographic context and a new approach for using object spatial support 
this work address the important problem of the discovery and analysis of social network from surveillance video a computer vision approach to this problem is made possible by the proliferation of video data obtained from camera network particularly state of the art pan tilt zoom ptz and tracking camera system that have the capability to acquire high resolution face image a well a track of people under challenging condition we perform opportunistic face recognition on captured image and compute motion similarity between track of people on the ground plane to deal with the unknown correspondence between face and track we present a novel graph cut based algorithm to solve this association problem it enables the robust estimation of a social network that capture the interaction between individual in spite of large amount of noise in the datasets we also introduce an algorithm that we call modularity cut which is an eigen analysis based approach for discovering community and leadership structure in the estimated social network our approach is illustrated with promising result from a fully integrated multi camera system under challenging condition over long period of time 
analytic manifold were recently used for motion averaging segmentation and robust estimation here we consider the epipolar constraint for calibrated camera which is the most general motion model for calibrated camera and is encoded by the essential matrix the set of all essential matrix form the essential manifold we provide a theoretical characterization of the geometry of the essential manifold and develop a parametrization which associate each essential matrix with a unique point on the manifold our work provides a more complete theoretical analysis of the essential manifold than previous work in this direction we show the result of using this parametrization with real data set while previous work concentrated on theoretical analysis with synthetic data 
we present a novel method for modeling dynamic visual phenomenon which consists of two key aspect first the integral motion of constituent element in a dynamic scene is captured by a common underlying geometric transform process second a lie algebraic representation of the transform process is introduced which map the transformation group to a vector space and thus overcomes the difficulty due to the group structure consequently the statistical learning technique based on vector space can be readily applied moreover we discus the intrinsic connection between the lie algebra and the linear dynamical process showing that our model induces spatially varying field that can be estimated from local motion without continuous tracking following this we further develop a statistical framework to robustly learn the flow model from noisy and partially corrupted observation the proposed methodology is demonstrated on real world phenomenon inferring common motion pattern from surveillance video of crowded scene and satellite data of weather evolution 
visual recognition and detection are computationally intensive task and current research effort primarily focuson solving them without considering the computational capability of the devicesthey run on in this paperwe explore the challenge of deriving method that consider constraint on computation appropriatelyschedule the next best computation to perform and finally have the capability of producing reasonable result at any time when a solution is required we specifically derive an approach for the task of object category localization and classification in cluttered natural scene that can not only produce anytime result but also utilize the principle of value of information in order to provide the most recognition bang for the computational buck experiment on two standard object detection challenge show that the proposed framework can triage computation effectively and attain state of the art result when allowed to run till completion additionally the real benefit of the proposed framework is highlighted in the experiment where we demonstrate that the method can provide reasonable recognition result even if the procedure need to terminate before completion 
in this paper we present a solution to the novel problem of recognizing primitive actor object interaction from video here we introduce the concept of actor object state our method is based on the observation that at the moment of physical contact both the motion and the appearance of actor are constrained by the target object we propose a probabilistic framework that automatically learns model in such constrained state we use joint probability distribution to represent both actor and object appearance a well a their intrinsic spatio temporal configuration finally we demonstrate the applicability of our approach on series of human object interaction classification experiment 
we propose a novel algorithm for clustering data sampled from multiple submanifolds of a riemannian manifold first we learn a representation of the data using generalization of local nonlinear dimensionality reduction algorithm from euclidean to riemannian space such generalization exploit geometric property of the riemannian space particularly it riemannian metric then assuming that the data point from different group are separated we show that the null space of a matrix built from the local representation give the segmentation of the data our method is computationally simple and performs automatic segmentation without requiring user initialization we present result on d motion segmentation and diffusion tensor imaging segmentation 
this paper present a nonparametric discriminant hmm and applies it to facial expression recognition in the proposed hmm we introduce an effective nonparametric output probability estimation method to increase the discrimination ability at both hidden state level and class level the proposed method us a nonparametric adaptive kernel to utilize information from all class and improve the discrimination at class level the discrimination between hidden state is increased by defining membership coefficient which associate each reference vector with hidden state the adaption of such coefficient is obtained by the expectation maximization em method furthermore we present a general formula for the estimation of output probability which provides a way to develop new hmms finally we evaluate the performance of the proposed method on the cmu expression database and compare it with other nonparametric hmms 
currently video analysis algorithm suffer from lack of information regarding the object present their interaction a well a from missing comprehensive annotated video database for benchmarking we designed an online and openly accessible video annotation system that allows anyone with a browser and internet access to efficiently annotate object category shape motion and activity information in real world video the annotation are also complemented with knowledge from static image database to infer occlusion and depth information using this system we have built a scalable video database composed of diverse video sample and paired with human guided annotation we complement this paper demonstrating potential us of this database by studying motion statistic a well a cause effect motion relationship between object 
non negative matrix factorization nmf is an excellent tool for unsupervised part based learning but prof to be ineffective when part of a whole follow a specific pattern analyzing such local change is particularly important when studying anatomical transformation we propose a supervised method that incorporates a regression constraint into the nmf framework and learns maximally changing part in the basis image called regression based nmf rnmf the algorithm is made robust against outlier by learning the distribution of the input manifold space where the data resides one of our main goal is to achieve good region localization by incorporating a gradient smoothing and independence constraint into the factorized base contiguous local region are captured we apply our technique to a synthetic dataset and structural mri brain image of subject with varying age rnmf find the localized region which are expected to be highly changing over age to be manifested in it significant basis and it also achieves the best performance compared to other statistical regression and dimensionality reduction technique 
in this paper we demonstrate that the support vector tracking svt framework first proposed by avidan is equivalent to the canonical lucas kanade lk algorithm with a weighted euclidean norm from this equivalence we empirically demonstrate that in many circumstance the canonical svt approach is unstable and characterize these circumstance theoretically we then propose a novel nonpositive support kernel machine nskm to circumvent this limitation and allow the effective use of discriminative classification within the weighted lk framework this approach ensures that the pseudo hessian realized within the weighted lk algorithm is positive semidefinite which allows for fast convergence and accurate alignment tracking a further benefit of our proposed method is that the nskm solution result in a much sparser kernel machine than the canonical svm leading to sizeable computational saving and much improved alignment performance 
abstract we address the problem of label assignment in computer vision given a novel d or d scene we wish to assign a unique label to every site voxel pixel superpixel etc to this end the markov random field framework ha proven to be a model of choice a it us contextual information to yield improved classification result over locally independent classifier in this work we adapt a functional gradient approach for learning high dimensional parameter of random field in order to perform discrete multi label classification with this approach we can learn robust model involving high order interaction better than the previously used learning method we validate the approach in the context of point cloud classification and improve the state of the art in addition we successfully demonstrate the generality of the approach on the challenging vision problem of recovering d geometric surface from image 
sparse representation in compressive sensing is gaining increasing attention due to it success in various application a we demonstrate in this paper however image sparse representation is sensitive to image plane transformation such that existing approach can not reconstruct the sparse representation of a geometrically transformed image we introduce a simple technique for obtaining transformation invariant image sparse representation it is rooted in two observation if the aligned model image of an object span a linear subspace their transformed version with respect to some group of transformation can still span a linear subspace in a higher dimension if a target or test image aligned with the model image life in the above subspace it pre alignment version would get closer to the subspace after applying estimated transformation with more and more accurate parameter these observation motivate u to project a potentially unaligned target image to random projection manifold defined by the model image and the transformation model each projection is then separated into the aligned projection target and a residue due to misalignment the desired aligned projection target is then iteratively optimized by gradually diminishing the residue in this framework we can simultaneously recover the sparse representation of a target image and the image plane transformation between the target and the model image we have applied the proposed methodology to two application face recognition and dynamic texture registration the improved performance over previous method that we obtain demonstrates the effectiveness of the proposed approach 
interactive image search or relevance feedback is the process which help a user refining his query and finding difficult target category this consists in partially labeling a very small fraction of an image database and iteratively refining a decision rule using both the labeled and unlabeled data training of this decision rule is referred to a transductive learning our work is an original approach for relevance feedback based on graph laplacian we introduce a new graph laplacian which make it possible to robustly learn the embedding of the manifold enclosing the dataset via a diffusion map our approach is three fold it allows u i to integrate all the unlabeled image in the decision process ii to robustly capture the topology of the image set and iii to perform the search process inside the manifold relevance feedback experiment were conducted on simple database including olivetti and swedish a well a challenging and large scale database including corel comparison show clear and consistent gain of our graph laplacian method with respect to state of the art relevan ce feedback approach 
in this paper we propose an image super resolution approach using a novel generic image prior gradient profile prior which is a parametric prior describing the shape and the sharpness of the image gradient using the gradient profile prior learned from a large number of natural image we can provide a constraint on image gradient when we estimate a hi resolution image from a low resolution image with this simple but very effective prior we are able to produce state of the art result the reconstructed hi resolution image is sharp while ha rare ringing or jaggy artifact 
web photo in social medium sharing website such a flickr are generally accompanied by rich but noisy textual description tag caption category etc in this paper we proposed a tag based photo retrieval framework to improve the retrieval performance for flickr photo by employing a novel batch mode re tagging method the proposed batch mode re tagging method can automatically refine noisy tag of a group of flickr photo uploaded by the same user within a short period by leveraging million of training web image and their associated rich textual description specifically for one group of flickr photo we construct a group specific lexicon which contains only the tag of all photo within the group for each query tag we employ the inverted file method to automatically find loosely labeled training web image we propose a svm with augmented feature referred to a afsvm to learn adapted classifier to refine the annotation tag of photo by leveraging the existing svm classifier of popular tag which are associated with a large amount of positive training web image moreover to further refine the annotation tag of photo in the same group we additionally introduce an objective function that utilizes the visual similarity of photo within the group a well a the semantic proximity of their tag based on the refined tag photo can be retrieved according to more reliable relevance score extensive experiment demonstrate the effectiveness of our framework 
we propose a subspace learning algorithm for face recognition by directly optimizing recognition performance score our approach is motivated by the following observation different face recognition task i e face identification and verification have different performance metric which implies that there exist distinguished subspace that optimize these score respectively most prior work focused on optimizing various discriminative or locality criterion and neglect such distinction a the gallery target and the probe query data are collected in different setting in many real world application there could exist consistent appearance incoherence between the gallery and the probe data for the same subject knowledge regarding these incoherence could be used to guide the algorithm design resulting in performance gain prior effort have not focused on these fact in this paper we rigorously formulate performance score for both the face identification and the face verification task provide a theoretical analysis on how the optimal subspace for the two task are related and derive gradient descent algorithm for optimizing these subspace our extensive experiment on a number of public database and a real world face database demonstrate that our algorithm can improve the performance of given subspace based face recognition algorithm targeted at a specific face recognition task 
in this paper we present an approach to multi view image based d reconstruction by statistically inversing the ray tracing based image generation process the proposed algorithm is fast accurate and doe not need any initialization the geometric representation is a discrete volume divided into voxels with each voxel associated with two property opacity shape and color appearance the problem is then formulated a inferring each voxel s most probable opacity and color through map estimation of the developed ray markov random field raymrf raymrf is constructed with three kind of clique the usual unary and pairwise clique favoring connected voxel region and most importantly ray clique modelling the ray tracing based image generation process each ray clique connects the voxels that the viewing ray pass through it provides a principled way of modeling the occlusion without approximation the inference problem involved in the map estimation is handled by an optimized belief propagation algorithm one unusual structure of the proposed mrf is that each ray clique usually involves hundred thousand of random variable which seems to make the inference computationally formidable thanks to the special property of the ray clique functional form we investigate the deep factorization property of ray clique energy and get a highly efficient algorithm based on the general loopy belief propagation which ha reduced the computational complexity from exponential to linear both of the efficient inference algorithm and the overall system concept are new combining these result in an algorithm that can reverse the image generation process very fast d surface reconstruction in a i e voxel space with image requires roughly minute on a ghz single core cpu the running time grows linearly with respect to the number of voxels and the number of image and the speed could be further improved with a hierarchical sparse representation of the volume like octree experiment on several standard datasets show the quality and speed of the proposed model and algorithm 
graph based semi supervised learning ha gained considerable interest in the past several year thanks to it effectiveness in combining labeled and unlabeled data through label propagation for better object modeling and classification a critical issue in constructing a graph is the weight assignment where the weight of an edge specifies the similarity between two data point in this paper we present a novel technique to measure the similarity among data point by decomposing each data point a an l sparse linear combination of the rest of the data point the main idea is that the coefficient in such a sparse decomposition reflect the point s neighborhood structure thus providing better similarity measure among the decomposed data point and the rest of the data point the proposed approach is evaluated on four commonly used data set and the experimental result show that the proposed sparsity induced similarity si measure significantly improves label propagation performance a an application of the si based label propagation we show that the si measure can be used to improve the bag of word approach for scene classification 
this paper address a key bottleneck in the use of the d medial axis ma representation namely how the complex ma structure can be regularized so that similar within category d shape yield similar d ma that are distinct from the non category shape we rely on previous work which i construct a hierarchical ma hypergraph the medial scaffold m and ii the theoretical classification of the instability of this structure or transition sudden topological change due to a small perturbation the shape at transition point are degenerate our approach is to recognize the transition which are close by to a given shape and transform the shape to this transition point and repeat until no close by transition exists this move towards degeneracy is the basis of simplification of shape we derive transforms from transition and follow a greedy scheme in applying the transform the result show that the simplified ma preserve with in category similarity thus indicating it potential use in various application including shape analysis manipulation and matching 
in this paper we propose a high order graph matching formulation to address non rigid surface matching the singleton term capture the geometric and appearance similarity e g curvature and texture while the high order term model the intrinsic embedding energy the novelty of this paper includes casting d surface registration into a graph matching problem that combine both geometric and appearance similarity and intrinsic embedding information the first implementation of high order graph matching algorithm that solves a non convex optimization problem and an efficient two stage optimization approach to constrain the search space for dense surface registration our method is validated through a series of experiment demonstrating it accuracy and efficiency notably in challenging case of large and or non isometric deformation or mesh that are partially occluded 
this paper study image alignment the problem of learning a shape and appearance model from labeled data and efficiently fitting the model to a non rigid object with large variation given a set of image with manually labeled landmark our model representation consists of a shape component represented by a point distribution model and an appearance component represented by a collection of local feature trained discriminatively a a two class classifier using boosting image with ground truth landmark are the positive training sample while those with perturbed landmark are considered a negative enabled by piece wise affine warping corresponding local feature position across all training sample form a hypothesis space for boosting image alignment is performed by maximizing the boosted classifier score which is our distance measure through iteratively mapping the feature position to the image and computing the gradient direction of the score with respect to the shape parameter we apply this approach to human body alignment from surveillance type image we conduct experiment on the mit pedestrian database where the body size is approximately time pixel and demonstrate our real time alignment capability 
given an image we propose a hierarchical generative model that classifies the overall scene recognizes and segment each object component a well a annotates the image with a list of tag to our knowledge this is the first model that performs all three task in one coherent framework for instance a scene of a polo game consists of several visual object such a human horse grass etc in addition it can be further annotated with a list of more abstract e g dusk or visually le salient e g saddle tag our generative model jointly explains image through a visual model and a textual model visually relevant object are represented by region and patch while visually irrelevant textual annotation are influenced directly by the overall scene class we propose a fully automatic learning framework that is able to learn robust scene model from noisy web data such a image and user tag from flickr com we demonstrate the effectiveness of our framework by automatically classifying annotating and segmenting image from eight class depicting sport scene in all three task our model significantly outperforms state of the art algorithm 
detecting object in complex scene while recovering the scene layout is a critical functionality in many vision based application inspired by the work of we advocate the importance of geometric contextual reasoning for object recognition we start from the intuition that object location and pose in the d space are not arbitrarily distributed but rather constrained by the fact that object must lie on one or multiple supporting surface we model such supporting surface by mean of hidden parameter i e not explicitly observed and formulate the problem of joint scene reconstruction and object recognition a the one of finding the set of parameter that maximizes the joint probability of having a number of detected object on k supporting plane given the observation a a key ingredient for solving this optimization problem we have demonstrated a novel relationship between object location and pose in the image and the scene layout parameter i e normal of one or more supporting plane in d and camera pose location and focal length using the probabilistic formulation and the above relationship our method ha the unique ability to jointly i reduce false alarm and false negative object detection rate ii recover object location and supporting plane within the d camera reference system iii infer camera parameter view point and the focal length from just one single uncalibrated image quantitative and qualitative experimental evaluation on a number of datasets a novel in house dataset and label me on car and pedestrian demonstrates our theoretical claim 
depth map captured with time of flight camera have very low data quality the image resolution is rather limited and the level of random noise contained in the depth map is very high therefore such flash lidar cannot be used out of the box for high quality d object scanning to solve this problem we present lidarboost a d depth superresolution method that combine several low resolution noisy depth image of a static scene from slightly displaced viewpoint and merges them into a high resolution depth image we have developed an optimization framework that us a data fidelity term and a geometry prior term that is tailored to the specific characteristic of flash lidar we demonstrate both visually and quantitatively that lidarboost produce better result than previous method from the literature 
we present a novel framework for learning pattern of motion and size of object in static camera surveillance the proposed method provides a new higher level layer to the traditional surveillance pipeline for anomalous event detection and scene model feedback pixel level probability density function pdfs of appearance have been used for background modelling in the past but modelling pixel level pdfs of object speed and size from the track is novel each pdf is modelled a a multivariate gaussian mixture model gmm of the motion destination location transition time and the size width height parameter of the object at that location output of the tracking module is used to perform unsupervised em based learning of every gmm we have successfully used the proposed scene model to detect local a well a global anomaly in object track we also show the use of this scene model to improve object detection through pixel level parameter feedback of the minimum object size and background learning rate most object path modelling approach first cluster the track into major path in the scene which can be a source of error we avoid this by building local pdfs that capture a variety of track which are passing through them qualitative and quantitative analysis of actual surveillance video proved the effectiveness of the proposed approach 
most active scene recovery technique assume that a scene point is illuminated only directly by the illumination source consequently global illumination effect du e to inter reflection sub surface scattering and volumetr ic scattering introduce strong bias in the recovered scene shape our goal is to recover scene property in the presence of global illumination to this end we study the interplay between global illumination and the depth cue of illumination defocus by expressing both these effect a low pas filter we derive an approximate invariant that can be used to separate them without explicitly modeling the light transport this is directly useful in any scenario where limited depth of field device such a projector a re used to illuminate scene with global light transport and significant depth variation we show two application a accurate depth recovery in the presence of global illumination and b factoring out the effect of defocus for correc t direct global separation in large depth scene we demonstrate our approach using scene with complex shape reflectance texture and translucency quire explicit modeling of global light transport given t he complexity of global illumination this can be intractable we consider illumination defocus the depth cue for the shape from projector defocus approach in this case we show that global illumination can be separated from the depth cue without explicitly modeling or measuring light transport the key observation is that both illumination de focus and global illumination manifest a low pas filter during image formation if the scene is illuminated with a periodic illumination pattern we show that the observed radiance at each pixel over time can be modeled a a convolution of the input pattern with the two blur kernel associate d with defocus and global illumination see figure expressing both the shape cue defocus and global illumination a blur kernel can appear to be counterproductive a it may make it harder to separate the two however illumination defocus and global illumination are different physical phenomenon illumination defocus is a result of the optic of the source and encodes scene depth on the other hand global illumination encodes the intrinsic property of the scene such a d geometry and material property thus although changing the projector focus setting change the defocus blur the global illumination blur remains approximately constant based on this observation we derive an invariant between global illumination blur and defocused illumination which can be used to separate the two effect this invariant is directly useful in scenar io where limited depth of field device such a projector s are used to illuminate scene with global light transport an d large depth variation we show two application which require separation of defocus and global illumination first accurate depth recovery in the presence of global illumination sub surface scattering and inter reflection we follow the frequency domain approach of zhang et al and derive two depth estimation algorithm the first algorithm requires a sweep of the projector focal plane across the scene and is dual to shape from camera focus technique the second algorithm requires only two focal plane setting and is similar in spirit to shape from camera defocus method second separation of the direct and global component of light transport for scene with depth variation larger than the narrow depth of field of projector m we follow the spatial domain approach of nayar et al and derive defocus invariant measure of global illumination again we present two algorithm for separation based on a multiple focal plane position and b single focal plane posit ion and a depth map estimated in the first application 
in this paper based on manifold harmonic we propose a novel framework for d shape similarity comparison and partial matching first we propose a novel symmetric mean value representation to robustly construct high quality manifold harmonic base on nonuniform sampling mesh then based on the manifold harmonic base constructed a novel shape descriptor is presented to capture both of global and local feature of d shape this feature descriptor is isometry invariant i e invariant to rigid body transformation and non rigid bending after characterizing d model with the shape feature we perform d retrieval with a up to date discriminative kernel this kernel is a dimension free approach to quantifying the similarity between two unordered feature set thus especially suitable for our high dimensional feature data experimental result show that our framework can be effectively used for both comprehensive comparison and partial matching among non rigid d shape 
in this paper we propose a prior for hand pose estimation that integrates the direct relation between a manipulating hand and a d object this is of particular interest for a variety of application since many task performed by human require hand object interaction inspired by the ability of human to learn the handling of an object from a single example our focus lie on very sparse training data we express estimated hand pose in local object coordinate and extract for each individual hand segment the relative position and orientation a well a contact point on the object the prior is then modeled a a spatial distribution conditioned to the object given a new object of the same object class and new hand dimension we can transfer the prior by a procedure involving a geometric warp in our experiment we demonstrate that the prior may be used to improve the robustness of a d hand tracker and to synthesize a new hand grasping a new object for this we integrate the prior into a unified belief propagation framework for tracking and synthesis 
lambert s model is widely used in low level computer vision algorithm such a matching tracking or optical ow computation for example however it is well known that these algorithm often fail when they face complex luminance variation therefore we revise in this paper the underlying hypothesis of it temporal constancy and propose a new optical ow constraint to do that we use the blinnphong reection model to take into account that the scene may move with respect to the lighting and or to the observer and that specular highlight may occur to validate in practice these analytical result we consider the case where a camera is mounted on a robot end effector with a lighting mounted on this camera and show experimental result of target tracking by visual servoing such an approach requires to analytically compute the luminance variation due to the observer motion which can be easily derived from our revised optical ow constraint in addition while the visual servoing classical approach rely on geometric feature we present here a new method that directly relies on the luminance of all pixel in the image which doe not require any tracking or matching process 
this paper address the question of computationally inexpensive yet discriminative and robust feature set for real world face recognition the proposed descriptor named pattern of oriented edge magnitude poem ha desirable property poem is an oriented spatial multi resolution descriptor capturing rich information about the original image is a multi scale self similarity based structure that result in robustness to exterior variation and is of low complexity and is therefore practical for real time application briefly speaking for every pixel the poem feature is built by applying a self similarity based structure on oriented magnitude calculated by accumulating a local histogram of gradient orientation over all pixel of image cell centered on the considered pixel the robustness and discriminative power of the poem descriptor is evaluated for face recognition on both constrained feret and unconstrained lfw datasets experimental result show that our algorithm achieves better performance than the state of the art representation more impressively the computational cost of extracting the poem descriptor is so low that it run around time faster than just the first step of the method based upon gabor filter moreover it data storage requirement are and time smaller than those of the lgbp local gabor binary pattern and hgpp histogram of gabor phase pattern descriptor respectively 
we consider a class of region based energy for image segmentation and inpainting which combine region integral with curvature regularity of the region boundary to minimize such energy we formulate an integer linear program which jointly estimate region and their boundary curvature regularity is imposed by respective cost on pair of adjacent boundary segment by solving the associated linear programming relaxation and thresholding the solution one obtains an approximate solution to the original integer problem to our knowledge this is the first approach to impose curvature regularity in region based formulation in a manner that is independent of initialization and allows to compute a bound on the optimal energy in a variety of experiment on segmentation and inpainting we demonstrate the advantage of higher order regularity moreover we demonstrate that for most experiment the optimality gap is smaller than of the global optimum for many instance we are even able to compute the global optimum 
measuring image similarity is a central topic in computer vision in this paper we learn similarity from flickr group and use it to organize photo two image are similar if they are likely to belong to the same flickr group our approach is enabled by a fast stochastic intersection kernel machine sikma training algorithm which we propose this proposed training method will be useful for many vision problem a it can produce a classifier that is more accurate than a linear classifier trained on ten of thousand of example in two minute the experimental result show our approach performs better on image matching retrieval and classification than using conventional visual feature 
a guidewire is a medical device inserted into vessel during image guided intervention for balloon inflation during intervention the guidewire undergoes non rigid deformation due to patient breathing and cardiac motion and such d motion are complicated when being projected onto the d fluoroscopy furthermore in fluoroscopy there exist severe image artifact and other wire like structure all these make robust guidewire tracking challenging to address these challenge this paper present a probabilistic framework for robust guidewire tracking we first introduce a semantic guidewire model that contains three part including a catheter tip a guidewire tip and a guidewire body measurement of different part are integrated into a bayesian framework a measurement of a whole guidewire for robust guidewire tracking moreover for each part two type of measurement one from learning based detector and the other from online appearance model are applied and combined a hierarchical and multi resolution tracking scheme is then developed based on kernel based measurement smoothing to track guidewires effectively and efficiently in a coarse to fine manner the presented framework ha been validated on a test set of sequence and achieves a mean tracking error of le than pixel this demonstrates the great potential of our method for clinical application 
psychologist have proposed that many human object interaction activity form unique class of scene recognizing these scene is important for many social function to enable a computer to do this is however a challenging task take people playing musical instrument ppmi a an example to distinguish a person playing violin from a person just holding a violin requires subtle distinction of characteristic image feature and feature arrangement that differentiate these two scene most of the existing image representation method are either too coarse e g bow or too sparse e g constellation model for performing this task in this paper we propose a new image feature representation called grouplet the grouplet capture the structured information of an image by encoding a number of discriminative visual feature and their spatial configuration using a dataset of different ppmi activity we show that grouplets are more effective in classifying and detecting human object interaction than other state of the art method in particular our method can make a robust distinction between human playing the instrument and human co occurring with the instrument without playing 
recognizing people in image is one of the foremost challenge in computer vision it is important to remember that consumer photography ha a highly social aspect the photographer capture image not in a random fashion but rather to remember or document meaningful event in her life the culture of the society of which the photographer is a part provides a strong context for recognizing the content of the captured image we demonstrate one aspect of this cultural context by recognizing people from first name the distribution of first name chosen for newborn baby evolves with time and is gender specific a a result a first name provides a strong prior for describing the individual specifically we use the u s social security administration baby name database to learn prior for gender and age for first name most face recognition method do not even consider the name of the individual of interest or the name is treated merely a an identifier that provides no information about appearance in contrast we combine image based gender and age classifier with the cultural context information provided by first name to recognize people with no labeled example our model us image based age and gender estimate for assigning first name to people and in turn the age and gender estimate are improved 
we propose a face recognition approach based on hashing the approach yield comparable recognition rate with the random approach which is considered the state of the art but our method is much faster it is up to time faster than on the yaleb dataset we show that with hashing the sparse representation can be recovered with a high probability because hashing preserve the restrictive isometry property moreover we present a theoretical analysis on the recognition rate of the proposed hashing approach experiment show a very competitive recognition rate and significant speedup compared with the state of the art 
activity analysis is a basic task in video surveillance and ha become an active research area however due to the diversity of moving object category and their motion pattern developing robust semantic scene model for activity analysis remains a challenging problem in traffic scenario this paper proposes a novel framework to learn semantic scene model in this framework the detected moving object are first classified a pedestrian or vehicle via a co trained classifier which take advantage of the multiview information of object a a result the framework can automatically learn motion pattern respectively for pedestrian and vehicle then a graph is proposed to learn and cluster the motion pattern to this end trajectory is parameterized and the image is cut into multiple block which are taken a the node in the graph based on the parameter of trajectory the primary motion pattern in each node block are extracted via gaussian mixture model gmm and supplied to this graph the graph cut algorithm is finally employed to group the motion pattern together and trajectory are clustered to learn semantic scene model experimental result and application to real world scene show the validity of our proposed method 
in this paper range flow estimation is extended to handle brightness change in image data caused by inhomogeneous illumination standard range flow computes d velocity field from range and intensity image sequence to this end it combine a depth change model and a brightness constancy model in this contribution the brightness constancy model is exchanged by a gradient constancy model a combination of gradient and brightness constancy constraint that ha been used successfully for optical flow estimation in literature and a physic based brightness change model insensitivity to brightness change can also be achieved by prefiltering of the input intensity data high pas or homomorphic filtering are the most well known approach from literature in performance test therefore the well known version and the novel version of range flow estimation are investigated on prefiltered or non prefiltered data using synthetic ground truth and real data from a botanical experiment 
this is a high level computer vision paper which employ concept from natural language understanding in solving the video retrieval problem our main contribution is the utilization of the semantic word similarity measure lin and pmi ir similarity for video retrieval in our approach we use trained concept detector and the visual co occurrence relation between such concept we propose two method for content based retrieval of video a method for retrieving a new concept a concept which is not known to the system and no annotationis available using semantic word similarity and visual co occurrence a method for retrieval of video based on their relevance to a user defined text query using the semantic word similarity and visual content of video for evaluation purpose we have mainly used the automatic search and the high level feature extraction test set of trecvid benchmark and the automatic search test set of trecvid these two data set consist of hour of multilingual news video captured from american arabic german and chinese tv channel although our method for retrieving a new concept is an unsupervised method it outperforms the trained concept detector which are supervised on out of test concept and overall it performs very close to the trained detector on the other hand our visual content based semantic retrieval method performs better than the textbased retrieval method this show that using visual content alone we can obtain significantly good retrieval result 
through radiometric compensation a projector camera system can project a desired image onto a non flat and non white surface this can be achieved by computing the inverse light transport of a scene a light transport matrix is in general large and on the order of element therefore computing the inverse light transport matrix is computationally and memory intensive two prior method were proposed to simplify matrix inversion by ignoring scene inter reflection between individual or cluster of camera pixel however compromising scene inter reflection in spatial domain introduces spatial artifact and how to systematically adjust the compensation quality is not obvious in this work we show how scene inter reflection can be systematically approximated by stratifying the light transport of a scene the stratified light transport enables a similar stratification in the inverse light transport we can show that the stratified inverse light transport converges to the true inverse for radiometric compensation the set of stratified inverse light transport provides a systematic way of quantifying the tradeoff between computational efficiency and accuracy the framework of stratified matrix inversion is general and can have other application especially for application that involve large size sparse matrix 
this paper address the problem of rigid and nonrigid shape registration and recovery in the presence of shape deformation missing part and or overlapping of multiple shape a novel shape evolution approach based on truncated warping transformation formulated in an energy minimization curve evolution framework is proposed to solve this problem we deterministically model the rigid and nonrigid shape deformation registration a curve evolution by a warping function mapping we also derive the curve evolution equation of warping to minimize functional energy hence by selecting a prior shape a the initial curve for the curve evolution the shape evolution for registration is within the shape space generated by the warping transformation of the prior shape based on the fourier shape contour spectrum local shape contour distortion that result in significant visual impact is considered to be largely contained in the change of the high frequency component thus the smoothing of the warping function by truncation is performed to recover the true shape we adopted the chan vese model and a truncated warping function to obtain our algorithm for shape registration and recovery experiment validated our model and algorithm quantitatively 
several researcher have addressed the problem of human action recognition using a variety of algorithm an underlying assumption in most of these algorithm is that action boundary are already known in a test video sequence in this paper we propose a fast method for continuous human action recognition in a video sequence we propose the use of a low dimensional feature vector which consists of a the projection of the width profile of the actor on to a discrete cosine transform dct basis and b simple spatio temporal feature we use an earlier proposed average template with multiple feature for modelling human action and combine it with one pas dynamic programing dp algorithm for continuous action recognition this model account for intra class variability in the way an action is performed furthermore we demonstrate a way to perform noise robust recognition by creating a noise match condition between the train and the test data the effectiveness of our method is demonstrated by conducting experiment on the ixmas dataset of person performing various action and an outdoor action database collected by u 
the ambiguity inherent in a localized analysis of event from video can be resolved by exploiting constraint between event and examining only feasible global explanation we show how jointly recognizing and linking event can be formulated a labeling of a bayesian network the framework can be extended to multiple linking layer expressing explanation a compositional hierarchy the best global explanation is the maximum a posteriori map solution over a set of feasible explanation the search space is sampled using reversible jump markov chain monte carlo rjmcmc we propose a set of general move type that is extensible to multiple layer of linkage and u se simulated annealing to find the map solution given all observation we provide experimental result for a challeng ing two layer linkage problem demonstrating the ability t o recognise and link drop and pick event of bicycle in a rack over five day 
in this paper we present a novel framework to address the confounding effect of illumination variation in face recognition by augmenting the gallery set with realistically relit image we enhance recognition performance in a classier independent way we describe a novel method for single image relighting morphable reectance field morf which doe not require manual intervention and provides relighting superior to that of existing automatic method we test our framework through face recognition experiment using various state of the art classier s and popular benchmark datasets cmu pie multi pie and merl dome we demonstrate that our morf relighting and gallery augmentation framework achieves improvement in term of both rank recognition rate and roc curve we also compare our model with other automatic relighting method to conrm it advantage finally we show that the recognition rate achieved using our framework exceed those of state of the art recognizers on the aforementioned database 
abstract ieee conference on computer vision and pattern recognition miami beach florida june our goal is to turn an intensity image into it perceived luminance without parsing it into depth surface or scene illumination we start with jarring intensity difference at two scale mixed according to edge identified by a pixelcentric edge detector we propose angular embedding a a more robust efficient and versatile alternative to l lle and ncuts for obtaining a global brightness ordering from local difference our model explains a variety of brightness illusion with a single algorithm brightness of a pixel can be understood locally a it intensity deviating in the gradient direction and globally a finding it rank relative to others particularly the lightest and darkest one 
correspondence problem are of great importance in computer vision they appear a subtasks in many application such a object recognition merging partial d reconstruction and image alignment automatically matching feature from appearance only is difficult and error are frequent thus it is necessary to use geometric consistency to remove incorrect correspondence typically heuristic method like ransac or em like algorithm are used but they risk getting trapped in local optimum and are in no way guaranteed to find the best solution this paper illustrates how pairwise constraint in combination with graph method can be used to efficiently find optimal correspondence these idea are implemented on two basic geometric problem d d registration and d d registration the developed scheme can handle large rate of outlier and cope with multiple hypothesis despite the combinatorial explosion the resulting algorithm which ha been extensively evaluated on real data yield competitive running time compared to state of the art 
in this work we consider the dense reconstruction of specular object we propose the use of a specularity constraint based on surface normal depth consistency to define a matching cost function that can drive standard stereo reconstruction method we discus the type of ambiguity that can arise and suggest an aggregation method based on anisotropic diffusion that is particularly suitable for this matching cost function we also present a controlled illumination setup that includes a pair of camera and one lcd monitor which is used a a calibrated variable position light source we use this setup to evaluatethe proposedmethod on real data and demonstrate it capacity to recover high quality depth and orientation from specular object with some hypothesized position and normal the proposed position normaltuple exhibit specularity consistency if the observed pixel is consistent with the intersection of the reflected ray and the known scene given only a single camera position we find that an infinity of position normal tuples will necessarily satisfy the consistency condition for any proposed position we can find a normal such that the reflected ray hit any desired scene point two camera position however provide disambiguating information and in most case restrict u to a single allowed position normal exception are discussed later in the paper note that in general a point is reconstructed not because different camera observe the same part of the scene reflected from it they observe different reflection that are both consistent with the hypothesized position normal this specularity consistency condition ha been previously identified and exploited in other context we propose to use the constraint to define a matching cost function for two camera view and demonstrate that the condition may be used for dense stereo reconstructionof specular d object we analyze our system on synthetic imagery and show real world result our contribution include defining a stereo matching cost function based on the specularity consistency constraint proposing a novel normal based anisotropic diffusion scheme for the matching cost which strengthens match lying on a continuous surface presentinga theoreticalanalysis of the ambiguitiesthat can arise from the specularity consistency constraint obtaining dense and accurate d reconstruction of specular object by directly exploiting this constraint 
edge detection in image ha been a fundamental problem in computer vision from it early day edge detection on surface on the other hand ha received much le attention the most common edge on surface are ridge and valley used for processing range image in computer vision a well a for non photorealistic rendering in computer graphic we propose a new type of edge on surface termed relief edge intuitively the surface can be considered a an unknown smooth manifold on top of which a local height image is placed relief edge are the edge of this local image we show how to compute these edge from the local differential geometric surface property by fitting a local edge model to the surface we also show how the underlying manifold and the local image can be roughly approximated and exploited in the edge detection process last but not least we demonstrate the application of relief edge to artifact illustration in archaeology 
automated tracking of vehicle and people is essential for the effective utilization of imagery in wide area surveillance application in order to determine the best tracking algorithm and parameter for a given application a comprehensive evaluation procedure is required however despite half a century of research in multi target tracking there is no consensus on how to score the overall performance of these tracker existing evaluation approach ass tracker performance through measure of correspondence between ground truth track and system track using metric such a track detection rate track completeness track fragmentation rate and track id change rate however each of these only provides a partial measure of performance and no good method exists to combine them into a holistic metric towards this end this paper present a pair of information theoretic metric with similar behavior to the receiver operating characteristic roc curve of signal detection theory overall performance is evaluated with the percentage of truth information that a tracker captured and the total amount of false information that it reported information content is quantified through conditional entropy and mutual information computation using numerical estimate of the probability of association between the truth and the system track this paper demonstrates how these information quality metric provide a comprehensive evaluation of overall tracker performance and how they can be used to perform tracker comparison and parameter tuning on wide area surveillance imagery and other application 
in this paper we propose a novel probabilistic view of the spectral clustering algorithm in our framework the spectral clustering algorithm can be viewed a assigning class label to sample to minimize the bayes classification error rate by using a kernel density estimator kde from this perspective we propose to construct directed graph using variable bandwidth kdes such a variable bandwidth kde based directed graph ha the advantage that it encodes the local density information of the data in the graph edge weight in order to cluster vertex of the directed graph we develop a directed graph partitioning algorithm which optimizes a random walk isoperimetric ratio the partitioning result can be obtained efficiently by solving a system of linear equation we have applied our algorithm to several benchmark data set and obtained promising result 
in this paper we address the problem of localisation and recognition of human activity in unsegmented image sequence the main contribution of the proposed method is the use of an implicit representation of the spatiotemporal shape of the activity which relies on the spatiotemporal localization of characteristic sparse visual word and visual verb evidence for the spatiotemporal localization of the activity are accumulated in a probabilistic spatiotemporal voting scheme the local nature of our voting framework allows u to recover multiple activity that take place in the same scene a well a activity in the presence of clutter and occlusion we construct class specific codebooks using the descriptor in the training set where we take the spatial co occurrence of pair of codewords into account the position of the codeword pair with respect to the object centre a well a the frame in the training set in which they occur are subsequently stored in order to create a spatiotemporal model of codeword co occurrence during the testing phase we use mean shift mode estimation in order to spatially segment the subject that performs the activity in every frame and the radon transform in order to extract the most probable hypothesis concerning the temporal segmentation of the activity within the continuous stream 
in this paper we exploit normalized mutual information for the nonrigid registration of multimodal image rather than assuming that image statistic are spatially stationary a often done in traditional information theoretic method we take into account the spatial variability through a weighted combination of global normalized mutual information and local matching statistic spatial relationship are incorporated into the registration criterion by adoptively adjusting the weight according to the strength of local cue with a continuous representation of image and parzen window estimator we have developed closed form expression of the first order variation with respect to any general nonparametric infinite dimensional deformation of the image domain to characterize the performance of the proposed approach synthetic phantom simulated mri and clinical data are used in a validation study the result suggest that the augmented normalized mutual information provides substantial improvement in term of registration accuracy and robustness 
this paper proposes an affine invariant matching algorithm for shape correspondence problem in arbitrary dimension formulating shape by configuration matrix of landmark and using the fact that subspace e g range space of these matrix are invariant to affine transformation the shape correspondence is modelled a a permutation relation between orthogonal projection matrix of the subspace then the matching result is solved by an efficient factorization procedure for rank deficient matrix the algorithm is compact fast and independent of dimension experimental result for d d and d matchings of synthetic and real data are provided which demonstrate potential application of the algorithm to shape analysis and to other related problem like wide baseline stereo matching and range data registration 
in this work we address the problem of building recognition across two camera view with large change in scale and viewpoint the main idea is to construct a semantically rich sketch based representation for building which is invariant under large scale and perspective change after multi scale maximally stable extremal region mser detection the proposed approach find repeated structural component of building such a window door and facade and extract semantically rich feature which are organized into a sketch based representation of building these descriptor are then clustered in association with different plane of the building and matched across video frame using spectral graph analysis our experiment demonstrate that the proposed approach outperforms sift based matching scheme especially for image with large viewpoint change 
we present an efficient method for feature correspondence and object based image matching which exploit both photometric similarity and pairwise geometric consistency from local invariant feature we formulate object based image matching a an unsupervised multi class clustering problem on a set of candidate feature match and propose a novel pairwise dissimilarity measure and a robust linkage model in the framework of hierarchical agglomerative clustering the algorithm handle significant amount of outlier and deformation a well a multiple cluster thus enabling simultaneous feature matching and clustering from real world image pair with significant clutter and multiple deformable object the experimental evaluation on feature correspondence object recognition and object based image matching demonstrates that our method is robust to both outlier and deformation and applicable to a wide range of image matching problem 
linear inverse problem in computer vision including motion estimation shape fitting and image reconstruction give rise to parameter estimation problem with highly correlated error in variable established total least square method estimate the most likely correction a andb to a given data matrix a b perturbed by additive gaussian noise such that there exists a solution y with a a b b y in practice regression imposes a more restrictive constraint namely the existence of a solution x with a a x b b in addition more complicated correlation arise canonically from the use of linear filter we therefore propose a maximum likelihood estimator for regression in the general case of arbitrary positive definite covariance matrix we show that a b and x can be found simultaneously by the unconstrained minimization of a multivariate polynomial which can in principle be carried out by mean of a gr obner basis result for plane fitting and optical flow computation indicate the superiority of the proposed method 
we propose a network flow based optimization method for data association needed for multiple object tracking the maximum a posteriori map data association problem is mapped into a cost flow network with a non overlap constraint on trajectory the optimal data association is found by a min cost flow algorithm in the network the network is augmented to include an explicit occlusion model eom to track with long term inter object occlusion a solution to the eom based network is found by an iterative approach built upon the original algorithm initialization and termination of trajectory and potential false observation are modeled by the formulation intrinsically the method is efficient and doe not require hypothesis pruning performance is compared with previous result on two public pedestrian datasets to show it improvement 
many computer vision application such a image classification and video indexing are usually multi label classification problem in which an instance can be assigned to more than one category in this paper we present a novel multi label classification approach with hypergraph regularization that address the correlation among different category first a hypergraph is constructed to capture the correlation among different category in which each vertex represents one training instance and each hyperedge for one category contains all the instance belonging to the same category then an improved svm like learning system incorporating the hypergraph regularization called rank hlapsvm is proposed to handle the multi label classification problem we find that the corresponding optimization problem can be efficiently solved by the dual coordinate descent method many promising experimental result on the real datasets including imageclef and mediamill demonstrate the effectiveness and efficiency of the proposed algorithm 
in this paper we show how to generate a sharp panorama from a set of motion blurred video frame our technique is based on joint global motion estimation and multi frame deblurring it also automatically computes the duty cycle of the video namely the percentage of time between frame that is actually exposure time the duty cycle is necessary for allowing the blur kernel to be accurately extracted and then removed we demonstrate our technique on a number of video 
we describe an accurate keypoint detector that is stable under viewpoint change in this paper keypoints correspond to actual junction in the image the principle of asn differs fundamentally from other keypoint detector at each position in the image and before any detection it systematically estimate the position of a potential junction from the local gradient field keypoints then appear where multiple position estimate are attracted this approach allows the detector to adapt in shape and size to the image content one further obtains the area where the keypoint ha attracted solution comparative result with other detector show the improved accuracy and stability with viewpoint change 
in this paper we propose a new region based method for accurate motion estimation using discrete optimization in particular the input image is represented a a tree of over segmented region and the optical flow is estimated by optimizing an energy function defined on such a region tree using dynamic programming to accommodate the sampling inefficiency problem intrinsic to discrete optimization compared to the continuous optimization based method both spatial and solution domain coarse to fine c f strategy are used that is multiple region tree are built using different over segmentation granularity starting from a global displacement label discretization optical flow estimation on the coarser level region tree is used for defining region wise finer displacement sampling for finer level region tree furthermore cross checking based occlusion detection and correction and continuous optimization are also used to improve accuracy extensive experiment using the middlebury benchmark datasets have shown that our proposed method can produce top ranking result 
camera network have gained increased importance in recent year previous approach mostly used point correspondence between different camera view to calibrate such system however it is often difficult or even impossible to establish such correspondence in this paper we therefore present an approach to calibrate a static camera network where no correspondence between different camera view are required each camera track it own set of feature point on a commonly observed moving rigid object and these d feature trajectory are then fed into our algorithm by assuming the camera can be well approximated with an affine camera model we show that the projection of any feature point trajectory onto any affine camera axis is restricted to a dimensional subspace this observation enables the computation of the camera calibration matrix the coordinate of the tracked feature point and the rigid motion of the object with a non iterative trilinear factorization approach this solution can then be used a an initial guess for iterative optimization scheme which make use of the strong algebraic structure contained in the data our new approach can handle extreme configuration e g a camera in a camera network tracking only one single feature point the applicability of our algorithm is evaluated with synthetic and real world data 
in this paper we study how to build a vision based system for global localization with accuracy within cm for robot and human operating both indoors and outdoors over wide area covering many square kilometer in particular we study the parameter of building a landmark database rapidly and utilizing that database online for realtime accurate global localization although the accuracy of traditional short term motion based visual odometry system ha improved significantly in recent year these system alone cannot solve the drift problem over large area landmark based localization combined with visual odometry is a viable solution to the large scale localization problem however a systematic study of the specification and use of such a landmark database ha not been undertaken we propose technique to build and optimize a landmark database systematically and efficiently using visual odometry first topology inference is utilized to find overlapping image in the database second bundle adjustment is used to refine the accuracy of each d landmark finally the database is optimized to balance the size of the database with achievable accuracy once the landmark database is obtained a new real time global localization methodology that work both indoors and outdoors is proposed we present result of our study on both synthetic and real datasets that help u determine critical design parameter for the landmark database and the achievable accuracy of our proposed system 
we present a method for real time d object detection that doe not require a time consuming training stage and can handle untextured object at it core is a novel template representation that is designed to be robust to small image transformation this robustness based on dominant gradient orientation let u test only a small subset of all possible pixel location when parsing the image and to represent a d object with a limited set of template we show that together with a binary representation that make evaluation very fast and a branch and bound approach to efficiently scan the image it can detect untextured object in complex situation and provide their d pose in real time 
this paper present an approach to reconstruct nonstationary articulated object from silhouette obtained with a monocular video sequence we introduce the concept of motion blurred scene occupancy a direct analogy of motion blurred image but in a d object scene occupancy space resulting from the motion deformation of the object our approach start with an image based fusion step that combine color and silhouette information from multiple view to this end we propose to use a novel construct the temporal occupancy point top which is the estimated d scene location of a silhouette pixel and contains information about duration of time it is occupied instead of explicitly computing the top in d space we directly obtain it s imaged projected location in each view this enables u to handle monocular video and arbitrary camera motion in scenario where complete camera calibration information may not be available the result is a set of blurred scene occupancy image in the corresponding view where the value at each pixel correspond to the fraction of total time duration that the pixel observed an occupied scene location we then use a motion de blurring approach to de blur the occupancy image the de blurred occupancy image correspond to a silhouette of the mean motion compensated object shape and are used to obtain a visual hull reconstruction of the object we show promising result on challenging monocular datasets of deforming object where traditional visual hull intersection approach fail to reconstruct the object correctly 
when imaging in scattering medium there is a need to enhance visibility some approach have used polarized image in this context with apparent success these method take advantage of the fact that the path radiance airlight is partially polarized however mountinga polarizer attenuates the signal associated with the object this attenuation degrades the image quality thus a question arises is the use of a polarizer worth the mentioned loss the ability to see object is limited by noise therefore in this work we analyze the change in signal to noise ratio snr following the use of a polarizer or a dehazing process typically method use either one polarized image with minimumpathradiance ortwo polarizedimagescorresponding to extremum of the path radiance we show that if the only goal is signal discrimination over noise and not color or radiance recovery in haze the use of polarization in both approach is unnecessary polarization rarely improves the snr over an average of unpolarized image acquired under the same acquisition time nevertheless under a single frame constraint the use of a single polarized image is beneficial 
in recent year local pattern based object detection and recognition have attracted increasing interest in computer vision research community however to our best knowledge no previous work ha focused on utilizing local pattern for the task of human detection in this paper we develop a novel human detection system in personal album based on lbp local binary pattern descriptor firstly we review the existing gradient based local feature widely used in human detection analyze their limitation and argue that lbp is more discriminative secondly original lbp descriptor doe not suit the human detecting problem well due to it high complexity and lack of semantic consistency thus we propose two variant of lbp semantic lbp and fourier lbp carefully designed experiment demonstrate the superiority of lbp over other traditional feature for human detection especially we adopt a random ensemble algorithm for better comparison between different descriptor all experiment are conducted on inria human database 
abstract for content level access very often database need the query a a sample image however the image may contain private information and hence the user doe not wish to reveal the image to the database private content based image retrieval pcbir deal with retrieving similar image from an image database without revealing the content of the query image not even to the database server we propose algorithm for pcbir when the database is indexed using hierarchical index structure or hash based indexing scheme experiment are conducted on real datasets with popular feature and state of the art data structure it is observed that specialty and subjectivity of image retrieval unlike sql query to a relational database enables in computationally efficient yet private solution 
advance in object detection have made it possible to collect large database of certain object in this paper we exploit these datasets for within object classification for example we classify gender in face image pose in pedestrian image and phenotype in cell image previous work ha mainly targeted the above task individually using object specific representation here we propose a general bayesian framework for within object classification image are represented a a regular grid of non overlapping patch in training these patch are approximated by a predefined library in inference the choice of approximating patch determines the classification decision we propose a bayesian framework in which we marginalize over the patch frequency parameter to provide a posterior probability for the class we test our algorithm on several challenging real world database 
this paper explores how shape motion and lighting interact in the case of a two frame motion sequence we consider a rigid object with lambertian reflectance property undergoing small motion with respect to both a camera and a stationary point light source assuming orthographic projection we derive a single first order quasilinear partial differential equation that relates shape motion and lighting while eliminating out the albedo we show how this equation can be solved when the motion and lighting parameter are known to produce a d reconstruction of the object a solution is obtained using the method of characteristic and can be refined by adding regularization we further show that both smooth bounding contour a well a surface marking can be used to derive dirichlet boundary condition experimental result demonstrate the quality of this reconstruction 
learning object category from small sample is a challenging problem where machine learning tool can in general provide very few guarantee exploiting prior knowledge may be useful to reproduce the human capability of recognizing object even from only one single view this paper present an svm based model adaptation algorithm able to select and weight appropriately prior knowledge coming from different category the method relies on the solution of a convex optimization problem which ensures to have the minimal leave one out error on the training set experiment on a subset of the caltech database show that the proposed method produce better result than both choosing one single prior model and transferring from all previous experience in a flat uninformative way 
this paper proposes a new affine registration algorithm for matching two point set in ir or ir the input point set are represented a probability density function using either gaussian mixture model or discrete density model and the problem of registering the point set is treated a aligning the two distribution since polynomial transform a symmetric tensor under an affine transformation the distribution moment which are the expected value of polynomial also transform accordingly therefore instead of solving the harder problem of aligning the two distribution directly we solve the softer problem of matching the distribution moment by formulating a least square problem for matching moment of the two distribution up to degree three the resulting cost function is a polynomial that can be efficiently optimized using technique originated from algebraic geometry the global minimum of this polynomial can be determined by solving a system of polynomial equation the algorithm is robust in the presence of noise and outlier and we validate the proposed algorithm on a variety of point set with varying degree of deformation and noise 
we consider the problem of finding a matching between two set of feature given complex relation among them going beyond pairwise each feature set is modeled by a hypergraph where the complex relation are represented by hyper edge a match between the feature set is then modeled a a hypergraph matching problem we derive the hyper graph matching problem in a probabilistic setting represented by a convex optimization first we formalize a soft matching criterion that emerges from a probabilistic interpretation of the problem input and output a opposed to previous method that treat soft matching a a mere relaxation of the hard matching problem second the model induces an algebraic relation between the hyper edge weight matrix and the desired vertex to vertex probabilistic matching third the model explains some of the graph matching normalization proposed in the past on a heuristic basis such a doubly stochastic normalization of the edge weight a key benefit of the model is that the global optimum of the matching criterion can be found via an iterative successive projection algorithm the algorithm reduces to the well known sinkhorn row column matrix normalization procedure in the special case when the two graph have the same number of vertex and a complete matching is desired another benefit of our model is the straightforward scalability from graph to hyper graph 
high level or holistic scene understanding involves reasoning about object region and the d relationship between them this requires a representation above the level of pixel that can be endowed with high level attribute such a class of object region it orientation a nd rough d location within the scene towards this goal we propose a region based model which combine appearance and scene geometry to automatically decompose a scene into semantically meaningful region our model is defined in term of a unified energy function over scene appearance and structure we show how this energy function can be learned from data and present an efficient inference technique that make use of multiple over segmentation of the image to propose move in the energy space we show experimentally that our method achieves state of the art p erformance on the task of both multi class image segmentation and geometric reasoning finally by understanding region class and geometry we show how our model can be used a the basis for d reconstruction of the scene 
sparse coding which encodes the original signal in a sparse signal space ha shown it state of the art performance in the visual codebook generation and feature quantization process of bow based image representation however in the feature quantization process of sparse coding some similar local feature may be quantized into different visual word of the codebook due to the sensitiveness of quantization in this paper to alleviate the impact of this problem we propose a laplacian sparse coding method which will exploit the dependence among the local feature specifically we propose to use histogram intersection based knn method to construct a laplacian matrix which can well characterize the similarity of local feature in addition we incorporate this laplacian matrix into the objective function of sparse coding to preserve the consistence in sparse representation of similar local feature comprehensive experimental result show that our method achieves or outperforms existing state of the art result and exhibit excellent performance on scene data set 
boundary snapping is an interactive image cutout algorithm that requires a small number of user supplied control point or landmark to infer the cutout contour the key idea is to match the appearance of all point along the desired contour to the landmark point where appearance is given by an intensity profile perpendicular to the boundary an optimization process attempt to find a contour that maximizes the similarity score of it point with the landmark this approach work well in the typical case where the foreground and background differ in appearance a well a in challenging case where the subject is clearly perceived but the region on both side of the boundary are similar and cannot be easily discriminated by enabling the user to define the boundary point directly the technique is not limited to boundary that necessarily have to be the most salient or high gradient feature in the region it can also be used for margin cutout around the boundary the use of multiple control point along the boundary can handle spatially varying attribute a both foreground and background may change in appearance along the boundary the final result is accurate because it allows the user to enforce hard constraint on the boundary directly at the expense of moderate user labor in positioning the landmark point finally the algorithm is fast work on a variety of image and handle situation where the boundary is not obvious 
we present a new variational level set based segmentation formulation that us both shape and intensity prior information learned from a training set by applying bayes rule to the segmentation problem the cost function decomposes into shape and image energy part the shape energy is based on recently proposed nonparametric shape distribution and we propose a new image energy model that incorporates learned intensity information from both foreground and background object the proposed variational level set segmentation framework ha two main advantage first by characterizing image information with regional intensity distribution there is no need to balance image energy and shape energy using a heuristic weighting factor second by incorporating learned intensity information into the image model using a nonparametric density estimation method and an appropriate distance measure our segmentation framework can handle problem where the interior exterior of the shape ha a highly inhomogeneous intensity distribution we demonstrate our segmentation algorithm using challenging pelvis ct scan 
this paper present a study on how to numerically solve thefeasibility test problem which is the core of the bisectionalgorithm for minimizing the l error function weconsider a strategy that minimizes the maximum infeasibility theminimization can be performed using several numerical computationmethods among which the barrier method and the primal dual methodare examined in both of the method the inequality aresequentially approximated by log barrier function an initialfeasible solution is found easily by the construction of thefeasibility problem and newton style update computes the optimalsolution iteratively when we apply the method to the problem ofestimating the structure and motion every newton update requiressolving a very large system of linear equation we show that thesparse bundle adjustment technique previously developed forstructure and motion estimation can be utilized during the newtonupdate in the primal dual interior point method in contrast tothe barrier method the sparse structure is all destroyed due to anextra constraint introduced for finding an initial solution however we show that this problem can be overcome by utilizing thematrix inversion lemma which allows u to exploit the sparsity inthe same manner a in the barrier method we finally show that thesparsity appears in both of the l formulation linear programming and second order cone programming 
we introduce a new technique that can reduce any higher order markov random field with binary label into a first order one that ha the same minimum a the original moreover we combine the reduction with the fusion move and qpbo algorithm to optimize higher order multi label problem while many vision problem today are formulated a energy minimization problem they have mostly been limited to using first order energy which consist of unary and pairwise clique potential with a few exception that consider triple this is because of the lack of efficient algorithm to optimize energy with higher order interaction our algorithm challenge this restriction that limit the representational power of the model so that higherorder energy can be used to capture the rich statistic of natural scene to demonstrate the algorithm we minimize a third order energy which allows clique potential with up to four pixel in an image restoration problem the problem us the field of expert model a learned spatial prior of natural image that ha been used to test two belief propagation algorithm capable of optimizing higher order energy the result show that the algorithm exceeds the bp algorithm in both optimization performance and speed 
the aim of this work is to learn a shape prior model for an object class and to improve shape matching with the learned shape prior given image of example instance we can learn a mean shape of the object class a well a the variation of non affine and affine transformation separately based on the thin plate spline tps parameterization unlike previous method for learning we represent shape by vector field instead of feature which make our learning approach general during shape matching we inject the shape prior knowledge and make the matching result consistent with the training example this is achieved by an extension of the tps rpm algorithm which find a closed form solution for the tps transformation coherent with the learned transformation we test our approach by using it to learn shape prior model for all the five object class in the ethz shape class the result show that the learning accuracy is better than previous work and the learned shape prior model are helpful for object matching in real application such a object classification 
in this paper we propose how the parameter distribution of multilinear geometric entity can be dualised the dualisation concern for example the parameter distribution of conic multiple view tensor homographies or a simple entity a point line and plane the dual distribution are related to triggs joint feature distribution but our approach is different in certain fundamental aspect our starting point is in the assumption that the maximum likelihood estimate or the corresponding robust estimate and the covariance matrix of the parameter of the geometric entity are available we then use the asymptotic normality property of the mle which allows u to transform the parameter uncertainty distribution in a dual form the dualisation of the parameter distribution allows u for instance to look at the uncertainty distribution in feature distribution which are essentially tied to the distribution of training data and help u to derive conditional distribution for point or line transfer and characterise confidence interval of the estimate application of the proposed approach are thus uncertainty analysis statistical prediction probabilistic transfer etc 
one of the key factor for the success of recent energy minimization method is that they seek to compute global solution even for non convex energy functionals optimization method such a graph cut have proven to produce high quality solution by iterative minimization based on large neighborhood making them le vulnerable to local minimum our approach take this a step further by enlarging the search neighborhood with one dimension in this paper we consider binary total variation problem that depend on an additional set of parameter example include 
we present a closed form solution to the problem of recovering the d shape of a non rigid potentially stretchable surface from d to d correspondence in other word we can reconstruct a surface from a single image without a priori knowledge of it deformation in that image state of the art solution to non rigid d shape recovery rely on the fact that distance between neighboring surface point must be preserved and are therefore limited to inelastic surface here we show that replacing the inextensibility constraint by shading one remove this limitation while still allowing d reconstruction in closed form we demonstrate our method and compare it to an earlier one using both synthetic and real data 
many problem in computer vision can be modeled using conditional markov random field crf since finding the maximum a posteriori map solution in such model is np hard much attention in recent year ha been placed on finding good approximate solution in particular graph cut based algorithm such a expansion are tremendously successful at solving problem with regular potential however for arbitrary energy function message passing algorithm such a max product belief propagation are still the only resort in this paper we describe a general framework for finding approximate map solution of arbitrary energy function our algorithm calledalphabet soup for sequential optimization for unrestricted potential performs a sear ch over variable assignment by iteratively solving subproblems over a reduced state space we provide a theoretical guarantee on the quality of the solution when the inner loop of our algorithm is solved exactly we show that this approach greatly improves the efficiency of inference and achieves lower energy solution for a broad range of vision problem 
abstract this paper proposes a new concept in hierarchical representation that exploit feature of different granularity and specificity coming from all layer of the hierarchy the concept is realized within a cross layered compositional representation learned from the visual data we show how similarity connection among discrete label within and across hierarchical layer can be established in order to produce a set of layer independent shape terminal i e shapinals we thus break the traditional notion of hierarchy and show how the category specific layer can make use of all the necessary feature stemming from all hierarchical layer this on the one hand brings higher generalization into the representation yet on the other hand it also encodes the notion of scale directly into the hierarchy thus enabling a multi scale representation of object category by focusing on shape information only the approach is tested on the caltech dataset demonstrating good performance in comparison with other state of the art method 
we present a new approach for building reconstruction from a single digital elevation model dem it treat building a an assemblage of simple urban structure extracted from a library of d parametric block like a lego r set this method work on various data resolution such a m satellite and m aerial dems and allows u to obtain d representation with various level of detail first the d support of the urban structure are extracted either interactively or automatically then d block are placed on the d support using a gibbs model a bayesian decision find the optimal configuration of d block using a rjmcmc sampler experimental result on complex building and dense urban area are presented using data at various resolution 
edge based color constancy make use of image derivative to estimate the illuminant however different edge type exist in real world image such a shadow geometry material and highlight edge these different edge type may have a distinctive inf luence on the performance of the illuminant estimation therefore in this paper an extensive analysis is provided of different edge type on the performance of edge based color constancy method first an edge based taxonomy is presented classifying edge type based on their ref lectance property e g material shadow geometry and highlight then a performance evaluation of edge based color constancy is provided using these different edge type from this performance evaluation it is derived that certain edge type are more valuable than material edge for the estimation of the illuminant to this end the weighted grey edge algorithm is proposed in which certain valuable edge type are more emphasized for the estimation of the illuminant from the experimental result it is shown that the proposed weighted grey edge algorithm based on the shadowshading variant i e assigning higher weight to edge with more energy in the shadow shading direction result in the best performance moreover all current state of theart method including pixel based method and edge based method have been signif icantly outperformed by the proposed weighted grey edge algorithm resulting in an improvement of over the current best performing algorithm 
we introduce an algorithm to estimate the optimal exposure parameter from the analysis of a single possibly underor over exposed image this algorithm relies on a new quantitative measure of exposure quality based on the average rendering error that is the difference between the original irradiance and it reconstructed value after processing and quantization in order to estimate the exposure quality in the presence of saturated pixel we fit a log normal distribution to the brightness data computed from the unsaturated pixel experimental result are presented comparing the estimated v ground truth optimal exposure parameter under various illumination condition 
in this paper we present a new method for categorizing video sequence capturing different scene class this can be seen a a generalization of previous work on scene classification from single image a scene is represented by a collection of d point with an appearance based codeword attached to each point the cloud of point is recovered by using a robust sfm algorithm applied on the video sequence a hierarchical structure of histogram located at different location and at different scale is used to capture the typical spatial distribution of d point and codewords in the working volume the scene is classified by svm equipped with a histogram matching kernel similar to result on a challenging dataset of scene category show competitive classification accuracy and superior performance with respect to a state of the art d pyramid matching method applied to individual image frame 
a novel approach to scene categorization is proposed similar to previous work of we introduce an intermediate space based on a low dimensional semantic theme image representation however instead of learning the theme in an unsupervised manner they are learned with weak supervision from casual image annotation each theme induces a probability density on the space of low level feature and image are represented a vector of posterior theme probability this enables an image to be associated with multiple theme even when there are no multiple association in the training label an implementation is presented and compared to various existing algorithm on benchmark datasets it is shown that the proposed low dimensional representation correlate well with human scene understanding and is able to learn theme co occurrence without explicit training it is also shown to outperform unsupervised latent space method with much smaller training complexity and to achieve performance close to the state of the art method which rely on much higher dimensional image representation finally a study of the effect of dimensionality on the classification performance is presented indicating that the dimensionality of theme space grows sub linearly with the number of scene category 
we propose a posture invariant surface descriptor for triangular mesh using intrinsic geometry the surface is first transformed into a representation that is independent of the posture spin image is then adapted to derive a descriptor for the representation the descriptor is used for extracting surface feature automatically it is invariant with respect to rigid and isometric deformation and robust to noise and change in resolution the result is demonstrated by using the automatically extracted feature to find correspondence between articulated mesh 
surface reconstruction from gradient field is an important final step in several application involving gradient manipulation and estimation typically the resulting gradient field is nonintegrable due to linear non linear gradient manipulation or due to presence of noise outlier in gradient estimation in this paper we analyze integrability a error correction inspired from recent work in compressed sensing particulary l l we propose to obtain the surface by finding the gradient field which best fit the corrupted gradient field in l sense we present an exhaustive analysis of the property of l solution for gradient field integration using linear algebra and graph analogy we consider three case a noise but no outlier b no noise but outlier and c presence of both noise and outlier in the given gradient field we show that l solution performs a well a least square in the absence of outlier while previous l l equivalence work ha focused on the number of error outlier we show that the location of error is equally important for gradient field integration we characterize the l solution both in term of location and number of outlier and ouline scenario where l solution is equivalent to l solution we also show that when l solution is not able to remove outlier the property of local error confinement hold i e the error do not propagate to the entire surface a in least square we compare with previous technique and show that l solution performs well across all scenario without the need for any tunable parameter adjustment 
we present a method for detecting and parsing building from unorganized d point cloud into a compact hierarchical representation that is useful for high level task the input is a set of range measurement that cover large scale urban environment the desired output is a set of parse tree such that each tree represents a semantic decomposition of a building the node are roof surface a well a volumetric part inferred from the observable surface we model the above problem using a simple and generic grammar and use an efficient dependency parsing algorithm to generate the desired semantic description we show how to learn the parameter of this simple grammar in order to produce correct par of complex structure we are able to apply our model on large point cloud and parse an entire city 
we present a framework for vision assisted tagging of personal photo collection using context whereas previous effort mainly focus on tagging people we develop a unified approach to jointly tag across multiple domain specifically people event and location the heart of our approach is a generic probabilistic model of context that couple the domain through a set of cross domain relation each relation model how likely the instance in two domain are to co occur based on this model we derive an algorithm that simultaneously estimate the cross domain relation and infers the unknown tag in a semi supervised manner we conducted experiment on two well known datasets and obtained significant performance improvement in both people and location recognition we also demonstrated the ability to infer event label with missing timestamps i e with no event feature 
most method for learning object category require large amount of labeled training data however obtaining such data can be a difficult and time consuming endeavor we have developed a novel entropy based active learning approach which make significant progress towards this problem the main idea is to sequentially acquire labeled data by presenting an oracle the user with unlabeled image that will be particularly informative when labeled active learning adaptively prioritizes the order in which the training example are acquired which a shown by our experiment can significantly reduce the overall number of training example required to reach near optimal performance at first glance this may seem counter intuitive how can the algorithm know whether a group of unlabeled image will be informative when by definition there is no label directly associated with any of the image our approach is based on choosing an image to label that maximizes the expected amount of information we gain about the set of unlabeled image the technique is demonstrated in several context including improving the efficiency of web image search query and open world visual learning by an autonomous agent experiment on a large set of visual object category taken directly from text based web image search show that our technique can provide large improvement up to x reduction in the number of training example needed over baseline technique 
in real world an image is usually associated with multiple label which are characterized by different region in the image thus image classification is naturally posed a both a multi label learning and multi instance learning problem different from existing research which ha considered these two problem separately we propose an integrated multilabel multi instance learning mlmil approach based on hidden conditional random field hcrfs which simultaneously capture both the connection between semantic label and region and the correlation among the label in a single formulation we apply this mlmil framework to image classification and report superior performance compared to key existing approach over the msr cambridge msrc and corel data set 
we present a simple framework to model contextual relationship between visual concept the new framework combine idea from previous object centric method which model contextual relationship between object in an image such a their co occurrence pattern and scenecentric method which learn a holistic context model from the entire image known a it gist this is accomplished without demarcating individual concept or region in the image first using the output of a generic appearance based concept detection system a semantic space is formulated where each axis represents a semantic feature next context model are learned for each of the concept in the semantic space using mixture of dirichlet distribution finally an image is represented a a vector of posterior concept probability under these contextual concept model it is shown that these posterior probability are remarkably noise free and an effective model of the contextual relationship between semantic concept in natural image this is further demonstrated through an experimental evaluation with respect to two vision task viz scene classification and image annotation on benchmark datasets the result show that besides quite simple to compute the proposed context model attain superior performance than state of the art system in both task 
segmenting image into distinct material type is a very useful capability most work in image segmentation address the case where only a single image is available some method improve on this by collecting hdr or multispectral image however it is also possible to use the reflectance property of the material to obtain better result by acquiring many image of an object under different lighting condition we have more sample of the surface bidirectional reflectance distribution function brdf we show that this additional information enlarges the class of material type that can be well separated by segmentation and that properly treating the information a sample of the brdf further increase accuracy without requiring an explicit estimation of the material brdf environmental monitoring to art history the simplest imaging source which creates the hardest classification task is a single grayscale image color and hyperspectral image provide more information a do polarizing filter we investigate a different source of additional information the angular variation of reflectance while color and polarization all deal with a single point sample from the surface s four dimensional brdf we capture a d slice of the brdf and show that this enlarges the class of material type that can be well separated we also demonstrate how this information is best leveraged comparing pixel by transforming the segmentation space using a brdf model instead of raw measurement achieving greater surface orientation invariance if an object is photographed twice from the same camera position but with the light source in a different location the resulting image may differ this happens because the reflectance of many material varies according to the incoming and outgoing light direction for example shiny object exhibit specular reflection and diffuse object exhibit the cosine term modulation this variation is described by the material s d bidirectional reflectance distribution function brdf specifying the brightness observed in any outgoing direction two dimension when light arrives from any incoming direction two dimension capturing sample over the entire d brdf can be impractical for many application requiring image from many location at many lighting condition such a process re 
we propose a novel approach for modelling correlation between activity in a busy public space captured by multiple non overlapping and uncalibrated camera in our approach each camera view is automatically decomposed into semantic region across which different spatio temporal activity pattern are observed a novel cross canonical correlation analysis xcca framework is formulated to detect and quantify temporal and causal relationship between regional activity within and across camera view the approach accomplishes three task estimate the spatial and temporal topology of the camera network facilitate more robust and accurate person re identification perform global activity modelling and video temporal segmentation by linking visual evidence collected across camera view our approach differs from the state of the art in that it doe not rely on either intra or inter camera tracking it therefore can be applied to even the most challenging video surveillance setting featured with severe occlusion and extremely low spatial and temporal resolution it effectiveness is demonstrated using hour of video from camera installed in a busy underground station 
this paper deal with the d shape estimation from silhouette cue of multiple moving object in general indoor or outdoor d scene with potential static obstacle using multiple calibrated video stream most shape from silhouette technique use a two classification of space occupancy and silhouette based on image region that match or disagree with a static background appearance model binary silhouette information becomes insufficient to unambiguously carve d space region a the number and density of dynamic object increase in such difficult scene multi view stereo method suffer from visibility problem and rely on color calibration procedure tedious to achieve outdoors we propose a new algorithm to automatically detect and reconstruct scene with a variable number of dynamic object our formulation distinguishes between m different shape in the scene by using automatically learnt view specific appearance model eliminating the color calibration requirement bayesian reasoning is then applied to solve the m shape occupancy problem with m updated a object enter or leave the scene result show that this method yield multiple silhouette based estimate that drastically improve scene reconstruction over traditional two label silhouette scene analysis this enables the method to also efficiently deal with multi person tracking problem 
median shift is a mode seeking algorithm that relies on computing the median of local neighborhood instead of the mean we further combine median shift with locality sensitive hashing lsh and show that the combined algorithm is suitable for clustering large scale high dimensional data set in particular we propose a new mode detection step that greatly accelerates performance in the past lsh wa used in conjunction with mean shift only to accelerate nearest neighbor query here we show that we can analyze the density of the lsh bin to quickly detect potential mode candidate and use only them to initialize the median shift procedure we use the median instead of the mean or it discrete counterpart the medoid because the median is more robust and because the median of a set is a point in the set a median is well defined for scalar but there is no single agreed upon extension of the median to high dimensional data we adopt a particular extension known a the tukey median and show that it can be computed efficiently using random projection of the high dimensional data onto d line just like lsh leading to a tightly integrated and efficient algorithm 
we use concept from chaos theory in order to model nonlinear dynamical system that exhibit deterministic behavior observed time series from such a system can be embedded into a higher dimensional phase space without the knowledge of an exact model of the underlying dynamic such an embedding warp the observed data to a strange attractor in the phase space which provides precise information about the dynamic involved we extract this information from the strange attractor and utilize it to predict future observation given an initial condition the prediction in the phase space are computed through kernel regression this approach ha the advantage of modeling dynamic without making any assumption about the exact form linear polynomial radial basis etc of the mapping function the predicted point are then warped back to the observed time series we demonstrate the utility of these prediction for human action synthesis and dynamic texture synthesis our main contribution are multivariate phase space reconstruction for human action and dynamic texture a deterministic approach to model dynamic in contrast to the popular noise driven approach for dynamic texture and video synthesis from kernel regression in the phase space experimental result provide qualitative and quantitative analysis of our approach on standard data set 
joint alignment for an image ensemble can rectify image in the spatial domain such that the aligned image are a similar to each other a possible this important technology ha been applied to various object class and medical application however previous approach to joint alignment work on an ensemble of a single object class given an ensemble with multiple object class we propose an approach to automatically and simultaneously solve two problem image alignment and clustering both the alignment parameter and clustering parameter are formulated into a unified objective function whose optimization lead to an unsupervised joint estimation approach it is further extended to semi supervised simultaneous estimation where a few labeled image are provided extensive experiment on diverse real world database demonstrate the capability of our work on this challenging problem 
color information can be used a a basic and crucial cue for finding correspondence in a stereo matching algorithm in a real scene however image color are affected by various geometric and radiometric factor for this reason the raw color recorded by a camera is not a reliable cue and the color consistency assumption is no longer valid between stereo image in real scene hence the performance of most conventional stereo matching algorithm can be severely degraded under the radiometric variation in this paper we present a new stereo matching algorithm that is invariant to various radiometric variation between left and right image unlike most stereo algorithm we explicitly employ the color formation model in our framework and propose a new measure called adaptive normalized cross correlation ancc for a robust and accurate correspondence measure ancc is invariant to lighting geometry illuminant color and camera parameter change between left and right image and doe not suffer from fattening effect unlike conventional normalized cross correlation ncc experimental result show that our algorithm outperforms other stereo algorithm under severely different radiometric condition between stereo image 
this paper proposes an adaptive learning method for tracking target across multiple camera with disjoint view two visual cue are usually employed for tracking target across camera spatio temporal cue and appearance cue to learn the relationship among camera traditional method used batch learning procedure or hand labeled correspondence which can work well only within a short period of time in this paper we propose an unsupervised method which learns both spatio temporal relationship and appearance relationship adaptively and can be applied to long term monitoring our method performs target tracking across multiple camera while also considering the environment change such a sudden lighting change also we improve the estimation of spatio temporal relationship by using the prior knowledge of camera network topology 
we introduce a distributed algorithm for solving large scale support vector machine svm problem the algorithm divide the training set into a number of processing node each running independently an svm sub problem associated with it subset of training data the algorithm is a parallel jacobi block update scheme derived from the convex conjugate fenchel duality form of the original svm problem each update step consists of a modified svm solver running in parallel over the sub problem followed by a simple global update we derive bound on the number of update showing that the number of iteration independent svm application on sub problem required to obtain a solution of accuracy is o log we demonstrate the efficiency and applicability of our algorithm by running on large scale experiment on standardized datasets while comparing the result to the state of the art svm solver 
we propose an approach to restore severely degraded document image using a probabilistic context model unlike traditional approach that use previously learned prior model to restore an image we are able to learn the text model from the degraded document itself making the approach independent of script font style etc we model the contextual relationship using an mrf the ability to work with larger patch size allows u to deal with severe degradation including cut blob merges and vandalized document our approach can also integrate document restoration and super resolution into a single framework thus directly generating high quality image from degraded document experimental result show significant improvement in image quality on document image collected from various source including magazine and book and comprehensivelydemonstratethe robustness and adaptabilityof the approach it work well with document collection such a book even with severe degradation and hence is ideally suited for repository such a digital library 
structural semantics are fundamental to understanding both natural and man made object from language to building they are manifested a repeated structure or pattern and are often captured in image finding repeated pattern in image therefore ha important application in scene understanding d reconstruction and image retrieval a well a image compression previous approach in visual pattern mining limited themselves by looking for frequently co occurring feature within a small neighborhood in an image however semantics of a visual pattern are typically defined by specific spatial relationship between feature regardless of the spatial proximity in this paper semantics are represented a visual element and geometric relationship between them a novel unsupervised learning algorithm find pair wise association of visual element that have consistent geometric relationship sufficiently often the algorithm are efficient maximal matchings are determined without combinatorial search high order structural semantics are extracted by mining pattern that are composed of pairwise spatially consistent association of visual element we demonstrate the effectiveness of our approach for discovering repeated visual pattern on a variety of image collection 
we present a novel multi person pose estimation framework which extends pictorial structure p to explicitly model interaction between people and to estimate their pose jointly interaction are modeled a occlusion between people first we propose an occlusion probability predictor based on the location of person automatically detected in the image and incorporate the prediction a occlusion prior into our multi person p model moreover our model includes an inter people exclusion penalty preventing body part from different people from occupying the same image region thanks to these element our model ha a global view of the scene resulting in better pose estimate in group photo where several person stand nearby and occlude each other in a comprehensive evaluation on a new challenging group photo datasets we demonstrate the benefit of our multi person model over a state of the art single person pose estimator which treat each person independently 
this paper investigates a new learning formulation called dynamic group sparsity it is a natural extension of the standard sparsity concept in compressive sensing and is motivated by the observation that in some practical sparse data the nonzero coefficient are often not random but tend to be clustered intuitively better result can be achieved in these case by reasonably utilizing both clustering and sparsity prior motivated by this idea we have developed a new greedy sparse recovery algorithm which prune data residue in the iterative process according to both sparsity and group clustering prior rather than only sparsity a in previous method the proposed algorithm can recover stably sparse data with clustering trend using far fewer measurement and computation than current state of the art algorithm with provable guarantee moreover our algorithm can adaptively learn the dynamic group structure and the sparsity number if they are not available in the practical application we have applied the algorithm to sparse recovery and background subtraction in video numerous experiment with improved performance over previous method further validate our theoretical proof and the effectiveness of the proposed algorithm 
indoor and outdoor urban environment posse many regularity which can be efficiently exploited and used for general image parsing task we present a novel approach for detecting rectilinear structure and demonstrate their use for wide baseline stereo matching planar d reconstruction and computation of geometric context assuming a presence of dominant orthogonal vanishing direction we proceed by formulating the detection of the rectilinear structure a a labeling problem on detected line segment the line segment label respecting the proposed grammar rule are established a the map assignment of the corresponding mrf the proposed framework allows to detect both full a well a partial rectangle rectangle inrectangle structure and rectangle sharing edge the use of detected rectangle is demonstrated in the context of difficult wide baseline matching task in the presence of repetitive structure and large appearance change 
we present an approach to determine the category and location of object in image it performs very fast categorization of each pixel in an image a brute force approach made feasible by three key development first our method reduces the size of a large generic dictionary on the order of ten thousand word to the low hundred while increasing classification performance compared to k mean this is achieved by creating a discriminative dictionary tailored to the task by following the information bottleneck principle second we perform feature based categorization efficiently on a dense grid by extending the concept of integral image to the computation of local histogram third we compute sift descriptor densely in linear time we compare our method to the state of the art and find that it excels in accuracy and simplicity performing better while assuming le 
in an d echocardiogram exam an ultrasound probe sample the heart with d slice changing the orientation and position on the probe change the slice viewpoint altering the cardiac anatomy being imaged the determination of the probe viewpoint form an essential step in automatic cardiac echo image analysis in this paper we present a system for automatic view classification that exploit cue from both cardiac structure and motion in echocardiogram video in our framework each image from the echocardiogram video is represented by a set of novel salient feature we locate these feature at scale invariant point in the edge filtered motion magnitude image and encode them using local spatial textural and kinetic information training in our system involves learning a hierarchical feature dictionary and parameter of a pyramid matching kernel based support vector machine while testing each image classified independently cast a vote towards parent video classification and the viewpoint with maximum vote win through experiment on a large database of echocardiogram obtained from both diseased and control subject we show that our technique consistently outperforms stateof the art method in the popular four view classification test we also present result for eight view classification to demonstrate the scalability of our framework 
graph based method form a main category of semi supervised learning offering flexibility and easy implementation in many application however the performance of these method is often sensitive to the construction of a neighborhood graph which is non trivial for many real world problem in this paper we propose a novel framework that build on learning the graph given labeled and unlabeled data the paper ha two major contribution firstly we use a nonparametric algorithm to learn the entire adjacency matrix of a symmetry favored k nn graph assuming that the matrix is doubly stochastic the nonparametric algorithm make the constructed graph highly robust to noisy sample and capable of approximating underlying submanifolds or cluster secondly to address multi class semi supervised classification we formulate a constrained label propagation problem on the learned graph by incorporating class prior leading to a simple closed form solution experimental result on both synthetic and real world datasets show that our approach is significantly better than the state of the art graph based semi supervised learning algorithm in term of accuracy and robustness 
optical flow estimation requires spatial integration which essentially pose a grouping question what point belong to the same motion and what do not classical local approach to optical flow such a lucas kanade use isotropic neighborhood and have considerable difficulty near motion boundary in this work we utilize imagebased grouping to facilitate spatialand scale adaptive integration we define soft spatial support using pairwise affinity computed through intervening contour we sample image at edge and corner and iteratively estimate affine motion at sample point figure ground organization further improves grouping and flow estimation near boundary we show that affinity based spatial integration enables reliable flow estimation and avoids erroneous motion propagation from and or across object boundary we demonstrate our approach on the middlebury flow dataset 
supervised learning of a part based model can be formulated a an optimization problem with a large exponential in the number of part set of constraint we show how this seemingly difficult problem can be solved by i reducing it to an equivalent convex problem with a small polynomial number of constraint taking advantage of the fact that the model is tree structured and the potential have a special form and ii obtaining the globally optimal model using an efficient dual decomposition strategy each component of the dual decomposition is solved by a modified version of the highly optimized svm light algorithm to demonstrate the effectiveness of our approach we learn human upper body model using two challenging publicly available datasets our model account for the articulation of human a well a the occlusion of part we compare our method with a baseline iterative strategy a well a a state of the art algorithm and show significant efficiency improvement tive model in similar setting inspired by this observation we develop a supervised discriminative approach for efficiently learning the model using large amount of training data specifically we learn the weighting of the shape appearance and spatial configuration of the model such that it maximizes the margin between the pose of the object in the positive image provided by the user during training and all possible pose in the negative image the main problem to be addressed here is that of handling the large number of possible pose of the object in the negative image we show how this seemingly difficult task can be reduced to that of solving a series of small convex optimization problem by i considering tree structured model and ii taking advantage of the form of spatial configuration generally used in such model e g potts truncated linear or truncated quadratic these restriction might not allow the model to fully capture the statistic of the object category however a observed in previous work the advantage of these model efficient learning and testing outweigh their disadvantage 
a new algorithm is proposed for background subtraction in highly dynamic scene background subtraction is equated to the dual problem of saliency detection background point are those considered not salient by suitable comparison of object and background appearance and dynamic drawing inspiration from biological vision saliency is defined locally using center surround computation that measure local feature contrast a discriminant formulation is adopted where the saliency of a location is the discriminant power of a set of feature with respect to the binary classification problem which opposes center to surround to account for both motion and appearance and achieve robustness to highly dynamic background these feature are spatiotemporal patch which are modeled a dynamic texture the resulting background subtraction algorithm is fully unsupervised requires no training stage to learn background parameter and depends only on the relative disparity of motion between the center and surround region this make it insensitive to camera motion the algorithm is tested on challenging video sequence and shown to outperform various state of the art technique for background subtraction 
global optimisation via s t graph cut is widely used in computer vision and graphic to obtain high resolution output graph cut method must construct massive n d grid graph containing billion of vertex we show that when these graph do not fit into physical memory current max flow min cut algorithm the workhorse of graph cut method are totally impractical others have resorted to banded or hierarchical approximation method that get trapped in local minimum which loses the main benefit of global optimisation we enhance the push relabel algorithm for maximum flow with two practical contribution first true global minimum can now be computed on immense grid like graph too large for physical memory these graph are ubiquitous in computer vision medical imaging and graphic second for commodity multi core platform our algorithm attains near linear speedup with respect to number of processor to achieve these goal we generalised the standard relabeling operation associated with push relabel 
a prototype based approach is introduced for action recognition the approach represents an action a a sequence of prototype for efficient and flexible action matching in long video sequence during training first an action prototype tree is learned in a joint shape and motion space via hierarchical k mean clustering then a lookup table of prototype to prototype distance is generated during testing based on a joint likelihood model of the actor location and action prototype the actor is tracked while a frame to prototype correspondence is established by maximizing the joint likelihood which is efficiently performed by searching the learned prototype tree then action are recognized using dynamic prototype sequence matching distance matrix used for sequence matching are rapidly obtained by look up table indexing which is an order of magnitude faster than brute force computation of frame to frame distance our approach enables robust action matching in very challenging situation such a moving camera dynamic background and allows automatic alignment of action sequence experimental result demonstrate that our approach achieves recognition rate of on a large gesture dataset with dynamic background on the weizmann action dataset and on the kth action dataset 
in this paper we present a novel method for parsing aerial image with a hierarchical and contextual model learned in a statistical framework we learn hierarchy at the scene and object level to handle the difficult task of representing scene element at different scale and add con textual constraint to resolve ambiguity in the scene int erpretation this allows the model to rule out inconsistent detection like car on tree and to verify low probabilit y detection based on their local context such a small car i n parking lot we also present a two step algorithm for parsing aerial image that first detects object level element like tree and parking lot using color histogram and bag ofwords model and object like roof and road usingcompositional boosting a powerful method for finding image structure we then activate the top down scene model to prune false positive from the first stage we learn this scen e model in a minimax entropy framework and show unique sample from our prior model which capture the layout of scene object we present experiment showing that hierarchical and contextual information greatly reduces the number of false positive in our result 
in many image and video collection we have access only to partially labeled data for example personal photo collection often contain several face per image and a caption that only specifies who is in the picture but not which name match which face similarly movie screenplay can tell u who is in the scene but not when and where they are on the screen we formulate the learning problem in this setting a partially supervised multiclass classification where each instance is labeled ambiguously with more than one label we show theoretically that effective learning is possible under reasonable assumption even when all the data is weakly labeled motivated by the analysis we propose a general convex learning formulation based on minimization of a surrogate loss appropriate for the ambiguous label setting we apply our framework to identifying face culled from web news source and to naming character in tv series and movie we experiment on a very large dataset consisting of hour of video and in particular achieve error for character naming on episode of lost 
we present a novel stereo algorithm which performs surface reconstruction from planar camera array it incorporates the merit of both generic camera array and rectified binocular setup recovering large surface like the former and performing efficient computation like the latter first we introduce a rectification algorithm which give freedom in the design of camera array and simplifies photometric and geometric computation we then define a novel set of data fusion function over neighborhood of camera which treat all camera symmetrically and enable standard binocular stereo algorithm to handle array with arbitrary number of camera in particular we introduce a photometric fusion function which handle partial visibility and extract depth information along both horizontal and vertical baseline finally we show that layered depth image and sprite with depth can be efficiently extracted from the rectified d space experimental result on real image confirm the effectiveness of the proposed method which reconstructs dense surface larger by on tsukuba 
efficient view registration with respect to a given d reconstruction ha many application like inside out tracking in indoor and outdoor environment and geo locating image from large photo collection we present a fast location recognition technique based on structure from motion point cloud vocabulary tree based indexing of feature directly return relevant fragment of d model instead of document from the image database additionally we propose a compressed d scene representation which improves recognition rate while simultaneously reducing the computation time and the memory consumption the design of our method is based on algorithm that efficiently utilize modern graphic processing unit to deliver real time performance for view registration we demonstrate the approach by matching hand held outdoor video to known d urban model and by registering image from online photo collection to the corresponding landmark 
we present a method for tracking a hand while it is interacting with an object this setting is arguably the one where hand tracking ha most practical relevance but pose significant additional challenge strong occlusion by the object a well a self occlusion are the norm and classical anatomical constraint need to be softened due to the external force between hand and object to achieve robustness to partial occlusion we use an individual local tracker for each segment of the articulated structure the segment are connected in a pairwise markov random field which enforces the anatomical hand structure through soft constraint on the joint between adjacent segment the most likely hand configuration is found with belief propagation both range and color data are used a input experiment are presented for synthetic data with ground truth and for real data of people manipulating object 
in this paper we present a new approach for segmentation of tubular structure in d image providing minimal interaction the main objective is to extract centerline and boundary of the vessel at the same time the first step is to represent the trajectory of the vessel not a a d curve but to go up a dimension and represent the entire vessel a a d curve where each point represents a d disc two coordinate for the center point and one for the radius the d vessel structure is then obtained a the envelope of the family of disc traversed along this d curve since this d shape is defined simply from a d curve we are able to fully exploit minimal path technique to obtain globally minimizing trajectory between two or more user supplied point using front propagation the main contribution of our approach consists on building a multi resolution metric that guide the propagation in this d space we have chosen to exploit the tubular structure of the vessel one want to extract to built an anisotropic metric giving higher speed on the center of the vessel and also when the minimal path tangent is coherent with the vessel s direction this measure is required to be robust against the disturbance introduced by noise or adjacent structure with intensity similar to the target vessel indeed if we examine the flux of the projected image gradient along a given direction on a circle of a given radius or scale one can prove that this flux is maximal at the center of the vessel in it direction and with it exact radius this approach is called optimally oriented flux combining anisotropic minimal path technique and optimally oriented flux we obtain promising result on noisy synthetic and real data 
interpolated image have data redundancy and special correlation exists among neighboring pixel which is a crucial clue in digital forensics we design a neural network based framework to approximate the stylized computational rule of interpolation algorithm for learning statistical inter pixel correlation of interpolated image the interpolation process is cognized from the interpolation result experiment are carried out on camera built in color filter array interpolation and super resolution three classifier are trained to classify image interpolation algorithm identify source camera and uncover digital forgery like the wiener attack in watermarking the special correlation can be reduced or transferred it to another image by our learned network 
the use of sparse invariant feature to recognise class of action or object ha become common in the literature however feature are often engineered to be both sparse and invariant to transformation and it is assumed that they provide the greatest discriminative information to tackle activity recognition we propose learning compound feature that are assembled from simple d corner in both space and time each corner is encoded in relation to it neighbour and from an over complete set in excess of million possible feature compound feature are extracted using data mining the final classifier consisting of set of compound feature can then be applied to recognise and localise an activity in real time while providing superior performance to other state of the art approach including those based upon sparse feature detector furthermore the approach requires only weak supervision in the form of class label for each training sequence no ground truth position or temporal alignment is required during training 
the state of the art in visual object retrieval from large database is achieved by system that are inspired by text retrieval a key component of these approach is that local region of image are characterized using high dimensional descriptor which are then mapped to visual word selected from a discrete vocabulary this paper explores technique to map each visual region to a weighted set of word allowing the inclusion of feature which were lost in the quantization stage of previous system the set of visual word is obtained by selecting word based on proximity in descriptor space we describe how this representation may be incorporated into a standard tf idf architecture and how spatial verification is modified in the case of this soft assignment we evaluate our method on the standard oxford building dataset and introduce a new dataset for evaluation our result exceed the current state of the art retrieval performance on these datasets particularly on query with poor initial recall where technique like query expansion suffer overall we show that soft assignment is always beneficial for retrieval with large vocabulary at a cost of increased storage requirement for the index 
in this work we revisit the mumford shah functional one of the most studied variational approach to image segmentation the contribution of this paper is to propose an algorithm which allows to minimize a convex relaxation of the mumford shah functional obtained by functional lifting the algorithm is an efficient primal dual projection algorithm for which we prove convergence in contrast to existing algorithm for minimizing the full mumford shah this is the first one which is based on a convex relaxation a a consequence the computed solution are independent of the initialization experimental result confirm that the proposed algorithm determines smooth approximation while preserving discontinuity of the underlying signal 
recent year have seen the development of fast and accurate algorithm for detecting object in image however a the size of the scene grows so do the running time of these algorithm if a pixel image requires m to process searching for object in a image will take s this is unsuitable under real time operating constraint by the time a frame ha been processed the object may have moved an analogous problem occurs when controlling robot camera that need to scan scene in search of target object in this paper we consider a method for improving the run time of general purpose object detection algorithm our method is based on a model of visual search in human which schedule eye fixation to maximize the long term information accrued about the location of the target of interest the approach can be used to drive robot camera that physically scan scene or to improve the scanning speed for very large high resolution image we consider the latter application in this work by simulating a digital fovea and sequentially placing it in various region of an image in a way that maximizes the expected information gain we evaluate the approach using the opencv version of the viola jones face detector after accounting for all computational overhead introduced by the fixation controller the approach double the speed of the standard viola jones detector at little cost in accuracy ishes a a function of eccentricity scanning very large image can be seen a a special case of scanning world scene thus it is reasonable to expect that the approach that biology ha found useful for scanning the world may also be useful for scanning high resolution image in this paper we explore this idea by digitally simulating in software a foveal camera the sequential placement of the digital fovea is then controlled using a policy designed to maximize the information gathered about the location of the target of interest the proposed approach is plug and play it can be applied to standard object detector in a modular manner in this our first implementation we double the computational efficiency of current object detector i e the computational overhead required to implement the digital fovea and control policy is more than compensated by the improvement in scanning efficiency the source code needed to reproduce the result in this paper is provided online a part of nick s machine perception toolbox 
given the video of a still background occluded by a fluid dynamic texture fdt this paper address the problem of separating the video sequence into it two constituent layer one layer corresponds to the video of the unoccluded background and the other to that of the dynamic texture a it would appear if viewed against a black background the model of the dynamic texture is unknown except that it represents fluid flow we present an approach that us the image motion information to simultaneously obtain a model of the dynamic texture and separate it from the background which is required to be still previous method have considered occluding layer whose dynamic follows simple motion model e g periodic or d parametric motion fdts considered in this paper exhibit complex stochastic motion we consider video showing an fdt layer e g pummeling smoke or heavy rain in front of a static background layer e g brick building we propose a novel method for simultaneously separating these two layer and learning a model for the fdt due to the fluid nature of the dt we are required to learn a model for both the spatial appearance and the temporal variation due to change in density of the fdt along with a valid estimate of the background we model the frame of a sequence a being produced by a continuous hmm characterized by transition probability based on the navier stokes equation for fluid dynamic and by generation probability based on the convex matting of the fdt with the background we learn the fdt appearance the fdt temporal variation and the background by maximizing their joint probability using interactive conditional mode icm since the learned model is generative it can be used to synthesize new video with different background and density variation experiment on video that we compiled demonstrate the performance of our method 
most current approach to recognition aim to be scale invariant however the cue available for recognizing a pixel tall object are qualitatively different from those for recognizing a pixel tall object we argue that for sensor with finite resolution one should instead use scale variant or multiresolution representation that adapt in complexity to the size of a putative detection window we describe a multiresolution model that act a a deformable part based model when scoring large instance and a rigid template with scoring small instance we also examine the interplay of resolution and context and demonstrate that context is most helpful for detecting low resolution instance when local model are limited in discriminative power we demonstrate impressive result on the caltech pedestrian benchmark which contains object instance at a wide range of scale whereas recent state of the art method demonstrate missed detection rate of at false positive per image our multiresolution model reduces the rate to 
image auto annotation is an important open problem in computer vision for this task we propose tagprop a discriminatively trained nearest neighbor model tag of test image are predicted using a weighted nearest neighbor model to exploit labeled training image neighbor weight are based on neighbor rank or distance tagprop allows the integration of metric learning by directly maximizing the log likelihood of the tag prediction in the training set in this manner we can optimally combine a collection of image similarity metric that cover different aspect of image content such a local shape descriptor or global color histogram we also introduce a word specific sigmoidal modulation of the weighted neighbor tag prediction to boost the recall of rare word we investigate the performance of different variant of our model and compare to existing work we present experimental result for three challenging data set on all three tagprop make a marked improvement a compared to the current state of the art 
graph cut based algorithm are effective for a variety of segmentation task in computer vision ongoing research is focused toward making the algorithm even more general a well a to better understand their behavior with respect to issue such a the choice of the weighting function and sensitivity to placement of seed in this paper we investigate in the context of neuroimaging segmentation the sensitivity stability of the solution with respect to the input label or seed in particular a a form of parameter learning we are interested in the effect of allowing the given set of label and consequently the response statistic of the weighting function to vary for obtaining lower energy segmentation solution this perturbation lead to a refined label set or parameter better suited to the input image yielding segmentation that are le sensitive to the set of label or seed provided our proposed algorithm using parametric pseudoflow yield improvement over graph cut based segmentation with a fixed set of label we present experiment on about d brain image volume demonstrating the efficacy of the algorithm 
this paper proposes a learnt data driven approach for accurate real time tracking of facial feature using only intensity information constraint such a a priori shape model or temporal model for dynamic are not required or used tracking facial feature simply becomes the independent tracking of a set of point on the face this allows u to cope with facial configuration not present in the training data tracking is achieved via linear predictor which provide a fast and effective method for mapping pixel level information to tracked feature position displacement to improve on this a novel and robust biased linear predictor is proposed in this paper multiple linear predictor are grouped into a rigid flock to increase robustness to further improve tracking accuracy a novel probabilistic selection method is used to identify relevant visual area for tracking a feature point these selected flock are then combined into a hierarchical multi resolution lp model experimental result also show that this method performs more robustly and accurately than aams without any a priori shape information and with minimal training example 
our objective is to obtain a state of the art object category detector by employing a state of the art image classifier to search for the object in all possible image subwindows we use multiple kernel learning of varma and ray iccv to learn an optimal combination of exponential kernel each of which capture a different feature channel our feature include the distribution of edge dense and sparse visual word and feature descriptor at different level of spatial organization such a powerful classifier cannot be tested on all image sub window in a reasonable amount of time thus we propose a novel three stage classifier which combine linear quasi linear and non linear kernel svms we show that increasing the non linearity of the kernel increase their discriminative power at the cost of an increased computational complexity our contribution include i showing that a linear classifier can be evaluated with a complexity proportional to the number of sub window independent of the sub window area and descriptor dimension ii a comparison of three efficient method of proposing candidate region including the jumping window classifier of chum and zisserman cvpr based on proposing window from scale invariant feature and iii introducing overlap recall curve a a mean to compare and optimize the performance of the intermediate pipeline stage the method is evaluated on the pascal visual object detection challenge and exceeds the performance of previously published method for most of the class 
this paper investigates the design of a system for recognizing object in d point cloud of urban environment the system is decomposed into four step locating segmenting characterizing and classifying cluster of d point specifically we first cluster nearby point to form a set of potential object location with hierarchical clustering then we segment point near those location into foreground and background set with a graph cut algorithm next we build a feature vector for each point cluster based on both it shape and it context finally we label the feature vector using a classifier trained on a set of manually labeled object the paper present several alternative method for each step we quantitatively evaluate the system and tradeoff of different alternative in a truthed part of a scan of ottawa that contains approximately million point and object of interest then we use this truth data a a training set to recognize object amidst approximately billion point of the remainder of the ottawa scan 
region based feature are getting popular due to their higher descriptive power relative to other feature however real world image exhibit change in image segment capturing the same scene part taken at different time under different lighting condition from different viewpoint etc segmentation algorithm reect these change and thus segmentation exhibit poor repeatability in this paper we address the problem of matching region of similar object under unstable segmentation merging and splitting of region make it difcult to nd such correspondence using one to one matching algorithm we present partial region matching a a solution to this problem we assume that the high contrast dominant contour of an object are fairly repeatable and use them to compute partial matching cost pmc between region region correspondence are obtained under region adjacency constraint encoded by region adjacency graph rag we integrate pmc in a many to one label assignment framework for matching rag and solve it using belief propagation we show that our algorithm can match image of similar object across unstable image segmentation we also compare the performance of our algorithm with that of the standard one to one matching algorithm on three motion sequence we conclude that our partial region matching approach is robust under segmentation irrepeatabilities 
we propose an algorithm for semantic segmentation based on d point cloud derived from ego motion we motivate five simple cue designed to model specific pattern of motion and d world structure that vary with object category we introduce feature that project the d cue back to the d image plane while modeling spatial layout and context a randomized decision forest combine many such feature to achieve a coherent d segmentation and recognize the object category present our main contribution is to show how semantic segmentation is possible based solely on motion derived d world structure our method work well on sparse noisy point cloud and unlike existing approach doe not need appearance based descriptor experiment were performed on a challenging new video database containing sequence filmed from a moving car in daylight and at dusk the result confirm that indeed accurate segmentation and recognition are possible using only motion and d world structure further we show that the motion derived information complement an existing state of the art appearance based method improving both qualitative and quantitative performance 
accurate estimation of optical flow is a challenging task which often requires addressing difficult energy optimization problem to solve them most top performing method rely on continuous optimization algorithm the modeling accuracy of the energy in this case is often traded for it tractability this is in contrast to the related problem of narrow baseline stereo matching where the top performing method employ powerful discrete optimization algorithm such a graph cut and message passing to optimize highly non convex energy in this paper we demonstrate how similar non convex energy can be formulated and optimized discretely in the context of optical flow estimation starting with a set of candidate solution that are produced by fast continuous flow estimation algorithm the proposed method iteratively fuse these candidate solution by the computation of minimum cut on graph the obtained continuous valued fusion result is then further improved using local gradient descent experimentally we demonstrate that the proposed energy is an accurate model and that the proposed discretecontinuous optimization scheme not only find lower energy solution than traditional discrete or continuous optimization technique but also lead to flow estimate that outperform the current state of the art 
this paper introduces the minimal local reconstruction error mlre a a similarity measure and present a mlre based classier from the geometric meaning of the minimal local reconstruction error we derive that the mlre based classifier is a generalization of the conventional nearest neighbor classier and the nearest neighbor line and plane classifier we further apply the mlre measure to characterize the within class and between class local scatter and then develop a mlre measure based discriminant feature extraction method the proposed mlre based feature extraction method is in line with the mlre based classification method in spirit thus the two method can be seamlessly combined in application the experimental result on the cenparmi handwritten numeral database and the feret face image database show effectiveness of the proposed mlre based feature extraction and classification method 
in this paper we want to start the discussion on whether image based d modelling technique can possibly be used to replace lidar system for outdoor d data acquisition two main issue have to be addressed in this context i camera calibration internal and external and ii dense multi view stereo to investigate both we have acquired test data from outdoor scene both with lidar and camera using the lidar data a reference we estimated the ground truth for several scene evaluation set are prepared to evaluate different aspect of d model building these are i pose estimation and multi view stereo with known internal camera parameter ii camera calibration and multi view stereo with the raw image a the only input and iii multi view stereo 
in this paper we present a novel on line probabilistic generative model that simultaneously deal with both the clustering and the tracking of an unknown number of moving object the proposed model assumes that i time series data are composed of a time varying number of object and that ii each object is governed by a mixture of an unknown number of different pattern of dynamic the problem of learning pattern of dynamic is formulated a the clustering of tracked object based on a nonparametric bayesian model with conjugate prior and this clustering in turn improves the tracking we present a particle filter for posterior estimation of simultaneous clustering and tracking through experiment with synthetic and real movie data we confirmed that the proposed model successfully learned the hidden cluster pattern and obtained better tracking result than conventional model without clustering 
medial description such a shock graph have gained significant momentum in the shape based object recognition community due to their invariance to translation rotation scale and articulation and their ability to cope with moderate amount of within class deformation while they attempt to decompose a shape into a set of part this decomposition can suffer from ligature induced instability in particular the addition of even a small part can have a dramatic impact on the representation in the vicinity of it attachment we present an algorithm for identifying and representing the ligature structure and restoring the nonligature structure that remain this lead to a bone graph a new medial shape abstraction that capture a more intuitive notion of an object s part than a skeleton or a shock graph and offer improved stability and within class deformation invariance we demonstrate these advantage by comparing the use of bone graph to shock graph in a set of view based object recognition and pose estimation trial 
object in the world can be arranged into a hierarchy based on their semantic meaning e g organism animal feline cat what about defining a hierarchy based on the visual appearance of object this paper investigates way to automatically discover a hierarchical structure for the visual world from a collection of unlabeled image previous approach for unsupervised object and scene discovery focused on partitioning the visual data into a set of nonoverlapping class of equal granularity in this work we propose to group visual object using a multi layer hierarchy tree that is based on common visual element this is achieved by adapting to the visual domain the generative hierarchical latent dirichlet allocation hlda model previously used for unsupervised discovery of topic hierarchy in text image are modeled using quantized local image region a analogue to word in text employing the multiple segmentation framework of russell et al we show that meaningful object hierarchy together with object segmentation can be automatically learned from unlabeled and unsegmented image collection without supervision we demonstrate improved object classification and localization performance using hlda over the previous non hierarchical method on the msrc dataset 
in this paper the accuracy of feature point in image detected by the scale invariant feature transform sift is analyzed it is shown that there is a systematic error in the feature point localization the systematic error is caused by the improper subpel and subscale estimation an interpolation with a parabolic function to avoid the systematic error the detection of high accurate localized feature half is proposed we present two model for the localization of a feature point in the scale space a gaussian and a difference of gaussians based model function for evaluation ground truth image data is synthesized to experimentally prove the systematic error of sift and to show that the error is eliminated using half experiment with natural image data show that the proposed methodsincrease the accuracy of the feature point position by using the gaussian and by using the difference of gaussians model 
piecewise planar model for stereo have recently become popular for modeling indoor and urban outdoor scene the strong planarity assumption overcomes the challenge presented by poorly textured surface and result in low complexity d model for rendering storage and transmission however such a model performs poorly in the presence of non planar object for example bush tree and other clutter present in many scene we present a stereo method capable of handling more general scene containing both planar and non planar region our proposed technique segment an image into piecewise planar region a well a region labeled a non planar the nonplanar region are modeled by the result of a standard multi view stereo algorithm the segmentation is driven by multi view photoconsistency a well a the result of a colorand texture based classifier learned from hand labeled planar and non planar image region additionally our method link and fuse plane hypothesis across multiple overlapping view ensuring a consistent d reconstruction over an arbitrary number of image using our system we have reconstructed thousand of frame of street level video result show our method successfully recovers piecewise planar surface alongside general d surface in challenging scene containing large building a well a residential house 
in this paper we present a novel face classification system where we represent face image a a spatial arrangement of image patch and seek a smooth non linear functional mapping for the corresponding patch such that in the range space patch of the same face are close to one another while patch from different face are far apart in l sense we accomplish this using volterra kernel which can generate successively better approximation to any smooth non linear functional during learning for each set of corresponding patch we recover a volterra kernel by minimizing a goodness functional defined over the range space of the sought functional we show that for our definition of the goodness functional which minimizes the ratio between intra class distance and inter class distance the problem of generating volterra approximation to any order can be posed a a generalized eigenvalue problem during testing each patch from the test image that is classified independently cast a vote towards image classification and the class with the maximum vote is chosen a the winner we demonstrate the effectiveness of the proposed technique in recognizing face by extensive experiment on yale cmu pie and extended yale b benchmark face datasets and show that our technique consistently outperforms the state of the art in learning based face discrimination 
in this paper we address the complex problem of rapid modeling of large scale area and present a novel approach for the automatic reconstruction of city from remote sensor data the goal in this work is to automatically create lightweight watertight polygonal d model from lidar data light detection and ranging captured by an airborne scanner this is achieved in three step preprocessing segmentation and modeling a shown in figure our main technical contribution in this paper are i a novel robust automatic segmentation technique based on the statistical analysis of the geometric property of the data which make no particular assumption about the input data thus having no data dependency and ii an efficient and automatic modeling pipeline for the reconstruction of large scale area containing several thousand of building we have extensively tested the proposed approach with several city size datasets including downtown baltimore downtown denver the city of atlanta downtown oakland and we present and evaluate the experimental result 
in this work video segmentation is viewed a an efficient intra frame grouping temporally reinforced by a strong inter frame coherence traditional approach simply regard pixel motion a another prior in the mrf map framework since pixel pre grouping is inefficiently performed on every frame the strong correlation between inter frame grouping is largely underutilized we exploit the inter frame correlation to propagate trustworthy grouping from the previous frame a preceding graph is constructed and labeled for the previous frame it is temporally propagated to the current frame and validated by similarity measure all unlabeled subgraphs are spatially aggregated for the final grouping experimental result show that the proposed approach is highly efficient for spatio temporal segmentation it make good use of temporal correlation and produce satisfactory grouping result 
we present a novel method to solve sign ambiguity for phase demodulation from a single interferometric image that possibly contains closed fringe the problem is formulated in a binary pairwise energy minimization framework based on phase gradient orientation continuity the objective function is non submodular and therefore it minimization is an np hard problem for which we devise a multigrid hierarchy of quadratic pseudoboolean optimization problem that can be improved iteratively to approximate the optimal solution compared with traditional path following phase demodulation method the new approach doe not require any heuristic scanning strategy it is not subject to the propagation of error and the extension to three dimensional fringe pattern is straightforward a set of experiment with synthetic data and real prelens tear film interferometric image of the human eye demonstrate the effectiveness and robustness of the proposed algorithm in comparison with existing state of the art phase demodulation method 
we present a novel approach to compute the similarity between two unordered variable sized vector set to solve this problem several author have proposed to model each vector set with a gaussian mixture model gmm and to compute a probabilistic measure of similarity between the gmms the main contribution of this paper is to model each vector set with a gmm adapted from a common ldquouniversalrdquo gmm using the maximum a posteriori map criterion the advantage of this approach are twofold map provides a more accurate estimate of the gmm parameter compared to standard maximum likelihood estimation mle in the challenging case where the cardinality of the vector set is small moreover there is a correspondence between the gaussians of two gmms adapted from a common distribution and one can take advantage of this fact to compute efficiently the probabilistic similarity this work is applied to the image categorization problem image are modeled a bag of low level feature and classification is performed using a kernel classifier based on the proposed similarity measure experimental result on the pascal voc and voc database show the excellent performance of our approach 
transfer learning allows leveraging the knowledge of source domain available a priori to help training a classifier for a target domain where the available data is scarce the effectiveness of the transfer is affected by the relationship between source and target rather than improving the learning brute force leveraging of a source poorly related to the target may decrease the classifier performance one strategy to reduce this negative transfer is to import knowledge from multiple source to increase the chance of finding one source closely related to the target this work extends the boosting framework for transferring knowledge from multiple source two new algorithm multisource tradaboost and tasktradaboost are introduced analyzed and applied for object category recognition and specific object detection the experiment demonstrate their improved performance by greatly reducing the negative transfer a the number of source increase tasktradaboost is a fast algorithm enabling rapid retraining over new target 
normalized cut is a widely used technique for solving a variety of problem although finding the optimal normalized cut ha proven to be np hard spectral relaxation can be applied and the problem of minimizing the normalized cut can be approximately solved using eigen computation however it is a challenge to incorporate prior information in this approach in this paper we express prior knowledge by linear constraint on the solution with the goal of minimizing the normalized cut criterion with respect to these constraint we develop a fast and effective algorithm that is guaranteed to converge convincing result are achieved on image segmentation task where the prior knowledge is given a the grouping information of feature 
a well known theoretical result for motion estimation using the generalized camera model is that corresponding image ray can be used to solve linearly for the motion of a generalized camera however this paper show that for many common configuration of the generalized camera model e g multi camera rig catadioptric camera etc such a simple point algorithm doe not exist due to some previously overlooked ambiguity we further discover that despite the above ambiguity we are still able to solve the motion estimation problem effectively by a new algorithm proposed in this paper our algorithm is essentially linear easy to implement and the computational efficiency is very high experiment on both real and simulated data show that the new algorithm achieves reasonably high accuracy a well 
recently on line adaptation of binary classifier for tracking have been investigated on line learning allows for simple classifier since only the current view of the object from it surrounding background need to be discriminiated however on line adaption face one key problem each update of the tracker may introduce an error which finally can lead to tracking failure drifting the contribution of this paper is a novel on line semi supervised boosting method which significantly alleviates the drifting problem in tracking application this allows to limit the drifting problem while still staying adaptive to appearance change the main idea is to formulate the update process in a semi supervised fashion a combined decision of a given prior and an on line classifier this come without any parameter tuning in the experiment we demonstrate real time tracking of our semiboost tracker on several challenging test sequence where our tracker outperforms other on line tracking method 
we propose a novel method for removing irrelevant frame from a video given user provided frame level labeling for a very small number of frame we first hypothesize a number of candidate area which possibly contain the object of interest and then figure out which area s truly contain the object of interest our method enjoys several favorable property first compared to approach where a single descriptor is used to describe a whole frame each area s feature descriptor ha the chance of genuinely describing the object of interest hence it is le affected by background clutter second by considering the temporal continuity of a video instead of treating the frame a independent we can hypothesize the location of the candidate area more accurately third by infusing prior knowledge into the topic motion model we can precisely follow the trajectory of the object of interest this allows u to largely reduce the number of candidate area and hence reduce the chance of overfitting the data during learning we demonstrate the effectiveness of the method by comparing it to several other semi supervised learning approach on challenging video clip 
although object recognition method based on local learning can reasonably resolve the difficulty caused by the large variation in image from the same category the high risk of overfitting and the heavy computational cost in training numerous local model classifier or distance function often limit their applicability to address these two unpleasant issue we cast the multiple independent training process of local model a a correlative multi task learning problem and design a new boosting algorithm to accomplish it specifically we establish a parametric space where these local model lie and spread a a manifold like structure and use boosting to perform local model training by completing the manifold embedding via sharing the common embedding space the learning of each local model can be properly regularized by the extra knowledge from other model while the training time is also significantly reduced experimental result on two benchmark datasets caltech and voc support that our approach not only achieves promising recognition rate but also give a two order speed up in realizing local learning 
we introduce an algorithm that guide the user to tag face in the best possible order during a face recognition assisted tagging scenario in particular we extend the active learning paradigm to take advantage of constraint known a priori for example in the context of personal photo collection if two face come from the same source photograph we know that they must be of different people similarly in the context of video we know that the face from a single track must be of the same person given a set of unlabeled image and constraint we use a probabilistic discriminative model that model the posterior distribution by propagating label information using a message passing scheme the uncertainty estimate provided by the model naturally allows for active learning paradigm where the user is consulted after each iteration to tag additional face our experiment show that performing active learning while incorporating a priori constraint provides a significant boost in many real world face recognition task 
this paper proposes a generic method for action recognition in uncontrolled video the idea is to use image collected from the web to learn representation of action and use this knowledge to automatically annotate action in video our approach is unsupervised in the sense that it requires no human intervention other than the text querying it benefit are two fold we can improve retrieval of action image and we can collect a large generic database of action pose which can then be used in tagging video we present experimental evidence that using action image collected from the web annotating action is possible 
tracking the left ventricle lv in d ultrasound data is a challenging task because of the poor image quality and speed requirement many previous algorithm applied standard d tracking method to tackle the d problem however the performance is limited due to increased data size landmark ambiguity signal drop out or non rigid deformation in this paper we present a robust fast and accurate d lv tracking algorithm we propose a novel onestep forward prediction to generate the motion prior using motion manifold learning and introduce two collaborative tracker to achieve both temporal consistency and failure recovery compared with tracking by detection and d optical flow our algorithm provides the best result and subvoxel accuracy the new tracking algorithm is completely automatic and computationally efficient it requires le than second to process a d volume which contains voxels 
how can knowing about some category help u to discover new one in unlabeled image unsupervised visual category discovery is useful to mine for recurring object without human supervision but existing method assume no prior information and thus tend to perform poorly for cluttered scene with multiple object we propose to leverage knowledge about previously learned category to enable more accurate discovery we introduce a novel object graph descriptor to encode the layout of object level co occurrence pattern relative to an unfamiliar region and show that by using it to model the interaction between an image s known and unknown object we can better detect new visual category rather than mine for all category from scratch our method identifies new object while drawing on useful cue from familiar one we evaluate our approach on benchmark datasets and demonstrate clear improvement in discovery over conventional purely appearance based baseline 
this paper present a new approach for multi view object class detection appearance and geometry are treated a separate learning task with different training data our approach us a part model which discriminatively learns the object appearance with spatial pyramid from a database of real image and encodes the d geometry of the object class with a generative representation built from a database of synthetic model the geometric information is linked to the d training data and allows to perform an approximate d pose estimation for generic object class the poseestimation providesan efficientmethodto evaluate the likelihood of group of d part detection with respect to a full d geometry model in order to disambiguate and prune d detection and to handle occlusion in contrast to other method neither tediousmanual part annotationof training image nor explicit appearance matching between synthetic and real training data is required which result in high geometric fidelity and in increased flexibility on the d object category datasets car and bicycle the current state of the art benchmark for d object detection our approach outperforms previously published result for viewpoint estimation 
this paper present a new image denoising model for real color photo noise removal our model is implemented in the hue saturation and intensity hsi space the hue and saturation denoising are combined and implemented a a complex total variation tv diffusion the intensity denoising is based on a diffusion flow to minimize a new energy functional which is constructed with intensity component statistic besides the common gradient based edge stopping function for anisotropic diffusion specifically for color photo denoising we incorporate an intensity based brightness adjusting term in the new energy which corresponds to the noise disturbance with respect to photo intensity in addition we use the gradient vector flow gvf a the new diffusion direction for more accurate and robust denoising compared with previous diffusion flow only based on regular image gradient this model provides more accurate image structure and intensity noise characterization for better denoising comprehensive quantitative and qualitative experiment on color photo demonstrate the improved performance of the proposed model when compared with recognized approach and commercial software 
in this paper we present a novel algorithm based on flow velocity field estimation to count the number of pedestrian across a detection line or inside a specified region we regard pedestrian across the line a fluid flow and design a novel model to estimate the flow velocity field by integrating over time the dynamic mosaic are constructed to count the number of pixel and edge passed through the line consequentially the number of pedestrian can be estimated by quadratic regression with the number of weighted pixel and edge a input the regressors are learned off line from several camera tilt angle and have taken the calibration information into account we use tilt angle specific learning to ensure direct deployment and avoid overfitting while the commonly used scene specific learning scheme need on site annotation and always trend to overfitting experiment on a variety of video verified that the proposed method can give accurate estimation under different camera setup in real time 
given a finite number of data point sampled from a low dimensional manifold embedded in a high dimensional space together with the parameter vector for a subset of the data point we need to determine the parameter vector for the rest of the data point this problem is known a semi supervised manifold learning and in this paper we propose method to handle this problem by solving certain eigenvalue problem our proposed method address two key issue in semi supervised manifold learning fitting of the local affine geometric structure and preserving the global manifold structure embodied in the overlapping neighborhood around each data point we augment the alignment matrix of local tangent space alignment ltsa with the orthogonal projection based on the known parameter vector giving rise to the eigenvalue problem that characterizes the semi supervised manifold learning problem we also discus the role of different type of neighborhood and their influence on the learning process we illustrate the performance of the proposed method using both synthetic data set a well a data set arising from application in video annotation 
with the emergence of new application centered around the sharing of image data question concerning the protection of the privacy of people visible in the scene arise recently formal method for the de identification of image have been proposed which would benefit from multi factor coding to separate identity and non identity related factor however existing multi factor model require complete label during training which are often not available in practice in this paper we propose a new multi factor framework which unifies linear bilinear and quadratic model we describe a new fitting algorithm which jointly estimate all model parameter and show that it outperforms the standard alternating algorithm we furthermore describe how to avoid overfitting the model and how to train the model in a semi supervised manner in experiment on a large expression variant face database we show that data coded using our multi factor model lead to improved data utility while providing the same privacy protection 
this paper present a novel distributed framework for multi target tracking with an efficient data association computation a decentralized representation of tracker motion and association variable is adopted considering the interleaved nature of data association and tracker filtering the multi target tracking is formulated a a missing data problem and the solution is found by the proposed variational em algorithm we analytically show that the posteriori distribution of tracker motion the real interest in term of tracking application can be effectively computed in the e step of the em iteration and the solution of tracker association variable can be pursued under a derived graph based discrete optimization formulation thus efficiently estimated in the m step by the recently emerging graph optimization algorithm the proposed approach is very general such that sophisticated data association priori and likelihood function can be easily incorporated this general framework is tested with both simulation data and real world surveillance video the reported qualitative and quantitative study verify the effectiveness and low computational cost of the algorithm 
the notion of using contextinformationfor solving highlevel vision problem ha been increasingly realized in the field however how to learn an effective and efficient context model together with the image appearance remains mostly unknown the current literature using markov randomfields mrfs andconditionalrandomfields crfs often involves specific algorithm design in which the modeling and computing stage are studied in isolation in this paper we propose an auto context algorithm given a set of training image and their corresponding label map we first learn a classifier on local image patch the discriminative probability or classification confidence map by the learned classifier are then used a context information in addition to the original image patch to train a new classifier the algorithm then iterates to approach the ground truth auto context learns an integrated low level and context model and is very general and easy to implement under nearly the identical parameter setting in the training we apply the algorithm on three challengingvision application object segmentation human body configuration and scene region labeling it typically take about second to run the algorithm in testing moreover the scope of the proposed algorithm go beyond high level vision it ha the potential to be used for a wide variety of problem of multi variate labeling 
this paper introduces a method for scene categorization by modeling ambiguity in the popular codebook approach the codebook approach describes an image a a bag of discrete visual codewords where the frequency distribution of these word are used for image categorization there are two drawback to the traditional codebook model codeword uncertainty and codeword plausibility both of these drawback stem from the hard assignment of visual feature to a single codeword we show that allowing a degree of ambiguity in assigning codewords improves categorization performance for three state of the art datasets 
we propose a method that detects and segment multiple partially occluded object in image a part hierarchy is defined for the object class whole object segmentor and part detector are learned by boosting shape oriented local image feature during detection the part detector are applied to the input image all the edge pixel in the image that positively contribute to part detection response are extracted a joint likelihood of multiple object is defined based on the part detection response and the object edge computing the joint likelihood includes an inter object occlusion reasoning that is based on the object silhouette extracted with the whole object segmentor by maximizing the joint likelihood part detection response are grouped merged and assigned to multiple object hypothesis the proposed approach is applied to the pedestrian class and evaluated on two public test set the experimental result show that our method outperforms the previous one 
a novel and automated technique for learning human perspective context hpc from a scene is proposed in this paper it is found that two model are required to describe hpc for camera tilt angle ranging from deg to deg from a scene the tilt angle can be inferred from the observed human shape and head foot position afterward a novel me dt model estimation data tuning algorithm is proposed to learn human perspective context from live data of various degree of uncertainty the uncertainty may come from the variation of human individual height and pose and segmentation recognition error me dt not only estimate the model parameter from the training data but also tune the data to achieve a better head foot correlation the human perspective context provides a feasible constraint on the scale position and orientation of human in the scene applying this constraint to the hog human detection great reduction of the detection window and improved performance have been obtained compared to conventional method 
conventional wired detection of vital sign limit the use of these important physiological parameter by many application such a airport health screening elder care and workplace preventive care in this paper we explore contact free heart rate and respiratory rate detection through measuring infrared light modulation emitted near superficial blood vessel or a nasal area respectively to deal with complication caused by subject movement facial expression and partial occlusion of the skin we propose a novel algorithm based on contour segmentation and tracking clustering of informative pixel and dominant frequency component estimation the proposed method achieves robust subject region of interest alignment and motion compensation in infrared video with low snr it relaxes some strong assumption used in previous work and substantially improves on previously reported performance preliminary experiment on heart rate estimation for subject and respiratory rate estimation for subject exhibit promising result 
we present a novel keyframe selection and recognition method for robust markerless real time camera tracking our system contains an offline module to select feature from a group of reference image and an online module to match them to the input live video in order to quickly estimate the camera pose the main contribution lie in constructing an optimal set of keyframes from the input reference image which are required to approximately cover the entire space and at the same time minimize the content redundancy amongst the selected frame this strategy not only greatly save the computation but also help significantly reduce the number of repeated feature so a to improve the camera tracking quality our system also employ a parallel computing scheme with multi cpu hardware architecture experimental result show that our method dramatically enhances the computation efficiency and eliminates the jittering artifact 
the paper address the problem of factorization based d reconstruction from uncalibrated image sequence we propose a quasi perspective projection model and apply the model to structure and motion recovery of rigid and nonrigid object based on factorization of tracking matrix the novelty and contribution of the paper lie in three aspect first under the assumption that the camera is far away from the object with small rotation we propose and prove that the imaging process can be modeled by quasiperspective projection the model is more accurate than affine since the projective depth are implicitly embedded second we apply the model to the factorization algorithm and establish the framework of rigid and nonrigid factorization under quasi perspective assumption third we propose a new and robust method to recover the transformation matrix that upgrade the factorization to the euclidean space the proposed method is validated and evaluated on synthetic and real image sequence and good improvement over existing solution are observed 
we present a novel image operator that seek to find the value of stroke width for each image pixel and demonstrate it use on the task of text detection in natural image the suggested operator is local and data dependent which make it fast and robust enough to eliminate the need for multi scale computation or scanning window extensive testing show that the suggested scheme outperforms the latest published algorithm it simplicity allows the algorithm to detect text in many font and language 
this paper address the problem of generating a super resolution sr image from a single low resolution input image we approach this problem from the perspective of compressed sensing the low resolution image is viewed a downsampled version of a high resolution image whose patch are assumed to have a sparse representation with respect to an over complete dictionary of prototype signal atom the principle of compressed sensing ensures that under mild condition the sparse representation can be correctly recovered from the downsampled signal we will demonstrate the effectiveness of sparsity a a prior for regularizing the otherwise ill posed super resolution problem we further show that a small set of randomly chosen raw patch from training image of similar statistical nature to the input image generally serve a a good dictionary in the sense that the computed representation is sparse and the recovered high resolution image is competitive or even superior in quality to image produced by other sr method 
traditionally object recognition is performed based solely on the appearance of the object however relevant information also exists in the scene surrounding the object a supported by our human study this contextual information is necessary for accurate recognition in low resolution image this scenario with impoverished appearance information a opposed to using image of higher resolution provides an appropriate venue for studying the role of context in recognition in this paper we explore the role of context for dense scene labeling in small image given a segmentation of an image our algorithm assigns each segment to an object category based on the segment s appearance and contextual information we explicitly model context between object category through the use of relative location and relative scale in addition to co occurrence we perform recognition test on low and high resolution image which vary significantly in the amount of appearance information present using just the object appearance information the combination of appearance and context a well a just context without object appearance information blind recognition we also perform these test in human study and analyze our finding to reveal interesting pattern with the use of our context model our algorithm achieves state of the art performance on msrc and corel datasets 
online foreground extraction is very difficult due to the complexity of real scene almost all the previous method assume that the background is stationary which not only incur unreliable result due to background activity like dynamic shadow moving background object etc but also make them hard to be extended to the case of non stationary background in this paper we assume that the background is continuous instead of stationary and present a transductive video segmentation method that can handle dynamic scene captured by a hand held moving camera the segmentation is propagated based on local color model and temporal prior a well a a dynamic global color model dgkde in the case of occlusion a novel local color modeling method flkde is proposed to model both local color distribution and temporal prior at each pixel flkde can be learned additively to reach real time speed finally a very fast geodesic based method is adopted to solve for the segmentation experiment show that our method can generate good quality segmentation for wide variety of scene and can reach fps for size of input image sequence 
segmentation of document image remains a challenging vision problem although document image have a structured layout capturing enough of it for segmentation can be difficult most current method combine text extraction and heuristic for segmentation but text extraction is prone to failure and measuring accuracy remains a difficult challenge furthermore when presented with significant degradation many common heuristic method fall apart in this paper we propose a bayesian generative model for document image which seek to overcome some of these drawback our model automatically discovers different region present in a document image in a completely unsupervised fashion we attempt no text extraction but rather use discrete patch based codebook learning to make our probabilistic representation feasible each latent region topic is a distribution over these patch index we capture rough document layout with an mrf potts model we take an analysis by synthesis approach to examine the model and provide quantitative segmentation result on a manuallylabeled document image data set we illustrate our model s robustness by providing result on a highly degraded version of our test set 
this paper present an algorithm for recovering the globally optimal d human figure detection using a loopy graph model this is computationally challenging because the time complexity scale exponentially in the size of the largest clique in the graph the proposed algorithm us branch and bound bb to search for the globally optimal solution the algorithm converges rapidly in practice and this is due to a novel method for quickly computing tree based lower bound the key idea is to recycle the dynamic programming dp table associated with the tree model to look up the tree based lower bound rather than recomputing the lower bound from scratch this technique is further sped up using range minimum query data structure to provide o cost for computing the lower bound for most iteration of the bb algorithm the algorithm is evaluated on the iterative parsing dataset and it is shown to run fast empirically 
this paper proposes a new approach for video stabilization most existing video stabilization method adopt a framework of three step motion estimation motion compensation and image composition camera motion is often estimated based on pairwise registration between frame thus these method often assume static scene or distant background furthermore for scene with moving object robust method are required for finding the dominant motion such assumption and judgement could lead to error in motion parameter error are compounded by motion compensation which smoothes motion parameter this paper proposes a method to directly stabilize a video without explicitly estimating camera motion thus assuming neither motion model nor dominant motion the method first extract robust feature trajectory from the input video optimization is then performed to find a set of transformation to smooth out these trajectory and stabilize the video in addition the optimization also considers quality of the stabilized video and selects a video with not only smooth camera motion but also le unfilled area after stabilization experiment show that our method can deal with complicated video containing near large and multiple moving object 
this paper address the problem of track stitching and dynamic event detection in a sequence of frame the input data consists of track possibly fragmented due to occlusion belonging to multiple target the goal are to i establish track identity across occlusion and ii detect point where the motion of these target undergo substantial change the main result of the paper is a simple computationally inexpensive approach that achieves these goal in a unified way given a continuous track the main idea is to detect change in the dynamic by parsing it into segment according to the complexity of the model required to explain the observed data intuitively change in this complexity correspond to point where the dynamic change since the problem of estimating the complexity of the underlying model can be reduced to estimating the rank of a matrix constructed from the observed data these change can be found with a simple algorithm computationally no more expensive that a sequence of svds proceeding along the same line fragmented track corresponding to multiple target can be linked by searching for set corresponding to minimal complexity joint model a we show in the paper this problem can be reduced to a semi definite optimization and efficiently solved with commonly available software 
recent study have shown that embedding similarity dissimilarity measure between distribution in the variational level set framework can lead to effective object segmentation tracking algorithm in this connection existing method assume implicitly that the overlap between the distribution of image data within the object and it background ha to be minimal unfortunately such assumption may not be valid in many important application this study investigates an overlap prior which embeds knowledge about the overlap between the distribution of the object and the background in level set tracking it consists of evolving a curve to delineate the target object in the current frame the level set curve evolution equation is sought following the maximization of a functional containing three term an original overlap prior which measure the conformity of overlap between the nonparametric kernel based distribution within the object and the background to a learned description a term which measure the similarity between a model distribution of the object and the sample distribution inside the curve and a regularization term for smooth segmentation boundary the bhattacharyya coefficient is used a an overlap measure apart from leading to a method which is more versatile than current one the overlap prior speed up significantly the curve evolution comparison and result demonstrate the advantage of the proposed prior over related method and it usefulness in important application such a the left ventricle tracking in magnetic resonance mr image 
many feature detection algorithm rely on the choice of scale in this paper we complement standard scaleselection algorithm with spatial regularization to this end we formulate scale selection a a graph labeling problem and employ markov random field multi label optimization we focus on detecting the scale of vascular structure in medical image we compare the detected vessel scale using our method to those obtained using the selection approach of the well known vesselness filter frangi et al we propose and discus two different approach for evaluating the goodness of scale selection our result s on image from the digital retinal image for vessel extraction drive database show an average reduction in these error measurement by more than 
we address the volumetric reconstruction problem that take a input a series of orthographic multi energy x ray image producing a output a reconstructed model space consisting of uniform size mass density voxels our approach solves the non linear constrained optimization formulation problem by constructing a compliant estimate of volumetric distribution subject to projective and domain constraint and minimizes variational irregularity to resolve the inherent ambiguity of single view formulation an optional shape model may be introduced to aid the reconstruction process we demonstrate our method s practical usage a a new in vivo method for estimating threedimensional body segmental composition and compare it result with those of existing method 
restoring a clear image from a single motion blurred image due to camera shake ha long been a challenging problem in digital imaging existing blind deblurring technique either only remove simple motion blurring or need user interaction to work on more complex case in this paper we present an approach to remove motion blurring from a single image by formulating the blind blurring a a new joint optimization problem which simultaneously maximizes the sparsity of the blur kernel and the sparsity of the clear image under certain suitable redundant tight frame system curvelet system for kernel and framelet system for image without requiring any prior information of the blur kernel a the input our proposed approach is able to recover high quality image from given blurred image furthermore the new sparsity constraint under tight frame system enable the application of a fast algorithm called linearized bregman iteration to efficiently solve the proposed minimization problem the experiment on both simulated image and real image showed that our algorithm can effectively removing complex motion blurring from nature image 
in this paper we address the pair activity classification problem which explores the relationship between two active object based on their motion information our contribution are three fold first we design a set of feature e g causality ratio and feedback ratio based on the granger causality test gct for describing the pair activity encoded a trajectory pair these feature along with conventional velocity and position feature are essentially of multi modality and may be greatly different in scale and importance to make full use of them we then present a novel feature normalization procedure to learn the coefficient for weighting these feature by maximizing the discriminating power measured by weighted correlation finally we collected a pair activity database of five category each of which consists of about instance the extensive experiment on this database validate the effectiveness of the designed feature for pair activity representation and also demonstrate that the proposed feature normalization procedure greatly boost the pair activity classification accuracy 
we present a fast graph cut algorithm for planar graph it is based on the graph theoretical work and lead to an efficient method that we apply on shape matching and image segmentation in contrast to currently used method in computer vision the presented approach provides an upper bound for it runtime behavior that is almost linear in particular we are able to match two different planar shape of n point in o n logn and segment a given image of n pixel in o n logn we present two experimental benchmark study which demonstrate that the presented method is also in practice faster than previously proposed graph cut method on planar shape matching and image segmentation we observe a speed up of an order of magnitude depending on resolution 
future progress in neuroscience hinge on reconstruction of neuronal circuit to the level of individual synapsis because of the specific of neuronal architecture imaging must be done with very high resolution and throughput while electron microscopy em achieves the required resolution in the transverse direction it depth resolution is a severe limitation computed tomography ct may be used in conjunction with electron microscopy to improve the depth resolution but this severely limit the throughput since several ten or hundred of em image need to be acquired here we exploit recent advance in signal processing to obtain high depth resolution em image computationally first we show that the brain tissue can be represented a sparse linear combination of local basis function that are thin membrane like structure oriented in various direction we then develop reconstruction technique inspired by compressive sensing that can reconstruct the brain tissue from very few typically tomographic view of each section this enables tracing of neuronal connection across layer and hence high throughput reconstruction of neural circuit to the level of individual synapsis 
a variety of flexible model have been proposed to detect object in challenging real world scene motivated by some of the most successful technique we propose a hierarchical multi feature representation and automatically learn flexible hierarchical object model for a wide variety of object class to that end we not only rely on automatic selection of relevant individual feature but go beyond previous work by automatically selecting and modeling complex long range feature coupling within this model to achieve this generality and flexibility our work combine structure learning in conditional randomfields and discriminative parameter learning of classifier using hierarchical feature we adopt an efficient gradient based heuristic for model selection and carry it forward to discriminative multidimensional selection of feature and their coupling for improved detection performance experimentally we consistently outperform the currently leading method on all class of the pascal voc challenge and achieve the best published result on of class 
we consider the problem of lossy image compression from machine learning perspective typical image compression algorithm first transform the image from it spatial domain representation to frequency domain representation using some transform technique such a discrete cosine transform and discrete wavelet transform and then code the transformed value recently instead of performing a frequency transformation machine learning based approach ha been proposed which us the color information from a few representative pixel to learn a model which predicts color on the rest of the pixel selecting the most representative pixel is essentially an active learning problem while colorization is a semi supervised learning problem in this paper we propose a novel active learning algorithm called graph regularized experimental design gred which share the same principle of the semi supervised learning algorithm used for colorization this way active and semi supervised learning is unified into a single framework for pixel selection and colorization our experimental result suggest that the proposed approach achieves higher compression ratio and image quality while the compression time is significantly reduced 
a growing number of application depend on accurate and fast d scene analysis example are object recognition collision prevention d modeling mixed reality and gesture recognition the estimation of a range map by image analysis or laser scan technique is still a timeconsuming and expensive part of such system a lower priced fast and robust alternative for distance measurement are time of flight tof camera recently significant improvement have been made in order to achieve low cost and compact tof device that have the potential to revolutionize many field of research including computer vision computer graphic and human computer interaction hci these technology are starting to have an impact on research and commercial application the upcoming generation of tof sensor however will be even more powerful and will have the potential to become ubiquitous geometry device for gaming web conferencing and numerous other application this paper will give an account of some recent development in tof technology and will discus application of this technology for vision graphic and hci 
the concept of graph cut is by now a standard method for all sort of low level vision problem it popularity is largely due to the fact that globally or near globally optimal solution can be computed using efficient max flow algorithm on the other hand it ha been observed that this method may suffer from metrication error recent work ha begun studying continuousversions of graph cut which give smaller metrication error another advantage is that continuous cut are straightforward to parallelize in this paper we extend the class of functionals that can beoptimized in the continuoussetting to includeanisotropic tv norm we show that there is a so called coarea formula for these functionalsmaking it possible to minimize them by solving a convex problem we also show that the concept of expansion move can be reformulated to fit the continuous formulation and we derive approximation bound in analogy with the discrete case a continuous version of the potts model for multi class segmentation problem is presented and it is shown how to obtain provably good solution using continuous expansion 
bad weather such a fog and haze can significantly degrade the visibility of a scene optically this is due to the substantial presence of particle in the atmosphere that ab sorb and scatter light in computer vision the absorption and scattering process are commonly modeled by a linear combination of the direct attenuation and the airlight based on this model a few method have been proposed and most of them require multiple input image of a scene which have either different degree of polarization or different atmospheric condition this requirement is the mai n drawback of these method since in many situation it is difficult to be fulfilled to resolve the problem we introduce an automated method that only requires a single input image this method is based on two basic observation first image with enhanced visibility or clear day image have more contrast than image plagued by bad weather second airlight whose variation mainly depends on the distance of object to the viewer tends to be smooth relying on these two observation we develop a cost function in the framework of markov random field which can be efficiently optimized by various technique such a graph cut or belief propagation the method doe not require the geometrical information of the input image and is applicable for both color and gray image 
the goal of this work is to build video camera whose spatial and temporal resolution can be changed post capture depending on the scene building such camera is difficult due to two reason first current video camera allow the same spatial resolution and frame rate for the entire captured spatio temporal volume second both these parameter are fixed before the scene is captured we propose different component of video camera design a sampling scheme processing of captured data and hardware that offer post capture variable spatial and temporal resolution independently at each image location using the motion information in the captured data the correct resolution for each location is decided automatically our technique make it possible to capture fast moving object without motion blur while simultaneously preserving high spatial resolution for static scene part within the same video sequence our sampling scheme requires a fast per pixel shutter on the sensor array which we have implemented using a co located camera projector system 
the hybrid linear modeling problem is to identify a set of d dimensional affine set in rd it arises for example in object tracking and structure from motion the hybrid linear model can be considered a the second simplest behind linear manifold model of data in this paper we will present a very simple geometric method for hybrid linear modeling based on selecting a set of local best fit flat that minimize a global error measure the size of the local neighborhood is determined automatically by the jones number it is proven under certain geometric condition that good local neighborhood exist and are found by our method we also demonstrate how to use this algorithm for fast determination of the number of affine subspace we give extensive experimental evidence demonstrating the state of the art accuracy and speed of the algorithm on synthetic and real hybrid linear data 
several recently proposed architecture for high performance object recognition are composed of two main stage a feature extraction stage that extract locally invariant feature vector from regularly spaced image patch and a somewhat generic supervised classifier the first stage is often composed of three main module a bank of filter often oriented edge detector a non linear transform such a a point wise squashing function quantization or normalization a spatial pooling operation which combine the output of similar filter over neighboring region we propose a method that automatically learns such feature extractor in an unsupervised fashion by simultaneously learning the filter and the pooling unit that combine multiple filter output together the method automatically generates topographic map of similar filter that extract feature of orientation scale and position these similar filter are pooled together producing locally invariant output the learned feature descriptor give comparable result a sift on image recognition task for which sift is well suited and better result than sift on task for which sift is le well suited 
this paper present a novel approach to skim and describe d video d video is an imaging technology which consists in a stream of d model in motion captured by a synchronized set of video camera each frame is composed of one or several d model and therefore the acquisition of long sequence at video rate requires massive storage device in order to reduce the storage cost while keeping relevant information we propose to encode d video sequence using a topology based shape descriptor dictionary this dictionary is either generated from a set of extracted pattern or learned from training input sequence with semantic annotation it relies on an unsupervised d shape based clustering of the dataset by reeb graph and feature a markov network to characterize topological change the approach allows content based compression and skimming with accurate recovery of sequence and can handle complex topological change redundancy are detected and skipped based on a probabilistic discrimination process semantic description of video sequence is then automatically performed in addition forthcoming frame encoding is achieved using a multiresolution matching scheme and allows action recognition in d our experiment were performed on complex d video sequence we demonstrate the robustness and accuracy of the d video skimming with dramatic low bitrate coding and high compression ratio 
many application in computer vision and pattern recognition involve drawing inference on certain manifoldvalued parameter in order to develop accurate inference algorithm on these manifold we need to a understand the geometric structure of these manifold b derive appropriate distance measure and c develop probability distribution function pdf and estimation technique that are consistent with the geometric structure of these manifold in this paper we consider two related manifold the stiefel manifold and the grassmann manifold which arise naturally in several vision application such a spatio temporal modeling affine invariant shape analysis image matching and learning theory we show how accurate statistical characterization that reflects the geometry of these manifold allows u to design efficient algorithm that compare favorably to the state of the art in these very different application in particular we describe appropriate distance measure and parametric and non parametric density estimator on these manifold these method are then used to learn class conditional density for application such a activity recognition video based face recognition and shape classification 
we investigate how to discover all common visual pattern within two set of feature point common visual pattern generally share similar local feature a well a similar spatial layout in this paper these two type of information are integrated and encoded into the edge of a graph whose node represent potential correspondence and the common visual pattern then correspond to those strongly connected subgraphs all such strongly connected subgraphs correspond to large local maximum of a quadratic function on simplex which is an approximate measure of the average intra cluster affinity score of these subgraphs we find all large local maximum of this function thus discover all common visual pattern and recover the correct correspondence using replicator equation and through a systematic way of initialization the proposed algorithm posse two characteristic robust to outlier and being able to discover all common visual pattern no matter the mapping among the common visual pattern are one to one one to many or many to many extensive experiment on both point set and real image demonstrate the property of our proposed algorithm in term of robustness to outlier tolerance to large spatial deformation and simplicity in implementation 
a new problem of retrieving social game from unstructured video is proposed social game are characterized by repetition with variation of alternating turn between two player we define game a quasi periodic motion pattern in video based on their repetitiveness property we have developed an algorithm to extract such pattern from video the pattern extracted by our method from video clip of social game taken from youtube are shown to correspond to meaningful stage of the game we demonstrate promising result in retrieving social game from unstructured lab recorded footage of child s play and identifying social interaction in a dataset of approximately hour of home movie 
in this paper we consider the problem of categorizing video of dynamic texture under varying view point we propose to model each video with a collection of linear dynamic system ldss describing the dynamic of spatiotemporal video patch this bag of system bos representation is analogous to the bag of feature bof representation except that we use ldss a feature descriptor this pose several technical challenge to the bof framework most notably ldss do not live in a euclidean space hence novel method for clustering ldss and computing codewords of ldss need to be developed our framework make use of nonlinear dimensionality reduction and clustering technique combined with the martin distance for ldss for tackling these issue our experiment show that our bos approach can be used for recognizing dynamic texture in challenging scenario which could not be handled by existing dynamic texture recognition method 
in this paper we present a simple yet effective method that take advantage of the gradient information to accomplish the multi exposure image composition in both static and dynamic scene given multiple image with different exposure the proposed approach is capable of producing a pleasant tone mapped like high dynamic range hdr image by compositing them seamlessly with the guidance of gradient based quality assessment especially two novel quality measure visibility and consistency are developed based on the observation of gradient change among different exposure experiment in various static and dynamic scene are conducted to demonstrate the effectiveness of the proposed method 
in this paper we revisit local feature detector descriptor developed for d image and extend them to the more general framework of scalar field defined on d manifold we provide method and tool to detect and describe feature on surface equiped with scalar function such a photometric information this is motivated by the growing need for matching and tracking photometric surface over temporal sequence due to recent advancement in multiple camera d reconstruction we propose a d feature detector meshdog and a d feature descriptor meshhog for uniformly triangulated mesh invariant to change in rotation translation and scale the descriptor is able to capture the local geometric and or photometric property in a succinct fashion moreover the method is defined generically for any scalar function e g local curvature result with matching rigid and non rigid mesh demonstrate the interest of the proposed framework 
the conditional random field crf model using patch based classification bound with context information ha recently been widely adopted for image segmentation labeling in this paper we propose three component for improving the speed and accuracy and illustrate them on a recently developed auto context algorithm a new coding scheme for multiclass classification named data assisted output code daoc a scale space approach to make it le sensitive to geometric scale change and a region based voting scheme to make it faster and more accurate at object boundary the proposed multiclass classifier daoc is general and particularly appealing when the number of class becomes large since it need a minimal number oflog kbinary classifier for k class we show advantage of the daoc classifier over the existing algorithm on several irvine repository datasets a well a vision application combining daoc the scale space approach and the region based voting scheme for autocontext the overall algorithm is significantly faster time than the original auto context with improved accuracyover manyof the existing algorithmson the msrc and voc datasets 
object detection and tracking ha various application area including intelligent transportation system we introduce an object detection and tracking approach that combine the background subtraction algorithm and the feature tracking and grouping algorithm wefirst present an augmented background subtraction algorithm which us a low level feature tracking a a cue the resulting background subtraction cue are used to improve the feature detection and grouping result we then present a dynamic multi level feature grouping approach that can be used in real time application and also provides high quality trajectory experimental result from video clip of a challenging transportation application are presented 
content aware video image resizing is of increasing relevance to allow high quality image and video resizing to be displayed on device with different resolution in this paper we present a novel algorithm to find multiple d surface simultaneously with globally optimal solution for video image resizing our algorithm is based on graph theory and it first analyzes the video image data to define the energy value for each voxel then a d graph is constructed and the cost are assigned according to the energy value finally multiple d surface are detected by a global optimization process which can be solved via s t graph cut by removing or inserting these multiple d surface content aware video image resizing is achieved we also have proved that our algorithm can find the globally optimal solution for crossing surface problem in which several surface can cross each other the proposed method is demonstrated on a variety of video image data and compared to the state of the art in video image resizing 
we propose a principled framework to model persistent motion in dynamic scene in contrast to previous effort on object tracking and optical flow estimation that focus on local motion we primarily aim at inferring a global model of persistent and collective dynamic with this in mind we first introduce the concept of geometric flow that describes motion simultaneously over space and time and derive a vector space representation based on lie algebra we then extend it to model complex motion by combining multiple flow in a geometrically consistent manner taking advantage of the linear nature of this representation we formulate a stochastic flow model and incorporate a gaussian process to capture the spatial coherence more effectively this model lead to an efficient and robust algorithm that can integrate both point pair and frame difference in motion estimation we conducted experiment on different type of video the result clearly demonstrate that the proposed approach is effective in modeling persistent motion 
we propose a new approach for detecting low textured planar object and estimating their d pose standard matching and pose estimation technique often depend on texture and feature point they fail when there is no or only little texture available edge based approach mostly can deal with these limitation but are slow in practice when they have to search for six degree of freedom we overcome these problem by introducing the distance transform template generated by applying the distance transform to standard edge based template we obtain robustness against perspective transformation by training a classifier for various template pose in addition spatial relation between multiple contour on the template are learnt and later used for outlier removal at runtime the classifier provides the identity and a rough d pose of the distance transform template which is further refined by a modified template matching algorithm that is also based on the distance transform we qualitatively and quantitatively evaluate our approach on synthetic and real life example and demonstrate robust real time performance 
we present a method for spotting word in the wild i e in real image taken in unconstrained environment text found in the wild ha a surprising range of difficulty at one end of the spectrum optical character recognition ocr applied to scanned page of well formatted printed text is one of the most successful application of computer vision to date at the other extreme lie visual captchas text that is constructed explicitly to fool computer vision algorithm both task involve recognizing text yet one is nearly solved while the other remains extremely challenging in this work we argue that the appearance of word in the wild span this range of difficulty and propose a new word recognition approach based on state of the art method from generic object recognition in which we consider object category to be the word themselves we compare performance of leading ocr engine one open source and one proprietary with our new approach on the icdar robust reading data set and a new word spotting data set we introduce in this paper the street view text data set we show improvement of up to on the data set demonstrating the feasibility of a new approach to a seemingly old problem 
the classical approach to depth from defocus us two image taken with circular aperture of different size we show in this paper that the use of a circular aperture severely restricts the accuracy of depth from defocus we derive a criterion for evaluating a pair of aperture with respect to the precision of depth recovery this criterion is optimized using a genetic algorithm and gradient descent search to arrive at a pair of high resolution aperture the two coded aperture are found to complement each other in the scene frequency they preserve this property enables them to not only recover depth with greater fidelity but also obtain a high quality all focused image from the two captured image extensive simulation a well a experiment on a variety of scene demonstrate the benefit of using the coded aperture over conventional circular aperture 
parametric model of shape and texture such a active appearance model aams are diverse tool for deformable object appearance modeling and have found important application in both image synthesis and analysis problem among the numerous algorithm that have been proposed for aam fitting those based on the inversecompositional image alignment technique have recently received considerable attention due to their potential for high efficiency however existing fitting algorithm perform poorly when used in conjunction with model exhibiting significant appearance variation such a aams trained on multiple subject human face image we introduce two enhancement to inverse compositional aam matching algorithm in order to overcome this limitation first we propose fitting algorithm adaptation by mean of a fitting matrix adjustment and b aam mean template update second we show how prior information can be incorporated and constrain the aam fitting process the inverse compositional nature of the algorithm allows efficient implementation of these enhancement both technique substantially improve aam fitting performance a demonstrated with experiment on publicly available multiperson face datasets 
an important research area in computer vision is developing algorithm that can reconstruct the d surface of an object represented by a single d line drawing previous work on d reconstruction from single d line drawing focus on object with planar face in this paper we propose a novel approach to the reconstruction of solid object that have not only planar but also curved face our approach consists of four step identifying the curved face and planar face in a line drawing transforming the line drawing into one with straight edge only reconstructing the d wireframe of the curved object from the transformed line drawing and the original line drawing and generating the curved face with bezier patch and triangular mesh with a number of experimental result we demonstrate the ability of our approach to perform curved object reconstruction successfully 
perceiving dynamic scene of rigid body through affine projection of moving d point cloud boil down to clustering the rigid motion subspace supported by the point image trajectory for a physically meaningful interpretation cluster must be consistent with the geometry of the underlying subspace most of the existing measure for subspace clustering are ambiguous or geometrically inconsistent a practical consequence is that method based on such dis similarity are unstable when the number of rigid body increase this paper introduces the normalized subspace inclusion nsi criterion to resolve these issue relying on this similarity we propose a robust methodology for rigid motion segmentation and test it extensively on the hopkins database the geometric consistency of the nsi assures the method s accuracy when the number of rigid body increase while robustness prof to be suitable for dealing with challenging imaging condition 
we present a novel approach to address the representation issue and the matching issue in face recognition verification firstly our approach encodes the micro structure of the face by a new learning based encoding method unlike many previous manually designed encoding method e g lbp or sift we use unsupervised learning technique to learn an encoder from the training example which can automatically achieve very good tradeoff between discriminative power and invariance then we apply pca to get a compact face descriptor we find that a simple normalization mechanism after pca can further improve the discriminative ability of the descriptor the resulting face representation learning based le descriptor is compact highly discriminative and easy to extract to handle the large pose variation in real life scenario we propose a pose adaptive matching method that us pose specific classifier to deal with different pose combination e g frontal v s frontal frontal v s left of the matching face pair our approach is comparable with the state of the artmethodson the labeled face in wild lfw benchmark we achieved recognition rate while maintaining excellent compactness simplicity and generalization ability across different datasets 
we propose a multi object multi camera framework for tracking large number of tightly spaced object that rapidly move in three dimension we formulate the problem of finding correspondence across multiple view a a multidimensional assignment problem and use a greedy randomized adaptive search procedure to solve this np hard problem efficiently to account for occlusion we relax the one to one constraint that one measurement corresponds to one object and iteratively solve the relaxed assignment problem after correspondence are established object trajectory are estimated by stereoscopic reconstruction using an epipolar neighborhood search we embedded our method into a tracker to tracker multi view fusion system that not only obtains the three dimensional trajectory of closely moving object but also accurately settle track uncertainty that could not be resolved from single view due to occlusion we conducted experiment to validate our greedy assignment procedure and our technique to recover from occlusion we successfully track hundred of flying bat and provide an analysis of their group behavior based on reconstructed d trajectory 
while there is a large class of multiple target tracking mtt problem for which batch processing is possible and desirable batch mtt remains relatively unexplored in comparison to sequential approach in this paper we give a principled probabilistic formalization of batch mtt in which we introduce two new very general constraint that considerably help u in reaching the correct solution first we exploit the correlation between the appearance of a target and it motion second entrance and departure of target are encouraged to occur at the boundary of the scene we show how to implement these constraint in a formal and efficient manner our approach is applied to challenging d biomedical imaging data where the number of target is unknown and may vary and numerous challenging tracking event occur we demonstrate the ability of our model to simultaneously track the nucleus of over one hundred migrating neuron precursor cell in image stack series collected from a photon microscope 
this paper present a novel integrated background model for video surveillance our model us a primal sketch representation for image appearance and d scene geometry to capture the ground plane and major surface in the scene the primal sketch model divide the background image into three type of region flat sketchable and textured the three type of region are modeled respectively by mixture of gaussians image primitive and lbp histogram we calibrate the camera and recover important plane such a ground horizontal surface wall stair in the d scene and use geometric information to predict the size and location of foreground blob to further reduce false alarm compared with the state of theart background modeling method our approach is more effective especially for indoor scene where shadow highlight and reflection of moving object and camera exposure adjusting usually cause problem experiment result demonstrate that our approach improves the performance of background foreground separation at pixel level and the integrated video surveillance system at the object and trajectory level 
this paper deal with shading and aams shading is created by lighting change it can be of two type selfshading and external shading the effect of self shading can be explicitly learned and handled by aams this is not however possible for external shading which is usually dealt with by robustifying the cost function we take a different approach we measure the fitting cost in a so called light invariant space this approach naturally handle self shading and external shading the framework is based on mild assumption on the scene reflectance and the camera some photometric camera response parameter are required we propose to estimate these while fitting an existing color aam in a photometric self calibration manner we report successful result with a face aam with test image taken indoor under simple lighting change 
we present a new approachto the mattingproblem which split the task into two step interactive trimap extraction followed by trimap based alpha matting by doing so we gain considerably in term of speed and quality and are able to deal with high resolution image this paper ha three contribution i a new trimap segmentation method using parametric max flow ii an alpha matting technique for high resolution image with a new gradient preserving prior on alpha iii a database of ground truth alpha matte of still object which is considerably larger than previous database and also of higher quality the database is used to train our system and to validate that both our trimap extraction and our matting method improve on state of the art technique 
removing image partial blur is of great practical importance however a existing recovery technique usually assume a one layer clear image model they can not characterize the actual generation process of partial blur in this paper a two layer image model is investigated based on the study of partial blur generation process a novel recovery technique is proposed for a single input image both foreground and background layer are recovered simultaneously with the help of the matting technique powerful image prior model and user assistance the effectiveness of the proposed approach is demonstrated by extensive experiment on image recovery and synthesis on real data 
figure top ranked image for the query eiffel tower using a a text based image search engine and b our model ordered left to right abstract web image search using text query ha received considerable attention however current state of the art approach require training model for every new query and are therefore unsuitable for real world web search application the key contribution of this paper is to introduce generic classifier that are based on query relative feature which can be used for new query without additional training they combine textual feature based on the occurence of query term in web page and image meta data and visual histogram representation of image the second contribution of the paper is a new database for the evaluation of web image search algorithm it includes image returned by a web search engine for different search query along with their meta data and ground truth annotation using this data set we compared the image ranking performance of our model with that of the search engine and with an approach that learns a separate classifier for each query our generic model that use query relative feature improve significantly over the raw search engine ranking and also outperform the query specific model 
we study the cosegmentation problem where the objective is to segment the same object i e region from a pair of image the segmentation for each image can be cast using a partitioning segmentation function with an additional constraint that seek to make the histogram of the segmented region based on intensity and texture feature similar using markov random field mrf energy term for the simultaneous segmentation of the image together with histogram consistency requirement using the squared l rather than l distance after linearization and adjustment yield an optimization model with some interesting combinatorial property we discus these property which are closely related to certain relaxation strategy recently introduced in computer vision finally we show experimental result of the proposed approach 
variation due to viewpoint is one of the key challenge that stand in the way of a complete solution to the face recognition problem it is easy to note that local region of the face change differently in appearance a the viewpoint varies recently patch based approach such a those of kanade and yamada have taken advantage of this effect resulting in improved viewpoint invariant face recognition in this paper we propose a data driven extension to their approach in which we not only model how a face patch varies in appearance but also how it deforms spatially a the viewpoint varies we propose a novel alignment strategy which we refer to a stack flow that discovers viewpoint induced spatial deformity undergone by a face at the patch level one can then view the spatial deformation of a patch a the correspondence of that patch between two viewpoint we present improved identification and verification result to demonstrate the utility of our technique 
we propose a novel approachfor improving level set segmentation method by embedding the potential function from a discriminatively trained conditional random field crf into a level set energy function the crf term can be efficiently estimated and lead to both discriminative local potential and edge regularizers that take into account interaction among the label unlike discrete crfs the use of a continuous level set framework allows the natural use of flexible continuousregularizers such a shape prior we show promising experimental result for the method on two difficult medical image segmentation task 
this paper describes a method for finding wide baseline correspondence between image at location along gradient edge we find edge in scale space using established method and develop invariant descriptor for these edge based on orientation and scale histogram because edge are often found on occluding boundary we calculate and store two descriptor per edge one on each side for robustness to occlusion we demonstrate the effectiveness of edge matching in the application of wide baseline correspondence structure from motion from line segment and object category recognition on the caltech dataset 
in computer vision the bag of visual word image representation ha been shown to yield good result recent work ha shown that modeling the spatial relationship between visual word further improves performance previous work extract higher order spatial feature exhaustively however these spatial feature are expensive to compute we propose a novel method that simultaneously performs feature selection and feature extraction higher order spatial feature are progressively extracted based on selected lower order one thereby avoiding exhaustive computation the method can be based on any additive feature selection algorithm such a boosting experimental result show that the method is computationally much more efficient than previous approach without sacrificing accuracy 
this paper focus on the task of recovering the neutral d face of a person when given his her d face model with facial expression we propose a learning based expression removal framework to tackle this task our basic idea is to model expression residue from sample and then use the inferred expression residue from the input expressional face model to recover the neutral one a two step non rigid alignment method is introduced to make all the face model topologically share a common structure then we construct two space normal space and expression residue space for modeling expression therefore the expression removal problem can be formalized a the inference of expression residue from normal space the neutral face model can be generated in a poisson based framework by the inferred expression residue the experimental result on bu dfed database demonstrate the effectiveness of our approach 
we address the problem of tracking and recognizing face in real world noisy video we track face using a tracker that adaptively build a target model reflecting change in appearance typical of a video setting however adaptive appearance tracker often suffer from drift a gradual adaptation of the tracker to non target to alleviate this problem our tracker introduces visual constraint using a combination of generative and discriminative model in a particle filtering framework the generative term conforms the particle to the space of generic face pose while the discriminative one ensures rejection of poorly aligned target this lead to a tracker that significantly improves robustness against abrupt appearance change and occlusion critical for the subsequent recognition phase identity of the tracked subject is established by fusing pose discriminant and person discriminant feature over the duration of a video sequence this lead to a robust video based face recognizer with state of the art recognition performance we test the quality of tracking and face recognition on real world noisy video from youtube a well a the standard honda ucsd database our approach produce successful face tracking result on over of all video without video or person specific parameter tuning the good tracking performance induces similarly high recognition rate on honda ucsd and over on the youtube set containing celebrity in sequence 
a multiclass classification problem can be reduced to a collection of binary problem using an error correcting coding matrix that specifies the binary partition of the class the final classifier is an ensemble of base classifier learned on binary problem and it performance is affected by two major factor the quality of the base classifier and the coding matrix previous study either focus on one of these factor or consider two factor separately in this paper we propose a new multiclass boosting algorithm called adaboost sip that considers both two factor simultaneously in this algorithm informative pattern which are shareable by different class rather than only discriminative on specific single class are generated at first then the binary partition preferred by each pattern is found by performing stage wise functional gradient descent on a margin based cost function finally base classifier and coding matrix are optimized simultaneously by maximizing the negative gradient of such cost function the proposed algorithm is applied to scene and event recognition and experimental result show it effectiveness in multiclass classification 
we present a motion estimation algorithm for multicamera system consisting of more than one calibrated camerasecurely attachedon a movingobject so theymove all together but do not require to have overlapping view across the camera the geometrically optimal solution of the motion for the multi camera system under l norm is providedin thispaperusinga globaloptimizationtechnique which ha been introduced recently in the computer vision research field taking advantage of an optimal estimate of the essential matrix through searching rotation space we provide the optimal solution for translation by using linear programming and branch bound algorithm synthetic and real data experiment are conducted and they show more robust and improved performance than the previous method 
we present a new approach for the discriminative training of continuous valued markov random field mrf model parameter in our approach we train the mrf model by optimizing the parameter so that the minimum energy solution of the model is a similar a possible to the ground truth this lead to parameter which are directly optimized to increase the quality of the map estimate during inference our proposed technique allows u to develop a framework that is flexible and intuitively easy to understand and implement which make it an attractive alternative to learn the parameter of a continuous valued mrf model we demonstrate the effectiveness of our technique by applying it to the problem of image denoising and inpainting using the field of expert model in our experiment the performance of our system compare favourably to the field of expert model trained using contrastive divergenc e when applied to the denoising and inpainting task 
graph partitioning active contour gpac is a recently introduced approach that elegantly embeds the graph based image segmentation problem within a continuous optimization framework gpac can be used within parametric snake based or implicit level set based active contour continuous paradigm for image partitioning however gpac similar to many other graph based approach ha quadratic memory requirement which severely limit the scalability of the algorithm to practical problem domain an n xn image requires o n computation and memory to create and store the full graph of pixel inter relationship even before the start of the contour optimization process for example an x grayscale image need over one terabyte of memory approximation using tile block based or superpixel based multiscale grouping of the pixel reduces this complexity by trading off accuracy this paper describes a new algorithm that implement the exact gpac algorithm using a constant memory requirement of a few kilobyte independent of image size 
categorizing web based video is an important yet challenging task the difficulty arise from large data diversity within a category lack of labeled data and degradation of video quality this paper present a large scale video taxonomic classification scheme with more than category tackling these issue taxonomic structure of category is deployed in classifier training to compensate for the lack of labeled video data a novel method is proposed to adapt the web text document trained classifier to video domain so that the availability of a large corpus of labeled text document can be leveraged video content based feature are integrated with text based feature to gain power in the case of degradation of one type of feature evaluation on video from hundred of category show that the proposed algorithm generate significant performance improvement over text classifier or classifier trained using only video content based feature 
we propose a new method to partition an unlabeled dataset called discriminative context partitioning dcp it is motivated by the idea of splitting the dataset based only on how well the resulting part can be separated from a context class of disjoint data point this is in contrast to typical clustering technique like k mean that are based on a generative model by implicitly or explicitly searching for mode in the distribution of sample the discriminative criterion in dcp avoids the problem that density based method have when the a priori assumption of multimodality is violated when the number of sample becomes small in relation to the dimensionality of the feature space or if the cluster size are strongly unbalanced we formulate dcp s separation property a a large margin criterion and show how the resulting optimization problem can be solved efficiently experiment on the mnist and usps datasets of handwritten digit and on a subset of the caltech dataset show that given a suitable context dcp can achieve good result even in situation where density based clustering technique fail 
this paper address the problem of learning archetypal structural model from example this is done by providing a generative model for graph where the distribution of observed node and edge is governed by a set of independent bernoulli trial with parameter to be estimated however the correspondence between sample node and model node is not known and must be estimated from local structure the parameter are estimated maximizing the likelihoodoftheobservedgraphs marginalizingit overallpossible node correspondence this is done adopting an importance sampling approach to limit the exponential explosion of the set of correspondence the approach is used to summarize the variation in two different structural abstraction of shape delaunay graph over a set of image feature and shock graph the experiment show that the approach can be used to recognize structure belonging to a same class 
we present a completely automated structure and motion pipeline capable of working with uncalibrated image with varying internal parameter and no ancillary information the system is based on a novel hierarchical scheme which reduces the total complexity by one order of magnitude we ass the quality of our approach analytically by comparing the recovered point cloud with laser scan which serf a ground truth data 
given a set of algorithm which one s should you apply to i compute optical flow or ii perform feature matching would looking at the sequence in question help you decide it is unclear if even a person with intimate knowledge of all the different algorithm and access to the sequence itself could predict which one to apply our hypothesis is that the most suitable algorithm can be chosen for each video automatically through supervised training of a classifier the classifier treat the different algorithm a black box alternative class and predicts when each is best because of their respective performance on training example where ground truth flow wa available our experiment show that a simple random forest classifier is predictive of algorithm suitability the automatic feature selection make use of both our spatial and temporal video feature we find that algorithm suitability can be determined per pixel capitalizing on the heterogeneity of appearance and motion within a video we demonstrate our learned region segmentation approach quantitatively using four available flow algorithm on both known and novel image sequence with ground truth flow we achieve performance that often even surpasses that of the one best algorithm at our disposal 
this paper present a simple yet practical d modeling method for recovering surface shape and reflectance from a set of image we attach a point light source to a hand held camera to add a photometric constraint to the multi view stereo problem using the photometric constraint we simultaneously solve for shape surface normal and reflectance unlike prior approach we formulate the problem using realistic assumption of a near light source non lambertian surface perspective camera model and the presence of ambient lighting the effectiveness of the proposed method is verified using simulated and real world scene 
multi modal image registration is a challenging problem in medical imaging the goal is to align anatomically identical structure however their appearance in image acquired with different imaging device such a ct or mr may be very different registration algorithm generally deform one image the floating image such that it match with a second the reference image by maximizing some similarity score between the deformed and the reference image instead of using a universal but a priori fixed similarity criterion such a mutual information we propose learning a similarity measure in a discriminative manner such that the reference and correctly deformed floating image receive high similarity score to this end we develop an algorithm derived from max margin structured output learning and employ the learned similarity measure within a standard rigid registration algorithm compared to other approach our method adapts to the specific registration problem at hand and exploit correlation between neighboring pixel in the reference and the floating image empirical evaluation on ct mr pet mr rigid registration task demonstrates that our approach yield robust performance and outperforms the state of the art method for multi modal medical image registration 
we present an imaging framework to acquire d surface scan at ultra high resolution exceeding sample per mm our approach couple a standard structured light setup and photometric stereo using a large format ultra high resolution camera while previous approach have employed similar hybrid imaging system to fuse positional data with surface normal what is unique to our approach is the significant asymmetry in the resolution between the low resolution geometry and the ultra high resolution surface normal to deal with these resolution difference we propose a multi resolution surface reconstruction scheme that propagates the low resolution geometric constraint through the different frequency band while gradually fusing in the high resolution photometric stereo data in addition to deal with the ultra high resolution image our surface reconstruction is performed in a patch wise fashion and additional boundary constraint are used to ensure patch coherence based on this multi resolution reconstruction scheme our imaging framework can produce d scan that show exceptionally detailed d surface far exceeding existing technology 
the phenomenon of visual curve completion where the visual system completes the missing part e g due to occlusion between two contour fragment is a major problem in perceptual organization research previous computational approach for the shape of the completed curve typically follow formal description of desired image based perceptual property e g minimum total curvature roundedness etc unfortunately however it is difficult to determine such desired property psychophysically and indeed there is no consensus in the literature for what they should be instead in this paper we suggest to exploit the fact that curve completion occurs in early vision in order to formalize the problem in a space that explicitly abstract the primary visual cortex we first argue that a suitable abstraction is the unit tangent bundle r s and then we show that a basic principle of minimum energy consumption in this space namely a minimum length completion entail desired perceptual property for the completion in the image plane we present formal theoretical analysis and numerical solution method we show result on natural image and their advantage over existing popular approach and we discus how our theory explains recent finding from the perceptual literature using basic principle only 
this paper describes a discriminatively trained multiscale deformable part model for object detection our system achieves a two fold improvement in average precision over the best performance in the pascal person detection challenge it also outperforms the best result in the challenge in ten out of twenty category the system relies heavily on deformable part while deformable part model have become quite popular their value had not been demonstrated on difficult benchmark such a the pascal challenge our system also relies heavily on new method for discriminative training we combine a margin sensitive approach for data mining hard negative example with a formalism we calllatent svm a latent svm like a hidden crf lead to a non convex training problem however a latent svm is semi convex and the training problem becomes convex once latent information is specified for the positive example we believe that our training method will eventually make possible the effective use of more latent information such a hierarchical grammar model and model involving latent three dimensional pose 
even if the class label information is unknown side information represents some equivalence constraint between pair of pattern indicating whether pair originate from the same class exploiting side information we develop algorithm to preserve both the intra class and inter class local structure this new type of locality preserving projection lpp called lpp with side information lppsi preserve the data s local structure in the sense that the close similar training pattern will be kept close whilst the close but dissimilar one are separated our algorithm balance these conflicting requirement and we further improve this technique using kernel method experiment conducted on popular face database demonstrate that the proposed algorithm significantly outperforms lpp further we show that the performance of our algorithm with partial side information that is using only small amount of pair wise similarity dissimilarity information during training is comparable with that when using full side information we conclude that exploiting side information by preserving both similar and dissimilar local structure of the data significantly improves performance 
effective reduction of noise is generally difficult because of the possible tight coupling of noise with high frequency image structure the problem is worse under low light condition in this paper we propose slightly optically defocusing the image in order to loosen this noise image structure coupling this allows u to more effectively reduce noise and subsequently restore the small defocus we analytically show how this is possible and demonstrate our technique on a number of example that include low light image 
we present an approach to visual tracking based on dividing a target into multiple region or fragment the target is represented by a gaussian mixture model in a joint feature spatial space with each ellipsoid correspo nding to a different fragment the fragment are automatically adapted to the image data being selected by an efficient region growing procedure and updated according to a weighted average of the past and present image statistic modeling of target and background are performed in a chan vese manner using the framework of level set to preserve accurate boundary of the target the extracted target boundary are used to learn the dynamic shape of the target over time enabling tracking to continue under total occlusion experimental result on a number of challenging sequence demonstrate the effectiveness of the technique 
this paper present an approach to unsupervised segmentation of moving and static object occurring in a video object are in general spatially cohesive and characterized by locally smooth motion trajectory therefore the y occupy region within each frame the shape and location of these region vary slowly from frame to frame thus video segmentation can be done by tracking region across the frame such that the resulting track are locally smooth to this end we use a low level segmentation to extract region in all frame then similar region are transitively matched and clustered across the video region similarity i s defined with respect to geometric and motion property of region contour to match region contour we formulate a new circular dynamic time warping cdtw algorithm that generalizes dtw to closed contour without compromising the optimality and low complexity of dtw our quantitative evaluation and comparison with the state of the art suggest that the proposed approach is a competitive alternative to currently prevailing point based method 
in this paper we present a new framework of video object segmentation in which we formulate the task of extracting prominent object from a scene a the problem of hypergraph cut we initially over segment each frame in the sequence and take the over segmented image patch a the vertex in the graph different from the traditional pairwise graph structure we build a novel graph structure hypergraph to represent the complex spatio temporal neighborhood relationship among the patch we assign each patch with several attribute that are computed from the optical flow and the appearance based motion profile and the vertex with the same attribute value is connected by a hyperedge through all the hyperedges not only the complex non pairwise relationship between the patch are de scribed but also their merit are integrated together orga nically the task of video object segmentation is equivalent to the hypergraph partition which can be solved by the hypergraph cut algorithm the effectiveness of the proposed method is demonstrated by extensive experiment on nature scene 
graph matching is an important problem in computer vision it is used in d and d object matching and recognition despite it importance there is little literature on learning the parameter that control the graph matching problem even though learning is important for improving the matching rate a shown by this and other work in this paper we show for the first time how to perform parameter learning in an unsupervised fashion that is when no correct correspondence between graph are given during training we show empirically that unsupervised learning is comparable in efficiency and quality with the supervised one while avoiding the tedious manual labeling of ground truth correspondence we also verify experimentally that this learning method can improve the performance of several state of the art graph matching algorithm 
a more image and category become available organizing them becomes crucial we present a novel statistical method for organizing a collection of image into a treeshaped hierarchy the method employ a non parametric bayesian model and is completely unsupervised each image is associated with a path through a tree similar image share initial segment of their path and therefore have a smaller distance from each other each internal node in the hierarchy represents information that is common to image whose path pas through that node thus providing a compact image representation our experiment show that a disorganized collection of image will be organized into an intuitive taxonomy furthermore we find that the taxonomy allows good image categorization and in this respect is superior to the popular lda model 
linear discriminant analysis lda is one of the wellknown method for supervised dimensionality reduction over the year many lda based algorithm have been developed to cope with the curse of dimensionality in essence most of these algorithm employ various technique to deal with the singularity problem which occurs when the data dimensionality is larger than the sample size they have been applied successfully in various application however there is a lack of a systematic study of the commonality and difference of these algorithm a well a their intrinsic relationship in this paper a unified framework for generalized lda is proposed via a transfer function the proposed framework elucidates the property of various algorithm and their relationship based on the presented analysis we propose an efficient model selection algorithm for lda we conduct extensive experiment using a collection of high dimensional data including text document face image gene expression data and gene expression pattern image to evaluate the proposed theory and algorithm 
we present an integrated model for visual object localization and continuous state estimation in a discriminative structured prediction framework while existing discriminative prediction through time method have showed remarkable versatility for visual reconstruction and tracking problem they tend to assume that the input is known or the object is segmented a condition that can rarely be accommodated in image of real scene our structural support vector machine structsvm framework offer an end to end training and inference framework that overcomes these limitation by consistently searching both in the space of possible input effectively an efficient form of object localization and in the space of possible structured output given those input we demonstrate the potential of this methodology for d human pose reconstruction in monocular image both in the humaneva benchmark where d ground truth is available and qualitatively in un instrumented image of real scene 
we address the problem of computing joint sparse representation of visual signal across multiple kernel based representation such a problem arises naturally in supervised visual recognition application where one aim to reconstruct a test sample with multiple feature from a few training subject a possible we cast the linear version of this problem into a multi task joint covariate selection model which can be very efficiently optimized via ker nelizable accelerated proximal gradient method furthermore two kernel view extension of this method are provided to handle the situation where descriptor and similarity function are in the form of kernel matrix we then investigate into two application of our algorithm to feature combination fusing gray level and lbp feature for face recognition and combining multiple kernel for object categorization experimental result on challenging real world datasets show that the feature combination capability of our proposed algorithm is competitive to the state of the art multiple kernel learning method 
we propose a novel consistent max covering scheme for human pose estimation consistent max covering formulates pose estimation a the covering of body part polygon on an object silhouette so that the body part tile maximally cover the foreground match local image feature and satisfy body linkage plan and color constraint it us high order constraint to anchor multiple body part simultaneously the hyper edge in the part relation graph are essential for detecting complex pose because of using multiple clue in pose estimation this method is resistant to cluttered foreground we propose an efficient linear relaxation method to solve the consistent max covering problem experiment on a variety of image and video show that the proposed method is more robust than locally constrained method for human pose estimation 
the position of a world point s solar shadow depends on it geographical location the geometrical relationship between the orientation of the sunshine and the ground plane where the shadow cast this paper investigates the property of solar shadow trajectory on a planar surface and show that camera parameter latitude longitude can be estimated from two observed shadow trajectory our contribution is that we use the design of the analemmatic sundial to get the shadow conic and furthermore recover the camera s geographical location the proposed method doe not require the shadow casting object or a vertical object to be visible in the recovery of camera calibration this approach is thoroughly validated on both synthetic and real data and tested against various source of error including noise and number of observation 
in this paper we present a new minimal solver for the relative pose of a calibrated stereo camera it is based on the observation that a feature visible in all camera constrains the relative pose of the second stereo camera to be on a sphere around the feature which ha a known position relative to the first stereo camera pose due to it triangulation the constraint leaf three degree of freedom two for the location of the second camera on the sphere and the third for rotation in the plane tangent to the sphere we use three temporal d correspondence two correspondence from the left or right camera and one correspondence from the other camera to solve for these three remaining degree of freedom this approach is amenable to stereo pair having a small overlap in their view we present an efficient solution of this novel relative pose problem theoretically derive how to use our new solver with two class of measurement in ransac evaluate it performance given noise and outlier and demonstrate it use in a real time structure from motion system in this paper we present a new minimal solver for use in stereo camera based structure from motion sfm or visual simultaneous localization and mapping vslam one popular application would be vslam for a humanoid robot our approach is analogous to human vision where both eye overlap in only part of the total viewing frustum excluding prior model human posse such a relative size of object expected relative position expected ego motion etc depth could be perceived from the region of overlap between our eye while rotation is derived from both overlapping and non overlapping region this configuration of eye or camera provides a large total field of view of the two camera while at the same time allowing the scale to be fixed based on triangulation in the camera s region of overlap this give the best of what a two camera system can deliver a wide field of view for accurate rotation estimation with an absolutely scaled translation measurement 
many segmentation problem in medical imaging rely on accurate modeling and estimation of tissue intensity probability density function gaussian mixture modeling currently the most common approach ha several drawback such a reliance on a specific model and iterative optimization it also doe not take advantage of substantially larger amount of data provided by d acquisition which are becoming standard in clinical environment we propose a novel completely non parametric algorithm to estimate the tissue intensity probability in d image instead of relying on traditional framework of iterating between classification and estimation we pose the problem a an instance of a blind source separation problem where the unknown distribution are treated a source and histogram of image subvolumes a mixture the new approach performed well on synthetic data and real magnetic resonance mr scan robustly capturing intensity distribution of even small image structure and partial volume voxels 
tracking people in a dense crowd is a challenging problem for a single camera tracker due to occlusion and extensive motion that make human segmentation difficult in this paper we suggest a method for simultaneously tracking all the people in a densely crowded scene using a set of camera with overlapping field of view to overcome occlusion the camera are placed at a high elevation and only people s head are tracked head detection is still difficult since each foreground region may consist of multiple subject by combining data from several view height information is extracted and used for head segmentation the head top which are regarded a d patch at various height are detected by applying intensity correlation to aligned frame from the different camera the detected head top are then tracked using common assumption on motion direction and velocity the method wa tested on sequence in indoor and outdoor environment under challenging illumination condition it wa successful in tracking up to people walking in a small area people per m in spite of severe and persistent occlusion 
this paper present a new photometric stereo method aiming to efficiently estimate brdf and reconstruct glossy surface rough specular surface exhibit wide specular lobe under different lightning they are ubiquitous and usually bring difficulty to both specular pixel removal and surface normal recovery in our approach we do not apply unreliable highlight separation and specularity estimation instead an important visual cue i e the cast shadow silhouette of the object is employed to optimally recover global brdf parameter these parameter estimate are then taken into a reflectance model for robustly computing the surface normal and other local parameter using an iterative optimization within the unified framework our method can also be used to reconstruct object surface assembled with multiple material 
graph cut is a popular technique for interactive image segmentation however it ha certain shortcoming in particular graph cut ha problem with segmenting thin elongated object due to the ldquoshrinking biasrdquo to overcome this problem we propose to impose an additional connectivity prior which is a very natural assumption about object we formulate several version of the connectivity constraint and show that the corresponding optimization problem are all np hard for some of these version we propose two optimization algorithm i a practical heuristic technique which we call dijkstragc and ii a slow method based on problem decomposition which provides a lower bound on the problem we use the second technique to verify that for some practical example dijkstragc is able to find the global minimum 
given two shape the correspondence between distinct visual feature is the basisformost alignment process and shape similarity measure thispaperpresentsan approach introducing particle filter to establish perceptually correct correspondence between point set representing shape local shape feature descriptor are used to establish correspondence probability the global correspondence structure is calculated using additional constraint based on domain knowledge domain knowledge is characterized a prior distribution expressing hypothesis about the global relationship between shape these hypothesis are generated during the iterative particle filtering process experiment using standard alignment technique based on the given correspondence relationship demonstrate the advantage of this approach 
the robust alignment of image and scene seen from widely different viewpoint is an important challenge for camera and scene reconstruction this paper introduces a novel class of viewpoint independent local feature for robust registration and novel algorithm to use the rich information of the new feature for d scene alignment and large scale scene reconstruction the key point of our approach consists of leveraging local shape information for the extraction of an invariant feature descriptor the advantage of the novel viewpoint invariant patch vip are that the novel feature are invariant to d camera motion and that a single vip correspondence uniquely defines the d similarity transformation between two scene in the paper we demonstrate how to use the property of the vip in an efficient matching scheme for d scene alignment the algorithm is based on a hierarchical matching method which test the component of the similarity transformation sequentially to allow efficient matching and d scene alignment we evaluate the novel feature on real data with known ground truth information and show that the feature can be used to reconstruct large scale urban scene 
human action video sequence can be considered a nonlinear dynamic shape manifold in the space of image frame in this paper we address learning and classifying human action on embedded low dimensional manifold we propose a novel manifold embedding method called local spatio temporal discriminant embedding lstde the discriminating capability of the proposed method are two fold for local spatial discrimination lstde project data point silhouette based image frame of human action sequence in a local neighborhood into the embedding space where data point of the same action class are close while those of different class are far apart in such a local neighborhood each data point ha an associated short video segment which form a local temporal subspace on the embedded manifold lstde find an optimal embedding which maximizes the principal angle between those temporal subspace associated with data point of different class benefiting from the joint spatio temporal discriminant embedding our method is potentially more powerful for classifying human action with similar space time shape and is able to perform recognition on a frame by frame or short video segment basis experimental result demonstrate that our method can accurately recognize human action and can improve the recognition performance over some representative manifold embedding method especially on highly confusing human action type 
one source of difficulty when processing outdoor image is the presence of haze fog or smoke which fade the color and reduces the contrast of the observed object we introduce a novel algorithm and variant for visibility restoration from a single image the main advantage of the proposed algorithm compared with other is it speed it complexity is a linear function of the number of image pixel only this speed allows visibility restoration to be applied for the first time within real time processing application such a sign lane marking and obstacle detection from an in vehicle camera another advantage is the possibility to handle both color image or gray level image since the ambiguity between the presence of fog and the object with low color saturation is solved by assuming only small object can have color with low saturation the algorithm is controlled only by a few parameter and consists in atmospheric veil inference image restoration and smoothing tone mapping a comparative study and quantitative evaluation is proposed with a few other state of the art algorithm which demonstrates that similar or better quality result are obtained finally an application is presented to lane marking extraction in gray level image illustrating the interest of the approach 
object tracking typically relies on a dynamic model to predict the object s location from it past trajectory in crowded scenario a strong dynamic model is particularly important because more accurate prediction allow for smaller search region which greatly simplifies data association traditional dynamic model predict the location for each target solely based on it own history without taking into account the remaining scene object collision are resolved only when they happen such an approach ignores important aspect of human behavior people are driven by their future destination take into account their environment anticipate collision and adjust their trajectory at an early stage in order to avoid them in this work we introduce a model of dynamic social behavior inspired by model developed for crowd simulation the model is trained with video recorded from bird eye view at busy location and applied a a motion model for multi people tracking from a vehicle mounted camera experiment on real sequence show that accounting for social interaction and scene knowledge improves tracking performance especially during occlusion 
contemporary face recognition algorithm rely on precise localization of keypoints corner of eye nose etc unfortunately finding keypoints reliably and accurately remains a hard problem in this paper we pose two question first is it possible to exploit the gallery image in order to find keypoints in the probe image for instance consider finding the left eye in the probe image rather than using a generic eye model we use a model that is informed by the appearance of the eye in the gallery image to this end we develop a probabilistic model which combine recognition and keypoint localization second is it necessary to localize keypoints alternatively we can consider keypoint position a a hidden variable which we marginalize over in a bayesian manner we demonstrate that both of these innovation improve performance relative to conventional method in both frontal and cross pose face recognition 
this paper present a novel descriptor for human detection in video sequence it is referred to a spatial temporal granularity tunable gradient partition stggp which is an extension of granularity tunable gradient partition ggp from the still image domain to the spatial temporal domain specifically the moving human body is considered a a dimensional entity in the spatial temporal domain then in d hough space we define the generalized plane a a primitive to parse the structure of this d entity the advantage of the generalized plane is that it can tolerate imperfect plane with certain level of uncertainty in rotation and translation the robustness to the uncertainty is controlled quantitatively by the granularity parameter defined explicitly in the generalized plane this property endows the stggp descriptor versatile ability to represent both the deterministic structure and the statistical summarization of the object moreover the stggp descriptor encodes much heterogeneous information such a the gradient strength position and distribution a well a their temporal motion to enrich it representation ability we evaluate the stggp on human detection in sequence on the public datasets and very promising result have been achieved 
spatiotemoral stereo is concerned with the recovery of the d structure of a dynamic scene from a temporal sequence of multiview image this paper present a novel method for computing temporally coherent disparity map from a sequence of binocular image through an integrated consideration of image spacetime structure and without explicit recovery of motion the approach is based on matching spatiotemporal quadric element stequels between view a it is shown that this matching primitive provides a natural way to encapsulate both local spatial and temporal structure for disparity estimation empirical evaluation with laboratory based imagery with ground truth and more typical natural imagery show that the approach provides considerable benefit in comparison to alternative method for enforcing temporal coherence in disparity estimation 
visual and non visual data are often related through complex indirect link thus making the prediction of one from the other difficult example include the partiallyunderstood connection between firing of v neuron and visual stimulus the coupling between recorded speech and video of the corresponding lip movement and the attempt to infer criminal intention from surveillance video in this study we explore the exploitation of the visual non visual relation between genetic sequence and visual appearance this exploitation is currently considered infeasible due to the many hidden variable and unknown factor involved the considerable variability and noise that exist in image and the high dimensionality of the data despite the difficulty we show convincing evidence that the application of correlation between genotype and visual phenotype for identification is feasible with current technology to this end we employ sensitive forcedmatching test that can accurately detect correlation between data set these test are used to compare the performance of several existing algorithm a well a novel one that we have designed for the task 
object localization in an image is usually handled by searching for an optimal subwindow that tightly cover the object of interest however the subwindows considered in previous work are limited to rectangle or other specified simple shape with such specified shape no subwindow can cover the object of interest tightly a a result the desired subwindow around the object of interest may not be optimal in term of the localization objective function and cannot be detected by a subwindow search algorithm in this paper we propose a new graph theoretic approach for object localization by searching for an optimal subwindow without pre specifying it shape instead we require the resulting subwindow to be well aligned with edge pixel that are detected from the image this requirement is quantified and integrated into the localization objective function based on the widely used bag of visual word technique we show that the ratio contour graph algorithm can be adapted to find the optimal free shape subwindow in term of the new localization objective function in the experiment we test the proposed approach on the pascal voc and voc database for localizing several category of animal we find that it performance is better than the previous efficient subwindow search algorithm 
a new approach to align an image of a textured object with a given prototype learned reference object is proposed visual appearance of the image after equalizing their signal is modeled with a markov gibbs random field with pairwise interaction similarity to the prototype learned reference object is measured by a gibbs energy of signal co occurrence in a characteristic subset of pixel pair derived automatically from the prototype an object is aligned by an affine transformation maximizing the similarity by using an automatic initialization followed by gradient search to get accurate appearance model we developed a new approach to automatically select the most important clique neighborhood system that describe the visual appearance of a texture object experiment confirm that our approach aligns complex object better than popular conventional algorithm 
abstract this paper proposes a novel descriptor granularitytunable gradient partition ggp for human detection the concept granularity is used to define the spatial and angular uncertainty of the line segment in the hough space then this uncertainty is backprojected into the image space by orientation space partitioning to achieve efficient implementation by changing the granularity parameter the level of uncertainty can be controlled quantitatively therefore a family of descriptor with versatile representation property can be generated specifically the finely granular ggp descriptor can represent the specific geometry information of the object the same a edgelet while the coarsely granular ggp descriptor can provide the statistical representation of the object the same a histogram of oriented gradient hog moreover the position orientation strength and distribution of the gradient are embedded into a unified descriptor to further improve the ggp s representation power a cascade structured classifier is built by boosting the linear regression function experimental result on inria dataset show that the proposed method achieves comparable result to those of the state of the art method 
this paper present a new method to extract tubular structure from bi dimensional image the core of the proposed algorithm is the computation of geodesic curve over a four dimensional space that includes local orientation and scale these shortest path follow closely the centerline of tubular structure provide an estimation of the radius and can deal robustly with crossing over the image plane numerical experiment on a database of synthetic and natural image show the superiority of the proposed approach with respect to several method based on shortest path extraction 
given a single image of an arbitrary road that may not be well paved or have clearly delineated edge or some a priori known color or texture distribution is it possible for a computer to find this road this paper address this question by decomposing the road detection process into two step the estimation of the vanishing point associated with the main straight part of the road followed by the segmentation of the corresponding road area based on the detected vanishing point the main technical contribution of the proposed approach are a novel adaptive soft voting scheme based on variable sized voting region using confidence weighted gabor filter which compute the dominant texture orientation at each pixel and a new vanishing point constrained edge detection technique for detecting road boundary the proposed method ha been implemented and experiment with general road image demonstrate that it is both computationally efficient and effective at detecting road region in challenging condition 
we propose a method for estimating camera response function using a probabilistic intensity similarity measure the similarity measure represents the likelihood of two intensity observation corresponding to the same scene radiance in the presence of noise we show that the response function and the intensity similarity measure are strongly related our method requires several input image of a static scene taken from the same viewing position with fixed camera parameter noise cause pixel value at the same pixel coordinate to vary in these image even though they measure the same scene radiance we use these fluctuation to estimate the response function by maximizing the intensity similarity function for all pixel unlike prior noise based estimation method our method requires only a small number of image so it work with digital camera a well a video camera moreover our method doe not rely on any special image processing or statistical prior model real world experiment using different camera demonstrate the effectiveness of the technique 
this paper present a collaborative benchmark for region of interest roi detection in image roi detection ha many useful application and many algorithm have been proposed to automatically detect roi unfortunately due to the lack of benchmark these method were often tested on small data set that are not available to others making fair comparison of these method difficult example from many field have shown that repeatable experiment using published benchmark are crucial to the fast advancement of the field to fill the gap this paper present our design for a collaborative game called photoshoot to collect human roi annotation for constructing an roi benchmark using this game we have gathered a large number of annotation and fused them into aggregated roi model with these model we are able to evaluate six roi detection algorithm quantitatively 
image classification and annotation are important problem in computer vision but rarely considered together intuitively annotation provide evidence for the class label and the class label provides evidence for annotation for example an image of class highway is more likely annotated with word road car and traffic than word fish boat and scuba in this paper we develop a new probabilistic model for jointly modeling the image it class label and it annotation our model treat the class label a a global description of the image and treat annotation term a local description of part of the image it underlying probabilistic assumption naturally integrate these two source of information we derive an approximate inference and estimation algorithm based on variational method a well a efficient approximation for classifying and annotating new image we examine the performance of our model on two real world image data set illustrating that a single model provides competitive annotation performance and superior classification performance 
in this paper we propose a new method to construct an edge preserving filter which ha very similar response to the bilateral filter the bilateral filter is a normalized convolution in which the weighting for each pixel is determined by the spatial distance from the center pixel and it relative difference in intensity range the spatial and range weighting function are typically gaussian in the literature in this paper we cast the filtering problem a a vector mapping approximation and solve it using a support vector machine svm each pixel will be represented a a feature vector comprising of the exponentiation of the pixel intensity the corresponding spatial filtered response and their product the mapping function is learned via svm regression using the feature vector and the corresponding bilateral filtered value from the training image the major computation involved is the computation of the spatial filtered response of the exponentiation of the original image which is invariant to the filter size given that an iir o solution is available for the spatial filtering kernel to our knowledge this is the first learning based o bilateral filtering method unlike previous o method our method is valid for both low and high range variance gaussian and the computational complexity is independent of the range variance value our method is also the fastest o bilateral filtering yet developed besides our method allows varying range variance value based on which we propose a new bilateral filtering method avoiding the over smoothing or under smoothing artifact in traditional bilateral filter 
recently facial trait code ftc wa proposed for solving face recognition and wa reported with promising recognition rate however several simplification in the ftc encoding make it unable to handle the most rigorous face recognition scenario in which only one facial image per individual is available for enrollment in the gallery set and the probe set includes face under variation caused by illumination expression pose or misalignment in this study we propose the probabilistic facial trait code pftc with a novel encoding scheme and a probabilistic codeword distance measure we also proposed the pattern specific subspace learning pssl scheme that encodes and recognizes face robustly under aforementioned variation the proposed pftc wa evaluated and compared with state of the art algorithm including the ftc the algorithm using sparse representation and the one using local binary pattern our experimental study considered factor such a the number of enrollment allowed in the gallery the variation among gallery or probe set and reported result for both identification and verification problem the proposed pftc yielded significant better recognition rate in most of the scenario than all the state of the art algorithm evaluated in this study 
this paper present a novel learning based tracking model combined with object detection the existing technique proceed by linearizing the motion which make an implicit euclidean space assumption most of the transformation used in computer vision have matrix lie group structure we learn the motion model on the lie algebra and show that the formulation minimizes a first order approximation to the geodesic error the learning model is extended to train a class specific tracking function which is then integrated to an existing pose dependent object detector to build a pose invariant object detection algorithm the proposed model can accurately detect object in various pose where the size of the search space is only a fraction compared to the existing object detection method the detection rate of the original detector is improved by more than for large transformation 
we use segmentation to match image by shape to address the unreliability of segmentation we give a closed form approximation to an average over all segmentation our technique ha many extension yielding new algorithm for tracking object detection segmentation and edge preserving smoothing for segmentation instead of a maximum a posteriori approach we compute the central segmentation minimizing the average distance to all segmentation of an image our method for segmentation and object detection perform competitively and we also show promising result in tracking and edge preserving smoothing 
in this work we construct scale invariant descriptor sids without requiring the estimation of image scale we thereby avoid scale selection which is often unreliable our starting point is a combination of log polar sampling and spatially varying smoothing that convert image scaling and rotation into translation scale invariance can then be guaranteed by estimating the fourier transform modulus ftm of the formed signal a the ftm is translation invariant we build our descriptor using phase orientation and amplitude feature that compactly capture the local image structure our result show that the constructed sids outperform state of the art descriptor on standard datasets a main advantageof sids is that they are applicableto a broader range of image structure such a edge for which scale selection is unreliable we demonstrate this by combining sids with contour segment and show that the performance of a boundary based model is systematically improved on an object detection task 
this paper present a solution to the problem of pose estimation in the presence of heavy radial distortion and a potentially large number of outlier the main contribution is an algorithm that solves for radial distortion focal length and camera pose using a minimal set of four point correspondence between d world point and image point we use a ransac loop to find a set of inliers and an initial estimate for bundle adjustment unlike previous approach where one start out by assuming a linear projection model our minimal solver allows u to handle large radial distortion already at the ransac stage we demonstrate that with the inclusion of radial distortion in an early stage of the process a broader variety of camera can be handled than wa previously possible in the experiment no calibration whatsoever is applied to the camera instead we assume square pixel zero skew and centered principal point although these assumption are not strictly true we show that good result are still obtained and by that conclude that the proposed method is applicable to uncalibratedphotographs 
this paper proposes a method for capturing the performance of a human or an animal from a multi view video sequence given an articulated template model and silhouette from a multi view image sequence our approach recovers not only the movement of the skeleton but also the possibly non rigid temporal deformation of the d surface while large scale deformation or fast movement are captured by the skeleton pose and approximate surface skinning true small scale deformation or non rigid garment motion are captured by fitting the surface to the silhouette we further propose a novel optimization scheme for skeleton based pose estimation that exploit the skeleton s tree structure to split the optimization problem into a local one and a lower dimensional global one we show on various sequence that our approach can capture the d motion of animal and human accurately even in the case of rapid movement and wide apparel like skirt 
mean shift clustering is a powerful unsupervised data analysis technique which doe not require prior knowledge of the number of cluster and doe not constrain the shape of the cluster the data association criterion is based on the underlying probability distribution of the data point which is defined in advance via the employed distance metric in many problem domain the initially designed distance metric fails to resolve the ambiguity in the clustering process we present a novel semi supervised kernel mean shift algorithm where the inherent structure of the data point is learned with a few user supplied constraint in addition to the original metric the constraint we consider are the pair of point that should be clustered together the data point are implicitly mapped to a higher dimensional space induced by the kernel function where the constraint can be effectively enforced the mode seeking is then performed on the embedded space and the approach preserve all the advantage of the original mean shift algorithm experiment on challenging synthetic and real data clearly demonstrate that significant improvement in clustering accuracy can be achieved by employing only a few constraint 
abstract this article proposes a novel similarity measure between vector sequence recently a model based approach wa introduced to address this issue it consists in modeling each sequence with a continuous hidden markov model chmm and computing a probabilistic measure of similarity between c hmms in this paper we propose to model sequence with semi continuous hmms sc hmms the gaussians of the sc hmms are constrained to belong to a shared pool of gaussians this constraint provides two major benefit first the a priori information contained in the common set of gaussians lead to a more accurate estimate of the hmm parameter second the computation of a probabilistic similarity between two sc hmms can be simplified to a dynamic time warping dtw between their mixture weight vector which reduces significantly the computational cost experimental result on a handwritten word retrieval task show that the proposed similarity outperforms the traditional dtw between the original sequence and the model based approach which us c hmms we also show that this increase in accuracy can be traded against a significant reduction of the computational cost up to time 
we present a novel algorithm for simultaneous color and depth inpainting the algorithm take stereo image and estimated disparity map a input and fill in missing color and depth information introduced by occlusion or object removal we first complete the disparity for the occlusion region using a segmentation based approach the completed disparity can be used to facilitate the user in labeling object to be removed since part of the removed region in one image is visible in the other we mutually complete the two image through d warping finally we complete the remaining unknown region using a depth assisted texture synthesis technique which simultaneously fill in both color and depth we demonstrate the effectiveness of the proposed algorithm on several challenging data set 
in this paper we present a new algorithm that combine the advantage of tensor voting into graph cut tensor voting ha been a popular tool for a number of early vision problem since it can use principle of perceptual grouping which are not well considered in graph cut we attempt to encode the power of tensor voting into an energy minimization framework for this we assume that the tensor map obtained by tensor voting induces a riemannian metric in image domain and the metric is constructed according to the conventional way of tensor interpretation finally by embedding the induced riemannian metric into the graph via edge weight the graph cut algorithm can have prior considering principle of perceptual grouping the proposed method can be used in the labeling of occluded region object segmentation using only edge information and boundary regularization 
the sliding window approach of detecting rigid object such a car is predicated on the belief that the object can be identified from the appearance in a small region around the object other type of object of amorphous spatial extent e g tree sky however are more naturally classified based on texture or color in this paper we seek to combine recognition of these two type of object into a system that leverage context toward improving detection in particular we cluster image region based on their ability to serve a context for the detection of object rather than providing an explicit training set with region label our method automatically group region based on both their appearance and their relationship to the detection in the image we show that our thing and stuff ta context model produce meaningful cluster that are readily interpretable and help improve our detection ability over state of the art detector we also present a method for learning the active set of relationship for a particular dataset we present result on object detection in image from the pascal voc datasets and on the task of overhead car detection in satellite image demonstrating significant improvement over state of the art detector 
the popular bag of feature representation for object recognition collect signature of local image patch and discard spatial information some have recently attempted to at least partially overcome this limitation for instance by spatial pyramid and proximity kernel we introduce the general formalism of relaxed matching kernel rmks that includes such approach a special case allow u to derive useful general property of these kernel and to introduce new one a an example we introduce a kernel based on matching graph of feature and one based on matching information compressed feature we show that all rmks are competitive and outperform in several case recently published state of the art result on standard datasets however we also show that a proper implementation of a baseline bag of feature algorithm can be extremely competitive and outperform the other method in some case 
in this paper we propose a novel supervised hierarchical sparse coding model based on local image descriptor for classification task the supervised dictionary training is performed via back projection by minimizing the training error of classifying the image level feature which are extracted by max pooling over the sparse code within a spatial pyramid such a max pooling procedure across multiple spatial scale offer the model translation invariant property similar to the convolutional neural network cnn experiment show that our supervised dictionary improves the performance of the proposed model significantly over the unsupervised dictionary leading to state of the art performance on diverse image database further more our supervised model target learning linear feature implying it great potential in handling large scale datasets in real application 
this paper proposes a new stereo model which encodes the simple assumption that the scene is composed of a few smooth surface a key feature of our model is the surfacebased representation where each pixel is assigned to a d surface plane or b spline this representation enables several important contribution firstly we formulate a higher order prior which state that pixel of similar appearance are likely to belong to the same d surface this enables to incorporate the very popular color segmentation constraint in a soft and principled way secondly we use a global mdl prior to penalize the number of surface thirdly we are able to incorporate in a simple way a prior which favor low curvature surface fourthly we improve the asymmetric occlusion model by disallowing pixel of the same surface to occlude each other finally we use the known fusion move approach which enables a powerful optimization of our model despite the infinite number of possible labelings surface 
this paper present a general method for segmenting a vector valued sequence into an unknown number of subsequence where all data point from a subsequence can be represented with the same affine parametric model the idea is to cluster the data into the minimum number of such subsequence which a we show can be cast a a sparse signal recovery problem by exploiting the temporal correlation between consecutive data point we try to maximize the sparsity i e the number of zero element of the first order difference of the sequence of parameter vector each non zero element in the first order difference sequence corresponds to a change a weightedl norm based convex approximation is adopted to solve the change detection problem we apply the proposed method to video segmentation and temporal segmentation of dynamic texture 
this paper present a target tracking framework forunstructured crowded scene unstructured crowded scene are defined a those scene where the motion of a crowd appears to be random with different participant moving in different direction over time this mean each spatial location in such scene support more than one or multi modal crowd behavior the case of tracking instructured crowded scene where the crowd move coherently in a common direction and the direction of motion doe not vary over time wa previously handled in in this work we propose to model various crowd behavior or motion modality at different location of the scene by employing correlated topic model ctm of in our construction word correspond to low level quantized motion feature and topic correspond to crowd behavior it is then assumed that motion at each location in an unstructured crowd scene is generated by a set of behavior proportion where behavior represent distribution over low level motion feature this way any one location in the scene may support multiple crowd behavior modality and can be used a prior information for tracking our approach enables u to model a diverse set of unstructured crowd domain which range from cluttered time lapse microscopy video of cell population in vitro to footage of crowded sporting event 
this paper study the problem of spatio temporal matching between trajectory from two video of the same scene in real application trajectory are usually extracted independently in different video so possibly a lot of trajectory stay alone have no corresponding trajectory in the other video in this paper we propose a novel matching algorithm which can not only find the existing correspondence between trajectory but also recover the corresponding trajectory of alone one first we cast trajectory matching problem a an element recovering problem from a matrix constructed by matched trajectory of the two video which is naturally incomplete then under affine camera assumption we recover the matrix by sparse representation and regularization technique finally the result are refined to the case of perspective projection by a local depth estimation procedure our algorithm can handle noisy incomplete or outlying data experiment on both synthetic data and real video show that the proposed method ha good performance 
the one shot similarity measure ha recently been introduced in the context of face recognition where it wa used to produce state of the art result given two vector their one shot similarity score reflects the likelihood of each vector belonging in the same class a the other vector and not in a class defined by a fixed set of negative example the potential of this approach ha thus far been largely unexplored in this paper we analyze the one shot score and show that when using a version of lda a the underlying classifier this score is a conditionally positive definite kernel and may be used within kernel method e g svm it can be efficiently computed and that it is effective a an underlying mechanism for image representation we further demonstrate the effectiveness of the one shot similarity score in a number of application including multiclass identification and descriptor generation 
shape optimization is a problem which arises in numerous computer vision problem such a image segmentation and multiview reconstruction in this paper we focus on a certain class of binary labeling problem which can be globally optimized both in a spatially discrete setting and in a spatially continuous setting the main contribution of this paper is to present a quantitative comparison of the reconstruction accuracy and computation time which allows to ass some of the strength and limitation of both approach we also present a novel method to approximate length regularity in a graph cut based framework instead of using pairwise term we introduce higher order term these allow to represent a more accurate discretization of the l norm in the length term 
we present a method for simultaneously recovering shape and spatially varying reflectance of a surface from photometric stereo image the distinguishing feature of our approach is it generality it doe not rely on a specific parametric reflectance model and is therefore purely datadriven this is achieved by employing novel bi variate approximation of isotropic reflectance function by combining this new approximation with recent development in photometric stereo we are able to simultaneously estimate an independent surface normal at each point a global set of non parametric basis material brdfs and per point material weight our experimental result validate the approach and demonstrate the utility of bi variate reflectance function for general non parametric appearance capture 
in this work we present a non rigid approach to jointly solve the task of d d pose estimation and d image segmentation in general most framework which couple both pose estimation and segmentation assume that one ha the exact knowledge of the d object however in non ideal condition this assumption may be violated if only a general class to which a given shape belongs to is given e g car boat or plane thus the key contribution in this work is to solve the d d pose estimation and d image segmentation for a general class of object or deformation for which one may not be able to associate a skeleton model moreover the resulting scheme can be viewed a an extension of the framework presented in in which we include the knowledge of multiple d model rather than assuming the exact knowledge of a single d shape prior we provide experimental result that highlight the algorithm s robustness to noise clutter occlusion and shape recovery on several challenging pose estimation and segmentation scenario 
many object surface are composed of layer of different physical substance known a layered surface these surface such a patina water color and wall painting have more complex optical property than diffuse surface although the characteristic of layered surface like layer opacity mixture of color and color gradation are significant they are usually ignored in the analysis of many method in computer vision causing inaccurate or even erroneous result therefore the main goal of this paper are twofold to solve problem of layered surface by focusing mainly on surface with two layer i e top and bottom layer and to introduce a decomposition method based on a novel representation of a nonlinear correlation in the color space that we call the spider model when we plot a mixture of color of one bottom layer and n different top layer into the rgb color space then we will have n different curve intersecting at one point resembling the shape of a spider hence given a single input image containing one bottom layer and at least one top layer we can fit their color distribution by using the spider model and then decompose those layered surface the last step is equivalent to extracting the approximated optical property of the two layer the top layer s opacity and the top and bottom layer reflection experiment with real image which include the photograph of ancient wall painting show the effectiveness of our method 
my first paper of a computer vision signature on invariant related to optic flow date from i have published in computer vision next to work in cybernetics psychology physic mathematics and philosophy till my retirement earlier this year hence the slightly blue feeling thus my career roughly cover the history of the field vision ha diverse connotation the fundamental dichotomy is between optically guided action and visual experience the former applies to much of biology and computer vision and involves only concept from science and engineering e g inverse optic the latter involves intention and meaning and thus additionally involves concept from psychology and philosophy david marr s notion of vision is an uneasy blend of the two on the one hand the goal is to create a representation of the scene in front of the eye involving intention and meaning on the other hand the mean by which this is attempted are essentially inverse optic although this ha nominally become something of the standard model of cv it is actually incoherent it is the latter notion of vision that ha always interested me most mainly because one is still grappling with basic concept it ha been my aspiration to turn it into science although in this i failed yet much ha happened something old and is happening now something new i will discus some of the issue that seem crucial to me mostly illustrated through my own work though i shamelessly borrow from friend in the cv community where i see fit 
low rank approximation of image collection e g via pca is a popular tool in many area of computer vision yet surprisingly little is known justifying the observati on that image of an object or scene tend to be low dimensional beyond the special case of lambertian scene this paper considers the question of how many basis image are needed to span the space of image of a scene under realworld lighting and viewing condition allowing for general brdfs we establish new theoretical upper bound on the number of basis image necessary to represent a wide variety of scene under very general condition and perform empirical study to justify the assumption we then demonstrate a number of novel application of linear model for scene appearance for internet photo collection these application include image reconstructi on occluder removal and expanding field of view 
linear discriminant analysis lda ha been successfully applied into computer vision and pattern recognition for effective feature extraction high dimensional object such a image are usually transform a d vector before the lda transformation recently two dimension lda dlda method have been proposed which reduced the dimensionality of image without transforming the matrix into vector however the objective function for dlda remains an unresolved problem in this paper we propose a symmetric lda formulation which resolve the ambiguity problem and propose an effective algorithm to solve the symmetric dlda objective experiment on umist cmu pie and yaleb image database show that our approach outperforms the other dlda method in term of both classification accuracy and objective function result 
real world face recognition system often have to face the single sample per person sspp problem that is only a single training sample for each person is enrolled in the database in this case many of the popular face recognition method fail to work well due to the inability to learn the discriminatory information specific to the person to be identified to address this problem in this paper we propose an adaptive generic learning agl method which adapts a generic discriminant model to better distinguish the person with single face sample a a specific implementation of the agl a coupled linear representation clr algorithm is proposed to infer based on the generic training set the within class scatter matrix and the class mean of each person given it single enrolled sample thus the traditional fisher s linear discriminant fld can be applied to sspp task experiment on the feret and a challenging passport face database show that the proposed method can achieve better result compared with other common solution to the sspp problem 
patchmatch is a fast algorithm for computing dense approximate nearest neighbor correspondence between patch of two image region this paper generalizes patchmatch in three way to find k nearest neighbor a opposed to just one to search across scale and rotation in addition to just translation and to match using arbitrary descriptor and distance not just sum of squared difference on patch color in addition we offer new search and parallelization strategy that further accelerate the method and we show performance improvement over standard kd tree technique across a variety of input in contrast to many previous matching algorithm which for efficiency reason have restricted matching to sparse interest point or spatially proximate match our algorithm can efficiently find global dense match even while matching across all scale and rotation this is especially useful for computer vision application where our algorithm can be used a an efficient general purpose component we explore a variety of vision application denoising finding forgery by detecting cloned region symmetry detection and object detection 
spatiotemporal data is associated with vast amount of raw sample given the limited computational resource typically available an initial organization of this data supporting semantically meaningful line of inquiry would facilitate efficient processing in this paper a new representation for grouping raw image data into a set of coherent spacetime region is proposed unique in this proposal is that coherency is related to a richer description of local spacetime structure than generally considered in particular the representation describes the presence of particular oriented spacetime structure in a distributed manner a key advantage of this representation is it ability to signal the presence of multiple oriented structure at a given spacetime location more generally the abstraction allows for the description and grouping of motion and non motionrelated pattern in a uniform manner empirical evaluation of the grouping method on synthetic and challenging natural imagery suggests it efficacy 
we propose an algorithm which can jointly estimate camera pose and point set registration given point set from two view of a stationary scene our algorithm register the point set while retaining internal scene structure it simultaneously ensures that the resultant registration is consistent with that of a moving camera viewing a static scene adheres to some epipolar constraint our statistical formulation can incorporate but doe not necessarily require additional constraint such a brightness constancy and high dimensional point descriptor such a sift we show that our algorithm is stable over a variety of scene and offer a pose from edge system which handle currently difficult structure from motion scene more robustly 
automatic facial image analysis ha been a long standing research problem in computer vision a key component in facial image analysis largely conditioning the success of subsequent algorithm e g facial expression recognition is to define a vocabulary of possible dynamic facial event to date that vocabulary ha come from the anatomically based facial action coding system facs or more subjective approach i e emotion specified expression the aim of this paper is to discover facial event directly from video of naturally occurring facial behavior without recourse to facs or other labeling scheme to discover facial event we propose a temporal clustering algorithm aligned cluster analysis aca and a multi subject correspondence algorithm for matching expression we use a variety of video source posed facial behavior cohn kanade database unscripted facial behavior ru facs database and some video in infant accuracy of unsupervised aca approached that of a supervised version achieved moderate intersystem agreement with facs and proved informative a a visualization summarization tool 
study on face aging are handicapped by lack of long term dense aging sequence for model training to handle this problem we propose a new face aging model which learns long term face aging pattern from partially dense aging database the learning strategy is based on two assumption i short term face aging pattern is relatively simple and is possible to be learned from currently available database ii long term face aging is a continuous and smooth markov process adopting a compositional face representation our aging algorithm learns a function based short term aging model from real aging sequence to infer facial parameter within a short age span based on the predefined smoothness criterion between two overlapping short term aging pattern we concatenate these learned short term aging pattern to build the long term aging pattern both the subjective assessment and objective evaluation of synthetic aging sequence validate the effectiveness of the proposed model 
we present a method to learn visual attribute eg red metal spotted and object class eg car dress umbrella together we assume image are labeled with category but not location of an instance we estimate model with an iterative procedure the current model is used to produce a saliency score which together with a homogeneity cue identifies likely location for the object resp attribute then those location are used to produce better model with multiple instance learning crucially the object and attribute model must agree on the potential location of an object this mean that the more accurate of the two model can guide the improvement of the le accurate model our method is evaluated on two data set of image of real scene one in which the attribute is color and the other in which it is material we show that our joint learning produce improved detector we demonstrate generalization by detecting attribute object pair which do not appear in our training data the iteration give significant improvement in performance 
clustering is a fundamental task in many vision application to date most clustering algorithm work in a batch setting and training example must be gathered in a large group before learning can begin here we explore incremental clustering in which data can arrive continuously we present a novel incremental model based clustering algorithm based on nonparametric bayesian method which we call memory bounded variational dirichlet process mb vdp the number of cluster are determined flexibly by the data and the approach can be used to automatically discover object category the computational requirement required to produce model update are bounded and do not grow with the amount of data processed the technique is well suited to very large datasets and we show that our approach outperforms existing online alternative for learning nonparametric bayesian mixture model 
abstract this paper present technique for improving the numerical stability of gr obner basis solver for polynomial equation recently gr obner basis method have been used succesfully to solve polynomial equation arising in global optimization e g three view triangulation and in many important minimal case of structure from motion such method work extremely well for problem of reasonably low degree involving a few variable currently the limiting factor in using these method for larger and more demanding problem is numerical difficulty in the paper we i show how to change basis in the quotient space r x i and propose a strategy for selecting a basis which improves the conditioning of a crucial elimination step ii use this technique to devise a gr obner basis with improved precision and iii show how solving for the eigenvalue instead of eigenvectors can be used to improve precision further while retaining the same speed we study these method on some of the latest reported us of gr obner basis method and demonstrate dramatically improved numerical precision using these new technique making it possible to solve a larger class of problem than previously 
we present a random field based model for stereo vision with explicit occlusion labeling in a probabilistic framework the model employ non parametric cost function that can be learnt automatically using the structured support vector machine the learning algorithm enables the training of model that are steered towards optimizing for a particular desired loss function such a the metric used to evaluate the quality of the stereo labeling experimental result demonstrate that the performance of our method surpasses that of previous learning approach and is comparable to the state of the art for pixel based stereo moreover our method achieves good result even when trained on different image set in contrast with the common practice of hand tuning to specific benchmark image in addition we investigate the impact of graph structure on model performance our study show that random field model with longer range edge generally outperform the connected grid and that this advantage is especially pronounced for noisy image 
we proposea generic groupingalgorithm that construct a hierarchy of region from the output of any contour detector our method consists of two step an oriented watershed transform owt to form initial region from contour followed by construction of an ultrametric contour map ucm defining a hierarchical segmentation we provide extensive experimental evaluation to demonstrate that when coupled to a high performance contour detector the owt ucm algorithm produce state of the art image segmentation these hierarchical segmentation can optionally be further refined by user specified annotation 
we propose a scheme to introduce directionality in the random walker algorithm for image segmentation in particular we extend the optimization framework of this algorithm to combinatorial graph with directed edge our scheme is interactive and requires the user to label a few pixel that are representative of a foreground object and of the background these labeled pixel are used to learn intensity model for the object and the background which allow u to automatically set the weight of the directed edge these weight are chosen so that they bias the direction of the object boundary gradient to flow from region that agree well with the learned object intensity model to region that do not agree well we use these weight to define an energy function that associate asymmetric quadratic penalty with the edge in the graph we show that this energy function is convex hence it ha a unique minimizer we propose a provably convergent iterative algorithm for minimizing this energy function we also describe the construction of an equivalent electrical network with diode and resistor that solves the same segmentation problem a our framework finally our experiment on a database of image show that the use of directional information doe improve the segmenting power of the random walker algorithm 
in this paper we explore the use of shape of nose for performing partial human biometrics the basic idea is to represent nasal surface using indexed collection of isocurves and to analyze shape of nose by comparing their corresponding curve we extend past work in riemannian analysis of shape of closed curve in r to obtain a similar riemannian analysis for nasal surface in particular we obtain algorithm for computing geodesic computing statistical mean and stochastic clustering we demonstrate these idea in two application context authentication and identification we evaluate performance on a large database involving scan from frgc v database and present a hierarchical organization of nose database to allow for efficient search 
detecting object in cluttered scene and estimating articulated human body part are two challenging problem in computer vision the difficulty is particularly pronounced in activity involving human object interaction e g playing tennis where the relevant object tends to be small or only partially visible and the human body part are often self occluded we observe however that object and human pose can serve a mutual context to each other recognizing one facilitates the recognition of the other in this paper we propose a new random field model to encode the mutual context of object and human pose in human object interaction activity we then cast the model learning task a a structure learning problem of which the structural connectivity between the object the overall human pose and different body part are estimated through a structure search approach and the parameter of the model are estimated by a new max margin algorithm on a sport data set of six class of human object interaction we show that our mutual context model significantly outperforms state of the art in detecting very difficult object and human pose 
we present a minimal solution for aligning two image taken by a rotating camera from point correspondence the solution particularly address the case where there is lens distortion in the image we assume to know the two camera center but not the focal length and allow the latter to vary our solution us a minimal number three of point correspondence and is well suited to be used in a hypothesis testing framework it doe not suffer from numerical instability observed in other algebraic minimal solver and is also efficient we validate our solution in multi image panoramic stitching on real image with lens distortion 
in this paper we present a new approach for recovering spacetime consistent depth map from multiple video sequence captured by stationary synchronized and calibrated camera for depth based free viewpoint video rendering our two pas approach is generalized from the recently proposed region tree based binocular stereo matching method in each pas to enforce temporal consistency between successive depth map the traditional region tree is extended into a temporal one by including connection to temporal neighbor region in previous video frame which are identified using estimated optical flow information for enforcing spatial consistency multi view geometric constraint are used to identify inconsistency between depth map among different view which are captured in an inconsistency map for each view iterative optimization are performed to progressively correct inconsistency through inconsistency map based depth hypothesis pruning and visibility reasoning furthermore the background depth and color information is generated from the result of the first pas and is used in the second pas to enforce sequence wise temporal consistency and to aid in identifying and correcting spatial inconsistency the extensive experimental evaluation have shown that our proposed approach is very effective in producing spatially and temporally consistent depth map 
shadow are one of the most significant difficulty of the photometric stereo method when four or more image are available local surface orientation is overdetermined and the shadowed pixel can be discarded in this paper we look at the challenging case when only three image under three different illumination are available in this case when one of the three pixel intensity constraint is missing due to shadow a dof ambiguity per pixel arises we show that using integrability one can resolve this ambiguity and use the remaining two constraint to reconstruct the geometry in the shadow region a the problem becomes ill posed in the presence of noise we describe a regularization scheme that improves the numerical performance of the algorithm while preserving data we propose a simple mrf optimization scheme to identify and segment shadow region in the image finally the paper describes how this theory applies in the framework of color photometric stereo where one is restricted to only three image experiment on synthetic and real image sequence are presented 
surface registration is widely used in machine vision and medical imaging where correspondence between surface are computed to study their variation surface map are usually stored a the d coordinate each vertex is mapped to which often requires lot of storage memory this cause inconvenience in data transmission and data storage especially when a large set of surface are analyzed to tackle this problem we propose a novel representation of surface diffeomorphisms using beltrami coefficient which are complex valued function defined on surface with supreme norm le than fixing any point on a pair of surface there is a correspondence between the set of surface diffeomorphisms between them and the set of beltrami coefficient on the source domain hence every bijective surface map can be represented by a unique bel trami coefficient conversely given a beltrami coefficient we can reconstruct the unique surface map associated to it using the beltrami holomorphic flow bhf method introduced in this paper using this representation of the storage space is saved we can further reduce the storage requirement by by compressing the beltrami coefficient using fourier approximation we test our algorithm on synthetic data real human brain and hippocampal surface our result show high accuracy in the reconstructed data while the amount of storage is greatly reduced our approach is compared with the fourier compression of the coordinate function using the same amount of data the latter approach often show jaggy result and cannot guarantee to preserve diffeomorphisms 
in this paper we address the problem of deformable object matching alignment and segmentation with cluttered background we propose a novel hierarchical log linear model hllm which represents both shape and appearance feature at multiple level of a hierarchy this model enables u to combine appearance cue at multiple scale directly into the hierarchyand to model shape deformation at short range medium range and long range we introduce the structure perceptron algorithm to estimate the parametersofthehllm ina discriminativeway thelearning is ableto estimate the appearanceand shape parameterssimultaneously in a global manner moreover the structureperceptron learning ha a feature selection aspect similar to adaboost which enables u to specify a class of appearance shape feature and allow the algorithm to select which feature to use and weight their importance this method wa applied to the task of deformable object localization segmentation matching alignment and parsing we demonstrate that the algorithm achieves the state of the art performance by evaluation on public dataset horse and multi view face 
learning a robust projection with a small number of training sample is still a challenging problem in face recognition especially when the unseen face have extreme variation in pose illumination and facial expression to address this problem we propose a framework formulated under statistical learning theory that facilitates robust learning of a discriminative projection dimensionality reduction using the projection matrix is combined with a linear classifier in the regularized framework of lasso regression the projection matrix in conjunction with the classifier parameter are then found by solving an optimization problem over the stiefel manifold the experimental result on standard face database suggest that the proposed method outperforms some recent regularized technique when the number of training sample is small 
hough transform based object detector learn a mapping from the image domain to a hough voting space within this space object hypothesis are formed by local maximum the vote contributing to a hypothesis are called support in this work we investigate the use of the support and it backprojection to the image domain for multi view object detection to this end we create a shared codebook with training and matching complexity independent of the number of quantized view we show that since backprojection encodes enough information about the viewpoint all view can be handled together in our experiment we demonstrate that superior accuracy and efficiency can be achieved in comparison to the popular one v the rest detector by treating view jointly especially with few training example and no view annotation furthermore we go beyond the detection case and based on the support we introduce a part based similarity measure between two arbitrary detection which naturally take spatial relationship of part into account and is insensitive to partial occlusion we also show that backprojection can be used to efficiently measure the similarity of a detection to all training example finally we demonstrate how these metric can be used to estimate continuous object parameter like human pose and object s viewpoint in our experiment we achieve state of the art performance for view classification on the pascal voc dataset 
multi exposure x ray imaging can see through object and separate different material into transparent layer however layer motion make the separation task under determined instead of aligning the non rigid motion we address the layer separation problem in gradient domain and propose an energy optimization framework to regularize it by explicitly enforcing independence constraint it is shown that gradient domain allows more accurate and robust independence analysis between non stationary signal using mutual information mi and hence achieves better separation furthermore gradient field contain sufficient information for full reconstruction of separated layer by solving the poisson equation for efficient regularization of the gradient separation energy term based on the taylor expansion of mi is further derived evaluation on both synthesized and real datasets prof the effectiveness of our algorithm and it robustness to complex tissue motion 
in this paper we extend a computationally efficient framework for real time d tracking and segmentation to support deformable subdivision surface segmentation is performed in a sequential state estimation fashion using an extended kalman filter to estimate shape and pose parameter for the subdivision surface a an example we have integrated doo sabin subdivision surface into the framework furthermore we provide a method for evaluating basis function for doo sabin surface at arbitrary parameter value these basis function are precomputed during initialization and later used during segmentation to quickly evaluate surface point used for edge detection fully automatic tracking and segmentation of the left ventricle is demonstrated in a dataset of d echocardiography recording successful segmentation wa achieved in all case with limit of agreement mean sd for point to surface distance of mm compared to manually verified segmentation real time segmentation at a rate of frame per second consumed a cpu load of 
dense d reconstruction of extremely fast moving object could contribute to various application such a body structure analysis and accident avoidance and so on the actual case for scanning we assume are for example acquiring sequential shape at the moment when an object explodes or observing fast rotating turbine s blade in this paper we propose such a technique based on a one shot scanning method that reconstructs d shape from a single image where dense and simple pattern are projected onto an object to realize dense d reconstruction from a single image there are several issue to be solved e g instability derived from using multiple color and difficulty on detecting dense pattern because of influence of object color and texture compression this paper describes the solution of the issue by combining two method that is an efficient line detection technique based on de bruijn sequence and belief propagation and an extension of shape from intersection of line method a a result a scanning system that can capture an object in fast motion ha been actually developed by using a high speed camera in the experiment the proposed method successfully captured the sequence of dense shape of an exploding balloon and a breaking ceramic dish at fps 
most successful object recognition system rely on binary classification deciding only if an object is present or not but not providing information on the actual object location to perform localization one can take a sliding window approach but this strongly increase the computational cost because the classifier function ha to be evaluated over a large set of candidate subwindows in this paper we propose a simple yet powerful branchand bound scheme that allows efficient maximization of a large class of classifier function over all possible subimages it converges to a globally optimal solution typically in sublinear time we show how our method is applicable to different object detection and retrieval scenario the achieved speedup allows the use of classifier for localization that formerly were considered too slow for this task such a svms with a spatial pyramid kernel or nearest neighbor classifier based on the distance we demonstrate state of the art performance of the resulting system on the uiuc car dataset the pascal voc dataset and in the pascal voc competition 
fast retrieval method are critical for large scale and data driven vision application recent work ha explored way to embed high dimensional feature or complex distance function into a low dimensional hamming space where item can be efficiently searched however existing method do not apply for high dimensional kernelized data when the underlying feature embedding for the kernel is unknown we show how to generalize locality sensitive hashingto accommodatearbitrary kernel function making it possible to preserve the algorithm s sub linear time similarity search guaranteesfor a wide class of useful similarity function since a number of successful image based kernel have unknown or incomputable embeddings this is especially valuable for image retrieval task we validate our technique on several large scale datasets and show that it enables accurate and fast performance for example based object classification feature matching and content based retrieval 
in this paper we propose a unified graphical model framework to interpret a scene composed of multiple object in monocular video sequence using a single pairwise markov random field mrf all the observed and hidden variable of interest such a image intensity pixel state associated object s index and relative depth object state model motion parameter and relative depth are jointly considered particular attention is given to occlusion handling by introducing a rigorous visibility modeling within the mrf formulation through minimizing the mrf s energy we simultaneously segment track and sort by depth the object promising experimental result demonstrate the potential of this framework and it robustness to image noise cluttered background moving camera and background and even complete occlusion 
in many recent object recognition system feature extraction stage are generally composed of a filter bank a non linear transformation and some sort of feature pooling layer most system use only one stage of feature extraction in which the filter are hard wired or two stage where the filter in one or both stage are learned in supervised or unsupervised mode this paper address three question how doe the non linearity that follow the filter bank influence the recognition accuracy doe learning the filter bank in an unsupervised or supervised manner improve the performance over random filter or hardwired filter is there any advantage to using an architecture with two stage of feature extraction rather than one we show that using non linearity that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmark we show that two stage of feature extraction yield better accuracy than one most surprisingly we show that a two stage system with random filter can yield almost recognition rate on caltech provided that the proper non linearity and pooling layer are used finally we show that with supervised refinement the system achieves state of the art performance on norb dataset and unsupervised pre training followed by supervised refinement produce good accuracy on caltech and the lowest known error rate on the undistorted unprocessed mnist dataset 
when a curved mirror like surface move relative to it environment it induces a motion field or specular flow on the image plane that observes it this specular flow is related to the mirror s shape through a non linear partial differential equation and there is interest in understanding when and how this equation can be solved for surface shape existing analysis of this shape from specular flow equation have focused on closed form solution and while they have yielded insight their critical reliance on externally provided initial condition and or specific motion make them difficult to apply in practice this paper resolve these issue we show that a suitable reparameterization lead to a linear formulation of the shape from specular flow equation this formulation radically simplifies the reconstruction process and allows for example both motion and shape to be recovered from a few a two specular flow even when no externally provided initial condition are available our analysis move u closer to a practical method for recovering shape from specular flow that operates under arbitrary unknown motion in unknown illumination environment and doe not require additional shape information from other source 
it ha recently been shown that deformable d surface could be recovered from single video stream however existing technique either require a reference view in which the shape of the surface is known a priori which often may not be available or require tracking point over long sequence which is hard to do in this paper we overcome these limitation to this end we establish correspondence between pair of frame in which the shape is different and unknown we then estimate homographies between corresponding local planar patch in both image these yield approximate d reconstruction of point within each patch up to a scale factor since we consider overlapping patch we can enforce them to be consistent over the whole surface finally a local deformation model is used to fit a triangulated mesh to the d point cloud which make the reconstruction robust to both noise and outlier in the image data 
this paper introduces a novel method for recovering both the light direction and camera pose from a single sphere traditional method for estimating light direction using sphere either assume both the radius and center of the sphere being known precisely or they depend on multiple calibrated view to recover these parameter it will be shown in this paper that the light direction can be uniquely determined from the specular highlight observed in a single view of a sphere without knowing or recovering the exact radius and center of the sphere besides if the sphere is being observed by multiple camera it image will uniquely define the translation vector of each camera from a common world origin centered at the sphere center it will be shown that the relative rotation between the camera can be recovered using two or more light direction estimated from each view closed form solution for recovering the light direction and camera pose are presented and experimental result on both synthetic and real data show the practicality of the proposed method 
we propose an unconventional but highly effective approach to robust fitting of multiple structure by using statistical learning concept we design a novel mercer kernel for the robust estimation problem which elicits the potential of two point to have emerged from the same underlying structure the mercer kernel permit the application of well grounded statistical learning method among which nonlinear dimensionality reduction principal component analysis and spectral clustering are applied for robust fitting our method can remove gross outlier and in parallel discover the multiple structure present it function well under severe outlier more than of the data and considerable inlier noise without requiring elaborate manual tuning or unrealistic prior information experiment on synthetic and real problem illustrate the superiority of the proposed idea over previous method 
symmetry is one of the important cue for human and machine perception of the world for over three decade automatic symmetry detection from image pattern ha been a standing topic in computer vision we present a timely systematic and quantitative performance evaluation of three state of the art discrete symmetry detection algorithm this evaluation scheme includes a set of carefully chosen synthetic and real image presenting justified unambiguous single or multiple dominant symmetry and a pair of well defined success rate for validation we make our test image with associated hand labeled ground truth publicly available with this paper in addition we explore the potential contribution of symmetry detection for object recognition by testing the symmetry detection algorithm on three publicly available object recognition image set pascal voc msrc and caltech our result indicate that even after several decade of effort symmetry detection in real world image remains a challenging unsolved problem in computer vision meanwhile we illustrate it future potential in object recognition 
we propose a novel approach to unsupervised facial image alignment differently from previous approach that are confined to affine transformation on either the entire face or separate patch we extract a nonrigid mapping between facial image based on a regularized face model we frame unsupervised face alignment into the lucas kanade image registration approach we propose a robust optimization scheme to handle appearance variation the method is fully automatic and can cope with pose variation and expression all in an unsupervised manner experiment on a large set of image showed that the approach is effective 
without a deformation model monocular d shape recovery of deformable surface is severly under constrained even when the image information is rich enough prior knowledge of the feasible deformation is required to overcome the ambiguity this is further accentuated when such information is poor which is a key issue that ha not yet been addressed in this paper we propose an approach to learning shape prior to solve this problem by contrast with typical statistical learning method that build model for specic object shape we learn local deformation model and combine them to reconstruct surface of arbitrary global shape not only doe this improve the generality of our deformation model but it also facilitates learning since the space of local deformation is much smaller than that of global one while using a texture based approach we show that our model are effective to reconstruct from single video poorly textured surface of arbitrary shape made of material a different a cardboard that deforms smoothly and much lighter tissue paper whose deformation may be far more complex 
we present an analysis of the spatial covariance structure of an articulated motion prior in which joint angle have a known covariance structure from this a well known but often ignored deficiency of the kinematic skeleton representation becomes clear spatial variance not only depends on limb length but also increase a the kinematic chain are traversed we then present two similar gaussian like motion prior that are explicitly expressed spatially and a such avoids any variance coming from the representation the resulting prior are both simple and easy to implement yet they provide superior prediction 
this paper address the boundary ownership problem also known a the figure ground assignment problem estimating boundary ownership is a key step in perceptual organization it allows higher level processing to be applied on non accidental shape corresponding to figural region existing method for estimating the boundary ownership for a given set of boundary curve model the probability distribution function pdf of the binary figure ground random variable associated with the curve instead of modeling this pdf directly the proposed method us the d model it model the pdf of the ordinal depth of the image segment enclosed by the curve after this pdf is maximized the boundary ownership of a curve is determined according to the ordinal depth of the two image segment it abuts this method ha two advantage first boundary ownership configuration inconsistent with every depth ordering and thus very likely to be incorrect are eliminated from consideration second it allows for the integration of cue related to image segment not necessarily adjacent in addition to those related to the curve the proposed method model the pdf a a conditional random field crf conditioned on cue related to the curve t junction and image segment the crf is formulated using learnt non parametric distribution of the cue the method significantly improves the currently achieved figure ground assignment accuracy with fewer error in the berkeley segmentation dataset 
conventional approach to relevance feedback in content based image retrieval are based on the assumption that relevant image are physically close to the query image or the query region can be identified by a set of clustering center however semantically related image are often scattered across the visual space it is not always reliable that the refined query point or the clustering center are capable of representing a complex query region in this work we propose a novel relevance feedback approach which directly aim at extracting a set of sample to represent the query region regardless of it underlying shape the sample set extracted by our method is competent a well a compact for subsequent retrieval moreover we integrate feature re weighting in the process to estimate the importance of each image descriptor unlike most existing relevance feedback approach in which all query point share a same feature weight distribution our method re weight the feature importance for each relevant image respectively so that the representative and discriminative ability for all the image can be maximized experimental result on two database show the effectiveness of our approach 
the inference of specular mirror like shape is a particularly difficult problem because an image of a specular object is nothing but a distortion of the surrounding environment consequently when the environment is unknown such an image would seem to convey little information about the shape itself it ha recently been suggested adato et al iccv that observation of relative motion between a specular object and it environment can dramatically simplify the inference problem and allow one to recover shape without explicit knowledge of the environment content however this approach requires solving a non linear pde the shape from specular flow equation and analytic solution are only known to exist for very constrained motion in this paper we consider the recovery of shape from specular flow under general motion we show that while the shape from specular flow pde for a single motion is non linear we can combine observation of multiple specular flow from distinct relative motion to yield a linear set of equation we derive necessary condition for this procedure discus several numerical issue with their solution and validate our result quantitatively using image data 
in this paper we introduce a template based method for recognizing human action called action mach our approach is based on a maximum average correlation height mach filter a common limitation of template based method is their inability to generate a single template using a collection of example mach is capable of capturing intra class variability by synthesizing a single action mach filter for a given action class we generalize the traditional mach filter to video d spatiotemporal volume and vector valued data by analyzing the response of the filter in the frequency domain we avoid the high computational cost commonly incurred in template based approach vector valued data is analyzed using the clifford fourier transform a generalization of the fourier transform intended for both scalar and vector valued data finally we perform an extensive set of experiment and compare our method with some of the most recent approach in the field by using publicly available datasets and two newannotatedhumanaction datasetswhichinclude action performed in classic featurefilms and sport broadcast television 
action are spatio temporal pattern which can be characterized by collection of spatio temporal invariant feature detection of action is to find the re occurrence e g through pattern matching of such spatio temporal pattern this paper address two critical issue in pattern matching based action detection efficiency of pattern search in d video and tolerance of intra pattern variation of action our contribution are two fold first we propose a discriminative pattern matching called naivebayes based mutual information maximization nbmim for multi class action categorization it improves the stateof the art result on standard kth dataset second a novel search algorithm is proposed to locate the optimal subvolume in the d video space for efficient action detection our method is purely data driven and doe not rely on object detection tracking or background subtraction it can well handle the intra pattern variation of action such a scale and speed variation and is insensitive to dynamic and clutter background and even partial occlusion the experiment on versatile datasets including kth and cmu action datasets demonstrate the effectiveness and efficiency of our method 
this article present a general approach for the active stereo tracking of multiple moving target the problem is formulated on the plane where camera are modeled a line scan camera and target are described a point with unconstrained motion we propose to control the active system parameter in such a manner that the image of the target in the two view are related by an homography this homography is specified during the design stage and implicitly encodes the tracking behavior it is shown that this formulation lead to an elegant geometric framework that enables to decide about the feasibility of a particular active tracking task we apply it to prove that two camera with rotation and zoom control can track up to three moving target while assuring that the image location of each target is the same for both view in addition the framework is also useful for devising tracking strategy and deriving the required control equation this feature is illustrated through a real experiment on tracking two independent target using a binocular stereo head 
color and texture have been widely used in image segmentation however their performance is often hindered by scene ambiguity overlapping object or missing part in this paper we propose an interactive image segmentation approach with shape prior model within a bayesian framework interactive feature through mouse stroke reduce ambiguity and the incorporation of shape prior enhances quality of the segmentation where color and or texture are not solely adequate the novelty of our approach are in i formulating the segmentation problem in a well defined bayesian framework with multiple shape prior ii efficiently estimating parameter of the bayesian model and iii multi object segmentation through userspecified prior we demonstrate the effectiveness of our method on a set of natural and synthetic image 
in this paper we propose a particle filtering approach for the problem of registering two point set that differ by a rigid body transformation typically registration algorithm compute the transformation parameter by maximizing a metric given an estimate of the correspondence between point across the two set of interest this can be viewed a a posterior estimation problem in which the corresponding distribution can naturally be estimated using a particle filter in this work we treat motion a a local variation in pose parameter obtained from running a few iteration of the standard iterative closest point icp algorithm employing this idea we introduce stochastic motion dynamic to widen the narrow band of convergence often found in local optimizer function used to tackle the registration task thus the novelty of our method is twofold firstly we employ a particle filtering scheme to drive the point set registration process secondly we increase the robustness of the registration performance by introducing a dynamic model of uncertainty for the transformation parameter in contrast with other technique our approach requires no annealing schedule which result in a reduction in computational complexity a well a maintains the temporal coherency of the state no loss of information also unlike most alternative approach for point set registration we make no geometric assumption on the two data set experimental result are provided that demonstrate the robustness of the algorithm to initialization noise missing structure or differing point density in each set on challenging d and d registration task 
conditional random field model have proved effective for several low level computer vision problem inference in these model involves solving a combinatorial optimization problem with method such a graph cut belief propagation although several method have been proposed to learn the model parameter from training data they suffer from various drawback learning these parameter involves computing the partition function which is intractable to overcome this state of the art structured learning method frame the problem a one of large margin estimation iterative solution have been proposed to solve the resulting convex optimization problem each iteration involves solving an inference problem over all the label which limit the efficiency of these structured method in this paper we present an efficient large margin piecewise learning method which is widely applicable we show how the resulting optimization problem can be reduced to an equivalent convex problem with a small number of constraint and solve it using an efficient scheme our method is both memory and computationally efficient we show result on publicly available standard datasets 
many computer vision method rely on annotated image set without taking advantage of the increasing number of unlabeled image available this paper explores an alternative approach involving unsupervised structure discovery and semi supervised learning ssl in image collection focusing on object class the first part of the paper contributes with an extensive evaluation of state of the art image representation thus it underline the decisive influence of the local neighborhood structure and it direct consequence on ssl result and the importance of developing powerful object representation in a second part we propose and explore promising direction to improve result by looking at the local topology between image and feature combination strategy 
in this paper we present a systematic framework for recognizing realistic action from video in the wild such unconstrained video are abundant in personal collection a well a on the web recognizing action from such video ha not been addressed extensively primarily due to the tremendous variation that result from camera motion background clutter change in object appearance and scale etc the main challenge is how to extract reliable and informative feature from the unconstrained video we extract both motion and static feature from the video since the raw feature of both type are dense yet noisy we propose strategy to prune these feature we use motion statistic to acquire stable motion feature and clean static feature furthermore pagerank is used to mine the most informative static feature in order to further construct compact yet discriminative visual vocabulary a divisive information theoretic algorithm is employed to group semantically related feature finally adaboost is chosen to integrate all the heterogeneous yet complementary feature for recognition we have tested the framework on the kth dataset and our own dataset consisting of category of action collected from youtube and personal video and have obtained impressive result for action recognition and action localization 
we introduce a generalized representation for a boosted classifier with multiple exit node and propose a method to training which combine the idea of propagating score across boosted classifier and the use of asymmetric goal a mean for determining the ideal constant asymmetric goal is provided which is theoretically justified under a conservative bound on the roc operating point target and empirically near optimal under the exact bound moreover our method automatically minimizes the number of weak classifier avoiding the need to retrain a boosted classifier multiple time for empirical best performance a in conventional method experimental result show significant reduction in training time and number of weak classifier a well a better accuracy compared to conventional cascade and multi exit boosted classifier 
within the field of action recognition feature and descriptor are often engineered to be sparse and invariant to transformation while sparsity make the problem tractable it is not necessarily optimal in term of class separability and classification this paper proposes a novel approach that us very dense corner feature that are spatially and temporally grouped in a hierarchical process to produce an overcomplete compound feature set frequently reoccurring pattern of feature are then found through data mining designed for use with large data set the novel use of the hierarchical classifier allows real time operation while the approach is demonstrated to handle camera motion scale human appearance variation occlusion and background clutter the performance of classification outperforms other state of the art action recognition algorithm on the three datasets kth multi kth and realworld movie sequence containing broad action multiple action localisation is performed though no groundtruth localisation data is required using only weak supervision of class label for each training sequence the realworld movie dataset contain complex realistic action from movie the approach outperforms the published accuracy on this dataset and also achieves real time performance 
natural image are known to have scale invariant statistic while some eariler study have reported the kurtosis of marginal bandpass filter response distribution to be constant throughout scale other study have reported that the kurtosis value are lower for high frequency filter than for lower frequency one in this work we propose a resolution for this discrepancy and suggest that this change in kurtosis value is due to noise present in the image we suggest that this effect is consistent with a clean natural image corrupted by white noise we propose a model for this effect and use it to estimate noise standard deviation in corrupted natural image in particular our result suggest that classical benchmark image used in low level vision are actually noisy and can be cleaned up our result on noise estimation on two set of and a natural image are significantly better than the state of the art 
it is common to use domain specific terminology attribute to describe the visual appearance of object in order to scale the use of these describable visual attribute to a large number of category especially those not well studied by psychologist or linguist it will be necessary to find alternative technique for identifying attribute vocabulary and for learning to recognize attribute without hand labeled training data we demonstrate that it is possible to accomplish both these task automatically by mining text and image data sampled from the internet the proposed approach also characterizes attribute according to their visual representation global or local and type color texture or shape this work focus on discovering attribute and their visual appearance and is a agnostic a possible about the textual description 
when classifying high dimensional sequence data traditional method e g hmms crfs may require large amount of training data to avoid overtting in such case dimensionality reduction can be employed to nd a low dimensional representation on which classication can be done more efciently existing method for supervised dimensionality reduction often presume that the data is densely sampled so that a neighborhood graph structure can be formed or that the data arises from a known distribution sufcient dimension reduction technique aim to nd a low dimensional representation such that the remaining degree of freedom become conditionally independent of the output value in this paper we develop a novel sequence kernel dimension reduction approach s kdr our approach doe not make strong assumption on the distribution of the input data spatial temporal and periodic information is combined in a principled manner and an optimal manifold is learned for the end task we demonstrate the effectiveness of our approach on several task involving the discrimination of human gesture and motion category a well a on a database of dynamic texture 
a a well known fixed point iteration algorithm for kernel density mode seeking mean shift ha attracted wide attention in pattern recognition field to date mean shift algorithm is typically implemented in a batch way with the entire data set known at once in this paper based on stochastic gradient optimization technique we present the stochastic gradient mean shift sg m along with it approximation performance analysis we apply sg m to the speedup of gaussian blurring mean shift gbms clustering experiment in toy problem and image segmentation show that while the clustering accuracy is comparable between sg gbms and naive gbms the former significantly outperforms the latter in running time 
in this paper we presenta spatio temporalfeaturerepresentationanda probabilisticmatchingfunctiontorecognise lip movement from pronounced digit our model automatically selects spatio temporal feature extracted from digit model template and match them with probe video sequence spatio temporalfeatures embed lip movement from pronouncing digit and contain more discriminative information than spatial feature alone a model template for each digit is represented by a set of spatiotemporal feature at multiple scale a probabilistic sequence matching function automatically segment a probe video sequence and match the most likely sequence of digit recognised in the probe sequence we demonstrate the proposedapproachusing the cuave databaseand compareour representationalscheme with three alternative method based on optical flow intensity gradientand block matching respectively the evaluation show that the proposed approach outperforms the others in recognition accuracy and is robust in coping with variation in probe sequence 
the articulated body model used to represent human motion typically have many degree of freedom usually expressed a joint angle that are highly correlated the true range of motion can therefore be represented by latent variable that span a low dimensional space this ha often been used to make motion tracking easier however learning the latent space in a problemindependent way make it non trivial to initialize the tracking process by picking appropriate initial value for the latent variable and thus for the pose in this paper we show that by directly using observable quantity a our latent variable we eliminate this problem and achieve full automation given only modest amount of training data more specifically we exploit the fact that the trajectory of a person s foot or hand strongly constrains body pose in motion such a skating skiing or golfing these trajectory are easy to compute and to parameterize using a few variable we treat these a our latent variable and learn a mapping between them and sequence of body pose in this manner by simply tracking the foot or the hand we can reliably guess initial pose over whole sequence and then refine them 
we propose a robust object recognition method based on approximate d model that can effectively match object under large viewpoint change and partial occlusion the specific problem we solve is given two view of an object determine if the view are for the same or different object our domain of interest is vehicle but the approach can be generalized to other man made rigid object a key contribution of our approach is the use of approximate model with locally and globally constrained rendering to determine matching object we utilize a compact set of d model to provide geometry constraint and transfer appearance feature for object matching across disparate viewpoint the closest model from the set together with it pose with respect to the data is used to render an object both at pixel local level and region part global level especially symmetry and semantic part ownership are used to extrapolate appearance information a piecewise markov random field mrf model is employed to combine observation obtained from local pixel and global region level belief propagation bp with reduced memory requirement is employed to solve the mrf model effectively no training is required and a realistic object image in a disparate viewpoint can be obtained from a few a just one image experimental result on vehicle data from multiple sensor platform demonstrate the efficacy of our method 
in this paper we propose a robust visual tracking method by casting tracking a a sparse approximation problem in a particle filter framework in this framework occlusion corruption and other challenging issue are addressed seamlessly through a set of trivial template specifically to find the tracking target at a new frame each target candidate is sparsely represented in the space spanned by target template and trivial template the sparsity is achieved by solving an regularized least square problem then the candidate with the smallest projection error is taken a the tracking target after that tracking is continued using a bayesian state inference framework in which a particle filter is used for propagating sample distribution over time two additional component further improve the robustness of our approach the nonnegativity constraint that help filter out clutter that is similar to tracked target in reversed intensity pattern and a dynamic template update scheme that keep track of the most representative template throughout the tracking procedure we test the proposed approach on five challenging sequence involving heavy occlusion drastic illumination change and large pose variation the proposed approach show excellent performance in comparison with three previously proposed tracker 
we consider the problem of visual categorization with minimal supervision during training we propose a partbased model that loosely capture structural information we represent image a a collection of part characterized by an appearance codeword from a visual vocabulary and by a neighborhood context organized in an ordered set of bag of feature representation these bag are computed in a local overlapping area around the part a semantic distance between image is obtained by matching part associated with the same codeword using their context distribution the classification is done using svm with the kernel obtained from the proposed distance the experiment show that our method outperforms all the classification method from the pascal challenge on half of the voc category and ha the best average eer it also outperforms the constellation model learned via boosting a proposed by bar hillel et al on their data set which contains more rigid object in this work we consider a compromise between the two opposing view and propose modeling the structural information in a loose manner this is done by augmenting a bag of feature with loose spatial information we represent image a a collection of part characterized by an appearance codeword from a visual vocabulary and by a neighborhood context organized in an ordered set of bagof feature representation these bag are computed in four overlapping area in the local coordinate system of each part we call these representation context distribution the semantic distance between image is obtained by matching part associated with the same codeword using context distribution the matching is polynomial in the number of part the average weight of the matching yield the distance between the image which is small when they correspond to the same category the proposed distance can be easily incorporated in different discriminative classifier in this work we convert it into a kernel and use it in the svm classification our method is robust to translation scale and some degree of rotation thus it can be applied to image with clutter and pose variation the experiment show that our approach outperforms state of the art appearance based algorithm and loose shape method on a very challenging voc data set which contains different view of category of object with a lot of clutter we also show that the proposed loose shape approach performs much better than the constellation type model such a on the dog v animal test despite the similar pose of the dog in this data set which allows learning the spatial relation between part 
repetitive and ambiguous visual structure in general pose a severe problem in many computer vision application identification of incorrect geometric relation between image solely based on low level feature is not always possible and a more global reasoning approach about the consistency of the estimated relation is required we propose to utilize the typically observed redundancy in the hypothesized relation for such reasoning and focus on the graph structure induced by those relation chaining the reversible transformation over cycle in this graph allows to build suitable statistic for identifying inconsistent loop in the graph this data provides indirect evidence for conflicting visual relation inferring the set of likely false positive geometric relation from these non local observation is formulated in a bayesian framework we demonstrate the utility of the proposed method in several application most prominently the computation of structure and motion from image 
recognition of dynamic scene based on shape information could be useful for various application in this study we aimed at improving the resolution of three dimensional d data obtained from moving target we present a simple clean and robust method that jointly estimate motion parameter and a high resolution d shape experimental result are provided to illustrate the performance of the proposed algorithm 
for various d shape analysis task the laplace beltrami lb embedding ha become increasingly popular a it enables the efficient comparison of shape based on intrinsic geometry one fundamental difficulty in using the lb embedding however is the ambiguity in the eigen system and it is conventionally only handled in a heuristic way in this work we propose a novel and intrinsic metric the spectral l distance to overcome this difficulty we prove mathematically that this new distance satisfies the condition of a rigorous metric using the resulting optimal embedding determined by the spectral l distance we can perform both local and global shape analysis intrinsically in the embedding space we demonstrate this by developing a template matching approach in the optimal embedding space to solve the challenging problem of identifying major sulcus on vervet cortical surface in our experiment we validate the robustness of our method by the successful identification of major sulcal line on a large data set of cortical surface and illustrate it potential in brain mapping study 
facial expression modeling is central to facial expression recognition and expression synthesis for facial animation previous work reported that modeling the facial expression with low dimensional manifold is more appropriate than using a linear subspace in this paper we propose a manifold based d face reconstruction approach to estimating the d face model and the associated expression deformation from a single face image in the training phase we build a nonlinear d expression manifold from a large set of d facial expression model to represent the facial shape deformation due to facial expression then a gaussian mixture model in this manifold is learned to represent the distribution of expression deformation by combining the merit of morphable neutral face model and the low dimensional expression manifold we propose a new algorithm to reconstruct the d face geometry a well a the d shape deformation from a single face image with expression in an energy minimization framework experimental result on cmu pie image database and fg net video database are shown to validate the effectiveness and accuracy of the proposed algorithm 
modeling and recognizing landmark at world scale is a useful yet challenging task there exists no readily available list of worldwide landmark obtaining reliable visual model for each landmark can also pose problem and efficiency is another challenge for such a large scale system this paper leverage the vast amount of multimedia data on the web the availability of an internet image search engine and advance in object recognition and clustering technique to address these issue first a comprehensive list of landmark is mined from two source million gps tagged photo and online tour guide web page candidate image for each landmark are then obtained from photo sharing website or by querying an image search engine second landmark visual model are built by pruning candidate image using efficient image matching and unsupervised clustering technique finally the landmark and their visual model are validated by checking authorship of their member image the resulting landmark recognition engine incorporates landmark from city in country the experiment demonstrate that the engine can deliver satisfactory recognition performance with high efficiency 
in this paper we address the problem of human gait recognition from a robust identification and model in validation prospective the main idea is to apply dimensionality reduction technique to extract the spatio temporal information by mapping the gait silhouette sequence to a low dimensional time sequence which is considered a the output of a linear time invariant lti system a class of gait is associated to a nominal discrete lti system which ha a periodic impulse response and is identified by robust identification approach correspondingly gait recognition can be formulated a measuring the difference between the model representing different gait sequence our approach provides an efficient way to extract to model shape motion information of gait sequence and to measure the difference between gait sequence model which is robust to gait cycle localization gross appearance variation and time scaling these result are illustrated with practical example on popular gait database 
discovering the underlying low dimensional latent structure in high dimensional perceptual observation e g image video can in many case greately improve performance in recognition and tracking however non linear dimensionality reduction method are often susceptible to local minimum and perform poorly when initialized far from the global optimum even when the intrinsic dimensionality is known a priori in this work we introduce a prior over the dimensionality of the latent space that penalizes high dimensional space and simultaneously optimize both the latent space and it intrinsic dimensionality in a continuous fashion ad hoc initialization scheme are unnecessary with our approach we initialize the latent space to the observation space and automatically infer the latent dimensionality we report result applying our prior to various probabilistic non linear dimensionality reduction task and show that our method can outperform graph based dimensionality reduction technique a well a previously suggested initialization strategy we demonstrate the effectiveness of our approach when tracking and classifying human motion 
abstract many computer vision problem can be formulated in a bayesian framework with markov random field mrf or conditional random field crf prior usually the model assumes that a full maximum a posteriori map estimation will be performed for inference which can be really slow in practice in this paper we argue that through appropriate training a mrf crf model can be trained to perform very well on a suboptimal inference algorithm the model is trained together with a fast inference algorithm through an optimization of a loss function on a training set containing pair of input image and desired output a validation set can be used in this approach to estimate the generalization performance of the trained system we apply the proposed method to an image denoising application training a field of expert mrf together with a iteration gradient descent inference algorithm experimental validation on unseen data show that the proposed training approach obtains an improved benchmark performance a well a a time speedup compared to the field of expert mrf trained with contrastive divergence using the new approach image denoising can be performed in real time at fps on a single cpu for a image sequence with close to state of the art accuracy 
in photometricstereo a robust method is required to deal with outlier such a shadow and non lambertian reflection in this paper we rely on a probabilistic imaging model that distinguishes between inliers and outlier and formulate the problem a a maximum likelihood estimation problem to signal which imaging model to use a hidden binary inlier map is introduced which to account for the fact that inlier outlier pixel typically group together is modelled a a markov random field to make inference of model parameter and hidden variable tractable a mean field expectation maximization em algorithm is used if for each pixel we add the scaled normal i e albedo and normal combined to the model parameter it would not be possible to obtain a confidence estimate in the result instead each scaled normal is added a a hidden variable the distribution of which approximated by a gaussian is also estimated in the em algorithm the covariance matrix of the recovered approximate gaussian distribution serf a a confidence estimate of the scaled normal we demonstrate experimentally the effectiveness or our approach 
the varying object appearance and unlabeled data from new frame are always the challenging problem in object tracking recently machine learning method are widely applied to tracking and some online and semi supervised algorithm are developed to handle these difficulty in this paper we consider tracking a a classification problem and present a novel tracking method based on boosting in a co training framework the proposed tracker can be online updated and boosted with multi view weak hypothesis the most important contribution of this paper is that we find a boosting error upper bound in a co training framework to guide the novel tracker construction in theory the proposed tracking method is proved to minimize this error bound in experiment the accuracy rate of foreground background classification and the tracking result are both served a evaluation metric experimental result show good performance of proposed novel tracker on challenging sequence 
video of multi player team sport provide a challenging domain for dynamic scene analysis player action and interaction are complex a they are driven by many factor such a the short term goal of the individual player the overall team strategy the rule of the sport and the current context of the game we show that constrained multi agent event can be analyzed and even predicted from video such analysis requires estimating the global movement of all player in the scene at any time and is needed for modeling and predicting how the multi agent play evolves over time on the field to this end we propose a novel approach to detect the location of where the play evolution will proceed e g where interesting event will occur by tracking player position and movement over time we start by extracting the ground level sparse movement of player in each time step and then generate a dense motion field using this field we detect location where the motion converges implying position towards which the play is evolving we evaluate our approach by analyzing video of a variety of complex soccer play 
in an extended image sequence of an outdoor scene one observes change in color induced by variation in the spectral composition of daylight this paper proposes a model for these temporal color change and explores it use for the analysis of outdoor scene from time lapse video data we show that the time varying change in direct sunlight and ambient skylight can be recovered with this model and that an image sequence can be decomposed into two corresponding component the decomposition provides access to both radiometric and geometric information about a scene and we demonstrate how this can be exploited for a variety of visual task including color constancy background subtraction shadow detection scene reconstruction and camera geo location 
discriminative approach to human pose inference involve mapping visual observation to articulated body congurations current probabilistic approach to learn this mapping have been limited in their ability to handle domain with a large number of activity that require very large training set we propose an online probabilistic regression scheme for efcient inference of complex highdimensional and multimodal mapping our technique is based on a local mixture of gaussian process where locality is dened based on both appearance and pose and where the mapping hyperparameters can vary across local neighborhood to better adapt to specic region in the pose space the mixture component are dened online in very small neighborhood so learning and inference is extremely efcient when the mapping is one to one we derive a bound on the approximation error of local regression v global regression for monotonically decreasing covariance function our method can determine when training example are redundant given the rest of the database and use this criterion for pruning we report result on synthetic poser and real humaneva pose database obtaining fast and accurate pose estimate using training set size up to 
each facial event will give rise to complex facial appearance variation in this paper we propose similarity feature to describe the facial appearance for video based facial event analysis inspired by the kernel feature for each sample we compare it with the reference set with a similarity function and we take the log weighted summarization of the similarity a it similarity feature due to the distinctness of the apex image of facial event we use their cluster center a the reference in order to capture the temporal dynamic we use the k mean algorithm to divide the similarity feature into several cluster in temporal domain and each cluster is modeled by a gaussian distribution based on the gaussian model we further map the similarity feature into dynamic binary pattern to handle the issue of time resolution which embed the time warping operation implicitly the haar like descriptor is used to extract the visual feature of facial appearance and adaboost is performed to learn the final classifier extensive experiment carried on the cohn kanade database show the promising performance of the proposed method 
in this paper we propose an algorithm to estimate missing value in tensor of visual data the value can be missing due to problem in the acquisition process or because the user manually identified unwanted outlier our algorithm work even with a small amount of sample and it can propagate structure to fill larger missing region our methodology is built on recent study about matrix completion using the matrix trace norm the contribution of our paper is to extend the matrix case to the tensor case by laying out the theoretical foundation and then by building a working algorithm first we propose a definition for the tensor trace norm that generalizes the established definition of the matrix trace norm second similar to matrix completion the tensor completion is formulated a a convex optimization problem unfortunately the straightforward problem extension is significantly harder to solve than the matrix case because of the dependency among multiple constraint to tackle this problem we employ a relaxation technique to separate the dependant relationship and use the block coordinate descent bcd method to achieve a globally optimal solution our experiment show potential application of our algorithm and the quantitative evaluation indicates that our method is more accurate and robust than heuristic approach 
two surface are conformally equivalent if there exists a bijective angle preserving map between them the teichmu ller space for surface with the same topology is a finite dimensional manifold where each point represents a conformal equivalence class and the conformal map is homotopic to the identity map in this paper we propose a novel method to apply conformal equivalence based shape index to study brain morphometry the shape index is defined based on teichmu ller space coordinate it is intrinsic and invariant under conformal transformation rigid motion and scaling it is also simple to compute no registration of surface is needed using the yamabe flow method we can conformally map a genus zero open boundary surface to the poincare disk the shape index that we compute are the length of a special set of geodesic under hyperbolic metric by computing and studying this shape index and it statistical behavior we can analyze difference in anatomical morphometry due to disease or development study on twin lateral ventricular surface data show it may help detect generic influence on lateral ventricular shape in leave one out validation test we achieved accurate classification versus only accuracy for volume measure in distinguishing hiv aid individual from healthy control subject based on teichmu ller coordinate for lateral ventricular surface extracted from their d mri scan our conformal invariant the teichmu ller coordinate successfully classified all lateral ventricular surface showing their promise for analyzing anatomical surface morphometry 
we demonstrate how to exploit reflection for accurate registration of shiny object the lighting environment can be retrieved from the reflection under a distant illumination assumption since it remains unchanged when the camera or the object of interest move this provides powerful additional constraint that can be incorporated into standard pose estimation algorithm the key idea and main contribution of the paper is therefore to show that the registration should also be performed in the lighting environment space instead of in the image space only this let u recover very accurate pose estimate because the specularities are very sensitive to pose change an interesting side result is an accurate estimate of the lighting environment furthermore since the mapping from lighting environment to specularities ha no analytical expression for object represented a d mesh and is not to registering lighting environment is far from trivial however we propose a general and effective solution our approach is demonstrated on both synthetic and real image 
in background subtraction cast shadow induce silhouette distortion and object fusion hindering performance of high level algorithm in scene monitoring we introduce a nonparametric framework to model surface behavior when shadow are cast on them based on physical property of light source and surface we identify a direction in rgb space on which background surface value under cast shadow are found we then model the posterior distribution of lighting attenuation under cast shadow and foreground object which allows differentiation of foreground and cast shadow value with similar chromaticity the algorithm are completely unsupervised and take advantage of scene activity to learn model parameter spatial gradient information is also used to reinforce the learning process contribution are two fold firstly with a better model describing cast shadow on surface we achieve a higher success rate in segmenting moving cast shadow in complex scene secondly obtaining such model is a step toward a full scene parametrization where light source property surface reflectance model and scene d geometry are estimated for low level segmentation 
the automatic detection of lung nodule attached to other pulmonary structure is a useful yet challenging task in lung cad system in this paper we propose a stratified statistical learning approach to recognize whether a candidate nodule detected in ct image connects to any of three other major lung anatomy namely vessel fissure and lung wall or is solitary with background parenchyma first we develop a fully automated voxel by voxel labeling segmentation method of nodule vessel fissure lung wall and parenchyma given a d lung image via a unified feature set and classifier under conditional random field second the generated class probability response map prm by voxel level classifier are used to form the so called pairwise probability co occurrence map pcm which encode the spatial contextual correlation of the candidate nodule in relation to other anatomical landmark based on pcms higher level classifier are trained to recognize whether the nodule touch other pulmonary structure a a multi label problem we also present a new iterative fissure structure enhancement filter with superior performance for experimental validation we create an annotated database of subvolumes with nodule of various size shape density and contextual anatomy and from patient high accuracy of multi class voxel labeling is achieved the area under roc curve auc of vessel fissure and lung wall connectivity classification reach and respectively 
we present a method that is capable of tracking and estimating pose of articulated object in real time this is achieved by using a bottom up approach to detect instance of the object in each frame these detection are then linked together using a high level a priori motion model unlike other approach that rely on appearance our method is entirely dependent on motion initial low level part detection is based on how a region move a opposed to it appearance this work is best described a pictorial structure using motion a sparse cloud of point extracted using a standard feature tracker are used a observational data this data contains noise that is not gaussian in nature but systematic due to tracking error using a probabilistic framework we are able to overcome both corrupt and missing data whilst still inferring new pose from a generative model our approach requires no manual initialisation and we show result for a number of complex scene and different class of articulated object this demonstrates both the robustness and versatility of the presented technique 
the accurate estimation of motion in image sequence is of central importance to numerous computer vision application most competitive algorithm compute flow field by minimizing an energy made of a data and a regularity term to date the best performing method rely on rather simple purely geometric regularizers favoring smooth motion in this paper we revisit regularization and show that appropriate adaptive regularization substantially improves the accuracy of estimated motion field in particular we systematically evaluate regularizers which adaptively favor rigid body motion if supported by the image data and motion field discontinuity that coincide with discontinuity of the image structure the proposed algorithm relies on sequential convex optimization is real time capable and outperforms all previously published algorithm by more than one average rank on the middlebury optic flow benchmark 
we propose an algorithm that simultaneously extract disparity and alpha matting information given a stereo image pair our method divide the reference image into a set of overlapping partially transparent color segment each segment pixel is assigned an alpha value and color the disparity inside the segment is modeled via a plane the goodnessof alpha color and disparity plane is measured by a new energy function it basic idea is to use the three parameter for generating artificial view representing the left and right image if alpha color and disparity plane are correct these artificial image should be very similar to the real one for generating the artificial right view we warp all pixel of the left into the geometry of the right image using the disparity plane we introduce the assumption of constant solidity in order to correctly model how pixel alpha value are affected by the warping operation experimental result on the middlebury set show that our algorithm give good result in comparison to the state of the art in stereo matching 
conventional approach to automatic image annotation usually suffer from two problem they cannot guarantee a good semantic coherence of the annotated word for each image a they treat each word independently without considering the inherent semantic coherence among the word they heavily rely on visual similarity for judging semantic similarity to address the above issue we propose a novel approach to image annotation which simultaneously learns a semantic distance by capturing the prior annotation knowledge and propagates the annotation of an image a a whole entity specifically a semantic distance function sdf is learned for each semantic cluster to measure the semantic similarity based on relative comparison relation of prior annotation to annotate a new image the training image in each cluster are ranked according to their sdf value with respect to this image and their corresponding annotation are then propagated to this image a a whole entity to ensure semantic coherence we evaluate the innovative sdf based approach on corel image compared with support vector machine based approach the experiment show that sdf based approach outperforms in term of semantic coherence especially when each training image is associated with multiple word 
we perform shape matching by transforming the problem of establishing shape correspondence into an image registration problem at each vertex on the shape we calculate a shape feature and encode this feature a image intensity at appropriate position in the image domain calculating multiple feature at each vertex and encoding them into the image domain result in a vector valued feature image establishing point correspondence between two shape is thereafter treated a a registration problem of two vectorvalued feature image with this shape representation various existing image registration strategy can now be easily applied these include the use of a scale space approach to diffuse the shape feature a coarse to fine registration scheme and various deformable registration algorithm a our validation show by representing shape a vectorvalued image the overall method is robust against noise and occlusion to this end we have successfully established d point correspondence of shape of corpus callosa vertebra and brain ventricle 
many method for d reconstruction in computer vision rely on probability model for example bayesian reasoning here we introduce a probability model of surface visibility in densely cluttered d scene the scene consist of a large number of small surface distributed randomly in a d view volume an example is the leaf or branch on a tree we derive probability for surface visibility instantaneous image velocity under egomotion and binocular half occlusion in these scene the probability depend on parameter such a scene depth object size d density observer speed and binocular baseline we verify the correctness of our model using computer graphic simulation and briefly discus application of the model to stereo and motion 
this paper present a novel method for reconstructing high quality video depth map a bundle optimization model is proposed to address the key issue including image noise and occlusion in stereo reconstruction our method not only us the color constancy constraint but also explicitly incorporates the geometric coherence constraint associating multiple frame in a video thus can naturally maintain the temporal coherence of the recovered video depth without introducing over smoothing artifact to make the inference problem tractable we introduce an iterative optimization scheme by first initializing disparity map using segmentation prior and then refining the disparity by mean of bundle optimization unlike previous work estimating complex visibility parameter our approach implicitly model the probabilistic visibility in a statistical way the effectiveness of our automatic method is demonstrated using challenging video example 
this paper present a new algorithm for multi view reconstruction that demonstrates both accuracy and efficiency our method is based on robust binocular stereo matching followed by adaptive point based filtering of the merged point cloud and efficient high quality mesh generation all aspect of our method are designed to be highly scalable with the number of view our technique produce the most accurate result among current algorithm for a sparse number of viewpoint according to the middlebury datasets additionally we prove to be the most efficient method among non gpu algorithm for the same datasets finally our scaled window matching technique also excels at reconstructing deformable object with high curvature surface which we demonstrate with a number of example 
we consider the problem of single image object motion deblurring from a static camera it is well known that deblurring of moving object using a traditional camera is ill posed due to the loss of high spatial frequency in the captured blurred image a coded exposure camera modulates the integration pattern of light by opening and closing the shutter within the exposure time using a binary code the code is chosen to make the resulting point spread function psf invertible for best deconvolution performance however for a successful deconvolution algorithm psf estimation is a important a psf invertibility we show that psf estimation is easier if the resulting motion blur is smooth and the optimal code for psf invertibility could worsen psf estimation since it lead to non smooth blur we show that both criterion of psf invertibility and psf estimation can be simultaneously met albeit with a slight increase in the deconvolution noise we propose design rule for a code to have good psf estimation capability and outline two search criterion for finding the optimal code for a given length we present theoretical analysis comparing the performance of the proposed code with the code optimized solely for psf invertibility we also show how to easily implement coded exposure on a consumer grade machine vision camera with no additional hardware real experimental result demonstrate the effectiveness of the proposed code for motion deblurring 
we present a resolution invariant image representation riir framework in this paper the riir framework includes the method of building a set of multi resolution base from training image estimating the optimal sparse resolution invariant representation of any image and reconstructing the missing patch of any resolution level a the proposed riir framework ha many potential resolution enhancement application we discus three novel image magnification application in this paper in the first application we apply the riir framework to perform multi scale image magnification where we also introduced a training strategy to built a compact riir set in the second application the riir framework is extended to conduct continuous image scaling where a new base at any resolution level can be generated using existing riir set on the fly in the third application we further apply the riir framework onto content base automatic zooming application the experimental result show that in all these application our riir based method outperforms existing method in various aspect 
a moving plane observed by a fixed camera induces a fundamental matrix f across multiple frame where the ratio among the element in the upper left submatrix are herein referred to a the fundamental ratio we show that fundamental ratio are invariant to camera parameter and hence can be used to identify similar plane motion from varying viewpoint for action recognition we decompose a body posture into a set of point triplet plane the similarity between two action is then determined by the motion of point triplet and hence by their associated fundamental ratio providing thus view invariant recognition of action result evaluated over semi synthetic video data with independent trial at a wide range of noise level and also on real video of different class of action confirm that our method can recognize action under substantial amount of noise even when they have dynamic timeline map and the viewpoint and camera parameter are unknown and totally different view invariant action recognition 
a fundamental problem in computer vision cv is the estimation of geometric parameter from multiple observation obtained from image example of such problem range from ellipse fitting to multi view structure from motion sfm the maximum likelihood ml method is widely used to estimate the parameter in such problem assuming gaussian noise to be present in the observation for example bundle adjustment for sfm according to the theory of statistic the ml estimate are nearly optimal for these problem provided that the variance of the observation noise is sufficiently small this implies that when noise are not small more accurate estimate can be derived a compared to the ml estimate in this study we propose the application of a method called the projected score method developed in statistic for computing higheraccuracy estimate to the cv problem we describe how it can be customized to solve the cv problem and propose a numerical algorithm to implement the method we show that the method work effectively for such problem 
the middlebury multi view stereo evaluation clearly show that the quality and speed of most multi view stereo algorithm depends significantly on the number and selection of input image in general not all input image contribute equally to the quality of the output model since several image may often contain similar and hence overly redundant visual information this lead to unnecessarily increased processing time on the other hand a certain degree of redundancy can help to improve the reconstruction in more difficult region of a model in this paper we propose an image selection scheme for multi view stereo which result in improved reconstruction quality compared to uniformly distributed view our method is tuned towards the typical requirement of current multi view stereo algorithm and is based on the idea of incrementally selecting image so that the overall coverage of a simultaneously generated proxy is guaranteed without adding too much redundant information critical region such a cavity are detected by an estimate of the local photo consistency and are improved by adding additional view our method is highly efficient since most computation can be out sourced to the gpu we evaluate our method with four different method participating in the middlebury benchmark and show that in each case reconstruction based on our selected image yield an improved output quality while at the same time reducing the processing time considerably 
given an object model and a black box measure of similarity between the model and candidate target we consider visual object tracking a a numerical optimization problem during normal tracking condition when the object is visible from frame to frame local optimization is used to track the local mode of the similarity measure in a parameter space of translation rotation and scale however when the object becomes partially or totally occluded such local tracking is prone to failure especially when common prediction technique like the kalman filter do not provide a good estimate of object parameter in future frame to recover from these inevitable tracking failure we consider object detection a a global optimization problem and solve it via adaptive simulated annealing asa a method that avoids becoming trapped at local mode and is much faster than exhaustive search a a monte carlo approach asa stochastically sample the parameter space in contrast to local deterministic search we apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker our numerical hybrid local and global mode seeking tracker is validated on challenging airborne video with heavy occlusion and large camera motion our approach outperforms state of the art tracker on the vivid benchmark datasets 
the explosion of image data on the internet ha the potential to foster more sophisticated and robust model and algorithm to index retrieve organize and interact with image and multimedia data but exactly how such data can be harnessed and organized remains a critical problem we introduce here a new database called imagenet a largescale ontology of image built upon the backbone of the wordnet structure imagenet aim to populate the majority of the synset of wordnet with an average of clean and full resolution image this will result in ten of million of annotated image organized by the semantic hierarchy of wordnet this paper offer a detailed analysis of imagenet in it current state subtrees with synset and million image in total we show that imagenet is much larger in scale and diversity and much more accurate than the current image datasets constructing such a large scale database is a challenging task we describe the data collection scheme with amazon mechanical turk lastly we illustrate the usefulness of imagenet through three simple application in object recognition image classification and automatic object clustering we hope that the scale accuracy diversity and hierarchical structure of imagenet can offer unparalleled opportunity to researcher in the computer vision community and beyond 
we present a practical algorithm that provably achieves the global optimum for a class of bilinear program commonly arising in computer vision application our approach relies on constructing tight convex relaxation of the objective function and minimizing it in a branch and bound framework a key contribution of the paper is a novel provably convergent branching strategy that allows u to solve large scale problem by restricting the branching dimension to just one set of variable constituting the bilinearity experiment with synthetic and real data validate our claim of optimality speed and convergence we contrast the optimality of our solution with those obtained by a traditional singular value decomposition approach among several potential application we discus two exemplar based face reconstruction and non rigid structure from motion in both case we compute the best bilinear fit that represents a shape observed in a single image from an arbitrary viewpoint a a combination of the element of a basis 
we propose novel algorithm for the detection segmentation recognition and pose estimation of three dimensional object our approach initially infers geometric primitive to describe the set of d object a hierarchical structure is constructed to organize the object in term of shared primitive and relation between different primitive in the same object this structure is shown to disambiguate the object model and to improve recognition rate the primitive are obtained through our new invariant hough transform this algorithm us geometric invariant to compute relation for subset of point in a specific object each relation is stored in a hash table according to the invariant value the hash table is used to find potential corresponding point between object with point match pose estimation is achieved by building a probability distribution of transformation we evaluate our method with experiment using synthetic and real d object 
in this paper we study the following problem given two source image a and a and a target image b can we learn to synthesize a new image b which relates to b in the same way that a relates to a we propose an algorithm which a us a semi supervised component to exploit the fact that the target image b is available apriori b us inference on a markov random field mrf to ensure global consistency and c us image quilting to ensure local consistency our algorithm can also deal with the case when a is only partially labeled that is only small part of a are available for training empirical evaluation show that our algorithm consistently produce visually pleasing result outperforming the state of the art 
we propose recursive compositional model rcms for simultaneous multi view multi object detection and parsing e g view estimation and determining the position of the object subpart we represent the set of object by a family of rcms where each rcm is a probability distribution defined over a hierarchical graph which corresponds to a specific object and viewpoint an rcm is constructed from a hierarchy of subpart subgraphs which are learnt from training data part sharing is used so that different rcms are encouraged to share subpart subgraphs which yield a compact representation for the set of object and which enables efficient inference and learning from a limited number of training sample in addition we use appearance sharing so that rcms for the same object but different viewpoint share similar appearance cue which also help efficient learning rcms lead to a multi view multi object detection system we illustrate rcms on four public datasets and achieve state of the art performance 
object class model trained on hundred or thousand of image have shown to enable robust detection transferring knowledge from such model to new object class trained from a few or even a little a one training instance however is still in it infancy this paper design a shape based model that allows to easily and explicitly transfer knowledge on three different level transfer of individual part shape and appearance information transfer of local symmetry between part and transfer of part topology due to the factorized form of the model knowledge can either be transferred for the complete model or just partial knowledge corresponding to certain aspect of the model the experiment clearly demonstrate that the proposed model is competitive with the state of the art and enables both full and partial knowledge transfer 
we present an over segmentation based dense stereo algorithm that jointly estimate segmentation and depth for mixed pixel on segment boundary the algorithm computes foreground opacity alpha a well a color and depth for the foreground and background we model the scene a a collection of fronto parallel planar segment in a reference view and use a generative model for image formation that handle mixed pixel at segment boundary our method iteratively update the segmentation based on color depth and shape constraint using map estimation given a segmentation the depth estimate are updated using belief propagation we show that our method is competitive with the state of the art based on the new middlebury stereo evaluation and that it overcomes limitation of traditional segmentation based method while properly handling mixed pixel z keying result show the advantage of combining opacity and depth estimation 
in this paper we propose a new transductive learning framework for image retrieval in which image are taken a vertex in a weighted hypergraph and the task of image search is formulated a the problem of hypergraph ranking based on the similarity matrix computed from various feature descriptor we take each image a a centroid vertex and form a hyperedge by a centroid and it k nearest neighbor to further exploit the correlation information among image we propose a probabilistic hypergraph which assigns each vertex vi to a hyperedge ej in a probabilistic way in the incidence structure of a probabilistic hypergraph we describe both the higher order grouping information and the affinity relationship between vertex within each hy peredge after feedback image are provided our retrieval system rank image label by a transductive inference approach which tends to assign the same label to vertex that share many incidental hyperedges with the constraint that predicted label of feedback image should be similar to their initial label we compare the proposed method to several other method and it effectiveness is demonstrated by extensive experiment on corel k the scene dataset and caltech 
the image of an outdoor scene collected over time are valuable in studying the scene appearance variation which can lead to novel application and help enhance existing method that were constrained to controlled environment however the image do not reflect the true appearance of the scene in many case due to the radiometric property of the camera the radiometric response function and the changing exposure we introduce a new algorithm to compute the radiometric response function and the exposure of image given a sequence of image of a static outdoor scene where the illumination is changing we use group of pixel with constant behavior towards the illumination change for the response estimation and introduce a sinusoidal lighting variation model representing the daily motion of the sun to compute the exposure 
a novel model based approach to d hand tracking from monocular video is presented the d hand pose the hand texture and the illuminant are dynamically estimated through minimization of an objective function derived from an inverse problem formulation the objective function enables explicit use of texture temporal continuity and shading information while handling important self occlusion and time varying illumination the minimization is done efficiently using a quasi newton method for which we propose a rigorous derivation of the objective function gradient particular attention is given to term related to the change of visibility near self occlusion boundary that are neglected in existing formulation in doing so we introduce new occlusion force and show that using all gradient term greatly improves the performance of the method experimental result demonstrate the potential of the formulation 
generally the bag of word based image representation follows a bottom up paradigm the subsequent stage of the process feature detection feature description vocabulary construction and image representation are performed independent of the intentioned object class to be detected in such a framework combining multiple cue such a shape and color often provides below expected result this paper present a novel method for recognizing object category when using multiple cue by separating the shape and color cue color is used to guide attention by mean of a top down category specific attention map the color attention map is then further deployed to modulate the shape feature by taking more feature from region within an image that are likely to contain an object instance this procedure lead to a category specific image histogram representation for each category furthermore we argue that the method combine the advantage of both early and late fusion we compare our approach with existing method that combine color and shape cue on three data set containing varied importance of both cue namely soccer color predominance flower color and shape parity and pascal voc challenge shape predominance the experiment clearly demonstrate that in all three data set our proposed framework significantly outperforms the state ofthe art method for combining color and shape information 
graphical model such a bayesian network bns are being increasingly applied to various computer vision problem one bottleneck in using bn is that learning the bn model parameter often requires a large amount of reliable and representative training data which prof to be difficult to acquire for many computer vision task on the other hand there is often available qualitative prior knowledge about the model such knowledge come either from domain expert based on their experience or from various physical or geometric constraint that govern the object we try to model unlike the quantitative prior the qualitative prior is often ignored due to the difficulty of incorporating them into the model learning process in this paper we introduce a closed form solution to systematically combine the limited training data with some generic qualitative knowledge for bn parameter learning to validate our method we compare it with the maximum likelihood ml estimation method under sparse data and with the expectation maximization em algorithm under incomplete data respectively to further demonstrate it application for computer vision we apply it to learn a bn model for facial action unit au recognition from real image data the experimental result show that with simple and generic qualitative constraint and using only a small amount of training data our method can robustly and accurately estimate the bn model parameter 
we address the character identification problem in movie and television video assigning name to face on the screen most prior work on person recognition in video assumes some supervised data such a screenplay or handlabeled face in this paper our only source of supervision are the dialog cue first second and third person reference such a i m jack hey jack and jack left while this kind of supervision is sparse and indirect we exploit multiple modality and their interaction appearance dialog mouth movement synchrony continuityediting cue to effectively resolve identity through local temporal grouping followed by global weakly supervised recognition we propose a novel temporal grouping model that partition face track across multiple shot while respecting appearance geometric and film editing cue and constraint in this model state represent partition of the k most recent face track and transition represent compatibility of consecutive partition we present dynamic programming inference and discriminative learning for the model the individual face track are subsequently assigned a name by learning a classifier from partial label constraint the weakly supervised classifier incorporates multiple instance constraint from dialog cue a well a soft grouping constraint from our temporal grouping we evaluate both the temporal grouping and final character naming on several hour of tv and movie 
image of an object undergoing egoor camera motion often appear to be scaled rotated and deformed version of each other to detect and match such distorted pattern to a single sample view of the object requires solving a hard computational problem that ha eluded most object matching method we propose a linear formulation that simultaneously find feature point correspondence and global geometrical transformation in a constrained solution space further reducing the search space based on the lower convex hull property of the formulation our method scale well with the number of candidate feature our result on a variety of image and video demonstrate that our method is accurate efficient and robust over local deformation occlusion clutter and large geometrical transformation 
multiple instance learning mil provides a framework for training a discriminative classifier from data with ambiguous label this framework is well suited for the task of learning object classifier from weakly labeled image data where only the presence of an object in an image is known but not it location some recent work ha explored the application of mil algorithm to the task of image categorization and natural scene classification in this paper we extend these idea in a framework that us mil to recognize and localizeobjects in image to achieve this we employ state of the art image descriptor and multiple stable segmentation these component combined with a powerful mil algorithm form our object recognition system called mil we show highly competitive object categorization result on the caltech dataset to evaluate the performance of our algorithm further we introduce the challenging landmark dataset a collection of photograph of famous landmark from around the world the result on this new dataset show the great potential of our proposed algorithm 
we propose a method for estimating the pose of a human body using it approximate d volume visual hull obtained in real time from synchronized video our method can cope with loose fitting clothing which hide the human body and produce non rigid motion and critical reconstruction error a well a tight fitting clothing to follow the shape variation robustly against erratic motion and the ambiguity between a reconstructed body shape and it pose the probabilistic dynamical model of human volume is learned from training temporal volume refined by error correction the dynamical model of a body pose joint angle is also learned with it corresponding volume by comparing the volume model with an input visual hull and regressing it pose from the pose model pose estimation can be realized in our method this is improved by double volume comparison comparison in a low dimensional latent space with probabilistic volume model and comparison in an observation volume space using geometric constrains between a real volume and a visual hull comparative experiment demonstrate the effectiveness of our method faster than existing method 
multilinear algebra is a powerful theoretical tool for visual geometry but widespread usage of traditional typographical notation often hide it conceptual elegance and simplicity a demonstrated in other scientific field we can take full advantage of multilinear method using graphical notation in this paper we adapt standard tensor diagrammatic technique to the specific requirement of visual geometry so that geometric relation are represented by circuit which can be manipulated using simple rule the advantage of this approach are illustrated in several construction including straightforward derivation of the standard multiview relation fundamental matrix trifocal and quadrifocal tensor and nearly mechanical procedure for camera extraction 
we present an efficient multi stage approach to detection of deformable object in real cluttered image given a single or few hand drawn example a model the method handle deformation of the object by first breaking the given model into segment at high curvature point we allow bending at these point a it ha been studied that deformation typically happens at high curvature point the broken segment are then scaled rotated deformed and searched independently in the gradient image point map are generated for each segment that represent the location of the match for that segment we then group kpoints from the point map of kadjacent segment using a cost function that take into account local scale variation a well a inter segment orientation these matched group yield plausible location for the object in the fine matching stage the entire object contour in the localized region is built from the k segment group and given a comprehensive score in a method that us dynamic programming an evaluation of our algorithm on a standard dataset yielded result that are better than published work on the same dataset at the same time we also evaluate our algorithm on additional image with considerable object deformation to verify the robustness of our method 
in this paper we propose multivariate tensor based surface morphometry a new method for surface analysis using holomorphic differential we also apply it to study brain anatomy differential form provide a natural way to parameterize d surface but the multivariate statistic of the resulting surface metric have not previously been investigated we computed new statistic from the riemannian metric tensor that retain the full information in the deformation tensor field we present the canonical holomorphic one form with improved numerical accuracy and computational efficiency we applied this framework to d mri data to analyze hippocampal surface morphometry in alzheimer s disease ad subject lateral ventricular surface morphometry in hiv aid subject and biomarkers in lateral ventricle in hiv aid subject experimental result demonstrated that our method powerfully detected brain surface abnormality multivariate statistic on the local tensor outperformed other tbm method including analysis of the jacobian determinant the largest eigenvalue or the pair of eigenvalue of the surface jacobian matrix 
in this paper we introduce a learning approach to improve the efficiency of manual image annotation although important in practice manual image annotation ha rarely been studied in a quantitative way we propose formal model to characterize the annotation time for two commonly used manual annotation approach i e tagging and browsing the formal model make clear the complementary property of these two approach and inspire a learning based hybrid annotation algorithm our experiment show that the proposed algorithm can achieve up to a reduction in annotation time over baseline method 
partially occluded face are common in many application of face recognition while algorithm based on sparse representation have demonstrated promising result they achieve their best performance on occlusion that are not spatially correlated i e random pixel corruption we show that such sparsity based algorithm can be significantly improved by harnessing prior knowledge about the pixel error distribution we show how a markov random field model for spatial continuity of the occlusion can be integrated into the computation of a sparse representation of the test image with respect to the training image our algorithm efficiently and reliably identifies the corrupted region and excludes them from the sparse representation extensive experiment on both laboratory and real world datasets show that our algorithm tolerates much larger fraction and variety of occlusion than current state of the art algorithm 
in this paper we propose a two dimensional active learning scheme and show it application in image classification traditional active learning method select sample only along the sample dimension while this is the right strategy in binary classification it is sub optimal for multilabel classification in multi label classification we argue that for each selected sample only a part of more effective label are necessary to be annotated while others can be inferred by exploring the correlation among the label the reason is that the contribution of different label to minimizing the classification error are different due to the inherent label correlation to this end we propose to select sample label pair rather than only sample to minimize a multi label bayesian classification error bound this new active learning strategy not only considers the sample dimension but also the label dimension and we call it two dimensional active learning dal we also show that the traditional active learning formulation is a special case of dal when there is only one label extensive experiment conducted on two real world application show that the dal significantly outperforms the best existing approach which did not take label correlation into account 
while low dimensional image representation have been very popular in computer vision they suffer from two limitation i they require collecting a large and varied training set to learn a low dimensional set of basis function and ii they do not retain information about the d geometry of the object being imaged in this paper we show that it is possible to estimate low dimensional manifold that describe object appearance while retaining the geometrical information about the d structure of the object by using a combination of analytically derived geometrical model and statistical learning method this can be achieved using a much smaller training set than most of the existing approach specifically we derive a quadrilinear manifold of object appearance that can represent the effect of illumination pose identity and deformation and the basis function of the tangent space to this manifold depend on the d surface normal of the object we show experimental result on constructing this manifold and how to efficiently track on it using an inverse compositional algorithm number of example of the object s appearance and the accuracy of the method depends upon the example that have been chosen for the training phase representation of appearance that have not been seen during the training phase can be inaccurate second these representation do not retain any information about the d structure of the object although the appearance must depend upon the d shape this make it difficult to understand the physical implication of the learned basis function in mathematical modeling term this is a purely data driven approach 
higher order energy function have the ability to encode high level structural dependency between pixel which have been shown to be extremely powerful for image labeling problem their use however is severely hampered in practice by the intractable complexity of representing and minimizing such function we observed that higher order function encountered in computer vision are very often sparse i e many labelings of a higher order clique are equally unlikely and hence have the same high cost in this paper we address the problem of minimizing such sparse higher order energy function our method work by transforming the problem into an equivalent quadratic function minimization problem the resulting quadratic function can be minimized using popular message passing or graph cut based algorithm for map inference although this is primarily a theoretical paper it also show how higher order function can be used to obtain impressive result for the binary texture restoration problem 
to achieve more accurate and consistent registration in an image population a novel hierarchical groupwise registration framework called atlas building by self organized registration and bundling absorb is proposed in this paper in this new framework the global structure i e the relative distribution of subject image is always preserved during the registration process by constraining each subject image to deform only locally with respect to it neighbor within the learned image manifold to achieve this goal two novel strategy i e the self organized registration by warping one image towards a set of it eligible neighbor and image bundling to cluster similar image are specially proposed by using these two strategy this new framework can perform groupwise registration in a hierarchical way specifically in the high level it will perform on a much smaller dataset formed by the representative subject image of all subgroup that are generated in the previous level of registration compared to the other groupwise registration method our proposed framework ha several advantage it explores the local data distribution and us the obtained distribution information to guide the registration the possible registration error can be greatly reduced by requiring each individual subject to move only towards it nearby subject with similar structure it can produce a smoother registration path in general from each subject image to the final built atlas than other groupwise registration method experimental result on both synthetic and real datasets show that the proposed framework can achieve substantial improvement compared to the other two widely used groupwise registration method in term of both registration accuracy and robustness 
we address the problem of image search on a very large scale where three constraint have to be considered jointly the accuracy of the search it efficiency and the memory usage of the representation we first propose a simple yet efficient way of aggregating local image descriptor into a vector of limited dimension which can be viewed a a simplification of the fisher kernel representation we then show how to jointly optimize the dimension reduction and the indexing algorithm so that it best preserve the quality of vector comparison the evaluation show that our approach significantly outperforms the state of the art the search accuracy is comparable to the bag of feature approach for an image representation that fit in byte searching a million image dataset take about m 
we present a streaming framework for seamless building reconstruction from huge aerial lidar point set by storing data a stream file on hard disk and using main memory a only a temporary storage for ongoing computation we achieve efficient out of core data management this give u the ability to handle data set with hundred of million of point in a uniform manner by adapting a building modeling pipeline into our streaming framework we create the whole urban model of atlanta from gb lidar data with m point in under hour using le than gb memory to integrate this complex modeling pipeline with our streaming framework we develop a state propagation mechanism and extend current reconstruction algorithm to handle the large scale of data 
a video sequence of an underwater scene taken from above the water surface suffers from severe distortion due to water fluctuation in this paper we simultaneously estimate the shape of the water surface and recover the planar underwater scene without using any calibration pattern image prior multiple viewpoint or active illumination the key idea is to build a compact spatial distortion model of the water surface using the wave equation based on this model we present a novel tracking technique that is designed specifically for water surface and address two unique challenge the absence of an object model or template and the presence of complex appearance change in the scene due to water fluctuation we show the effectiveness of our approach on both simulated and real scene with text and texture 
we propose a novel hashing scheme for image retrieval clustering and automatic object discovery unlike commonly used bag of word approach the spatial extent of image feature is exploited in our method the geometric information is used both to construct repeatable hash key and to increase the discriminability of the description each hash key combine visual appearance visual word with semi local geometric information compared with the state of the art min hash the proposed method ha both higher recall probability of collision for hash on the same object and lower false positive rate random collision the advantage of geometric min hashing approach are most pronounced in the presence of viewpoint and scale change significant occlusion or small physical overlap of the viewing field we demonstrate the power of the proposed method on small object discovery in a large unordered collection of image and on a large scale image clustering problem 
in this paper we present an algorithm to probabilistically estimate object shape in a d dynamic scene using their silhouette information derived from multiple geometrically calibrated video camcorder the scene is represented by a d volume every object in the scene is associated with a distinctive label to represent it existence at every voxel location the label link together automatically learned view specific appearance model of the respective object so a to avoid the photometric calibration of the camera generative probabilistic sensor model can be derived by analyzing the dependency between the sensor observation and object label bayesian reasoning is then applied to achieve robust reconstruction against real world environment challenge such a lighting variation changing background etc our main contribution is to explicitly model the visual occlusion process and show static object such a tree or lamp post a part of the pre learned background model can be automatically recovered a a byproduct of the inference ambiguity due to inter occlusion between multiple dynamic object can be alleviated and the final reconstruction quality is drastically improved several indoor and outdoor real world datasets are evaluated to verify our framework 
a richer model for stereo vision are constructed there is a growing interest in learning model parameter to estimate parameter in markov random field mrf based stereo formulation one usually need to perform approximate probabilistic inference message passing algorithm based on variational method and belief propagation are widely used for approximate inference in mrfs conditional random field crfs are discriminative version of traditional mrfs and have recently been applied to the problem of stereo vision however crf parameter training typically requires expensive inference step for each iteration of optimization inference is particularly slow when there are many discrete disparity level due to high state space cardinality we present a novel crf for stereo matching with an explicit occlusion model and propose sparse message passing to dramatically accelerate the approximate inference needed for parameter optimization we show that sparse variational message passing iteratively minimizes the kl divergence between the approximation and model distribution by optimizing a lower bound on the partition function our experimental result show reduction in inference time of one order of magnitude with no loss in approximation quality learning using sparse variational message passing improves result over prior work using graph cut 
we introduce a new image representation that encompasses both the general layout of group of quantized local invariant descriptor a well a their relative frequency a graph of interest point cluster is constructed and we use the matrix of commute time between the different node of the graph to obtain a description of their relative arrangement that is robust to large intra class variation the obtained high dimensional representation is then embedded in a space of lower dimension by exploiting the spectral property of the graph made of the different image classification task can be performed in this embedding space we expose classification and labelling result obtained on three different datasets including the challe nging pascal voc dataset the performance of our approach compare favorably with the standard bag of feature which is a particular case of our representation 
we present a higher level visual representation visual synset for object categorization the visual synset improves the traditional bag of word representation with better discrimination and invariance power first the approach strengthens the inter class discrimination power by constructing an intermediate visual descriptor delta visual phrase from frequently co occurring visual word set with similar spatial context second the approach achieves better intra class invariance power by clustering delta visual phrase into visual synset based their probabilistic semantics i e class probability distribution hence the resulting visual synset can partially bridge the visual difference of image of same class the test on caltech and pascalvoc dataset demonstrated that the proposed image representation can achieve good accuracy 
extremely crowded scene present unique challenge to video analysis that cannot be addressed with conventional approach we present a novel statistical framework for modeling the local spatio temporal motion pattern behavior of extremely crowded scene our key insight is to exploit the dense activity of the crowded scene by modeling the rich motion pattern in local area effectively capturing the underlying intrinsic structure they form in the video in other word we model the motion variation of local spacetime volume and their spatial temporal statistical behavior to characterize the overall behavior of the scene we demonstrate that by capturing the steady state motion behavior with these spatio temporal motion pattern model we can naturally detect unusual activity a statistical deviation our experiment show that local spatio temporal motion pattern modeling offer promising result in realworld scene with complex activity that are hard for even human observer to analyze 
a major reason leading to tracking failure is the spatial distraction that exhibit similar visual appearance a the target because they also generate good match to the target and thus distract the tracker it is in general very difficult to handle this situation in a selective attention tracking paradigm this paper advocate a new approach of discriminative spatial attention that identifies some special region on the target called attentional region ar the ar show strong discriminative power in their discriminative domain where they do not observe similar thing this paper present an efficient two stage method that divide the discriminative domain into a local and a semi local one in the local domain the visual appearance of an attentional region is locally linearized and it discriminative power is closely related to the property of the associated linear manifold so that a gradient based search is designed to locate the set of local ar based on that the set of semi local ar are identified through an efficient branch and bound procedure that guarantee the optimality extensive experiment show that such discriminative spatial attention lead to superior performance in many challenging target tracking task 
belief propagation bp can be very useful and efficient for performing approximate inference on graph but when the graph is very highly connected with strong conflicting interaction bp tends to fail to converge generalized belief propagation gbp provides more accurate solution on such graph by approximating kikuchi free energy but the cluster required for the kikuchi approximation are hard to generate we propose a new algorithmic way of generating such cluster from a graph without exponentially increasing the size of the graph during triangulation in order to perform the statistical region labeling we introduce the use of superpixels for the node of the graph a it is a more natural representation of an image than the pixel grid this result in a smaller but much more highly interconnected graph where bp consistently fails we demonstrate how our version of the gbp algorithm outperforms bp on synthetic and natural image and in both case gbp converges after only a few iteration 
in this work we introduce a novel implicit representation of shape which is based on assigning to each pixel a probability that this pixel is inside the shape this probabilistic representation of shape resolve two important drawback of alternative implicit shape representation such a the level set method firstly the space of shape is convex in the sense that arbitrary convex combination of a set of shape again correspond to a valid shape secondly we prove that the introduction of shape prior into variational image segmentation lead to functionals which are convex with respect to shape deformation for a large class of commonly considered spatially continuous functionals we prove that under mild regularity assumption segmentation and tracking with statistical shape prior can be performed in a globally optimal manner in experiment on tracking a walking person through a cluttered scene we demonstrate the advantage of global versus local optimality 
in this paper we propose a partially blurred image classication and analysis framework for automatically detecting image containing blurred region and recognizing the blur type for those region without needing to perform blur kernel estimation and image deblurring we develop several blur feature modeled by image color gradient and spectrum information and use feature parameter training to robustly classify blurred image our blur detection is based on image patch making region wise training and classication in one image efcient extensive experiment show that our method work satisfactorily on challenging image data which establishes a technical foundation for solving several computer vision problem such a motion analysis and image restoration using the blur information 
non rigid object detection and articulated pose estimation are two related and challenging problem in computer vision numerous model have been proposed over the year and often address different special case such a pedestrian detection or upper body pose estimation in tv footage this paper show that such specialization may not be necessary and proposes a generic approach based on the pictorial structure framework we show that the right selection of component for both appearance and spatial modeling is crucial for general applicability and overall performance of the model the appearance of body part is modeled using densely sampled shape context descriptor and discriminatively trained adaboost classifier furthermore we interpret the normalized margin of each classifier a likelihood in a generative model non gaussian relationship between part are represented a gaussians in the coordinate system of the joint between part the marginal posterior of each part is inferred using belief propagation we demonstrate that such a model is equally suitable for both detection and pose estimation task outperforming the state of the art on three recently proposed datasets 
an important problem in image labeling concern learning with image labeled at varying level of specificity we propose an approach that can incorporate image with label drawn from a semantic hierarchy and can also readily cope with missing label and roughly specified object boundary we introduce a new form of latent topic model learning a novel context representation in the joint label and image space by capturing co occurring pattern within and between image feature and object label given a topic the model generates the input data a well a a topic dependent probabilistic classifier to predict label for image region we present result on two real world datasets demonstrating significant improvement gained by including the coarsely labeled image 
human face are neither exactly lambertian nor entirely convex and hence most model in literature which make the lambertian assumption fall short when dealing with specularities and cast shadow in this paper we present a novel anti symmetric tensor spline a spline for tensorvalued function based method for the estimation of the apparent brdf abrdf field for human face that seamlessly account for specularities and cast shadow furthermore unlike other method it doe not require any d information to build the model and can work with a few a image in order to validate the accuracy of our antisymmetric tensor spline model we present a novel approximation of the abrdf using a continuous mixture of singlelobed spherical function we demonstrate the effectiveness of our anti symmetric tensor spline model in comparison to other popular model in the literature by presenting extensive result for face relighting and face recognition using the extended yale b database 
ranking large scale image and video collection usually expects higher accuracy on top ranked data while tolerates lower accuracy on bottom ranked one in view of this we propose a rank learning algorithm called imbalanced rankboost which merges rankboost and iterative thresholding into a unified loss optimization framework the proposed approach provides a more efficient ranking process by iteratively identifying a cutoff threshold in each boosting iteration and automatically truncating ranking feature computation for the data ranked below experiment on the trecvid high level feature benchmark show that the proposed approach outperforms rankboost in term of both ranking effectiveness and efficiency it achieves an up to improvement in term of mean average precision or equivalently a fold speedup in the ranking process 
we introduce a convex relaxation framework to optimally minimize continuous surface ratio the key idea is to minimize the continuous surface ratio by solving a sequence of convex optimization problem we show that such minimal ratio are superior to traditionally used minimal surface formulation in that they do not suffer from a shrinking bias and no longer require the choice of a regularity parameter the absence of a shrinking bias in the minimal ratio model is proven analytically furthermore we demonstrate that continuous ratio optimization can be applied to derive a new algorithm for reconstructing three dimensional silhouette consistent object from multiple view experimental result confirm that our approach allows to accurately reconstruct deep concavity even without the specification of tuning parameter 
we present a novel single image deblurring method to estimate spatially non uniform blur that result from camera shake we use existing spatially invariant deconvolution method in a local and robust way to compute initial estimate of the latent image the camera motion is represented a a motion density function mdf which record the fraction of time spent in each discretized portion of the space of all possible camera pose spatially varying blur kernel are derived directly from the mdf we show that d camera motion is well approximated by degree of motion in plane translation and rotation and analyze the scope of this approximation we present result on both synthetic and captured data our system out performs current approach which make the assumption of spatially invariant blur 
illuminant estimation from shadow typically relies on accurate segmentation of the shadow and knowledge of exact d geometry while shadow estimation is difficult in the presence of texture these can be onerous requirement in this paper we propose a graphical model to estimate the illumination environment and detect the shadow of a scene with textured surface from a single image and only coarse d information we represent the illumination environment a a mixture of von mi fisher distribution then each shadow pixel becomes the combination of sample generated from this illumination environment we integrate a number of low level illumination invariant d cue in a graphical model to detect and estimate cast shadow on textured surface both d cue and approximate d reasoning are combined to infer a set of label that identify the shadow in the image and estimate the position shape and intensity of the light source our result demonstrate that the probabilistic combination of multiple cue unlike prior approach manages to differentiate both hard and soft shadow from the underlying surface texture even when we can only coarsely anticipate the effect of d geometry we also experimentally demonstrate how correct estimation of the sharpness and shape of the light source improves the augmented reality result 
we propose a hybrid body representation that represents each typical pose by both template like view information and part based structural information specifically each body part a well a the whole body are represented by an off line learned shape model where both region based and edge based prior are combined in a coupled shape representation part based spatial prior are represented by a ldquostarrdquo graphical model this hybrid body representation can synergistically integrate pose recognition localization and segmentation into one computational flow moreover a an important step for feature extraction and model inference segmentation is involved in the low level mid level and high level vision stage where top down prior knowledge and bottom up data processing is well integrated via the proposed hybrid body representation 
the geometric median is a classic robust estimator of centrality for data in euclidean space in this paper we formulate the geometric median of data on a riemannian manifold a the minimizer of the sum of geodesic distance to the data point we prove existence and uniqueness of the geometric median on manifold with non positive sectional curvature and give sufficient condition for uniqueness on positively curved manifold generalizing the weiszfeld procedure for finding the geometric median of euclidean data we present an algorithm for computing the geometric median on an arbitrary manifold we show that this algorithm converges to the unique solution when it exists this method produce a robust central point for data lying on a manifold and should have use in a variety of vision application involving manifold we give example of the geometric median computation and demonstrate it robustness for three type of manifold data the d rotation group tensor manifold and shape space 
we propose a novel geometric rao blackwellized particle filtering framework for monocular slam with locally planar landmark we represent the state for the camera pose and the landmark plane normal a se and so respectively which are both lie group the measurement error is also represented a another lie group sl corresponding to the space of homography matrix we then formulate the unscented transformation on lie group for optimal importance sampling and landmark estimation via unscented kalman filter the feasibility of our framework is demonstrated via various experiment 
in this paper we propose a group sensitive multiple kernel learning g mkl method to accommodate the intra class diversity and the inter class correlation for object categorization by introducing an intermediate representation group between image and object category g mkl attempt to find appropriate kernel combination for each group to get a finer depiction of object category for each category image within a group share a set of kernel weight while image from different group may employ distinct set of kernel weight in g mkl such group sensitive kernel combination together with the multi kernel based classifier are optimized in a joint manner to seek a trade off between capturing the diversity and keeping the invariance for each category extensive experiment show that our proposed g mkl method ha achieved encouraging performance over three challenging datasets 
we propose an approach for learning visual model of object category in an unsupervised manner in which we first build a large scale complex network which capture the interaction of all unit visual feature across the entire training set and we infer information such a which feature are in which category directly from the graph by using link analysis technique the link analysis technique arebasedonwell establishedgraphminingtechniquesused in diverse application such a www bioinformatics and social network the techniquesoperate directly on the pattern of connection between feature in the graph rather thanon statistical property e g from clustering in feature space we argue that the resulting technique are simpler and we show that they perform similarly or better compared to state of the art technique on common data set we also show result on more challenging data set than those that have been used in prior work on unsupervised modeling 
the goal of this work is to automatically learn a large number of british sign language bsl sign from tv broadcast we achieve this by using the supervisory information available from subtitle broadcast simultaneously with the signing this supervision is both weak and noisy it is weak due to the correspondence problem since temporal distance between sign and subtitle is unknown and signing doe not follow the text order it is noisy because subtitle can be signed in different way and because the occurrence of a subtitle word doe not imply the presence of the corresponding sign the contribution are i we propose a distance function to match signing sequence which includes the trajectory of both hand the hand shape and orientation and properly model the case of hand touching ii we show that by optimizing a scoring function based on multiple instance learning we are able to extract the sign of interest from hour of signing footage despite the very weak and noisy supervision the method is automatic given the english target word of the sign to be learnt result are presented for word including noun verb and adjective 
warping is fundamental to multiple algorithm in computervision andmedical imagingsuchasimage andvolume registration warping is performed by determining a continuous deformation map and applying it to a given image or volume in registration the deformation map is determined based on correspondence between two image it is often the case that the deformation map can only be determined at discrete location and so ha to be interpolated the discrete location where the deformation map is determined form irregular sampling of the unknown continuous deformation map thin plate spline are commonly used to perform the interpolation and provide an optimal solution in the sense of bending energy minimization assuming n sample of the deformation map and n image pixel thin plate spline require solving a n n dense linear system with o n complexity for determining spline coefficient and n computation per pixel with o nn complexity for determining interpolated value when n and n are large a in the case of volumetric medical image analysisthis cost becomes prohibitive the approach proposed in this paper is based on subdivisionsurfaces and is capableof achieving similar quality result with o n log n complexity for coefficient determination and o n complexity for computing interpolated value experimental result demonstrate two order of magnitude performance improvement on actual clinical data a continuous deformation field the given value of the deformation map are normally irregular sample of the continuous deformation map thin plate spline tps are commonly used for interpolating deformation map based on irregular sample tps are based on radial basis function and are optimal in the sense of minimizing the bending energy of the map tps is capable of modeling arbitrary non rigid deformation in it regularized form the tps model includes the affine model a a special case the computational cost of tps becomes prohibitive when the number of sample is large let n be the number of sample of a deformation map and n be the number of pixel in an image using tps requires the solution of a n n dense system with o n complexity for determining interpolation coefficient and evaluation of a radial basis function at n location per pixel for interpolation with o nn complexity 
we present a hierarchical principle for object recognition and it application to automatically classify developmental stage of c elegans animal from a population of mixed stage the object recognition machine consists of four hierarchical layer each composed of unit upon which evaluation function output a label score followed by a grouping mechanism that resolve ambiguity in the score by imposing local consistency constraint each layer then output group of unit from which the unit of the next layer are derived using this hierarchical principle the machine build up successively more sophisticated representation of the object to be classified the algorithm segment large and small object decomposes object into part extract feature from these part and classifies them by svm we are using this system to analyze phenotypic data from c elegans high throughput genetic screen and our system overcomes a previous bottleneck in image analysis by achieving near real time scoring of image data the system is in current use in a functioning c elegans laboratory and ha processed over two hundred thousand image for lab user 
we propose a convex framework for silhouette and stereo fusion in d reconstruction from multiple image the key idea is to show that the reconstruction problem can be cast a one of minimizing a convexfunctional where the exact silhouette consistency is imposed a a convex constraint that restricts the domain of admissible function a a consequence we can retain the original stereo weighted surface area a a cost functional without heuristic modification by balloon term or other strategy yet still obtain meaningful nonempty global minimizers compared to previous method the introduced approach doe not depend on initialization and lead to a more robust numerical scheme by removing the bias near the visual hull boundary we propose an efficient parallel implementation of this convex optimization problem on a graphic card based on a photoconsistency map and a set of image silhouette we are therefore able to compute highly accurate and silhouette consistent reconstruction for challenging real world data set in le than one minute 
in this paper we propose a novel computational method to infer visual saliency in image the method is based on the idea that salient object should have local characteristic that are different than the rest of the scene being edge color or shape by using a novel operator these characteristic are combined to infer global information the obtained information is used a a weighting for the output of a segmentation algorithm so that the salient object in the scene can easily be distinguished from the background the proposed approach is fast and it doe not require any learning the experimentation show that the system can enhance interesting object in image and it is able to correctly locate the same object annotated by human with an f measure of when the object size is known and when the object size is unknown improving the state of the art performance on a public dataset 
in this paper we propose a novel framework for video based facial expression recognition which can handle the data with various time resolution including a single frame we first use the haar like feature to represent facial appearance due to their simplicity and effectiveness then we perform k mean clustering on the facial appearance feature to explore the intrinsic temporal pattern of each expression based on the temporal pattern model we further map the facial appearance variation into dynamic binary pattern finally boosting learning is performed to construct the expression classifier compared to previous work the dynamic binary pattern encode the intrinsic dynamic of expression and our method make no assumption on the time resolution of the data extensive experiment carried on the cohn kanade database show the promising performance of the proposed method 
we address the alignment of a group of image with simultaneous registration therefore we provide further insight into a recently introduced class of multivariate similarity measure referred to a accumulated pair wise estimate ape and derive efficient optimization method for it more specifically we show a strict mathematical deduction of ape from a maximum likelihood framework and establish a connection to the congealing framework this is only possible after an extension of the congealing framework with neighborhood information moreover we address the increased computational complexity of simultaneous registration by deriving efficient gradient based optimization strategy for ape gau newton and the efficient second order minimization esm we present next to ssd the usage of the intrinsically non squared similarity measure ncc cr and mi in this least square optimization framework finally we evaluate the performance of the optimization strategy with respect to the similarity measure obtaining very promising result for esm 
establishing visual correspondence is an essential component of many computer vision problem and is often done with robust local feature descriptor transmission and storage of these descriptor are of critical importance in the context of mobile distributed camera network and large indexing problem we propose a framework for computing low bit rate feature descriptor with a time reduction in bit rate the framework is low complexity and ha significant speed up in the matching stage we represent gradient histogram a tree structure which can be efficiently compressed we show how to efficiently compute distance between descriptor in their compressed representation eliminating the need for decoding we perform a comprehensive performance comparison with sift surf and other low bit rate descriptor and show that our proposed chog descriptor outperforms existing scheme 
in this paper we introduce a novel algorithm to solve global shape registration problem we use gray scale image to represent source shape and propose a novel two component gaussian mixture gm distance map representation for target shape based on this flexible asymmetric image based representation a new energy function is defined it prof to be a more robust shape dissimilarity metric that can be computed efficiently such high efficiency is essential for global optimization method we adopt one of them the particle swarm optimization pso to effectively estimate the global optimum of the new energy function experiment and comparison performed on generalized shape data including continuous shape unstructured sparse point set and gradient map demonstrate the robustness and effectiveness of the algorithm 
this paper present a general solution to the determination of the pose of a perspective camera with unknown focal length from image of four d reference point our problem is a generalization of the p p and p p problem previously developed for fully calibrated camera given four d to d correspondence we estimate camera position orientation and recover the camera focal length we formulate the problem and provide a minimal solution from four point by solving a system of algebraic equation we compare the hidden variable resultant and gr obner basis technique for solving the algebraic equation of our problem by evaluating them on synthetic and on real data we show that the gr obner basis technique provides stable result 
we introduce a novel data driven mean shift belief propagation ddmsbp method for non gaussian mrfs which often arise in computer vision application with the aid of scale space theory optimization of non gaussian multimodal mrf model using ddmsbp becomes le sensitive to local maximum this is a significant improvement over standard bp inference and extends the range of method that are computationally tractable in particular when pair wise potential are gaussians the time complexity of ddmsbp becomes bilinear in the number of state and node in the mrf experimental result from simulation and non rigid deformable neuroimage registration demonstrate that our method is faster and more accurate than state of the art inference algorithm 
both detection and tracking people are challenging problem especially in complex real world scene that commonly involve multiple people complicated occlusion and cluttered or even moving background people detector have been shown to be able to locate pedestrian even in complex street scene but false positive have remained frequent the identification of particular individual ha remained challenging a well on the other hand tracking method are able to find a particular individual in image sequence but are severely challenged by real world scenario such a crowded street scene in this paper we combine the advantage of both detection and tracking in a single framework the approximate articulation of each person is detected in every frame based on local feature that model the appearance of individual body part prior knowledge on possible articulation and temporal coherency within a walking cycle are modeled using a hierarchical gaussian process latent variable model hgplvm we show how the combination of these result improves hypothesis for position and articulation of each person in several subsequent frame we present experimental result that demonstrate how this allows to detect and track multiple people in cluttered scene with reoccurring occlusion 
method for super resolution can be broadly classified into two family of method i the classical multi image super resolution combining image obtained at subpixel misalignment and ii example based super resolution learning correspondence between low and high resolution image patch from a database in this paper we propose a unified framework for combining these two family of method we further show how this combined approach can be applied to obtain super resolution from a little a a single image with no database or prior example our approach is based on the observation that patch in a natural image tend to redundantly recur many time inside the image both within the same scale a well a across different scale recurrence of patch within the same image scale at subpixel misalignment give rise to the classical super resolution whereas recurrence of patch across different scale of the same image give rise to example based super resolution our approach attempt to recover at each pixel it best possible resolution increase based on it patch redundancy within and across scale 
this paper introduces a new sparsity prior to the estimation of dense flow field based on this new prior a complex flow field with motion discontinuity can be accurately estimated by finding the sparsest representation of the flow field in certain domain in addition a stronger additional sparsity constraint on the flow gradient is incorporated into the model to cope with the measurement noise robust estimation technique are also employed to identify the outlier and to refine the result this new sparsity model can accurately and reliably estimate the entire dense flow field from a small portion of measurement when other measurement are corrupted by noise experiment show that our method significantly outperforms traditional method that are based on global or piecewise smoothness prior 
a new framework termed spatially aligned pyramid matching is proposed for near duplicate image identification the proposed method robustly handle spatial shift a well a scale change image are divided into both overlapped and non overlapped block over multiple level in the first matching stage pairwise distance between block from the examined image pair are computed using sift feature and earth moverpsilas distance emd in the second stage multiple alignment hypothesis that consider piecewise spatial shift and scale variation are postulated and resolved using integer flow emd two application scenario are addressed retrieval ranking and binary classification for retrieval ranking a pyramid based scheme is constructed to fuse matching result from different partition level for binary classification a novel generalized neighborhood component analysis method is formulated that can be effectively used in tandem with svms to select the most critical matching component the proposed method are shown to clearly outperform existing method through extensive testing on the columbia near duplicate image database and another new dataset 
multi instance multi label learning miml refers to the learning problem where each example is represented by a bag collection of instance and is labeled by multiple label an example application of miml is visual object recognition in which each image is represented by multiple key point i e instance and is assigned to multiple object category in this paper we study the problem of learning a distance metric from multi instance multi label data it is significantly more challenging than the conventional setup of distance metric learning because it is difficult to associate instance in a bag with it assigned class label we propose an iterative algorithm for miml distance metric learning it first estimate the association between instance in a bag and it assigned class label and learns a distance metric from the estimated association by a discriminative analysis the learned metric will be used to update the association between instance and class label which is further used to improve the learning of distance metric we evaluate the proposed algorithm by the task of automated image annotation a well known miml problem our empirical study show an encouraging result when combining the proposed algorithm with citation knn a state of the art algorithm for multi instance learning 
we present a comparative study on how to use discriminative learning method such a classification regression and ranking to address deformable shape segmentation traditional generative model and energy minimization method suffer from local minimum by casting the segmentation into a discriminative framework the target fitting function can be steered to posse a desired shape for ease of optimization yet better characterize the relationship between shape and appearance to address the high dimensional learning challenge present in the learning framework we use a multi level approach to learning discriminative model our experimental result on left ventricle segmentation from ultrasound image and facial feature point localization demonstrate that the discriminative model outperform generative model and energy minimization method by a large margin 
we address the problem of efficient structure from motion for large unordered highly redundant and irregular ly sampled photo collection such a those found on internet photo sharing site our approach computes a smallskeletal subset of image reconstructs the skeletal set and add the remaining image using pose estimation our technique drastically reduces the number of parameter that are considered resulting in dramatic speedup while provably ap proximating the covariance of the full set of parameter to compute a skeletal image set we first estimate the accuracy of two frame reconstruction between pair of overlapping image then use a graph algorithm to select a subset of image that when reconstructed approximates the accuracy of the full set a final bundle adjustment can then optionally be used to restore any loss of accuracy 
active learning method aim to select the most informative unlabeled instance to label first and can help to focus image or video annotation on the example that will most improve a recognition system however most existing method only make myopic query for a single label at a time retraining at each iteration we consider the problem where at each iteration the active learner must select a set of example meeting a given budget of supervision where the budget is determined by the fund or time available to spend on annotation we formulate the budgeted selection task a a continuous optimization problem where we determine which subset of possible query should maximize the improvement to the classifier s objective without overspending the budget to ensure far sighted batch request we show how to incorporate the predicted change in the model that the candidate example will induce we demonstrate the proposed algorithm on three datasets for object recognition activity recognition and content based retrieval and we show it clear practical advantage over random myopic and batch selection baseline 
we present a framework for computing optimal transformation aligning one point set to another in the presence of outlier example application include shape matching and registration using for example similarity affine or projective transformation a well a multiview reconstruction problem triangulation camera pose etc while standard method like ransac essentially use heuristic to cope with outlier we seek to find the largest possible subset of consistent correspondence and the globally optimal transformation aligning the point set based on theory from computational geometry we show that this is indeed possible to accomplish in polynomial time we develop several algorithm which make efficient use of convex programming the scheme ha been tested and evaluated on both synthetic and real data for several application 
in this paper we propose using bin ratio information which is collected from the ratio between bin value of histogram for scene and category classification to use such information a new histogram dissimilarity bin ratio dissimilarity brd is designed we show that brd provides several attractive advantage for category and scene classification task first brd is robust to cluttering partial occlusion and histogram normalization second brd capture rich co occurrence information while enjoying a linear computational complexity third brd can be easily combined with other dissimilarity measure such a l and to gather complimentary information we apply the proposed method to category and scene classification task in the bag of word framework the experiment are conducted on several widely tested datasets including pascal pascal oxford flower and scene dataset in all experiment the proposed method demonstrate excellent performance in comparison with previously reported solution 
recent work showed that learning based patch rectification method are both faster and more reliable than affine region method unfortunately their performance improvement are founded in a computationally expensive offline learning stage which is not possible for application such a slam in this paper we propose an approach whose training stage is fast enough to be performed at run time without the loss of accuracy or robustness to this end we developed a very fast method to compute the mean appearance of the feature point over set of small variation that span the range of possible camera viewpoint then by simply matching incoming feature point against these mean appearance we get a coarse estimate of the viewpoint that is refined afterwards because there is no need to compute descriptor for the input image the method is very fast at run time we demonstrate our approach on trackingby detection for slam real time object detection and pose estimation application 
searching approximate nearest neighbor in large scale high dimensional data set ha been a challenging problem this paper present a novel and fast algorithm for learning binary hash function for fast nearest neighbor retrieval the nearest neighbor are defined according to the semantic similarity between the object our method us the information of these semantic similarity and learns a hash function with binary code such that only object with high similarity have small hamming distance the hash function is incrementally trained one bit at a time and a bit are added to the hash code hamming distance between dissimilar object increase we further link our method to the idea of maximizing conditional entropy among pair of bit and derive an extremely efficient linear time hash learning algorithm experiment on similar image retrieval and celebrity face recognition show that our method produce apparent improvement in performance over some state ofthe art method 
visual recognition of human action in video clip ha been an active field of research in recent year however most published method either analyse an entire video and assign it a single action label or use relatively large lookahead to classify each frame contrary to these strategy human vision prof that simple action can be recognised almost instantaneously in this paper we present a system for action recognition from very short sequence snippet of frame and systematically evaluate it on standard data set it turn out that even local shape and optic flow for a single frame are enough to achieve correct recognition and snippet of frame second of video are enough to achieve a performance similar to the one obtainable with the entire video sequence 
with the popularity of bag of visual term representation of image many text indexing technique have been applied in large scale image retrieval system however due to a fundamental difference between an image query e g visual term and a text query e g term the usage of some text indexing technique e g inverted list are misleading in this work we develop a novel indexing technique for this problem the basic idea is to decompose a document like representation of an image into two component one for dimension reduction and the other for residual information preservation the computing of similarity of two image can be transferred to measuring similarity of their component the decomposition ha two major merit these component have good property which enable them to be efficiently indexed and retrieved the decomposition ha better generalization ability than other dimension reduction algorithm the decomposition can be achieved by either a graphical model or a matrix factorization approach theoretic analysis and extensive experiment over a million image database show that this framework is scalable to index large scale image database to support fast and accurate visual search 
image to class i c distance is first used in naive bayes nearest neighbor nbnn classifier for image classification and ha successfully handled datasets with large intra class variance however the performance of this distance relies heavily on the large number of local feature in the training set and test image which need heavy computation cost for nearest neighbor nn search in the testing phase if using small number of local feature for accelerating the nn search the performance will be poor in this paper we propose a large margin framework to improve the discrimination of i c distance especially for small number of local feature by learning per class mahalanobis metric our i c distance is adaptive to different class by combining with the learned metric for each class these multiple per class metric are learned simultaneously by forming a convex optimization problem with the constraint that the i c distance from each training image to it belonging class should be le than the distance to other class by a large margin a gradient descent method is applied to efficiently solve this optimization problem for efficiency and performance improved we also adopt the idea of spatial pyramid restriction and learning i c distance function to improve this i c distance we show in experiment that the proposed method can significantly outperform the original nbnn in several prevalent image datasets and our best result can achieve state of the art performance on most datasets 
we present an efficient algorithm for continuous image recognition and feature descriptor tracking in video which operates by reducing the search space of possible interest point inside of the scale space image pyramid instead of performing tracking in d image we search and match candidate feature in local neighborhood inside the d image pyramid without computing their feature descriptor the candidate are further validated by fitting to a motion model the resulting tracked interest point are more repeatable and resilient to noise and descriptor computation becomes much more efficient because only those area of the image pyramid that contain feature are searched we demonstrate our method on real time object recognition and label augmentation running on a mobile device 
with improved sensor the amount of data available in many vision problem ha increased dramatically and allows the use of sophisticated learning algorithm to perform inference on the data however since these algorithm scale with data size pruning the data is sometimes necessary the pruning procedure must be statistically valid and a representative subset of the data must be selected without introducing selection bias information theoretic measure have been used for sampling the data retaining it original information content we propose an efficient r enyi entropy based subset selection algorithm the algorithm is first validated and then applied to two sample application where machine learning and data pruning are used in the first application gaussian process regression is used to learn object pose here it is shown that the algorithm combined with the subset selection is significantly more efficient in the second application our subset selection approach is used to replace vector quantization in a standard object recognition algorithm and improvement are shown 
we present a recursive algorithm for d surface reconstruction based on photometric stereo in the presence of highlight and self and cast shadow we assume that the surface reflectance outside the highlight can be approximated by the lambertian model the algorithm work with a few a three light source and it can be generalised for n without any difficulty furthermore this reconstruction method is able to identify area where the majority of the lighting direction result in unreliable pixel intensity providing the capability to adjust a reconstruction algorithm and improve it performance avoiding the unreliable source we report result for both artificial and real image and compare them with the result of other state of the art photometric stereo algorithm 
an efficient and robust framework for two view multiple structur e and motion segmentation is proposed to handle this otherwise recursive problem hypothesis for the model are generated by local sampling once these hypothesis are available a model selection problem is formulated which take into account the hypothesis likelihood and model complexity an explicit model for outlier is also added for robust model selection the model selection criterion is optimized through branch and bound technique of combinatorial optimization which guaranty optimality over current set of hypothesis by efficient search of solution space segmentation of structure and motion is a vital step tow ards interpretation of a dynamic scene a typical dynamic scene structure includes multiple independently moving object which is being captured by a moving camera conventional approach based on frame difference or d flow based method are restricted in segmenting such a scene frame difference based approach are limited due to requirement of camera motion compensation while d flow based approach are limited by camera model used which is typically affine to address the problem is a better way a comprehensive theory of structureand motion sam estimation from perspective image ha been developed by computer vision researcher over the year analysis of dynamic scene based on this theory also known a multi body structure and motion msam is 
we propose a novel method for automatically discovering key motion pattern happening in a scene by observing the scene for an extended period our method doe not rely on object detection and tracking and us low level feature the direction of pixel wise optical flow we first divide the video into clip and estimate a sequence of flow field each moving pixel is quantized based on it location and motion direction this is essentially a bag of word representation of clip once a bag of word representation is obtained we proceed to the screening stage using a measure called the conditional entropy after obtaining useful word we apply diffusion map diffusion map framework embeds the manifold point into a lower dimensional space while preserving the intrinsic local geometric structure finally these useful word in lower dimensional space are clustered to discover key motion pattern diffusion map embedding involves diffusion time parameter which give u ability to detect key motion pattern at different scale using multi scale analysis in addition clip which are represented in term of frequency of motion pattern can also be clustered to determine multiple dominant motion pattern which occur simultaneously providing u further understanding of the scene we have tested our approach on two challenging datasets and obtained interesting and promising result 
we present a probabilistic stick figure model that us a nonparametric bayesian distribution over tree for it structure prior stick are represented by node in a tree in such a way that their parameter distribution are probabilistically centered around their parent node this prior enables the inference procedure to learn multiple explanation for motion capture data each of which could be tree of different depth and path length thus the algorithm can automatically determine a reasonable distribution over the number of stick in a given dataset and their hierarchical relationship we provide experimental result on several motion capture datasets demonstrating the model s ability to recover plausible stick figure structure and also the model s robust behavior when faced with occlusion 
we present an extension of the classical ambrosio tortorelli approximation of the mumford shah approach for the segmentation of image with uncertain gray value resulting from measurement error and noise our approach yield a reliable precision estimate for the segmentation result and it allows to quantify the robustness of edge in noisy image and under gray value uncertainty we develop an ansatz space for such image by identifying gray value with random variable the use of these stochastic image in the minimization of energy of ambrosio tortorelli type lead to stochastic partial differential equation for the stochastic smoothed image and a stochastic phase field for the edge set for their discretization we utilize the generalized polynomial chaos expansion and the generalized spectral decomposition gsd method we demonstrate the performance of the method on artificial data a well a real medical ultrasound data 
in this paper we introduce a new shape constraint for interactive image segmentation it is an extension of veksler s star convexity prior in two way from a single star to multiple star and from euclidean ray to geodesic path global minimum of the energy function are obtained subject to these new constraint we also introduce geodesic forest which exploit the structure of shortest path in implementing the extended constraint the starconvexity prior is used here in an interactive setting and this is demonstrated in a practical system the system is evaluated by mean of a robot user to measure the amount of interaction required in a precise way we also introduce a new and harder dataset which augments the existing grabcut dataset with image and ground truth taken from the pascal voc segmentation challenge 
we present some theoretical result related to the problem of actively searching for a target in a d environment under the constraint of a maximum search time we define the object localization problem a the maximization over the search region of the lebesgue integral of the scene structure probability we study variant of the problem a they relate to actively selecting a finite set of optimal viewpoint of the scene for detecting and localizing an object we do a complexity level analysis and show that the problem variant are np complete or np hard we study the tradeoff of localizing v detecting a target object using single view and multiple view recognition under imperfect dead reckoning and an imperfect recognition algorithm these result motivate a set of property that efficient and reliable active object localization algorithm should satisfy 
atmospheric condition induced by suspended particle such a fog and haze severely degrade image quality restoring the true scene color clear day image from a single image of a weather degraded scene remains a challenging task due to the inherent ambiguity between scene albedoanddepth inthispaper weintroducea novelprobabilistic method that fully leverage natural statistic of both the albedo and depth of the scene to resolve this ambiguity our key idea is to model the image with a factorial markov random field in which the scene albedo and depth are two statistically independent latent layer we show that we may exploit natural image and depth statistic a prior on these hidden layer and factorize a single foggy image via a canonical expectation maximization algorithm with alternating minimization experimental result show that the proposed method achieves more accurate restoration compared to state of the art method that focus on only recovering scene albedo or depth individually 
abstract the computer aided diagnosis cad problem of detecting potentially diseased structure from medical image are typically distinguished by the following challenging characteristic extremely unbalanced data between negative and positive class stringent real time requirement of online execution multiple positive candidate generated for the same malignant structure that are highly correlated and spatially close to each other to address all these problem we propose a novel learning formulation to combine cascade classification and multiple instance learning mil in a unified min max framework leading to a joint optimization problem which can be converted to a tractable quadratically constrained quadratic program and efficiently solved by block coordinate optimization algorithm we apply the proposed approach to the cad problem of detecting pulmonary embolism and colon cancer from computed tomography image experimental result show that our approach significantly reduces the computational cost while yielding comparable detection accuracy to the current state of the art mil or cascaded classifier although not specifically designed for balanced mil problem the proposed method achieves superior performance on balanced mil benchmark data such a musk and image data set 
linear discriminant analysis lda which work by maximizing the within class similarity and minimizing the between class similarity simultaneously is a popular dimensionality reduction technique in pattern recognition and machine learning in real world application when labeled data are limited lda doe not work well under many situation however it is easy to obtain unlabeled data in large quantity in this paper we propose a novel dimensionality reduction method called semi supervised discriminant analysis ssda which can utilize both labeled and unlabeled data to perform dimensionality reduction in the semi supervised setting our method us a robust path based similarity measure to capture the manifold structure of the data and then us the obtained similarity to maximize the separability between different class a kernel extension of the proposed method for nonlinear dimensionality reduction in the semi supervised setting is also presented experiment on face recognition demonstrate the effectiveness of the proposed method 
recently svms using spatial pyramid matching spm kernel have been highly successful in image classification despite it popularity these nonlinear svms have a complexity o n n in training and o n in testing where n is the training size implying that it is nontrivial to scaleup the algorithm to handle more than thousand of training image in this paper we develop an extension of the spm method by generalizing vector quantization to sparse coding followed by multi scale spatial max pooling and propose a linear spm kernel based on sift sparse code this new approach remarkably reduces the complexity of svms to o n in training and a constant in testing in a number of image categorization experiment we find that in term of classification accuracy the suggested linear spm based on sparse coding of sift descriptor always significantly outperforms the linear spm kernel on histogram and is even better than the nonlinear spm kernel leading to state of the art performance on several benchmark by using a single type of descriptor 
many vision problem can be cast a optimizing the conditional probability density function p ci where i is an image and c is a vector of model parameter describing the image ideally the density function p ci would be smooth and unimodal allowing local optimization technique such a gradient descent or simplex to converge to an optimal solution quickly while preserving significant nonlinearities of the model we propose to learn a conditional probability density satisfying these desired property for the given training data set to do this we formulate a novel regression problem that find a function approximating the target density learning the regressor is challenging due to the high dimensionality of model parameter c and the complexity of relating the image and the model our approach make two contribution first we take a multilevel refinement approach by learning a series of density function each of which guide the solution of optimization algorithm increasingly converging to the correct solution second we propose a new data sampling algorithm that take into account the gradient information of the target function we have applied this learning approach to deformable shape segmentation and have achieved better accuracy than the previous method 
density of mole is a strong predictor of malignant melanoma some dermatologist advocate periodic fullbody scan for high risk patient in current practice physician compare image taken at different time instance to recognize change there is an important clinical need to follow change in the number of mole and their appearance size color texture shape in image from two different time in this paper we propose a method for finding corresponding mole in patient s skin back image at different scanning time at first a template is defined for the human back to calculate the mole normalized spatial coordinate next matching mole across image is modeled a a graph matching problem and algebraic relation between node and edge in the graph are induced in the matching cost function which contains term reflecting proximity regularization angular agreement between mole pair and agreement between the mole normalized coordinate calculated in the unwarped back template we propose and discus alternative approach for evaluating the goodness of matching we evaluate our method on a large set of synthetic data hundred of pair a well a pair of real dermatological image our proposed method compare favorably with the state of the art 
in state of the art image retrieval system an image is represented by a bag of visual word obtained by quantizing high dimensional local image descriptor and scalable scheme inspired by text retrieval are then applied for large scale image indexing and retrieval bag of word representation however reduce the discriminative power of image feature due to feature quantization and ignore geometric relationship among visual word exploiting such geometric constraint by estimating a d affine transformation between a query image and each candidate image ha been shown to greatly improve retrieval precision but at high computational cost in this paper we present a novel scheme where image feature are bundled into local group each group of bundled feature becomes much more discriminative than a single feature and within each group simple and robust geometric constraint can be efficiently enforced experiment in web image search with a database of more than one million image show that our scheme achieves a improvement in average precision over the baseline bag of word approach retrieval performance is comparable to existing full geometric verification approach while being much le computationally expensive when combined with full geometric verification we achieve a precision improvement over the baseline bag of word approach and a improvement over full geometric verification alone 
context is critical for minimising ambiguity in object detection in this work a novel context modelling framework is proposed without the need of any prior scene segmentation or context annotation this is achieved by exploring a new polar geometric histogram descriptor for context representation in order to quantify context we formulate a new context risk function and a maximum margin context mmc model to solve the minimization problem of the risk function crucially the usefulness and goodness of contextual information is evaluated directly and explicitly through a discriminant context inference method and a context confidence function so that only reliable contextual information that is relevant to object detection is utilised experiment on pascal voc and i lid datasets demonstrate that the proposed context modelling approach improves object detection significantly and outperforms a state of the art alternative context model 
in this paper we address the problem of representing human action using visual cue for the purpose of learning and recognition traditional approach model action a space time representationswhich explicitly or implicitly encode the dynamicsof an action through temporal dependency in contrast we propose a new compact and efficient representation which doe not account for such dependency instead motion sequence are represented with respect to a set of discriminative static key pose exemplar and without modeling any temporal ordering the interest is a time invariant representation that drastically simplifies learning and recognition by removing time related information such a speed or length of an action the proposed representation is equivalent to embedding action into a space definedby distancesto key poseexemplars we show howto build such embedding space of low dimension by identifying a vocabularyof highly discriminative exemplar using a forward selection to test our representation we have used a publicly available dataset which demonstrates that our method can precisely recognize action even with cluttered and non segmented sequence 
efficient segmentation of globally optimal surface in volumetric image is a central problem in many medical image analysis application intra class variance ha been successfully utilized for instance in the chan vese model especially for image without prominent edge in this paper we study the optimization problem of detecting a region volume between two coupled smooth surface by minimizing the intra class variance using an efficient polynomial time algorithm our algorithm is based on the shape probing technique in computational geometry and computes a sequence of minimum cost closed set in a derived parametric graph the method ha been validated on computer synthetic volumetric image and in x ray ctscanned datasets of plexiglas tube of known size it applicability to clinical data set wa demonstrated in human ct image data the achieved result were highly accurate with mean signed surface positioning error of the inner and outer wall of the tube of mm and mm respectively given a voxel size of mm comparing with the original chan vese method our algorithm expressed higher robustness with it polynomialtime efficiency our algorithm is ready to be extended to higher dimensional image segmentation in addition the developed technique is of it own interest we expect that it can shed some light on solving other important optimization problem arising in computer vision to the best of our knowledge the shape probing technique is for the first time introduced into the field of computer vision 
the visual world demonstrates organized spatial pattern among object or region in a scene object part in an object and low level feature in object part these class of spatial structure are inherently hierarchical in nature although seemingly quite different these spatial pattern are simply manifestation of different level in a hierarchy in this work we present a unified approach to unsupervised learning of hierarchical spatial structure from a collection of image ours is a hierarchical rule based model capturing spatial pattern where each rule is represented by a star graph we propose an unsupervised emstyle algorithm to learn our model from a collection of image we show that the inference problem of determining the set of learnt rule instantiated in an image is equivalent to finding the minimum cost steiner tree in a directed acyclic graph we evaluate our approach on a diverse set of data set of object category natural outdoor scene and image from complex street scene with multiple object 
in this paper we present a new object matching algorithm based on linear programming and a novel locally affine invariant geometric constraint previous work have shown possible way to solve the feature and object matching problem by linear programming technique to model and solve the matching problem in a linear formulation all geometric constraint should be able to be exactly or approximately reformulated into a linear form this is a major difficulty for this kind of matching algorithm we propose a novel locally affine invariant constraint which can be exactly linearized and requires a lot fewer auxiliary variable than the previous work doe the key idea behind it is that each point can be exactly represented by an affine combination of it neighboring point whose weight can be solved easily by least square the resulting overall objective function can then be solved efficiently by linear programming technique our experimental result on both rigid and non rigid object matching show the advantage of the proposed algorithm 
given an input video sequence of one person conducting a sequence of continuous action we consider the problem of jointly segmenting and recognizing action we propose a discriminative approach to this problem under a semi markov model framework where we are able to define a set of feature over input output space that capture the characteristic on boundary frame action segment and neighboring action segment respectively in addition we show that this method can also be used to recognize the person who performs in this video sequence a viterbi like algorithm is devised to help efficiently solve the induced optimization problem experiment on a variety of datasets demonstrate the effectiveness of the proposed method 
this paper present a novel approach that achieves complete matching of d dynamic surface surface are captured from multi view video data and represented by sequence of d manifold mesh in motion d video we propose to perform dense surface matching between d video frame using geodesic diffeomorphisms our algorithm us a coarse to fine strategy to derive a robust correspondence map then a probabilistic formulation is coupled with a voting scheme in order to obtain local unicity of matching candidate and a smooth mapping the significant advantage of the proposed technique compared to existing approach is that it doe not rely on a color based feature extraction process hence our method doe not lose accuracy in poorly textured region and is not bounded to be used on video sequence of a unique subject therefore our complete surface mapping can be applied to texture transfer between surface model extracted from different sequence dense motion flow estimation in d video and motion transfer from a d video to an unanimated d model experiment are performed on challenging publicly available real world datasets and show compelling result 
we present a continuous optimization framework for interactive tracking of d generic object in a single video stream the user begin with specifying the location of a target object in a small set of keyframes the system then automatically track location of the object by combining user constraint with visual measurement across the entire sequence we formulate the problem in a spacetime optimization framework that optimizes over the whole sequence simultaneously the resulting solution is consistent with visual measurement across the entire sequence while satisfying user constraint we also introduce prior term to reduce tracking ambiguity we demonstrate the power of our algorithm on tracking object with significant occlusion scale and orientation change illumination change sudden movement of object and also simultaneous tracking of multiple object we compare the performance of our algorithm with alternative method 
in this paper we describe the explicit application of articulation constraint for estimating the motion of a system of plane we relate articulation to the relative homography between plane and show that for affine camera these articulation translate into linear equality constraint on a linear least square system yielding accurate and numerically stable estimate of motion the global nature of motion estimation allows u to handle area where there is limited texture information and area that leave the field of view our result demonstrate the accuracy of the algorithm in a variety of case such a human body tracking motion estimation of rigid piecewise planar scene and motion estimation of triangulated mesh 
this paper provides a new perspective on human motion analysis namely regarding human motion in video a general discrete time signal while this seems an intuitive idea research on human motion analysis ha attracted little attention from the signal processing community sophisticated signal processing technique create important opportunity for new solution to the problem of human motion analysis this paper investigates how the deformation of human silhouette or shape during articulated motion can be used a discriminating feature to implicitly capture motion dynamic in particular we demonstrate the applicability of two widely used signal transform method namely the discrete fourier transform dft and discrete wavelet transform dwt for characterization and recognition of human motion sequence experimental result show the effectiveness of the proposed method on two state of the art data set 
inspired by weber s law this paper proposes a simple yet very powerful and robust local descriptor weber local descriptor wld it is based on the fact that human perception of a pattern depends on not only the change of a stimulus such a sound lighting et al but also the original intensity of the stimulus specifically wld consists of two component it differential excitation and orientation a differential excitation is a function of the ratio between two term one is the relative intensity difference of it neighbor against a current pixel the other is the intensity of the current pixel an orientation is the gradient orientation of the current pixel for a given image we use the differential excitation and the orientation component to construct a concatenated wld histogram feature experimental result on brodatz texture show that wld impressively outperforms the other classical descriptor e g gabor especially experimental result on face detection show a promising performance although we train only one classifier based on wld feature the classifier obtains a comparable performance to state of the art method on mit cmu frontal face test set ar face dataset and cmu profile test set 
this paper address two critical but rarely concerned issue in d face recognition wider range tolerance to pose variation and misalignment we propose a new textural hausdorff distance thd which is a compound measurement integrating both spatial and textural feature the thd is applied to a significant jet point sjp representation of face image where a varied number of shape driven sjps are detected automatically from low level edge map with rich information content the comparative experiment conducted on publicly available feret and ar face database demonstrated that the proposed approach ha a considerably wider range of tolerance against both in depth head rotation and face misalignment 
dense and accurate motion tracking is an important requirement for many video feature extraction algorithm in this paper we provide a method for computing point trajectory based on a fast parallel implementation of a recent optical flow algorithm that tolerates fast motion the parallel implementation of large displacement optical flow run about faster than the serial c version this make it practical to use in a variety of application among them point tracking in the course of obtaining the fast implementation we also proved that the fixed point matrix obtained in the optical flow technique is positive semi definite we compare the point tracking to the most commonly used motion tracker the klt tracker on a number of sequence with ground truth motion our resulting technique track up to three order of magnitude more point and is more accurate than the klt tracker it also provides a tracking density of and ha an occlusion error of compared to a density of and occlusion error of for the klt tracker compared to the particle video tracker we achieve better accuracy while retaining the ability to handle large displacement while running an order of magnitude faster 
in many case human action can be identified not only by the singular observation of the human body in motion but also property of the surrounding scene and the related object in this paper we look into this problem and propose an approach for human action recognition that integrates multiple feature channel from several entity such a object scene and people we formulate the problem in a multiple instance learning mil framework based on multiple feature channel by using a discriminative approach we join multiple feature channel embedded to the mil space our experiment over the large youtube dataset show that scene and object information can be used to complement person feature for human action recognition 
human pose estimation is the task of determining the state location orientation and scale of each body part it is important for many vision understanding application e g visual interactive gaming immersive virtual reality content based image retrieval etc however it remains a challenging task because of unknown image background presence of clutter partial occlusion and especially the high dimensional state space usually dimension in this paper we contribute to human pose estimation in two aspect first we design two efficient markov chain dynamic under the data driven markov chain monte carlo ddmcmc framework to effectively explore the complex solution space second we parse the tree structure state space into a lexicographic order according to the image observation and body topology and the optimization process is conducted in this order this realizes a much more efficient exploration than the sampling based search and exhaustive search and thus achieves a tremendous speed up experimental result demonstrate the efficiency and effectiveness of the proposed method in estimating various kind of human pose even with cluttered background poor illumination or partial self occlusion 
we present a novel method for the discovery and detection of visual object category based on decomposition using topic model the approach is capable of learning a compact and low dimensional representation for multiple visual category from multiple view point without labeling of the training instance the learnt object component range from local structure over line segment to global silhouette like description this representation can be used to discover object category in a totally unsupervised fashion furthermore we employ the representation a the basis for building a supervised multi category detection system making efficient use of training example and outperforming pure feature based representation the proposed speed ups make the system scale to large database experiment on three database show that the approach improves the state of the art in unsupervised learning a well a supervised detection in particular we improve the stateof the art on the challenging pascal multi class detection task for several category 
we propose semantic texton forest efficient and powerful new low level feature these are ensemble of decision tree that act directly on image pixel and therefore do not need the expensive computation of filter bank response or local descriptor they are extremely fast to both train and test especially compared with k mean clustering and nearest neighbor assignment of feature descriptor the node in the tree provide i an implicit hierarchical clustering into semantic textons and ii an explicit local classification estimate our second contribution the bag of semantic textons combine a histogram of semantic textons over an image region with a region prior category distribution the bag of semantic textons is computed over the whole image for categorization and over local rectangular region for segmentation including both histogram and region prior allows our segmentation algorithm to exploit both textural and semantic context our third contribution is an image level prior for segmentation that emphasizes those category that the automatic categorization belief to be present we evaluate on two datasets including the very challenging voc segmentation dataset our result significantly advance the state of the art in segmentation accuracy and furthermore our use of efficient decision forest give at least a five fold increase in execution speed 
we describe a solution to the challenging problem of estimating human body shape from a single photograph or painting our approach computes shape and pose parameter of a d human body model directly from monocular image cue and advance the state of the art in several direction first given a user supplied estimate of the subject s height and a few clicked point on the body we estimate an initial d articulated body pose and shape second using this initial guess we generate a tri map of region inside outside and on the boundary of the human which is used to segment the image using graph cut third we learn a low dimensional linear model of human shape in which variation due to height are concentrated along a single dimension enabling height constrained estimation of body shape fourth we formulate the problem of parametric human shape from shading we estimate the body pose shape and reflectance a well a the scene lighting that produce a synthesized body that robustly match the image evidence quantitative experiment demonstrate how smooth shading provides powerful constraint on human shape we further demonstrate a novel application in which we extract d human model from archival photograph and painting 
modeling moving and deforming object requires capturing a much information a possible during a very short time when using off the shelf hardware this often hinders the resolution and accuracy of the acquired model our key observation is that in a little a four frame both sparse surface positional measurement and dense surface orientation measurement can be acquired using a combination of structured light and photometric stereo resulting in high resolution model of moving and deforming object our system project alternating geometric and photometric pattern onto the object using a set of three projector and capture the object using a synchronized camera small motion among temporally close frame is compensated by estimating the optical flow of image captured under the uniform illumination of the photometric light then spatial temporal photogeometric reconstruction are performed to obtain dense and accurate point sample with a sampling resolution equal to that of the camera temporal coherence is also enforced we demonstrate our system by successfully modeling several moving and deforming real world object 
recently a large amount of research ha been devoted to automatic activity analysis typically activity have been defined by their motion characteristic and represented by trajectory these trajectory are collected and clustered to determine typical behavior this paper evaluates different similarity measure and clustering methodology to catalog their strength and weakness when utilized for the trajectory learning problem the clustering performance is measured by evaluating the correct clustering rate on different datasets with varying characteristic 
statistical approach for building non rigid deformable model such a the active appearance model aam have enjoyed great popularity in recent year but typically require tedious manual annotation of training image in this paper a learning based approach for the automatic annotation of visually deformable object from a single annotated frontal image is presented and demonstrated on the example of automatically annotating face image that can be used for building aams for fitting and tracking this approach employ the idea of initially learning the correspondence between landmark in a frontal image and a set of training image with a face in arbitrary pose using this learner virtual image of unseen face at any arbitrary pose for which the learner wa trained can be reconstructed by predicting the new landmark location and warping the texture from the frontal image view based aams are then built from the virtual image and used for automatically annotating unseen image including image of different facial expression at any random pose within the maximum range spanned by the virtually reconstructed image the approach is experimentally validated by automatically annotating face image from three different database 
a mechanism for efficient mean shift belief propagation msbp is introduced the novelty of our work is to use mean shift to perform nonparametric mode seeking on belief surface generated within the belief propagation framework belief propagation bp is a powerful solution for performing inference in graphical model however there is a quadratic increase in the cost of computation with respect to the size of the hidden variable space while the recently proposed nonparametric belief propagation nbp ha better performance in term of speed even for continuous hidden variable space computation is still slow due to the particle filter sampling process our msbp method only need to compute a local grid of sample of the belief surface during each iteration this approach need a significantly smaller number of sample than nbp reducing computation time yet it also yield more accurate and stable solution the efficiency and robustness of msbp is compared against other variant of bp on application in multi target tracking and d articulated body tracking 
the kneed walker is a physic based model derived from a planar biomechanical characterization of human locomotion by controlling torque at the knee hip and torso th e model capture a full range of walking motion with foot contact and balance constraint are used to properly handle ground collision and joint limit a prior density over walking motion is based on dynamic that are optimized for efficient cyclic gait over a wide range of natural human walking speed and step length on different slope the generative model used for monocular tracking comprises the kneed walker prior a d kinematic model constrained to be consistent with the underlying dynamic and a simple measurement model in term of appearance and optical flow the tracker is applied to people walking with varying speed on hill and with occlusion of human walking called the kneed walker it ha a torso and two leg with knee and ankle it is capable of exhibiting a wide range of plausible gait style one of the key contribution in this paper is to characterize the space of suitable joint torque we show that one can optimize a parameterization of the joint torque a a function of speed step length and ground slope to find stable human like gait in doing so we also address the proper handling of ground collision and joint limit both of which produce discontinuous motion finally based on the kneed walker we propose a simple generative model for monocular video based people tracking we demonstrate the approach on several image sequence showing that the new pose tracker is much more accurate but similarly efficient a that in over a wide range of walking speed we also show that the new tracker handle people walking on steep hill unlike kinematic based tracker the model produce physically plausible motion with no footskate 
in this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment given an input image we retrieve it best match from a large database with annotated image using our modified coarse to fine sift flow algorithm that aligns the structure within two image based on the dense scene correspondence obtained from the sift flow our system warp the existing annotation and integrates multiple cue in a markov random field framework to segment and recognize the query image promising experimental result have been achieved by our nonparametric scene parsing system on a challenging database compared to existing object recognition approach that require training for each object category our system is easy to implement ha few parameter and embeds contextual information naturally in the retrieval alignment procedure 
it is well known that the effect of illumination is mainly on the large scale feature low frequency component of a face image in solving the illumination problem for face recognition most if not all existing method either only use extracted small scale feature while discard large scale feature or perform normalization on the whole image in the latter case small scale feature may be distorted when the large scale feature are modified in this paper we argue that large scale feature of face image are important and contain useful information for face recognition a well a visual quality of normalized image moreover this paper suggests that illumination normalization should mainly perform on large scale feature of face image rather than the whole face image along this line a novel framework for face illumination normalization is proposed in this framework a single face image is first decomposed into largeand smallscale feature image using logarithmic total variation ltv model after that illumination normalization is performed on large scale feature image while small scale feature image is smoothed finally a normalized face image is generated by combination of the normalized large scale feature image and smoothed small scale feature image cmu pie and extended yaleb face database with different illumination variation are used for evaluation and the experimental result show that the proposed method outperforms existing method 
we present a technique to construct increased resolution image from multiple photo taken without moving the camera or the sensor like other super resolution technique we capture and merge multiple image but instead of moving the camera sensor by sub pixel distance for each image we change mask in the lens aperture and slightly defocus the lens the resulting capture system is simpler and tolerates modest mask registration error well we present a theoretical analysis of the camera and image merging method show both simulated result and actual result from a crudely modified consumer camera and compare it result to robust blind method that rely on uncontrolled camera displacement 
one of the principal bottleneck in applying learning technique to classification problem is the large amount of labeled training data required especially for image and video providing training data is very expensive in term of human time and effort in this paper we propose an active learning approach to tackle the problem instead of passively accepting random training example the active learning algorithm iteratively selects unlabeled example for the user to label so that human effort is focused on labeling the most useful example our method relies on the idea of uncertainty sampling in which the algorithm selects unlabeled example that it find hardest to classify specifically we propose an uncertainty measure that generalizes margin based uncertainty to the multi class case and is easy to compute so that active learning can handle a large number of class and large data size efficiently we demonstrate result for letter and digit recognition on datasets from the uci repository object recognition result on the caltech dataset and scene categorization result on a dataset of natural scene category the proposed method give large reduction in the number of training example required over random selection to achieve similar classification accuracy with little computational overhead 
level set method based segmentation provides an efficient tool for topological and geometrical shape handling conventional level set surface are only c continuous since the level set evolution involves linear interpolation to compute derivative bajaj et al present a higher order method to evaluate level set surface that are c continuous but are slow due to high computational burden in this paper we provide a higher order gpu based solver for fast and efficient segmentation of large volumetric image we also extend the higher order method to multi domain segmentation our streaming solver is efficient in memory usage 
this paper proposes an approach called dasiastructure based spectral clusteringpsila to identify cluster in motion time series for sequential pattern discovery the proposed approach deploys a dasiastatistical feature based distance computationpsila for spectral clustering algorithm compared to traditional spectral clustering approach in which the similarity matrix is constructed from the original data point by applying some similarity function the proposed approach build the matrix based on a finite set of feature vector when the proposed approach us le data point and simpler similarity function to computing the similarity matrix input for spectral clustering it can improve the computational efficiency in constructing the similarity graph in spectral clustering compared to conventional approach promising experimental result with high accuracy on real world data set demonstrate the capability and effectiveness of the proposed approach for pattern discovery in motion video sequence 
we consider the problem of recognizing human action from still image we propose a novel approach that treat the pose of the person in the image a latent variable that will help with recognition different from other work that learns separate system for pose estimation and action recognition then combine them in an ad hoc fashion our system is trained in an integrated fashion that jointly considers pose and action our learning objective is designed to directly exploit the pose information for action recognition our experimental result demonstrate that by inferring the latent pose we can improve the final action recognition result 
co occurrence feature are effective for object classification because observing co occurrence of two event is far more informative than observing occurrence of each event separately for example a color co occurrence histogram capture co occurrence of pair of color at a given distance while a color histogram just express frequency of each color a one of such co occurrence feature cohog co occurrence histogram of oriented gradient ha been proposed and a method using cohog with a linear classifier ha shown a comparable performance with state of the art pedestrian detection method according to recent study it ha been suggested that combining heterogeneous feature such a texture shape and color is useful for object classification therefore we introduce three heterogeneous feature based on co occurrence called color cohog cohed and cohd respectively each heterogeneous feature are evaluated on the inria person dataset and the oxford category flower datasets the experimental result show that color cohog is effective for the inria person dataset and cohed is effective for the oxford flower datasets by combining above heterogeneous feature the proposed method achieves comparable classification performance to state of the art method on the above datasets the result suggest that the proposed method using heterogeneous feature can be used a an off the shelf method for various object classification task 
this paper present a novel approach to achieve accurate and complete multi view reconstruction of dynamic scene or d video d video consist in sequence of d model in motion captured by a surrounding set of video camera to date d video are reconstructed using multiview wide baseline stereo mv reconstruction technique however it is still tedious to solve stereo correspondence problem reconstruction accuracy fall when stereo photo consistency is weak and completeness is limited by self occlusion most mv technique were indeed designed to deal with static object in a controlled environment and therefore cannot solve these issue hence we propose to take advantage of the image content stability provided by each single view video to recover any surface region visible by at least one camera in particular we present an original probabilistic framework to derive and predict the true surface of model we propose to fuse multi view structure from motion with robust d feature obtained by mv in order to significantly improve reconstruction completeness and accuracy a min cut problem where all exact feature serve a prior is solved in a final step to reconstruct the d model in addition experimental result were conducted on synthetic and challenging real world datasets to illustrate the robustness and accuracy of our method 
we present a novel approach to non rigid structure from motion nrsfm from an orthographic video sequence based on a new interpretation of the problem existing approach assume the object shape space is well modeled by a linear subspace our approach only assumes that small neighborhood of shape are well modeled with a linear subspace this constrains the shape to belong to a manifold of dimensionality equal to the number of degree of freedom of the object after showing that the problem is still overconstrained we present a solution composed of a novel initialization algorithm followed by a robust extension of the locally smooth manifold learning algorithm tailored to the nrsfm problem we finally present some test case where the linear basis method fails and is actually not meant to work while the proposed approach is successful 
in this paper we identify the constraint under which the generally ill posed problem of simultaneous recovery of surface shape and it photometric invariant can be rendered tractable we examine the case where a single or more image are acquired using different lighting direction with known illuminant power given these condition we state the constraint upon which the recovery of the surface geometry and it photometric parameter can be estimated with these constraint we then show how the recovery process may be formulated a an optimisation algorithm which aim to fit the reflectance model under study to the image reflectance the approach presented here is general and can be applied to a family of reflectance model that are based on the fresnel reflection theory thus we provide a theoretical and computational background for recovering shape material index of refraction and microscopic roughness from multi spectral image 
manually labeled landmark set are often required a input for landmark based image registration identifying an optimal subset of landmark from a training dataset may be useful in reducing the labor intensive task of manual labeling in this paper we present a new problem and a method to solve it given a set of n landmark find the k n best landmark such that aligning these k landmark that produce the best overall alignment of all n landmark the resulting procedure allows u to select a reduced number of landmark to be labeled a a part of the registration procedure we apply this methodology to the problem of registering cerebral cortical surface extracted from mri data we use manually traced sulcal curve a landmark in performing inter subject registration of these surface to minimize the error metric we analyze the correlation structure of the sulcal error in the landmark point by modeling them a a multivariate gaussian process selection of the optimal subset of sulcal curve is performed by computing the error variance for the subset of unconstrained landmark conditioned on the constrained set we show that the registration error predicted by our method closely match the actual registration error the method determines optimal curve subset of any given size with minimal registration error 
we propose a novel framework for contour based object detection and recognition which we formulate a a joint contour fragment grouping and labeling problem for a given set of contour of model shape we simultaneously perform selection of relevant contour fragment in edge image grouping of the selected contour fragment and their matching to the model contour the inference in all these step is performed using particle filter pf but with static observation our approach need one example shape per class a training data the pf framework combined with decomposition of model contour fragment to part bundle allows u to implement an intuitive search strategy for the target contour in a clutter of edge fragment first a rough sketch of the model shape is identified followed by fine tuning of shape detail we show that this framework yield not only accurate object detection but also localization in real cluttered image 
the appearance of a distant object when viewed through a telephoto lens is often deformed nonuniformly by the influence of hot air optical turbulence the deformation is unsteady an image sequence can include nonuniform movement of the object even if a stationary camera is used for a static object this study proposes a multi frame super resolution reconstruction from such an image sequence the process consists of the following three stage in the first stage an image frame without deformation is estimated from the sequence however there is little detailed information about the object in the second stage each frame in the sequence is aligned non rigidly to the estimated image using a non rigid deformation model a stable nonrigid registration technique with a b spline function is also proposed in this study for dealing with a textureless region in the third stage a multi frame superresolution reconstruction using the non rigid deformation recovers the detailed information in the frame obtained in the first stage experiment using synthetic image demonstrate the accuracy and stability of the proposed non rigid registration technique furthermore experiment using real sequence underscore the effectiveness of the proposed process 
oneimportantproblemincomputervisionisto providea demographic description a person from an image in practice many of the state of the art method use only an analysis of the face to estimate the age and gender of a person of interest we present a modelthat combinestwo problem heightestimation and demographicclassification which allows each to serve a context for the other our idea is to use a calibrated camera for measuring the height of people in the scene height is measured by jointly inferring across anthropometric dimension age and gender using publicly available statistic the height estimate provides context for recognizing the age and gender of the subject and likewise age and gender condition the distribution of the anthropometric feature for estimating height the performance of our method is explored on a new database of people captured with a calibrated camera with recorded height age and gender we show that estimating height lead to improvement in age and gender classification and vice versa to the best of our knowledge our model produce the most accurate automatic height estimate reported with the error having a standard deviation of mm 
this paper describes a new passive approach to capture time varying scene geometry in large acquisition volume from multi view video it can be applied to reconstruct complete moving model of human actor that feature even slightest dynamic geometry detail such a wrinkle and fold in clothing and that can be viewed from starting from multi view video stream recorded under calibrated lighting we first perform marker le human motion capture based on a smooth template with no highfrequency surface detail subsequently surface reflectance and time varying normal field are estimated based on the coarse template shape the main contribution of this paper is a new statistical approach to solve the non trivial problem of transforming the captured normal field that is defined over the smooth non planar d template into true d displacement our spatio temporal reconstruction method output displaced geometry that is accurate at each time step of video and temporally smooth even if the input data are affected by noise 
in this paper we present an algorithm for occlusion boundary detection the main contribution is a probabilistic detection framework defined on spatio temporal lattice which enables joint analysis of image frame for this purpose we introduce two complementary cost function for creating the spatio temporal lattice and for performing global inference of the occlusion boundary respectively in addition a novel combination of low level occlusion feature is discriminatively learnt in the detection framework simulation on the cmu motion dataset provide ample evidence that proposed algorithm outperforms the leading existing method 
this paper introduces a fully automated unsupervised method to recognise sign from subtitle it doe this by using data mining to align correspondence in section of video based on head and hand tracking a novel temporally constrained adaptation of apriori mining is used to extract similar region of video with the aid of a proposed contextual negative selection method these region are refined in the temporal domain to isolate the occurrence of similar sign in each example the system is shown to automatically identify and segment sign from standard news broadcast containing a variety of topic 
object detection is challenging when the object class exhibit large within class variation in this work we show that foreground background classification detection and within class classification of the foreground class pose estimation can be jointly learned in a multiplicative form of two kernel function one kernel measure similarity for foreground background classification the other kernel account for latent factor that control within class variation and implicitly enables feature sharing among foreground training sample detector training can be accomplished via standard svm learning the resulting detector are tuned to specific variation in the foreground class they also serve to evaluate hypothesis of the foreground state when the foreground parameter are provided in training the detector can also produce parameter estimate when the foreground object mask are provided in training the detector can also produce object segmentation the advantage of our method over past method are demonstrated on data set of human hand and vehicle 
salient area in natural scene are generally regarded a the candidate of attention focus in human eye which is the key stage in object detection in computer vision many model have been proposed to simulate the behavior of eye such a saliencytoolbox stb neuromorphic vision toolkit nvt and etc but they demand high computational cost and their remarkable result mostly rely on the choice of parameter recently a simple and fast approach based on fourier transform called spectral residual sr wa proposed which used sr of the amplitude spectrum to obtain the saliency map the result are good but the reason is questionable in this paper we propose it is the phase spectrum not the amplitude spectrum of the fourier transform that is the key in obtaining the location of salient area we provide some example to show that pft can get better result in comparison with sr and requires le computational complexity a well furthermore pft can be easily extended from a two dimensional fourier transform to a quaternion fourier transform qft if the value of each pixel is represented a a quaternion composed of intensity color and motion feature the added motion dimension allows the phase spectrum to represent spatio temporal saliency in order to engage in attention selection for video a well a image extensive test of video natural image and psychological pattern show that the proposed method is more effective than other model moreover it is very robust against white colored noise and meet the real time requirement which ha great potential in engineering application 
for a large class of application there is time to train the system in this paper we propose a learning based approach to patch perspective rectification and show that it is both faster and more reliable than state of the art ad hoc affine region detection method our method performs in three step first a classifier provides for every keypoint not only it identity but also a first estimate of it transformation this estimate allows carrying out in the second step an accurate perspective rectification using linear predictor we show that both the classifier and the linear predictor can be trained online which make the approach convenient the last step is a fast verification made possible by the accurate perspective rectificationof the patch identity and it sub pixel precision position estimation we test our approach on real time d object detection and tracking application we show that we can use the estimated perspective rectification to determine the object pose and a a result we need much fewer correspondence to obtain a precise pose estimation 
we revisit stereo matching function a topic that is considered well understood from a different angle our goal is to discover a transformation that operates on the cost or similarity measure between pixel in binocular stereo this transformation should produce a new matching curve that result in higher matching accuracy the desired transformation must have no additional parameter over those of the original matching function and must result in a new matching function that can be used by existing local global and semi local stereo algorithm without having to modify the algorithm we propose a transformation that meet these requirement taking advantage of information derived from matching the input image against themselves we analyze the behavior of this transformation which we call self aware matching measure samm on a diverse set of experiment on data with ground truth our result show that the samm improves the performance of dense and semi dense stereo moreover a opposed to the current state of the art it doe not require distinctiveness to match pixel reliably cost function in this paper we revisit the matching function for stereo aiming at extracting more information from the image pair before applying a stereo algorithm note that the term cost and similarity are used interchangeably in the paper since one can trivially be converted to the other via a monotonically decreasing function we use the term matching measure to refer to both cost and similarity we focus our investigation to the core of the stereo correspondence problem the estimation of dense or semi dense disparity map from rectified stereo pair by dense or semi dense we refer to an attempt to estimate correspondence for all pixel without a priori feature extraction the result may be semi dense if correspondence are rejected according to some criterion we seek a transformation that operates on the matching measure between pixel and result in a new matching function which ha the same form a the original and is better than the original according to widely accepted criterion the requirement for the transformation are that it must have no additional parameter over those of the original matching function and that the new matching function must behave exactly a the original in the sense that existing stereo algorithm must be able to use it without any modification we do not attempt to estimate sub pixel match do not model occlusion or depth discontinuity and do not apply constraint such a ordering or uniqueness other than the epipolar constraint we also do not attempt to rank the various matching function 
state of the art method for image and object retrieval exploit both appearance via visual word and local geometry spatial extent relative pose in large scale problem memory becomes a limiting factor local geometry is stored for each feature detected in each image and requires storage larger than the inverted le and term frequency and inverted document frequency weight together we propose a novel method for learning discretized local geometry representation based on minimization of average reprojection error in the space of ellipsis the representation requires only bit per feature without drop in performance additionally we show that if the gravity vector assumption is used consistently from the feature description to spatial verication it improves retrieval performance and decrease the memory footprint the proposed method outperforms state of the art retrieval algorithm in a standard image retrieval benchmark 
maximum a posteriori map inference in markov random field mrfs is an np hard problem and thus research ha focussed on either finding efficiently solvable subclass e g tree or approximate algorithm e g loopy belief propagation bp and tree reweighted trw method this paper present a unifying perspective of these approximate technique called decomposition method these are method that decompose the given problem over a graph into tractable subproblems over subgraphs and then employ message passing over these subgraphs to merge the solution of the subproblems into a global solution this provides a new way of thinking about bp and trw a successive step in a hierarchy of decomposition method using this framework we take a principled first step towards extending this hierarchy beyond tree we leverage a new class of graph amenable to exact inference called outerplanar graph and propose an approximate inference algorithm called outer planar decomposition opd opd is a strict generalization of bp and trw and contains both of them a special case our experiment show that this extension beyond tree is indeed very powerful opd outperforms current state of art inference method on hard non submodular synthetic problem and is competitive on real computer vision application 
while video based activity analysis and recognition ha received much attention existing body of work mostly deal with single object person case coordinated multi object activity or group activity present in a variety of application such a surveillance sport and biological monitoring record etc are the main focus of this paper unlike earlier attempt which model the complex spatial temporal constraint among multiple object with a parametric bayesian network we propose a discriminative temporal interaction manifold dtim framework a a data driven strategy to characterize the group motion pattern without employing specific domain knowledge in particular we establish probability density on the dtim whose element the discriminative temporal interaction matrix compactly describes the coordination and interaction among multiple object in a group activity for each class of group activity we learn a multi modal density function on the dtim a maximum a posteriori map classifier on the manifold is then designed for recognizing new activity experiment on football play recognition demonstrate the effectiveness of the approach 
recently tof camera have attracted attention because of their ability to generate a full d depth image at video frame rate thus tof camera are suitable for real time d task such a tracking visual servoing or object pose estimation the usability of such system mainly depends on an accurate camera calibration in this work a calibration process for tof camera with respect to the intrinsic parameter the depth measurement distortion and the pose of the camera relative to a robot s endeffector is described the calibration process is not only based on the monochromatic image of the camera but also us it depth value that are generated from a chequer board pattern the robustness and precision of the presented method is assessed applying it to randomly selected shot and comparing the calibrated measurement to a ground truth obtained from a laser scanner 
this paper introduces a feature descriptor called shape of gaussian sog which is based on a general feature descriptor design framework called shape of signal probability density function sospdf sospdf take the shape of a signal s probability density function pdf a it feature under such a view both histogram and region covariance often used in computer vision are sospdf feature histogram describes sospdf by a discrete approximation way region covariance describes sospdf a an incomplete parameterized multivariate gaussian distribution our proposed sog descriptor is a full parameterized gaussian so it ha all the advantage of region covariance and is more effective furthermore we identify that sogs form a lie group based on lie group theory we propose a distance metric for sog we test sog feature in tracking problem experiment show better tracking result compared with region covariance moreover experiment result indicate that sog feature attempt to harvest more useful information and are le sensitive against noise 
we present a face recognition method based on sparse representation for recognizing d face mesh under expression using low level geometric feature first to en able the application of the sparse representation framework we develop a uniform remeshing scheme to establish a consistent sampling pattern across d face to handle facial expression we design a feature pooling and ranking scheme to collect various type of low level geometric feature and rank them according to their sensitivity to facial expression by simply applying the sparse representation framework to the collected low level feature o ur proposed method already achieves satisfactory recognitio n rate which demonstrates the efficacy of the framework for d face recognition to further improve result in the presence of severe facial expression we show that by choosing higher ranked i e expression insensitive featur e the recognition rate approach those for neutral face withou t requiring an extensive set of reference face for each individual to cover possible variation caused by expression a proposed in previous work we apply our face recognition method to the gavabdb and frgc database and demonstrate encouraging result 
from the recovery of structure from motion to the separation of style and content many problem in computer vision have been successfully approached by using bilinear model the reason for the success of these model is that a globally optimal decomposition is easily obtained from the singular value decomposition svd of the observation matrix however in practice the observation matrix i s often incomplete the svd can not be used and only suboptimal solution are available the majority of these solution are based on iterative local refinement of a given cost function and lack any guarantee of convergence to the global optimum in this paper we propose a globally optimal solution for particular pattern of missing entry t o achieve this goal we re formulate the problem a the minimization of the spectral norm of the matrix of residual i e we seek the completion of the observation matrix such that the largest singular value of it difference to a low rank matrix is the smallest possible the class of pattern of missi ng entry we deal with is known a the young diagram which includes a particular case many relevant situation s uch 
this paper present a method for estimating geographic location for sequence of time stamped photograph a prior distribution over travel describes the likelihood of traveling from one location to another during a given time interval this distribution is based on a training database of million photograph from flickr com an image likelihood for each location is defined by matching a test photograph against the training database inferring location for image in a test sequence is then performed using the forwardbackward algorithm and the model can be adapted to individual user a well using temporal constraint allows our method to geolocate image without recognizable landmark and image with no geographic cue whatsoever this method achieves a substantial performance improvement over the best available baseline and geolocates some user image with near perfect accuracy 
local learning for classification is useful in dealing with various vision problem one key factor for such approach to be effective is to find good neighbor for the learning procedure in this work we describe a novel method to rank neighbor by learning a local distance function and meanwhile to derive the local distance function by focusing on the high ranked neighbor the two aspect of consideration can be elegantly coupled through a well defined objective function motivated by a supervised ranking method called p norm push while the local distance function are learned independently they can be reshaped altogether so that their value can be directly compared we apply the proposed method to the caltech dataset and demonstrate the use of proper neighbor can improve the performance of classification technique based on nearest neighbor selection 
graphical model are fundamental tool for modeling image and other application in this paper we propose the logistic random field lrf model for representing a discrete valued graphical model the lrf model is based on an underlying quadratic model and a logistic function the chief advantage of the lrf are it convenience and flexibility the quadratic model make inference easy to implement using standard numerical linear algebra routine this quadratic model also allows the log likelihood of the training data to be differentiated with respect to any parameter in the model enhancing the flexibility of the lrf model to demonstrate the usefulness of this model we use it to learn how to segment object specifically road horse and cow in addition we demonstrate the flexibility of the lrf model by incorporating super pixel we then show that the lrf segmentation model produce segmentation that are competitive with recently published result 
near infra red nir image of natural scene usually have better contrast and contain rich texture detail that may not be perceived in visible light photograph vi in this paper we propose a novel method to enhance a photograph by using the contrast and texture information of it corresponding nir image more precisely we first decompose the nir vi pair into average and detail wavelet subbands we then transfer the contrast in the average subband and transfer texture in the detail subbands we built a special camera mount that optically aligns two consumergrade digital camera one of which wa modified to capturenir ourresultsexhibithighervisual qualitythantonemapped hdr image showing that nir imaging is useful for computational photography 
visual tracking is a challenging problem a an object may change it appearance due to pose variation illumination change and occlusion many algorithm have been proposed to update the target model using the large volume of available information during tracking but at the cost of high computational complexity to address this problem we present a tracking approach that incrementally learns a low dimensional covariance tensor representation efficiently adapting online to appearance change for each mode of the target with only computational complexity moreover a weighting scheme is adopted to ensure le modeling power is expended fitting older observation both of these feature contribute measurably to improving overall tracking performance tracking is then led by the bayesian inference framework in which a particle filter is used to propagate sample distribution over time with the help of integral image our tracker achieves real time performance extensive experiment demonstrate the effectiveness of the proposed tracking algorithm for the target undergoing appearance variation 
this paper proposes a novel approach to anomalous behaviour detection in video the approach is comprised of three key component first distribution of spatiotemporal oriented energy are used to model behaviour this representation can capture a wide range of naturally occurring visual spacetime pattern and ha not previously been applied to anomaly detection second a novel method is proposed for comparing an automatically acquired model of normal behaviour with new observation the method account for situation when only a subset of the model is present in the new observation a when multiple activity are acceptable in a region yet only one is likely to be encountered at any given instant third event driven processing is employed to automatically mark portion of the video stream that are most likely to contain deviation from the expected and thereby focus computational effort the approach ha been implemented with real time performance quantitative and qualitative empirical evaluation on a challenging set of natural image video demonstrates the approach s superior performance relative to various alternative 
we present a manifold learning approach to dimensionality reduction that explicitly model the manifold a a mapping from low to high dimensional space the manifold is represented a a parametrized surface represented by a set of parameter that are defined on the input sample the representation also provides a natural mapping from high to low dimensional space and a concatenation of these two mapping induces a projection operator onto the manifold the explicit projection operator allows for a clearly defined objective function in term of projection distance and reconstruction error a formulation of the mapping in term of kernel regression permit a direct optimization of the objective function and the extremal point converge to principal surface a the number of data to learn from increase principal surface have the desirable property that they informally speaking pas through the middle of a distribution we provide a proof on the convergence to principal surface and illustrate the effectiveness of the proposed approach on synthetic and real data set nate system of the manifold the parametrization c and the ambient data space d researcher usually resort to a weighted nearest neighbor averaging but there is nothing in the construction of manifold from these method that give any assurance about the quality of these approximation based on these observation we propose an approach to manifold learning that explicitly provides mapping for embedding and reconstruction and specifically optimizes the projection distance the mapping are computed by kernel regression on manifold coordinate defined on the input data the coordinate determine the shape of the manifold thus we can evaluate and by adjusting the manifold coordinate optimize the manifold in term of projection distance we call this approach the kernel map manifold kmms in this paper we show that kmms are formally principal surface we show that kmms can easily be used in conjunction with and improve on existing global method and readily extend to n dimensional principal surface background 
we address the problem of blindly separating mixture of multiple layer image with unknown spatial shift and mixing coefficient our proposed method can handle the over determined determined and under determined case where mixture are more than a many a and fewer than layer respectively the method is fast in over determined and determined case with the same complexity a the fast fourier transform fft and can separate more layer from fewer mixture in the under determined case it consists of two main step first a novel sparse blind separation algorithm is applied to estimate the spatial shift the mixing coefficient and the edge image of each layer second all layer are reconstructed by large scale linear programming in the under determined case or by least square solution in other case the effectiveness of this technology is shown in the experiment on two simulated mixture of four layer with spatial shift real mixture photo containing transparency and reflection and real mixture image in a dissolve from a video 
the variation of pose lead to significant performance decline in face recognition system which is a bottleneck in face recognition a key problem is how to measure the similarity between two image vector of unequal length that viewed from different pose in this paper we propose a novel approach for pose robust face recognition in which the similarity is measured by correlation in a medium subspace between different pose on patch level the medium subspace is constructed by canonical correlation analysis such that the intra individual correlation are maximized based on the medium subspace two recognition approach are developed in the first we transform non frontal face into frontal for recognition and in the second we perform recognition in the medium subspace with probabilistic modeling the experimental result on feret database demonstrate the efficiency of our approach 
object model based on bag of word representation can achieve state of the art performance for image classification and object localization task however a they consider object a loose collection of local patch they fail to accurately locate object boundary and are not able to produce accurate object segmentation on the other hand markov random field model used for image segmentation focus on object boundary but can hardly use the global constraint necessary to deal with object category whose appearance may vary significantly in this paper we combine the advantage of both approach first a mechanism based on local region allows object detection using visual word occurrence and produce a rough image segmentation then a mrf component give clean boundary and enforces label consistency guided by local image cue color texture and edge cue and by long distance dependency gibbs sampling is used to infer the model the proposed method successfully segment object category with highly varying appearance in the presence of cluttered background and large view point change we show that it outperforms published result on the pascal voc dataset 
in this paper we focus on the problem of detecting matching a query object in a given image we propose a new algorithm shape band which model an object within a bandwidth of it sketch contour the feature associated with each point on the sketch are the gradient within the bandwidth in the detection stage the algorithm simply scan an input image at various location and scale for good candidate we then perform fine scale shape matching to locate the precise object boundary also by taking advantage of the information from the shape band the overall algorithm is very easy to implement and our experimental result show that it can outperform stat of the art contour based object detection algorithm 
a catadioptric system consisting of a pinhole camera and two planar mirror is deeply investigated in this paper the two mirror combine to form a corner and face to face with the pinhole their relative pose is unknown an object will be reflected in the mirror corner one time or multiple time using the pinhole we may take an image containing the object and it reflection i e simultaneously imaging multiple view of an object by a single camera we discovered that each d point and it reflection lie on a circle we call the point set composed of a d point and it reflection a reflection point group rpg and the circle related to a rpg is called a rpg circle all rpg circle are parallel to one another furthermore each rpg can be partitioned into two separate subgroup shape formed by all point in a subgroup is invariant with respect to location of the d point from these geometric property two calibration approach can be utilized one is based on parallel circle the other is using d homographies among invariant shape experiment validate our approach 
analyzing video of human activity involves not only recognizing action typically based on their appearance but also determining the story plot of the video the storyline of a video describes causal relationship between action beyond recognition of individual action discovering causal relationship help to better understand the semantic meaning of the activity we present an approach to learn a visually grounded storyline model of video directly from weakly labeled data the storyline model is represented a an and or graph a structure that can compactly encode storyline variation across video the edge in the and or graph correspond to causal relationship which are represented in term of spatio temporal constraint we formulate an integer programming framework for action recognition and storyline extraction using the storyline model and visual grounding learned from training data 
the problem of reconstructing a d scene from a moving camera can be solved by mean of the so called factorization method it directly computes a global solution without the need to merge several partial reconstruction however if the trajectory are not complete i e not every feature point could be observed in all the image this method cannot be used we use a factorization style algorithm for recovering the unobserved feature position in a non incremental way this method uniformly utilizes all dataandfindsa globalsolution without any need of sequential or hierarchical merging two contribution are made in this work firstly partially known trajectory are completed by minimizing the distance between the subspace and the trajectory within an affine subspace associated with the trajectory this amount to imposing a global constraint on the data secondly we propose to further include local constraint derived from epipolar geometry into the estimation it is shownhowto simultaneouslyoptimize bothconstraints by using simulated and real image sequence we show the improvement achieved with our algorithm 
the automatic reconstruction of d model from image sequence is still a very active field of research all existing method are designed for a given camera model and a new and ambitious challenge is d modeling with a method which is exploitable for any kind of camera a similar approach wa recently suggested for structure frommotion thanks to the use of generic camera model in this paper we first introduce geometric tool designed for d scene modeling with a generic camera model then these tool are used to solve many issue matching error wide range of point depth depth discontinuity and view point selection for reconstruction experiment are provided for perspective and catadioptric camera 
volumetric detail of cardiac electrophysiology such a transmembrane potential dynamic and tissue excitability of the myocardium are of fundamental importance for understanding normal and pathological cardiac mechanism and for aiding the diagnosis and treatment of cardiac arrhythmia noninvasive observation however are made on body surface a an integration projection of the volumetric phenomenon inside patient s heart we present a physiological model constrained statistical framework where prior knowledge of general myocardial electrical activity is used to guide the reconstruction of patient specific volumetric cardiac electrophysiological detail from body surface potential data sequential data assimilation with proper computational reduction is developed to estimate transmembrane potential and myocardial excitability inside the heart which are then utilized to depict arrhythmogenic substrate effectiveness and validity of the framework is demonstrated through it application to evaluate the location and extent of myocardial infract using real patient data 
we propose a variational bayes approach to the problem of robust estimation of gaussian mixture from noisy input data the proposed algorithm explicitly take into account the uncertainty associated with each data point make no assumption about the structure of the covariance matrix and is able to automatically determine the number of the gaussian mixture component through the use of both synthetic and real world data example we show that by incorporating uncertainty information into the clustering algorithm we get better result at recovering the true distribution of the training data compared to other variational bayesian clustering algorithm tomatically chooses the appropriate number of component in the mixture model we show that by taking into account the uncertainty of information our algorithm performs better at estimating the correct number of cluster and recovering the true distribution of the training data compared to other variational bayesian clustering algorithm the proposed algorithm is evaluated on a number of synthetic and real data set and is shown to improve the result of various pattern recognition task such a motion segmentation and partitioning of microarray gene expression 
the state of the art content based image retrieval system ha been significantly advanced by the introduction of sift feature and the bag of word image representation converting an image into a bag of word however involves three non trivial step feature detection feature description and feature quantization at each of these step there is a significant amount of information lost and the resulted visual word are often not discriminative enough for large scale image retrieval application in this paper we propose a novel multi sample multi tree approach to computing the visual word codebook by encoding more information of the original image feature our approach generates a much more discriminative visual word codebook that is also efficient in term of both computation and space consumption without losing the original repeatability of the visual feature we evaluate our approach using both a ground truth data set and a real world large scale image database our result show that a significant improvement in both precision and recall can be achieved by using the codebook derived from our approach 
abstract image matting deal with finding the probability that each pixel in an image belongs to a user specified object or to the remaining background most existing method estimate the matte for two group only moreover most of these method estimate the matte with a particular bias towards the object and hence the resulting matte do not sum up to across the different group in this work we propose a general framework to estimate the alpha matte for multiple image layer the matte are estimated a the solution to the dirichlet problem on a combinatorial graph with boundary condition we consider the constrained optimization problem that enforces the alpha matte to take value in and sum up to at each pixel we also analyze the property of the solution obtained by relaxing either of the two constraint experiment demonstrate that our proposed method can be used to extract accurate matte of multiple object with little user interaction 
this paper present a fast method for detecting multi view car in real world scene car are artificial object with various appearance change but they have relatively consistent characteristic in structure that consist of some basic local element inspired by this we propose a novel set of image strip feature to describe the appearance of those element the new feature represent various type of line and arc with edge like and ridge like strip pattern which significantly enrich the simple feature such a haar like feature and edgelet feature they can also be calculated efficiently using the integral image moreover we develop a new complexity aware criterion for realboost algorithm to balance the discriminative capability and efficiency of the selected feature the experimental result on widely used single view and multi view car datasets show that our approach is fast and ha good performance 
the matching and retrieval of d shape is an important challenge in computer vision a large number of shape similarity approach have been developed with the main focus being the comparison or matching of pair of shape in these approach other shape do not influence the similarity measure of a given pair of shape in the proposed approach other shape do influence the similarity measure of each pair of shape and we show that this influence is beneficial even in the unsupervised setting without any prior knowledge of shape class the influence of other shape is propagated a a diffusion process on a graph formed by a given set of shape however the classical diffusion process doe not perform well in shape space for two reason it is unstable in the presence of noise and the underlying local geometry is sparse we introduce a locally constrained diffusion process which is more stable even if noise is present and we densify the shape space by adding synthetic point we call ghost point we present experimental result that demonstrate very significant improvement over state of the art shape matching algorithm on the mpeg data set we obtained a bull s eye retrieval score of which is the highest score ever reported in the literature 
this paper present a new approach to discriminative modeling for classification and labeling our method called boosting on multilevel aggregate bma add a new class of hierarchical adaptive feature into boostingbased discriminative model each pixel is linked with a set of aggregate region in a multilevel coarsening of the image the coarsening is adaptive rapid and stable the multilevel aggregate present additional information rich feature on which to boost such a shape property neighborhood context hierarchical characteristic and photometric statistic we implement and test our approach on three two class problem classifying document in office scene building and horse in natural image in all three case the majority about of feature selected during boosting are our proposed bma feature rather than patchbased feature this large percentage demonstrates the discriminative power of the multilevel aggregate feature over conventional patch based feature our quantitative performance measure show the proposed approach give superior result to the state of the art in all three application 
flow doppler imaging ha become an integral part of an echocardiographic exam automated interpretation of flow doppler imaging ha so far been restricted to obtaining hemodynamic information from velocity time profile depicted in these image in this paper we exploit the shape pattern in doppler image to infer the similarity in valvular disease label for purpose of automated clinical decision support specifically we model the similarity in appearance of doppler image from the same disease class a a constrained non rigid translation transform of the velocity envelope embedded in these image the shape similarity between two doppler image is then judged by recovering the alignment transform using a variant of dynamic shape warping result of similarity retrieval of doppler image for cardiac decision support on a large database of image are presented 
interactive segmentation is often performed on image that have been stored on disk e g a medical image server for some time prior to user interaction we propose to use this time to perform an offline precomputation of the segmentation prior to user interaction that significantly decrease the amount of user time necessary to produce a segmentation knowing how to effectively precompute the segmentation prior to user interaction is difficult since a user may choose to guide the segmentation algorithm to segment any object or multiple object in the image consequently precomputation performed prior to user interaction must be performed without any knowledge of the user interaction specifically we show that one may precompute several eigenvectors of the weighted laplacian matrix of a graph and use this information to produce a linear time approximation of the random walker segmentation algorithm even without knowing where the foreground background seed will be placed finally we also show that this procedure may be interpreted a a seeded interactive normalized cut algorithm 
non rigid registration is central to many problem in computer vision and medical image analysis we propose a registration algorithm which is regularized by prior knowledge in the form of a statistical deformation model this model is obtained from previous registration performed on a set of noise free training example given by image or shape represented by level set function contrary to similar approach our method doe not strictly constrain the result to lie in the span of the statistical model but rather us the model for tikhonov regularization therefore our method can be used to reduce the influence of noise and artifact even when the model contains only a few typical example this automatically give rise to a bootstrapping strategy for building statistical model from noisy data set requiring only a limited number of high quality example we demonstrate the effectiveness of the approach on synthetic and medical image 
the popular bag of word paradigm for action recognition task is based on building histogram of quantized feature typically at the cost of discarding all information about relationship between them however although the beneficial nature of including these relationship seems obvious in practice finding good representation for feature relationship in video is difficult we propose a simple and computationally efficient method for expressing pairwise relationship between quantized feature that combine the power of discriminative representation with key aspect of na ve bayes we demonstrate how our technique can augment both appearanceand motion based feature and that it significantly improves performance on both type of feature 
the problem of recognizing action in realistic video is challenging yet absorbing owing to it great potential in many practical application most previous research is limited due to the use of simplified action database under controlled environment or focus on excessively localized feature without sufficiently encapsulating the spatiotemporal context in this paper we propose to model the spatio temporal context information in a hierarchical way where three level of context are exploited in ascending order of abstraction point level context sift average descriptor intra trajectory context trajectory transition descriptor and inter trajectory context trajectory proximity descriptor to obtain efficient and compact representation for the latter two level we encode the spatiotemporal context information into the transition matrix of a markov process and then extract it stationary distribution a the final context descriptor building on the multichannel nonlinear svms we validate this proposed hierarchical framework on the realistic action hoha and event lscom recognition database and achieve and relative performance improvement over the state ofthe art result respectively we further propose to employ the multiple kernel learning mkl technique to prune the kernel towards speedup in algorithm evaluation 
a new learning strategy for object detection is presented the proposed scheme forgoes the need to train a collection of detector dedicated to homogeneous family of pose and instead learns a single classifier that ha the inherent ability to deform based on the signal of interest specifically we train a detector with a standard adaboost procedure by using combination of pose indexed feature and pose estimator instead of the usual image feature this allows the learning process to select and combine various estimate of the pose with feature able to implicitly compensate for variation in pose we demonstrate that a detector built in such a manner provides noticeable gain on two hand video sequence and analyze the performance of our detector a these data set are synthetically enriched in pose while not increased in size preamble machine learning object detection technique rely on searching for the presence of the target over all scale and location of a scene in order to handle complex case where latent variable modulate change in appearance for instance due to rotation or variation in illumination two strategy have emerged either building a collection of pose dedicated classifier or explicitly visiting the additional latent variable in the same manner a one explores location and scale we propose a new approach which consists of designing a family of pose estimator able to compute meaningful value for the additional latent variable directly from the signal we allow the learning procedure to automatically 
the error correcting output code ecoc is a general framework to extend any binary classifier to the multiclass case finding the optimal ecoc is known a a np hard problem in this paper we present a spectral analysis approach for the design of ecoc we construct a similarity graph of the class and generate ecoc with a subset of thresholded eigenvectors of the graph laplacian using the spectral analysis the coding efficiency classifier s diversity hamming distance among codewords and binary classifier accuracy can be simultaneously considered the resulting ecoc is efficient thus only a small set of binary classifier are to be evaluated when making a decision in experiment with large multiclass problem our method is between and time faster comparing to one against all with comparable classification accuracy our method also show a better performance than the most of leading method e g classmap random dense ecoc random sparse ecoc and discriminant ecoc 
visual tracking is a key componentin many computer vision application linear subspace technique e g eigentracking are one of the most popular approach to align template with appearance variation e g illumination iconic change a number of well known tracking algorithm have been proposed in the last year to accurately fit these model to image computational efficiency is an important limitation in object tracking algorithm and different efficient technique such a the projected out optimization have been proposed they reduce the computational cost using an efficient formulation in which many of the involved operation can be precomputed on the other hand alternative simultaneous algorithm jointly optimize pose and appearanceparameters providing better performance but increasing the computational cost in this paper we propose an algorithm for efficient linear appearance model fitting based on the inverse compositional simultaneous optimization of pose and appearance we introduce a novel formulation which reduces the required computational time while maintaining similar convergence property of previous simultaneous approach experimental result illustrate the capability of this algorithm in face tracking 
spatial prior play crucial role in many high level vision task e g scene understanding usually learning spatial prior relies on training a structured output model in this paper two special case of discriminative structured output model i e conditional random field crfs and max margin markov network m n are demonstrated to perform image scene understanding the two model are empirically compared in a fair manner i e using the common feature representation and the same optimization algorithm particularly we adopt online exponentiated gradient eg algorithm to solve the convex duals of both model we describe the general procedure of eg algorithm and present a two stage training procedure to overcome the degeneration of eg when exact inference is intractable experiment on a large scale image region annotation task are carried out the result show that both model yield encouraging result but crfs slightly outperforms m n 
several spatiotemporal feature point detector have been recently used in video analysis for action recognition feature point are detected using a number of measure namely saliency cornerness periodicity motion activity etc each of these measure is usually intensity based and provides a different trade off between density and informativeness in this paper we use saliency for feature point detection in video and incorporate color and motion apart from intensity our method us a multi scale volumetric representation of the video and involves spatiotemporal operation at the voxel level saliency is computed by a global minimization process constrained by pure volumetric constraint each of them being related to an informative visual aspect namely spatial proximity scale and feature similarity intensity color motion point are selected a the extremum of the saliency response and prove to balance well between density and informativeness we provide an intuitive view of the detected point and visual comparison against state of the art space time detector our detector outperforms them on the kth dataset using nearestneighbor classifier and rank among the top using different classification framework statistic and comparison are also performed on the more difficult hollywood human action hoha dataset increasing the performance compared to current published result 
in this paper we introduce a higher order mrf optimization framework on the one hand it is very general we thus use it to derive a generic optimizer that can be applied to almost any higher order mrf and that provably optimizes a dual relaxation related to the input mrf problem on the other hand it is also extremely flexible and thus can be easily adapted to yield far more powerful algorithm when dealing with subclass of high order mrfs we thus introduce a new powerful class of high order potential which are shown to offer enough expressive power and to be useful for many vision task to address them we derive based on the same framework a novelandextremely efficient message passing algorithm which go beyond the aforementioned generic optimizer and is able to deliver almost optimal solution of very high quality experimental result on vision problem demonstrate the extreme effectiveness of our approach for instance we show that in some case we are even able to compute the global optimum for np hard higher order mrfs in a very efficient manner 
this paper examines the issue of scale in modeling texture for the purpose of segmentation we propose a scale descriptor for texture and an energy minimization model to find the scale of a given texture at each location for each pixel we use the intensity distribution in a local patch around that pixel to determine the smallest size of the domain that can be used to generate neighboring patch the energy functional we propose to minimize is comprised of three term the first is the dissimilarity measure using the wasserstein distance or kullback leibler divergence between neighboring patch distribution the second maximizes the entropy of the local patch and the third penalizes larger size at equal fidelity our experiment show the proposed scale model successfully capture the intrinsic scale of texture at each location we also apply our scale descriptor for improving texture segmentation based on histogram matching 
we present an online recursive filtering technique to model linear dynamical system that operate on the state space of symmetric positive definite matrix tensor that lie on a riemannian manifold the proposed approach describes a predict and update computational paradigm similar to a vector kalman filter to estimate the optimal tensor state we adapt the original kalman filtering algorithm to appropriately propagate the state over time and assimilate observation while conforming to the geometry of the manifold we validate our algorithm with synthetic data experiment and demonstrate it application to visual object tracking using covariance feature 
we describe an energy minimization algorithm for function defined on connected lattice of the type usually encountered in problem involving image such function are often minimized using graph cut max flow but this method is only applicable to submodular problem in this paper we describe an algorithm that will solve any binary problem irrespective of whether it is submodular or not and for multilabel problem we use alpha expansion the method is based on the elimination algorithm which eliminates node from the graph until the remaining function is submodular it can then be solved using max flow value of eliminated variable are recovered using back substitution we compare the algorithm s performance against alternative method for solving non submodular problem with favourable result 
we present a practical approach for surface reconstruction of smooth mirror like object using sparse reflection correspondence rcs assuming finite object motion with a fixed camera and un calibrated environment we derive the relationship between rc and the surface shape we show that by locally modeling the surface a a quadric the relationship between the rcs and unknown surface parameter becomes linear we develop a simple surface reconstruction algorithm that amount to solving either an eigen value problem or a second order cone program socp ours is the first method that allows for reconstruction of mirror surface from sparse rcs obtained from standard algorithm such a sift our approach overcomes the practical issue in shape from specular flow sfsf such a the requirement of dense optical flow and undefined infinite flow at parabolic point we also show how to incorporate auxiliary information such a sparse surface normal into our framework experiment both real and synthetic are shown that validate the theory presented cvpr 
boosted one versus all ovum classifier are commonly used in multiclass problem such a generic object recognition biometrics based identification or gesture recog nition jointboost is a recently proposed method where ovum classifier are trained jointly and are forced to share feature jointboost ha been demonstrated to lead both to higher accuracy and smaller classification time compared to using ovum classifier that were trained independently and without sharing feature however even with the improved efficiency of jointboost the time complexity of ovabased multiclass recognition is still linear to the number o f class and can lead to prohibitively large running time in domain with a very large number of class in this paper it is shown that jointboost based recognition can be re duced at classification time to nearest neighbor search ina vector space using this reduction we propose a simple and easy to implement vector indexing scheme based on principal component analysis pca in our experiment the proposed method achieves a speedup of two order of magnitude over standard jointboost classification in a hand pose recognition system where the number of class is close to with negligible loss in classification accuracy ou r method also yield promising result in experiment on the widely used frgc face recognition dataset where the number of class is 
joint data alignment is often regarded a a data simplification process this idea is powerful and general but raise two delicate issue first one must make sure that the useful information about the data is preserved by the alignment process this is especially important when data are affected by non invertible transformation such a those originating from continuous domain deformation in a discrete image lattice we propose a formulation that explicitly avoids this pitfall second one must choose an appropriate measure of data complexity we show that standard concept such a entropy might not be optimal for the task and we propose alternative measure that reflect the regularity of the codebook space we also propose a novel and efficient algorithm that allows joint alignment of a large number of sample ten of thousand of image patch and doe not rely on the assumption that pixel are independent this is done for the case where the data is postulated to live in an affine subspace of the embedding space of the raw data we apply our scheme to learn sparse base for natural image that discount domain deformation and hence significantly decrease the complexity of codebooks while maintaining the same generative power 
in this paper we propose a novel algorithm for computing an atlas from a collection of image in the literature atlas have almost always been computed a some type of mean such a the straightforward euclidean mean or the more general karcher mean on riemannian manifold in the context of image the paper s main contribution is a geometric framework for computing image atlas through a two step process the localization of mean and the realization of it a an image in the localization step a few nearest neighbor of the mean among the input image are determined and the realization step then proceeds to reconstruct the atlas image using these neighbor decoupling the localization step from the realization step provides the flexibility that allows u to formulate a general algorithm for computing image atlas more specifically we assume the input image belong to some smooth manifold m modulo image rotation we use a graph structure to represent the manifold and for the localization step we formulate a convex optimization problem in k k the number of input image to determine the crucial neighbor that are used in the realization step to form the atlas image the algorithm is both unbiased and rotation invariant we have evaluated the algorithm using synthetic and real image in particular experimental result demonstrate that the atlas computed using the proposed algorithm preserve important image feature and generally enjoy better image quality in comparison with atlas computed using existing method 
calibr ating a network of camera with non overlapping view is an important and challenging problem in computer vision in this paper we present a novel technique for camera calibration using a planar mirror we overcome the need for all camera to see a common calibration object directly by allowing them to see it through a mirror we use the fact that the mirrored view generate a family of mirrored camera pose that uniquely describe the real camera pose our method consists of the following two step using standard calibration method to find the internal and external parameter of a set of mirrored camera pose estimating the external parameter of the real camera from their mirrored pose by formulating constraint between them we demonstrate our method on real and synthetic data for camera cluster with small overlap between the view and non overlapping view 
palm line are the most important feature for palmprint recognition they are best considered a typical multiscale feature where the principal line can be represented at a larger scale while the wrinkle at a smaller scale motivated by the success of coding based palmprint recognition method this paper investigates a compact representation of multiscale palm line orientation feature and proposes a novel method called the sparse multiscale competitive code smcc the smcc method first defines a filter bank of second derivative of gaussians with different orientation and scale and then us the l norm sparse coding to obtain a robust estimation of the multiscale orientation field finally a generalized competitive code is used to encode the dominant orientation experimental result show that the smcc achieves higher verification accuracy than state of the art palmprint recognition method yet us a smaller template size than other multiscale method 
d angiographic roadmapping is used frequently during image guided intervention to superimpose vessel structure onto currently acquired fluoroscopic image while the fluoroscopic image acquired with frame per second show patient bone anatomy a well a the current location of the inserted catheter the roadmap delineates vessel to provide path information and to avoid accidental vessel wall puncture during catheter advancement this technique successfully reduces the injection of contrast agent which is hazardous for the patient however it suffers from inaccuracy due to inevitable patient movement which yield a misalignment of the roadmap laid over the current fluoroscopic frame we propose a method for rigid patient motion compensation via the trifocal tensor and image based rendering ibr the method us two contrasted and slightly shifted view and the current fluoroscopic frame different to the existing solution we perform the motion compensation inherently in d increasing reliability and accuracy of the resulting vascular rendering moreover with the ibr technique we avoid an explicit reconstruction thus achieving reasonable result even for very small patient movement which are common in interventional scenario 
we propose a principled approach to summarization of visual data image or video based on optimization of a well defined similarity measure the problem we consider is re targeting or summarization of image video data into smaller size a good visual summary should satisfy two property it should contain a much a possible visual information from the input data it should introduce a few a possible new visual artifact that were not in the input data i e preserve visual coherence we propose a bi directional similarity measure which quantitatively capture these two requirement two signal s and t are considered visually similar if all patch of s at multiple scale are contained in t and vice versa the problem of summarization re targeting is posed a an optimization problem of this bi directional similarity measure we show summarization result for image and video data we further show that the same approach can be used to address a variety of other problem including automatic cropping completion and synthesis of visual data image collage object removal photo reshuffling and more 
we propose a method to identify and localize object class in image instead of operating at the pixel level we advocate the use of superpixels a the basic unit of a class segmentation or pixel localization scheme to this end we construct a classifier on the histogram of local feature found in each superpixel we regularize this classifier by aggregating histogram in the neighborhood of each superpixel and then refine our result further by using the classifier in a conditional random field operating on the superpixel graph our proposed method exceeds the previously published state of the art on two challenging datasets graz and the pascal voc segmentation challenge 
human being have the ability to learn to recognize a new visual category based on only one or few training example part of this ability might come from the use of knowledge from previous visual experience we show that such knowledge can be expressed a a set of ldquouniversalrdquo visual feature which are learned from randomly collected natural scene image using these visual feature we have obtained state of the art performance on several classification task using a single layer classifier 
we propose a novel approach to reconstruct complete d deformable model over time by a single depth camera provided that most part of the model are observed by the camera at least once the core of this algorithm is based on the assumption that the deformation is continuous and predictable in a short temporal interval while the camera can only capture part of a whole surface at any time instant partial surface reconstructed from different time are assembled together to form a complete d surface for each time instant even when the shape is under severe deformation a mesh warping algorithm based on linear mesh deformation is used to align different partial surface a volumetric method is then used to combine partial surface fix missing hole and smooth alignment error our experiment show that this approach is able to reconstruct visually plausible d surface deformation result with a single camera 
we propose a novel tracking algorithm for the target of which geometric appearance change drastically over time to track it we present a local patch based appearance model and provide an efficient scheme to evolve the topology between local patch by on line update in the process of on line update the robustness of each patch in the model is estimated by a new method of measurement which analyzes the landscape of local mode of the patch this patch can be moved deleted or newly added which give more flexibility to the model additionally we introduce the basin hopping monte carlo bhmc sampling methodto ourtrackingproblemto reducethe computational complexity and deal with the problem of getting trapped in local minimum the bhmc method make it possible for our appearancemodel to consist of enough number of patch since bhmc us the same local optimizer that is used in the appearance modeling it can be efficiently integrated into our tracking framework experimental result show that our approach track the object whose geometric appearance is drastically changing accurately and robustly 
we describe a novel application framework to reduce the effect of ink bleed in old document this task is treated a a classification problem where training data is used to compute per pixel likelihood for use in a dual layer markov random field mrf that simultaneously label image pixel of the front and back of a document a either foreground background or ink bleed while maintaining the integrity of foreground stroke our approach obtains better result than previous work without the need for assumption about ink bleed intensity or extensive parameter tuning our overall framework is detailed including front and back image alignment training data collection and the mrf formulation with associated likelihood and intraand interlayer cost computation 
camera calibration a a fundamental issue in computer vision is indispensable in many visual surveillance application firstly calibrated camera can help to deal with perspective distortion of object appearance on image plane secondly calibrated camera make it possible to recover metric from image which are robust to scene or view angle change in addition with calibrated camera we can make use of prior information of d model to estimate d pose of object and make object detection or tracking more robust to noise and occlusion in this paper we propose an automatic method to recover camera model from traffic scene surveillance video with only the camera height h measured we can completely recover both intrinsic and extrinsic parameter of camera based on appearance and motion of object in video experiment are conducted in different scene and experimental result demonstrate the effectiveness and practicability of our approach which can be adopted in many traffic scene surveillance application 
in this paper we consider the problem of recovering the spatial layout of indoor scene from monocular image the presence of clutter is a major problem for existing singleview d reconstruction algorithm most of which rely on finding the ground wall boundary in most room this boundary is partially or entirely occluded we gain robustness to clutter by modeling the global room space with a parameteric d box and by iteratively localizing clutter and refitting the box to fit the box we introduce a structured learning algorithm that chooses the set of parameter to minimize error based on global perspective cue on a dataset of image we demonstrate the ability of our algorithm to recover spatial layout in cluttered room and show several example of estimated free space 
in this paper we propose a novel graph based clustering approach with satisfactory clustering performance and low computational cost it consists of two main step tree fitting and partitioning we first introduce a probabilistic method to fit a tree to a data graph under the sense of minimum entropy then we propose a novel tree partitioning method under a normalized cut criterion called normalized tree partitioning ntp in which a fast combinatorial algorithm is designed for exact bipartitioning moreover we extend it to k way tree partitioning by proposing an efficient best first recursive bipartitioning scheme compared with spectral clustering ntp produce the exact global optimal bipartition introduces fewer approximation for k way partitioning and can intrinsically produce superior performance compared with bottom up aggregation method ntp adopts a global criterion and hence performs better last experimental result on image segmentation demonstrate that our approach is more powerful compared with existing graph based approach 
this paper present an online detection based two stage multi object tracking method in dense visual surveillance scenario with a single camera in the local stage a particle filter with observer selection that could deal with partial object occlusion is used to generate a set of reliable tracklets in the global stage the detection response are collected from a temporal sliding window to deal with ambiguity caused by full object occlusion to generate a set of potential tracklets the reliable tracklets generated in the local stage and the potential tracklets generated within the temporal sliding window are associated by hungarian algorithm on a modified pairwise tracklets association cost matrix to get the global optimal association this method is applied to the pedestrian class and evaluated on two challenging datasets the experimental result prove the effectiveness of our method 
the computational complexity of current visual categorization algorithm scale linearly at best with the number of category the goal of classifying simultaneously ncat visual category requires sub linear classification cost we explore algorithm for automatically building classification tree which have in principle logncat complexity we find that a greedy algorithm that recursively split the set of category into the two minimally confused subset achieves fold speedup at a small cost in classification performance our approach is independent of the specific classification algorithm used a welcome by product of our algorithm is a very reasonable taxonomy of the caltech dataset 
metric learning aim at finding a distance that approximates a task specific notion of semantic similarity typically a mahalanobis distance is learned from pair of data labeled a being semantically similar or not in this paper we learn such metric in a weakly supervised setting where bag of instance are labeled with bag of label we formulate the problem a a multiple instance learning mil problem over pair of bag if two bag share at least one label we label the pair positive and negative otherwise we propose to learn a metric using those labeled pair of bag leading to mildml for multiple instance logistic discriminant metric learning mildml iterates between update of the metric and selection of putative positive pair of example from positive pair of bag to evaluate our approach we introduce a large and challenging data set labeled yahoo news which we have manually annotated and contains detected face of different people in image we group the face detected in an image into a bag and group the name detected in the caption into a corresponding set of label when the label come from manual annotation we find that mildml using the bag level annotation performs a well a fully supervised metric learning using instance level annotation we also consider performance in the case of automatically extracted label for the bag where some of the bag label do not correspond to any example in the bag in this case mildml work substantially better than relying on noisy instance level annotation derived from the bag level annotation by resolving face name association in image with their caption 
online boosting method have recently been used successfully for tracking background subtraction etc conventional online boosting algorithm emphasize on interchanging new weak classifier feature to adapt with the change over time we are proposing a new online boosting algorithm where the form of the weak classifier themselves are modified to cope with scene change instead of replacement the parameter of the weak classifier are altered in accordance with the new data subset presented to the online boosting process at each time step thus we may avoid altogether the issue of how many weak classifier to be replaced to capture the change in the data or which efficient search algorithm to use for a fast retrieval of weak classifier a computationally efficient method ha been used in this paper for the adaptation of linear weak classifier the proposed algorithm ha been implemented to be used both a an online learning and a tracking method we show quantitative and qualitative result on both uci datasets and several video sequence to demonstrate improved performance of our algorithm cvpr 
we present fast d surface registration method for inhand modeling this allows user to scan complete object swiftly by simply turning them around in front of the scanner the paper make two main contribution first we propose an efficient method for detecting registration failure which is a vital property of any automatic modeling system our method is based on two different consistency test one based on geometry and one based on texture second we extend icp by three additional fast registration method for both coarse and fine alignment based on both texture and geometry each of those method brings in additional information that can compensate for ambiguity in the other cue together they allow for the robust reconstruction of a large variety of object with different geometric and photometric property finally we show how both failure detection and fast registration can be combined in a practical and robust in hand modeling system that operates at interactive frame rate 
abstract we present a real time algorithm to estimate the d pose of a previously unseen face from a single range image based on a novel shape signature to identify nose in range image we generate candidate for their position and then generate and evaluate many pose hypothesis in parallel using modern graphic processing unit gpus we developed a novel error function that compare the input range image to precomputed pose image of an average face model the algorithm is robust to large pose variation of at fps to evaluate the algorithm we built a database of range image with large pose variation and developed a method for automatic ground truth annotation 
graph cut optimization is prevalent in vision and graphic problem it is thus of great practical importance to parallelize the graph cut optimization using today s ubiquitous multi core machine however the current best serial algorithm by boykov and kolmogorov called the bk algorithm still ha the superior empirical performance it is non trivial to parallelize a expensive synchronization overhead easily offset the advantage of parallelism in this paper we propose a novel adaptive bottom up approach to parallelize the bk algorithm we first uniformly partition the graph into a number of regularly shaped disjoint subgraphs and process them in parallel then we incrementally merge the subgraphs in an adaptive way to obtain the global optimum the new algorithm ha three benefit it is more cache friendly within smaller subgraphs it keep balanced workload among computing core it cause little overhead and is adaptable to the number of available core extensive experiment in common application such a d d image segmentation and d surface fitting demonstrate the effectiveness of our approach 
scene understanding in the context of a smart meeting room involves the extraction of various kind of cue at different level of semantic abstraction specifically human activity in a scene is usually monitored using array of audio and visual sensor task such a person localization and tracking speaker id focus of attention detection speech recognition and affective state recognition are among them in this paper we demonstrate a system that extract such information by synergistically combining the information from the various task to support each other we exploit the fact that the output of one kind of human activity analysis task contains valuable information for another such block and by interconnecting them a robust system result we demonstrate this in a smart meeting room context equipped with camera and microphone the system performs the task of person tracking head pose estimation beamforming speaker id and speech recognition using audio and visual cue the novelty lie in putting together the task such that they can provide relevant information to one another we evaluate the performance of our system and present result for task such a keyword spotting and tracking re identification on real world meeting scene collected in our audio visual testbed 
in this paper we propose a robust and efficient approach to localizingand estimatingthe motion of non rigidand articulated object using marginal trajectory spectrum learning detecting the motion directly in the euclidean space is often found difficult to guarantee a smooth and accurate result and might be affected by drifting these issue however can be addressed effectively by formulatingthe motion estimation problem a spectrum detection in the trajectory space the full trajectory space can be decomposed into orthogonalsubspaces defined by generic base such a the discrete fourier transform dft the obtained representation is shown to be compact facilitating efficient learning and optimization in it marginal space in the training stage local feature are extended in the temporal domain to integrate the time coherence constraint and selected via boosting to form strong classifier an incremental optimization is performed in sparse marginal space learned from the training data to maximize efficiency and robustness we constrain the search based on cluster of hypothesis defined in each subspace experiment demonstrate the performance of the proposed method on articulated motion estimationof aortic and mitral valve from ultrasounddata our method is evaluated on d tee sequence volume with the accuracy in the range of the inter user variability of expert user it provides in le than second with an precision of mm a personalized d model of aorticand mitral valve crucial for the clinical workflow 
to learn a new visual category from few example prior knowledge from unlabeled data a well a previous related category may be useful we develop a new method for transfer learning which exploit available unlabeled data and an arbitrary kernel function we form a representation based on kernel distance to a large set of unlabeled data point to transfer knowledge from previous related problem we observe that a category might be learnable using only a small subset of reference prototype related problem may share a signicant number of relevant prototype we nd such a concise representation by performing a joint loss minimization over the training set of related problem with a shared regularization penalty that minimizes the total number of prototype involved in the approximation this optimization problem can be formulated a a linear program that can be solved efciently we conduct experiment on a news topic prediction task where the goal is to predict whether an image belongs to a particular news topic our result show that when only few example are available for training a target topic leveraging knowledge learnt from other topic can signicantly improve performance 
the internet contains billion of image freely available online method for efficiently searching this incredibly rich resource are vital for a large number of application these include object recognition computer graphic personal photo collection online image search tool in this paper our goal is to develop efficient image search and scene matching technique that are not only fast but also require very little memory enabling their use on standard hardware or even on handheld device our approach us recently developed machine learning technique to convert the gist descriptor a real valued vector that describes orientation energy at different scale and orientation within an image to a compact binary code with a few hundred bit per image using our scheme it is possible to perform real time search with million from the internet using a single large pc and obtain recognition result comparable to the full descriptor using our code on high quality labeled image from the labelme database give surprisingly powerful recognition result using simple nearest neighbor technique 
the ever increasing gigantic amount of image over the web necessitates automatic scheme for meta tagging content description such a object category these meta tag are essential to text based image search engine to improve their search relevance traditional supervised scheme is not suitable for this task because it need too much manual labelling effort and yet is hard to scale to a large number of object category notice that in the search scenario the meta tagging doe not need to be perfect to help improve relevance because the available text tag and user click through log can partially rectify the inaccurate information a weakly supervised scheme would be ideal when only sporadic labelled example are exploited in spite of the expected loss in tagging accuracy in this paper we develop a novel weakly semi supervised ensemble classifier trained based on a co training framework for this tagging task in essence the meta tag are recursively propagated from the sparsely tagged example to the un tagged one preliminary experiment on benchmark database such a graz demonstrate the efficacy of the proposed approach 
in factorization approach to nonrigid structure from motion the d shape of a deforming object is usually modeled a a linear combination of a small number of basis shape the original approach to simultaneously estimate the shape basis and nonrigid structure exploited orthonormality constraint for metric rectification recently it ha been asserted that structure recovery through orthonormality constraint alone is inherently ambiguous and cannot result in a unique solution this assertion ha been accepted a conventional wisdom and is the justification of many remedial heuristic in literature our key contribution is to prove that orthonormality constraint are in fact sufficient to recover the d structure from image observation alone we characterize the true nature of the ambiguity in using orthonormality constraint for the shape basis and show that it ha no impact on structure reconstruction we conclude from our experimentation that the primary challenge in using shape basis for nonrigid structure from motion is the difficulty in the optimization problem rather than the ambiguity in orthonormality constraint 
we present a system for the estimation of unconstrained d human upper body movement from multiple camera it main novelty lie in the integration of three component single framepose recovery temporal integrationandmodel adaptation single frame pose recovery consists of a hypothesis generation stage where candidate d pose are generated based on hierarchical shape matching in the individual camera view in the subsequent hypothesis verification stage candidate d pose are re projected to the other camera view and ranked according to a multi view matching score temporal integration consists of computing best trajectory combining a motion model and observation in a viterbi style maximum likelihood approach pose that lie on the best trajectory are used to generate and adapt a texture model which in turn enriches the shape component used for pose recovery we demonstrate that our approach outperforms the state of the art in experiment with large and challenging real world data from an outdoor setting the new data set is made public to facilitate benchmarking 
this paper present a multi frame data association algorithm for tracking multiple target in video sequence multi frame data association involves finding the most probable correspondence between target track and measurement collected over multiple time instance a well a handling the common tracking problem such a track initiation and termination occlusion and noisy detection the problem is known to be np hard for more than two frame a rank constrained continuous formulation of the problem is presented that can be efficiently solved using nonlinear optimization method it is shown that the global and local extremum of the continuous problem respectively coincide with the maximum and the maximal solution of the discrete counterpart a scanning window based tracking algorithm is developed using the formulation that performs well under noisy condition with frequent occlusion and multiple track initiation and termination the above claim are supported by experiment and quantitative evaluation using both synthetic and real data under different operating condition 
we present an algorithm to reduce per pixel search range for markov random field based stereo algorithm our algorithm is based on the intuition that reliably matched pixel need le regularization in the energy minimization and neighboring pixel should have similar disparity search range if their pixel value are similar we propose a novel bi labeling process to classify reliable and unreliable pixel that incorporate left right consistency check we then propagate the reliable disparity into unreliable region to form a complete disparity map and construct per pixel search range based on the difference between the disparity map after propagation and the one computed from a winner take all method experimental result evaluated on the middlebury stereo benchmark show our proposed algorithm is able to achieve average reduction rate while preserving satisfactory accuracy 
unsupervised over segmentation of an image into superpixels is a common preprocessing step for image parsing algorithm superpixels are used a both region of support for feature vector and a a starting point for the final segmentation in this paper we investigate incorporating a priori information into superpixel segmentation we learn a probabilistic model that describes the spatial density of the object boundary in the image we then describe an over segmentation algorithm that partition this density roughly equally between superpixels whilst still attempting to capture local object boundary we demonstrate this approach using road scene where object in the center of the image tend to be more distant and smaller than those at the edge we show that our algorithm successfully learns this foveated spatial distribution and can exploit this knowledge to improve the segmentation lastly we introduce a new metric for evaluating vision labeling problem we measure performance on a challenging real world dataset and illustrate the limitation of conventional evaluation metric 
in this paper we propose a method for estimating the optical center of a camera given only a single image with vignetting this is accomplished by identifying the center of the vignetting effect in the image through an analysis of semicircular tangential gradient sctgs for a given image pixel the sctg is the image gradient along the tangential direction of the circle centered at the currently estimated optical center and passing through the pixel we show that for natural image with vignetting the distribution of sctgs is generally symmetric if the optical center is estimated accurately but is skewed otherwise by minimizing the asymmetry of the sctg distribution with nonlinear optimization our method is able to obtain reliable estimate of the optical center experiment on simulated and real vignetting image demonstrate the effectiveness of this technique 
by combining histogram of oriented gradient hog and local binary pattern lbp a the feature set we propose a novel human detection approach capable of handling partial occlusion two kind of detector i e global detector for whole scanning window and part detector for local region are learned from the training data using linear svm for each ambiguous scanning window we construct an occlusion likelihood map by using the response of each block of the hog feature to the global detector the occlusion likelihood map is then segmented by mean shift approach the segmented portion of the window with a majority of negative response is inferred a an occluded region if partial occlusion is indicated with high likelihood in a certain scanning window part detector are applied on the unoccluded region to achieve the final classification on the current scanning window with the help of the augmented hog lbp feature and the global part occlusion handling method we achieve a detection rate of with fppw with fppw and with fppw on the inria dataset which to our best knowledge is the best human detection performance on the inria dataset the global part occlusion handling method is further validated using synthesized occlusion data constructed from the inria and pascal dataset 
visual categorization problem such a object classification or action recognition are increasingly often approached using a detection strategy a classifier function is first applied to candidate subwindows of the image or the video and then the maximum classifier score is used for class decision traditionally the subwindow classifier are trained on a large collection of example manually annotated with mask or bounding box the reliance on time consuming human labeling effectively limit the application of these method to problem involving very few category furthermore the human selection of the mask introduces arbitrary bias e g in term of window size and location which may be suboptimal for classification in this paper we propose a novel method for learning a discriminative subwindow classifier from example annotated with binary label indicating the presence of an object or action of interest but not it location during training our approach simultaneously localizes the instance of the positive class and learns a subwindow svm to recognize them we extend our method to classification of time series by presenting an algorithm that localizes the most discriminative set of temporal segment in the signal we evaluate our approach on several datasets for object and action recognition and show that it achieves result similar and in many case superior to those obtained with full supervision 
abstract one promising approach to remove motion deblurring is to recover one clear image using an image pair existing dual image method require an accurate image alignment between the image pair which could be very challenging even with the help of user interaction based on the observation that typical motion blur kernel will have an extremely sparse representation in the redundant curvelet system we propose a new minimization model to recover a clear image from the blurred image pair by enhancing the sparsity of blur kernel in the curvelet system the sparsity prior on the motion blur kernel improves the robustness of our algorithm to image alignment error and image formation noise also a numerical method is presented to efficiently solve the resulted minimization problem the experiment showed that our proposed algorithm is capable of accurately estimating the blur kernel of complex camera motion with low requirement on the accuracy of image alignment which in turn led to a high quality recovered image from the blurred image pair 
we present a novel and effective algorithm for rotation symmetry group detection from real world image we propose a frieze expansion method that transforms rotation symmetry group detection into a simple translation symmetry detection problem we define and construct a dense symmetry strength map from a given image and search for potential rotational symmetry center automatically frequency analysis using discrete fourier transform dft is applied to the frieze expansion pattern to uncover the type and the cardinality of multiple rotation symmetry group in an image concentric or otherwise furthermore our detection algorithm can discriminate discrete versus continuous and cyclic versus dihedral symmetry group and identify the corresponding supporting region in the image experimental result on over synthetic and natural image demonstrate superior performance of our rotation detection algorithm in accuracy and in speed over the state of the art rotation detection algorithm 
this paper present an approach to extracting and using semantic layer from low altitude aerial video for scene understanding and object tracking the input video is captured by low flying aerial platform and typically consists of strong parallax from non ground plane structure a key aspect of our approach is the use of geo registration of video frame to reference image database such a those available from terraserver and google satellite imagery to establish a geo spatial coordinate system for pixel in the video geo registration enables euclidean d reconstruction with absolute scale unlike traditional monocular structure from motion where continuous scale estimation over long period of time is an issue geo registration also enables correlation of video data to other stored information source such a gi geo spatial information system database in addition to the geo registration and d reconstruction aspect the key contribution of this paper include exploiting appearance and d shape constraint derived from geo registered video for labeling of structure such a building foliage and road for scene understanding and elimination of moving object detection and tracking error using d parallax constraint and semantic label derived from geo registered video experimental result on extended time aerial video data demonstrates the qualitative and quantitative aspect of our work 
in video surveillance scenario appearance of both human and their nearby scene may experience large variation due to scale and view angle change partial occlusion or interaction of a crowd these challenge may weaken the effectiveness of a dedicated target observation model even based on multiple cue which demand for an agile framework to adjust target observation model dynamically to maintain their discriminative power towards this end we propose a new adaptive way to integrate multi cue in tracking multiple human driven by human detection given a human detection can be reliably associated with an existing trajectory we adapt the way how to combine specifically devised model based on different cue in this tracker so a to enhance the discriminative power of the integrated observation model in it local neighborhood this is achieved by solving a regression problem efficiently specifically we employ observation model for a single person tracker based on color model of part of torso region an elliptical head model and bag of local feature respectively extensive experiment on challenging surveillance datasets demonstrate long term reliable tracking performance of this method 
active learning strategy can be useful when manual labeling effort is scarce a they select the most informative example to be annotated first however for visual category learning the active selection problem is particularly complex a single image will typically contain multiple object label and an annotator could provide multiple type of annotation e g class label bounding box segmentation any of which would incur a variable amount of manual effort we present an active learning framework that predicts the tradeoff between the effort and information gain associated with a candidate image annotation thereby ranking unlabeled and partially labeled image according to their expected net worth to an object recognition system we develop a multi label multiple instance approach that accommodates multi object image and a mixture of strong and weak label since the annotation cost can vary depending on an image s complexity we show how to improve the active selection by directly predicting the time required to segment an unlabeled image given a small initial poolof labeleddata the proposedmethod actively improves the category model with minimal manual intervention 
sparse feature have traditionally been tracked from frame to frame independently of one another we propose a framework in which feature are tracked jointly combining idea from lucas kanade and horn schunck the estimated motion of a feature is influenced by the estimated motion of neighboring feature the approach also handle the problem of tracking edge in a unified way by estimating motion perpendicular to the edge using the motion of neighboring feature to resolve the aperture problem result are shown on several image sequence to demonstrate the improved result obtained by the approach 
head pose and eye location estimation are two closely related issue which refer to similar application area in recent year these problem have been studied individually in numerous work in the literature previous research show that cylindrical head model and isophote based scheme provide satisfactory precision in head pose and eye location estimation respectively however the eye locator is not adequate to accurately locate eye in the presence of extreme head pose therefore head pose cue may be suited to enhance the accuracy of eye localization in the presence of severe head pose in this paper a hybrid scheme is proposed in which the transformation matrix obtained from the head pose is used to normalize the eye region and in turn the transformation matrix generated by the found eye location is used to correct the pose estimation procedure the scheme is designed to enhance the accuracy of eye location estimation in low resolution video to extend the operating range of the eye locator and to improve the accuracy and re initialization capability of the pose tracker from the experimental result it can be derived that the proposed unified scheme improves the accuracy of eye estimation by to further it considerably extends it operating range by more than by overcoming the problem introduced by extreme head pose finally the accuracy of the head pose tracker is improved by to 
we analyze a previously unexplored generalization of the scalar total variation to vector valued function which is motivated by geometric measure theory a complete mathematical characterization is given which prof important invariance property a well a existence of solution of the vectorial rof model a an important feature there exists a dual formulation for the proposed vectorial total variation which lead to a fast and stable minimization algorithm the main difference to previous approach with similar property is that we penalize across a common edge direction for all channel which is a major theoretical advantage experiment show that this lead to a significantly better restoration of color edge in practice 
we present a method for detecting and parsing building from unorganized d point cloud into a compact hierarchical representation that is useful for high level task the input is a set of range measurement that cover large scale urban environment the desired output is a set of parse tree such that each tree represents a semantic decomposition of a building the node are roof surface a well a volumetric part inferred from the observable surface we model the above problem using a simple and generic grammar and use an efficient dependency parsing algorithm to generate the desired semantic description we show how to learn the parameter of this simple grammar in order to produce correct par of complex structure we are able to apply our model on large point cloud and parse an entire city 
given a multi exposure sequence of a scene our aim is to recover the absolute irradiance falling onto a linear camera sensor the established approach is to perform a weighted average of the scaled input exposure however there is no clear consensus on the appropriate weighting to use we propose a weighting function that produce statistically optimal estimate under the assumption of compound gaussian noise our weighting is based on a calibrated camera model that account for all noise source this model also allows u to simultaneously estimate the irradiance and it uncertainty we evaluate our method on simulated and real world photograph and show that we consistently improve the signal to noise ratio over previous approach finally we show the effectiveness of our model for optimal exposure sequence selection and hdr image denoising 
we propose a method for estimating inherent surface color robustly against image noise from two registered image taken under different outdoor illumination we formulate the estimation based on maximum likelihood manner while considering both inter pixel and intra pixel relationship we define inter pixel relationship based on stochastic behavior of image noise and property of outdoor illumination chromaticity we rely on the spatial continuity of both surface color and illumination to define intra pixel relationship we also propose to maximize the estimation function in two step manner experimental result demonstrate the significant improvement of the proposed method in estimation accuracy compared to previous method 
object recognition is challenging due to high intra class variability caused e g by articulation viewpoint change and partial occlusion successful method need to strike a balance between being flexible enough to model such variation and discriminative enough to detect object in cluttered real world scene motivated by these challenge we propose a latent conditional random field crf based on a flexible assembly of part by modeling part label a hidden node and developing an em algorithm for learning from class label alone this new approach enables the automatic discovery of semantically meaningful object part representation to increase the flexibility and expressiveness of the model we learn the pairwise structure of the underlying graphical model at the level of object part interaction efficient gradient based technique are used to estimate the structure of the domain of interest and carried forward to the multi label or object part case our experiment illustrate the meaningfulness of the discovered part and demonstrate state of the art performance of the approach 
vision based road detection is important in different area of computer vision such a autonomous driving car collision warning and pedestrian crossing detection however current vision based road detection method are usually based on low level feature and they assume structured road road homogeneity and uniform lighting condition therefore in this paper contextual d information is used in addition to low level cue low level photometric invariant cue are derived from the appearance of road contextual cue used include horizon line vanishing point d scene layout and d road stage moreover temporal road cue are included all these cue are sensitive to different imaging condition and hence are considered a weak cue therefore they are combined to improve the overall performance of the algorithm to this end the low level contextual and temporal cue are combined in a bayesian framework to classify road sequence large scale experiment on road sequence show that the road detection method is robust to varying imaging condition road type and scenario tunnel urban and highway further using the combined cue outperforms all other individual cue finally the proposed method provides highest road detection accuracy when compared to state of the art method 
detecting an object part relies on two source of information the appearance of the part itself and the context supplied by surrounding part in this paper we consider problem in which a target part cannot be recognized reliably using it own appearance such a detecting low resolution hand and must be recognized using the context of surrounding part we develop the chain model which can locate part of interest in a robust and precise manner even when the surrounding context is highly variable and deformable in the proposed model the relation between context feature and the target part is modeled in a non parametric manner using an ensemble of feature chain leading from part in the context to the detection target the method us the configuration of the feature in the image directly rather than through fitting an articulated d model of the object in addition the chain are composable meaning that new chain observed in the test image can be composed of sub chain seen during training consequently the model is capable of handling object pose which are infrequent even non existent during training we test the approach in different setting including object part detection a well a complete object detection the result show the advantage of the chain model for detecting and localizing part of complex deformable object 
this paper describes how phase sensitive rotation invariant for three dimensional data may be obtained a bispectrum is formulated for rotation and it property are derived for spherical harmonic coefficient a well a for moment the bispectral invariant offer improved discrimination over previously published magnitude only invariant they are able to distinguish rotation from reflection a well a rotation of an entire shape from component wise rotation of element of the shape a experiment show they provide robust performance for both surface and voxel data 
this paper show that the performance of a binary classifier can be significantly improved by the processing of structured unlabeled data i e data are structured if knowing the label of one example restricts the labeling of the others we propose a novel paradigm for training a binary classifier from labeled and unlabeled example that we call p n learning the learning process is guided by positive p and negative n constraint which restrict the labeling of the unlabeled set p n learning evaluates the classifier on the unlabeled data identifies example that have been classified in contradiction with structural constraint and augments the training set with the corrected sample in an iterative process we propose a theory that formulates the condition under which p n learning guarantee improvement of the initial classifier and validate it on synthetic and real data p n learning is applied to the problem of on line learning of object detector during tracking we show that an accurate object detector can be learned from a single example and an unlabeled video sequence where the object may occur the algorithm is compared with related approach and state of the art is achieved on a variety of object face pedestrian car motorbike and animal 
given a set of d image we propose a novel approach for the reconstruction of straight d line segment that represent the underlying geometry of static d object in the scene such an algorithm is especially useful for the automatic d reconstruction of man made environment the main contribution of our approach is the generation of an improved reconstruction by imposing global topological constraint given by connection between neighbouring line additionally our approach doe not employ explicit line matching between view thus making it more robust against image noise and partial occlusion furthermore we suggest a technique to merge independent reconstruction that are generated from different base image which also help to remove outlier the proposed algorithm is evaluated on synthetic and real scene by comparison with ground truth 
in this paper we propose a method for calibrating relative position and orientation of multiple unsynchronized camera from general moving point if the sampling time of multiple camera are different from each other there is no corresponding point in the image of moving point and we cannot calibrate these camera in this paper we analyze geometric relationship of multiple camera in the frequency space and show that they enable u to calibrate multiple unsynchronized camera accurately even if exact corresponding point do not exist in image the proposed method doe not require any interpolation of moving point in image 
we propose a novel method for automatic camera calibration and foot head homology estimation by observing person standing at several position in the camera field of view we demonstrate that human body can be considered a a calibration target thus avoiding special calibration object or manually established fiducial point first by assuming roughly parallel human pose we derive a new constraint which allows to formulate the calibration of internal and external camera parameter a a quadratic eigenvalue problem secondly we couple the calibration with an improved effective integral contour based human detector and use d projected model to capture a large variety of person and camera mutual position the resulting camera auto calibration method is very robust and efficient and thus well suited for surveillance application where the camera calibration process cannot use special calibration target and must be simple 
this paper introduces a novel method for reconstructing human eye and visual display from reflection on the cornea this problem is difficult because the camera is not directly facing the display but instead capture the eye of a person in front of the display reconstruction of eye and display is useful for point of gaze estimation which can be approximated from the d position of the iris and display it is shown that iris boundary limbus and display reflection in a single intrinsically calibrated image provide enough information for such an estimation the proposed method assumes a simplified geometric eyeball model with certain anatomical constant which are used to reconstruct the eye a noise performance analysis show the sensitivity of the proposed method to imperfect data experiment on various subject show that it is possible to determine the approximate area of gaze on a display from a single image 
in matching task in computer vision and particularly in real time tracking from video there are generally strong prior available on absolute and relative correspondence location thanks to motion and scene model while these prior are often partially used post hoc to resolve matching consensus in algorithm like ransac it wa recently shown that fully integrating them in an active matching am approach permit efficient guided image processing with rigorous decision guided by information theory am s weakness wa that the overhead induced by intermediate bayesian update required meant poor scaling to case where many correspondence were sought in this paper we show that relaxation of the rigid probabilistic model of am where every feature measurement directly affect the prediction of every other permit dramatically more scalable operation without affecting accuracy we take a general graph theoretic view of the structure of prior information in matching to sparsify and approximate the interconnection we demonstrate the performance of two variation clam and subam in the context of sequential camera tracking these algorithm are highly competitive with other technique at matching hundred of feature per frame while retaining great intuitive appeal and the full probabilistic capability to digest prior information 
piecewise planar model for stereo have recently become popular for modeling indoor and urban outdoor scene the strong planarity assumption overcomes the challenge presented by poorly textured surface and result in low complexity d model for rendering storage and transmission however such a model performs poorly in the presence of non planar object for example bush tree and other clutter present in many scene we present a stereo method capable of handling more general scene containing both planar and non planar region our proposed technique segment an image into piecewise planar region a well a region labeled a non planar the non planar region are modeled by the result of a standard multi view stereo algorithm the segmentation is driven by multi view photoconsistency a well a the result of a color and texture based classifier learned from hand labeled planar and non planar image region additionally our method link and fuse plane hypothesis across multiple overlapping view ensuring a consistent d reconstruction over an arbitrary number of image using our system we have reconstructed thousand of frame of street level video result show our method successfully recovers piecewise planar surface alongside general d surface in challenging scene containing large building a well a residential house 
we present a background model that differentiates between background motion and foreground object unlike most model that represent the variability of pixel intensity at a particular location in the image we model the underlying warping of pixel location arising from background motion the background is modeled a a set of warping layer where at any given time different layer may be visible due to the motion of an occluding layer foreground region are thus defined a those that cannot be modeled by some composition of some warping of these background layer we illustrate this concept by first reducing the possible warp to those where the pixel are restricted to displacement within a spatial neighborhood and then learning the appropriate size of that spatial neighborhood then we show how change in intensity color histogram of pixel neighborhood can be used to discriminate foreground and background region we find that this approach compare favorably with the state of the art while requiring le computation 
object are usually embedded into context visual context ha been successfully used in object detection task however it is often ignored in object tracking we propose a method to learn supporter which are be it only temporally useful for determining the position of the object of interest our approach exploit the general hough transform strategy it couple the supporter with the target and naturally distinguishes between strongly and weakly coupled motion by this the position of an object can be estimated even when it is not seen directly e g fully occluded or outside of the image region or when it change it appearance quickly and significantly experiment show substantial improvement in model free tracking a well a in the tracking of virtual point e g in medical application 
it ha been shown that the d shape of a deformable surface in an image can be recovered by establishing correspondence between that image and a reference one in which the shape is known these match can then be used to set up a convex optimization problem in term of the shape parameter which is easily solved however in many case the correspondence are hard to establish reliably in this paper we show that we can solve simultaneously for both d shape and correspondence thereby using d shape constraint to guide the image matching and increasing robustness for example when the texture are repetitive this involves solving a mixed integer quadratic problem while optimizing this problem is np hard in general we show that it solution can nevertheless be approximated effectively by a branch and bound algorithm 
simultaneous registration and segmentation sr provides a powerful framework for tracking an object of interest in an image sequence the state of the art sr based tracking method assume that the illumination is maintained constant across consecutive frame however this assumption doe not hold in many natural image sequence due to dynamic light source and shadow we propose a generalized model for sr based tracking in this paper to account for non uniform additive illumination change more specifically we introduce two new term in the sr energy functional which address the above mentioned problem the first term couple the shape based cue and intensity based cue to establish a correspondence between them the second term compensates for the illumination change which is complementary to the first term we demonstrate that the proposed sr energy functional yield superior performance over the state of the art sr based method for various indoor and outdoor image sequence 
kernel regression technique such a relevance vector machine rvm regression support vector regression and gaussian process are widely used for solving many computer vision problem such a age head pose d human pose and lighting estimation however the presence of outlier in the training dataset make the estimate from these regression technique unreliable in this paper we propose robust version of the rvm regression that can handle outlier in the training dataset we decompose the noise term in the rvm formulation into a sparse outlier noise term and a gaussian noise term we then estimate the outlier noise along with the model parameter we present two approach for solving this estimation problem a bayesian approach which essentially follows the rvm framework and an optimization approach based on basis pursuit denoising in the bayesian approach the robust rvm problem essentially becomes a bigger rvm problem with the advantage that it can be solved efficiently by a fast algorithm empirical evaluation and real experiment on image de noising and age estimation demonstrate the better performance of the robust rvm algorithm over that of the rvm reg ression 
enlarging or reducing the template size by adding new part or removing part of the template according to their suitability for tracking requires the ability to deal with the variation of the template size for instance real time template tracking using linear predictor although fast and reliable requires using template of fixed size and doe not allow on line modification of the predictor to solve this problem we propose the adaptive linear predictor alp which enable fast online modification of pre learned linear predictor instead of applying a full matrix inversion for every modification of the template shape a standard approach to learning linear predictor do we just perform a fast update of this inverse this allows u to learn the alp in a much shorter time than standard learning approach while performing equally well we performed exhaustive evaluation of our approach and compared it to standard linear predictor and other state of the art approach 
markov random field with higher order potential have emerged a a powerful model for several problem in computer vision in order to facilitate their use we propose a new representation for higher order potential a upper and lower envelope of linear function our representation concisely model several commonly used higher order potential thereby providing a unified framework for minimizing the corresponding gibbs energy function we exploit this framework by converting lower envelope potential to standard pairwise function with the addition of a small number of auxiliary variable this allows u to minimize energy function with lower envelope potential using conventional algorithm such a bp trw and expansion furthermore we show how the minimization of energy function with upper envelope potential lead to a difficult minmax problem we address this difficulty by proposing a new message passing algorithm that solves a linear programming relaxation of the problem although this is primarily a theoretical paper we demonstrate the efficacy of our approach on the binary fg bg segmentation problem 
acquiring and representing the d space of ray in the world the light field is important for many computer vision and graphic application yet light field acquisition is costly due to their high dimensionality existing approach either capture the d space explicitly or involve an error sensitive depth estimation process this paper argues that the fundamental difference between different acquisition and rendering technique is a difference between prior assumption on the light field we use the previously reported dimensionality gap in the d light field spectrum to propose a new light field prior the new prior is a gaussian assigning a non zero variance mostly to a d subset of entry since there is only a low dimensional subset of entry with non zero variance we can reduce the complexity of the acquisition process and render the d light field from d measurement set moreover the gaussian nature of the prior lead to linear and depth invariant reconstruction algorithm we use the new prior to render the d light field from a d focal stack sequence and to interpolate sparse directional sample and aliased spatial measurement in all case the algorithm reduces to a simple spatially invariant deconvolution which doe not involve depth estimation 
a recent dominating trend in tracking called tracking by detection us on line classifier in order to redetect object over succeeding frame although these method usually deliver excellent result and run in real time they also tend to drift in case of wrong update during the self learning process recent approach tackled this problem by formulating tracking by detection a either one shot semi supervised learning or multiple instance learning semi supervised learning allows for incorporating prior and is more robust in case of occlusion while multiple instance learning resolve the uncertainty where to take positive update during tracking in this work we propose an on line semi supervised learning algorithm which is able to combine both of these approach into a coherent framework this lead to more robust result than applying both approach separately additionally we introduce a combined loss that simultaneously us labeled and unlabeled sample which make our tracker more adaptive compared to previous on line semi supervised method experimentally we demonstrate that by using our semi supervised multiple instance approach and utilizing robust learning method we are able to outperform state of the art method on various benchmark tracking video 
purely bottom up unsupervised segmentation of a single image into foreground and background region remains a challenging task for computer vision co segmentation is the problem of simultaneously dividing multiple image into region segment corresponding to different object class in this paper we combine existing tool for bottom up image segmentation such a normalized cut with kernel method commonly used in object recognition these two set of technique are used within a discriminative clustering framework the goal is to assign foreground background label jointly to all image so that a supervised classifier trained with these label lead to maximal separation of the two class in practice we obtain a combinatorial optimization problem which is relaxed to a continuous convex optimization problem that can itself be solved efficiently for up to dozen of image we illustrate the proposed method on image with very similar foreground object a well a on more challenging problem with object with higher intra class variation 
we present a change detection method resistant to global and local illumination variation for use in visual surveillance scenario approach designed thus far for robustness to illumination change are generally based either on color normalization texture e g edge rank order statistic etc or illumination compensation normalization based method sacrifice discriminability while texture based method cannot operate on texture le region both type of method can produce large missing region in the distance image which in turn pose problem for higher level processing task that may be shape or region based and require accurate foreground mask e g person detection and tracking crowd segmentation etc texture based method have an additional problem in that they produce false alarm due to texture induced by local illumination effect e g cast shadow in this paper we propose a compensation based approach for change detection prior work on compensation ha largely taken an empirical approach and ha not dealt with the important problem of rejecting outlier when they dominate the scene in contrast our generative approach and systematic handling of outlier enables u to achieve robustness to illumination change while eliminating the problem mentioned above furthermore the computational complexity of our method is low enough for real time performance result comparing image taken under strongly different illumination condition demonstrate the power and generality of the proposed method 
we present two novel method to automatically learn spatio temporal dependency of moving agent in complex dynamic scene they allow to discover temporal rule such a the right of way between different lane or typical traffic light sequence to extract them sequence of activity need to be learned while the first method extract rule based on a learned topic model the second model called ddp hmm jointly learns co occurring activity and their time dependency to this end we employ dependent dirichlet process to learn an arbitrary number of infinite hidden markov model in contrast to previous work we build on state of the art topic model that allow to automatically infer all parameter such a the optimal number of hmms necessary to explain the rule governing a scene the model are trained offline by gibbs sampling using unlabeled training data 
this paper present a new approach for multi view object class detection appearance and geometry are treated a separate learning task with different training data our approach us a part model which discriminatively learns the object appearance with spatial pyramid from a database of real image and encodes the d geometry of the object class with a generative representation built from a database of synthetic model the geometric information is linked to the d training data and allows to perform an approximate d pose estimation for generic object class the pose estimation provides an efficient method to evaluate the likelihood of group of d part detection with respect to a full d geometry model in order to disambiguate and prune d detection and to handle occlusion in contrast to other method neither tedious manual part annotation of training image nor explicit appearance matching between synthetic and real training data is required which result in high geometric fidelity and in increased flexibility on the d object category datasets car and bicycle the current state of the art benchmark for d object detection our approach outperforms previously published result for viewpoint estimation 
a novel framework for anomaly detection in crowded scene is presented three property are identified a important for the design of a localized video representation suitable for anomaly detection in such scene joint modeling of appearance and dynamic of the scene and the ability to detect temporal and spatial abnormality the model for normal crowd behavior is based on mixture of dynamic texture and outlier under this model are labeled a anomaly temporal anomaly are equated to event of low probability while spatial anomaly are handled using discriminant saliency an experimental evaluation is conducted with a new dataset of crowded scene composed of video sequence and five well defined abnormality category the proposed representation is shown to outperform various state of the art anomaly detection technique 
we investigate dynamical model of human motion that can support both synthesis and analysis task unlike coarser discriminative model that work well when action class are nicely separated we seek model that have fine scale representational power and can therefore model subtle difference in the way an action is performed to this end we model an observed action a an unknown linear time invariant dynamical model of relatively small order driven by a sparse bounded input signal our motivating intuition is that the time invariant dynamic will capture the unchanging physical characteristic of an actor while the input used to excite the system will correspond to a causal signature of the action being performed we show that our model ha sufficient representational power to closely approximate large class of non stationary action with significantly reduced complexity we also show that temporal statistic of the inferred input sequence can be compared in order to recognize action and detect transition between them 
in this paper we considerably improve on a state of the art alpha matting approach by incorporating a new prior which is based on the image formation process in particular we model the prior probability of an alpha matte a the convolution of a high resolution binary segmentation with the spatially varying point spread function psf of the camera our main contribution is a new and efficient de convolution approach that recovers the prior model given an approximate alpha matte by assuming that the psf is a kernel with a single peak we are able to recover the binary segmentation with an mrf based approach which exploit flux and a new way of enforcing connectivity the spatially varying psf is obtained via a partitioning of the image into region of similar defocus incorporating our new prior model into a state of the art matting technique produce result that outperform all competitor which we confirm using a publicly available benchmark 
image matting is the process of extracting a soft segmentation of an object in an image a defined by the matting equation most current technique focus largely on computing the alpha value of unknown pixel and treat computation of the foreground and background color a an afterthought if at all however for many application such a compositing an object into a new scene or deleting an object from the scene the foreground and background color are vital for an acceptable answer we propose a method of solving for the foreground background and alpha of an unknown region in an image simultaneously this allows for novel constraint to be placed directly on the foreground and background a well a on alpha we show through both visual result and quantitative measurement on standard datasets that this approach produce more accurate foreground and background value at each pixel while maintaining competitive result on the alpha matte 
we present a novel method for the discovery and statistical representation of motion pattern in a scene observed by a static camera related method involving learning of pattern of activity rely on trajectory obtained from object detection and tracking system which are unreliable in complex scene of crowded motion we propose a mixture model representation of salient pattern of optical flow and present an algorithm for learning these pattern from dense optical flow in a hierarchical unsupervised fashion using low level cue of noisy optical flow k mean is employed to initialize a gaussian mixture model for temporally segmented clip of video the component of this mixture are then filtered and instance of motion pattern are computed using a simple motion model by linking component across space and time motion pattern are then initialized and membership of instance in different motion pattern is established by using kl divergence between mixture distribution of pattern instance finally a pixel level representation of motion pattern is proposed by deriving conditional expectation of optical flow result of extensive experiment are presented for multiple surveillance sequence containing numerous pattern involving both pedestrian and vehicular traffic 
we describe a general method for building cascade classifier from part based deformable model such a pictorial structure we focus primarily on the case of star structured model and show how a simple algorithm based on partial hypothesis pruning can speed up object detection by more than one order of magnitude without sacrificing detection accuracy in our algorithm partial hypothesis are pruned with a sequence of threshold in analogy to probably approximately correct pac learning we introduce the notion of probably approximately admissible paa threshold such threshold provide theoretical guarantee on the performance of the cascade method and can be computed from a small sample of positive example finally we outline a cascade detection algorithm for a general class of model defined by a grammar formalism this class includes not only tree structured pictorial structure but also richer model that can represent each part recursively a a mixture of other part 
kernel machine rely on an implicit mapping of the data such that non linear classification in the original space corresponds to linear classification in the new space a kernel machine are difficult to scale to large training set it ha been proposed to perform an explicit mapping of the data and to learn directly linear classifier in the new space in this paper we consider the problem of learning image categorizers on large image set e g k image using bag of visual word bov image representation and support vector machine classifier we experiment with three approach to bov embedding kernel pca kpca a modified kpca we propose for additive kernel and random projection for shift invariant kernel we report experiment on datasets cal tech voc and imagenet an important conclusion is that simply square rooting bov vector which corresponds to an exact mapping for the bhattacharyya kernel already lead to large improvement often quite close to the best result obtained with additive kernel another conclusion is that although it is possible to go beyond additive kernel the embedding come at a much higher cost 
this paper address action spotting the spatiotemporal detection and localization of human action in video a novel compact local descriptor of video dynamic in the context of action spotting is introduced based on visual spacetime oriented energy measurement this descriptor is efficiently computed directly from raw image intensity data and thereby forgoes the problem typically associated with flow based feature an important aspect of the descriptor is that it allows for the comparison of the underlying dynamic of two spacetime video segment irrespective of spatial appearance such a difference induced by clothing and with robustness to clutter an associated similarity measure is introduced that admits efficient exhaustive search for an action template across candidate video sequence empirical evaluation of the approach on a set of challenging natural video suggests it efficacy 
in this paper we present an appearance based method for person re identification it consists in the extraction of feature that model three complementary aspect of the human appearance the overall chromatic content the spatial arrangement of color into stable region and the presence of recurrent local motif with high entropy all this information is derived from different body part and weighted opportunely by exploiting symmetry and asymmetry perceptual principle in this way robustness against very low resolution occlusion and pose viewpoint and illumination change is achieved the approach applies to situation where the number of candidate varies continuously considering single image or bunch of frame for each individual it ha been tested on several public benchmark datasets viper ilids ethz gaining new state of the art performance 
maji and berg have recently introduced an explicit feature map approximating the intersection kernel this enables efficient learning method for linear kernel to be applied to the non linear intersection kernel expanding the applicability of this model to much larger problem in this paper we generalize this idea and analyse a large family of additive kernel called homogeneous in a unified framework the family includes the intersection hellinger s and kernel commonly employed in computer vision using the framework we are able to i provide explicit feature map for all homogeneous additive kernel along with closed form expression for all common kernel ii derive corresponding approximate finite dimensional feature map based on the fourier sampling theorem and iii quantify the extent of the approximation we demonstrate that the approximation have indistinguishable performance from the full kernel on a number of standard datasets yet greatly reduce the train test time of svm implementation we show that the kernel which ha been found to yield the best performance in most application also ha the most compact feature representation given these train test advantage we are able to obtain a significant performance improvement over current state of the art result based on the intersection kernel 
winder et al have recently shown the superiority of the daisy descriptor in comparison to other widely extended descriptor such a sift and surf motivated by those result we present a novel algorithm that extract viewpoint and illumination invariant keypoints and describes them with a particular implementation of a daisy like layout we demonstrate how to efficiently compute the scale space and re use this information for the descriptor comparison to similar approach such a sift and surf show higher precision v recall performance of the proposed method moreover we dramatically reduce the computational cost by a factor of x and x respectively we also prove the use of the proposed method for computer vision application 
classification of image in many category datasbets ha rapidly improved in recent year however system that perform well on particular datasets typically have one or more limitation such a a failure to generalize across visual task e g requiring a face detector or extensive retuning of parameter insufficient translation invariance inability to cope with partial view and occlusion or significant performance degradation a the number of class is increased here we attempt to overcome these challenge using a model that combine sequential visual attention using fixation with sparse coding the model s biologically inspired filter are acquired using unsupervised learning applied to natural image patch using only a single feature type our approach achieves accuracy on caltech and on the flower dataset when trained on instance per class and it achieves accuracy on the ar face database with training instance per person the same feature and parameter are used across these datasets to illustrate it robust performance 
in this work we address boundary detection and boundary grouping we first pursue a learning based approach to boundary detection for this i we leverage appearance and context information by extracting descriptor around edgels and use them a feature for classification ii we use discriminative dimensionality reduction for efficiency and iii we use outlier resilient boosting to deal with noise in the training set we then introduce fractional linear programming to optimize a grouping criterion that is expressed a a cost ratio our contribution are systematically evaluated on the berkeley benchmark 
many successful model for scene or object recognition transform low level descriptor such a gabor filter response or sift descriptor into richer representation of intermediate complexity this process can often be broken down into two step a coding step which performs a pointwise transformation of the descriptor into a representation better adapted to the task and a pooling step which summarizes the coded feature over larger neighborhood several combination of coding and pooling scheme have been proposed in the literature the goal of this paper is threefold we seek to establish the relative importance of each step of mid level feature extraction through a comprehensive cross evaluation of several type of coding module hard and soft vector quantization sparse coding and pooling scheme by taking the average or the maximum which obtains state of the art performance or better on several recognition benchmark we show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding we provide theoretical and empirical insight into the remarkable performance of max pooling by teasing apart component shared by modern mid level feature extractor our approach aim to facilitate the design of better recognition architecture 
in this paper we present a novel framework to address the confounding effect of illumination variation in face recognition by augmenting the gallery set with realistically relit image we enhance recognition performance in a classifier independent way we describe a novel method for single image relighting morphable reflectance field morf which doe not require manual intervention and provides relighting superior to that of existing automatic method we test our framework through face recognition experiment using various state of the art classifier and popular benchmark datasets cmu pie multi pie and merl dome we demonstrate that our morf relighting and gallery augmentation framework achieves improvement in term of both rank recognition rate and roc curve we also compare our model with other automatic relighting method to confirm it advantage finally we show that the recognition rate achieved using our framework exceed those of state of the art recognizers on the aforementioned database 
although not commonly used correlation filter can track complex object through rotation occlusion and other distraction at over time the rate of current state of the art technique the oldest and simplest correlation filter use simple template and generally fail when applied to tracking more modern approach such a asef and umace perform better but their training need are poorly suited to tracking visual tracking requires robust filter to be trained from a single frame and dynamically adapted a the appearance of the target object change this paper present a new type of correlation filter a minimum output sum of squared error mosse filter which produce stable correlation filter when initialized using a single frame a tracker based upon mosse filter is robust to variation in lighting scale pose and nonrigid deformation while operating at frame per second occlusion is detected based upon the peak to sidelobe ratio which enables the tracker to pause and resume where it left off when the object reappears 
we present a framework that retains ambiguity in feature matching to increase the performance of d object recognition system whereas previous system removed ambiguous correspondence during matching we show that ambiguity should be resolved during hypothesis testing and not at the matching phase to preserve ambiguity during matching we vector quantize and match model feature in a hierarchical manner this matching technique allows our system to be more robust to the distribution of model descriptor in feature space we also show that we can address recognition under arbitrary viewpoint by using our framework to facilitate matching of additional feature extracted from affine transformed model image the evaluation of our algorithm in d object recognition is demonstrated on a difficult dataset of image 
in this paper we present a new method for bidirectional relighting for d aided d face recognition under large pose and illumination change during subject enrollment we build subject specific d annotated model by using the subject raw d data and d texture during authentication the probe d image are projected onto a normalized image space using the subject specific d model in the gallery then a bidirectional relighting algorithm and two similarity metric a view dependent complex wavelet structural similarity and a global similarity are employed to compare the gallery and probe we tested our algorithm on the uhdb and uhdb database that contain d data with probe image under large lighting and pose variation the experimental result show the robustness of our approach in recognizing face in difficult situation 
we present a novel approach to fully automated delineation of tree structure in noisy d image and d image stack unlike earlier method that rely mostly on local evidence our method build a set of candidate tree over many different subset of point likely to belong to the final one and then chooses the best one according to a global objective function since we are not systematically trying to span all node our algorithm is able to eliminate noise while retaining the right tree structure manually annotated dendrite micrographs and retinal scan are used to evaluate the performance of our method which is shown to be able to reject noise while retaining the tree structure 
we apply the concept of natural gradient to deformable registration the motivation stem from the lack of physical interpretation for gradient of image based difference measure the main idea is to endow the space of deformation with a distance metric which reflects the variation of the difference measure between two deformation this is in contrast to standard approach which assume the euclidean frame the modification of the distance metric is realized by treating the deformation a a riemannian manifold in our case the manifold is induced by the riemannian metric tensor based on the approximation of the fisher information matrix which take into account the information about the chosen difference measure and the input image thus the resulting natural gradient defined on this manifold inherently take into account this information the practical advantage of the proposed approach are the improvement of registration error and faster convergence for low gradient region the proposed scheme is applicable to arbitrary difference measure and can be readily integrated into standard variational deformable registration method with practically no computational overhead 
registration is a ubiquitous task for image analysis application generally the requirement of registration algorithm include fast computation and large capture range for these purpose registration in the fourier domain using normalized cross correlation is well suited and ha been extensively studied in the literature another common requirement is masking which is necessary for application where certain region of the image that would adversely affect the registration result should be ignored to address these requirement we have derived a mathematical model that describes an exact form for embedding the masking step fully into the fourier domain we also provide an extension of this masked registration approach from simple translation to also include rotation and scale we demonstrate the computational efficiency of our algorithm and validate it correctness on several synthetic image and real ultrasound image our framework enables fast global parameter free registration of image with masked region 
we introduce locally rigid motion a general framework for solving the m point n view structure from motion problem for unknown body deforming under orthography the key idea is to first solve many local point n view rigid problem independently providing a soup of specific plausibly rigid d triangle the main advantage here is that the extraction of d triangle requires only very weak assumption deformation can be locally approximated by near rigid motion of three point i e stretching not dominant and local motion involve some generic rotation in depth triangle from this soup are then grouped into body and their depth flip and instantaneous relative depth are determined result on several sequence both our own and from related work suggest these condition apply in diverse setting including very challenging one e g multiple deforming body our starting point is a novel linear solution to point structure from motion a problem for which no general algorithm currently exist 
noise confounds present serious complication to accurate data analysis in functional magnetic resonance imaging fmri simply relying on contextual image information often result in unsatisfactory segmentation of active brain region to remedy this we propose a novel group markov random field group mrf that extends the neighborhood system to other subject to incorporate group information in modeling each subject s brain activation our approach ha the distinct advantage of being able to regularize the state of both intraand inter subject neighbor without having to create a stringent one to one voxel correspondence a in standard fmri group analysis also our method can be efficiently implemented a a single mrf hence enabling activation map of a group of subject to be simultaneously and collaboratively segmented we validate on both synthetic and real fmri data and demonstrate superior performance over standard analysis technique 
the primary and novel contribution of this work is the conjecture that large collection of georeferenced photo collection can be used to derive map of what is where on the surface of the earth we investigate the application of what we term proximate sensing to the problem of land cover classification for a large geographic region we show that our approach is able to achieve almost classification accuracy in a binary land cover labelling problem using image from a photo sharing site in a completely automated fashion we also investigate how existing geographic knowledge can be used to provide labelled training data in a weakly supervised manner the effect of the photographer s intent when he or she capture the photograph and a method for filtering out non informative image 
in the field of neuroanatomy automatic segmentation of electron microscopy image is becoming one of the main limiting factor in getting new insight into the functional structure of the brain we propose a novel framework for the segmentation of thin elongated structure like membrane in a neuroanatomy setting the probability output of a random forest classifier is used in a regular cost function which enforces gap completion via perceptual grouping constraint the global solution is efficiently found by graph cut optimization we demonstrate substantial qualitative and quantitative improvement over state of the art segmentation on two considerably different stack of sstem image a well a in segmentation of street in satellite imagery we demonstrate that the superior performance of our method yield fully automatic d reconstruction of dendrite from sstem data 
we address the problem of image search on a very large scale where three constraint have to be considered jointly the accuracy of the search it efficiency and the memory usage of the representation we first propose a simple yet efficient way of aggregating local image descriptor into a vector of limited dimension which can be viewed a a simplification of the fisher kernel representation we then show how to jointly optimize the dimension reduction and the indexing algorithm so that it best preserve the quality of vector comparison the evaluation show that our approach significantly outperforms the state of the art the search accuracy is comparable to the bag of feature approach for an image representation that fit in byte searching a million image dataset take about m 
in this paper we propose and validate a pca based respiratory motion model for motion compensation during image guided cardiac intervention in a preparatory training phase a preoperative d segmentation of the coronary artery is automatically registered with a cardiac gated biplane cineangiogram and used to build a respiratory motion model this motion model is subsequently used a a prior within the intraoperative registration process for motion compensation to restrict the search space our hypothesis is that the use of this model constrained registration increase the robustness and registration accuracy especially for weak data constraint such a low signal to noise ratio the lack of contrast information or an intraoperative monoplane setting this allows for reducing radiation exposure without compromising on registration accuracy synthetic data a well a phantom and clinical datasets have been used to validate the model based registration in term of registration accuracy robustness and speed we were able to significantly accelerate the intraoperative registration with a d tre of le than mm for both monoplane image and intraprocedure setting with missing contrast information based on d guidewire tracking which make it feasible for motion correction in clinical procedure 
thousand of hour of video are recorded every second across the world due to the fact that searching for a particular event of interest within hour of video is time consuming most captured video are never examined and are only used in a post factum manner in this work we introduce activity specific video summary which provide an effective mean of browsing and indexing video based on a set of event of interest our method automatically generates a compact video representation of a long sequence which feature only activity of interest while preserving the general dynamic of the original video given a long input video sequence we compute optical flow and represent the corresponding vector field in the clifford fourier domain dynamic region within the flow field are identified within the phase spectrum volume of the flow field we then compute the likelihood that certain activity of relevance occur within the the video by correlating it with spatio temporal maximum average correlation height filter finally the input sequence is condensed via a temporal shift optimization resulting in a short video clip which simultaneously display multiple instance of each relevant activity 
many feature detection algorithm rely on the choice of scale in this paper we complement standard scale selection algorithm with spatial regularization to this end we formulate scale selection a a graph labeling problem and employ markov random field multi label optimization we focus on detecting the scale of vascular structure in medical image we compare the detected vessel scale using our method to those obtained using the selection approach of the well known vesselness filter frangi et al we propose and discus two different approach for evaluating the goodness of scale selection our result on image from the digital retinal image for vessel extraction drive database show an average reduction in these error measurement by more than 
active learning method aim to select the most informative unlabeled instance to label first and can help to focus image or video annotation on the example that will most improve a recognition system however most existing method only make myopic query for a single label at a time retraining at each iteration we consider the problem where at each iteration the active learner must select a set of example meeting a given budget of supervision where the budget is determined by the fund or time available to spend on annotation we formulate the budgeted selection task a a continuous optimization problem where we determine which subset of possible query should maximize the improvement to the classifier s objective without overspending the budget to ensure far sighted batch request we show how to incorporate the predicted change in the model that the candidate example will induce we demonstrate the proposed algorithm on three datasets for object recognition activity recognition and content based retrieval and we show it clear practical advantage over random myopic and batch selection baseline 
two challenge in computer vision are to accommodate noisy data and missing data many problem in computer vision such a segmentation filtering stereo reconstruction inpainting and optical flow seek solution that match the data while satisfying an additional regularization such a total variation or boundary length a regularization which ha received le attention is to minimize the curvature of the solution one reason why this regularization ha received le attention is due to the difficulty in finding an optimal solution to this image model since many existing method are complicated slow and or provide a suboptimal solution following the recent progress of schoenemann et al we provide a simple formulation of curvature regularization which admits a fast optimization which give globally optimal solution in practice we demonstrate the effectiveness of this method by applying this curvature regularization to image segmentation 
this paper present a novel method to increase the accuracy of linear fitting of implicit polynomial the proposed method is based on the l algorithm philosophy the novelty lie on the relaxation of the additional constraint already imposed by the l algorithm hence the accuracy of the final solution is increased due to the proper adjustment of the expected value in the aforementioned additional constraint although iterative the proposed approach solves the fitting problem within a linear framework which is independent of the threshold tuning experimental result both in d and d showing improvement in the accuracy of the fitting are presented comparison with both state of the art algorithm and a geometric based one non linear fitting which is used a a ground truth are provided 
this paper present region moment a class of appearance descriptor based on image moment applied to a pool of image feature a careful design of the moment and the image feature make the descriptor scale and rotation invariant and therefore suitable for vehicle detection from aerial video where target appear at different scale and orientation region moment are linearly related to the image feature thus comparing descriptor by computing costly geodesic distance and non linear classifier can be avoided because euclidean geometry and linear classifier are still effective the descriptor computation is made efficient by designing a fast procedure based on the integral representation an extensive comparison between region moment and the region covariance descriptor report theoretical qualitative and quantitative difference among them with a clear advantage of the region moment when used for detecting small image structure such a vehicle in aerial video the proposed descriptor hold the promise to become an effective building block in other application 
for object category recognition to scale beyond a small number of class it is important that algorithm be able to learn from a small amount of labeled data per additional class one shot recognition aim to apply the knowledge gained from a set of category with plentiful data to category for which only a single exemplar is available for each a with earlier effort motivated by transfer learning we seek an internal representation for the domain that generalizes across class however in contrast to existing work we formulate the problem in a fundamentally new manner by optimizing the internal representation for the one shot task using the notion of micro set a micro set is a sample of data that contains only a single instance of each category sampled from the pool of available data which serf a a mechanism to force the learned representation to explicitly address the variability and noise inherent in the one shot recognition task we optimize our learned domain feature so that they minimize an expected loss over micro set drawn from the training set and show that these feature generalize effectively to previously unseen category we detail a discriminative approach for optimizing one shot recognition using micro set and present experiment on the animal with attribute and caltech datasets that demonstrate the benefit of our formulation 
given a pair of image represented using bag of visual word and a label corresponding to whether the image are related must link constraint or unrelated cannot link constraint we address the problem of selecting a subset of visual word that are salient in explaining the relation between the image pair in particular a subset of feature is selected such that the distance computed using these feature satisfies the given pairwise constraint an efficient online feature selection algorithm is presented based on the dual gradient descent approach side information in the form of pair wise constraint is incorporated into the feature selection stage providing the user with flexibility to use an unsupervised or semi supervised algorithm at a later stage correlated subset of visual word usually resulting from hierarchical quantization process called group are exploited to select a significantly smaller vocabulary a group lasso regularizer is used to drive a many feature weight to zero a possible we evaluate the quality of the pruned vocabulary by clustering the data using the resulting feature subset experiment on pascal voc dataset using visual keywords resulted in around reduction in the number of keywords with little or no loss in performance 
dynamic programming dp ha been a useful tool for a variety of computer vision problem however it application is usually limited to problem with a one dimensional or low treewidth structure whereas most domain in vision are at least d in this paper we show how to apply dp for pixel labeling of d scene with simple tiered structure while there are many variation possible for the application we consider the following tiered structure is appropriate an image is first divided by horizontal curve into the top middle and bottom region and the middle region is further subdivided vertically into subregions under these constraint a globally optimal labeling can be found using an efficient dynamic programming algorithm we apply this algorithm to two very different task the first is the problem of geometric class labeling where the goal is to assign each pixel a label such a sky ground and surface above ground the second task involves incorporating simple shape prior for segmentation of an image into the foreground and background region 
this paper present a new approach to the problem of camera localization with non overlapping camera view particularly relevant for video surveillance system we show how to recast localization a quasi convex optimization under the l infinity norm thereby we add the problem of reconstructing camera center and d point for non overlapping camera with known internal parameter and known rotation to the class of known geometric problem solvable with second order cone programming the d point are never seen by more than one camera which make the localization problem ill posed therefore the proposed approach employ temporal consistency of the d point to supply the missing constraint our formulation allows a global optimal solution to be found with a clear physical meaning of the cost function being minimized 
recent advance in scene understanding and related task have highlighted the importance of using region to reason about high level scene structure typically the region are selected beforehand and then an energy function is defined over them this two step process suffers from the following deficiency i the region may not match the boundary of the scene entity thereby introducing error and ii a the region are obtained without any knowledge of the energy function they may not be suitable for the task at hand we address these problem by designing an efficient approach for obtaining the best set of region in term of the energy function itself each iteration of our algorithm selects region from a large dictionary by solving an accurate linear programming relaxation via dual decomposition the dictionary of region is constructed by merging and intersecting segment obtained from multiple bottom up over segmentation to demonstrate the usefulness of our algorithm we consider the task of scene segmentation and show significant improvement over state of the art method 
though it ha cost great research effort for decade object recognition is still a challenging problem traditional method based on machine learning or computer vision are still in the stage of tackling hundred of object category in recent year non parametric approach have demonstrated great success which understand the content of an image by propagating label of it similar image in a large scale dataset however due to the limited dataset size and imperfect image crawling strategy previous work can only address a biased small subset of image concept here we introduce the arista project which aim to build a practical image annotation engine targeting at popular concept in the real world in this project we are particularly interested in understanding how many image concept can be addressed by the data driven annotation approach coverage and how good the performance is precision this paper report the first stage of the work two billion web image were indexed and based on simple yet effective near duplicate detection the system is capable of automatically generating accurate tag for popular web image having near duplicate in the database we found that about web image have more than ten near duplicate and the number increase to for top image in search result further based on random sample in the latter case we observed the precision of at the point of the highest recall of on ground truth tag 
in this paper we propose a novel approach to the perceptual interpretation of building facade that combine shape grammar supervised classification and random walk procedural modeling is used to model the geometric and the photometric variation of building this is fused with visual classification technique randomized forest that provide a crude probabilistic interpretation of the observation space in order to measure the appropriateness of a procedural generation with respect to the image a random exploration of the grammar space is used to optimize the sequence of derivation rule towards a semantico geometric interpretation of the observation experiment conducted on complex architecture facade with ground truth validate the approach 
this paper address the problem of segmenting a combination of linear subspace and quadratic surface from sample data point corrupted by not necessarily small noise our main result show that this problem can be reduced to minimizing the rank of a matrix whose entry are affine in the optimization variable subject to a convex constraint imposing that these variable are the moment of an unknown probability distribution function with finite support exploiting the linear matrix inequality based characterization of the moment problem and appealing to well known convex relaxation of rank lead to an overall semi definite optimization problem we apply our method to problem such a simultaneous d motion segmentation and motion segmentation from two perspective view and illustrate that our formulation substantially reduces the noise sensitivity of existing approach 
in this paper we derive formal constraint relating terrain elevation and observed cast shadow we show how an optimisation framework can be used to refine surface estimate using shadowing constraint from one or more image the method is particularly applicable to the digital elevation model produced by the shuttle radar topography mission srtm which have an abundance of void in mountainous area where elevation data is missing cast shadow map are detected automatically from multi spectral satellite imagery using a simple heuristic which is reliable over varying type of surface cover we show that the combination of our shadow segmentation and terrain correction method can restore the structure of mountain ridge in interpolated srtm void using five satellite image decreasing the rms error by over 
we propose a novel scheme to recover depth map containing thin structure based on nonlocal mean filtering regularization the scheme imposes a distributed smoothness constraint by relying on the assumption that pixel with similar color are likely to belong to the same surface and therefore can be used jointly to obtain a robust estimate of their depth this scheme can be used to solve shape from x problem and we demonstrate it use in the case of depth from defocus we cast the problem in a variational framework and solve it by linearizing the corresponding euler lagrange equation the linearized system is then inverted by using efficient numerical method such a successive overrelaxations or more general method such a conjugate gradient when the system is not diagonally dominant one of the main benefit of this formulation is that it can handle the regularization of highly fragmented surface which require large neighborhood structure typically difficult to solve efficiently with graph based method we compare the performance of the proposed algorithm with method recently proposed in the literature that are analogous to neighborhood filter finally experimental result are shown on synthetic and real data 
this paper proposes an approach called object cut to tackle an important problem in computer vision d object reconstruction from single line drawing given a complex line drawing representing a solid object our algorithm find the place called cut to separate the line drawing into much simpler one the complex d object is obtained by first reconstructing the d object from these simpler line drawing and then combining them together several proposition and criterion are presented for cut finding a theorem is given to guarantee the existence and uniqueness of the separation of a line drawing along a cut our experiment show that the proposed approach can deal with more complex d object reconstruction than state of the art method 
this paper address the problem of recognizing free form d object in point cloud compared to traditional approach based on point descriptor which depend on local information around point we propose a novel method that creates a global model description based on oriented point pair feature and match that model locally using a fast voting scheme the global model description consists of all model point pair feature and represents a mapping from the point pair feature space to the model where similar feature on the model are grouped together such representation allows using much sparser object and scene point cloud resulting in very fast performance recognition is done locally using an efficient voting scheme on a reduced two dimensional search space we demonstrate the efficiency of our approach and show it high recognition performance in the case of noise clutter and partial occlusion compared to state of the art approach we achieve better recognition rate and demonstrate that with a slight or even no sacrifice of the recognition performance our method is much faster then the current state of the art approach 
we propose a semi supervised model which segment and annotates image using very few labeled image and a large unaligned text corpus to relate image region to text label given photo of a sport event all that is necessary to provide a pixel level labeling of object and background is a set of newspaper article about this sport and one to five labeled image our model is motivated by the observation that word in text corpus share certain context and feature similarity with visual object we describe image using visual word a new region based representation the proposed model is based on kernelized canonical correlation analysis which find a mapping between visual and textual word by projecting them into a latent meaning space kernel are derived from context and adjective feature inside the respective visual and textual domain we apply our method to a challenging dataset and rely on article of the new york time for textual feature our model outperforms the state of the art in annotation in segmentation it compare favorably with other method that use significantly more labeled training data 
we address the problem of object detection and segmentation using holistic property of object shape global shape representation are highly susceptible to clutter inevitably present in realistic image and can be robustly recognized only using a precise segmentation of the object to this end we propose a figure ground segmentation method for extraction of image region that resemble the global property of a model boundary structure and are perceptually salient our shape representation called the chordiogram is based on geometric relationship of object boundary edge while the perceptual saliency cue we use favor coherent region distinct from the background we formulate the segmentation problem a an integer quadratic program and use a semidefinite programming relaxation to solve it obtained solution provide the segmentation of an object a well a a detection score used for object recognition our single step approach improves over state of the art method on several object detection and segmentation benchmark 
in image categorization the goal is to decide if an image belongs to a certain category or not a binary classifier can be learned from manually labeled image while using more labeled example improves performance obtaining the image label is a time consuming process we are interested in how other source of information can aid the learning process given a fixed amount of labeled image in particular we consider a scenario where keywords are associated with the training image e g a found on photo sharing website the goal is to learn a classifier for image alone but we will use the keywords associated with labeled and unlabeled image to improve the classifier using semi supervised learning we first learn a strong multiple kernel learning mkl classifier using both the image content and keywords and use it to score unlabeled image we then learn classifier on visual feature only either support vector machine svm or least square regression lsr from the mkl output value on both the labeled and unlabeled image in our experiment on class from the pascal voc set and from the mir flickr set we demonstrate the benefit of our semi supervised approach over only using the labeled image we also present result for a scenario where we do not use any manual labeling but directly learn classifier from the image tag the semi supervised approach also improves classification accuracy in this case 
the camera in video conference system is typically positioned above or below the screen causing the gaze of the user to appear misplaced we propose an effective solution to this problem that is based on replacing the eye of the user this replacement when done accurately is enough to achieve a natural looking video at an initialization stage the user is asked to look straight at the camera we store these frame then track the eye accurately in the video sequence and replace the eye taking care of illumination and ghosting artifact we have tested the system on a large number of video demonstrating the effectiveness of the proposed solution 
while the problem of tracking d human motion ha been widely studied most approach have assumed that the person is isolated and not interacting with the environment environmental constraint however can greatly constrain and simplify the tracking problem the most studied constraint involve gravity and contact with the ground plane we go further to consider interaction with object in the environment in many case tracking rigid environmental object is simpler than tracking high dimensional human motion when a human is in contact with object in the world their pose constrain the pose of body essentially removing degree of freedom thus what would appear to be a harder problem combining object and human tracking is actually simpler we use a standard formulation of the body tracking problem but add an explicit model of contact with object we find that constraint from the world make it possible to track complex articulated human motion in d from a monocular camera 
we propose a method of gait silhouette transformation from one speed to another to cope with walking speed change in gait identification when a person change his her walking speed dynamic feature e g stride and joint angle are changed while static feature e g thigh and shin length are unchanged based on the fact firstly static and dynamic feature are separated from gait silhouette by fitting a human model secondly a factorization based speed transformation model for the dynamic feature is created using a training set for multiple person on multiple speed this model can transform the dynamic feature from a reference speed to another arbitrary speed finally silhouette are restored by combining the unchanged static feature and the transformed dynamic feature evaluation by gait identification using silhouette based frequency domain feature show the effectiveness of the proposed method 
flow doppler imaging ha become an integral part of an echocardiographic exam automated interpretation of flow doppler imaging ha so far been restricted to obtaining hemodynamic information from velocity time profile depicted in these image in this paper we exploit the shape pattern in doppler image to infer the similarity in valvular disease label for purpose of automated clinical decision support specifically we model the similarity in appearance of doppler image from the same disease class a a constrained non rigid translation transform of the velocity envelope embedded in these image the shape similarity between two doppler image is then judged by recovering the alignment transform using a variant of dynamic shape warping result of similarity retrieval of doppler image for cardiac decision support on a large database of image are presented 
in this work we present an approach to fuse video with orientation data obtained from extended inertial sensor to improve and stabilize full body human motion capture even though video data is a strong cue for motion analysis tracking artifact occur frequently due to ambiguity in the image rapid motion occlusion or noise a a complementary data source inertial sensor allow for drift free estimation of limb orientation even under fast motion however accurate position information cannot be obtained in continuous operation therefore we propose a hybrid tracker that combine video with a small number of inertial unit to compensate for the drawback of each sensor type on the one hand we obtain drift free and accurate position information from video data and on the other hand we obtain accurate limb orientation and good performance under fast motion from inertial sensor in several experiment we demonstrate the increased performance and stability of our human motion tracker 
tracking by detection is increasingly popular in order to tackle the visual tracking problem existing adaptive method suffer from the drifting problem since they rely on self update of an on line learning method in contrast to previous work that tackled this problem by employing semi supervised or multiple instance learning we show that augmenting an on line learning method with complementary tracking approach can lead to more stable result in particular we use a simple template model a a non adaptive and thus stable component a novel optical flow based mean shift tracker a highly adaptive element and an on line random forest a moderately adaptive appearance based learner we combine these three tracker in a cascade all of our component run on gpus or similar multi core system which allows for real time performance we show the superiority of our system over current state of the art tracking method in several experiment on publicly available data 
we present a new image morphing approach in which the output sequence is regenerated from small piece of the two source input image the approach doe not require manual correspondence and generates compelling result even when the image are of very different object e g a cloud and a face we pose the morphing task a an optimization with the objective of achieving bidirectional similarity of each frame to it neighbor and also to the source image the advantage of this approach are it can operate fully automatically producing effective result for many sequence but also support manual correspondence when available ghosting artifact are minimized and different part of the scene move at different rate yielding more interesting and le robotic transition 
taking multiple exposure is a well established approach both for capturing high dynamic range hdr scene and for noise reduction but what is the optimal set of photo to capture the typical approach to hdr capture us a set of photo with geometrically spaced exposure time at a fixed iso setting typically iso or by contrast we show that the capture sequence with optimal worst case performance in general us much higher and variable iso setting and spends longer capturing the dark part of the scene based on a detailed model of noise we show that optimal capture can be formulated a a mixed integer programming problem compared to typical hdr capture our method let u achieve higher worst case snr in the same capture time for some camera up to db improvement in the darkest region or much faster capture for the same minimum acceptable level of snr our experiment demonstrate this advantage for both real and synthetic scene 
we introduce a new algorithm for video retargeting that us discontinuous seam carving in both space and time for resizing video our algorithm relies on a novel appearance based temporal coherence formulation that allows for frame by frame processing and result in temporally discontinuous seam a opposed to geometrically smooth and continuous seam this formulation optimizes the difference in appearance of the resultant retargeted frame to the optimal temporally coherent one and allows for carving around fast moving salient region additionally we generalize the idea of appearance based coherence to the spatial domain by introducing piece wise spatial seam our spatial coherence measure minimizes the change in gradient during retargeting which preserve spatial detail better than minimization of color difference alone we also show that per frame saliency gradient based or feature based doe not always produce desirable retargeting result and propose a novel automatically computed measure of spatio temporal saliency a needed a user may also augment the saliency by interactive region brushing our retargeting algorithm process the video sequentially making it conducive for streaming application 
though modern visual simultaneous localisation and mapping vslam system are capable of localising robustly and efficiently even in the case of a monocular camera the map produced are typically sparse point cloud that are difficult to interpret and of little use for higher level reasoning task such a scene understanding or humanmachine interaction in this paper we begin to address this deficiency presenting progress on expanding the competency of visual slam system to build richer map specifically we concentrate on modelling indoor scene using semantically meaningful surface and accompanying label such a floor wall and ceiling an important step towards a representation that can support higher level reasoning and planning we leverage the manhattan world assumption and show how to extract vanishing direction jointly across a video stream we then propose a guided line detector that utilises known vanishing point to extract extremely subtle axisaligned edge we utilise recent advance in single view structure recovery to building geometric scene model and demonstrate our system operating on line 
mirror have been used to enable wide field of view fov catadioptric imaging the mapping between the incoming and reflected light ray depends non linearly on the mirror shape and ha been well studied using caustic we analyze this mapping using two plane light field parameterization which provides valuable insight into the geometric structure of reflected ray using this analysis we study the problem of generating a single viewpoint virtual perspective image for catadioptric system which is unachievable for several common configuration instead of minimizing distortion appearing in a single image we propose to capture all the ray required to generate a virtual perspective by capturing a light field we consider rotationally symmetric mirror and show that a traditional planar light field result in significant aliasing artifact we propose axial light field captured by moving the camera along the mirror rotation axis for efficient sampling and to remove aliasing artifact this allows u to computationally generate wide fov virtual perspective using a wider class of mirror than before without using scene prior or depth estimation we analyze the relationship between the axial light field parameter and the fov resolution of the resulting virtual perspective real result using a spherical mirror demonstrate generating fov virtual perspective using multiple fov image 
the calculation of a low rank approximation of a matrix is a fundamental operation in many computer vision application the workhorse of this class of problem ha long been the singular value decomposition however in the presence of missing data and outlier this method is not applicable and unfortunately this is often the case in practice in this paper we present a method for calculating the low rank factorization of a matrix which minimizes the l norm in the presence of missing data our approach represents a generalization the wiberg algorithm of one of the more convincing method for factorization under the l norm by utilizing the differentiability of linear program we can extend the underlying idea behind this approach to include this class of l problem a well we show that the proposed algorithm can be efficiently implemented using existing optimization software we also provide preliminary experiment on synthetic a well a real world data with very convincing result 
we present an automatic method that establishes d correspondence between isometric shape our goal is to find an optimal correspondence between two given nearly isometric shape that minimizes the amount of deviation from isometry we cast the problem a a complete surface correspondence problem our method first divide the given shape to be matched into surface patch of equal area and then seek for a mapping between the patch center which we refer to a base vertex hence the correspondence is established in a fast and robust manner at a relatively coarse level a imposed by the patch radius we optimize the isometry cost in two step in the first step the base vertex are transformed into spectral domain based on geodesic affinity where the isometry error are minimized in polynomial time by complete bipartite graph matching the resulting correspondence serf a a good initialization for the second step of optimization in which we explicitly minimize the isometry cost via an iterative greedy algorithm in the original d euclidean space we demonstrate the performance of our method on various isometric or nearly isometric pair of shape for some of which the ground truth correspondence is available 
blur from camera shake is mostly due to the d rotation of the camera resulting in a blur kernel that can be significantly non uniform across the image however most current deblurring method model the observed image a a convolution of a sharp image with a uniform blur kernel we propose a new parametrized geometric model of the blurring process in term of the rotational velocity of the camera during exposure we apply this model to two different algorithm for camera shake removal the first one us a single blurry image blind deblurring while the second one us both a blurry image and a sharp but noisy image of the same scene we show that our approach make it possible to model and remove a wider class of blur than previous approach including uniform blur a a special case and demonstrate it effectiveness with experiment on real image 
this paper present a sparse representation of d planar shape through the composition of warping function termed formlets localized in scale and space each formlet subject the d space in which the shape is embedded to a localized isotropic radial deformation by constraining these localized warping transformation to be diffeomorphisms the topology of shape is preserved and the set of simple closed curve is closed under any sequence of these warping a generative model based on a composition of formlets applied to an embryonic shape e g an ellipse ha the advantage of synthesizing only those shape that could correspond to the boundary of physical object to compute the set of formlets that represent a given boundary we demonstrate a greedy coarse to fine formlet pursuit algorithm that serf a a non commutative generalization of matching pursuit for sparse approximation we evaluate our method by pursuing partially occluded shape comparing performance against a contour based sparse shape coding framework 
we present an activity recognition feature inspired by human psychophysical performance this feature is based on the velocity history of tracked keypoints we present a generative mixture model for video sequence using this feature and show that it performs comparably to local spatio temporal feature on the kth activity recognition dataset in addition we contribute a new activity recognition dataset focusing on activity of daily living with high resolution video sequence of complex action we demonstrate the superiority of our velocity history feature on high resolution video sequence of complicated activity further we show how the velocity history feature can be extended both with a more sophisticated latent velocity model and by combining the velocity history feature with other useful information like appearance position and high level semantic information our approach performs comparably to established and state of the art method on the kth dataset and significantly outperforms all other method on our challenging new dataset 
in this paper we describe a method to learn parameter which govern pedestrian motion by observing video data our learning framework is based on variational mode learning and allows u to efficiently optimize a continuous pedestrian cost model we show that this model can be trained on automatic tracking result and provides realistic and accurate pedestrian motion 
we propose a posture invariant surface descriptor for triangular mesh using intrinsic geometry the surface is first transformed into a representation that is independent of the posture spin image is then adapted to derive a descriptor for the representation the descriptor is used for extracting surface feature automatically it is invariant with respect to rigid and isometric deformation and robust to noise and change in resolution the result is demonstrated by using the automatically extracted feature to find correspondence between articulated mesh 
we present an interactive approach for segmenting thin volumetric structure the proposed segmentation model is based on an anisotropic weighted total variation energy with a global volumetric constraint and is minimized using an efficient numerical approach and a convex relaxation the algorithm is globally optimal w r t the relaxed problem for any volumetric constraint the binary solution of the relaxed problem equal the globally optimal solution of the original problem implemented on today s user programmable graphic card it allows real time user interaction the method is applied to and evaluated on the task of articular cartilage segmentation of human knee joint and segmentation of tubular structure like liver vessel and airway tree 
we propose a multi view stereo reconstruction algorithm which recovers urban scene a a combination of mesh and geometric primitive it provides a compact model while preserving detail irregular element such a statue and ornament are described by mesh whereas regular structure such a column and wall are described by primitive plane sphere cylinder cone and torus a jump diffusion process is designed to sample these two type of element simultaneously the quality of a reconstruction is measured by a multi object energy model which take into account both photo consistency and semantic consideration i e geometry and shape layout the sampler is embedded into an iterative refinement procedure which provides an increasingly accurate hybrid representation experimental result on complex urban structure and large scene are presented and compared to multi view based meshing algorithm 
we present a completely automated structure and motion pipeline capable of working with uncalibrated image with varying internal parameter and no ancillary information the system is based on a novel hierarchical scheme which reduces the total complexity by one order of magnitude we ass the quality of our approach analytically by comparing the recovered point cloud with laser scan which serf a ground truth data 
many object surface are composed of layer of different physical substance known a layered surface these surface such a patina water color and wall painting have more complex optical property than diffuse surface although the characteristic of layered surface like layer opacity mixture of color and color gradation are significant they are usually ignored in the analysis of many method in computer vision causing inaccurate or even erroneous result therefore the main goal of this paper are twofold to solve problem of layered surface by focusing mainly on surface with two layer i e top and bottom layer and to introduce a decomposition method based on a novel representation of a nonlinear correlation in the color space that we call the spider model when we plot a mixture of color of one bottom layer and n different top layer into the rgb color space then we will have n different curve intersecting at one point resembling the shape of a spider hence given a single input image containing one bottom layer and at least one top layer we can fit their color distribution by using the spider model and then decompose those layered surface the last step is equivalent to extracting the approximated optical property of the two layer the top layer s opacity and the top and bottom layer reflection experiment with real image which include the photograph of ancient wall painting show the effectiveness of our method 
we describe a simple and efficient algorithm for two view triangulation of d point from approximate d match based on minimizing the l reprojection error our iterative algorithm improves on the one by kanatani et al by ensuring that in each iteration the epipolar constraint is satisfied in the case where the two camera are pointed in the same direction the method provably converges to an optimal solution in exactly two iteration for more general camera pose two iteration are sufficient to achieve convergence to machine precision which we exploit to devise a fast non iterative method the resulting algorithm amount to little more than solving a quadratic equation and involves a fixed small number of simple matrix vector operation and no conditional branch we demonstrate that the method computes solution that agree to very high precision with those of hartley and sturm s original polynomial method though achieves higher numerical stability and order of magnitude greater speed 
we examine the shape from shading problem without boundary condition a a polynomial system this view allows in generic case a complete solution for ideal polyhedral object for the general case we propose a semidefinite programming relaxation procedure and an exact line search iterative procedure with a new smoothness term that favor fold at edge we use this numerical technique to inspect shading ambiguity 
modern structure from motion technique are capable of building city scale d reconstruction from large image collection but have mostly ignored the problem of large scale structural change over time we present a general framework for estimating temporal variable in structure from motion problem including an unknown date for each camera and an unknown time interval for each structural element given a collection of image with mostly unknown or uncertain date we use this framework to automatically recover the date of all image by reasoning probabilistically about the visibility and existence of object in the scene we present result on a collection of over historical image of a city taken over decade of time 
recent work in object localization ha shown that the use of contextual cue can greatly improve accuracy over model that use appearance feature alone although many of these model have successfully explored different type of contextual source they only consider one type of contextual interaction e g pixel region or object level interaction leaving open question about the true potential contribution of context furthermore contribution across object class and over appearance feature still remain unknown in this work we introduce a novel model for multi class object localization that incorporates different level of contextual interaction we study contextual interaction at pixel region and object level by using three different source of context semantic boundary support and contextual neighborhood our framework learns a single similarity metric from multiple kernel combining pixel and region interaction with appearance feature and then us a conditional random field to incorporate object level interaction we perform experiment on two challenging image database msrc and pascal voc experimental result show that our model outperforms current state of the art contextual framework and reveals individual contribution for each contextual interaction level a well a the importance of each type of feature in object localization 
in this paper we introduce a novel riemannian framework for shape analysis of parameterized surface we derive a distance function between any two surface that is invariant to rigid motion global scaling and re parametrization it is the last part that present the main difficulty our solution to this problem is twofold we define a special representation called a q map to represent each surface and we develop a gradient based algorithm to optimize over different re parameterizations of a surface the second step is akin to deforming the mesh on a fixed surface to optimize it placement this is different from the current method that treat the given mesh a fixed under the chosen representation with the l metric the action of the re parametrization group is by isometry this result in to our knowledge the first riemannian distance between parameterized surface to have all the desired invariance we demonstrate this framework with several example using some toy shape and real data with anatomical structure and cropped facial surface we also successfully demonstrate clustering and classification of these object under the proposed metric 
we present a practical approach for surface reconstruction of smooth mirror like object using sparse reflection correspondence rcs assuming finite object motion with a fixed camera and un calibrated environment we derive the relationship between rc and the surface shape we show that by locally modeling the surface a a quadric the relationship between the rcs and unknown surface parameter becomes linear we develop a simple surface reconstruction algorithm that amount to solving either an eigenvalue problem or a second order cone program socp ours is the first method that allows for reconstruction of mirror surface from sparse rcs obtained from standard algorithm such a sift our approach overcomes the practical issue in shape from specular flow sfsf such a the requirement of dense optical flow and undefined infinite flow at parabolic point we also show how to incorporate auxiliary information such a sparse surface normal into our framework experiment both real and synthetic are shown that validate the theory presented 
we present an object recognition system that locates an object identifies it part and segment out it contour a key distinction of our approach is that we use long salient bottom up image contour to learn object shape and to achieve object detection with the learned shape most learning method rely on one to one matching of contour to a model however bottom up image contour often fragment unpredictably we resolve this difficulty by using many to one matching of image contour to a model to learn a descriptive object shape model we combine bottom up contour from a few representative image the goal is to allow most of the contour in the training image to be many to one matched to the model for detection our challenge are inferring the object contour and part location in addition to object location because the location of object part and match of contour are not annotated they appear a latent variable during training we use the latent svm learning formulation to discriminatively tune the many to one matching score using the max margin criterion we evaluate on the challenging ethz shape category dataset and outperform all existing method 
recent work have shown that d shape of non rigid surface can be accurately retrieved from a single image given a set of d to d correspondence between that image and another one for which the shape is known however existing approach assume that such correspondence can be readily established which is not necessarily true when large deformation produce significant appearance change between the input and the reference image furthermore it is either assumed that the pose of the camera is known or the estimated solution is pose ambiguous in this paper we relax all these assumption and given a set of d and d unmatched point we present an approach to simultaneously solve their correspondence compute the camera pose and retrieve the shape of the surface in the input image this is achieved by introducing weak prior on the pose and shape that we model a gaussian mixture by combining them into a kalman filter we can progressively reduce the number of d candidate that can be potentially matched to each d point while pose and shape are refined this let u to perform a complete and efficient exploration of the solution space and retain the best solution 
in this paper we propose a novel framework for detecting multiple object in d and d image since a joint multi object model is difficult to obtain in most practical situation we focus here on detecting the object sequentially one by one the interdependence of object pose and strong prior information embedded in our domain of medical image result in better performance than detecting the object individually our approach is based on sequential estimation technique frequently applied to visual tracking unlike in tracking where the sequential order is naturally determined by the time sequence the order of detection of multiple object must be selected leading to a hierarchical detection network hdn we present an algorithm that optimally selects the order based on probability of state object pose within the ground truth region the posterior distribution of the object pose is approximated at each step by sequential monte carlo the sample are propagated within the sequence across multiple object and hierarchical level we show on d ultrasound image of left atrium that the automatically selected sequential order yield low mean detection error we also quantitatively evaluate the hierarchical detection of fetal face and three fetal brain structure in d ultrasound image 
optical character recognition ocr remains a difficult problem for noisy document or document not scanned at high resolution many current approach rely on stored font model that are vulnerable to case in which the document is noisy or is written in a font dissimilar to the stored font we address these problem by learning character model directly from the document itself rather than using pre stored font model this method ha had some success in the past but we are able to achieve substantial improvement in error reduction through a novel method for creating nearly error free document specific training data and building character appearance model from this data in particular we first use the state of the art ocr system tesseract to produce an initial translation then our method identifies a subset of word that we have high confidence have been recognized correctly and us this subset to bootstrap document specific character model we present theoretical justification that a word in the selected subset is very unlikely to be incorrectly recognized and empirical result on a data set of difficult historical newspaper scan demonstrating that we make only two error in document we then relax the theoretical constraint in order to create a larger training set and using document specific character model generated from this data we are able to reduce the error over properly segmented character by overall from the initial tesseract translation 
an image search for clownfish yield many photo of clownfish each of a different individual of a different d shape in a different pose yet to the human observer this set of image contains enough information to infer the underlying d deformable object class our goal is to recover such a deformable object class model directly from unordered image for class where feature point correspondence can be found this is a straightforward extension of non rigid factorization yielding a set of d basis shape to explain the d data however when each image is of a different object instance surface texture is generally unique to each individual and doe not give rise to usable image point correspondence we overcome this sparsity using curve correspondence crease edge silhouette or class specific internal texture edge even rigid contour reconstruction is difficult due to the lack of reliable correspondence we incorporate correspondence variation into the optimization thereby extending contour based reconstruction technique to deformable object modelling the notion of correspondence is extended to include mapping between d image curve and corresponding part of the desired d object surface combined with class specific prior our method enables effective de formable class reconstruction from unordered image despite significant occlusion and the scarcity of shared d image feature 
many computer vision and pattern recognition problem may be posed by defining a way of measuring dissimilarity between pattern for many type of data these dissimilarity are not euclidean and may not be metric in this paper we provide a mean of embedding such data we aim to embed the data on a hypersphere whose radius of curvature is determined by the dissimilarity data the hypersphere can be either of positive curvature elliptic or of negative curvature hyperbolic we give an efficient method for solving the elliptic and hyperbolic embedding problem on symmetric dissimilarity data this method give the radius of curvature and a method for approximating the object a point on a hyperspherical manifold we apply our method to a variety of data including shape similarity graph similarity and gesture similarity data in each case the embedding maintains the local structure of the data while placing the point in a metric space 
recent work show how to use local spatio temporal feature to learn model of realistic human action from video however existing method typically rely on a predefined spatial binning of the local descriptor to impose spatial information beyond a pure bag of word model and thus may fail to capture the most informative space time relationship we propose to learn the shape of space time feature neighborhood that are most discriminative for a given action category given a set of training video our method first extract local motion and appearance feature quantizes them to a visual vocabulary and then form candidate neighborhood consisting of the word associated with nearby point and their orientation with respect to the central interest point rather than dictate a particular scaling of the spatial and temporal dimension to determine which point are near we show how to learn the class specific distance function that form the most informative configuration descriptor for these variable sized neighborhood are then recursively mapped to higher level vocabulary producing a hierarchy of space time configuration at successively broader scale our approach yield state of the art performance on the ucf sport and kth datasets 
in this paper we propose two new perceptually motivated strategy to better measure the similarity of d shape instance that are in the form of closed contour the first strategy handle shape that can be decomposed into a base structure and a set of inward or outward pointing strand structure where a strand structure represents a very thin elongated shape part attached to the base structure the similarity of two such shape contour can be better described by measuring the similarity of their base structure and strand structure in different way the second strategy handle shape that exhibit good bilateral symmetry in many case such shape are invariant to a certain level of scaling transformation along their symmetry axis in our experiment we show that these two strategy can be integrated into available shape matching method to improve the performance of shape classification on several widely used shape data set 
we propose a new type of saliency context aware saliency which aim at detecting the image region that represent the scene this definition differs from previous definition whose goal is to either identify fixation point or detect the dominant object in accordance with our saliency definition we present a detection algorithm which is based on four principle observed in the psychological literature the benefit of the proposed approach are evaluated in two application where the context of the dominant object is just a essential a the object themselves in image retargeting we demonstrate that using our saliency prevents distortion in the important region in summarization we show that our saliency help to produce compact appealing and informative summary 
online boosting is one of the most successful online learning algorithm in computer vision while many challenging online learning problem are inherently multi class online boosting and it variant are only able to solve binary task in this paper we present online multi class lpboost omclp which is directly applicable to multi class problem from a theoretical point of view our algorithm try to maximize the multi class soft margin of the sample in order to solve the lp problem in online setting we perform an efficient variant of online convex programming which is based on primal dual gradient descent ascent update strategy we conduct an extensive set of experiment over machine learning benchmark datasets a well a on caltech category recognition dataset we show that our method is able to outperform other online multi class method we also apply our method to tracking where we present an intuitive way to convert the binary tracking by detection problem to a multi class problem where background pattern which are similar to the target class become virtual class applying our novel model we outperform or achieve the state of the art result on benchmark tracking video 
maximum a posteriori map inference in markov random field mrfs is an np hard problem and thus research ha focussed on either finding efficiently solvable subclass e g tree or approximate algorithm e g loopy belief propagation bp and tree reweighted trw method this paper present a unifying perspective of these approximate technique called decomposition method these are method that decompose the given problem over a graph into tractable subproblems over subgraphs and then employ message passing over these subgraphs to merge the solution of the subproblems into a global solution this provides a new way of thinking about bp and trw a successive step in a hierarchy of decomposition method using this framework we take a principled first step towards extending this hierarchy beyond tree we leverage a new class of graph amenable to exact inference called outer planar graph and propose an approximate inference algorithm called outer planar decomposition opd opd is a strict generalization of bp and trw and contains both of them a special case our experiment show that this extension beyond tree is indeed very powerful opd outperforms current state of art inference method on hard non submodular synthetic problem and is competitive on real computer vision application 
building robust low and mid level image representation beyond edge primitive is a long standing goal in vision many existing feature detector spatially pool edge information which destroys cue such a edge intersection parallelism and symmetry we present a learning framework where feature that capture these mid level cue spontaneously emerge from image data our approach is based on the convolutional decomposition of image under a spar sity constraint and is totally unsupervised by building a hierarchy of such decomposition we can learn rich feature set that are a robust image representation for both the analysis and synthesis of image 
learning a generative model of natural image is a useful way of extracting feature that capture interesting regularity previous work on learning such model ha focused on method in which the latent feature are used to determine the mean and variance of each pixel independently or on method in which the hidden unit determine the covariance matrix of a zero mean gaussian distribution in this work we propose a probabilistic model that combine these two approach into a single framework we represent each image using one set of binary latent feature that model the image specific covariance and a separate set that model the mean we show that this approach provides a probabilistic framework for the widely used simple cell complex cell architecture it produce very realistic sample of natural image and it extract feature that yield state of the art recognition accuracy on the challenging cifar dataset 
we present a system that automatically recommends tag for youtube video solely based on their audiovisual content we also propose a novel framework for unsupervised discovery of video category that exploit knowledge mined from the world wide web text document search first video content to tag association is learned by training classifier that map audiovisual content based feature from million of video on youtube com to existing uploader supplied tag for these video when a new video is uploaded the label provided by these classifier are used to automatically suggest tag deemed relevant to the video our system ha learned a vocabulary of over tag secondly we mined large volume of web page and search query to discover a set of possible text entity category and a set of associated is a relationship that map individual text entity to category finally we apply these is a relationship mined from web text on the tag learned from audiovisual content of video to automatically synthesize a reliable set of category most relevant to video along with a mechanism to predict these category for new uploads we then present rigorous rating study that establish that a the average relevance of tag automatically recommended by our system match the average relevance of the uploader supplied tag at the same or better coverage and b the average precision k of video category discovered by our system is with k 
the widespread availability of digital camera and ubiquitous internet access have facilitated the creation of massive image collection these collection can be highly interconnected through implicit link between image pair viewing the same or similar object we propose building graph called image web to represent such connection while earlier effort studied local neighborhood of such graph we are interested in understanding global structure and exploiting connectivity at larger scale we show how to efficiently construct image web that capture the connectivity in an image collection using spectral graph theory our technique can link together ten of thousand of image in a few minute using a computer cluster we also demonstrate application for exploring collection based on global topological analysis 
we present topic regression multi modal latent dirich let allocation tr mmlda a novel statistical topic model for the task of image and video annotation at the heart of our new annotation model lie a novel latent variable regression approach to capture correlation between image or video feature and annotation text instead of sharing a set of latent topic between the data modality a in the formulation of correspondence lda in our approach introduces a regression module to correlate the set of topic which capture more general form of association and allows the number of topic in the data modality to be different we demonstrate the power of tr mmlda on standard annotation datasets a image subset of corel and a image labelme dataset the proposed association model show improved performance over correspondence lda a measured by caption perplexity 
we propose a calibration free gaze sensing method using visual saliency map our goal is to construct a gaze estimator only using eye image captured from a person watching a video clip the key is treating saliency map of the video frame a probability distribution of gaze point to efficiently identify gaze point from saliency map we aggregate saliency map based on the similarity of eye appearance we establish mapping between eye image to gaze point by gaussian process regression the experimental result show that the proposed method work well with different people and video clip and achieves degree of accuracy which is useful for estimating a person s attention on monitor 
finding fiducial facial point in any frame of a video showing rich naturalistic facial behaviour is an unsolved problem yet this is a crucial step for geometric feature based facial expression analysis and method that use appearance based feature extracted at fiducial facial point location in this paper we present a method based on a combination of support vector regression and markov random field to drastically reduce the time needed to search for a point s location and increase the accuracy and robustness of the algorithm using markov random field allows u to constrain the search space by exploiting the constellation that facial point can form the regressors on the other hand learn a mapping between the appearance of the area surrounding a point and the position of these point which make detection of the point very fast and can make the algorithm robust to variation of appearance due to facial expression and moderate change in head pose the proposed point detection algorithm wa tested on image the result of which showed we outperform current state of the art point detector 
this paper overview a new gesture recognition framework based on learning local motion signature lm introduced by after the generation of these lm computed on one individual by tracking histogram of oriented gradient hog descriptor we learn a codebook of video word i e cluster of lm using k mean algorithm on a learning gesture video database then the video word are compacted to a codebook of code word by the maximization of mutual information mmi algorithm at the final step we compare the lm generated for a new gesture w r t the learned codebook via the k nearest neighbor k nn algorithm and a novel voting strategy our main contribution is the handling of the n to n mapping between code word and gesture label with the proposed voting strategy experiment have been carried out on two public gesture database kth and ixmas result show that the proposed method outperforms recent state of the art method 
we present a novel image operator that seek to find the value of stroke width for each image pixel and demonstrate it use on the task of text detection in natural image the suggested operator is local and data dependent which make it fast and robust enough to eliminate the need for multi scale computation or scanning window extensive testing show that the suggested scheme outperforms the latest published algorithm it simplicity allows the algorithm to detect text in many font and language 
we present an active learning framework to simultaneously learn appearance and contextual model for scene understanding task multi class classification existing multi class active learning approach have focused on utilizing classification uncertainty of region to select the most ambiguous region for labeling these approach however ignore the contextual interaction between different region of the image and the fact that knowing the label for one region provides information about the label of other region for example the knowledge of a region being sea is informative about region satisfying the on relationship with respect to it since they are highly likely to be boat we explicitly model the contextual interaction between region and select the question which lead to the maximum reduction in the combined entropy of all the region in the image image entropy we also introduce a new methodology of posing labeling question mimicking the way human actively learn about their environment in these question we utilize the region linked to a concept with high confidence a anchor to pose question about the uncertain region for example if we can recognize water in an image then we can use the region associated with water a an anchor to pose question such a what is above water our active learning framework also introduces question which help in actively learning contextual concept for example our approach asks the annotator what is the relationship between boat and water and utilizes the answer to reduce the image entropy throughout the training dataset and obtain more relevant training example for appearance model 
this paper describes a photometric stereo method that work with a wide range of surface reflectance unlike previous approach that assume simple parametric model such a lambertian reflectance the only assumption that we make is that the reflectance ha three property monotonicity visibility and isotropy with respect to the cosine of light direction and surface orientation in fact these property are observed in many non lambertian diffuse reflectance we also show that the monotonicity and isotropy property hold specular lobe with respect to the cosine of the surface orientation and the bisector between the light direction and view direction each of these three property independently give a possible solution space of the surface orientation by taking the intersection of the solution space our method determines the surface orientation in a consensus manner our method naturally avoids the need for radiometrically calibrating camera because the radiometric response function preserve these three property the effectiveness of the proposed method is demonstrated using various simulated and real world scene that contain a variety of diffuse and specular surface 
we present a new approach for building an efficient and robust classifier for the two class problem that localizes object that may appear in the image under different orientation in contrast to other work that address this problem using multiple classifier each one specialized for a specific orientation we propose a simple two step approach with an estimation stage and a classification stage the estimator yield an initial set of potential object pose that are then validated by the classifier this methodology allows reducing the time complexity of the algorithm while classification result remain high the classifier we use in both stage is based on a boosted combination of random fern over local histogram of oriented gradient hog which we compute during a preprocessing step both the use of supervised learning and working on the gradient space make our approach robust while being efficient at run time we show these property by thorough testing on standard database and on a new database made of motorbike under planar rotation and with challenging condition such a cluttered background changing illumination condition and partial occlusion 
in this paper we introduce a new shape constraint for interactive image segmentation it is an extension of veksler s star convexity prior in two way from a single star to multiple star and from euclidean ray to geodesic path global minimum of the energy function are obtained subject to these new constraint we also introduce geodesic forest which exploit the structure of shortest path in implementing the extended constraint the star convexity prior is used here in an interactive setting and this is demonstrated in a practical system the system is evaluated by mean of a robot user to measure the amount of interaction required in a precise way we also introduce a new and harder dataset which augments the existing grabcut dataset with image and ground truth taken from the pascal voc segmentation challenge 
this paper present a novel mixture of expert framework for pedestrian classification with partial occlusion handling the framework involves a set of component based expert classifier trained on feature derived from intensity depth and motion to handle partial occlusion we compute expert weight that are related to the degree of visibility of the associated component this degree of visibility is determined by examining occlusion boundary i e discontinuity in depth and motion occlusion dependent component weight allow to focus the combined decision of the mixture of expert classifier on the unoccluded body part in experiment on extensive real world data set with both partially occluded and non occluded pedestrian we obtain significant performance boost over state of the art approach by up to a factor of four in reduction of false positive at constant detection rate the dataset is made public for benchmarking purpose 
despite impressive progress in people detection the performance on challenging datasets like caltech pedestrian or tud brussels is still unsatisfactory in this work we show that motion feature derived from optic flow yield substantial improvement on image sequence if implemented correctly even in the case of low quality video and consequently degraded flow field furthermore we introduce a new feature self similarity on color channel which consistently improves detection performance both for static image and for video sequence across different datasets in combination with hog these two feature outperform the state of the art by up to finally we report two insight concerning detector evaluation which apply to classifier based object detection in general first we show that a commonly under estimated detail of training the number of bootstrapping round ha a drastic influence on the relative and absolute performance of different feature classifier combination second we discus important intricacy of detector evaluation and show that current benchmarking protocol lack crucial detail which can distort evaluation 
gait is a well recognized biometric feature that is used to identify a human at a distance however in real environment appearance change of individual due to viewing angle change cause many difficulty for gait recognition this paper re formulates this problem a a regression problem a novel solution is proposed to create a view transformation model vtm from the different point of view using support vector regression svr to facilitate the process of regression a new method is proposed to seek local region of interest roi under one viewing angle for predicting the corresponding motion information under another viewing angle thus the well constructed vtm is able to transfer gait information under one viewing angle into another viewing angle this proposal can achieve view independent gait recognition it normalizes gait feature under various viewing angle into a common viewing angle before similarity measurement is carried out the extensive experimental result based on widely adopted benchmark dataset demonstrate that the proposed algorithm can achieve significantly better performance than the existing method in literature 
we present a fast and accurate algorithm for computing the d pose of object in image called cascaded pose regression cpr cpr progressively refines a loosely specified initial guess where each refinement is carried out by a different regressor each regressor performs simple image measurement that are dependent on the output of the previous regressors the entire system is automatically learned from human annotated training example cpr is not restricted to rigid transformation pose is any parameterized variation of the object s appearance such a the degree of freedom of deformable and articulated object we compare cpr against both standard regression technique and human performance computed from redundant human annotation experiment on three diverse datasets mouse face fish suggest cpr is fast m per pose estimate accurate approaching human performance and easy to train from small amount of labeled data 
we present a method that unifies tracking and video content recognition with application to mobile augmented reality mar we introduce the radial gradient transform rgt and an approximate rgt yielding the rotation invariant fast feature riff descriptor we demonstrate that riff is fast enough for real time tracking while robust enough for large scale retrieval task at the speed our tracking scheme obtains a more accurate global affine motion model than the kanade lucas tomasi klt tracker the same descriptor can achieve retrieval accuracy from a database of image 
this paper present a novel approach to single frame pedestrian classification and orientation estimation unlike previous work which addressed classification and orientation separately with different model our method involves a probabilistic framework to approach both in a unified fashion we address both problem in term of a set of view related model which couple discriminative expert classifier with sample dependent prior facilitating easy integration of other cue e g motion shape in a bayesian fashion this mixture of expert formulation approximates the probability density of pedestrian orientation and scale up to the use of multiple camera experiment on large real world data show a significant performance improvement in both pedestrian classification and orientation estimation of up to compared to state of the art using identical data and evaluation technique 
in this system paper we propose a real time car localisation process in dense urban area by using a single perspective camera and a priori on the environment to tackle this problem it is necessary to solve two well known monocular slam limitation scale factor drift and error accumulation the proposed idea is to combine a monocular slam process based on bundle adjustment with simple knowledge i e the position and orientation of the camera with regard to the road and a coarse d model of the environment a those provided by gi database first we show that thanks to specific slam based constraint the road homography can be expressed only with respect to the scale factor parameter this allows the scale factor to be robustly and frequently estimated then we propose to use the global information brought by d city model in order to correct the monocular slam error accumulation even with coarse d model turning give enough geometrical constraint to allow fitting the reconstructed d point cloud with the d model experiment on large scale sequence several kilometre show that the entire process permit the real time localisation of a car in city centre even in real traffic condition 
we present a novel approach for robust localization of multiple people observed using multiple camera we use this location information to generate sport visualization which include displaying a virtual offside line in soccer game and showing player position and motion pattern our main contribution is the modeling and analysis for the problem of fusing corresponding player positional information a finding minimum weight k length cycle in complete k partite graph to this end we use a dynamic programming based approach that varies over a continuum of being maximally to minimally greedy in term of the number of path explored at each iteration we present an end to end sport visualization framework that employ our proposed algorithm class we demonstrate the robustness of our framework by testing it on frame of soccer footage captured over different illumination condition play type and team attire 
tracking individual in extremely crowded scene is a challenging task primarily due to the motion and appearance variability produced by the large number of people within the scene the individual pedestrian however collectively form a crowd that exhibit a spatially and temporally structured pattern within the scene in this paper we extract this steady state but dynamically evolving motion of the crowd and leverage it to track individual in video of the same scene we capture the spatial and temporal variation in the crowd s motion by training a collection of hidden markov model on the motion pattern within the scene using these model we predict the local spatio temporal motion pattern that describe the pedestrian movement at each space time location in the video based on these prediction we hypothesize the target s movement between frame a it travel through the local space time volume in addition we robustly model the individual s unique motion and appearance to discern them from surrounding pedestrian the result show that we may track individual in scene that present extreme difficulty to previous technique 
we introduce a new class of probabilistic latent variable model called the implicit mixture of conditional restricted boltzmann machine imcrbm for use in human pose tracking key property of the imcrbm are a follows learning is linear in the number of training exemplar so it can be learned from large datasets it learns coherent model of multiple activity it automatically discovers atomic movemes and it can infer transition between activity even when such transition are not present in the training set we describe the model and how it is learned and we demonstrate it use in the context of bayesian filtering for multi view and monocular pose tracking the model handle difficult scenario including multiple activity and transition among activity we report state of the art result on the humaneva dataset 
markerless tracking of human pose is a hard yet relevant problem in this paper we derive an efficient filtering algorithm for tracking human pose using a stream of monocular depth image the key idea is to combine an accurate generative model which is achievable in this setting using programmable graphic hardware with a discriminative model that provides data driven evidence about body part location in each filter iteration we apply a form of local model based search that exploit the nature of the kinematic chain a fast movement and occlusion can disrupt the local search we utilize a set of discriminatively trained patch classifier to detect body part we describe a novel algorithm for propagating this noisy evidence about body part location up the kinematic chain using the unscented transform the resulting distribution of body configuration allows u to reinitialize the model based search we provide extensive experimental result on real world sequence using automatic ground truth annotation from a commercial motion capture system 
ultimately being motivated by facilitating space variant blind deconvolution we present a class of linear transformation that are expressive enough for space variant filter but at the same time especially designed for efficient matrix vector multiplication successful result on astronomical imaging through atmospheric turbulence and on noisy magnetic resonance image of constantly moving object demonstrate the practical significance of our approach 
we present an automatic and efficient method to extract spatio temporal human volume from video which combine top down model based and bottom up appearance based approach from the top down perspective our algorithm applies shape prior probabilistically to candidate image region obtained by pedestrian detection and provides accurate estimate of the human body area which serve a important constraint for bottom up processing temporal propagation of the identified region is performed with bottom up cue in an efficient level set framework which take advantage of the sparse top down information that is available our formulation also optimizes the extracted human volume across frame through belief propagation and provides temporally coherent human region we demonstrate the ability of our method to extract human body region efficiently and automatically from a large challenging dataset collected from youtube 
in this paper we present the use of time of flight tof camera in smart room and how this lead to improved result in segmenting the people in the room from the background and consequently better d reconstruction of the people a calibrated rig of one swissranger sr timeof flight range camera and a high resolution standard camera is set in a smart room consisting of other standard camera a probabilistic background model is used to segment each view and a shape from silhouette d volume is constructed it is shown that the presence of the range camera give way of eliminating regional artifact and therefore a more robust input for higher level application such people tracking or human motion analysis 
